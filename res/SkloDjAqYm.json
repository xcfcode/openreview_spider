{"notes": [{"id": "SkloDjAqYm", "original": "SkeUG2mKK7", "number": 295, "cdate": 1538087779154, "ddate": null, "tcdate": 1538087779154, "tmdate": 1545654829789, "tddate": null, "forum": "SkloDjAqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1ezaO4ZgE", "original": null, "number": 1, "cdate": 1544796346198, "ddate": null, "tcdate": 1544796346198, "tmdate": 1545354525092, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Meta_Review", "content": {"metareview": "This paper is about representation learning for calcium imaging and thus a bit different in scope that most ICLR submissions. But the paper is well-executed with good choices for the various parts of the model making it relevant for other similar domains.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Good applied paper "}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper295/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353265712, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353265712}}}, {"id": "H1g_CX2Q14", "original": null, "number": 12, "cdate": 1543910351808, "ddate": null, "tcdate": 1543910351808, "tmdate": 1543910351808, "tddate": null, "forum": "SkloDjAqYm", "replyto": "rkltL6Vc0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "In our opinion, the manuscript is well-suited for ICLR", "comment": "We kindly thank AnonReviewer1 for increasing his/her score. \n\nAs stated in the ICLR 2019 Call for Papers, applications of deep learning to neuroscience and computational biology belong to the relevant topics explored at the conference. For this reason, in our opinion, the manuscript is well-suited for ICLR, since we apply unsupervised representation learning to an interesting and important problem in the field of neuroscience. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "Sye_xEmt2X", "original": null, "number": 2, "cdate": 1541121008007, "ddate": null, "tcdate": 1541121008007, "tmdate": 1543290237033, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "content": {"title": "Interesting problem but the advantages of the model over other deep generative models are unclear", "review": "The paper proposes a VAE-style model for identifying motifs from calcium imaging videos. As opposed to standard VAE with Gaussian latent variables it relies on Bernouli variables and hence, requires Gumbel-softmax trick for inference. Compared to methods based on matrix factorization, the proposed method has the advantage of not requiring any preprocessing on the imaging videos. My main comments are as follows:\n\n- How sensitive is the method to the choice of beta and other hyperparameters?  Compared to SCC which has fewer hyperparameters, how robust is the method?\n- How does it perform on real data compared to methods based on spike time matrices? Do they generate similar motifs? \n- The application of the method seems quite limited to calcium imaging videos and it does not provide comparison with other deep generative models for videos. Methods such as Johnson et al. NIPS 2016 (Composing graphical models with neural networks for structured representations and fast inference) can also be applied to calcium imaging datasets and can potentially infer the motifs.\n\nI believe the problem of inferring the neural motifs is an interesting problem; however, I think this paper requires more work to it shows its advantages over other deep generative models for video data and also it\u2019s performance on real data compared to SCC (or some other matrix factorization based approach). \n-----------------------------------------------------------------------\nThe authors have addressed my comments about other deep generative models and hyperparameter sensitivity. However, I still think the paper is more suitable for other venues with readers from the neuroscience community. Hence, I change my rating to 5. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "cdate": 1542234494225, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335692433, "tmdate": 1552335692433, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJgD2xKHA7", "original": null, "number": 7, "cdate": 1542979759509, "ddate": null, "tcdate": 1542979759509, "tmdate": 1542979759509, "tddate": null, "forum": "SkloDjAqYm", "replyto": "BJef6TNVAQ", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "Response to additional comments and questions", "comment": "While GANs could be used to learn a generative distribution close to being indistinguishable from the observed data distribution, they are not directly applicable to the question we are targeting here. We are primarily interested in learning a certain constrained latent space structure for motif identification. In order to  get a posterior estimate for these latent variables, performing amortized inference via the proposed VAE is an intuitive and stable approach. This is not possible with a standard GAN.\n\nBy fixing F to a certain value we do not assume a fixed assembly firing structure. The value F only provides an upper bound for the temporal extend of the firing pattern. Within the F frames we do not restrict the firing structure at all. \nAn appropriate value of F mainly depends on the setup of the neurophysiological experiment and the research question in mind. For example, depending on the frame rate of the recording in one case it might make sense to look for motifs with temporal extend up to F=50 frames; while in another case with much lower frame rate motifs with temporal extend beyond 5 frames would be a big surprise. For this reason we intentionally left F as a parameter to be specified by the user. In cases where one is uncertain about the maximum temporal extent to be expected, there is no harm (other than computational effort) starting with a rather too large value of F. \n\nThere are different potential outcomes of the method where the distinction between firing patterns that are actually repeating in the data and artefacts is easily possible with a background in neurophysiology (which we expect the users of our method to have). \nOne example is shown in motif 1 found in real dataset 1. This motif shows extremely high luminosity in large parts of the imaging plane and individual cells can hardly be identified. When looking at the motif and also at the original video one easily sees that this comes from a single event at the beginning of the recording when the carbachol was washed in and the neuronal activity started. \nA second example are the motifs 1 and 2 found in dataset 2. When looking at them one sees that they also do not show individual cells but just randomly looking values. Therefore they can be easily identified as background noise. \nIn addition to looking at the motifs themselves, one can also look at the activations. Even in the not-thresholded case motif 1 and 2 of dataset 1 show only one big peak in their activations. As the patterns we are looking for are defined by reoccurrence, this clearly identifies this \u201cmotifs\u201d as artefacts. Thresholding the activations makes this finding even clearer. \nHowever, we prefer not to provide general instructions about when to discard a motif as this might also highly depend on the experimental setup and the scientific question. \n\nNeuronal assemblies are expected to show slightly variations in their firing and not every time the motif is active all cells might participate in the firing. Hence we expect the motif activation peaks to have different heights. Since the cells participating in any given motif will usually also fire outside the context of the motif, motif activation will also be non-zero elsewhere. We chose the threshold of 70% in order to show that for the motifs 0 found in the two datasets there are multiple time points in the recordings when a huge majority of the pattern is reactivated. Depending on the concrete scientific question it might be useful to apply a different threshold. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "BJef6TNVAQ", "original": null, "number": 6, "cdate": 1542897081788, "ddate": null, "tcdate": 1542897081788, "tmdate": 1542897081788, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SkluQYSgRX", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "Additional comments and questions", "comment": "I've read the additional section, although I believe it would suffice, I would also add what inherent properties you chose to exploit from the VAE compared to alternatives such as GANs.  I would also like to add the following questions;\n\n- To what extent does your results depend on the adequate value of F (Your temporal frame dependency)? In your paper you experiment with different values of F, and for the synthetic data you assume up to 30 consecutive frames as the maximum length - Can you imagine a way of inferring F from the data rather than qualitatively assuming a fixed assembly firing structure?\n\n- How do you qualify the motifs found in the real data as a motif? In Section 4.2 you describe how you define F, looking for up to three motifs, and note that the model together with the SCC method suffer from potential false detections. In the same paragraph you note that this is qualitatively easily discarded by watching the videos. Are there heuristic references that may replicate your assessment of motifs when assessing alternative calcium imaging data? How did you chose the 70% thresholding value?\n\nMy questions above highlight my need to understand the reproducibility of the results found in the paper, for which I am still, quite confident is of good quality."}, "signatures": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer4"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer4", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "SkluQYSgRX", "original": null, "number": 5, "cdate": 1542637855704, "ddate": null, "tcdate": 1542637855704, "tmdate": 1542789200353, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SJlbVaTcTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "Response to AnonReviewer4", "comment": "We are gratefull for AnonReviewer4's extra effort in order to provide us with a third review. We also thank him/her for the positive comments and for considering our paper to be well written and structured, and improving researchers efficiency. \n\nWe agree that the application to fMRI and other imaging modalities makes for interesting future work. \n\nWe took the reviewers comment into account and added a remark in the revised version at the beginning of section 3. The great benefit of this generative model in combination with the proposed VAE is the possibility to directly extract the temporal motifs and their activations and at the same time take into account the sparse nature of neuronal assemblies. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "SJlbVaTcTQ", "original": null, "number": 3, "cdate": 1542278441251, "ddate": null, "tcdate": 1542278441251, "tmdate": 1542278441251, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "content": {"title": "Interesting ideas applied in the neural domain", "review": "Thank you for a pleasurable and informative read, I consider the writing and structure of the paper to be coherent and well written. \n\nGiven an end-to-end learning of neural motifs, a great deal of time can be avoided, reducing the several intermediary steps required to detect motifs from calcium imaging. This paper may very well improve researchers efficiency, in particular when working with calcium imaging. The question remain to what extent these ideas may be useful in other imaging modalities, i.e. fMRI.\n\nMy main critique would be to be more explicit about why the VAE you propose, is superior to other models in the generative modelling domain.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "cdate": 1542234494225, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335692433, "tmdate": 1552335692433, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1lDvaPu6Q", "original": null, "number": 3, "cdate": 1542122846603, "ddate": null, "tcdate": 1542122846603, "tmdate": 1542122846603, "tddate": null, "forum": "SkloDjAqYm", "replyto": "Sye_xEmt2X", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "Response to AnonReviewer1 ", "comment": "We appreciate the reviewers comments and will address them in the following and in the revised version of the manuscript which is already uploaded. \n\nSensitivity to parameters: \nThe main parameters that need to be chosen for each dataset individually are the maximum number of motifs and the maximum motif length. In appendix E.1 and E.2 we show the effects of over- and under-estimating these numbers for LeMoNADe and that they can be set to quite liberal values. Additionally, one of the sparsity parameters beta or \u00e2 has to be adapted to the dataset. In appendix E.3 of the revised version we provide examples of different settings of \u00e2 and beta, showing that they are complementary. This leaves us with three parameters that have to be adapted to a new dataset. For SCC also three parameters have to be chosen: number of motifs, motif length, penalty on l_1 norm of the assemblies = sparsity parameter. \nThe examples in appendix E.3 also indicate that LeMoNADe's results are robust to small variations of \u00e2 and beta and the results only change significantly when the parameters are varied by more than one order of magnitude. Peter et al. describe a similar sensitivity of SCC to the variation of their sparsity parameter. \nOther hyper parameters of LeMoNADe (e.g. temperatures of the BinConcrete relaxation, learning rate) do not need to be adapted to different datasets. We found that our default settings worked well for different kinds of data. \n\nResults on real data compared to SCC results:\nIn appendix D.3 of the revised version we now show the results obtained with SCC on calcium traces of manually extracted ROIs from one of the datasets discussed in the paper. We also show, using traces extracted from the motif identified with LeMoNADe on the original dataset, that SCC and LeMoNADe find highly similar motifs on real data.  \n\nOther generative models: \nAs we mention in the related work section, a few deep generative models exist dealing with video data. However, to the best of our knowledge, none of these models is directly applicable to the task of detecting motifs with temporal structure in calcium imaging data.  \nIndeed, Johnson et al. present an interesting generative model for the analysis of video data. However, we consider this model as not being able to identify motifs with temporal structure from calcium imaging data due to two limitations (for the detection of motifs in calcium videos) of the model by Johnson et al.:\n1. Neuronal assemblies are expected to extend over multiple frames (depending on\nthe frame rate of the recording this could be easily more than 20 frames). Since in Johnson\net al.'s model the underlying latent process is a relatively simple first-order Markovian (switching) linear process, representing longer-term temporal dependencies will be very hard to achieve due to the usually exponential forgetting in such systems. In fact, Johnson et al.'s framework would need to be significantly extended, e.g. using LSTM units, to adapt their model for this task, which is a non-trivial task and could be considered to be a paper in its own right.\n2. In the model of Johnson et al. each frame is generated from exactly one of K latent states. For calcium imaging, however, most frames are not generated by one of the motifs but from noise. While LeMoNADe has the chance to set the latent variables for noise frames simply to zero, Johnson et al.'s model would have to choose one motif as responsible for the frame even if it contains only noise. Moreover, LeMoNADe has the flexibility to also allow the different motifs to temporally overlap. This is also not possible in the model by Johnson et al., since they allow always only exactly one latent state for each frame.  \nFor this reason, we cannot compare to Johnson et al. on the task of detecting motifs in calcium imaging data. In the revised version of the manuscript we extended our citation of Johnson et al. with a short explanation why the model is not directly applicable to our setup of motif detection from calcium imaging data. \n\nThe application is limited to calcium imaging data:\nThe model and network architectures are indeed optimised for the task of detecting motifs in calcium imaging data. This is, however, no downside of the method. Calcium imaging is a method of first importance in neurophysiology. It allows the concurrent monitoring of the individual actions of thousands of neurons at the same time. As explained above, no other method is directly applicable to finding temporal motifs in calcium imaging data and in order to do so we had to adapt our method to the special properties of calcium imaging and neuronal assemblies. Nevertheless, our approach could also be adapted for detecting spatio-temporal motifs in data from other imaging techniques, such as voltage-sensitive dyes or functional magnetic resonance imaging (fMRI)."}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "r1xhWlnDTX", "original": null, "number": 2, "cdate": 1542074372249, "ddate": null, "tcdate": 1542074372249, "tmdate": 1542074372249, "tddate": null, "forum": "SkloDjAqYm", "replyto": "Hyxv_pZwa7", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "i like your response :)", "comment": "to address why \"end-to-end\" is so important, the other strategy is both philosophically and statistically unpleasant.  philosophically, pipelining together many disparate processing stages creates all sorts of problems, as one cannot ever quite evaluate the impact of each decision on the final solution, because it is combinatorial. statistically, when one pipes together many algorithms, typically, the uncertainty associated with the output of each algorithm is lost when piping its MLE or MAP into the next algorithm.  so, if one were to report confidence intervals, they would be way too confident.  moreover, the goal in generating calcium imaging data is to discover motifs (or other interesting patterns), rather than, say, find all the spikes, which is really just a nuisance parameter.  so, piping things together results in optimizing each algorithm for the wrong metric. \n\nprevious review is below:\n\ni am extremely knowledgeable in calcium imaging analysis, much less so in DL, VAE, etc. the problem that the authors address is very important and timely. the pre-processing of datasets for calcium imaging (and other modalities) is a mess, lots of steps, each with lots of parameters, inferences in downstream steps do not typically consider uncertainty in upstream tasks, etc. so, having and \"end to end\" procedure to learn motifs would be awesome.\n\nthere are two aspects of this manuscript that i didn't love\n\n1. is VAE really necessary here? it seems like an extension of the sparse dictionary learning stuff might be sufficient, and much simpler? i'm concerned because more complex methods have more algorithmic parameters to tune, and therefore, having one \"end to end system\" that is nearly as complicated as 3 disparate methods does not really one of the main motivating problems. the authors are clearly capable of doing a simpler thing. i realize this paper is not about that. but, for this paper, some discussion on why this approach was taken instead of the dictionary learning one, and some insight into the complications associated with actually running this method successfully on a new dataset would be highly desirable. fig 1 implies that lemonade is not just better, but also simpler, than other stuff. perhaps you could demonstrate or justify that a bit more?\n\n2. the learned motifs in the simulated data looks like what i'd expect the motifs to look like. however, in the real data, they kind of look mostly like noise. i realize you did a bootstrap thing, etc. nonetheless, i am not convinced that you found legit motifs. specifically you even mention that the 3rd motif is not really even a motif at all, rather, just a single event. i wish there was a more convincing visualization or movie you could provide that made it really clear that you identified real biological motifs. i don't really have any good ideas for how to do that though."}, "signatures": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "Hyxv_pZwa7", "original": null, "number": 1, "cdate": 1542032750800, "ddate": null, "tcdate": 1542032750800, "tmdate": 1542035721377, "tddate": null, "forum": "SkloDjAqYm", "replyto": "B1l-SROznQ", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "content": {"title": "we liked your review last time, and we like it still ;)", "comment": "We kindly thank the reviewer for his/her positive feedback. We would appreciate it if you could state again - as you did in your last review - why the problem we address is an important one and why quote \"having an end-to-end procedure to learn motifs would be awesome\". :) \nOf course there are different approaches in general to infer generative models. However, given our particular generative model our approach to do inference via VI in the form of a VAE is rather intuitive and stable compared to e.g. sampling based approaches which are computationally more expensive or EM based approaches which are usually less flexible. So we are not using VAEs just because they are all the rage right now (then we would use a GAN anyway ;) ). Nevertheless, we will of course continue doing research on this topic and will also investigate other approaches in future work. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617890, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkloDjAqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper295/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper295/Authors|ICLR.cc/2019/Conference/Paper295/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers", "ICLR.cc/2019/Conference/Paper295/Authors", "ICLR.cc/2019/Conference/Paper295/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617890}}}, {"id": "B1l-SROznQ", "original": null, "number": 1, "cdate": 1540685369493, "ddate": null, "tcdate": 1540685369493, "tmdate": 1541534115495, "tddate": null, "forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "content": {"title": "i liked this paper last time i reviewed it, and i like it still :)", "review": "last time i had two comments:\n1. the real data motifs did not look like what i'd expect motifs to look like. now that the authors have thresholded the real data motifs, they do look as i'd expect.\n2. i'm not a fan of VAE, and believe that simpler optimization algorithms might be profitable.  i acknowledge that SCC requires additional steps; i am not comparing to SCC. rather, i'm saying given your generative model, there are many strategies one could employ to estimate the motifs.  i realize that VAE is all the rage, and is probably fine.  in my own experiments, simpler methods often work as well or better for these types of problems.  i therefore believe this would be an interesting avenue to explore in future work.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper295/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium imaging videos", "abstract": "Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or \"motifs\", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations.", "keywords": ["VAE", "unsupervised learning", "neuronal assemblies", "calcium imaging analysis"], "authorids": ["elke.kirschbaum@iwr.uni-heidelberg.de", "manuel.haussmann@iwr.uni-heidelberg.de", "steffen.wolf@iwr.uni-heidelberg.de", "hannah.sonntag@mpimf-heidelberg.mpg.de", "justus.schneider@physiologie.uni-heidelberg.de", "shehab.elzoheiry@physiologie.uni-heidelberg.de", "oliver.kann@physiologie.uni-heidelberg.de", "daniel.durstewitz@zi-mannheim.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "authors": ["Elke Kirschbaum", "Manuel Hau\u00dfmann", "Steffen Wolf", "Hannah Sonntag", "Justus Schneider", "Shehabeldin Elzoheiry", "Oliver Kann", "Daniel Durstewitz", "Fred A Hamprecht"], "TL;DR": "We present LeMoNADe, an end-to-end learned motif detection method directly operating on calcium imaging videos.", "pdf": "/pdf/f33573282308ee8c48f7bf6ecd16e216cb97bc64.pdf", "paperhash": "kirschbaum|lemonade_learned_motif_and_neuronal_assembly_detection_in_calcium_imaging_videos", "_bibtex": "@inproceedings{\nkirschbaum2018lemonade,\ntitle={LeMo{NAD}e: Learned Motif and Neuronal Assembly Detection in calcium imaging videos},\nauthor={Elke Kirschbaum and Manuel Hau\u00dfmann and Steffen Wolf and Hannah Sonntag and Justus Schneider and Shehabeldin Elzoheiry and Oliver Kann and Daniel Durstewitz and Fred A Hamprecht},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkloDjAqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper295/Official_Review", "cdate": 1542234494225, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkloDjAqYm", "replyto": "SkloDjAqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper295/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335692433, "tmdate": 1552335692433, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper295/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}