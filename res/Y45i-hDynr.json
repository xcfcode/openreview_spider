{"notes": [{"id": "Y45i-hDynr", "original": "DYVc0SqQtD_", "number": 907, "cdate": 1601308103817, "ddate": null, "tcdate": 1601308103817, "tmdate": 1614985720057, "tddate": null, "forum": "Y45i-hDynr", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks", "authorids": ["~Kevin_M._Potter1", "ssleder@sandia.gov", "mdsmith@sandia.gov", "jtencer@sandia.gov"], "authors": ["Kevin M. Potter", "Steven Richard Sleder", "Matthew David Smith", "John Tencer"], "keywords": ["graph convolutional neural network", "superpixel", "FAUST", "differential operators"], "abstract": "We present a novel graph convolutional layer that is fast, conceptually simple, and provides high accuracy with reduced overfitting. Based on pseudo-differential operators, our layer operates on graphs with relative position information available for each pair of connected nodes. We evaluate our method on a variety of supervised learning tasks, including superpixel image classification using the MNIST, CIFAR10, and CIFAR100 superpixel datasets, node correspondence using the FAUST dataset, and shape classification using the ModelNet10  dataset. The new layer outperforms multiple recent architectures on superpixel image classification tasks using the MNIST and CIFAR100 superpixel datasets and performs comparably with recent results on the CIFAR10 superpixel dataset. We measure test accuracy without bias to the test set by selecting the model with the best training accuracy. The new layer achieves a test error rate of 0.80% on the MNIST superpixel dataset, beating the closest reported rate of 0.95% by a factor of more than 15%. After dropping roughly 70% of the edge connections from the input by performing a Delaunay triangulation, our model still achieves a competitive error rate of 1.04%.", "one-sentence_summary": "We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "potter|parameterized_pseudodifferential_operators_for_graph_convolutional_neural_networks", "pdf": "/pdf/a86c6d26e57905eac75b2d2e545fb460ebf4d220.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=rQfdEzrQ3", "_bibtex": "@misc{\npotter2021parameterized,\ntitle={Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks},\nauthor={Kevin M. Potter and Steven Richard Sleder and Matthew David Smith and John Tencer},\nyear={2021},\nurl={https://openreview.net/forum?id=Y45i-hDynr}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "9aN2LcFvLA", "original": null, "number": 1, "cdate": 1610040421584, "ddate": null, "tcdate": 1610040421584, "tmdate": 1610474020358, "tddate": null, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "invitation": "ICLR.cc/2021/Conference/Paper907/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "All three reviewers expressed consistent concerns on this submission in their reviews. In addition, none of them enthusiastically supported this work during discussion. It is clear this submission does not make the bar of ICLR. Thus a reject is recommended."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks", "authorids": ["~Kevin_M._Potter1", "ssleder@sandia.gov", "mdsmith@sandia.gov", "jtencer@sandia.gov"], "authors": ["Kevin M. Potter", "Steven Richard Sleder", "Matthew David Smith", "John Tencer"], "keywords": ["graph convolutional neural network", "superpixel", "FAUST", "differential operators"], "abstract": "We present a novel graph convolutional layer that is fast, conceptually simple, and provides high accuracy with reduced overfitting. Based on pseudo-differential operators, our layer operates on graphs with relative position information available for each pair of connected nodes. We evaluate our method on a variety of supervised learning tasks, including superpixel image classification using the MNIST, CIFAR10, and CIFAR100 superpixel datasets, node correspondence using the FAUST dataset, and shape classification using the ModelNet10  dataset. The new layer outperforms multiple recent architectures on superpixel image classification tasks using the MNIST and CIFAR100 superpixel datasets and performs comparably with recent results on the CIFAR10 superpixel dataset. We measure test accuracy without bias to the test set by selecting the model with the best training accuracy. The new layer achieves a test error rate of 0.80% on the MNIST superpixel dataset, beating the closest reported rate of 0.95% by a factor of more than 15%. After dropping roughly 70% of the edge connections from the input by performing a Delaunay triangulation, our model still achieves a competitive error rate of 1.04%.", "one-sentence_summary": "We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "potter|parameterized_pseudodifferential_operators_for_graph_convolutional_neural_networks", "pdf": "/pdf/a86c6d26e57905eac75b2d2e545fb460ebf4d220.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=rQfdEzrQ3", "_bibtex": "@misc{\npotter2021parameterized,\ntitle={Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks},\nauthor={Kevin M. Potter and Steven Richard Sleder and Matthew David Smith and John Tencer},\nyear={2021},\nurl={https://openreview.net/forum?id=Y45i-hDynr}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040421571, "tmdate": 1610474020342, "id": "ICLR.cc/2021/Conference/Paper907/-/Decision"}}}, {"id": "24n_on_iHDQ", "original": null, "number": 1, "cdate": 1603848320523, "ddate": null, "tcdate": 1603848320523, "tmdate": 1606798551197, "tddate": null, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "invitation": "ICLR.cc/2021/Conference/Paper907/-/Official_Review", "content": {"title": "Simple operators for unstructured graphs", "review": "The paper proposes a new graph convolutional layer for graphs with relative position encoding. These types of graphs occur in applications such as meshes, point clouds, and super-pixel neighborhoods. The method extremely simple and generic.\n\nStrengths:\n+ The method is simple and can be easily integrated into existing frameworks. \n+ The method is more general than approaches designed directly for mesh processing\n+ Despite the simplicity, the paper performs well on the Faust node correspondence task. The results are close to that of recent approaches (Haan et al. 2020, Gong et al. 2019) which where directly designed for meshes, while this approach is more general. \n\nWeaknesses:\n- Most of the experiments were devoted to super-pixel image classification, MNIST and CIfFAR which isn't a very compelling use case for this type of method. The paper would be stronger with more experiments on datasets like Faust where the data is not grid structured. It would be interesting to see results on point cloud data, where graphs could be constructed using KNN or other methods. \n- Limited ablations. The features for message passing are derived from spatial gradients, it would be useful to know which operators are necessary. To my knowledge, without the gradient operators, the network reduces to something more like a generic graph convolutional network. Other parts of the paper say things like \"\n- The term psuedo differentiable operators isn't defined in the introduction which makes it difficult to understand how this paper relates to other work. It is not clear from to me the novelty compared to (Tencer & Potter, 2020)\n\nMinor Points:\n* The paper mentions trying voxel_grid and graclus but does not discuss what theses operations are for\n* The organization of the paper could be improved. Experimental details are scattered throughout the paper. Implementation details should be moved from the method sections to the experiments section.\n\nConclusion\nThe proposed method is simple and seems to work well on super-pixel and mesh processing tasks. However, limited experiments make it difficult to assess the generality of the method to other tasks\n\nPost-Rebuttal Update: The response from the authors addressed several of my concerns and several clarity issues where fixed in the update paper. However, I don't think the results on ModelNet10 provide strong support for this method. While I don't think it is reasonable to expect this method to outperform other works which are specifically designed for mesh/point cloud inputs (given that this method is more general), I think there needs to be some application outside of super-pixel classification where the proposed method shows an clear advantage.  \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper907/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper907/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks", "authorids": ["~Kevin_M._Potter1", "ssleder@sandia.gov", "mdsmith@sandia.gov", "jtencer@sandia.gov"], "authors": ["Kevin M. Potter", "Steven Richard Sleder", "Matthew David Smith", "John Tencer"], "keywords": ["graph convolutional neural network", "superpixel", "FAUST", "differential operators"], "abstract": "We present a novel graph convolutional layer that is fast, conceptually simple, and provides high accuracy with reduced overfitting. Based on pseudo-differential operators, our layer operates on graphs with relative position information available for each pair of connected nodes. We evaluate our method on a variety of supervised learning tasks, including superpixel image classification using the MNIST, CIFAR10, and CIFAR100 superpixel datasets, node correspondence using the FAUST dataset, and shape classification using the ModelNet10  dataset. The new layer outperforms multiple recent architectures on superpixel image classification tasks using the MNIST and CIFAR100 superpixel datasets and performs comparably with recent results on the CIFAR10 superpixel dataset. We measure test accuracy without bias to the test set by selecting the model with the best training accuracy. The new layer achieves a test error rate of 0.80% on the MNIST superpixel dataset, beating the closest reported rate of 0.95% by a factor of more than 15%. After dropping roughly 70% of the edge connections from the input by performing a Delaunay triangulation, our model still achieves a competitive error rate of 1.04%.", "one-sentence_summary": "We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "potter|parameterized_pseudodifferential_operators_for_graph_convolutional_neural_networks", "pdf": "/pdf/a86c6d26e57905eac75b2d2e545fb460ebf4d220.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=rQfdEzrQ3", "_bibtex": "@misc{\npotter2021parameterized,\ntitle={Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks},\nauthor={Kevin M. Potter and Steven Richard Sleder and Matthew David Smith and John Tencer},\nyear={2021},\nurl={https://openreview.net/forum?id=Y45i-hDynr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper907/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538131987, "tmdate": 1606915778582, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper907/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper907/-/Official_Review"}}}, {"id": "ARtPk3J8jC0", "original": null, "number": 3, "cdate": 1603977559261, "ddate": null, "tcdate": 1603977559261, "tmdate": 1606747982769, "tddate": null, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "invitation": "ICLR.cc/2021/Conference/Paper907/-/Official_Review", "content": {"title": "Proposed a graph convolutional layer inspired by the pseudo-differential operator", "review": "This paper proposed a novel graph convolutional layer inspired by the pseudo-differential operator. The proposed conv layer is based on Eqs.(1-3), which is  inspired by the differential operators such as gradient and laplacian operator. The paper claims that this proposed convolutional layer enables to achieve state-of-the-art results on super-pixel image classification. \n\nMy major concerns on the work are the limited novelties, insufficient comparisons, and limited significance on the application of super-pixel image classification. \n\n1.  There are several different designs in local convolution over graph nodes in previous works,  such as graph attention convolution, etc. What are the major advantages and novelties of the proposed convolution operators, compared with these previous local convolution designs?\n\n2.  The paper applied the proposed GCN to super-pixel 2D image classification. I have concerns on this application, because the super-pixel-based image recognition using GCN is not a dominant approach in 2D image recognition,  compared with other recognition networks based on regular pixel grids. I suggest that more comparisons on benchmark should be compared, e.g., the 3D shape recognition datasets, or point cloud datasets.\n\n3.  In table I and  II, on the results comparisons on superpixel image recognition, the paper mainly compared with the methods of Knyazev and Gray. I am curious on more comparisons with other GCNs on these datasets if the codes are available. \n\n4. The experimental results show that the proposed network works good on super-pixel image recognition with reduced over-fitting. What are the fundamental reasons that the proposed graph conv. layer is more effective? \n\n\n---\nPost rebuttal comments\uff1a\nThanks for the responses. After reading these responses and other reviews, I still has concerns on the justification of proposed convolution compared with other popular graph convolutions, and also the limited experiments on superpixel image recognition.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper907/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper907/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks", "authorids": ["~Kevin_M._Potter1", "ssleder@sandia.gov", "mdsmith@sandia.gov", "jtencer@sandia.gov"], "authors": ["Kevin M. Potter", "Steven Richard Sleder", "Matthew David Smith", "John Tencer"], "keywords": ["graph convolutional neural network", "superpixel", "FAUST", "differential operators"], "abstract": "We present a novel graph convolutional layer that is fast, conceptually simple, and provides high accuracy with reduced overfitting. Based on pseudo-differential operators, our layer operates on graphs with relative position information available for each pair of connected nodes. We evaluate our method on a variety of supervised learning tasks, including superpixel image classification using the MNIST, CIFAR10, and CIFAR100 superpixel datasets, node correspondence using the FAUST dataset, and shape classification using the ModelNet10  dataset. The new layer outperforms multiple recent architectures on superpixel image classification tasks using the MNIST and CIFAR100 superpixel datasets and performs comparably with recent results on the CIFAR10 superpixel dataset. We measure test accuracy without bias to the test set by selecting the model with the best training accuracy. The new layer achieves a test error rate of 0.80% on the MNIST superpixel dataset, beating the closest reported rate of 0.95% by a factor of more than 15%. After dropping roughly 70% of the edge connections from the input by performing a Delaunay triangulation, our model still achieves a competitive error rate of 1.04%.", "one-sentence_summary": "We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "potter|parameterized_pseudodifferential_operators_for_graph_convolutional_neural_networks", "pdf": "/pdf/a86c6d26e57905eac75b2d2e545fb460ebf4d220.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=rQfdEzrQ3", "_bibtex": "@misc{\npotter2021parameterized,\ntitle={Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks},\nauthor={Kevin M. Potter and Steven Richard Sleder and Matthew David Smith and John Tencer},\nyear={2021},\nurl={https://openreview.net/forum?id=Y45i-hDynr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper907/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538131987, "tmdate": 1606915778582, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper907/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper907/-/Official_Review"}}}, {"id": "-HhBuJyL-rt", "original": null, "number": 2, "cdate": 1603904154240, "ddate": null, "tcdate": 1603904154240, "tmdate": 1605024577212, "tddate": null, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "invitation": "ICLR.cc/2021/Conference/Paper907/-/Official_Review", "content": {"title": " Are simple differential operators really better?", "review": "The paper defines simple differential operators at nodes in a graph (gradient, Laplacian) and uses them in the proposed graph convolutional layer. The claim is that simple operators will limit the representation power of the layer leading to better generalization. While this might be true at some level, it goes against the trends in deep learning which move away from such predefined constraints on the representation power of models. \n\nThe paper is motivated by inherently non-Euclidean domains but mostly uses super-pixel representations of images for experiments which forces inherently Euclidean data into a non-Euclidean representation. Perhaps not surprisingly, while beating the state of the art in graph convolutional neural nets (CNN) on MNIST/CIFAR, the accuracy is still far from regular CNNs for image classification. I wonder if the choice to use the image data comes from the need to have positional information for the nodes of the graph and how well this requirement is met by other applications where the data is inherently non-Euclidean? The introduction only mentions image data as fitting this requirement. This should be further discussed. \n\nPerhaps a better way to demonstrate the claim that constraining the network to simple representations at each node leads to better generalization would be in the context of limited training data (semi-supervised learning, few shot learning etc). On the other hand, the accuracy of the proposed method is behind the state-of-the-art on the only inherently non-Euclidean dataset used (FAUST) which can be considered limited data (100 examples in total).\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper907/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper907/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks", "authorids": ["~Kevin_M._Potter1", "ssleder@sandia.gov", "mdsmith@sandia.gov", "jtencer@sandia.gov"], "authors": ["Kevin M. Potter", "Steven Richard Sleder", "Matthew David Smith", "John Tencer"], "keywords": ["graph convolutional neural network", "superpixel", "FAUST", "differential operators"], "abstract": "We present a novel graph convolutional layer that is fast, conceptually simple, and provides high accuracy with reduced overfitting. Based on pseudo-differential operators, our layer operates on graphs with relative position information available for each pair of connected nodes. We evaluate our method on a variety of supervised learning tasks, including superpixel image classification using the MNIST, CIFAR10, and CIFAR100 superpixel datasets, node correspondence using the FAUST dataset, and shape classification using the ModelNet10  dataset. The new layer outperforms multiple recent architectures on superpixel image classification tasks using the MNIST and CIFAR100 superpixel datasets and performs comparably with recent results on the CIFAR10 superpixel dataset. We measure test accuracy without bias to the test set by selecting the model with the best training accuracy. The new layer achieves a test error rate of 0.80% on the MNIST superpixel dataset, beating the closest reported rate of 0.95% by a factor of more than 15%. After dropping roughly 70% of the edge connections from the input by performing a Delaunay triangulation, our model still achieves a competitive error rate of 1.04%.", "one-sentence_summary": "We introduce a differential operator based graph convolutional layer that outperforms other work on superpixel image classification tasks in speed and accuracy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "potter|parameterized_pseudodifferential_operators_for_graph_convolutional_neural_networks", "pdf": "/pdf/a86c6d26e57905eac75b2d2e545fb460ebf4d220.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=rQfdEzrQ3", "_bibtex": "@misc{\npotter2021parameterized,\ntitle={Parameterized Pseudo-Differential Operators for Graph Convolutional Neural Networks},\nauthor={Kevin M. Potter and Steven Richard Sleder and Matthew David Smith and John Tencer},\nyear={2021},\nurl={https://openreview.net/forum?id=Y45i-hDynr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Y45i-hDynr", "replyto": "Y45i-hDynr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper907/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538131987, "tmdate": 1606915778582, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper907/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper907/-/Official_Review"}}}], "count": 5}