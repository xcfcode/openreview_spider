{"notes": [{"id": "v1JxAmT5HI", "original": null, "number": 19, "cdate": 1580698327068, "ddate": null, "tcdate": 1580698327068, "tmdate": 1580698327068, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "K7h6M2h9eT", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Response", "comment": "We are disappointed that the area chair decided to reject the paper. We believe that novelty is subjective and our work is novel. The concern about hyperparameters is also pretty strange, but is now resolved. See below: https://openreview.net/forum?id=ByeL1R4FvS&noteId=9ruUTMmdG4 \n\nA script to reproduce our performance on GPUs using a unified set of hyperparameters can be found here: \n\nCIFAR-10: https://github.com/google-research/uda/blob/master/image/scripts/run_cifar10_gpu.sh\nSVHN: https://github.com/google-research/uda/blob/master/image/scripts/run_svhn_gpu.sh"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "9ruUTMmdG4", "original": null, "number": 6, "cdate": 1579754521054, "ddate": null, "tcdate": 1579754521054, "tmdate": 1579754521054, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "rJeGMabR9r", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment", "content": {"title": "Current much more reasonable results", "comment": "The author just updated their running commands. A script is uploaded to reproduce the CIFAR-10 performance on GPU with a unified hyperparameter for all data sizes. Link: https://github.com/google-research/uda/blob/master/image/scripts/run_cifar10_gpu.sh. I think this used same hyper-parameter to get reasonable results. I should say, now it's a good improvement for the semi-supervised area."}, "signatures": ["~Xiao_Wang6"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Xiao_Wang6", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504202644, "tmdate": 1576860592844, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment"}}}, {"id": "ByeL1R4FvS", "original": "Hkxnb_MdDH", "number": 894, "cdate": 1569439197986, "ddate": null, "tcdate": 1569439197986, "tmdate": 1577168218469, "tddate": null, "forum": "ByeL1R4FvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 21, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "K7h6M2h9eT", "original": null, "number": 1, "cdate": 1576798709004, "ddate": null, "tcdate": 1576798709004, "tmdate": 1576800927380, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Decision", "content": {"decision": "Reject", "comment": "The paper shows that data augmentation methods work well for consistency training on unlabeled data in semi-supervised learning.\n\nReviewers and AC think that the reported experimental scores are interesting/strong, but scientific reasoning for convincing why the proposed method is valuable is limited. In particular, the authors are encouraged to justify novelty and hyper-parameters used in the paper. This is because I also think that it is not too surprising that more data augmentations in supervised learning are also effective in semi-supervised learning. It can be valuable if more scientific reasoning/justification is provided.\n\nHence, I recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721104, "tmdate": 1576800272066, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper894/-/Decision"}}}, {"id": "HJeeMT1coS", "original": null, "number": 11, "cdate": 1573678343523, "ddate": null, "tcdate": 1573678343523, "tmdate": 1573678343523, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "BJl8i-8vsH", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Please consider increasing your score if our response clarifies.", "comment": "As we have addressed your concerns about hyper-parameters, we hope the reviewer could reconsider the score. Thank you again for your suggestions to help us improve the paper!"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "S1gIR2k9sr", "original": null, "number": 10, "cdate": 1573678286282, "ddate": null, "tcdate": 1573678286282, "tmdate": 1573678286282, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "rkeS_ZLPor", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Please consider increasing your score if our response clarifies.", "comment": "As we have addressed your concerns about hyper-parameters and augmentation strengths, we hope the reviewer could reconsider the score, as promised in the original review. Thank you again for your suggestions to help us improve the paper!"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "BkggUf8Pir", "original": null, "number": 8, "cdate": 1573507655961, "ddate": null, "tcdate": 1573507655961, "tmdate": 1573507946016, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "Hyxy3W4bsr", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "On using Back-translation and RandAugment.", "comment": "Thank you for your comments! \n\n[Back translation] \nWe acknowledge your point about back-translation using translation data. However, as mentioned in the paper, we would like to point out that the translation task itself is quite distinctive from a text classification task and does not make use of any text classification label. In addition, back-translation is a general data augmentation method that can be applied to many tasks with the same model checkpoints.\n\n[RandAugment] \nAutoAugment is indeed very effective, but RandAugment [1] achieves as good performance and is simpler and more widely applicable to new tasks. Its effectiveness can be attributed to the richness of the augmentations. In Appendix A.1, we show that the diversity of the transformations in RandAugment is essential for its great performance. In addition, we also found that using a fixed set of 25 randomly sampled sub-policies does not achieve as good results.\n\nReferences:\n\n[1] The paper is available on arXiv, we do not provide a link here to preserve anonymity.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "ryx4I7IvjB", "original": null, "number": 9, "cdate": 1573507916186, "ddate": null, "tcdate": 1573507916186, "tmdate": 1573507916186, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Hyper-parameters used in the paper.", "comment": "We list our hyper-parameters here for reproducibility. \n\nOur default hyper-parameters are as follows:\n* training steps: 100k;\n* learning rate: 0.03;\n* TSA schedule: linear-schedule;\n* entropy minimization loss weight: 0.1;\n* consistency loss coefficient: 1;\n* weight decay: 5e-4; \n* unlabeled data batch size: 960; \n* softmax temperature: 1 (not used);\n* consistency threshold: 0 (not used).\n\nAdditional hyper-parameters for SVHN with 4,000, 2,000, 1,000, 500, 250 examples: learning rate: 0.05; unlabeled data batch size: 1280.\n\nAdditional hyper-parameters for CIFAR-10 with 4,000, 2,000, 1,000, 500 examples: no additional hyper-parameters.\n\nAdditional hyper-parameters for CIFAR-10 with 250 examples: \n* training steps: 50k;\n* TSA schedule: log-schedule;\n* consistency loss coefficient: 6;\n* weight decay: 7e-4; \n* unlabeled data batch size: 1280; \n* softmax temperature: 0.9;\n* consistency threshold: 0.8.\n\nWe only use a different hyper-parameter for the case of 250 examples on CIFAR-10. The hyper-parameters for other data sizes are the same. We found that given a reasonably large labeled set, our method is robust to hyper-parameters. Therefore, we use the same hyper-parameters in other cases.\n\nWe have also included these detailed hyper-parameters in our paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "rkeS_ZLPor", "original": null, "number": 5, "cdate": 1573507436583, "ddate": null, "tcdate": 1573507436583, "tmdate": 1573507591201, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "Byxu8IcTKH", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback!", "comment": "[Contribution] \nIt is not known before that the quality of data augmentation can lead to such a large and consistent gain on the semi-supervised learning performance. Our work is largely empirical and we have conducted extensive experiments to support our results.\n\n[Strengths of augmentation] \nFor each transformation in RandAugment, there is a single scalar from 1 to 10 to control the strength of the augmentation (higher value means more changes to the content of the input image). In theory, it is possible to adjust the distribution or range of the augmentation strength on each dataset based on dev performance. However, in this work, we find it works well to simply uniformly sample from 1 to 10 without any tuning.\n\n[Hyper-parameters]\nFor simplicity, we performed a random sampling search over hyper-parameters and choose the best one based on validation sets (20% of the training sets with different sizes). Specifically, we tried the following ranges:\n* training steps: 50k, 100k;\n* learning rate: 0.03, 0.05, 0.1;\n* TSA schedules: log-schedule, linear-schedule, exp-schedule, not using TSA;\n* entropy minimization loss weight: 0, 0.1, 0.3;\n* consistency loss weight: 1, 3, 6;\n* weight decay rate: 5e-4, 7e-4, 1e-3;\n* unlabeled data batch size: 960, 1280;\n* softmax temperature: 1, 0.9;\n* confidence threshold: 0, 0.8. \n\nThe sentence in the Appendix ''Other hyper-parameters follow those of the released AutoAugment code'' actually refers to the fact that we employ the same model architectures, including Wide-ResNet, Shake-Shake and ShakeDrop, as in the AutoAugment paper. AutoAugment use the same hyper-parameters as reported in the papers introducing the models except for the weight decay and the learning rate schedule.\n\nSince we use RandAugment instead of AutoAugment to produce perturbation, we DO NOT rely on any augmentation strategy searched by AutoAugment at all.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "BJxBTbLPsr", "original": null, "number": 7, "cdate": 1573507517203, "ddate": null, "tcdate": 1573507517203, "tmdate": 1573507517203, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "r1lbeiL5KH", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback!", "comment": " "}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "BJl8i-8vsH", "original": null, "number": 6, "cdate": 1573507485824, "ddate": null, "tcdate": 1573507485824, "tmdate": 1573507485824, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "rkxWsB9TKS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback!", "comment": "[Contribution]  \nIt is not known before that the quality of data augmentation can lead to such a large and consistent gain on the semi-supervised learning performance. Our work is largely empirical and we have conducted extensive experiments to support our results.\n\n[Hyper-parameters] \nWe only use a different hyper-parameter for the case of 250 examples on CIFAR-10. The hyper-parameters for other data sizes are the same. We found that given a reasonably large labeled set, our method is robust to hyper-parameters. Therefore, we use the same hyper-parameters in other cases.\n\nWe have already uploaded the hyper-parameters to github at the request of the comment but did not provide a link here to preserve anonymity. \n\nOur default hyper-parameters are as follows:\n* training steps: 100k;\n* learning rate: 0.03;\n* TSA schedule: linear-schedule;\n* entropy minimization loss weight: 0.1;\n* consistency loss coefficient: 1;\n* weight decay: 5e-4; \n* unlabeled data batch size: 960; \n* softmax temperature: 1 (not used);\n* consistency threshold: 0 (not used).\n\nAdditional hyper-parameters for SVHN with 4,000, 2,000, 1,000, 500, 250 examples: learning rate: 0.05; unlabeled data batch size: 1280.\n\nAdditional hyper-parameters for CIFAR-10 with 4,000, 2,000, 1,000, 500 examples: no additional hyper-parameters.\n\nAdditional hyper-parameters for CIFAR-10 with 250 examples: \n* training steps: 50k;\n* TSA schedule: log-schedule;\n* consistency loss coefficient: 6;\n* weight decay: 7e-4; \n* unlabeled data batch size: 1280; \n* softmax temperature: 0.9;\n* consistency threshold: 0.8.\n\nWe have included these detailed hyper-parameters in our paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "Hyxy3W4bsr", "original": null, "number": 5, "cdate": 1573106087258, "ddate": null, "tcdate": 1573106087258, "tmdate": 1573106136287, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment", "content": {"title": "Doubts about UDA called the methodology of semi-supervised learning", "comment": "Hello\uff0c\n     I have one question about the UDA on Bert as semi-supervised learning method.In the paper ,you said that \"on binary sentiment analysis tasks, with only 20 supervised examples, UDA outperforms the previous SOTA trained with full supervised data on IMDb and is competitive on Yelp-2 and Amazon-2.\"\uff0cbut in your code I realised that you use the pre-trained model of back translation,which trained on all labeled dataset.As defined in wikipedia\u2014\u2014Semi-supervised learning is a class of machine learning tasks and techniques that also make use of unlabeled data for training \u2013 typically a small amount of labeled data with a large amount of unlabeled data.In my own opinion,during the training of SSL, it can't use external information. So I think the UDA on NLP tasks couldn't be called as the methodology of semi-supervised learning.\n    About UDA on image classification,I'm not very familiar about tasks on image classification. But I read the paper of Autoaugment  previously. Well\uff0cI noticed that in the paper you just use a random method to augment data then get  perfect results. As we know that Autoaugment is a very effective method on data augmentation.So is such an impressive Autoaugment  on labeled datasets not as good as a random selection strategy algorithm on a large number of unlabeled datasets?What I mean is that I doubt about the results of UDA on image tasks."}, "signatures": ["~Zhang_Yuanyuan1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Zhang_Yuanyuan1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504202644, "tmdate": 1576860592844, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment"}}}, {"id": "r1lbeiL5KH", "original": null, "number": 1, "cdate": 1571609320729, "ddate": null, "tcdate": 1571609320729, "tmdate": 1572972539020, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper \"Unsupervised Data Augmentation for Consistency Training\" marries two recent ideas of \n1. \"Data Augmentation\" (DA) from supervised learning: The authors explore various methods for \"DA\" mostly inspired by much recent work such as Random image transformations, Backtranslation, and TF-IDF based word replacement.\n2. \"Consistency Training\" (CT) from semi-supervised learning: CT tries to minimize the divergence between the output distributions of the classifiers that are produced by adding noise to the input.\n\nThe key insight in this paper is that, data augmentation methods that work well during supervised training should also work equally well as the noise distribution for consistency training on unlabeled data. The authors support this claim empirically through the experiments in table 1 and 2. \n\nThe paper is well written and the authors present extensive comparative and ablation tests to demonstrate that their proposed method works well with both low and high amounts of labeled data.  This paper should be accepted into the conference."}, "signatures": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575572015950, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper894/Reviewers"], "noninvitees": [], "tcdate": 1570237745436, "tmdate": 1575572015962, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Review"}}}, {"id": "rkxWsB9TKS", "original": null, "number": 2, "cdate": 1571820952528, "ddate": null, "tcdate": 1571820952528, "tmdate": 1572972538983, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, their method brings substantial improvements across six language and three vision tasks under the same consistency training framework. I think the topic itself is interesting and I have the following concerns.\n(1) The first is about the contribution of this paper. In this paper, all the results, including the augmented methods are all well established approaches. The authors have just employed them in solving a new problem, without support about why they work. Thus, the results are only strategies, without theoretical guarantee or insights. It is difficult to convince the reviewers.\n(2) Although the authors have achieved seemingly promising results, I think it can not convince me since the authors have not answered the questions about why and when. I think this paper likes a technical report, not a research paper.\n(3) I have also noticed the discussions among the authors and other readers. It seems that the large improvement depends on the parameters heavily. So, why not to share the parameters directly? "}, "signatures": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575572015950, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper894/Reviewers"], "noninvitees": [], "tcdate": 1570237745436, "tmdate": 1575572015962, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Review"}}}, {"id": "Byxu8IcTKH", "original": null, "number": 3, "cdate": 1571821135737, "ddate": null, "tcdate": 1571821135737, "tmdate": 1572972538937, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes to substitute simple noising operations with many data augmentation methods in consistency-based semi-supervised learning. The main idea is the same as previous work: constrain the model predictions of unlabeled examples to be invariant to different noise. The proposed UDA is evaluated on a wide range of language and vision tasks.\n\nOverall, the paper is well-written and clear. The most impressive point of this paper is its strong empirical results. However, it looks not surprising to me that more data augmentations found in supervised learning are also effective in semi-supervised learning. The paper fails to provide any theoretical insights but a thorough empirical evaluation.\n\nOne of my concerns is that the hyperparameters on vision tasks follow those of AutoAugment, which is carefully tuned on supervised tasks. Apparently, their hyperparameters are based on the whole labeled training dataset. In this case, the adopted hyperparameters include sort of information of the whole labeled dataset. Is it fair?\n\nAnother concern is how to control the strength of augmentations. For example, for digit images like SVHN, a \"6\" rotates by 180 degree is \"9\", whose prediction should change correspondingly. In this case, the assumption of invariance does not hold when the augmentation is too strong. \n\nI'm willing to increase my score if the authors address my concerns."}, "signatures": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575572015950, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper894/Reviewers"], "noninvitees": [], "tcdate": 1570237745436, "tmdate": 1575572015962, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Review"}}}, {"id": "rklvT2-AqS", "original": null, "number": 3, "cdate": 1572900030779, "ddate": null, "tcdate": 1572900030779, "tmdate": 1572900842385, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "HyxAGp459r", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "You can tune hyperparameters with a small dev set by running experiments multiple times to reduce variance. ", "comment": "Thank you for your comments. First, we actually do not need to tune hyperparameters for a specific labeled set size except for 250 examples case on CIFAR-10. The same or similar hyperparameters work well for the cases with 500, 1000, 2000, 4000 examples on CIFAR-10 and work well across all data sizes for SVHN. As for the case with 250 examples on CIFAR-10, using the same hyperparameter leads to an error rate of $16.8 \\pm 4.19$. We will include the performance without hyperparameter tuning into the results section of our paper and include the tuned hyperparameters into the Appendix.\n\nWe do not yet know why using 250 labeled examples requires a very different hyperparameter. My guess is that it is a stability issue and improving the implementation's stability could help it. For example, it might help to employ Exponential Moving Average of model parameters, using a different learning rate schedule and so on. I personally do not have time to investigate it at this moment due to other obligations such as preparing thesis. If you indeed care about the case with a very small number of examples, it might be interesting to study how to improve the stability.\n\nSecond, for the 250 examples case, we can achieve better performance by tuning hyperparameters and it is feasible to tune hyperparameters with a small number of dev examples, e.g., with 50 examples. The key is to run experiments multiple times and use the average accuracy instead of a single accuracy to determine which hyperparameter is better. \n\nEmpirically, with 50 images in the dev set, it works well to run 10-20 experiments for each hyperparameter. Performance of semi-supervised learning algorithms is usually reported on 10 runs [1, 2, 3], so running multiple times should be expected though it incurs a significant computation cost. We will upload the code for splitting data so that you can try it yourself. We will also upload logs of tuning hyperparameters for the 250 labels' case.\n\nTheoretically, there are two difficulties to overcome when using a small dev set: (1) the hyperparameter that work well for a small dev set can overfit the small set and does not work well for a larger dev / test set. We empirically verified that this situation does not hold. We compared hyperparameter selection using a fixed small dev set and using cross validation and found that they lead to similar selections of hyperparameters. In fact, it has been found that models which performs well on a fixed test set generalize to other test sets [4, 5]. (2) It can be hard to estimate the performance on a small dev set due to a large variance. This difficulty is real and we run experiments multiple times and take the average to reduce the variance.\n\nCentral Limit Theorem (CLT) can explain why it helps to run experiments multiple times. This is a self-contained description of CLT: Without loss of generality, suppose that for a set of hyperparameter $h$, the accuracy measured on $k$ dev samples is subject to a Gaussian distribution\n$$\\mathcal{N}(\\mu_{h}, \\sigma_{h, k}^2)$$\nwhere the mean $\\mu_{h}$ is dependent on the hyperparameter $h$ and the standard deviation $\\sigma_{h, k}$ depends on both $h$ and $k$. A better hyperparameter would lead to a higher mean $\\mu_{h}$. A smaller dev set size would lead to a larger std $\\sigma_{h, k}$.\n\nTo determine whether $h_1$ is better than $h_2$, we run $n$ experiments for both $h_1$ and $h_2$. Suppose we get accuracies $X_1, X_2, \\cdots, X_n$ for hyperparameter $h_1$ and $Y_1, Y_2, \\cdots, Y_n$ for hyperparameter $h_2$. We compute their sample mean by  $$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i$$ $$\\bar{Y}=\\frac{1}{n}\\sum_{i=1}^n Y_i$$\n\nBasically, $\\bar{X}$ and $\\bar{Y}$ are our estimates for $\\mu_{h_1}$ and $\\mu_{h_2}$ and we decide that $h_1$ is better than $h_2$ if $\\bar{X}$ is higher than $\\bar{Y}$. \n\nBy CLT, we have that $\\bar{X}$ and $\\bar{Y}$ converge in distribution to $$\\mathcal{N}(\\mu_{h_1}, \\sigma_{h_1, k}^2 / n)$$ $$\\mathcal{N}(\\mu_{h_2}, \\sigma_{h_2, k}^2 / n)$$\n\nSo when $\\sigma_{h_1, k}$ and $\\sigma_{h_2, k}$ are large due to a small dev size, if you just run one experiment for a set of hyperparameter (setting $n$ to $1$), then the variance of $\\bar{X}$ and $\\bar{Y}$ might dominate the difference in $\\mu_{h_1}$ and $\\mu_{h_2}$. But if you sample multiple times by setting $n$ to $10$ or a larger number, the variance of $\\bar{X}$ and $\\bar{Y}$ can be reduced by $n$. So $\\bar{X}$ and $\\bar{Y}$ are reliable estimates for $\\mu_{h_1}$ and $\\mu_{h_2}$.\n\nThird, you mentioned that \u201cIn your mentioned paper, they are based 4,000 images. You use only 50 images to pick up the best hyper-parameter\u201d. This is not correct. We said that we use 50 examples for the case with 250 examples. For the case with 4,000 examples, we use 800 of them as the dev set and use the rest 3,200 images for training.\n\nLet us know if you have further questions or concerns.\n\nReferences are listed in the following post due to space limits.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "rJeGMabR9r", "original": null, "number": 4, "cdate": 1572900105644, "ddate": null, "tcdate": 1572900105644, "tmdate": 1572900118709, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "rklvT2-AqS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "References for the previous post", "comment": "References:\n\n[1] Miyato, T., Maeda, S. I., Koyama, M., Ishii, S. (2018). Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, 41(8), 1979-1993.\n\n[2] Tarvainen, A., Valpola, H. (2017). Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in neural information processing systems (pp. 1195-1204).\n\n[3] Laine, S., Aila, T. (2016). Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242.\n\n[4] Recht, B., Roelofs, R., Schmidt, L., Shankar, V. (2018). Do CIFAR-10 classifiers generalize to CIFAR-10?. arXiv preprint arXiv:1806.00451.\n\n[5] Recht, B., Roelofs, R., Schmidt, L., Shankar, V. (2019). Do ImageNet Classifiers Generalize to ImageNet?. arXiv preprint arXiv:1902.10811."}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "HyxAGp459r", "original": null, "number": 3, "cdate": 1572650262100, "ddate": null, "tcdate": 1572650262100, "tmdate": 1572650262100, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "BJgqLpcjFB", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment", "content": {"title": "How can we believe your results", "comment": "You said you use 50 examples to pick best hyper-parameter. This is not included in your code and your paper. Also, i never think 50 examples can really reflect the real distribution of the 50,000 examples. That is completely random if you use different random seed. I should say, if you tune hyper parameter based on that, what you get is completely random. Furthermore, you said you tune that based on 50 examples. Then please give me the code, let me run with different random seed to pick hyper-parameter and I am sure they are not the same and lead to completely different results. I am very confident you can not even achieve the mixmatch's performance.\nIn your mentioned paper, they are based 4,000 images. You use only 50 image to pick up best hyper-parameter. From my experience, that's impossible. If that can work, please release your code to let everyone \nto have a test. "}, "signatures": ["~Xiao_Wang6"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Xiao_Wang6", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504202644, "tmdate": 1576860592844, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment"}}}, {"id": "BJgjRju0Yr", "original": null, "number": 2, "cdate": 1571879891142, "ddate": null, "tcdate": 1571879891142, "tmdate": 1571968764837, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment", "content": {"title": "Question about Intuition behind Training Signal Annealing (TSA)", "comment": "Hello,\n\nIn your paper you provide intuition for when to use different schedules of TSA, specifically the logarithmic, linear, and exponential schedules: \n\n\"Intuitively, when the model is prone to overfit, e.g., when the problem is relatively easy or the number of labeled examples is very limited, the exp-schedule is most suitable as the supervised signal is mostly released at the end of training. In contrast, when the model is less likely to overfit (e.g., when we have abundant labeled examples or when the model employs effective regularization), the log-schedule can serve well.\"\n\nThe above would suggest that in the lowest data regimes in your paper (For example: CIFAR10 on 250 labels or SVHN on 250 labels), the exp-schedule would work best and in the higher data regimes the linear and log-schedule would work better.\n\nHowever, in your code implementation, you have listed that the training signal annealing schedule that achieved SOTA performance on CIFAR10 with 250 labels is the log-schedule.\n\nThis would directly contradict what is stated as intuition in the paper, as in the lowest data regime (250 labels) you used the log-schedule, which the paper states as only used \"when we have abundant labeled examples\". Is this a mistake in the paper or the implementation?\n\nThank you for clarifying! "}, "signatures": ["~Varun_Nair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Varun_Nair1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504202644, "tmdate": 1576860592844, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment"}}}, {"id": "rygEX4ak5B", "original": null, "number": 2, "cdate": 1571963931734, "ddate": null, "tcdate": 1571963931734, "tmdate": 1571964183633, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "BJgjRju0Yr", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Intuition behind TSA", "comment": "Hi, good question! Firstly, when entropy minimization is not employed, TSA with exp-schedule indeed works better for small labeled data. As shown in the ablation study for Yelp-5 in Table 6, the model achieves an error rate of 41.35, 45.41, 49.06 with exp-schedule, linear-schedule and log-schedule respectively. Secondly, when entropy minimization is employed, the confidence on labeled data is high even with an exp-schedule, since the model is regularized to make sharp predictions. In this case, TSA with exp-schedule is not able to limit the confidence on labeled data. As for CIFAR-10 with 250 examples, we employed entropy minimization to make the predictions sharper. Hence, we do not employ exp-schedule. We leave it as a future work to study how to better couple TSA with entropy minimization. "}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "BJgqLpcjFB", "original": null, "number": 1, "cdate": 1571691858433, "ddate": null, "tcdate": 1571691858433, "tmdate": 1571691858433, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "rkeL8DK9YB", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment", "content": {"title": "Source of Effectiveness.", "comment": "Hi, the effectiveness of our method is due to employing advanced data augmentation instead of using KL divergence. Specifically, we found that state-of-the-art data augmentations found in supervised learning can also serve as a superior source of noise under the consistency enforcing semi-supervised framework. The importance of advanced data augmentation is demonstrated clearly in Section 3.1, i.e., our study of correlation between supervised and semi-supervised performances. When we use cropping and flipping to augment the data, we only achieve an error rate of 16.17 with 4,000 labeled examples. In contrast, using RandAugment leads to an error rate of 4.23. \n\nWe followed prior works on semi-supervised learning (e.g., SNTG https://arxiv.org/pdf/1711.00258.pdf) and tuned hyperparameters for different data sizes. We do strictly limit the number of labeled examples while tuning the hyperparameters. For example, to determine the best hyperparameter for the setting with 250 labeled examples, we used 200 examples as the training set and 50 examples as the validation set and found out the best hyperparameters. Then we used the found hyperparameter to train a model with 250 labeled examples. We will release the corresponding hyperparameters.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper894/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper894/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper894/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper894/Authors|ICLR.cc/2020/Conference/Paper894/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164572, "tmdate": 1576860559820, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Official_Comment"}}}, {"id": "rkeL8DK9YB", "original": null, "number": 1, "cdate": 1571620685600, "ddate": null, "tcdate": 1571620685600, "tmdate": 1571620685600, "tddate": null, "forum": "ByeL1R4FvS", "replyto": "ByeL1R4FvS", "invitation": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment", "content": {"comment": "I think KL divergence is not a new idea in your paper for the semi-supervised area, which has been proposed in VAT. I don't know why your results work so well. \nTherefore, I simply run your code on cifar with the command you suggested. The results listed in the paper can't be achieved for 250 label, 500 label, 1000label. I think you may fine tuned the hyper parameters to get the results. \nHowever, in semi-supervised setting, for different number of labels, you must used the same hyper-parameters to evaluate the results.\nAlso, please release the command to run your code for different labels and show your training loss/accuracy vs epoch figures for 250labels. ", "title": "Doubted about the results"}, "signatures": ["~Xiao_Wang6"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Xiao_Wang6", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Data Augmentation for Consistency Training", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "authorids": ["qizhex@cs.cmu.edu", "dzihang@cs.cmu.edu", "hovy@cs.cmu.edu", "thangluong@google.com", "qvl@google.com"], "keywords": ["Semi-supervised learning", "computer vision", "natural language processing"], "TL;DR": "A semi-supervised learning method that enforces a model's prediction to be robust to advanced data augmentations.", "abstract": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.", "pdf": "/pdf/d8d552f970cb61b05f5c1d2d5f07ba24cba89a7d.pdf", "paperhash": "xie|unsupervised_data_augmentation_for_consistency_training", "original_pdf": "/attachment/4addd63466fe95c6aee4c6235870fd18f90e3d00.pdf", "_bibtex": "@misc{\nxie2020unsupervised,\ntitle={Unsupervised Data Augmentation for Consistency Training},\nauthor={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeL1R4FvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeL1R4FvS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504202644, "tmdate": 1576860592844, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper894/Authors", "ICLR.cc/2020/Conference/Paper894/Reviewers", "ICLR.cc/2020/Conference/Paper894/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper894/-/Public_Comment"}}}], "count": 22}