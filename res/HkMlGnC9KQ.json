{"notes": [{"id": "HkMlGnC9KQ", "original": "r1e1RJncY7", "number": 1233, "cdate": 1538087944009, "ddate": null, "tcdate": 1538087944009, "tmdate": 1545355375299, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ryxw5m4GgV", "original": null, "number": 1, "cdate": 1544860558918, "ddate": null, "tcdate": 1544860558918, "tmdate": 1545354533155, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Meta_Review", "content": {"metareview": "Reviewers generally found the RKHS perspective interesting, but did not feel that the results in the work (many of which were already known or follow easily from known theory) are sufficient to form a complete paper. Authors are encouraged to read the detailed reviewer comments which contain a number of critiques and suggestions for improvement.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "interesting perspective but insufficient contribution"}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1233/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352914184, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352914184}}}, {"id": "HkgaEqpayV", "original": null, "number": 9, "cdate": 1544571444556, "ddate": null, "tcdate": 1544571444556, "tmdate": 1544571496242, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "SygrOUpak4", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "reply", "comment": "Right, but note that this expression does not apply for x > -lambda epsilon: phi(x) is simply equal to 1 in this case, by definition. We will consider including a plot of the function phi if it helps clarify this definition."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "S1lj0an61N", "original": null, "number": 8, "cdate": 1544568275071, "ddate": null, "tcdate": 1544568275071, "tmdate": 1544568275071, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "SJgbLH36k4", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "response", "comment": "Thank you for you interest in our paper and for going through our proof.\n\nWe believe our current choice of function phi is correct: it corresponds to a ramp-like function that is equal to 0 to the left of (-gamma - lambda epsilon), 1 to the right of (- lambda epsilon), and is linear from 0 to 1 in between. Indeed, evaluating $1 + (x + lambda epsilon) / gamma$ at $x = -gamma - lambda epsilon$ and $x = -lambda epsilon$ yields 0 and 1, respectively."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "rkloNE79C7", "original": null, "number": 7, "cdate": 1543283762949, "ddate": null, "tcdate": 1543283762949, "tmdate": 1543283762949, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "Skx8HkyGT7", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "Thanks for the response!", "comment": "Dear Paper1233 Authors,\n\nAfter reading the response carefully, I still feel like this paper is not ready to publish. Part of the reason is the organization of this paper does not highlight its main contributions, and also the paper lacks in-depth original contribution.\n\nI encourage the authors to continue their works in this direction and reorganize the work to emphasize the main contributions. Especially, the lower bound+upper bound methods for RKHS regularization can be further developed and extended to a good work on its own.\n\nThanks,\nPaper1233 AnonReviewer1\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "SyevlN2F0X", "original": null, "number": 6, "cdate": 1543255023309, "ddate": null, "tcdate": 1543255023309, "tmdate": 1543255023309, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "Update after revision", "comment": "We have updated the paper with clarifications on the novelty of our RKHS perspective to regularization, and emphasized the benefits of controlling the RKHS norm, an aspect which was not clear in the original submission. We also included additional empirical results.\n\nIn particular, we hope to have clarified the following points:\n * empirically, we find that an appropriate control of the RKHS norm seems to be missing for existing methods based on robust optimization (which can give up global stability in favor of local robustness) or spectral norms (which reduce model complexity but can remain unstable locally)\n * the penalties |f|_M^2 and |\\nabla f|^2 that we obtain from RKHS arguments seem to provide a better control of the RKHS norm in practice\n * combining lower and upper bound approaches can further help control this norm\n * empirically, these methods often yield the best generalization performance on small datasets, and additionally can provide the most useful guarantees on adversarially robust generalization\n\nWe hope this update clarifies the concerns of the reviewers, and we would like to sincerely thank all reviewers again for their useful comments and remarks, which helped us improve our paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "Skx8HkyGT7", "original": null, "number": 2, "cdate": 1541693245927, "ddate": null, "tcdate": 1541693245927, "tmdate": 1541695700899, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "S1x3WD8ChQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for his comments. We address the comments about novelty in our general response ( https://openreview.net/forum?id=HkMlGnC9KQ&noteId=S1eid00WaQ ), for instance concerning the relationship to previous work, and the regularization penalty ||f||_M we propose. More detailed comments are addressed below.\n\n** weakness of adversarial training\n\nAs noted in our general response, our ||f||_M regularization approach empirically yields models with a more useful certified generalization guarantee in the presence of adversaries on Cifar10, while PGD adversarial training would likely require local verification of robustness around each test example, and we are not aware of useful guarantees on adversarial generalization for such models. We agree that this aspect is not clear in the current submission, and we will improve it in the next version.\n\n** relationship with traditional RKHS regularization\n\nThere is indeed no question that kernel methods/RKHSs have been widely used for regularization of non-linear functions, for over 20 years now, however these methods typically rely on solving convex optimization problems using the kernel trick, or various kernel approximations (such as random Fourier features). Separately, defining RKHSs that contain neural networks has indeed been the study of previous work, such as Bietti and Mairal (2018) or Zhang et al. (2016; 2017), however these only study theoretical properties of the kernel mapping and the RKHS norm, or derive convex learning procedures to replace training neural networks. Our approach is quite different, in that we leverage these insights to obtain practical regularization strategies for generic neural networks.\n\n** new regularization methods\n\nIn addition to the ||f||_M lower bound penalty discussed in our general response, we note that combined approaches based on lower bound + upper bound methods are also novel to the best of our knowledge, and in particular we found combining robust optimization techniques with spectral norm constraints to be quite successful in many of the small data scenarios considered (see Table 1).\n\nWe will happily clarify some of these points in an updated version of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "HJxIJl1za7", "original": null, "number": 3, "cdate": 1541693405802, "ddate": null, "tcdate": 1541693405802, "tmdate": 1541693690572, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "SylRu6annQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for his comments. Our general response ( https://openreview.net/forum?id=HkMlGnC9KQ&noteId=S1eid00WaQ ) details the aspects related to novelty. Further comments are addressed below.\n\n** comparison with Parseval networks + works of Miyato et al.\n\nWe agree that a better comparison with the Parseval network paper would be useful. Regarding generalization, the Parseval networks paper seems to only discuss standard generalization performance based on robustness, not *adversarial* generalization (that is, test error in the presence of an adversary), as considered in our work. Also, our bound seems significantly better: whereas the bound in Ciss\u00e9 et al. (2017) has an exponential dependence on the dimension due to covering number of the input space (this is a weakness of the generalization bounds from Xu and Mannor (2012), which do not leverage statistical properties of the function class being used), our margin bound has no dependence on the dimension, or only a logarithmic dependence if we use the Rademacher analysis of Bartlett et al. (2017) instead of our kernel framework.\nRegarding the improper acknowledgement of Miyato's work, we are a bit surprised by the reviewer's comment: we cite the work of Miyato almost each time we mention spectral regularization and the acknowledgment seems clear to us throughout the paper. However, if the reviewer finds any ambiguous claim in our paper that we would have missed, we would be happy to clarify it.\n\n ** role of the specific regularizer\n\nThe reviewer points out that some of the regularization functions we consider such as the spectral norm penalties, are not based on the precise upper bound we derive. Whereas optimizing a product of spectral norms is impractical, which naturally leads to other variants (sums of spectral norms or constraints), we would like to emphasize that such variants are empirically effective in the sense that the quantities obtained at the end of training---such as the spectral norms, (local or global) Lipschitz constants, and the margins of each datapoint---are controlled. These quantities are also what governs our generalization guarantees. Besides, we also note that many deep architectures with ReLUs (particularly VGG-like, if we ignore bias terms) are homogeneous in the weight matrices, making the relative norms at each layer not crucial (multiplying one layer by a scalar and dividing another by the same scalar leads to an equivalent model). In particular, this justifies using the same value for the spectral norm constraint of each layer.\n\n ** Usefulness of the RKHS framework\n\nThe RKHS framework was quite beneficial in our work because it displays several properties at once:\n (1) clear understanding of regularization and generalization through margin bounds\n (2) makes a clear link between stability/robustness and regularization/generalization by using the RKHS norm and properties of the kernel mapping\n (3) yields practical regularization algorithms through upper and lower bounds\n\nLooking at alternatives, if we consider the product of spectral norms instead of the RKHS norm, then we may have (1) using results of Bartlett et al.(2017) and partly (2) since we can upper bound the Lipschitz constant, however algorithms based on lower bounds are crucially missing, and our experiments suggest that these algorithms are often important for good performance, both for regularization on small datasets and for robustness.\nIf instead we consider the robust optimization approach, we obtain variants of good algorithms (3) such as PGD or gradient penalties, and perhaps some connections to regularization following Xu et al. (2009), however it is difficult to obtain useful generalization guarantees without defining a precise quantity of model complexity. Additionally, such approaches may favor local over global robustness, particularly with powerful function approximators such as neural networks, which may be undesirable when one wants global guarantees.\n\n** bounding l2 robustness with product of spectral norms\n\nIt is indeed easy to upper bound l2 robustness using the product of spectral norms. However, such a robustness guarantee is only useful if this quantity is appropriately controlled during training. In particular, for methods like PGD, we find that such a quantity is poorly controlled on Cifar10, and would thus only provide very weak guarantees.\n\n** on global vs local Lipschitz constants\n\nWe agree that in some cases local robustness is enough in practice, however this may come at the cost of having weak guarantees on adversarial generalization, and may require expensive verification procedures locally around each test example for guaranteed robustness, as mentioned in our general response.\n\nWe will happily clarify some of these points in an updated version of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "SJeWhgkfpQ", "original": null, "number": 4, "cdate": 1541693608629, "ddate": null, "tcdate": 1541693608629, "tmdate": 1541693608629, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "rkxTYDf2i7", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for his comments. We discuss the novelty aspects in our general response ( https://openreview.net/forum?id=HkMlGnC9KQ&noteId=S1eid00WaQ ) and will be happy to clarify this in the paper. Further comments are addressed below.\n\n** controlling the amount of deformations\n\nThe stability bounds of B+M provide upper bounds on ||Phi(x') - Phi(x)|| (where x' is a deformation of x) based on quantities related to the corresponding diffeomorphism, i.e. the maximum norm and the maximum jacobian norm. For simple classes of deformations these can be computed precisely in terms of the parameters of the deformation, e.g. for translations, rotations, scaling or simple parametric warps. When bounding these away from zero by a certain constant, ||Phi(x') - Phi(x)|| is then included in a centered ball of the RKHS with a radius growing with this constant. This constant then acts as a regularization parameter, just like the size of additive perturbations in the case of adversarial perturbations, and can be tuned by cross-validation.\n\n** tightness of the lower bounds\n\nThis is something that we verify empirically in our experiments at the end of training by checking the values of spectral norms as a proxy of the upper bound, and looking at the gap with the lower bound. In particular, when using the ||f||_M penalty, lower and upper bounds seem to be controlled together in our experiments (Figure 2), making the bound useful, in contrast to PGD, for which spectral norms grow uncontrolled when the lower bound decreases. We will further clarify this in the paper.\n\neqn (8), (12): thanks for pointing these out, we will fix this in the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "S1eid00WaQ", "original": null, "number": 1, "cdate": 1541693042788, "ddate": null, "tcdate": 1541693042788, "tmdate": 1541693042788, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "content": {"title": "General response to reviewers", "comment": "First, we would like to thank the reviewers for their useful remarks and suggestions. We provide general comments here that are relevant for all reviewers, with specific comments for each reviewer in individual replies.\n\nBased on the reviewers' comments, we realize that our original submission focuses too much on establishing links between regularization with the RKHS norm and existing strategies, which we found particularly interesting, rather than highlighting the benefits of the newly obtained strategies. Additionally, some of our observations and insights were a bit preliminary in the submission, particularly regarding robustness and security applications, given that our original main motivation for this work was different, focusing on regularization in small data settings. We hope to better clarify the concerns about novelty here, and welcome further remarks by the reviewers. We will do our best to update the paper accordingly before the end of the discussion period.\n\n** Novelty compared to Bietti and Mairal (2018)\n\nBietti and Mairal (2018) study theoretical properties of the RKHS only. Here, we provide *practical algorithms* for regularizing usual neural networks using the RKHS norm, which is a major step forward compared to this existing work.  We are also not aware of previous work that considers the RKHS norm for regularization of deep networks in practice. An interesting insight of our work is that this norm is quite large for standard networks trained with SGD, and that explicitly controlling it brings clear benefits.\n\n** Novelty of the regularization strategies\n\nThe adversarial perturbation penalty ||f||_M that we introduce in this work is quite different from previous work: (i) it encourages stability of the entire prediction function by considering a separate penalty term in the optimization objective; (ii) it optimizes worst-case stability across the domain, in contrast to other approaches which only optimize this on average over training points. On Cifar10, our method seems most effective in controlling the RKHS norm compared to other methods, where we observe that both the lower bound and spectral norms are controlled together. In contrast, other lower bound methods seem less effective at controlling the upper bound, and this is particularly pronounced in the case of PGD in to our experiments. This is mentioned in the last paragraph of Section 4, and displayed in Figure 2(left).\nThe approach ||f||_M yields the best accuracy for regularization on some of the small dataset problems we consider, and can achieve the best performance in some regimes of the robustness/generalization trade-off. Additionally, it provides the most useful certified guarantee on adversarial generalization in our experiments (see next bullet point).\n\nAnother key difference between our approach and previous ones is that our penalties involve a global optimization problem across the space of inputs X rather than only an average over training samples. This is true both for ||f||_M vs. PGD and for our gradient penalty vs. existing strategies based on gradients. We admittedly did not yet investigate the importance of this local vs. global regularization effect (and we currently only optimize across examples in a mini-batch), which we plan to do in a longer version of the paper. This indeed paves the way to transductive and semi-supervised settings, which we plan to investigate as well.\n\n** Certified guarantees for adversarial generalization, and novelty of our theoretical analysis\n\nWe also would like to point out that our original main motivation was to study regularization benefits, while some of our observations regarding robustness and security were somewhat preliminary at the time of submission. Yet, one important aspect of our work in the context of robustness is that controlling the RKHS norm can provide a model with *certified* guarantees on *adversarial* generalization (i.e. test accuracy in the presence of an adversary), as given by our margin bound analysis, although it depends on the RKHS norm which can only be approximated. We note that while margin bounds have been useful to establish (standard) generalization guarantees for neural networks, to our knowledge our work is the first to use similar arguments for bounding adversarial generalization.\n\nOur experiments suggest that the most useful guarantees are obtained for models trained with our penalty ||f||_M, for which the upper and lower bounds are more tightly related than for other methods (see Figure 2). In contrast, while methods like PGD may give improved robustness empirically in some regimes, our experiments on CIFAR10 suggest that the obtained models have large spectral norms, yielding quite weak guarantees on adversarial generalization.\nThis suggests that the robustness of such models may be only local, so that one may need (possibly costly) verification procedures on each test example in order to guarantee robustness against all adversaries."}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610482, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkMlGnC9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1233/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1233/Authors|ICLR.cc/2019/Conference/Paper1233/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers", "ICLR.cc/2019/Conference/Paper1233/Authors", "ICLR.cc/2019/Conference/Paper1233/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610482}}}, {"id": "S1x3WD8ChQ", "original": null, "number": 3, "cdate": 1541461763838, "ddate": null, "tcdate": 1541461763838, "tmdate": 1541533308582, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "content": {"title": "Well written with interesting findings, but limited novelty", "review": "Regularizing RKHS norm is a classic way to prevent overfitting. The authors\nnote the connections between RKHS norm and several common regularization and\nrobustness enhancement techniques, including gradient penalty, robust\noptimization via PGD and spectral norm normalization. They can be seen as upper\nor lower bounds of the RKHS norm.\n\nThere are some interesting findings in the experiments. For example, for\nimproving generalization, using the gradient penalty based method seems to work\nbest.  For improving robustness, adversarial training with PGD has the best\nresults (which matches the conclusions by Madry et al.); but as shown in Figure\n2, because adversarial training only decreases a lower bound of RKHS norm, it\ndoes not necessarily decrease the upper bound (the product of spectral norms).\nThis can be shown as a weakness of adversarial training if the authors explore\nfurther and deeper in this direction.\n\nOverall, this paper has many interesting results, but its contribution is\nlimited because:\n\n1. The regularization techniques in reproducing kernel Hilbert space (RKHS) has\nbeen well studied by previous literature. This paper simply applies these\nresults to deep neural networks, by treating the neural network as a big\nblack-box function f(x).  Many of the results have been already presented in\nprevious works like Bietti & Mairal (2018).\n\n2. In experiments, the authors explored many existing methods on improving\ngeneralization and robustness. However all these methods are known and not new.\nIdeally, the authors can go further and propose a new regularization method\nbased on the connection between neural networks and RKHS, and conduct\nexperiments to show its effectiveness.\n\nThe paper is overall well written, and the introductions to RKHS and each\nregularization techniques are very clear. The provided experiments also include\nsome interesting findings. My major concern is the lack of novel contributions\nin this paper.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "cdate": 1542234274895, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902090, "tmdate": 1552335902090, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SylRu6annQ", "original": null, "number": 2, "cdate": 1541361013580, "ddate": null, "tcdate": 1541361013580, "tmdate": 1541533308373, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "content": {"title": "Interesting ideas, but not enough of an independent contribution", "review": "This paper looks at adversarial examples from the context of RKHS norms for neural networks.  The work builds conceptually on the work of Bietti and Mairal (2018), who investigate approximate RKHS norms for neural networks (including computation via a specialized convolutional kernel), and Xu et al., (2009) which looks at robustness properties of kernel classifiers.  The authors discuss how the RKHS norm of neural network functions provide robustness guarantees for the resulting classifier, both in terms of a straightforward robustness property for a given example, as well as in terms of generalization guarantees about robustness.\n\nOverall, I think there are some interesting ideas in this work, but ultimately not enough to make a compelling independent paper.  The core issue here is that the RKHS properties are used only in a very minimal manner to actually provide much analysis or insight into the robustness properties of the network.  For example, the upper bound in (8) seems to be central here to illustrating how a bound on the RKHS norm can be upper bounded as a function of the operator l2 norm of the inner weight matrices (though the actual form of the bound isn't mentioned), and the latter term could thus provide a certified bound on the robustness loss of a classifier.  However, there are two big issues here: 1) it's trivial to directly bound the l2 robustness of a classifier by the product of the weight spectral norms and 2) the actual regularization term the authors proposed to use (the sum of spectral norms) is notably _not_ an upper bound on either the robust loss or the RKHS norm; naturally, this penalty along with the constrained version will still provide some degree of control over the actual robustness, but the authors don't connect this to any real bound.  I also think the authors aren't properly acknowledging just how similar this is to past work: the Parseval networks paper (Cisse et al., 2017), for instance, presents a lot of similar discussion of how to bound generalization error based based upon terms involving operator norms of the matrices, and the actual spectral normalization penalty that the authors advocate for has been studied by Miyato et al. (2018).  To be clear, both of these past works (and several similar ones) are of course cited by the current paper, but from a practical standpoint it's just not clear to me what the takeaways should be here above and beyond this past work, other than the fact that these quantities _also_ bound the relevant RKHS norms.  Likewise the generalization bound in the paper is a fairly straightforward application of existing bounds given the mechanics of the RKHS norm defined by previous work.\n\nTo be clear, I think the RKHS perspective that the authors advocate for here is actually quite interesting.  I wasn't particularly familiar with the Bietti and Mairal (2018) work, and going through it in some detail for reviewing this paper, I think it's an important directly for analysis of deep networks, including from a perspective of robustness.  But the results here seem more like a brief follow-on note to the past work, not a complete set of results in and of themselves.  Indeed, because the robustness perspective here can largely be derived completely independently of the RKHS framework, and because the resulting training procedures seem to be essentially identical to previously-proposed approaches, the mere contribution of connecting these works to the RKHS norm doesn't seem independently to be enough of a contribution in my mind.\n\nOne final, though more minor, point: It's worth pointing out that (globally) bounding the Lipschitz constant seems top stringent a condition for most networks, and most papers on certifiable robustness seem to instead focus on some kind of local Lipschitz bound around the training or test examples.  Thus, it's debatable whether even the lower bound on the RKHS norm is really reasonable to consider for the purposes of adversarial robustness.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "cdate": 1542234274895, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902090, "tmdate": 1552335902090, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkxTYDf2i7", "original": null, "number": 1, "cdate": 1540265860988, "ddate": null, "tcdate": 1540265860988, "tmdate": 1541533308122, "tddate": null, "forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "content": {"title": "Review", "review": "In this paper, the authors consider CNN models from the lens of kernel methods. They build upon past work that showed that such models can be seen to lie in appropriate RKHS, and derive upper and lower bounds for the kernel norm. These bounds can be used as regularizers that help train more robust neural networks, especially in the context of euclidean perturbations of the inputs, and training GANs. They show that the bounds can also be used to recover existing special cases such as spectral norm penalizations and gradient regularization. They derive generalization bounds from the point of view of adversarial learning, and report experiments to buttress their claims.\n\nOverall, the paper is a little confusing. A lot of the times, the result seem to be a derivative of the work by Bietti and Mairal, and looks like the main results in this paper are intertwined with stuff B+M already showed in their paper. It's hard to ascertain what exactly the contributions are, and how they might not be a straightforward consequence of prior work (for example, combining results from Bietti and Mairal; and generalization bounds for linear models). It might be nice to carefully delineate the authors' work from the former, and present their contributions. \n\nPage 4: Other Connections with Lower bounds: The first line \" \"we may also consider ... \". This line is vague. How will you ensure the amount of deformation is such that the set \\bar{U} is contained in U ?\n\nPage 4 last paragraph: \"One advantage ... complex architectures in practice\" : True, but the tightness of the bounds *do* depend on \"f\" (specifically the RKHS norm). It needs to be ascertained when equality holds in the bounds you propose, so that we know how tight they are. What if the bounds are too loose to be practical?\n\neqn (8): use something else to denote the function 'U'. You used 'U' before to denote the set. \n\neqn (12): does \\tilde{O} hide polylog factors? please clarify. \n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1233/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Regularization and Robustness of Deep Neural Networks", "abstract": "In this work, we study the connection between regularization and robustness of deep neural networks by viewing them as elements of a reproducing kernel Hilbert space (RKHS) of functions and by regularizing them using the RKHS norm. Even though this norm cannot be computed, we consider various approximations based on upper and lower bounds. These approximations lead to new strategies for regularization, but also to existing ones such as spectral norm penalties or constraints, gradient penalties, or adversarial training. Besides, the kernel framework allows us to obtain margin-based bounds on adversarial generalization. We show that our new algorithms lead to empirical benefits for learning on small datasets and learning adversarially robust models. We also discuss implications of our regularization framework for learning implicit generative models.", "keywords": ["regularization", "robustness", "deep learning", "convolutional networks", "kernel methods"], "authorids": ["alberto.bietti@inria.fr", "gregoire.mialon@inria.fr", "julien.mairal@inria.fr"], "authors": ["Alberto Bietti*", "Gr\u00e9goire Mialon*", "Julien Mairal"], "pdf": "/pdf/8060b3e985017452425db0182db32fdb290882e4.pdf", "paperhash": "bietti|on_regularization_and_robustness_of_deep_neural_networks", "_bibtex": "@misc{\nbietti*2019on,\ntitle={On Regularization and Robustness of Deep Neural Networks},\nauthor={Alberto Bietti* and Gr\u00e9goire Mialon* and Julien Mairal},\nyear={2019},\nurl={https://openreview.net/forum?id=HkMlGnC9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1233/Official_Review", "cdate": 1542234274895, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkMlGnC9KQ", "replyto": "HkMlGnC9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902090, "tmdate": 1552335902090, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 13}