{"notes": [{"id": "B1MX5j0cFX", "original": "S1xjnsocYQ", "number": 520, "cdate": 1538087818942, "ddate": null, "tcdate": 1538087818942, "tmdate": 1545355376051, "tddate": null, "forum": "B1MX5j0cFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJxj7TGfgE", "original": null, "number": 1, "cdate": 1544854818909, "ddate": null, "tcdate": 1544854818909, "tmdate": 1545354532637, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Meta_Review", "content": {"metareview": "The topic of universal adversarial perturbation is quite intriguing and fairly poorly studied and the paper provides a mix of new insights, both theoretical and empirical in nature. However, the significant presentation issues make it hard to properly understand and evaluate them. In particular, the theoretical part feels rushed and not sufficiently rigorous, and it is unclear why focusing on the case of equivariant network is crucial. Also, it would be useful if the authors put more effort in explaining how their contributions fit into the context of prior work in the area.\n\nOverall, this paper has a potential of becoming a solid contribution, once the above shortcomings are addressed.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": " Some interesting contribution, but there are significant exposition (and novelty) concerns"}, "signatures": ["ICLR.cc/2019/Conference/Paper520/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper520/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353187158, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper520/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper520/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper520/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353187158}}}, {"id": "ryeezddw2X", "original": null, "number": 1, "cdate": 1541011464422, "ddate": null, "tcdate": 1541011464422, "tmdate": 1543251213132, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "content": {"title": "Interesting observations, but paper needs clarity in writing ", "review": "The paper presents some interesting observations related to the connection between the universal adversarial attacks on CNNs and spectral properties. While most of the results are empirical, the authors present two theorems to justify some of the observations. However, the paper is poorly written and very hard to read. Rather than providing too many plots/results in the main paper (maybe use supplementary matl.), the empirical results should be better explained to help the readers. Similarly, the implications of the theorems are not really clear and bit hand-wavy.    \n\nxxxxxxxxxxxxxx\n\nIt seems that the authors provided a generic response to all the reviewers and I am not sure if they acknowledge the lack of clarity and lot of hand-wavy explanations in the paper. This issue has been raised by other reviewers too and is quite critical for becoming a good paper worthy for ICLR. Therefore, I am unable to update my score for this paper. However, I do appreciate the comparison with Moosavi-Dezfooli et al. (CVPR'17), this is a good addition as suggested by another reviewer. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper520/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "cdate": 1542234442613, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742950, "tmdate": 1552335742950, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1gumUHtRm", "original": null, "number": 4, "cdate": 1543226912346, "ddate": null, "tcdate": 1543226912346, "tmdate": 1543226912346, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "ryeezddw2X", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "content": {"title": "Revised with CIFAR10 experiments and comparison with Moosavi-Dezfooli et al.", "comment": "We show that the principal attack directions are nearly orthogonal to the principal invariant directions. Models learns invariance to rotations either when we explicitly use an equivariant network (GCNN, RotEqNet) or when we train any model (StdCNN, fully connected NN) with rotation augmentations or do both. We show a simple universal adversarial attack using the top principal component of any input-dependent attack direction on a small test sample. We show that even a simple approach of using the top singular vector of the gradients on a small sample of test points is comparable to the attack of Moosavi-Dezfooli et al. (CVPR'17). Moreover, the fooling rate of our universal attack gets better as the model is train-augmented with larger rotations."}, "signatures": ["ICLR.cc/2019/Conference/Paper520/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611344, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1MX5j0cFX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper520/Authors|ICLR.cc/2019/Conference/Paper520/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611344}}}, {"id": "Syep8HSKAX", "original": null, "number": 2, "cdate": 1543226708821, "ddate": null, "tcdate": 1543226708821, "tmdate": 1543226846838, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "Bkx4Djbh2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "content": {"title": "Revised with CIFAR10 experiments and comparison with Moosavi-Dezfooli et al.", "comment": "We have modified the submission with the experiments on CIFAR 10 dataset asked by the reviewer. \n\nWe show that the principal attack directions are nearly orthogonal to the principal invariant directions. Models learns invariance to rotations either when we explicitly use an equivariant network (GCNN, RotEqNet) or when we train any model (StdCNN, fully connected NN) with rotation augmentations or do both. We show a simple universal adversarial attack using the top principal component of any input-dependent attack direction on a small test sample. We show that even a simple approach of using the top singular vector of the gradients on a small sample of test points is comparable to the attack of Moosavi-Dezfooli et al. (CVPR'17). Moreover, the fooling rate of our universal attack gets better as the model is train-augmented with larger rotations."}, "signatures": ["ICLR.cc/2019/Conference/Paper520/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611344, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1MX5j0cFX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper520/Authors|ICLR.cc/2019/Conference/Paper520/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611344}}}, {"id": "rylRaSBFRm", "original": null, "number": 3, "cdate": 1543226821785, "ddate": null, "tcdate": 1543226821785, "tmdate": 1543226821785, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "ryg8nMgR3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "content": {"title": "Revised with CIFAR10 experiments and comparison with Moosavi-Dezfooli et al.", "comment": "We show that the principal attack directions are nearly orthogonal to the principal invariant directions. Models learns invariance to rotations either when we explicitly use an equivariant network (GCNN, RotEqNet) or when we train any model (StdCNN, fully connected NN) with rotation augmentations or do both. We show a simple universal adversarial attack using the top principal component of any input-dependent attack direction on a small test sample. We show that even a simple approach of using the top singular vector of the gradients on a small sample of test points is comparable to the attack of Moosavi-Dezfooli et al. (CVPR'17). Moreover, the fooling rate of our universal attack gets better as the model is train-augmented with larger rotations."}, "signatures": ["ICLR.cc/2019/Conference/Paper520/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611344, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1MX5j0cFX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper520/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper520/Authors|ICLR.cc/2019/Conference/Paper520/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers", "ICLR.cc/2019/Conference/Paper520/Authors", "ICLR.cc/2019/Conference/Paper520/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611344}}}, {"id": "ryg8nMgR3Q", "original": null, "number": 3, "cdate": 1541436077790, "ddate": null, "tcdate": 1541436077790, "tmdate": 1541533924975, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "content": {"title": "Principal directions towards universal attacks", "review": "This paper studies the problem of computing non-data specific perturbations, also known as universal perturbations, to attack neural networks and take profit of their inherent vulnerability. Compared to previous works in the domain, the authors look specifically at equivariant networks, and derive geometric insights and methods to compute universal perturbations for these networks. \n\nThe paper starts by analysing the main/principal directions of set of perturbations that are able to change the decisions in different forms of equivariant neural networks. With this heuristic study, a few main directions are shown to be shared by most adversarial perturbations. The authors then propose to construct universal perturbations built on the insights given by the principle directions of perturbations, which is an interesting an effective method. In addition, it is shown that a few adversarial samples are sufficient to identify pretty  accurately the principle directions. The fooling rates achieved by this method is pretty good, which demonstrates that the proposed strategy is reasonable.\n\nThe key idea in this paper (using principal shared directions of perturbations, computed on a small subset of data points) has unfortunately already been proposed and tested in classical (non-equivariant) neural networks - see for example Fig 9 in Moosavi-Dezfooli, 2017, cited in the paper, and published in CVPR 2017. The present paper proposes however a few additional bits of information with a nice theoretical analysis, while the previous works were mostly based on heuristics. It is probably not sufficient however to pass the cut in ICLR. \n\nThe interesting additional novelty here is the study of equivariant networks. However, this ends up falling sort of initial expectations - there seems to be nothing specific to equivariant networks in the proposed study, and the solution and algorithm is actually applicable to any neural network architectures (?). Also, no specific insights are derived for equivariant networks, which could be potentially very interesting to make progress in understanding better equivariant representations, which still consist in a widely open research problem. \n\nIn general, the paper has a non-classical organisation, with a lot of heuristics that are not discussed in depth - that gives a sort of high-level impression that the proposed idea is potentially nice, but that but superficially addressed. It should probably be improved in the next versions of this work. ", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper520/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "cdate": 1542234442613, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742950, "tmdate": 1552335742950, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Bkx4Djbh2Q", "original": null, "number": 2, "cdate": 1541311324068, "ddate": null, "tcdate": 1541311324068, "tmdate": 1541533924777, "tddate": null, "forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "invitation": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "content": {"title": "An interesting observation, but the contribution is not significant enough", "review": "The authors made an interesting observation: There's an important common subspace of Gradient/FGSM/Deepfool attacks among all examples. Therefore, they propose to use top SVD components of the directions to conduct universal attack. This is an interesting finding but also not surprising; we know the gradient of loss function w.r.t input can be used for interpretability, and in MNIST examples they usually reveals some rough shape of the class. This is also observed in Figure 8-13 in this paper, and thus it makes sense that the gradient directions share a common subspace. Therefore I think this observation itself is not significant enough. \n\nUsing this for universal attack is interesting, however the experiments are not that convincing: \n\n1. To show this is a good way for universal attack, I think the authors should compare with previous work in (Moosavi-Dezfooli et al). \n\n2. All the experiments are on MNIST. How about cifar/ImageNet? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper520/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Attacks on Equivariant Networks", "abstract": "Adversarial attacks on neural networks perturb the input at test time in order to fool trained and deployed neural network models. Most attacks such as gradient-based Fast Gradient Sign Method (FGSM) by Goodfellow et al. 2015 and DeepFool by Moosavi-Dezfooli et al. 2016 are input-dependent, small, pixel-wise perturbations, and they give different attack directions for different inputs. On the other hand, universal adversarial attacks are input-agnostic and the same attack works for most inputs. Translation or rotation-equivariant neural network models provide one approach to prevent universal attacks based on simple geometric transformations. In this paper, we observe an interesting spectral property shared by all of the above input-dependent, pixel-wise adversarial attacks on translation and rotation-equivariant networks. We exploit this property to get a single universal attack direction that fools the model on most inputs. Moreover, we show how to compute this universal attack direction using principal components of the existing input-dependent attacks on a very small sample of test inputs. We complement our empirical results by a theoretical justification, using matrix concentration inequalities and spectral perturbation bounds. We also empirically observe that the top few principal adversarial attack directions are nearly orthogonal to the top few principal invariant directions.\n", "keywords": ["adversarial", "equivariance", "universal", "rotation", "translation", "CNN", "GCNN"], "authorids": ["amitdesh@microsoft.com", "ksandeshk@cmi.ac.in", "kv@cmi.ac.in"], "authors": ["Amit Deshpande", "Sandesh Kamath", "K V Subrahmanyam"], "TL;DR": "Universal attacks on equivariant networks using a small sample of test data", "pdf": "/pdf/7146cf052a04170d4d2c120ce1247eaa6061b84b.pdf", "paperhash": "deshpande|universal_attacks_on_equivariant_networks", "_bibtex": "@misc{\ndeshpande2019universal,\ntitle={Universal Attacks on Equivariant Networks},\nauthor={Amit Deshpande and Sandesh Kamath and K V Subrahmanyam},\nyear={2019},\nurl={https://openreview.net/forum?id=B1MX5j0cFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper520/Official_Review", "cdate": 1542234442613, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1MX5j0cFX", "replyto": "B1MX5j0cFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper520/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742950, "tmdate": 1552335742950, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper520/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}