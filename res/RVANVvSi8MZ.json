{"notes": [{"id": "RVANVvSi8MZ", "original": "xSy2xf6-cKl", "number": 352, "cdate": 1601308046912, "ddate": null, "tcdate": 1601308046912, "tmdate": 1614985622531, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "u1tyvsYD0pN", "original": null, "number": 1, "cdate": 1610040537182, "ddate": null, "tcdate": 1610040537182, "tmdate": 1610474147253, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper proposed a GNN model based on a weighted line graph (dual of the input graph), where information is simultaneously propagated on both graphs, coupling the two propagations at each step. \n\nOverall, the reviewers were lukewarm about the paper, with some raised criticism including \n- limited novelty in light of Monti et al. 2018\n- limited theoretical justification\n- unconvincing and incomplete experiments, not offering significant improvement compared to other alternatives\n\nWhile the presented approach is interesting, we believe the paper is below the bar and recommend Rejection. \n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040537169, "tmdate": 1610474147237, "id": "ICLR.cc/2021/Conference/Paper352/-/Decision"}}}, {"id": "QrkQU64AyT", "original": null, "number": 6, "cdate": 1606258302747, "ddate": null, "tcdate": 1606258302747, "tmdate": 1606258302747, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "Mfs33e1HUw2", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment", "content": {"title": "Rebuttal to AnonReviewer4", "comment": "Question 1: The use of the word \"dynamics\" is confusing.\n\nAnswer: Thank you for pointing out this. We will fix this word to reduce the confusion.\n\nQuestion 2: It is not clear which datasets have node features.\n\nAnswer: Thank you for pointing out this. Social network datasets including COLLAB, IMDB, and REDDIT don\u2019t have node features while bioinformatic datasets such as MUTAG, PTC, PROTEINS, and D&D have node features. We will clarify this in the final version.\n\nQuestion 3: Possible explanation for higher standard deviation on PROTEINS and COLLAB datasets.\n\nAnswer: Since these datasets are relatively small, the original partition for 10-fold cross validation may generate folds with biased training examples distribution. It would be improved if a better partition scheme can be used. However, to ensure fair comparison, we strictly follow the same experimental settings as Graph U-Net and GIN.\n\nQuestion 4: I would like to see comparison with other methods on space/time complexity\n\nAnswer: In the paper, we mainly compare our methods with the original line graph implementation to improve efficiency. However, it is still hard to compete with other methods that utilize original graph structures. It can be considered as a trade-off between performance and efficiency. Using line graph structure can improve the performance but also involve efficiency issues. Our proposed implementation methods aim to provide a better trade-off between them."}, "signatures": ["ICLR.cc/2021/Conference/Paper352/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "RVANVvSi8MZ", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper352/Authors|ICLR.cc/2021/Conference/Paper352/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871920, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment"}}}, {"id": "jZKxeaJ96z8", "original": null, "number": 5, "cdate": 1606252892910, "ddate": null, "tcdate": 1606252892910, "tmdate": 1606252892910, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "S6I6ov6moc", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment", "content": {"title": "Rebuttal to AnonReviewer3", "comment": "We really appreciate your good words and valuable suggestions.\n\nQuestion 1: clarification on results in Table 1.\n\nAnswer: In our experiments, we strictly follow the same settings as GIN. In particular, we perform 10-fold cross-validation on training datasets since most of benchmarking datasets are very small. The reported confidence intervals are computed based on the accuracy results of 10 folds.\n\nQuestion 2: The optimization holds only for graphs where the edge features are materialized from the vertex features. Does this hold for all the datasets?\n\nAnswer: Yes, you are correct. We will continue to explore efficient implementation such that our methods can benefit datasets with edge features.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "RVANVvSi8MZ", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper352/Authors|ICLR.cc/2021/Conference/Paper352/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871920, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment"}}}, {"id": "t8MHg4vYsud", "original": null, "number": 4, "cdate": 1606245284709, "ddate": null, "tcdate": 1606245284709, "tmdate": 1606245284709, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "Bc0ZRGeWpfE", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment", "content": {"title": "Rebuttal to AnonReviewer2", "comment": "Question 1: In eq.1, the weight of self-loops is 1/D_b + 1/D_a, but it is unclear why it should be designed like this.\n\nAnswer: Yes. The weights designed like this will emphasize on the self-loops, which consequently results in the emphasis of node\u2019 own features. In regular deep neural networks, skip connections are commonly used, which can also emphasize own features. Thus, we believe such design can reasonably emphasize nodes\u2019 features.\n\n Question 2: In eq. 2-5, how is the edge feature matrix Y_l updated to Y_{l+1} is not specified.\n\nAnswer: Thanks for pointing out this. Yes, we didn\u2019t provide an equation for edge feature updates here. Actually, the update rule is specified in the sentence below Equation (7):\n\n\u201cB^T X computes edge features using node features\u201d.\n\nWe will add this update rule in to eq(2-5) to make it clear and complete.\n\nQuestion 3: Application to node classification tasks\n\nAnswer: Yes, our methods can be applied to node classification tasks by removing the readout layer from WLGCNets. We will add more results on node classification tasks in the final version.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "RVANVvSi8MZ", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper352/Authors|ICLR.cc/2021/Conference/Paper352/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871920, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment"}}}, {"id": "yexbSYKhi7G", "original": null, "number": 2, "cdate": 1606231328774, "ddate": null, "tcdate": 1606231328774, "tmdate": 1606241200565, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "NHFrT1acso", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment", "content": {"title": "Rebuttal to AnonReviewer5", "comment": "Question 2: Comparison with LGCNN\n\nAnswer: We have made comparisons with the regular line graph (LGNN) on various datasets including REDDIT-BINARY, REDDIT-MULTI5K, and REDDIT-MULTI12K datasets. The comparison results are illustrated in table 4. In particular, our WLGCN outperforms LGCN by 0.5%, 0.9%, and 0.7% on REDDIT-BINARY, REDDIT-MULTI5K, and REDDIT-MULTI12K datasets, respectively. These results demonstrate the advantage of our WLGCN over LGCN.\n\nQuestion 3: Comparison with GCNs and GATs \n\nAnswer: We provide the comparison results with GCN on image classification datasets as in table 4. In the final version, we plan to add more comparisons on recommended datasets.\n\nQuestion 4: Performances with normalized adjacency matrix\n\nAnswer: The results shown in tables 1, 3, and 4 are performances of using normalized adjacency matrix. We only do simple adjacency matrix normalization. In particular, we normalize each node by its incoming degree such that the aggregated features are scaled.\n\nQuestion 5: Performance of deep WLGCNets\n\nAnswer: The performances of WLGCNets achieves the best performance when the depth of networks is 3. We can observe from Figure 5 that when the depth increases, the performances decrease due to over-fitting issues.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "RVANVvSi8MZ", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper352/Authors|ICLR.cc/2021/Conference/Paper352/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871920, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment"}}}, {"id": "agNGW-Z1g3s", "original": null, "number": 3, "cdate": 1606241064348, "ddate": null, "tcdate": 1606241064348, "tmdate": 1606241064348, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "t0KqC1d4CnV", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment", "content": {"title": "Rebuttal to AnonReviewer1", "comment": "Question 1: Theoretical justification of using line graph structure.\n\nAnswer: The advantage of line graph structure has been explored on various graph embedding tasks such as [1, 2, 3]. Essentially, line graph structure can provide a different perspective to encode network embeddings. Also, it will give a good emphasize on edge features in graph neural networks.\n\nQuestion 2: equation (7) we see that essentially all the computations in layer \\ell can be done using node x node matrices.\n\nAnswer: There may be a misunderstanding here. Equation (7) provides an efficient computation when node features are utilized. However, when there are edge features, which is an important motivation of using line graph structure, we need to use the computations (2-5) in Section 3.3. \n\nQuestion 3: results are essentially on par with a number of other fully \"node-based\" methods\n\nAnswer: There may be a misunderstanding here. We mainly compare our methods with previous state-of-the-art models such as DGCNN, DIFFPOOL, SAGPool, g-U-Net, and GIN on graph classification tasks in Tables 1 and 3. Compared with previous methods, our methods can outperform them by 1% to 3% on most benchmarking datasets. Given that these datasets are popular benchmarking datasets and heavily explored, we consider these improvements to be significant and they can demonstrate the effectiveness of our methods."}, "signatures": ["ICLR.cc/2021/Conference/Paper352/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "RVANVvSi8MZ", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper352/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper352/Authors|ICLR.cc/2021/Conference/Paper352/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871920, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Comment"}}}, {"id": "t0KqC1d4CnV", "original": null, "number": 1, "cdate": 1603697171496, "ddate": null, "tcdate": 1603697171496, "tmdate": 1605024708907, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Review", "content": {"title": "Weighted Line Graph Convolutional Networks ", "review": "The paper introduces a GNN architecture that is based on a weighted line-graph transformation (in conjunction with a node-based architecture).\nThe central idea is that a normal line graph transformation will lead to an over-representation of certain nodes (motifs) in the network, which the authors strive to correct.\nThe efficacy of these ideas is tested in a range of numerical experiments.\n\nPro:\n* The presentation is quite clear, in my opinion apart from some smaller inaccuracies.\n* The experiments constructed appear thorough and rigorous.\n\nCons:\n* A more precise theoretical justification why their algorithm should work better (has more expressive power than other architectures) is missing\n* The improvements seen are not strong compared to other architectures\n* It seems that most of the computation could be implemented w/o ever appealing to a line graph transformation.\n\nAdditional comments:\nThe general idea of the paper sounds appealing. A line graph may be seen as a \"higher-order\" representation of a graph and thus we may (intuitively) hope that there is more information to be gained here.\nHowever, the authors argument hinges upon a single paper that shows some improvements for community detection using line-graphs, but not much further theoretical justification.\nThe fact that high-degree nodes will be over-represented (as they will have more edges in the line-graph), does not necessary mean that normalization will help. The neural network could also learn to take into account this information, in principle?\nIn particular, we know that GNN cannot be more expressive that the Weisfeiler Leman algorithm (see e.g., Morris et al); does a line-graph transformation help here and make the architecture more akin to a 2-WL network?\nI feel that some kind of stronger theoretical justification is missing here, given the computational costs of expanding the representation to edges.\nThe numerical results are not as strong to convince me in this regard.\n\nThe two theorems proven are very basic linear algebra, and cannot really be counted as a theoretical contribution here, in my opinion.\nIn particular all these ideas have already been presented in a lot of detail in the work by Evans and Lambiotte. A second citation that is missing in this context in my opinion is:\nEvans, Tim S., and Renaud Lambiotte. \"Line graphs of weighted networks for overlapping communities.\" The European Physical Journal B 77.2 (2010): 265-272.\n\nLooking at equation (7) we see that essentially all the computations in layer \\ell can be done  using node x node matrices (H, D, X), i.e., the implementation does not even need to appeal to any kind of line-graph transformation. This makes the rationale that the line-graph representation improves the learning somewhat questionable --- after all there is just a message passing between nodes going on here.\n\nIn summary, the paper provides a mixture of theory and experiments. \nUnfortunately, I feel that both the theory part and the experiments are not fully satisfactory. The theory part does not provide clear theoretical guarantees or insights why the proposed architectures would perform better, in general, I think. Moreover the computations still seem to boil down to a node-to-node message passing.\nIf the authors could provide a more rigorous justification here, this would significantly improve the paper.\n\nThe experiments appear to be rigorous, but the results are essentially on par with a number of other fully \"node-based\" methods, so it is not fully clear whether there is really a clear advantage here.\n\nMinor comments:\nHow is the incidence matrix B defined? It seems an unsigned version is used, which would be less common in a graph / network theory.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145097, "tmdate": 1606915810349, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper352/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Review"}}}, {"id": "Bc0ZRGeWpfE", "original": null, "number": 2, "cdate": 1603800810717, "ddate": null, "tcdate": 1603800810717, "tmdate": 1605024708843, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Review", "content": {"title": "Interesting paper but some mathematical details are not clearly presented", "review": "This paper proposes passing messages on the line graph for learning representations of graphs. To overcome the bias that high-degree nodes are over-emphasized during message passing, the authors propose to reweight edges in the line graph. Then it performs message passing on both the original graph and the weighted line graph. The authors also use incidence matrix in their model to reduce computation overhead. Overall, this paper is well written and easy to follow. The experimental results demonstrate the effectiveness and efficiency of the proposed method. However, I have the following concerns:\n\n1. In eq.1, the weight of self loops is 1/D_b + 1/D_a, but it is unclear why it should be designed like this. Does it mean that self loops are more important in the line graph? It seems more likely for the purpose of deriving Theorem 1.\n\n2. In eq. 2-5, how is the edge feature matrix Y_l updated to Y_{l+1} is not specified.\n\n3. In experiments the authors only conduct experiments on graph classification. Can the proposed method be applied to node classification? Does it work on large graphs with thousands of nodes?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145097, "tmdate": 1606915810349, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper352/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Review"}}}, {"id": "Mfs33e1HUw2", "original": null, "number": 3, "cdate": 1603900317348, "ddate": null, "tcdate": 1603900317348, "tmdate": 1605024708770, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Review", "content": {"title": "Overall, I vote to reject the paper. I do not disagree with the main premise of the paper but feel that it needs some rewriting as well as additional empirical evaluation.", "review": "# Summary\nThis paper introduces a weighted line graph formulation (WLGCL) which corrects the over-counting (\"bias\") of high-degree node features in a line-graph based convolutional network. Further, the paper uses Incidence Matrix to implement WLGCL updates which reduces the space complexity ($O(N^4) \\to O(N^3)$) and time complexity ($O(N^4 C) \\to O(N^4)$) compared to the naive implementation. The paper shows empirical evaluation on downstream task of graph classification and shows gain in accuracy. \n\n# Observations\n- The use of the word \"dynamics\" (Page 1, paragraph 2) in the context of over-representation of node features in the message passing is very confusing. Typically, \"dynamics\" in the context of graph networks often implies changing graph structure which is not the case here. The usage is taken from [Evans & Lambiote, 2009] (https://arxiv.org/pdf/0903.2181.pdf) but in that context it refers to random walks. \n\n- The paper mentions on Page 4 last line that \"advanced feature aggregation methods such as GAT\" can easily be applied to the line graph. This should be demonstrated, e.g., in the supplementary material.  As a note, in the paper [Monti et al. 2018] (available only on https://arxiv.org/pdf/1806.00770.pdf) also presents line-graph formulation with GAT applied to the line graph. \n\n- [Bandhopadhyay et al. 2019]  also present a weighted line graph but since it is only present on Arxiv (https://arxiv.org/abs/1912.05140), I disregard lack of comparison with that paper. \n\n- It is not clear which datasets have node features - this should be clearly mentioned preferably in the main text but if not definitely in the supplementary material. \n\n-  The paper claims performance improvement over graph U-net which demonstrates the benefit of weighted approach which does unbiased node-feature updates. For PROTEINS and COLLAB datasets, the standard deviation of the proposed method is significantly higher than competing methods - what would be the possible explanation for this? \n\n- The benefit of using Incidence Matrix based updates is clear in terms of space and time complexity. However, I would like to see comparison with other methods on space/time complexity if focussing solely on graph classification task. \n\n# Optional remarks \n- It is not necessary but might be useful to show evaluation on other downstream tasks.  For example, in downstream task of node classification - CORA, Citeseer, Pubmed (see e.g., the Graph U-nets paper). \n\n- The node feature bias might be more relevant when there are edge features as well. To my understanding, the current datasets do not have edge features.  For example, please see the CensNet paper (cited as Jiang, 2019 in this paper) and the multi-task classification datasets (_Tox21_ and _Lipophilicity_)\n\n# Minor comments\n- What is the dropout rate (Appendix A)? \n- As the model trains, a plot showing the test metrics would be good in the supplementary. \n\n# Recommendation \nOverall, I vote to reject the paper. I do not disagree with the main premise of the paper but feel that it needs some rewriting as well as additional empirical evaluation.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145097, "tmdate": 1606915810349, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper352/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Review"}}}, {"id": "S6I6ov6moc", "original": null, "number": 4, "cdate": 1603935880360, "ddate": null, "tcdate": 1603935880360, "tmdate": 1605024708699, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Review", "content": {"title": "Thorough paper on propagating over line graphs", "review": "Summary of contribution:\nThis paper discusses graph convolutional networks.  The authors recap existing work to observe that models already exist to propagate information through graphs in two different ways:\n1. Standard propagation passes information from nodes along edges to neighboring nodes\n2. Line graph propagation adopts the same scheme on the *line graph* of the original graph:  original edges become vertices in the line graph, and these new vertices are connected when they share an endpoint in the original graph.\n\nThe authors suggest a model that simultaneously propagates information in both graphs, coupling the two propagations at each step.\n\nThey additionally observe that high-degree vertices in the original graph induce cliques in the line graph, which will naively result in over-weighting such vertices, as they have many more paths along which to propagate information.  They propose reweighting the line graph so that vertices in the line graph all have weighted degree 2.\n\nThey perform a series of experiments using this combined propagation scheme through the graph and the weighted line graph.  The experiments cover graph classification tasks, and are well thought out.  There are a number of tasks with larger graphs, plus experiments with smaller graphs to test over-fitting.  There are a few ablation studies, and a sensitivity study on depth of their architecture.\n\nStrong points:\n* The weighting argument for line graphs seems natural, and as far as I can tell the authors are the first to propose this.\n* The coupling of propagation in the two graphs is elegantly established and also seems natural\n* The experiments are well-defined, and the results themselves are pretty compelling (but please see question below)\n\nWeak points / concerns:\n* The main proposed points of novelty in the paper are as follows, as far as I can tell:\n  N1: Weighted line graphs.  Line graphs themselves have been used before, and the weighting scheme itself is straightforward -- I believe it has been used before in combinatorial algorithms based on line graphs.\n  N2: There is a small optimization to avoid materializing the cliques in the line graph during propagation, but this also seems natural; in fact, it would be a bug not to retain the propagation structure in this clearly more efficient representation.\n  N3: The coupling of propagations in equation 5 seems nice.\nThese haven't been studied before, and N3 seems quite nice, but I don't see significant mathematical advances in this structure or significant advances in information flow.  I still feel pretty good about the contributions of the paper as they combine a number of natural steps, and they show good empirical outcomes.\n\nQuestions for the authors:\nQ1. In Table 1, I'm surprised that the WLGCNet has confidence intervals that overlap significantly with, say, GIN for many of the datasets.  However, there is never an inversion in the order of the winning system.  Depending on how the CIs were computed, this seems like an unexpected coincidence, which makes me think I may not understand the computation of the confidence intervals here.  Would appreciate some clarification.\nQ2. The optimization holds only for graphs where the edge features are materialized from the vertex features.  Does this hold for all the datasets?  ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145097, "tmdate": 1606915810349, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper352/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Review"}}}, {"id": "NHFrT1acso", "original": null, "number": 5, "cdate": 1604789084570, "ddate": null, "tcdate": 1604789084570, "tmdate": 1605024708617, "tddate": null, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "invitation": "ICLR.cc/2021/Conference/Paper352/-/Official_Review", "content": {"title": "Review for \"Weighted Line Graph Convolutional Networks\"", "review": "The paper proposed a GNN model based on a weighted line graph, which adds weights to the line graph for the original input graph in a node/graph property prediction task. The line graph is a graph built on the original graph but with edges as nodes. A new convolution called weighted line graph convolution layer (WLGCL) is proposed to overcome the issue of \"biased topological information\" of the line graph. The weights for the line graph in WLGCL are computed based on the node degree of the original graph, which implies the node degree in the line graph is always 2. The WLGCL can be implemented for different kinds of graph convolution, which rule incorporates graph connectivity, node features and edge features.  \nExperiments compared the performance of the proposed model with existing GNN methods on graph classification tasks and computational complexity with other methods.\n1. The WLGCL introduces the weights for edges in line graph convolution, which reduces the computational cost. The performance of WLGCL on some graph classification datasets are good. \n2. The WLGCL is a weighted version of the line graph neural networks (LGNNs) as studied previously in [Chen, Li, Bruna, Supervised Community Detection with Line Graph Neural Networks, ICLR 2019]. \nBesides saving the computational cost and removing biased degree information, what are other benefits over LGNN? Is there a significant improvement of the test accuracy against LGNN on various types of graph datasets? Maybe saying \u201cbiased topological information\u201d here is misleading as what change the WLGCL makes compared to LGNN is the node degree.\n3. The experiments, like Table 1, compare with some existing GNNs methods. The author should compare with more existing GNNs, such as GAT. The new datasets, Open Graph Benchmarks, should also be tested to show the performance of the proposed GNN model.\n4. What is the performance of WLGCL with the normalisation of the adjacency matrix on graph classification tasks?\n5. The study of the test accuracy vs depth of the GNN with WLGCL indicates the WLGCL may work in deep nets. Will increase the depth further be beneficial or not? Is there any interpretation from information theory?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper352/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper352/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weighted Line Graph Convolutional Networks", "authorids": ["~Hongyang_Gao1", "~Shuiwang_Ji1"], "authors": ["Hongyang Gao", "Shuiwang Ji"], "keywords": ["Line graph"], "abstract": "Line graphs have shown to be effective in improving feature learning in graph neural networks. Line graphs can encode topology information of their original graphs and provide a complementary representational perspective. In this work, we show that the encoded information in line graphs is biased. To overcome this issue, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges. Based on our weighted line graphs, we develop a weighted line graph convolution layer that takes advantage of line graph structures for better feature learning. In particular, it performs message passing operations on both the original graph and its corresponding weighted line graph. To address efficiency issues in line graph neural networks, we propose to use an incidence matrix to accurately compute the adjacency matrix of the weighted line graph, leading to dramatic reductions in computational resource usage. Experimental results on both real and simulated datasets demonstrate the effectiveness and efficiency of our proposed methods. ", "one-sentence_summary": "In this work, we propose a weighted line graph that corrects biases in line graphs by assigning normalized weights to edges.", "pdf": "/pdf/1970efff0f8551a6107450dfcbced030c9a9b37d.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|weighted_line_graph_convolutional_networks", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H-gK_-BAjr", "_bibtex": "@misc{\ngao2021weighted,\ntitle={Weighted Line Graph Convolutional Networks},\nauthor={Hongyang Gao and Shuiwang Ji},\nyear={2021},\nurl={https://openreview.net/forum?id=RVANVvSi8MZ}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "RVANVvSi8MZ", "replyto": "RVANVvSi8MZ", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145097, "tmdate": 1606915810349, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper352/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper352/-/Official_Review"}}}], "count": 12}