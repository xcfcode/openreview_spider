{"notes": [{"id": "ryfaViR9YX", "original": "rJl21FRPKm", "number": 42, "cdate": 1538087733245, "ddate": null, "tcdate": 1538087733245, "tmdate": 1545355422617, "tddate": null, "forum": "ryfaViR9YX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BkeoNokQeE", "original": null, "number": 1, "cdate": 1544907571403, "ddate": null, "tcdate": 1544907571403, "tmdate": 1545354492848, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Meta_Review", "content": {"metareview": "The authors propose a generative model based on variational autoencoders that provides means to manipulate the high-level attributes of a given input. The attributes can be either pre-defined ground truth attributes or unknown attributes automatically discovered from the data.\n\nWhile the reviewers acknowledged the potential usefulness of the proposed approach, they raised important concerns that were viewed by AC as a critical issue: (1) very limited experimental evaluation (e.g. no baseline or ablation results, no quantitative results); comparisons on other more complex datasets and more in-depth analysis would substantially strengthen the evaluation and would allow to assess the scope of the contribution of this work  \u2013 see, for example, R3\u2019s suggestion to use other dataset like dSprites or CelebA, where the ground truth attributes are known; (2) lack of presentation clarity \u2013 see R2\u2019s latest comment how to improve.\n\nA general consensus among reviewers and AC suggests, in its current state the manuscript is not ready for a publication. It needs clarification, more empirical studies and polish to achieve the desired goal.\n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Meta-Review"}, "signatures": ["ICLR.cc/2019/Conference/Paper42/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper42/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353358458, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper42/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper42/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper42/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353358458}}}, {"id": "B1efH9Ngg4", "original": null, "number": 5, "cdate": 1544731193541, "ddate": null, "tcdate": 1544731193541, "tmdate": 1544731193541, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ByeKdiFFAQ", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "content": {"title": "Trying to make the paper easier to follow", "comment": "Here there are some specifics about why I found the paper difficult to follow.\n\nThere are isolated statements that lack a motivation that can guide the reader about why this was a logical step to do. Two examples:\n\"The idea is then to compute z from z\u2217 by applying a transformation parametrized only by the feature space \u03a8\" --> what is the motivation?\n\"We now consider the regularization over Z. This regularization is in fact superfluous and could be removed.\" --> why is that?\n\nThe is a lack of justification in many places in which many things are taken for granted, or there is not a clear cause-effect flow. To mention three examples:\n- \"However, there is no reason, for a random attribute \u03c8 \u2208 \u03a8 /= \u03c6(x, m), that p(x|z) where z \u223c q(z|x, \u03c6) generates variations of the original x with features \u03c6\" --> what is the role of \u03c8 given that it is not mentioned in the rest of the sentence?\n- Regarding 2.3.1, it is not clear why the distribution \u03bd_\u03b1 turns out to be similar to the outputs of \u03b1_i (even more so if the discriminator encourages them to be turned apart, and so making it easy to separate z* and \u03c8, while allowing z* to contain all information about x).\n- In sec. 3.1. \"This degenerate behavior is a side-effect of our adversarial regularization since stochastic encoders have been successfully used in WAEs Rubenstein et al. (2018)\" it is not clear what adversarial regularization has to do with the degenerate behavior, and how the reference gives any support to that claim.\n\nOverall, given that the proposed model has a fair degree of complexity and thus is difficult to explain, it may be helpful to illustrate and motivate its parts with a specific example (e.g. an image of a particular thing), describing for each element of the approach, the kind of information it is supposed to contain for that particular case."}, "signatures": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621905, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryfaViR9YX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper42/Authors|ICLR.cc/2019/Conference/Paper42/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621905}}}, {"id": "SkertsUjy4", "original": null, "number": 3, "cdate": 1544412029098, "ddate": null, "tcdate": 1544412029098, "tmdate": 1544412029098, "tddate": null, "forum": "ryfaViR9YX", "replyto": "r1e4fcg_JN", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "content": {"title": "I understand the concerns raised", "comment": "As my evaluation below suggests, I am on the fence with this paper.\n\nThe concerns that the other authors have raised is valid (about experiments) and I am usually the one strict about having good experiments to back up any idea. However, at the same time given what the paper is trying to achieve, it is almost magical they were able to show anything at all on MNIST dataset. I am not sure what more the authors could have done to experimentally validate their ideas, but that may be due to my own lack of knowledge in this area. If the other reviewers could suggest possible other experiments to the authors that could make their work even more solid, I would be more than willing to put a rejection so that the authors can submit a much stronger paper later.  On the other hand, if it is difficult to design experiments for an idea, then such a paper should not be accepted just to maintain the rigorousness.\n\nI guess what I am saying is that it is difficult for me to champion this paper as it stands right now."}, "signatures": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621905, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryfaViR9YX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper42/Authors|ICLR.cc/2019/Conference/Paper42/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621905}}}, {"id": "ByeKdiFFAQ", "original": null, "number": 1, "cdate": 1543244657257, "ddate": null, "tcdate": 1543244657257, "tmdate": 1543244657257, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "content": {"title": "Reply", "comment": "We first thank the reviewers for their reviews and now answer individually to the concerns raised.\n\n-Review#1: Thanks a lot. We are glad that the interest of our contributions has been understood and appreciated. On top of the contributions mentioned, we also would like to mention the sound probabilistic formulation of our model which we think can be valuable since the probabilistic interpretation of the attributes allows to perform meaningful interpolations and to introduce a new sampling procedure.\nIndeed, understanding the interaction and the dynamics between all the elements highly interests us and we will work on that in the future: Especially, we would like to investigate how the dimensionality of the attribute space affects the learnt attributes and how we can shape these attributes by providing, for instance, weaker attribute functions.\n\n\n-Review#2: We are sorry that you find our paper hard to follow. Can you be more specific or provide us with ideas for improvement? We are quite surprised about this statement since we tried to be as detailed as possible: all aspects of the model are discussed, motivated and progressively introduced; we also provided a detailed algorithm together with a figure of our architecture. \n\nThe experimental part illustrates the different and novel sampling schemes offered by VarNet on a well-known and simple dataset. It is here for illustration purposes and it is not intended to prove anything. Our paper is not about a specific model or implementation. We chose MNIST because it allows to easily understand what this framework provides, without the need to focus on the implementation of the encoder, decoder and attribute function. That's why we chose simple MLPs for the encoder, decoder and attribute function and put this experimental part in appendix.\n \n The paper you propose is indeed relevant and we will include it in the related works. But this approach, like the Fader networks, requires known attributes (appearance).\n \n Concerning the last question, what prevents z* to be independent of x is that the attribute space is of low dimensionality (as in the Style Tokens paper), so you cannot fully reconstruct x by only considering its attributes. In the degenerate case, z* is a noise independent of x and VarNet amounts to a WAE.\n\n\n-Review#3: See reply to reviewer#2 concerning the clarity of our paper or the discussion concerning the experimental part. Indeed, we believe that the part in appendix is optional and is just here for illustrative purposes.\n\n \\phi(x, m) is just any neural network \"This attribute function is a deterministic neural network that will be learned during training and whose aim is to compute attributes of x \" Sect. 2.1. In the experiments, it is just a MLP (depending on x only or on x and m). We will precise that.\n \n Concerning your 3rd paragraph, we would like to stress upon the fact that there is no ground truth for the attributes. The purpose of this framework is not about that nor about disentanglement. Also, this is a framework to devise generative models with novel sampling properties, not about a specific implementation, so there is no point in showing log-likelihood of the reconstructions ( even if we take the same encoder and decoder networks, how to fairly compare this with a VAE?). \n When applied bluntly on CelebA and by considering the \"Eyeglasses\" attribute, we are for instance capable of adding\n different style of glasses on the same face simply by sampling. The attribute function learns in this case some kind of color palette. On Dsprites, we can obtain two-dimensional planes of variations accounting for the scale and y-position (controlled by the x-axis) and the rotation and x-position (controlled by the y-axis). There is indeed no reason why we could obtain a dimension accounting for only one attribute. We also applied this framework to the generation of sequences of discrete symbols and on sound generation with successful results. Since these experiments require more tuning about the\n encoder, decoder and attribute functions, we preferred to only display the simplest experiment allowing to understand and focus on the possibilities offered by VarNet."}, "signatures": ["ICLR.cc/2019/Conference/Paper42/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621905, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryfaViR9YX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper42/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper42/Authors|ICLR.cc/2019/Conference/Paper42/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers", "ICLR.cc/2019/Conference/Paper42/Authors", "ICLR.cc/2019/Conference/Paper42/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621905}}}, {"id": "HJljbAELp7", "original": null, "number": 3, "cdate": 1541979650862, "ddate": null, "tcdate": 1541979650862, "tmdate": 1541979650862, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "content": {"title": "Paper lacking an experimental section", "review": "This paper introduces a new framework for learning an interpretable representation of images and their attributes. The authors suggest decomposing the representation into a set of 'template' latent features, and a set of attribute-based features. The attribute-based features can be either 'free', i.e. discovered from the data, or 'fixed', i.e. based on the ground truth attributes. The authors encourage the decomposition of the latent space into the 'template' and the 'attributes' features by training a discriminator network to predict whether the attributes and the template features come from the same image or not.\n\nWhile the idea is interesting, the paper is lacking an experimental section, so the methodology is impossible to evaluate. Furthermore, while the authors spend many pages describing their methodology, the writing is often hard to follow, so I am still confused about the exact implementation of the attribute features \\phi(x, m) for example. The authors do point to the Appendix for their Experiments section, however this is not a good idea. The paper should be self-contained and the authors should not assume that their readers will read the information presented in the Appendix, which is always optional. \n\nUnfortunately, even the experimental section presented in the Appendix is not comprehensive enough to evaluate the proposed method. The authors train the model on a single dataset (MNIST), no baseline or ablation results are presented, and all the results are purely qualitative. Given that the ground truth attribute decomposition for MNIST is not known, even the qualitative results are impossible to evaluate. I recommend that the authors present quantitive results in the updated version of their paper (i.e. disentanglement metric scores, the log-likelihood of the reconstructions), including new experiments on a dataset like dSprites or CelebA, where the ground truth attributes are known.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "cdate": 1542234551021, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636038, "tmdate": 1552335636038, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyxsBAGAhX", "original": null, "number": 2, "cdate": 1541447235035, "ddate": null, "tcdate": 1541447235035, "tmdate": 1541534336228, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "content": {"title": "Interesting Work", "review": "The paper proposes a generative network capable of generating variations of a given input, conditioned on an attribute. Earlier papers generated variations of the input in the presence of the attribute and this attribute was assumed to be known during training. This paper proposes to automatically discover these attribute and thus work to produce variations even in the absence of known attribute information.\n\nThe paper is dense, but it is well written. It has mixed ideas from several papers - the basic VAE architecture, combined with a discriminator and regularizations over latent space. The key thing, of course, is the design of the attribute function. There seems to be an interesting interaction between the encoder, discriminator and the attribute function that requires more investigation. This is acknowledged in the conclusion as well.\n\nThe work is original and the results on the MNIST dataset are very interesting. I think the significance of this work lies in the fact that this can be a starting point for several interesting future works in this direction.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "cdate": 1542234551021, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636038, "tmdate": 1552335636038, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyxzkI2ThQ", "original": null, "number": 1, "cdate": 1541420506462, "ddate": null, "tcdate": 1541420506462, "tmdate": 1541534336027, "tddate": null, "forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "invitation": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "content": {"title": "Lack of clarity and almost no experiments", "review": "This paper proposes a generalization of variational auto-encoders to account for meta-data (attributes), learning new ones, in a way that these can be controlled to generate new samples. The model learns how to decouple the attributes in an adversarial way by means of a discriminator. The problem is interesting, but I found two main issues with this paper:\n1.- Lack of clarity: I found the paper difficult to follow, even after reading Sec. 2 and 3 several times.\n2.- Almost absence of experiments: The paper only has one experiment, which is in the appendix, and is about sampling using the MNIST dataset. Given that this paper proposes a model, whose properties can be assessed by means of experiments, the fact that there is nothing of the kind provides no support to any benefits the model may have.\n\nOther points:\nWhat in the model prevents the solution of z_* being just random (independently of x)?\n\nThis paper seems relevant Esser, Patrick, Ekaterina Sutter, and Bj\u00f6rn Ommer. \"A Variational U-Net for Conditional Appearance and Shape Generation.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper42/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variation Network: Learning High-level Attributes for Controlled Input Manipulation", "abstract": "This paper presents the Variation Network (VarNet), a  generative model providing means to manipulate the high-level attributes of a given input. The originality of our approach is that VarNet is not only capable of handling pre-defined attributes but can also learn the relevant attributes of the dataset by itself.  These two settings can be easily combined  which makes VarNet applicable for a wide variety of tasks. Further, VarNet has a sound probabilistic interpretation which grants us with  a novel way to navigate in the latent spaces as well as means to control how the  attributes are learned. We demonstrate  experimentally that this model is capable of performing interesting input manipulation  and that the learned attributes are relevant and interpretable.", "paperhash": "hadjeres|variation_network_learning_highlevel_attributes_for_controlled_input_manipulation", "keywords": ["Generative models", "Input manipulation", "Unsupervised feature learning", "Variations"], "authorids": ["hadjeres.g@gmail.com"], "authors": ["Ga\u00ebtan Hadjeres"], "TL;DR": "The Variation Network is a generative model able to learn high-level attributes without supervision that can then be used for controlled input manipulation.", "pdf": "/pdf/7219a3347854bcaadb59564e76eff04b865933bd.pdf", "_bibtex": "@misc{\nhadjeres2019variation,\ntitle={Variation Network: Learning High-level Attributes for Controlled Input Manipulation},\nauthor={Ga\u00ebtan Hadjeres},\nyear={2019},\nurl={https://openreview.net/forum?id=ryfaViR9YX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper42/Official_Review", "cdate": 1542234551021, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryfaViR9YX", "replyto": "ryfaViR9YX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper42/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636038, "tmdate": 1552335636038, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper42/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}