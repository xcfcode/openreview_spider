{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396549888, "tcdate": 1486396549888, "number": 1, "id": "HyAthz8ul", "invitation": "ICLR.cc/2017/conference/-/paper376/acceptance", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper presents an idea with a sensible core (augmenting amortized inference with per-instance optimization) but with an overcomplicated and ad-hoc execution. The reviewers provided clear guidance for how this paper could be improved, and thus I invite the authors to submit this paper to the workshop track.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396550394, "id": "ICLR.cc/2017/conference/-/paper376/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396550394}}}, {"tddate": null, "tmdate": 1485228728884, "tcdate": 1485228628633, "number": 3, "id": "rJpI9SVwg", "invitation": "ICLR.cc/2017/conference/-/paper376/public/comment", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["~Dilin_Wang1"], "readers": ["everyone"], "writers": ["~Dilin_Wang1"], "content": {"title": "Thank you for your review and comments", "comment": "We highly appreciate the time and feedback from all the reviewers, all of which we will take into serious consideration in our revision. We will particularly strengthen and clarify the empirical experiments. Below we address some of the major points: \n\n[Testing Accuracy Score]\nWe agree with the reviewers' point on the \"testing accuracy\" score, but think that it still provides some valuable insight about the dataset. Its blindness to the background can be a good thing in that it captures more information about the \"effective amount\" of objects the dataset contains.  The problem is that it is very difficult to obtain a *perfect* score, and reporting more than one metrics (in an objective fashion) can help to gain more comprehensive understandings. \n\n[Repulsive Term in High Dimension]\nOur repulsive force works due to two tricks: 1) scaling the bandwidth with the data diversity using the median trick, which alleviates the exponential decay of RBF kernel. 2) define kernel on the feature space instead of the raw pixels of the images, which allows us to respect the manifold structure of the images. The framework of SVGD allows us to use any positive definite kernels and change it adaptively during iterations, because the kernel only defines the \"tangent space\" for improvement. \n\nSteinGAN without kernel corresponds to Viterbi training of the energy model and we find it work well with careful tuning of parameters, but tend to converge to a small number of bad-looking images after running a large number of iterations; adding the kernel under the same setting helps prevent this problem. Our current results on CIFAR10 shows that SteinGAN without kernel gives an inception score of 6.34, while that SteinGAN with kernel gives 6.76. \n\n[Amortized is slower than non-amortized]\nAlthough the amortized algorithm has the overhead of updating $\\xi$, it stores the information in a generative network, and allows us to simulate as many images as we need. By using the one-step gradient update we proposed, the update of $\\xi$ is the same as standard backpropagation except replacing the Dlogp with the SVGD gradient. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287601011, "id": "ICLR.cc/2017/conference/-/paper376/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1oRQDqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper376/reviewers", "ICLR.cc/2017/conference/paper376/areachairs"], "cdate": 1485287601011}}}, {"tddate": null, "tmdate": 1482091497524, "tcdate": 1482091497524, "number": 3, "id": "By-ehDEEg", "invitation": "ICLR.cc/2017/conference/-/paper376/official/review", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/conference/paper376/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper376/AnonReviewer3"], "content": {"title": "Insufficient empirical evaluation.", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes an amortized version of the Stein variational gradient descent (SVGD) method in which \"a neural network is trained to mimic the SVGD dynamics\". It applies the method to generative adversarial training to yield a training procedure where the discriminator is interpreted as an energy-based probabilistic model.\n\nOne criticism I have of the presentation is that a lot of time and energy is spent setting the table for a method which is claimed to be widely applicable, and the scope of the empirical evaluation is narrowed down to a single specific setting. In my view, either the paper falls short of its goal of showing how widely applicable the proposed method is, or it spends too much time setting the table for SteinGAN and not enough time evaluating it.\n\nThe consequence of this is that the empirical results are insufficient in justifying the approach proposed by the paper. As another reviewer pointed out, DCGAN is becoming outdated as a benchmark for comparison.\n\nQualitatively, SteinGAN samples don't look significantly better than DCGAN samples, except for the CelebA dataset. In that particular case, the DCGAN samples don't appear to be the ones presented in the original paper; where do they come from?\n\nQuantitatively, DCGAN beats SteinGAN by a small margin for the ImageNet Inception Score and SteinGAN beats DCGAN by an even smaller margin for the CIFAR10 Inception Score. Also, in my opinion, the \"testing accuracy\" score is not a convincing evaluation metric: while it is true that it measures the amount of information captured in the simulated image sets, it is only sensitive to information useful for the discrimination task, not for the more general modeling task. For instance, this score is likely completely blind to information present in the background of the image.\n\nBecause of the reasons outlined above, I don't think the paper is ready for publication at ICLR.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512605418, "id": "ICLR.cc/2017/conference/-/paper376/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper376/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper376/AnonReviewer2", "ICLR.cc/2017/conference/paper376/AnonReviewer1", "ICLR.cc/2017/conference/paper376/AnonReviewer3"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512605418}}}, {"tddate": null, "tmdate": 1481934291037, "tcdate": 1481934259092, "number": 2, "id": "Byj2SWzVx", "invitation": "ICLR.cc/2017/conference/-/paper376/official/review", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/conference/paper376/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper376/AnonReviewer1"], "content": {"title": "Review: Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "rating": "4: Ok but not good enough - rejection", "review": "The authors propose amortized SVGD, an amortized form of prior work on SVGD, which is a particle variational method that maximally decreases the KL divergence at each update. \"amortized SVGD\" is done by training a neural network to learn this dynamic. They then apply this idea to train energy-based models, which admit a tractable unnormalized density.\n\nIn SVGD, the main difference from just MAP is the addition of a \"repulsive force\" that prevents degeneracy by encouraging probability mass to be spread to locations outside the mode. How this is able to still act as a strong enough entropy-like term in high dimensions is curious. From my understanding of their previous work, this was not a problem as the only experiments were on toy and UCI data sets.\n\nIn the experimental results here, they apply the kernel on the hidden representation of an autoencoder, which seems key, similar to Li et al. (2015) where their kernel approach for MMD would not work as well otherwise. However, unlike Li et al. (2015) the autoencoder is part of the model itself and not fixed. This breaks much of the authors' proposed motivation and criticisms of prior work, if they must autoencode onto some low-dimensional space (putting most effort then on the autoencoder, which changes per iteration) before then applying their method.\n\nUnlike previous literature which uses inference networks, their amortized SVGD approach seems in fact slower than the non-amortized approach. This is because they must make the actual update on xi before then regressing to perform the update on eta (in previous approaches, this would be like having to perform local inferences before then updating inference network parameters, or at least partially performing the local inference). This seems quite costly during training.\n\nI recommend the paper be rejected, and that the authors provide more comprehensive experimental results, expecially around the influence of the autoencoder, the incremental updates versus full updates, and the training time of amortized vs non-amortized approaches. The current results are promising but unclear why given the many knobs that the authors are playing with.\n\nReferences\n\nLi, Y., Swersky, K., & Zemel, R. (2015). Generative Moment Matching Networks. Presented at the International Conference on Machine Learning.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512605418, "id": "ICLR.cc/2017/conference/-/paper376/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper376/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper376/AnonReviewer2", "ICLR.cc/2017/conference/paper376/AnonReviewer1", "ICLR.cc/2017/conference/paper376/AnonReviewer3"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512605418}}}, {"tddate": null, "tmdate": 1481887666398, "tcdate": 1481887666398, "number": 1, "id": "r193JUZVl", "invitation": "ICLR.cc/2017/conference/-/paper376/official/review", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/conference/paper376/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper376/AnonReviewer2"], "content": {"title": "Decent results, but unclear whether this is due to the proposed Stein variational gradient", "rating": "4: Ok but not good enough - rejection", "review": "This paper considers the energy-based model interpretation of GAN, where the discriminator is an unnormalized model for the likelihood of a generative model p(x|theta) and the generator is a directed model that approximates this distribution. The generator is used to draw approximate negative phase samples that are used in stochastic maximum likelihood / contrastive divergence learning of the EBM / discriminator.\n\nThe main idea in the paper is to fit the generator by following the Stein variational gradient. In practice this gradient consists of the usual gradient provided by the discriminator with an added term that provides a repulsive force between the sampled data points to increase sample diversity.\n\nThe idea of using a kernel to push apart the sampled points is interesting, and will work in low dimensions, but it is hard to see how it can work in full scale images. For high dimensional samples x, the proposed kernel is unlikely to provide a useful distance measure between points. There are no convincing experiments in the paper that show otherwise. Specifically:\n\n- There is no experiment that compares between standard GAN and GAN + repulsion, using the same architecture. (please address this in the rebuttal)\n- If the Stein variational idea is taken literally, the right thing to do would be to fully optimize the generator at every step, and then taking a single optimization step on the discriminator. Instead, each is updated in turn, and the learning rates of both steps are adjusted to keep the two \"in line\".\n- The kernel used to fit the generator is defined in the auto-encoder space of the discriminator, and thus depends on the discriminator parameters. The objective that is used to fit the generator thus changes at every step, and the procedure can no longer be interpreted as stochastic gradient descent with respect to any single well defined objective.\n\nThe authors obtain good results: The generated images clearly look better than those generated by DCGAN. However, their approach has a number of changes compared to DCGAN, so it is not clear where the improvement comes from. In addition, by now the DCGAN is no longer a very strong baseline, as various other techniques have been proposed.\n\nNote: The use of phi for both the \"particle gradient direction\" and energy function is confusing", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512605418, "id": "ICLR.cc/2017/conference/-/paper376/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper376/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper376/AnonReviewer2", "ICLR.cc/2017/conference/paper376/AnonReviewer1", "ICLR.cc/2017/conference/paper376/AnonReviewer3"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512605418}}}, {"tddate": null, "tmdate": 1481658242401, "tcdate": 1481658242396, "number": 2, "id": "B1qKkApXx", "invitation": "ICLR.cc/2017/conference/-/paper376/public/comment", "forum": "H1oRQDqlg", "replyto": "SJwukvSQe", "signatures": ["~Dilin_Wang1"], "readers": ["everyone"], "writers": ["~Dilin_Wang1"], "content": {"title": "Reply to the pre-review from AnonReviewer1", "comment": "Thanks for the comments. I hope the following note could address your concern well. Thanks. \n\nhttp://goo.gl/gCSAl3"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287601011, "id": "ICLR.cc/2017/conference/-/paper376/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1oRQDqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper376/reviewers", "ICLR.cc/2017/conference/paper376/areachairs"], "cdate": 1485287601011}}}, {"tddate": null, "tmdate": 1481105283338, "tcdate": 1481105263469, "number": 2, "id": "SJwukvSQe", "invitation": "ICLR.cc/2017/conference/-/paper376/pre-review/question", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/conference/paper376/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper376/AnonReviewer1"], "content": {"title": "equation 10", "question": "Can you elaborate on the derivation of equation 10? I'm not sure I follow how it is obtained by \"performing only one step of gradient descent of (8) (or (9))\"."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481105264057, "id": "ICLR.cc/2017/conference/-/paper376/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper376/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper376/AnonReviewer3", "ICLR.cc/2017/conference/paper376/AnonReviewer1"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481105264057}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1480623409304, "tcdate": 1478288338586, "number": 376, "id": "H1oRQDqlg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "H1oRQDqlg", "signatures": ["~Dilin_Wang1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1480620461324, "tcdate": 1480620461320, "number": 1, "id": "BkrnKeCGg", "invitation": "ICLR.cc/2017/conference/-/paper376/public/comment", "forum": "H1oRQDqlg", "replyto": "SyINHx0zg", "signatures": ["~Dilin_Wang1"], "readers": ["everyone"], "writers": ["~Dilin_Wang1"], "content": {"title": "Thank you for reviewing our paper", "comment": "The experiment settings are as follows:\n\n1. Train ResNet classifiers on a) \"Real Training Set\" b) 100 copies of 500 examples taken at random from the \"Real Training Set\"  c) 50,000 DCGAN samples d) 50,000 SteinGAN samples\n2. Measure the classifiers' accuracy on the \"Real Testing Set\"\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287601011, "id": "ICLR.cc/2017/conference/-/paper376/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1oRQDqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper376/reviewers", "ICLR.cc/2017/conference/paper376/areachairs"], "cdate": 1485287601011}}}, {"tddate": null, "tmdate": 1480619309567, "tcdate": 1480619309563, "number": 1, "id": "SyINHx0zg", "invitation": "ICLR.cc/2017/conference/-/paper376/pre-review/question", "forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "signatures": ["ICLR.cc/2017/conference/paper376/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper376/AnonReviewer3"], "content": {"title": "Testing accuracy question", "question": "Can you clarify the method used to obtain the results presented in Figure 2's \"Testing Accuracy\" table? My understanding is as follows:\n\n1. Train a ResNet classifier on 50,000 SteinGAN samples.\n\n2. Measure the classifier's accuracy on a) the dataset used to train the SteinGAN model (\"Real Training Set\"), b) 100 copies of 500 examples taken at random from the \"Real Training Set\", c) DCGAN samples (how many?), and d) held-out SteinGAN samples (how many?).\n\nIs this correct?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning", "abstract": "We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results.", "pdf": "/pdf/d1cab3a9a4271a9003c492bb98269ec3e66a8fb4.pdf", "paperhash": "wang|learning_to_draw_samples_with_application_to_amortized_mle_for_generative_adversarial_learning", "keywords": ["Unsupervised Learning"], "conflicts": ["cs.dartmouth.edu"], "authors": ["Dilin Wang", "Qiang Liu"], "authorids": ["dilin.wang.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481105264057, "id": "ICLR.cc/2017/conference/-/paper376/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper376/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper376/AnonReviewer3", "ICLR.cc/2017/conference/paper376/AnonReviewer1"], "reply": {"forum": "H1oRQDqlg", "replyto": "H1oRQDqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper376/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481105264057}}}], "count": 10}