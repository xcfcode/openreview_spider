{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1391486160000, "tcdate": 1391486160000, "number": 3, "id": "h4624nkGACt8T", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "AY3Hz-ujSEXUl", "replyto": "AY3Hz-ujSEXUl", "signatures": ["anonymous reviewer f7a0"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep Belief Networks for Image Denoising", "review": "This work presents a method for denoising images using a DBN by identifying feature nodes that are associated with noise.  This is done by measuring the mean differences in activations when presented with noisy versus corresponding ground-truth clean images in the training set.  Test images are denoised by performing inference, reseting the 'noise' feature nodes to their average values across the clean images, and reconstructing from the resulting representation.  The method is tested on MNIST with additive Gaussian noise.\r\n\r\nThe method is simple and appealing; however, it is evaluated only on one very limited test case, and is under-analyzed.  How does this method perform for other types of input or noise?  Also, although the authors review some prior work on the subject, they do not explicitly compare their method against any other algorithm.\r\n\r\nA larger question I have is whether it is necessary to require clean/noisy inputs be associated in pairs, or if this association could be weakened or removed.  This would be a major advantage of this method if it were the case.  That is, is it enough to have a pool of known clean images and a pool of known noisy images, with no elementwise correspondence between the two?  If the clean data underlying the noisy data generation is the same between these two populations, then the difference in mean activations should be unchanged.  But it seems to me that these means might also not change much if the two sets of underlying clean images are distinct but from the same general population, e.g. if half of training images are clean, and the other half is used to generate noisy ones.\r\n\r\nThe paper is pretty clearly written, though I think the overview of RBMs and DBNs takes up too much space (2 pages); this seems it could be condensed, and replaced with more experiments and details on the method presented.  I also would have liked to see more illustrating the method's internals.  Why was the threshold of 0.9 chosen for identifying a node as a 'noise' feature, for example?  Some plots/histograms of the activations and 'relative activity' measurement could have been useful here.\r\n\r\n\r\nPros:\r\n\r\n- Natural and simple method with limited demonstrated effectiveness.\r\n\r\nCons:\r\n\r\n- Applied to only one limited setting\r\n- No comparisons to other methods\r\n- Could have more measurements to illustrate the method's internals"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Belief Networks for Image Denoising", "decision": "submitted, no decision", "abstract": "Deep Belief Networks which are hierarchical generative models are effective tools for feature representation and extraction. Furthermore, DBNs can be used in numerous aspects of Machine Learning such as image denoising. In this paper, we propose a novel method for image denoising which relies on the DBNs' ability in feature representation. This work is based upon learning of the noise behavior. Generally, features which are extracted using DBNs are presented as the values of the last layer nodes. We train a DBN a way that the network totally distinguishes between nodes presenting noise and nodes presenting image content in the last later of DBN, i.e. the nodes in the last layer of trained DBN are divided into two distinct groups of nodes. After detecting the nodes which are presenting the noise, we are able to make the noise nodes inactive and reconstruct a noiseless image. In section 4 we explore the results of applying this method on the MNIST dataset of handwritten digits which is corrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in average mean square error (MSE) was achieved when the proposed method was used for the reconstruction of the noisy images.", "pdf": "https://arxiv.org/abs/1312.6158", "paperhash": "keyvanrad|deep_belief_networks_for_image_denoising", "keywords": [], "conflicts": [], "authors": ["Mohammad Ali Keyvanrad", "mohammad pezeshki", "Mohammad Mehdi Homayounpour"], "authorids": ["keyvanrad@aut.ac.ir", "mohammadpz@gmail.com", "homayoun@aut.ac.ir"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390784040000, "tcdate": 1390784040000, "number": 2, "id": "fn_Dn2Z1DYB65", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "AY3Hz-ujSEXUl", "replyto": "AY3Hz-ujSEXUl", "signatures": ["anonymous reviewer 4d9c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep Belief Networks for Image Denoising", "review": "This paper presents an approach for image denoising, based on deep belief networks (DBN). The idea is to train a DBN on a training set consisting of both noising and non-noisy images. Then, the activity of top-hidden-layer units is compared between the noisy and non-noisy images, in order to identify units which are mostly involved in the modelling of noisy images. Denoising is then performed by inputing a noisy image, inferring the value of the top hidden units, fixing the 'noise' hidden units to its neutral value (i.e. its average value on the clean images) and then regenerating the input image. Experiments show that this approach has some success in performing denoising.\r\n\r\nThe main weakness of this paper is that no comparisons are made with other good denoising baselines. I would have at least expected a comparison with the denoising autoencoder work cited in this paper [6]. Also, denoising experiments on MNIST are not particularly compelling and too simplistic. \r\n\r\nPros: \r\n- The presented idea is simple. \r\n- Results seem OK.\r\n\r\nCons: \r\n- The results are too preliminary, as no comparisons are made with a good denoising baseline (including the deep learning work on denoising, cited in this paper).\r\n- Writing could be improved.\r\n\r\nOther comment\r\n- How is denoising performed in the 'reconstruction without eliminating any node'? Specifically, is this network trained on both noisy and non-noisy images, or only on clean images?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Belief Networks for Image Denoising", "decision": "submitted, no decision", "abstract": "Deep Belief Networks which are hierarchical generative models are effective tools for feature representation and extraction. Furthermore, DBNs can be used in numerous aspects of Machine Learning such as image denoising. In this paper, we propose a novel method for image denoising which relies on the DBNs' ability in feature representation. This work is based upon learning of the noise behavior. Generally, features which are extracted using DBNs are presented as the values of the last layer nodes. We train a DBN a way that the network totally distinguishes between nodes presenting noise and nodes presenting image content in the last later of DBN, i.e. the nodes in the last layer of trained DBN are divided into two distinct groups of nodes. After detecting the nodes which are presenting the noise, we are able to make the noise nodes inactive and reconstruct a noiseless image. In section 4 we explore the results of applying this method on the MNIST dataset of handwritten digits which is corrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in average mean square error (MSE) was achieved when the proposed method was used for the reconstruction of the noisy images.", "pdf": "https://arxiv.org/abs/1312.6158", "paperhash": "keyvanrad|deep_belief_networks_for_image_denoising", "keywords": [], "conflicts": [], "authors": ["Mohammad Ali Keyvanrad", "mohammad pezeshki", "Mohammad Mehdi Homayounpour"], "authorids": ["keyvanrad@aut.ac.ir", "mohammadpz@gmail.com", "homayoun@aut.ac.ir"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390695660000, "tcdate": 1390695660000, "number": 1, "id": "x1X3ZIGuLvwtO", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "AY3Hz-ujSEXUl", "replyto": "AY3Hz-ujSEXUl", "signatures": ["anonymous reviewer a9cd"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep Belief Networks for Image Denoising", "review": "This paper presents a simple method for denoising noisy mnist digits with a deep belief network. The method looks at the relative activities of the hidden units when the input is a normal vs a noisy image. After obtaining these statistics, at test time, noisy nodes or nodes which are affected by noise are removed, leading to better reconstructions.\r\n\r\nThe authors are recommended to reference the paper: Deep Networks for robust visual recognition, Tang&Eliasmith icml 2010, where the tasks are similar but with a more elaborate algorithm and experimental results.\r\n\r\nWhile the task is interesting and potentially very important, the method proposed in this paper is extremely simple and are not shown to work for difficult noise/occlusion cases. For example, simple reconstruction with DBN is already very good for the mnist digits.\r\n\r\nPossible improvements include trying more difficult noise and occlusions; look at how denoising can help reduce recognition error; and coming up with a more principled way of determining which nodes are affected. Since a DBN is a distributed network, it is likely that all hidden nodes would be affected somewhat, and each image would lead to a different activation for a particular hidden node, simply by looking at relative activations seems very ad hoc. There are several papers related to denoising using DBNs/DBMs that can be found with simple google search. The authors should compare/contrast, cite and test on similar experiments with those other papers."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Belief Networks for Image Denoising", "decision": "submitted, no decision", "abstract": "Deep Belief Networks which are hierarchical generative models are effective tools for feature representation and extraction. Furthermore, DBNs can be used in numerous aspects of Machine Learning such as image denoising. In this paper, we propose a novel method for image denoising which relies on the DBNs' ability in feature representation. This work is based upon learning of the noise behavior. Generally, features which are extracted using DBNs are presented as the values of the last layer nodes. We train a DBN a way that the network totally distinguishes between nodes presenting noise and nodes presenting image content in the last later of DBN, i.e. the nodes in the last layer of trained DBN are divided into two distinct groups of nodes. After detecting the nodes which are presenting the noise, we are able to make the noise nodes inactive and reconstruct a noiseless image. In section 4 we explore the results of applying this method on the MNIST dataset of handwritten digits which is corrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in average mean square error (MSE) was achieved when the proposed method was used for the reconstruction of the noisy images.", "pdf": "https://arxiv.org/abs/1312.6158", "paperhash": "keyvanrad|deep_belief_networks_for_image_denoising", "keywords": [], "conflicts": [], "authors": ["Mohammad Ali Keyvanrad", "mohammad pezeshki", "Mohammad Mehdi Homayounpour"], "authorids": ["keyvanrad@aut.ac.ir", "mohammadpz@gmail.com", "homayoun@aut.ac.ir"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387966800000, "tcdate": 1387966800000, "number": 58, "id": "AY3Hz-ujSEXUl", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "AY3Hz-ujSEXUl", "signatures": ["keyvanrad@aut.ac.ir"], "readers": ["everyone"], "content": {"title": "Deep Belief Networks for Image Denoising", "decision": "submitted, no decision", "abstract": "Deep Belief Networks which are hierarchical generative models are effective tools for feature representation and extraction. Furthermore, DBNs can be used in numerous aspects of Machine Learning such as image denoising. In this paper, we propose a novel method for image denoising which relies on the DBNs' ability in feature representation. This work is based upon learning of the noise behavior. Generally, features which are extracted using DBNs are presented as the values of the last layer nodes. We train a DBN a way that the network totally distinguishes between nodes presenting noise and nodes presenting image content in the last later of DBN, i.e. the nodes in the last layer of trained DBN are divided into two distinct groups of nodes. After detecting the nodes which are presenting the noise, we are able to make the noise nodes inactive and reconstruct a noiseless image. In section 4 we explore the results of applying this method on the MNIST dataset of handwritten digits which is corrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in average mean square error (MSE) was achieved when the proposed method was used for the reconstruction of the noisy images.", "pdf": "https://arxiv.org/abs/1312.6158", "paperhash": "keyvanrad|deep_belief_networks_for_image_denoising", "keywords": [], "conflicts": [], "authors": ["Mohammad Ali Keyvanrad", "mohammad pezeshki", "Mohammad Mehdi Homayounpour"], "authorids": ["keyvanrad@aut.ac.ir", "mohammadpz@gmail.com", "homayoun@aut.ac.ir"]}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 4}