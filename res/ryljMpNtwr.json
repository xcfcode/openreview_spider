{"notes": [{"id": "ryljMpNtwr", "original": "H1eJi4hLPH", "number": 424, "cdate": 1569438994706, "ddate": null, "tcdate": 1569438994706, "tmdate": 1577168258946, "tddate": null, "forum": "ryljMpNtwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ixOQerMM-a", "original": null, "number": 1, "cdate": 1576798696025, "ddate": null, "tcdate": 1576798696025, "tmdate": 1576800939608, "tddate": null, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes a benchmark for assessing the impact of image quality degradation (e.g. simulated fog, snow, frost) on the performance of object detection models. The authors introduce corrupted versions of popular object detection datasets, namely PASCAL-C, COCO-C and Cityscapes-C, and an evaluation protocol which reveals that the current models are not robust to such corruptions (losing as much as 60% of the performance). The authors then show that a simple data augmentation scheme significantly improves robustness. The reviewers agree that the manuscript is well written and that the proposed benchmark reveals major drawbacks of current detection models. However, two critical issues with the paper paper remain, namely lack of novelty in light of Geirhos et al., and how to actually use this benchmark in practice. I will hence recommend the rejection of this paper in the current state. Nevertheless, we encourage the authors to address the raised shortcomings (the new experiments reported in the rebuttal are a good starting point). ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795710265, "tmdate": 1576800259233, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper424/-/Decision"}}}, {"id": "rJgqFog3iS", "original": null, "number": 5, "cdate": 1573813122116, "ddate": null, "tcdate": 1573813122116, "tmdate": 1573833918714, "tddate": null, "forum": "ryljMpNtwr", "replyto": "Bkldg_0KKH", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "New experiments to demonstrate the relevance of our benchmark and method for real world corruptions", "comment": "Thank you for your feedback and your assessment of our article as being \u201cinteresting and clearly show[ing] the deficiencies of state-of-the-art object detection methods\u201d. \n\nYour main concern is the novelty of our approach. We agree that our work builds on extending the works of [8] and [9] for the object detection community. It was previously unclear to which degree detection models would be affected by image distortions. While our result may not be entirely surprising - the behavior is very similar to that of object recognition models - we consider it even more relevant for the object detection community which often struggles with \u201cnatural\u201d distribution shifts inherent to applying models \u201cin the wild\u201d. \n\nWe therefore aimed to address your concern by performing additional experiments on such *natural* distortion shifts induced by real-world (rather than synthetic) corruptions such as different weather conditions and the transition from daytime to nighttime, answering the (previously open) question of whether robustness towards synthetic distortions also implies robustness on real-world distortions, which goes much further than [8] and [9]. Our findings suggest that performance on the proposed benchmarks is indeed predictive for performance on natural distribution shifts. Moreover, combined training on normal and stylized data improves performance in every single experiment (for heavy fog, performance improves even for about 50%. Details are included in Section 3.5 of the updated PDF). While collecting data for real-world distortions is often prohibitively expensive, this opens up a \u201ccheap\u201d and effective proxy evaluation method that may be of interest to all those interested in building robust detection methods for \u201cthe wild\u201d.\n\nWe hope that this analysis addresses your concern in two ways. It adds novelty because such an analysis of both synthetic and real-world distortions has to the best of our knowledge never been conducted, and it demonstrates the relevance of the proposed benchmark when addressing distribution shifts that occur naturally.\n\n[8] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel: ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness, ICLR 2019\n[9] Dan Hendrycks, Thomas Dietterich: Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, ICLR 2019\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "r1lRZ3lnjH", "original": null, "number": 6, "cdate": 1573813253528, "ddate": null, "tcdate": 1573813253528, "tmdate": 1573813253528, "tddate": null, "forum": "ryljMpNtwr", "replyto": "rkle3iBPir", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "Additional experiments measuring the effect of corruptions on SSIM and performance of our method on natural distortions", "comment": "Again, thanks a lot for your ideas!\n\nFollowing your suggestion we performed an analysis similar to our previous RMSE analysis but instead using SSIM. We indeed find a better but still limited correspondence between SSIM and the impact of each corruption. We updated the draft to include these experiments.\n\nWe hope that your central concern concerning novelty was resolved through the clarification in the previous comment. This does not change the fact that our method was extending [8] and [9], as noted by the other reviewers. We agree with this assessment but still consider our benchmark highly relevant as object detection systems have a broad range of outdoor applications where they are confronted with natural distortions like weather changes. To strengthen this connection and add novelty we investigated whether results on our benchmark are related to natural distortions. We find this to be the case for images with annotations for weather conditions as well as highly realistic synthetic fog. Furthermoreour approach of training on the combination of normal and stylized data helps with every natural distortion we tested. For details please see our corresponding comment to Reviewer #2.\n\nWe updated the draft to include these results as well as an analysis of pre-trained backbones in Sections 3.5 and 3.4 respectively. \n\n[8] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel: ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness, ICLR 2019\n[9] Dan Hendrycks, Thomas Dietterich: Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, ICLR 2019\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "H1laE5l3jH", "original": null, "number": 4, "cdate": 1573812788700, "ddate": null, "tcdate": 1573812788700, "tmdate": 1573812882167, "tddate": null, "forum": "ryljMpNtwr", "replyto": "Bkeyu2SPsB", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "Submission updated", "comment": "We updated the article to include the experiments and results on natural distortions. "}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "Bkeyu2SPsB", "original": null, "number": 3, "cdate": 1573506150856, "ddate": null, "tcdate": 1573506150856, "tmdate": 1573507031675, "tddate": null, "forum": "ryljMpNtwr", "replyto": "r1gPC72CKH", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "Additional experiments to demonstrate the relevance to corruptions in the real world ", "comment": "Thank you for your valuable feedback and for your assessment of our work as addressing \u201can important problem\u201d. We provide a point-by-point response to your suggestions below.\n\n1a. Connection to perturbations in the real world\n\nThis is a good point, we assumed that improved performance on synthetic distortions automatically leads to better performance on perturbations in the real world\u2014but we never actually showed this in the paper. Following your suggestion, we conducted two experiments to investigate this link:\n \nI) We evaluated our approach (training on a combination of stylized and normal training data) on Foggy Cityscapes [1], a version of Cityscapes with realistic fog. In the presence of strong fog, a vanilla detection model shows strong performance impairments (down to 51% of its original performance). Our model, on the other hand, is far more robust on this real-world distortion (retaining 72% of original performance).\n\nAbsolute (AP) clean    0.005     0.01      0.02  (number indicates strength of fog)\nStandard         36.4       30.2      25.1     18.7\nOurs* \t\t36.3       32.2      29.9     26.2\n\nRelative (%)\tclean    0.005     0.01      0.02 \nStandard\t100       83.0      69.0      51.4\nOurs*\t\t100       88.7      82.4      72.2\n\n*  model trained jointly on stylized and clean data, denoted \u201ccombined\u201d in paper\n\nII) We measure the effect of our method on other natural distortions using weather annotations from the BDD100k dataset [2], which contains real-world rain and show images. The BDD100k distortions are relatively benign (e.g., images annotated as rainy often show only wet roads but no real rain). Consequently, the performance drop of a standard model is small. Nevertheless, our approach outperforms the baseline model on both \u201crainy\u201d and \u201csnowy\u201d conditions.\n\nBDD100k:\nWeather:\tClear       Rainy      Snowy\nStandard\t27.8          27.6         23.6\nOurs*\t\t27.7          28.0         24.2\n\nTaken together, these two additional experiments conducted in response to your suggestion establish a link between synthetic corruptions (as employed by our benchmark) and natural distortions (real-world rain, snow, fog) as evaluated on the Foggy Cityscapes / BDD100k datasets. Interestingly, good performance on synthetic corruptions is predictive for performance on natural distortions, which is a novel finding that has, to the best of our knowledge, never been reported before. As data for real-world distortions is often prohibitively expensive to collect, our benchmark opens up an efficient proxy method for assessing the effect of natural distortions.\n\n1b. Protocol for benchmark use by future researchers\n\nWe agree: defining a clear protocol on how to use the benchmark in the future is key. Our previous description of the submission process (how to submit, which metrics to report, how models will be ranked, \u2026) was buried in the Appendix, which probably is not salient enough to ensure a consistent evaluation protocol for future users of our benchmark. We will thus add a parapraph to section 2.1 (\u201cRobust Detection Benchmark\u201d).\n\n\nWe would appreciate it if you could take the time to assess these new results and indicate whether this addresses your suggestions and changes your assessment of our work. Please feel free to point out anything else you might consider relevant.\n\n\n[1] Christos Sakaridis, Dengxin Dai, and Luc Van Gool: Semantic Foggy Scene Understanding with Synthetic Data, International Journal of Computer Vision (IJCV), 2018\n[2] Fisher Yu, Wenqi Xian, Yingying Chen, Fangchen Liu, Mike Liao, Vashisht Madhavan and Trevor Darrell: BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling, Arxiv 2018\n[3] Agrim Gupta, Piotr Doll\u00e1r and Ross Girshick: LVIS: A Dataset for Large Vocabulary Instance Segmentation, Arxiv 2019"}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "SJeK4hrwiH", "original": null, "number": 2, "cdate": 1573506097196, "ddate": null, "tcdate": 1573506097196, "tmdate": 1573507010692, "tddate": null, "forum": "ryljMpNtwr", "replyto": "r1gPC72CKH", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "Relationship between corruption robustness and adversarial robustness", "comment": "There have been several recent publications showing that robustness towards common corruptions (as studied here) and robustness towards adversarial perturbations are not related. Engstrom et al. report that increasing robustness against adversarial L_infinity attacks does not increase robustness against translations and rotations [4]. Jordan et al. show that adversarial robustness does not transfer easily between attack classes [5]. Most importantly, Laugros et al experimentally show that adversarial robustness and robustness towards common corruptions are independent [6], a finding which is corroborated by Anonymous et al. [7]. Hence, there is no strong link between corruption and adversarial robustness, and we will add a paragraph to the related work section of our paper to point future readers to this insight.\n\n\n[4] Logan Engstrom, Dimitris Tsipras, Ludwig Schmidt, Aleksander Madry: A rotation and a translation suffice: Fooling CNNs with simple transformations.\n[5] Matt Jordan, Naren Manoj, Surbhi Goel, Alexandros G Dimakis: Quantifying perceptual distortion of adversarial examples.\n[6] Alfred Laugros, Alice Caplier, Matthieu Ospici: Are Adversarial Robustness and Common Perturbation Robustness Independent Attributes? \n[7] Anonymous: When Robustness Doesn\u2019t Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet (ICLR 2020 submission)"}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "rkle3iBPir", "original": null, "number": 1, "cdate": 1573505959625, "ddate": null, "tcdate": 1573505959625, "tmdate": 1573505959625, "tddate": null, "forum": "ryljMpNtwr", "replyto": "SJgukSgYFH", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment", "content": {"title": "Clarification with respect to Geirhos et al. 2019", "comment": "Thank you for your detailed review and excellent feedback! Before addressing your suggestions please allow us to quickly clarify one important point, which we think may be based on a misunderstanding: The unclear difference to Geirhos et al. (ICLR 2019) which you describe as the key reason for your score. We definitely need to make the difference more clear, thank you for pointing this out!\n\nGeirhos et al. indeed performed object detection experiments on MS COCO and Pascal VOC, showing that stylized ImageNet data helps for detection performance on *clean* images (through a better-performing ResNet backbone).\n\nThe authors however never evaluated the detection robustness of their method (on *corrupted* images). Geirhos et al. do not show corruption robustness results on Pascal / COCO or any other detection dataset. Our proposed benchmark is to the best of our knowledge the first evaluation of detection robustness towards a large set of corruptions.\n\nFor comparison reasons, we reimplemented their models and find only marginal robustness improvements from stylized pre-training of the ResNet backbone (<3% rPC):\n\nResults on COCO:\nPre-training:           P [AP]        mPC        rPC\nIN                            31.8         15.5         48.7\nSIN                          29.8         15.3         51.3\nIN+SIN                    31.1         16.0         51.4\nIN+SIN ft IN             32.3         16.2         50.1\n\nResults on Pascal VOC:\nPre-training          P [AP50]     mPC        rPC\nIN                            78.9         45.7        57.4\nSIN                          75.1         48.2        63.6\nIN+SIN                    78.0         50.6        64.2\nIN+SIN ft IN             79.0         48.9        61.4\n(abbreviations as in Geirhos et al.)\n\nIn summary, stylized ImageNet data for training a ResNet backbone helps not only on clean data (as reported by Geirhos et al.) but also for corruption robustness, albeit less than our approach:\n\nFor comparison the results of our method on COCO:\nTraining:        P [AP]        mPC        rPC\nCOCO              36.3         18.2        50.2\nStylized            21.5         14.1        65.6\nCombined        34.6         20.4         58.9\n\nand on Pascal VOC:\nTraining:       P [AP50]     mPC        rPC\nVOC                 80.5        48.6         60.4\nStylized            68.0        50.0         73.5\nCombined        80.4        56.2         69.9\n\nWe will add this experiment to the final version of the paper and try to make the difference more clear.\n\nWe will address some more of your suggestions later on but will need some time for the experiments and wanted to quickly address this point right away.\n\nImplementation details: \nFor the reimplementation, we follow Geirhos 2019 who use a slightly different model (Faster R-CNN without FPN, 31.8% AP) which performs a bit worse than the model we used throughout our paper (Faster R-CNN with FPN, 36.3% AP).\nPlease also note that we use the standard metrics (AP for COCO and AP50 for Pascal VOC) to be consistent with the rest of our paper. In contrast, Geirhos et al. report AP50 on COCO. The 31.8% AP of our baseline translate to 52.6% AP50 which is close to the 52.3% AP50 reported in Geirhos 2019. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper424/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryljMpNtwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper424/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper424/Authors|ICLR.cc/2020/Conference/Paper424/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171684, "tmdate": 1576860543760, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper424/Authors", "ICLR.cc/2020/Conference/Paper424/Reviewers", "ICLR.cc/2020/Conference/Paper424/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Comment"}}}, {"id": "SJgukSgYFH", "original": null, "number": 1, "cdate": 1571517663699, "ddate": null, "tcdate": 1571517663699, "tmdate": 1572972596907, "tddate": null, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary:\n- key problem or question: assessing / improving the robustness of object detectors to image corruptions (simulated fog, frost, snow, dragonfire...);\n- contributions: 1) a benchmark (obtained by adding image-level corruptions to PASCAL, COCO, and Cityscapes) and an experimental protocol to measure detection robustness , 2) extensive experiments quantifying the severe lack of robustness of multiple state-of-the-art models, 3) experiments showing that data augmentation via style transfer (Geirhos et al, ICLR'19) improves robustness at little cost (at most -2% performance degradation on clean COCO images).\n\nRecommendation: Weak Reject\n\nKey reason: unclear novelty w.r.t. Geirhos et al ICLR 2019, especially due to the lack of specificity to object detection (which is the main goal of the paper).\n- Although the paper from Geirhos et al. study a specific question (texture bias in CNNs), they propose a similar experimental protocol for assessing robustness, where the only differences are i) they use different corruptions (cf. Fig.6 in their paper, vs. Figs. 5, 7, 8, 9 here), ii) they do not have Cityscapes results (but they have PASCAL and COCO results).\n- Furthermore, Geirhos et al 2019 also study the benefits of style-transfer-based data augmentation (this submission uses their technique), they report similar results and conclusions to this submission, including for object detection on PASCAL and COCO (cf. Table 2 in Geirhos et al 2019).\n- What is, in the authors' opinion, the main differentiator of this submission? Does the difference in corruptions and evaluated models combined with the addition of Cityscapes yield new insights compared to Geirhos et al 2019?\n- Beyond this similarity, what is specific to object detection vs. image classification in this submission? Besides the summary evaluation metrics, the corruptions and stylization are global (image-level) and not object-specific. Is the observed lack of robustness due to localization errors, mis-classifications, or other types of detection mistakes (cf. Hoiem et al ECCV'12)? What are the conclusions about detection robustness that differ from the image classification ones? What would be local corruptions that specifically degrade object detection performance (as studied for instance in the adversarial attack community, including physical attacks like Eykholt et al 2018)?\n\nAdditional feedback / questions:\n- The results in section 3.4 / Fig.6 seem counterintuitive: more corruption should yield more degradation (as evidenced in Fig. 5 w.r.t. corruption severity). Is RMSE the right metric? Maybe SSIM would be better (more related to perceptual quality)?\n- The aforementioned remark also raises the point that corruption difficulty night not be related to its intensity / noise level, but more with the (hard to quantify) domain gap w.r.t. clean data. For instance, if some images contain natural fog, fog corruption robustness should be naturally higher, whereas robust to never seen unrealistic dragonfire is expected to be naturally low. Can this relation between corruption and domain gap be somehow assessed? For instance using perceptual distance (using features from intermediate layers) to nearest clean neighbors? Or maybe by correlating with a subjective measure of realism of the corruption assessed globally per corruption type via a human study?\n- Are corruption degradations dataset-specific? Fig. 7,8,9 seem to show different behaviors.\n- How does the proposed benchmark compare to the Robust Vision Challenge (http://www.robustvision.net) proposed at CVPR 2018? How does robustness to corruptions and robustness across datasets correlate? Are they both similar \"out of domain\" robustness measures? How does this \"out of domain\" issue relate to adversarial examples (besides being \"less extreme\")?\n- Could Fig. 5 include error bars / variance across corruption types?\n- rPC is a good metric to compare models but I am not sure it is great to compare robustification methods, because when improving \"clean\" performance you mechanically decrease rPC, hence why combined is worse than stylized (e.g., in Table 2). What would be a better metric?\n- Why does the stylized approach on COCO yields worse mPC (cf. Table 2 and 4), whereas it is expected to improve robustness under corruption (and does on other datasets), esp. since it sacrifices performance on the clean images by a lot?\n- What is the impact of the choice of style images on robustness induced by stylization? Is diversity the most important factor (this can be tested by reducing the number of styles available)? If not, what is and how can it be measured?\n- Do certain corruption (at certain severity levels) result in unrecoverable objects? For instance, dragonfire might completely occlude certain objects on the side, which might be a problem (e.g., there are frequent parked cars on the side in Cityscapes). What is the upper bound after corruption and how can it be measured?\n- What is the human robustness for the new corruptions not present in Geirhos et al 2019? (Also relates to the aforementioned upper bound.)\n- The paper is well written and I enjoyed the multiple pop culture references to Game of Thrones."}, "signatures": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875354224, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper424/Reviewers"], "noninvitees": [], "tcdate": 1570237752339, "tmdate": 1575875354235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Review"}}}, {"id": "Bkldg_0KKH", "original": null, "number": 2, "cdate": 1571575791948, "ddate": null, "tcdate": 1571575791948, "tmdate": 1572972596872, "tddate": null, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper introduces a  benchmark to assess the performance of object detection models when image quality degrades. Three variants of detection datasets, termed PASCAL-C, COCO-C and Cityscapes-C, are introduced that contain a large variety of image corruptions. The paper shows that standard object detection models suffer a severe performance loss on corrupted images (down to 30\u201360% of the original performance). Further, this work shows that a simple data augmentation trick of stylizing the training images leads to a substantial increase in robustness across corruption type, severity and dataset.\n\nThe paper is well written and easy to follow. The proposed benchmark is interesting and clearly show the deficiencies of state-of-the-art object detection methods in case of image corruptions or weather conditions. However, my main concern is the novelty in that the proposed approach is just an extension of [1]. [1] introduced corrupted versions of commonly used classification datasets (ImageNet-C, CIFAR10-C) as standardized benchmarks. The different types of corruptions used here for object detection and their sorting into four groups were also introduced originally in [1]. Moreover, the idea to use style transfer as an augmentation to  improve corruption robustness for image classification has been introduced in [2]. Therefore, the only contribution of this paper is to apply the ideas from [1, 2] for object detection. \n\n[1] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In ICLR, 2019.\n[2] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, and Wieland Brendel. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. In ICLR, 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875354224, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper424/Reviewers"], "noninvitees": [], "tcdate": 1570237752339, "tmdate": 1575875354235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Review"}}}, {"id": "r1gPC72CKH", "original": null, "number": 3, "cdate": 1571894222745, "ddate": null, "tcdate": 1571894222745, "tmdate": 1572972596838, "tddate": null, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "invitation": "ICLR.cc/2020/Conference/Paper424/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a benchmark for measuring robustness to input image corruption in object detection settings. The paper proposes a benchmark for this task, and proposes a simple data augmentation technique for this task.\n\nStrengths\n1. Understanding the robustness properties of existing vision models is an important problem.\n2. The paper establishes a sensible protocol for the benchmark, where methods are tested upon image perturbations that are not used for training the model.\n3. I like the proposed simple data augmentation procedure and the experimental finding that data augmentation with such a procedure leads to models that are robust to held-out, previously unseen perturbations.\n\nShortcomings:\n1. While the paper proposes a sensible experimental protocol, certain questions remain:\na) Are the set of test time perturbations exhaustive and representative of the perturbations in the real world? The paper doesn't talk about this, or provides any experimental data to establish this. The paper derives them from an earlier paper called \"Benchmarking neural network robustness to common corruptions and perturbations\", and thus I am not even sure if the proposed set of perturbations should be viewed as a contribution of the current paper.\nb) While the paper itself follows good practice by not training on perturbations that are considered at test time, unfortunately, it does not define a clear protocol or characterization as to how future researchers should use the benchmark. I believe setting up such a protocol is going to be difficult and is worthy of more thought and consideration, absence of this weakens the paper, as it leaves the door open for flawed future research.\n\n2. Missing comparisons: Proposed method is interesting, but I wonder if there were a more standard evaluation to test the efficiency of the method, perhaps something like testing if representations learned using such data augmentations were more robust to adversarial perturbations? Or perhaps, comparison against other methods that exist in literature for related tasks, such as methods that study how to make networks robust to adversarial perturbations?\n\nBecause of the aforementioned reasons, I don't view the benchmarking part of the paper as a solid contribution. Similarly, the proposed method is simple and intuitive (which is good), but it will help if there were more comparisons to set the paper in context of related work."}, "signatures": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper424/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming", "authors": ["Claudio Michaelis", "Benjamin Mitzkus", "Robert Geirhos", "Evgenia Rusak", "Oliver Bringmann", "Alexander S. Ecker", "Matthias Bethge", "Wieland Brendel"], "authorids": ["claudio.michaelis@uni-tuebingen.de", "benjamin.mitzkus@uni-tuebingen.de", "robert@geirhos.de", "evgenia.rusak@bethgelab.org", "oliver.bringmann@uni-tuebingen.de", "alexander.ecker@uni-tuebingen.de", "matthias@bethgelab.org", "wieland.brendel@bethgelab.org"], "keywords": ["deep learning", "object detection", "robustness", "neural networks", "data augmentation", "autonomous driving"], "TL;DR": "A benchmark to asses the robustness of object detection models towards common image corruptions. Like classification models, object detection models perform worse on corrupted images. Training with stylized data reduces the gap for all corruptions.", "abstract": "The ability to detect objects regardless of image distortions or weather conditions is crucial for real-world applications of deep learning like autonomous driving. We here provide an easy-to-use benchmark to assess how object detection models perform when image quality degrades. The three resulting benchmark datasets, termed PASCAL-C, COCO-C and Cityscapes-C, contain a large variety of image corruptions. We show that a range of standard object detection models suffer a severe performance loss on corrupted images (down to 30-60% of the original performance). However, a simple data augmentation trick - stylizing the training images - leads to a substantial increase in robustness across corruption type, severity and dataset. We envision our comprehensive benchmark to track future progress towards building robust object detection models. Benchmark, code and data are available at: (hidden for double blind review)", "pdf": "/pdf/b9a472db882a5c76b0fcddc5dfc073b3a146d87a.pdf", "paperhash": "michaelis|benchmarking_robustness_in_object_detection_autonomous_driving_when_winter_is_coming", "original_pdf": "/attachment/f37f8dbd8833cf0dd75fb73d46141facfb24a52c.pdf", "_bibtex": "@misc{\nmichaelis2020benchmarking,\ntitle={Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming},\nauthor={Claudio Michaelis and Benjamin Mitzkus and Robert Geirhos and Evgenia Rusak and Oliver Bringmann and Alexander S. Ecker and Matthias Bethge and Wieland Brendel},\nyear={2020},\nurl={https://openreview.net/forum?id=ryljMpNtwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryljMpNtwr", "replyto": "ryljMpNtwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875354224, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper424/Reviewers"], "noninvitees": [], "tcdate": 1570237752339, "tmdate": 1575875354235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper424/-/Official_Review"}}}], "count": 11}