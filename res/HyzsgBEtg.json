{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028583101, "tcdate": 1490028583101, "number": 1, "id": "SJ14OYTol", "invitation": "ICLR.cc/2017/workshop/-/paper74/acceptance", "forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028583667, "id": "ICLR.cc/2017/workshop/-/paper74/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028583667}}}, {"tddate": null, "tmdate": 1489565921362, "tcdate": 1489565921362, "number": 2, "id": "SJt1FuIox", "invitation": "ICLR.cc/2017/workshop/-/paper74/public/comment", "forum": "HyzsgBEtg", "replyto": "r1yGGiHje", "signatures": ["~Chris_Donahue1"], "readers": ["everyone"], "writers": ["~Chris_Donahue1"], "content": {"title": "No Title", "comment": "Dear reviewer, \n\nThank you for the thoughtful review. We omitted some of these details to accommodate the extended abstract length. \n\nAn unconditioned LSTM64 model trained on non-augmented Fraxtil data achieved a perplexity of 3.53 while the same unconditioned LSTM64 model trained on augmented data achieved a perplexity of 3.35. These scores are significantly worse than the 3.01 perplexity achieved by the beat-conditioned LSTM64 model trained on augmented data.\n\nWe believe the performance gap (on step selection) between the two datasets can be attributed to the fact that Fraxtil is a single-author dataset while ITG contains annotations from 9 choreographers. Author style tends to be distinctive and thus the single-author sequences are more predictable.\n\nWe have updated the workshop draft to address these points. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487323290955, "tcdate": 1487323290955, "id": "ICLR.cc/2017/workshop/-/paper74/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper74/reviewers"], "reply": {"forum": "HyzsgBEtg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487323290955}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1489565852528, "tcdate": 1487323290260, "number": 74, "id": "HyzsgBEtg", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HyzsgBEtg", "signatures": ["~Chris_Donahue1"], "readers": ["everyone"], "content": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489563830080, "tcdate": 1489563830080, "number": 1, "id": "H1R3xdUsx", "invitation": "ICLR.cc/2017/workshop/-/paper74/public/comment", "forum": "HyzsgBEtg", "replyto": "HypXbJZoe", "signatures": ["~Chris_Donahue1"], "readers": ["everyone"], "writers": ["~Chris_Donahue1"], "content": {"title": "No Title", "comment": "Dear reviewer,\n\nThanks for your thoughtful comments. A full-length version (forthcoming) contains many of these details, some of which we had to omit here for brevity. Some specific replies and clarifications follow.\n\nBeat phase is a one-hot encoding over the four possible 1/16th note subdivisions. We can calculate this information programmatically because charts in our corpus contain metronomic markings. \n\nThe step selection model runs over steps (chosen by step placement algorithm), not over evenly spaced intervals. The delta time features encode the duration since the last step and until the next step, both of which the step-selection LSTM cannot infer by itself.\n\nAs with many metrics, AUC is good primarily as a relative measure of performance. Note that for this problem, the \u201cground truth\u201d step placements depend on the individual choreographer and the choices they made on that particular chart. \n\nEven if the same choreographer wrote a second step chart for the same song, the chosen step placements would not overlap completely with the previous choices. We stress that in this case there is a ceiling on the highest possible AUC and that this metric should only be interpreted relatively to compare models. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487323290955, "tcdate": 1487323290955, "id": "ICLR.cc/2017/workshop/-/paper74/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper74/reviewers"], "reply": {"forum": "HyzsgBEtg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487323290955}}}, {"tddate": null, "tmdate": 1489510919425, "tcdate": 1489510919425, "number": 2, "id": "r1yGGiHje", "invitation": "ICLR.cc/2017/workshop/-/paper74/official/review", "forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "signatures": ["ICLR.cc/2017/workshop/paper74/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper74/AnonReviewer2"], "content": {"title": "an interesting application and a work in progress", "rating": "6: Marginally above acceptance threshold", "review": "This is an interesting application of DL in rhythm-based video games that learns two sub-tasks: step placement from raw audio, and step selection from ground truth placement. This seems to be a work in progress, as it doesn't address the complete end-to-end problem yet. \n\nSome key information is missing in the paper. For example, the authors observed that data augmentation and inclusion of manual features (beta phase etc) significantly improved the performance but there is no comparison results given. Have the authors tried to learn such manual features from data?\n\nAlso there is a clear performance gap between Fraxtill and ITG, particularly on the step selection task under the best model LSTM64. Also,  there is little difference between LSTM5 and LSTM64 on ITG while the improvement is more clear on Fraxtill. What are the reasons behind these observations? ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489510920291, "id": "ICLR.cc/2017/workshop/-/paper74/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper74/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper74/AnonReviewer1", "ICLR.cc/2017/workshop/paper74/AnonReviewer2"], "reply": {"forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper74/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper74/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489510920291}}}, {"tddate": null, "tmdate": 1489199396993, "tcdate": 1489199396993, "number": 1, "id": "HypXbJZoe", "invitation": "ICLR.cc/2017/workshop/-/paper74/official/review", "forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "signatures": ["ICLR.cc/2017/workshop/paper74/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper74/AnonReviewer1"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "The paper proposes a system to generate \"step charts\" for the game Dance Dance Revolution (DDR) from audio signals. The system constists of two neural networks: one to determine where to place the steps in time, and one to select the type of the steps (up / down / left / right).\n\nWhile the application is quite unusual, the paper is clear and the design choices for the system are well motivated. The evaluation is also quite solid, with several baselines provided.\n\nA few questions and comments:\n- For the step selection, the LSTM is conditioned on beat phase. How is beat phase determined? As far as I can tell this is not described anywhere.\n\n- Why does adding time delta features help when using LSTM? Shouldn't it be able to derive those by itself?\n\n- The AUC scores reported in table 1 are actually pretty low across the board. I suppose this is somewhat expected but it would be good to briefly discuss it.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dance Dance Convolution", "abstract": "Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players perform steps on a dance platform in synchronization with music as directed by on-screen step charts. While many step charts are available in standardized packs, users may grow tired of existing charts, or wish to dance to a song for which no chart exists. We introduce the task of learning to choreograph. Given a raw audio track, the goal is to produce a new step chart. This task decomposes naturally into two subtasks:  deciding when to place steps and deciding which steps to select. We demonstrate deep learning solutions for both tasks and establish strong benchmarks for future work.", "pdf": "/pdf/abca719c61cf87c407aa4b3e119f350f65d9a278.pdf", "TL;DR": "Introduces the task of automating Dance Dance Revolution choreography; offers a standardized dataset for investigation and a slew of deep learning baselines", "paperhash": "donahue|dance_dance_convolution", "keywords": ["Deep learning", "Supervised Learning", "Applications", "Games"], "conflicts": ["ucsd.edu", "cs.ucsd.edu"], "authors": ["Chris Donahue", "Zachary C. Lipton", "Julian McAuley"], "authorids": ["cdonahue@ucsd.edu", "zlipton@cs.ucsd.edu", "jmcauley@cs.ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489510920291, "id": "ICLR.cc/2017/workshop/-/paper74/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper74/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper74/AnonReviewer1", "ICLR.cc/2017/workshop/paper74/AnonReviewer2"], "reply": {"forum": "HyzsgBEtg", "replyto": "HyzsgBEtg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper74/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper74/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489510920291}}}], "count": 6}