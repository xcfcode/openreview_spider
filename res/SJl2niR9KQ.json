{"notes": [{"id": "SJl2niR9KQ", "original": "HJxED7A_YQ", "number": 747, "cdate": 1538087859915, "ddate": null, "tcdate": 1538087859915, "tmdate": 1549252335192, "tddate": null, "forum": "SJl2niR9KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJlterMflE", "original": null, "number": 1, "cdate": 1544852720869, "ddate": null, "tcdate": 1544852720869, "tmdate": 1545354532550, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Meta_Review", "content": {"metareview": "The paper describes the use of differentiable physics based rendering schemes to generate adversarial perturbations that are constrained by physics of image formation.\n\nThe paper puts forth a fairly novel approach to tackle an interesting question. However, some of the claims made regarding the \"believability\" of the adversarial examples produced by existing techniques are not fully supported. Also, the adversarial examples produced by the proposed techniques are not fully \"physical\" at least compared to how \"physical\" adversarial examples presented in some of the prior work were.\n\nOverall though this paper constitutes a valuable contribution. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "An interesting contribution, although some concerns regarding the claims"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper747/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353101243, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353101243}}}, {"id": "HJxMD1N20Q", "original": null, "number": 10, "cdate": 1543417689950, "ddate": null, "tcdate": 1543417689950, "tmdate": 1543417689950, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "S1eSUQsK0X", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Re: Concerns with \"believability\" and other claims", "comment": "Indeed, current pixel-based attacks can fool classifiers with imperceivable perturbations. The magnitude of a perturbation is not the only factor that determines how realistic or plausible it is to occur in the real world. Figure 1 demonstrates, reductio ad absurdum, that very large pixel perturbations can be realistic if the perturbation is conducted in the physical parameter space (e.g., lighting). We have provided visualization of small perturbations in Figure 12. Specifically, Figure 12 shows perturbations with the same \\ell_\\infty norm across columns and magnifies the perturbations at each row differently for visualization purposes. However, the structure of imperceivable perturbation may still not correspond to any real-world scenario.\n\nOur claimed contribution is to construct adversarial examples through perturbing physical parameters of the image formation model. We leave physical world geometry attacks to future work as it involves a non-trivial computational fabrication engineering aspect.\n\nThanks, we've corrected the reference\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "S1eSUQsK0X", "original": null, "number": 1, "cdate": 1543250764988, "ddate": null, "tcdate": 1543250764988, "tmdate": 1543250764988, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Public_Comment", "content": {"comment": "The adversarial examples created here with the differentiable renderer are certainly cool. However I have some concerns with the claimed contributions. \n\nFirst, a key claimed contribution is that of believability. To test this, the authors set a given \\ell_\\infty \\epsilon threat model, and generate adversarial examples with each method. This is a flawed experiment: by fixing a threat model, the compared against methods will use the entire allowed perturbation bound to create adversarial examples. All methods are minor variations of Projected Gradient Descent, which will, by the nature of the underlying algorithm, use the whole allowed perturbation budget (i.e. will produce perturbations that extend to the edges of the allowed \\ell_\\infty box). Therefore the experiment in Figure 1 shows nothing about the \"believability\" of perturbations produced with the various methods (the spaceship here could likely be misclassified with an imperceptible \\ell_\\infty norm perturbation generated with PGD).\n\nThe authors also claim that their method extends to create physical world adversarial examples, but only show this with adversarial lighting (not color, geometry, or any of the other parameters listed in Table 1) on a single example (oranges) in front of a single, uniformly black, backdrop, at a single angle.\n\nAlso, the citation for Athalye et al (listed as Athalye and Sutskever) is wrong; it should be:\n\n@misc{athalye2017synthesizing,\n    title={Synthesizing Robust Adversarial Examples},\n    author={Anish Athalye and Logan Engstrom and Andrew Ilyas and Kevin Kwok},\n    year={2017},\n    eprint={1707.07397},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}", "title": "Concerns with \"believability\" and other claims"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311761987, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SJl2niR9KQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311761987}}}, {"id": "BygeiOOKA7", "original": null, "number": 9, "cdate": 1543239832497, "ddate": null, "tcdate": 1543239832497, "tmdate": 1543239832497, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "H1gc6aNcaQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Reviewer 3 comments", "comment": "Thank you for the rebuttal. I think my initial rating is still relevant even after the revisions of the authors."}, "signatures": ["ICLR.cc/2019/Conference/Paper747/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "rkl80bNdCX", "original": null, "number": 8, "cdate": 1543156174156, "ddate": null, "tcdate": 1543156174156, "tmdate": 1543156174156, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SklLzoVcaX", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Thanks for the replies", "comment": "We changed the color of the updated text from green back to black as tomorrow is the end of the revision period. Thank you for all the replies."}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "Hylylvwcn7", "original": null, "number": 2, "cdate": 1541203686942, "ddate": null, "tcdate": 1541203686942, "tmdate": 1542584956370, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "content": {"title": "Good paper, but please address questions ", "review": "The paper demonstrates a method for constructing adversarial examples by modifications or perturbations to physical parameters in the scene itself---specifically scene lighting and object geometry---such that images taken of that scene are able to fool a classifier. It achieves this through a novel differentiable rendering engine, which allows the proposed method to back-propagate gradients to the desired physical parameters. Also interesting in the paper is the use of spherical harmonics, which restrict the algorithm to plausible lighting. The method is computationally efficient and appears to work well, generating plausible scenes that fool a classifier when imaged from different viewpoints.\n\nOverall, I have a positive view of the paper. However, there are certain issues below that the authors should address in the rebuttal for me to remain with my score of accept (especially the first one):\n\n\n- The paper has no discussion of or comparisons to the work of Athalye and Sutskever, 2017 and Zeng et al., 2017, except for a brief mention in Sec 2 that these methods also use differentiable renderers for adversarial attacks. These works address the same problem as this paper---computing physically plausible adversarial attacks---and by very similar means---back-propagation through a rendering engine. Therefore it is critical that the paper clarifies its novelty over these methods, and if appropriate, include comparisons.\n\n- While the goal of finding physically plausible adversarial examples is indeed important, I disagree with the claim that image-level attacks are \"primarily tools of basic research, and not models of real-world security scenarios\". In many applications, an attacker may have access to and be able to modify images after they've been captured and prior to sending them through a classifier (e.g., those attempting to detect transmission of spam or sensitive images). I believe the paper can make its case about the importance of physical adversarial perturbations without dismissing image-level perturbations as entirely impractical.\n\n- The Athalye 18 reference noted in Fig 1 is missing (the references section includes the reference to Athalye and Sutskever '17).\n\n===Post-rebuttal\n\nThanks for addressing my questions. With the new comparisons and discussions wrt the most relevant methods, I believe the contributions of the paper are clearer. I'm revising my score from 6 to 7.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "cdate": 1542234385495, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335794173, "tmdate": 1552335794173, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1gc6aNcaQ", "original": null, "number": 5, "cdate": 1542241729932, "ddate": null, "tcdate": 1542241729932, "tmdate": 1542241848253, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "HyekoBIv37", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Authors' Reply", "comment": "\n# Comparisons with state-of-the-art\nWe include direct comparisons to state-of-the-art differentiable renderers in Section 2 and Section 3.1. These clearly demonstrate our superiority with respect to speed and memory.\n\nConducting direct comparisons to state-of-the-art adversarial attacks is less well-posed. In the revision, we have expanded our feature comparison with a new table in Section 2. See further discussion in the Revision Summary post above.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "S1xI5a4cTQ", "original": null, "number": 4, "cdate": 1542241677541, "ddate": null, "tcdate": 1542241677541, "tmdate": 1542241835471, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "Hylylvwcn7", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Authors' Reply", "comment": "\n# Comparisons\nSee the Revision Summary post regarding a new comparison table.\n\n# Image-level perturbations\nWe have toned down our statements in the introduction.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "ryeo7aN56X", "original": null, "number": 3, "cdate": 1542241571003, "ddate": null, "tcdate": 1542241571003, "tmdate": 1542241822741, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "B1lBHma23X", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Authors' Reply", "comment": "\n# Simulation for performance enhancement\nWe thank the reviewer for pointing out related papers on this topic. They led us to many papers that demonstrate that models trained on synthetic data can outperform those trained on real data alone for real-world tasks. These references further strengthen our case for moving beyond the pixel-ball norms (Section 2, 5, and 6; highlighted in green).\n\n# Adversarial training\nOur paper focuses on how to create adversarial attacks beyond the pixel norm-ball using physical parameters via a novel differentiable renderer. In the revision, we have improved the description of our preliminary application of this insight to adversarial training (a replicable description is now provided in Appendix F). A more exhaustive study of adversarial training is left as future work (additional discussion in Section 6)."}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "SklLzoVcaX", "original": null, "number": 1, "cdate": 1542241037974, "ddate": null, "tcdate": 1542241037974, "tmdate": 1542241037974, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "content": {"title": "Revision Summary", "comment": "Thank you for your helpful comments and enthusiasm. In the revised document, we highlight all the changes in the green text. Our major changes are:\n# Add references that use simulation to enhance network performance on real-world tasks (Section 2)\n# Add detail of the adversarial training (Appendix F)\n# Add future extension for the adversarial training (Section 6)\n# Add a table comparison with previous non-image based adversarial attacks (Section 2)\n# Tone down the argument on image-based adversarial attacks (Section 1)\n# Typographical and reference issues\n\n# Comparison Feature Table (R1, R3)\nWe have included a new feature comparison table in Section 2 highlighted in green. This table shows that while [Athalye 2017] generates adversarial colors on the surface geometry, that method cannot compute adversarial examples by perturbing the physical parameters we are focusing on (lighting and geometry). Therefore, our methods are complementary. \nMeanwhile, [Zeng 2017] requires a non-trivial training phase to learn a proxy renderer. This training requires a substantial amount of data. Further, this data should be representative of scenes that will be witnessed at runtime, otherwise training-bias will occur. Even assuming high-quality training, the method of [Zeng 2017]  still takes orders of magnitude longer to compute adversarial examples (12 minutes reported in [Zeng 2017] versus a few seconds using our method).\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621610348, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2niR9KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper747/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper747/Authors|ICLR.cc/2019/Conference/Paper747/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers", "ICLR.cc/2019/Conference/Paper747/Authors", "ICLR.cc/2019/Conference/Paper747/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621610348}}}, {"id": "B1lBHma23X", "original": null, "number": 3, "cdate": 1541358397244, "ddate": null, "tcdate": 1541358397244, "tmdate": 1541533721725, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "content": {"title": "The paper describes the use of differentiable physics based rendering schemes to generate adversarial perturbations that are constrained by physics of image formation. The paper demonstrates how data augmentation using the scheme can improve robustness of classifiers in a limited experimental setting. ", "review": "Quality of the paper:  The paper is quite clear on the background literature on adversarial examples, physics based rendering, and the core idea of generating adversarial perturbations as a function of illumination and geometric changes.   \nOriginality and Significance: The idea of using differential renderers to produce physically consistent adversarial perturbations is novel. \nReferences: The references in the paper given its scope is fine.  It is recommended to  explore references to other recent papers that use simulation for performance enhancement in the context of transfer learning, performance characterization (e.g. veerasavarappu et al in arxiv, WACV, CVPR (2015 - 17)) \n\nPros:  Good paper , illustrates the utility of differentiable rendering and simulations to generate adversarial examples and to use them for improving robustness.\nCons: The experimental section needs to be extended and the results are limited to simulations on CIFAR-100 and evaluation on lab experimental data.  Inclusion of images showing CIFAR-100 images augmented with random lighting, adversarial lighting would have been good. The details of the image generation process for that experiment is vague and not reproducible. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "cdate": 1542234385495, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335794173, "tmdate": 1552335794173, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyekoBIv37", "original": null, "number": 1, "cdate": 1541002647085, "ddate": null, "tcdate": 1541002647085, "tmdate": 1541533721320, "tddate": null, "forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "content": {"title": "Interesting idea but lacks comparison with state of the art", "review": "Summary:\nThis work presents a method to generate adversary examples capable of fooling a neural network classifier. Szegedy et al. (2013) were the first to expose the weakness of neural networks against adversarial attacks, by adding a human-imperceptible noise to images to induce misclassification. Since then, several works tackled this problem by modifying the image directly in the pixel space: the norm-balls convention. The authors argue that this leads to non-realistic attacks and that a network would not benefit from training with these adversarial images when performing in the real world. Their solution and contributions are parametric norm-balls: unlike state-of-the-art methods, they perform perturbations in the image formation space, namely the geometry and the lighting, which are indeed perturbations that could happen in real life. For that, they defined a differentiable renderer by making some assumptions to simplify its expression compared to solving a light transport equation. The main simplifications are the direct illumination to gain computation efficiency and the distant illumination and diffuse material assumptions to represent lighting in terms of spherical harmonics as in Ramamoorthi et al. (2001), which require only 9 parameters to approximate lighting. This allows them to analytically derivate their loss function according to the geometry and lighting and therefore generate their adversary examples via gradient descent. They show that their adversary images generalize to other classifiers than the one used (ResNet). They then show that injecting these images into the training set increase the robustness of WideResNet against real attacks. These real attack images were taken by the authors in a laboratory with varying illumination.\n\nStrength:\n- The proposed perturbations in the image formation space simulate the real life scenario attacks.\n- The presented results show that the generated adversary images do fool the classifier (used to compute the loss) but also new classifiers (different than the one used to compute the loss). As a consequence the generated adversary images increase the robustness of the considered classifier. \n- Flexibility in their cost function allows for diverse types of attacks: the same modified geometry can fool a classifier in several views, either into detecting the same object or detecting different false objects under different views. \n\nMajor comments:\n- Method can only compute synthetic adversary examples, unlike state-of-the-art.\n- The main contribution claimed by the author is that their perturbations are realistic and that it would help better increase the robustness of classifiers against real attacks. However, they do not give any comparison to the state-of-the-art methods as is expected. \n\nMinor comments:\n- Even if the paper is well written, they are still some typos. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper747/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer", "abstract": "Many machine learning image classifiers are vulnerable to adversarial attacks, inputs with perturbations designed to intentionally trigger misclassification. Current adversarial methods directly alter pixel colors and evaluate against pixel norm-balls: pixel perturbations smaller than a specified magnitude, according to a measurement norm. This evaluation, however, has limited practical utility since perturbations in the pixel space do not correspond to underlying real-world phenomena of image formation that lead to them and has no security motivation attached. Pixels in natural images are measurements of light that has interacted with the geometry of a physical scene. As such, we propose a novel evaluation measure, parametric norm-balls, by directly perturbing physical parameters that underly image formation. One enabling contribution we present is a physically-based differentiable renderer that allows us to propagate pixel gradients to the parametric space of lighting and geometry. Our approach enables physically-based adversarial attacks, and our differentiable renderer leverages models from the interactive rendering literature to balance the performance and accuracy trade-offs necessary for a memory-efficient and scalable adversarial data augmentation workflow.", "keywords": ["adversarial examples", "norm-balls", "differentiable renderer"], "authorids": ["hsuehtil@cs.toronto.edu", "mtao@dgp.toronto.edu", "chunlial@cs.cmu.edu", "derek@cim.mcgill.ca", "jacobson@cs.toronto.edu"], "authors": ["Hsueh-Ti Derek Liu", "Michael Tao", "Chun-Liang Li", "Derek Nowrouzezahrai", "Alec Jacobson"], "TL;DR": "Enabled by a novel differentiable renderer, we propose a new metric that has real-world implications for evaluating adversarial machine learning algorithms, resolving the lack of realism of the existing metric based on pixel norms.", "pdf": "/pdf/028ad7abd781d3e1afab67b9fbbb6f6b8645839f.pdf", "paperhash": "liu|beyond_pixel_normballs_parametric_adversaries_using_an_analytically_differentiable_renderer", "_bibtex": "@inproceedings{\nliu2018beyond,\ntitle={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},\nauthor={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2niR9KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper747/Official_Review", "cdate": 1542234385495, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2niR9KQ", "replyto": "SJl2niR9KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper747/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335794173, "tmdate": 1552335794173, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper747/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 13}