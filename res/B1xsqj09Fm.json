{"notes": [{"id": "B1xsqj09Fm", "original": "Byl3-zn5Km", "number": 563, "cdate": 1538087826975, "ddate": null, "tcdate": 1538087826975, "tmdate": 1551127976153, "tddate": null, "forum": "B1xsqj09Fm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 26, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HklDpwqgVV", "original": null, "number": 11, "cdate": 1548949438962, "ddate": null, "tcdate": 1548949438962, "tmdate": 1548949438962, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rJlFIzT0YX", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Hi, I have a follow-up question regarding condition Batchnorm. What are the values of the embedding_dimension used for G with different resolutions? I could not find this information in the paper. Thanks.", "title": "embedding_dimension"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "rJxWKGUFyV", "original": null, "number": 1, "cdate": 1544278648655, "ddate": null, "tcdate": 1544278648655, "tmdate": 1545354496693, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Meta_Review", "content": {"metareview": "The paper proposes a set of tricks leading to a new SOTA for sampling high resolution images. It is clearly written and the presented contribution will be of high interest for practitioners.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Oral)", "title": "New SOTA for image sampling"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper563/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353172046, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353172046}}}, {"id": "SJl68_Hx37", "original": null, "number": 1, "cdate": 1540540501242, "ddate": null, "tcdate": 1540540501242, "tmdate": 1543225578478, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "content": {"title": "Great progress achievement in the field of image generation", "review": "This paper present extensions of the Self-Attention Generative Adversarial Network approach SAGAN, leading to impressive images generations conditioned on imagenet classes. \nThe key components of the approach are :\n- increasing the batch size by a factor 8\n- augmenting the width of the networks by 50% \nThese first two elements result in an Inception score (IS) boost from 52 to 93.  \n- the use of shared embeddings for the class conditioned batch norm layers, orthonormal regularization and hierarchical latent space bring an additional boost of IS 99.\nThe core novel element of the paper is the truncation trick: At train time, the input z is sampled from a normal distribution but at test time, a truncated normal distribution is used: when the magnitude of elements of z are above a certain threshold, they are re-sampled.\nVariations of this threshold lead to variations in FD and IS, as shown in insightful experiments. The comments that more data helps (internal dataset experiments) is also informative. \nVery nice to have included negative results and detailed parameter sweeps.\n\nThis is a very nice work with impressive results, a great progress achievement in the field of image generation. \nVery well written.\n\nSuggestions/questions: \n- it would be nice to also propose unconditioned experiments. \nIt would be good to give an idea in the text of TPU-GPU equivalence in terms of feasibility of a standard GPU implementation - computation time it would involve. \n- I understand that no data augmentation was used during training?    \n- clarification of the truncation trick: if the elements of z are re-sampled and are still above the threshold, are they re-sampled again and again until they are all below the given threshold?\n- A sentence could be added to explain the truncation trick in the abstract directly since it is simple to understand and is key to the quality of the results.\n- A reference to Appendix C could be given at the beginning of the Experiments section to help the reader find these details more easily.\n- It would be nice to display more Nearest neighbors for the dog image.\n- It would be nice to add a figure of random generations.\n- make the bib uniform: remove unnecessary doi - url - cvpr page numbers\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "cdate": 1542234432842, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335752748, "tmdate": 1552335752748, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkgkCbBm0Q", "original": null, "number": 11, "cdate": 1542832582844, "ddate": null, "tcdate": 1542832582844, "tmdate": 1542832582844, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "SJl68_Hx37", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We would like to thank Reviewer 3 for the review and constructive suggestions. Our responses inline:\n\n>it would be nice to also propose unconditioned experiments. \n-We agree; this was simply not within the scope of the work we conducted.\n\n>I understand that no data augmentation was used during training?  \n-This is correct, and consistent with previous works (Spectral Normalization and WGAN-GP). We briefly experimented with data augmentation (random crops and horizontal flips) but did not notice any measurable performance difference.\n  \n>clarification of the truncation trick: if the elements of z are re-sampled and are still above the threshold, are they re-sampled again and again until they are all below the given threshold?\n-Yes, this can effectively be seen as modifying the PDF of z to have no mass outside of the truncation threshold. TensorFlow offers a built-in implementation with tf.random.truncated_normal.\n\n>A sentence could be added to explain the truncation trick in the abstract directly since it is simple to understand and is key to the quality of the results.\n-We have revised the abstract to explain the truncation trick as controlling the tradeoff between fidelity and diversity by reducing the variance of the Generator\u2019s input.\n\n>A reference to Appendix C could be given at the beginning of the Experiments section to help the reader find these details more easily.\n-Thanks for the pointer! We have added this reference.\n\n>It would be nice to add a figure of random generations.\n-In the caption of Figure 5, we include a link to an anonymous drive folder with sample sheets at different resolutions and truncation values, with 12 random images per class.\n\n>make the bib uniform: remove unnecessary doi - url - cvpr page numbers\n-Thanks, we have fixed this."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "Syxd9-HXAQ", "original": null, "number": 10, "cdate": 1542832528512, "ddate": null, "tcdate": 1542832528512, "tmdate": 1542832528512, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "r1gI_-SQAm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Reviewer 2 (Part 2/2)", "comment": "> In Section 3.1 : \u201cAcross runs in Table 1, we observe that without Orthogonal Regularization, only 16% of models are amenable to truncation compared to 60% with Orthogonal Regularization.\u201d For me, this is not particularly clear. Is this something the reader should understand from Table 1?\n-This means that of all the models we trained for the study presented in Table 1 which did not use Orthogonal Regularization, only 16% were amenable to truncation. Of all the models which we trained for the study presented in Table 2 which did use Orthogonal Regularization, 60% were amenable to truncation. This is not reflected in Table 1, which is merely a presentation of how the introduced modifications impact performance.\n\n>I question the choice of sections chosen to be in the main paper/appendices. I greatly appreciated the negative results reported in the main text as well as in the appendices and this has significant value. However, as this is to me mostly a detailed empirical investigation and presentation of high-performance GANs on large scales, I would be likely to share this with colleagues who want to tackle similar problems. In this case, if future readers limit themselves to the main text, I think it can have more value to present some content form Appendix B and C than to have more than a full page on stability investigations and attempted tricks that turned out not to be used to reach maximal performance. However I do not want to discourage publishing of negative results, and I definitely wish to see this investigation in the paper, but I merely question the positioning of such information. With regard to my first negative point above about the lack of discussions, it seems the analysis of Section 4 is disproportionate compared to other places.\n-We appreciate this suggestion. While we recognize that this paper generally has a strong focus on implementation details, we felt that this instability was one of the most salient behaviors we observed, and that future work would be best served by presenting our investigations and attempts to understand its source, even if these methods did not improve performance.  The information in Appendix B and C is intended to be of interest to those who want to reproduce our experiments, so it largely comprises hyperparameters and architectural details that we felt were not necessary to understand the main results of the paper. \n\n>In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says \u201closses\u201d.\n-Thanks! This was indeed an error, which we\u2019ve corrected in the updated draft.\n\n>I would also be curious to see the proposed techniques applied on simpler datasets. Can this be useful for someone having less compute power and working on something similar to CelebA? \n-The goal of this work is to explore GANs at large scale; the exploration of small or medium scale models would indeed be interesting for another study. Having said that, we do evaluate BigGAN on conditional CIFAR-10 (mentioned briefly in Appendix C.2) and obtain an IS of 9.22 and an FID of 14.73 without truncation, which to our knowledge are better than any published results."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "r1gI_-SQAm", "original": null, "number": 9, "cdate": 1542832494327, "ddate": null, "tcdate": 1542832494327, "tmdate": 1542832494327, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "S1gaWerP2X", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Reviewer 2 (Part 1/2)", "comment": "We would like to thank Reviewer 2 for their review and constructive suggestions. Our responses inline:\n\n>Discussions sometimes lack depth or are absent.\n-We have added an additional section (Appendix G) expanding on our discussion and providing additional insight into the observed instabilities.\n\n>For example, it is unclear to me why some larger models are not amenable to truncation. Besides visible artifacts, what does it mean? Why does a smoother G reduces those artifacts?\n-Truncation introduces a train-test disparity in G\u2019s inputs--at sampling time, G is given a distribution it has effectively never seen in training. The observation that imposing orthogonality constraints improves amenability to truncation is empirical. Our suspicion is that if G is not encouraged to be \u201csmooth\u201d in some sense, then it is likely that G will only properly generate images given points from the untruncated distribution. We hypothesize that models which are not amenable end up learning mappings which, when given truncated noise, either attenuate or amplify certain activation pathways, leading to extreme output values (hence the observed saturation artifacts). We speculate that encouraging G\u2019s filters to have minimum pairwise cosine similarity means that, when exposed to distribution shift, the network\u2019s features are less correlated and less likely to align and amplify an activation path it would otherwise have learned to scale properly. \n \n\n>Were samples from those networks better without using truncation? Why would this be?\n-Samples from those networks without truncation do not have measurably different quality, and their training metrics (losses, singular values) show no differences. Aside from empirically testing each network individually for amenability to truncation, we found no other way to check for that amenability.\n\n> Authors report how wider networks perform best, and how deeper networks degrade performance. Again, discussions are lacking, and it doesn\u2019t seem the authors tried to understand why such behaviors were shown. Even though this is mostly an empirical investigation, I think some more efforts should be put in understanding and explaining why some of those behaviors are shown, as I think it can bootstrap future work more easily.\n-We are wary of explanations for which we do not have evidence. For each of the modifications introduced in Section 3, we offer a succinct conjecture as to why that change improves performance, but we are not aware of any existing reliable, informative metric which we could employ to understand or trace the source of each observed behavior, particularly with respect to GAN stability or performance.\nRegarding depth vs width: This paper is empirical, and we only briefly experimented with increasing depth analogously to increasing width. While increasing width provided an immediate measurable benefit, increasing depth did not. We felt that it was better to report the results of this brief investigation than to omit it for a lack of investigatory depth."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "BJeJx-H7RQ", "original": null, "number": 8, "cdate": 1542832359087, "ddate": null, "tcdate": 1542832359087, "tmdate": 1542832359087, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "HklmZ1xqhm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We would like to thank Reviewer 1 for their review and constructive suggestions. Our responses inline:\n\n>Can you elaborate more on why BatchNorm statistics are computed across all devices as opposed to per-device? Was this crucial for best performance?\n-The primary reason is to ensure that training is invariant to the per-device batch size. When scaling from resolution 128x128 to 256x256, we increase the number of devices but maintain the same overall batch size, reducing the per-device batch size. Cross-replica BatchNorm ensures that the smaller per-device batch size does not affect training. Switching to per-device BatchNorm at 128x128 results in a performance drop, albeit not a crippling one: for a model which would otherwise get an IS of 92 and an FID of 9.5, switching to per-device BatchNorm results in an IS of 78 and FID of 13.\n\n>It is not clear if provided analysis for large-scale GANs apply for small-medium sized GANs. Providing such analysis would be also helpful for the community.\n-The goal of this work is to explore GANs at large scale; the exploration of small or medium scale models would indeed be interesting for another study. Having said that, we do evaluate BigGAN on conditional CIFAR-10 (mentioned briefly in Appendix C.2) and obtain an IS of 9.22 and an FID of 14.73 without truncation, which to our knowledge are better than any published results.\n\n>How do you see the impact of the suggested techniques on tackling harder data-modalities for GANs, e.g. text or sequential data in general?\n-Any of the proposed techniques could be applied to standard GANs for text or other sequential data in principle, but we have not experimented with these applications ourselves.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "rJx99xSXAX", "original": null, "number": 7, "cdate": 1542832274151, "ddate": null, "tcdate": 1542832274151, "tmdate": 1542832274151, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Draft Update", "comment": "We would like to thank all reviewers for their reviews. We have uploaded a revised draft incorporating this feedback. Specifically:\n-We have added reference to the two papers mentioned in an earlier comment, as well as \u201cThe Unusual Effectiveness of Averaging in GAN Training,\u201d Yazici et al., arXiv:1806.04498.\n-Added Appendix G expanding on our discussion, and referenced this appendix at the end of section 4.2\n-Fixed typos in captions\n-Added a brief section on pitfalls of negative results in negative results appendix\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "S1gaWerP2X", "original": null, "number": 2, "cdate": 1540997124684, "ddate": null, "tcdate": 1540997124684, "tmdate": 1541533887141, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "content": {"title": "Good investigation, great results, could be improved.", "review": "Summary:\nThe authors present a empirical investigation of methods for scaling GANs to complex datasets, such as ImageNet, for class-conditioned image generation. They first build and describe a strong baseline based on recently proposed techniques for GANs and push the performance on large datasets with several modifications presented sequentially, to obtain strong state-of-the-art IS/FID scores, as well as impressive visual results. The authors propose a simple truncation trick to control the fidelity/variance which is interesting on its own but cannot always scale with the architecture. The authors further propose a orthogonalization-based regularization to mitigate this problem. An investigation of training collapse at large scale is also performed; the authors investigate some regularization schemes based on gathered empirical evidence. As a result, they explore and discard Spectral Normalization of the generator as a way to prevent collapse and show that a severe tradeoff between stability and quality can be controlled when using zero-centered gradient penalties in the Discriminator. In the end, no solution that can ensure quality and stability is found, except having prohibitively large amounts of data (~300M images). Models are evaluated on the ImageNet and on this internal, bigger dataset.\n\nPros:\n- This investigation gives a significant amount of insights on GAN stability and performance at large scales, which should be useful for anyone working with GANs on complex datasets (and that have access to great computational resources).\n\n- Even though commonly used evaluations metrics for GANs are still not fully adequate, the authors obtain quantitative performance significantly beyond previous work, which seems indeed correlated with remarkable visual results.\n\n- The baseline and added modifications are well presented and clearly explained. The Appendices also have great value in that regard.\n\n\nCons:\n- Discussions sometimes lack depth or are absent.\nFor example, it is unclear to me why some larger models are not amenable to truncation. Besides visible artifacts, what does it mean? Why does a smoother G reduces those artifacts? Were samples from those networks better without using truncation? Why would this be?\n\nAuthors report how wider networks perform best, and how deeper networks degrade performance. Again, discussions are lacking, and it doesn\u2019t seem the authors tried to understand why such behaviors were shown.\n\nEven though this is mostly an empirical investigation, I think some more efforts should be put in understanding and explaining why some of those behaviors are shown, as I think it can bootstrap future work more easily.\n\n- In Section 3.1 : \u201cAcross runs in Table 1, we observe that without Orthogonal Regularization, only 16% of models are amenable to truncation compared to 60% with Orthogonal Regularization.\u201d For me, this is not particularly clear. Is this something the reader should understand from Table 1? \n\n- I question the choice of sections chosen to be in the main paper/appendices. I greatly appreciated the negative results reported in the main text as well as in the appendices and this has significant value. However, as this is to me mostly a detailed empirical investigation and presentation of high-performance GANs on large scales, I would be likely to share this with colleagues who want to tackle similar problems. In this case, if future readers limit themselves to the main text, I think it can have more value to present some content form Appendix B and C than to have more than a full page on stability investigations and attempted tricks that turned out not to be used to reach maximal performance. However I do not want to discourage publishing of negative results, and I definitely wish to see this investigation in the paper, but I merely question the positioning of such information. With regard to my first negative point above about the lack of discussions, it seems the analysis of Section 4 is disproportionate compared to other places.\n\n\nSuggestions/Comments:\n\n- Regarding the diversity/fidelity tradeoff using different truncation thresholds, I think constraining the norm of the sampled noise vectors to the exact threshold value (by projecting the samples on the 0-centered hyper-sphere of radius = threshold) could yield even more interesting or more informative Figures, as obtained scores or samples on the edge of that hyper-sphere might provide information on the \u2018guaranteed\u2019 (not proven) quality/fidelity of samples mapped from inside that hyper-sphere. \n\n- In Appendix D, the Figures could be slightly clarified by using a colored heatmap to color the curve, with colors corresponding to the threshold values. Similar curves could also be produced with the hyper-sphere projection proposed above to have a slightly clearer idea of the behavior on the limit of that hyper-sphere.\n\n- In Section 4.2, in the second paragraph, you refer to Appendix F and describe \u201csharp upward jump at collapse\u201d in D\u2019s loss. However, it seems the only Figure showing D\u2019s loss when unconstrained is Figure 26, in which it is hard to notice any significant jump in the loss.\n\n- In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says \u201closses\u201d.\n\n\nThis investigation of GAN scalability is successful results-wise even though the inability to stabilize training without sacrificing great performance on ImageNet is disappointing. The improvement over previous SOTA is definitely significant. This work thus shows a modern GAN architecture for complex datasets that could be a strong basis for future work. However, I think the paper could and should be improved with some more detailed analysis and discussions of exhibited behaviors in order to further guide and encourage future work. It could also be clarified on some aspects, and potentially re-structured a bit to be better align with its probable impact directions.  I would also be curious to see the proposed techniques applied on simpler datasets. Can this be useful for someone having less compute power and working on something similar to CelebA? \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "cdate": 1542234432842, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335752748, "tmdate": 1552335752748, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HklmZ1xqhm", "original": null, "number": 3, "cdate": 1541172987204, "ddate": null, "tcdate": 1541172987204, "tmdate": 1541533886890, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "content": {"title": "Good paper", "review": "Summary:\nThis paper proposes a suite of tricks for training large-scale GANs, and obtaining state-of-the-art results for high-resolution images. The paper starts from a self-attention GAN baseline (Zhang 2018), and proposes:\n-\tIncreasing batch size (8x) and model size (2x)\n-\tSplitting noise z in multiple chunks, and injecting it in multiple layers of the generator\n-\tSampling from truncated normal distribution, where samples with norms that exceed a specific threshold are resampled. This seems to be used only at test-time and is used to control variety-fidelity tradeoff. The generator is encouraged to be smooth using an orthogonal regularization term.\nIn addition, the paper proposes practical recipes for characterizing collapse in GANs. In the generator, the exploding of the top 3 singular values of each weight matrix seem to indicate collapse. In the discriminator, the sudden increase of the ratio of first/second singular value of weight matrices indicate collapse in GANs. Interestingly, the paper suggests that various regularization methods which can improve stability in GAN training, do not necessarily correspond to improvement in performance.\n\nStrengths:\n-\tProposed techniques are intuitive and very well motivated\n-\tOne of the big pluses of this work is that authors try to \"quantify\" each proposed technique with training speed and/or performance improvement. This is really a good practice.\n-\tDetailed analysis for detecting collapse and improving stability in large-scale GAN\n-\tProbably no need to mention that, but results are quite impressive\n\nWeaknesses:\n-\tComputational budget required is massive. The paper mentions model use from 128-256 TPUs, which severely limits reproducibility of results.\n\nComments/Questions:\n-\tCan you elaborate more on why BatchNorm statistics are computed across all devices as opposed to per-device? Was this crucial for best performance? \n-\tIt is not clear if provided analysis for large-scale GANs apply for small-medium sized GANs. Providing such analysis would be also helpful for the community.\n-\tHow do you see the impact of the suggested techniques on tackling harder data-modalities for GANs, e.g. text or sequential data in general?\n\nOverall recommendation:\nThe paper is well written, ideas are well motivated/justified and results are very compelling. This is a good paper and I higly recommend acceptance.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Review", "cdate": 1542234432842, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335752748, "tmdate": 1552335752748, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkgcCLXypQ", "original": null, "number": 10, "cdate": 1541514961643, "ddate": null, "tcdate": 1541514961643, "tmdate": 1541515250959, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Hi, I would like to ask some details about calculating inception scores.\n\nHow did you calculate the inception score for images of 128x128 and 512x512 resolutions?\nDid you just resize the images to 229x229 and feed them into the inception-v3 model, which was pretrained on 229x229 imagenet dataset?\n\nFor calculating IS, did you use the code provided by openai? \nhttps://github.com/openai/improved-gan\n\nThanks in advance.", "title": "Question about calculating inception scores"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "Hkgd30pT27", "original": null, "number": 9, "cdate": 1541426864490, "ddate": null, "tcdate": 1541426864490, "tmdate": 1541426864490, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "The samples look extremely good. Have you tried to calculate intra-class FID like the cGANs with Projection Discriminator did? Also, have you tried training your model on any unlabelled data set?", "title": "Question about unsupervised training"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "BJgFGkiT2Q", "original": null, "number": 8, "cdate": 1541414672543, "ddate": null, "tcdate": 1541414672543, "tmdate": 1541414672543, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rJgBuz5a3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Thanks for sharing the details!", "title": "Thanks"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "rJgBuz5a3Q", "original": null, "number": 6, "cdate": 1541411437388, "ddate": null, "tcdate": 1541411437388, "tmdate": 1541411437388, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rJlaYkcTnX", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Question about Architecture", "comment": "1. Yes, the non-local blocks have spectral normalization applied to the convolutional weights, as in SA-GAN.\n\n2. No, following SN-GAN there is no BatchNorm in D.\n \n3. We do not apply BatchNorm or ReLU before the non-local block--it takes in the output of the previous residual block. Please see https://github.com/brain-research/self-attention-gan for a reference implementation of non-local blocks.\n\n4. The sign of gamma is arbitrary (the output of the block before being multiplied by gamma can take on either sign), and we observe both positive and negative gammas in our models. Gamma is a freely learned scalar parameter.\n\nThanks.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "rJlaYkcTnX", "original": null, "number": 7, "cdate": 1541410693449, "ddate": null, "tcdate": 1541410693449, "tmdate": 1541410693449, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Hi, I would like to ask some more details about your architecture.\n\n1. Do you apply spectral normalization in the attention layer (non-local block)?\n\n2. Do you apply batch normalization in the discriminator?\n\n3. Do you perform batch normalization or nonlinear (relu) to the input of the attention layer (non-local block) before transforming the input in to the feature spaces f, g?\n\n4. In the non-local block, the weight gamma is initialized as 0. Did you observe that gamma becomes negative during training? Or did you force gamma to be non-negative?\n\nThanks!", "title": "Question about the architecture"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "BklSXtmL2X", "original": null, "number": 5, "cdate": 1540925724789, "ddate": null, "tcdate": 1540925724789, "tmdate": 1540925724789, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Relevant Prior Work", "comment": "We've recently been made aware of two prior works that observe a correlation between the variance of the latent noise and the variety/quality of the Generator outputs. We will be adding references accordingly.\n\n[1] Marco Marchesi. Megapixel Size Image Creation using Generative Adversarial Networks. arXiv preprint arXiv:1706.00082.\n[2] Mathijs Pieters and Marco Wiering. Comparing Generative Adversarial Network Techniques for Image Creation and Modification. arXiv preprint arXiv:1803.09093."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "Sklp_OFLjm", "original": null, "number": 6, "cdate": 1539901557504, "ddate": null, "tcdate": 1539901557504, "tmdate": 1539905040807, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "SyesNhmUjm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Thank you for the clarification! It's very interesting that pre-SN singular values of some layers' weight keeps growing. That seems to suggest that the outputs of the layer lie in a very low-dimensional subspace.", "title": "Follow-up"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "SyesNhmUjm", "original": null, "number": 4, "cdate": 1539877938698, "ddate": null, "tcdate": 1539877938698, "tmdate": 1539877938698, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "Hke0IlKSim", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Anonymous", "comment": "Hi,\n\nAs mentioned in the first paragraph of Section 3, we use Spectral norm in both G and D. As mentioned in the caption of Figure 3, the spectra we plot are before spectral normalization, so the actual values will be normalized by the first singular value. We plot the unnormalized values to show how the spectra of the underlying weights change over time.\n\nThanks."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "Hke0IlKSim", "original": null, "number": 5, "cdate": 1539833942127, "ddate": null, "tcdate": 1539833942127, "tmdate": 1539833942127, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Thank you for great insights into instabilities of the generator and discriminator! I'm a little bit confused though. Do you employ Spectral Normalization in the generator and discriminator? Spectral normalization should make the largest singular value of the weight matrix around 1 but Figure 3 shows very large eigenvalues. Am I missing something?", "title": "Question about singular values"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "S1xw0OrXqm", "original": null, "number": 4, "cdate": 1538640078528, "ddate": null, "tcdate": 1538640078528, "tmdate": 1538640078528, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "I have a question about saturation artifacts you mention in section 3.\n\n>> The distribution shift caused by sampling with different latents than those seen in training is problematic for many models. \n>> Some of our larger models are not amenable to truncation, producing saturation artifacts (Figure 2(b)) when fed truncated noise. \n\nI wonder why larger models produce saturation artifacts when fed truncated noise.\nthe noise outside the range can be sampled from N(0, 1). so, I believe modles produce saturation artifacts without truncated trick.\nI believe that the reason why truncate trick produce saturation artifacts need more clarification.\n \nRegards.", "title": "Question about saturation artifacts"}, "signatures": ["~kohei_nishimura1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["~kohei_nishimura1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "SJlWU-HGcm", "original": null, "number": 3, "cdate": 1538572617263, "ddate": null, "tcdate": 1538572617263, "tmdate": 1538572617263, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rkxcudXfq7", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Jaonary", "comment": "Hi Jaonary,\n\nIt may be possible to get similar results using gradient aggregation, but it's tough to say--we use cross-replica BatchNorm in the Generator, so aggregating gradients with a smaller batch size will not be exactly equivalent. In our ablations using per-device BatchNorm reduced performance but still trained, so perhaps aggregating gradients with cross-replica BatchNorm and multiple GPUs will work (albeit it will be quite slow and not exactly equivalent to what we've done).\n\nThe architectural difference is in the channel pattern of the Discriminator, where each residual block takes in a tensor with num_in channels and outputs a tensor with num_out channels. In (Miyato, 2018) the first convolution in the residual block has num_in outputs, and the second convolution has num_out outputs. In (Zhang, 2018), however, the first convolution in the residual block has num_out outputs instead of num_in inputs, which results in the Discriminator having more parameters and more capacity. We use the channel pattern from (Zhang, 2018).\n\nThanks."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "rkxcudXfq7", "original": null, "number": 3, "cdate": 1538566257575, "ddate": null, "tcdate": 1538566257575, "tmdate": 1538566257575, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "One most striking results of your paper is the effect of the batch size. In your experiment you use some TPU cores so I guess that you have enough memory to store all of your batch. Do you think that it is possible to get the same result if you use multiple GPUs instead with reduced batch size and algorithm such as all reduce to aggregate the gradients ?\nOne more thing, it's not really clear what is the difference of your architecture and the one used by Miyato 2018 ? You said in the appendix B that the number of filters of the first conv layer of each block is equal to the number of the output filters but not the number of the input filters. Can you explain better what does it mean ?", "title": "Question about the architecture and the scalability"}, "signatures": ["~Jaonary_Rabarisoa1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["~Jaonary_Rabarisoa1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "SJgVJ8n1q7", "original": null, "number": 2, "cdate": 1538405851631, "ddate": null, "tcdate": 1538405851631, "tmdate": 1538405851631, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rJl92Zo197", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "Response to Sheng", "comment": "Hi Sheng,\n\nThe score reported in \"A note on the Inception Score\"  is for ImageNet at 64x64 resolution. We get approximately the same number using our code.\n\nThanks."}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "rJl92Zo197", "original": null, "number": 2, "cdate": 1538400690180, "ddate": null, "tcdate": 1538400690180, "tmdate": 1538400690180, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "I have a question about Inception Score. You mention in APPENDIX C \"We compute the IS for both the training and validation sets. At 128\u00d7128 the training data has an IS of 233, and the validation data has an IS of 166...\"\nHowever, in Table 1 of \"A Note on the Inception Score\", which is referenced by your paper, the Inception Score of ImageNet validation set is around 63.\nI wonder what is the cause of the gap between these two scores.", "title": "Question about Inception Score of ImageNet validation set"}, "signatures": ["~Sheng_Hu1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["~Sheng_Hu1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}, {"id": "rJlFIzT0YX", "original": null, "number": 1, "cdate": 1538343505095, "ddate": null, "tcdate": 1538343505095, "tmdate": 1538343505095, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "rJesh9ORFm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "content": {"title": "response to Mert", "comment": "Hi Mert,\n\ni/ii):\nPlease see our appendix for further details. A chunk refers to a subset of the dimensions of z in the channel dimension; if z is a 100 x 128-dimensional tensor (batch size x channels) sampled from N(0,1), then splitting it into 8 chunks would result in 8 tensors (z_i for i=1 to 8 )  each of dimension 100 x 16.  E.g.\nz = tf.random_normal((100,128))\nz_chunks = tf.split(z, 8, axis=1)\n\niii / iv):\nIn previous works on conditional GANs, the conditional batchnorm gains and biases are implemented as embeddings, similar to word embeddings in language models, with one embedding per layer.  We replace this with a single embedding which we pass through a single linear transform to get the batchnorm parameters. We describe this in the appendix, but here's some pseudocode:\nembedding_weights  = matrix in (num_classes, embedding_dimension)\nbias_projection = matrices in (embedding_dimension, batchnorm_channels_dimension)\ngain_projection = matrices in (embedding_dimension, batchnorm_channels_dimension)\n\nshared_embedding = embedding_weights * one_hot(class index)\nbias_i = bias_projection_i * shared_embedding\ngain_i = 1 + gain_projection_i * shared_embedding\n\nIf you're using hierarchical latents, use this instead:\nbias_i = bias_projection_i * concatenate(shared_embedding,  z_chunks_i)\ngain_i = 1 + gain_projection_i *concatenate(shared_embedding,  z_chunks_i)\n\nHope that helps!"}, "signatures": ["ICLR.cc/2019/Conference/Paper563/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616339, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1xsqj09Fm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper563/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper563/Authors|ICLR.cc/2019/Conference/Paper563/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616339}}}, {"id": "rJesh9ORFm", "original": null, "number": 1, "cdate": 1538325170880, "ddate": null, "tcdate": 1538325170880, "tmdate": 1538325170880, "tddate": null, "forum": "B1xsqj09Fm", "replyto": "B1xsqj09Fm", "invitation": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "content": {"comment": "Thank you for all your efforts towards understanding training dynamics in large-scale GANs. I have a question about conditional batch-norms.  You mention in Section 3 these \n* \" Instead of having a separate layer for each embedding (Miyato et al., 2018; Zhang et al., 2018), we opt to use a shared embedding, which is linearly projected to each layer\u2019s gains and biases (Perez et al., 2018).\" \n* \"For our architecture, this is easily accomplished by splitting z into one chunk per resolution, and concatenating each chunk to the conditional vector c which gets projected to the BatchNorm gains and biases. \".\n\nI believe that these statements need more clarification. i) how do you define a chunk?, ii) How z is split into chunks? iii) How do you compute shared embedding? iv) how parameters of an affine transformation for each layer is constructed from the shared embedding?\n\nRegards.", "title": "Regarding Conditional Batchnorms"}, "signatures": ["~Mert_B\u00fclent_Sar\u0131y\u0131ld\u0131z1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper563/Reviewers/Unsubmitted"], "writers": ["~Mert_B\u00fclent_Sar\u0131y\u0131ld\u0131z1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick\", allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Frechet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.", "keywords": ["GANs", "Generative Models", "Large Scale Training", "Deep Learning"], "authorids": ["ajb5@hw.ac.uk", "jeffdonahue@google.com", "simonyan@google.com"], "authors": ["Andrew Brock", "Jeff Donahue", "Karen Simonyan"], "TL;DR": "GANs benefit from scaling up.", "pdf": "/pdf/180bb2f7ee1c713a75b72fe89f719b7500608b84.pdf", "paperhash": "brock|large_scale_gan_training_for_high_fidelity_natural_image_synthesis", "_bibtex": "@inproceedings{\nbrock2018large,\ntitle={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},\nauthor={Andrew Brock and Jeff Donahue and Karen Simonyan},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=B1xsqj09Fm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper563/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311806835, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1xsqj09Fm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper563/Authors", "ICLR.cc/2019/Conference/Paper563/Reviewers", "ICLR.cc/2019/Conference/Paper563/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311806835}}}], "count": 27}