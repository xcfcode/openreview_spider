{"notes": [{"id": "Byg6VhUp8V", "original": "rkeLp0GhLN", "number": 1, "cdate": 1551883317129, "ddate": null, "tcdate": 1551883317129, "tmdate": 1556914603192, "tddate": null, "forum": "Byg6VhUp8V", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "content": {"title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper1/Authors"], "keywords": [], "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms.\nIn this paper, we provide a sober look on recent progress in the field and challenge some common assumptions.\nWe train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets.\nWe observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision.\nFurthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. \nOur results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.", "pdf": "/pdf/9f8e2fd83f6e283843ccfc140d326a3b3ca6a0b5.pdf", "paperhash": "anonymous|challenging_common_assumptions_in_the_unsupervised_learning_of_disentangled_representations", "_bibtex": null}, "signatures": ["ICLR.cc/2019/Workshop/RML"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "cdate": 1551883316747, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1551883316747, "tmdate": 1551883316747, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}, "tauthor": "OpenReview.net"}, {"id": "rygEcQ61K4", "original": null, "number": 1, "cdate": 1554137996412, "ddate": null, "tcdate": 1554137996412, "tmdate": 1554627187120, "tddate": null, "forum": "Byg6VhUp8V", "replyto": "Byg6VhUp8V", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper1/Official_Review", "content": {"title": "Interesting work on representation learning", "review": "Summary: This paper is an interesting discussion of disentanglement with an experimental study on several VAE variants.  I strongly recommend acceptance, however the writing could be a bit more conservative in the claims given that only VAE-based latent variable models are studied experimentally.  \n\nNotes: \n  -This paper investigates many proposed methods for learning disentangled representations.  \n  -Introduction does a good job of laying out the intuition for what we want to get out of \u201cdisentangled features\u201d.  \n  -There is some intuition that changing some \u201cdisentangled features\u201d should only change those factors of variation and not others.  \n  -Appendix A proves that unsupervised learning of disentangled representations is impossible without inductive biases (this doesn\u2019t seem obvious to me!)\n  -Paper measures disentanglement across 12k models.  \n  -Releases a \u201cdisentanglement_lib\u201d for evaluating disentangled representations.  \n  -Study of different models shows that the \u201caggregated posterior\u201d is not correlated, but the dimensions of the representation are correlated.  In this sentence I\u2019m a bit confused about whether this is referring to q(z|x) or q(z).  On first reading, I find this claim a bit confusing, because if q(z) follows a gaussian distribution, then its dimensions should be disentangled?  \n  -All datasets considered work on the assumption that x is a deterministic function of an underlying disentangled z.  \n\nComments: \n  -Uses the wrong style sheet.  \n  -It\u2019s a bit weird to play up the \u201c10k models\u201d aspect, because presumably this comes from some kind of hyperparameter sweep or combinatorial explosion?  \n  -I think it seems like kind of a bad omission to not include ALI (Dumoulin 2016) or any other models in this family.  \n  -Beginning of 4.3 has a typo.  \n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Paper1/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper1/Authors"], "keywords": [], "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms.\nIn this paper, we provide a sober look on recent progress in the field and challenge some common assumptions.\nWe train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets.\nWe observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision.\nFurthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. \nOur results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.", "pdf": "/pdf/9f8e2fd83f6e283843ccfc140d326a3b3ca6a0b5.pdf", "paperhash": "anonymous|challenging_common_assumptions_in_the_unsupervised_learning_of_disentangled_representations", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper1/Official_Review", "cdate": 1554124268981, "expdate": 1556236800000, "duedate": 1555372800000, "reply": {"forum": "Byg6VhUp8V", "replyto": "Byg6VhUp8V", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/RML/Paper1/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554124268981, "tmdate": 1554627185242, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Paper1/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}, {"id": "BygV7r-HYE", "original": null, "number": 1, "cdate": 1554482460217, "ddate": null, "tcdate": 1554482460217, "tmdate": 1554482460217, "tddate": null, "forum": "Byg6VhUp8V", "replyto": "Byg6VhUp8V", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper1/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper1/Authors"], "keywords": [], "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms.\nIn this paper, we provide a sober look on recent progress in the field and challenge some common assumptions.\nWe train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets.\nWe observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision.\nFurthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. \nOur results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.", "pdf": "/pdf/9f8e2fd83f6e283843ccfc140d326a3b3ca6a0b5.pdf", "paperhash": "anonymous|challenging_common_assumptions_in_the_unsupervised_learning_of_disentangled_representations", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper1/Decision", "cdate": 1554482375101, "reply": {"forum": "Byg6VhUp8V", "replyto": "Byg6VhUp8V", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554482375101, "tmdate": 1554482378058, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}], "count": 3}