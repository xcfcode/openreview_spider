{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730177810, "tcdate": 1509117708272, "number": 438, "cdate": 1518730177802, "id": "BkVf1AeAZ", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "BkVf1AeAZ", "original": "ByNG1CgC-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260079415, "tcdate": 1517250079096, "number": 747, "cdate": 1517250079075, "id": "S1PXLk6rf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "This paper proposes an approach for jointly learning a label embedding and prediction network, as a way of taking advantage of relationships between labels.  This general idea is well-motivated, but the specifics of the proposed approach are not motivated or described well.  More discussion of relationship with prior work (e.g. other ways of \"softening\" the softmax) is needed.  The authors claim to have state-of-the-art results, but reviewers point out that much better results exist."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448843, "tcdate": 1511539130620, "number": 1, "cdate": 1511539130620, "id": "Hk7pW6HlM", "invitation": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "signatures": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes to add an embedding layer for labels that constrains normal classifiers in order to find label representations that are semantically consistent. The approach is then experimented on various image and text tasks.\n\nThe description of the model is laborious and hard to follow. Figure 1 helps but is only referred to at the end of the description (at the end of section 2.1), which instead explains each step without the big picture and loses the reader with confusing notation. For instance, it only became clear at the end of the section that E was learned.\n\nOne of the motivations behing the model is to force label representations to be in a semantic space (where two labels with similar meanings would be nearby). The assumption given in the introduction is that softmax would not yield such a representation, but nowhere in the paper this assumption is verified. I believe that using cross-entropy with softmax should also push semantically similar labels to be nearby in the weight space entering the softmax. This should at least be verified and compared appropriately.\n\nAnother motivation of the paper is that targets are given as 1s or 0s while soft targets should work better. I believe this is true, but there is a lot of prior work on these, such as adding a temperature to the softmax, or using distillation, etc. None of these are discussed appropriately in the paper.\n\nSection 2.2 describes a way to compress the label embedding representation, but it is not clear if this is actually used in the experiments. h is never discussed after section 2.2.\n\nExperiments on known datasets are interesting, but none of the results are competitive with current state-of-the-art results (SOTA), despite what is said in Appending D. For instance, one can find SOTA results for CIFAR100 around 16% and for CIFAR10 around 3%. Similarly, one can find SOTA results for IWSLT2015 around 28 BLEU. It can be fine to not be SOTA as long as it is acknowledged and discussed appropriately.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448754, "id": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper438/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer1", "ICLR.cc/2018/Conference/Paper438/AnonReviewer3", "ICLR.cc/2018/Conference/Paper438/AnonReviewer2"], "reply": {"forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper438/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448754}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448806, "tcdate": 1511822345018, "number": 2, "cdate": 1511822345018, "id": "SyZf4f5gM", "invitation": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "signatures": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "not a well presented/justified  model", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a label embedding network method that learns label embeddings during the training process of deep networks. \nPros: Good empirical results.\nCons:  There is not much technical contribution. The proposed approach is neither well motivated, nor well presented/justified.  The presentation of the paper needs to be improved. \n\n1. Part of the motivation on page 1 does not make sense. In particular, for paragraph 3, if the classification task is just to separate A from B, then (1,0) separation should be better than (0.8, 0.2). \n\n2. Label embedding learning has been investigated in many previous works. The authors however ignored all the existing works on this topic, but enforce label embedding vectors as similarities between labels in Section 2.1 without clear motivation and justification. This assumption is not very natural \u2014 though label embeddings can capture semantic information and label correlations, it is unnecessary that label embedding matrix should be m xm and each entry should represent the similarity between a pair of labels.  The paper needs to provide a clear rationale/justification for the assumptions made, while clarifying the difference (and reason) from the literature works. \n\n3. The proposed model is not well explained.  \n(1) By using the objective in eq.(14), how to learn the embeddings E? \n(2) The authors state \u201cIn back propagation, the gradient from z2 is kept from propagating to h\u201d.  This makes the learning process quite arbitrary under the objective in eq.(14). \n(3) The label embeddings are not directly used for the classification (H(y, z\u2019_1)), but rather as auxiliary part of the objective.  How to decide the test labels?\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448754, "id": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper438/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer1", "ICLR.cc/2018/Conference/Paper438/AnonReviewer3", "ICLR.cc/2018/Conference/Paper438/AnonReviewer2"], "reply": {"forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper438/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448754}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448770, "tcdate": 1511919914089, "number": 3, "cdate": 1511919914089, "id": "r1zEZ9ief", "invitation": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "signatures": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Technique not properly justified; not enough insights can be learned from the work.", "rating": "3: Clear rejection", "review": "The paper proposes a method which jointly learns the label embedding (in the form of class similarity) and a classification model. While the motivation of the paper makes sense, the model is not properly justified, and I learned very little after reading the paper.\n\nThere are 5 terms in the proposed objective function. There are also several other parameters associated with them: for example, the label temperature of z_2\u2019\u2019 and and parameter alpha in the second last term etc.\n\nFor all the experiments, the same set of parameters are used, and it is claimed that \u201cthe method is robust in our experiment and simply works without fine tuning\u201d. While I agree that a robust and fine-tuning-free model is ideal 1) this has to be justified by experiment. 2) showing the experiment with different parameters will help us understand the role each component plays. This is perhaps more important than improving the baseline method by a few point, especially given that the goal of this work is not to beat the state-of-the-art.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448754, "id": "ICLR.cc/2018/Conference/-/Paper438/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper438/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper438/AnonReviewer1", "ICLR.cc/2018/Conference/Paper438/AnonReviewer3", "ICLR.cc/2018/Conference/Paper438/AnonReviewer2"], "reply": {"forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper438/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448754}}}, {"tddate": null, "ddate": null, "tmdate": 1512062086985, "tcdate": 1512062086985, "number": 1, "cdate": 1512062086985, "id": "By15nh6eG", "invitation": "ICLR.cc/2018/Conference/-/Paper438/Public_Comment", "forum": "BkVf1AeAZ", "replyto": "BkVf1AeAZ", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "There is a similar work", "comment": "The authors do not mention a similar recent paper:\nhttps://arxiv.org/abs/1609.06693\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks", "abstract": "We propose a method, called Label Embedding Network, which can learn label representation (label embedding) during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems.", "pdf": "/pdf/a3a65acfc6348430344d4bafc6cce5209857c360.pdf", "TL;DR": "Learning Label Representation for Deep Networks", "paperhash": "sun|label_embedding_network_learning_label_representation_for_soft_training_of_deep_networks", "_bibtex": "@misc{\nsun2018label,\ntitle={Label Embedding Network: Learning Label Representation for Soft Training of Deep Networks},\nauthor={Xu Sun and Bingzhen Wei and Xuancheng Ren and Shuming Ma},\nyear={2018},\nurl={https://openreview.net/forum?id=BkVf1AeAZ},\n}", "authors": ["Xu Sun", "Bingzhen Wei", "Xuancheng Ren", "Shuming Ma"], "keywords": ["label embedding", "deep learning", "label representation", "computer vision", "natural language processing"], "authorids": ["xusun@pku.edu.cn", "weibz@pku.edu.cn", "renxc@pku.edu.cn", "shumingma@pku.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791686497, "id": "ICLR.cc/2018/Conference/-/Paper438/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "BkVf1AeAZ", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper438/Authors", "ICLR.cc/2018/Conference/Paper438/Reviewers", "ICLR.cc/2018/Conference/Paper438/Area_Chair"], "cdate": 1512791686497}}}], "count": 6}