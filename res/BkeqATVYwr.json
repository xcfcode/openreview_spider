{"notes": [{"id": "BkeqATVYwr", "original": "rkxIVCWdwS", "number": 865, "cdate": 1569439185605, "ddate": null, "tcdate": 1569439185605, "tmdate": 1577168258409, "tddate": null, "forum": "BkeqATVYwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "AxUfguy4mC", "original": null, "number": 1, "cdate": 1576798708155, "ddate": null, "tcdate": 1576798708155, "tmdate": 1576800928200, "tddate": null, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Decision", "content": {"decision": "Reject", "comment": "All three reviewers are consistently negative on this paper. Thus a reject is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795710368, "tmdate": 1576800259359, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper865/-/Decision"}}}, {"id": "S1l9x8eior", "original": null, "number": 1, "cdate": 1573746162148, "ddate": null, "tcdate": 1573746162148, "tmdate": 1573747399445, "tddate": null, "forum": "BkeqATVYwr", "replyto": "B1gUZkOTKB", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment", "content": {"title": "Clarification on some confusions we have caused and added experiments", "comment": "The authors\u2019 would like to thank the reviewer for taking their time to read the paper and provide insightful and constructive feedback, which have helped us to improved the quality of our work. In the following we put our responses and the additional tasks performed to address the reviewer\u2019s concerns.\n\n- The number of negative samples is usually a small constant, 5, and it is based on this empirical fact that we have ignored the impact of the negative example, rs-. The training is still restricted to the actual edges and a constant number of negative examples per edge, which makes the cost still proportional to the number of edges,O(cE)=O(E) as c is a constant.\n\n- The statement \u201cThe goal is to learn, in an unsupervised fashion \u2026\u201d is to point out the fact that there are no extra labels to guide the training, other than maximizing the graph (edges) likelihood. All the baselines have a similar objective of maximizing the graph likelihood i.e., all baselines are annotated if edges are considered as annotations. Furthermore we would like to emphasize that we deal with node clustering task, which doesn\u2019t directly benefit from such annotations.\n\n- We have carried out the suggested experiments in your comment and added the results in the Appendix section, and our assumptions and design choices are validated. \n\n- As pointed out in an earlier response, almost all the baselines have a similar objective (maximizing the graph likelihood) and GAP has no special advantage as compared to the baselines.\n\n- The run time comparisons are performed on both real (Cora and Zhihu) and simulated datasets (BAG and ERG). The simulated datasets are included to see if graphs with different edge formation patterns have an effect on the training time in addition to the effect of their size, we have further clarified that in the paper.\n\n- GAP is carefully implemented not to include test nodes in the neighborhood of a node. However, since our algorithm is transductive, as are the baselines, it can only be trained on the current structure of the graph. (This can be verified from the source code that we have provided) in the gap_data.py file lines 50-52, \n# Ensures that no node from the test set is sampled in the neighbhorhood of any node    \n# mask_nodes is a variable containing test nodes.\nmsk = np.in1d(neighborhood_matrix, mask_nodes).reshape(neighborhood_matrix.shape)\nneighborhood_matrix[msk] = 0\n\nWe hope that our responses have addressed your concern."}, "signatures": ["ICLR.cc/2020/Conference/Paper865/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeqATVYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper865/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper865/Authors|ICLR.cc/2020/Conference/Paper865/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165016, "tmdate": 1576860543980, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment"}}}, {"id": "B1l0wclssr", "original": null, "number": 3, "cdate": 1573747301813, "ddate": null, "tcdate": 1573747301813, "tmdate": 1573747301813, "tddate": null, "forum": "BkeqATVYwr", "replyto": "rylsqZtauS", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment", "content": {"title": "Justification of our contribution", "comment": "The authors\u2019 would like to thank the reviewer for taking their time to read the paper and provide insightful and constructive feedback. It is our mistake that we haven\u2019t clearly explain some points, now we have added more clarification in the updated version of the paper to address the reviewer\u2019s concerns.\n\nHowever, we respectfully disagree with some of the reviewer\u2019s comments as discussed below. First, we believe that there is a novelty in adopting a solution to the problem of context-sensitive NRL from a completely orthogonal problem of Q&A ranking, and in further simplifying the original algorithm so that it feets our problem and also scale. Moreover, the proposed insights can also be useful to other domains where the nature of the problem matches the one in NRL. \n\nSecond, the assumption that the order of neighbors is not irrelevant is actually a natural assumption in network analysis. Often times one can effectively capture the essential properties of the graph by ignoring such order. Furthermore, this is a common assumption in a related line of research eg. [1, 2, 3]. In addition, we have added an experiment which validated our assumption. We kindly ask the reviewer to refer to the appendix in the modified version of the paper, particularly the variant called GAPCN.\n\nThird, we would like to point out that GAT is only loosely related work to our approach; while there is a superficial relation simply because both methods use attention mechanism nonetheless with a different intention and design. In addition, unlike our approach, GAT is a member of Graph Convolutional Networks (GCNs) eg.[ 4, 5, 6, 7].  Most importantly GAT is not context-sensitive whereas GAP is and the goal of this study is to demonstrate the benefit of context-free over context-sensitive approaches without using external metadata, such as textual features and labels, and this has dictated the choice of the baselines. This is actually the prevalent trend in existing SOTA context-sensitive methods that we are aware of (eg. CANE, DMTE, Splitter), among which we have included two of them (CANE, DMTE). As we have pointed out in the paper, the source code of Splitter was not publicly available at the time of submission. The aforementioned issues, we have tried to further emphasize and clarify in the updated version of the paper. In addition, most GCNs eg.[4, 5, 6, 7] are semi-supervised and inducting, which is not the case for GAP.\n\nWe hope that our response and the added clarification in the paper have addressed your concerns.\n\n\n1. Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '14). ACM, New York, NY, USA, 701-710. DOI: https://doi.org/10.1145/2623330.2623732\n2.  Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). ACM, New York, NY, USA, 855-864. DOI: https://doi.org/10.1145/2939672.2939754\n3. Ying, Rex et al. \u201cGraph Convolutional Neural Networks for Web-Scale Recommender Systems.\u201d Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining - KDD  \u201918 (2018): n. pag. Crossref. Web.\n4. Thomas N. Kipf, Max Welling, Semi-Supervised Classification with Graph Convolutional Networks (ICLR 2017)\n5. Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2 and Yoshua Bengio. Graph attention Networks. (ICLR 2018)\n6. Sami  Abu-El-Haija,  Bryan  Perozzi,  Amol  Kapoor,  Hrayr  Harutyunyan,  Nazanin  Alipourfard,Kristina Lerman,  Greg Ver Steeg,  and Aram Galstyan.   Mixhop:  Higher-order graph convolu-tional architectures  via sparsified neighborhood  mixing.CoRR, abs/1905.00067,  2019.   URLhttp://arxiv.org/abs/1905.00067.\n7. Felix  Wu,  Tianyi  Zhang,  Amauri  H.  Souza  Jr.,  Christopher  Fifty,  Tao  Yu,  and  Kilian  Q.  Wein-berger.  Simplifying graph convolutional networks.CoRR, abs/1902.07153, 2019.  URLhttp://arxiv.org/abs/1902.07153"}, "signatures": ["ICLR.cc/2020/Conference/Paper865/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeqATVYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper865/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper865/Authors|ICLR.cc/2020/Conference/Paper865/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165016, "tmdate": 1576860543980, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment"}}}, {"id": "rJxIIYliir", "original": null, "number": 2, "cdate": 1573747021770, "ddate": null, "tcdate": 1573747021770, "tmdate": 1573747085948, "tddate": null, "forum": "BkeqATVYwr", "replyto": "SJlUP9iqFr", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment", "content": {"title": "Response, clarifications, and corrections.", "comment": "The authors\u2019 would like to thank the reviewers insightful comment on both technical and presentation matters. We would like to apologize for the typos, other presentation mistakes and that we have not clearly explained some notions. We have corrected the errors pointed out, have done a thorough check to avoid any related mistakes as much as possible, and added more clarification.  \n\nWhat is guaranteed is that this objective is a proxy to maximize the likelihood of the graph, $\\mathcal{L}(E)$,  which is the de facto standard in NRL. It leads to latent representations of nodes that preserve the properties of the graph. In addition, hard margin loss is not the only alternative, for instance we have achieved similar results by materializing $\\mathcal{L}(E)$ using the log loss based on negative sampling [1]\n\n$$\\mathcal{L}(E) = - \\sum_{e \\in E } \\log P(e)$$\n$$ P(e = <s, t>)  = p(r_t | r_s) $$\n\nTherefore, hard margin is just a choice  for $\\mathcal{L}(E)$ that worked for us and the improvement is not mainly because of it, as almost all the baselines have a similar formulation. Rather, our argument is that the performance improvement over the baselines is achieved (i) because of the way we model nodes using their neighborhood, (ii) by the design choice that lets the representations of a pair of nodes to be a result of mutual influence based on their neighborhood (what we call context-sensitive approach) so as to capture complex edge formation patterns. To further corroborate our claim, we have included an experiment using three variants of GAP with the same objective and showed GAP outperforms them. We kindly refer the reviewer to the Appendix in the updated version of the paper.\n\nWhile our work has much more focus on empirical than theoretical aspects it nevertheless complies with the ICLR call and we believe it would be very interesting to the audience of ICLR\n\nWe hope that our response and the added clarification in the paper have addressed your concerns.\n\n[1] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2 (NIPS'13), C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger (Eds.), Vol. 2. Curran Associates Inc., USA, 3111-3119."}, "signatures": ["ICLR.cc/2020/Conference/Paper865/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeqATVYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper865/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper865/Authors|ICLR.cc/2020/Conference/Paper865/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165016, "tmdate": 1576860543980, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper865/Authors", "ICLR.cc/2020/Conference/Paper865/Reviewers", "ICLR.cc/2020/Conference/Paper865/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Comment"}}}, {"id": "rylsqZtauS", "original": null, "number": 1, "cdate": 1570767250892, "ddate": null, "tcdate": 1570767250892, "tmdate": 1572972542641, "tddate": null, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed a GAP (graph neighborhood attentive pooling) method to solve problems of node clustering and link prediction. The proposed idea is mostly inspired by the attentive pooling network approach (APN) that has been widely used in the NLP domains; indeed the detailed steps of the proposed method is almost a ``mirror\u201d application of APN from question-answer pair ranking in NLP to the graph domains, and the only difference is that rather than using an RNN or LSTM to deal with the temporal orders in sentences (as in APN), the proposed method simply collect the first-order neighbors of the source node and target node and concatenate them without considering their orders. For the rest part, the authors used a hard margin loss function which is also the same as in APN.\n\nThe proposed method is very similar to the APN method and so its novelty is limited. Another concern is that although graph nodes do not have temporal orders as in word sentences, their relative connections manifested through the edges are important topological information that should be captured in contextualize a node. Unfortunately the authors almost totally ignored this information. The ignorance of the node orders appear to me not an advantage but instead a limitation, though it makes the computation and implementation much easier.\n\nThe graph attention network (GAT) is a very related method but I see no comparison with it in node clustering tasks. Also many recent methods on graph convolutional networks are not incorporated for comparison. \n\nBased on the concerns of novelty, lack of considering node topologies, and lack of comparison with strongly related methods, it is hard to recommend acceptance of this paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575087799431, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper865/Reviewers"], "noninvitees": [], "tcdate": 1570237745858, "tmdate": 1575087799442, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Review"}}}, {"id": "SJlUP9iqFr", "original": null, "number": 2, "cdate": 1571629661705, "ddate": null, "tcdate": 1571629661705, "tmdate": 1572972542607, "tddate": null, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "- Minimal theoretical novelty: The paper is too focussed on the empirical advantage achieved on the datasets used in the experiments. \n\n- Regarding equation (2), what is the guarantee this modification depicted by the hard-margin loss will always lead to improved performance like what happened with the experimented datasets? or more practically what are the required conditions for it to perform well?\n\n- Writing really needs to improve. There are too many typos and grammatical mistakes. \nExamples include:\n -- p1: \"to learn representation of graphs\". \n -- p1: \"on other contexts its coupled with\".\n -- p1: \"NRL studies have shown a context-sensitive approach significantly outperform previous context-free SOTA methods in link-prediction task.\"\n -- p3: \"a more sophisticated neighborhood functions\".\n -- p5: \"reporeted\"\n -- p7: \"two other variant\"\n -- p8: \"and gain\"\n\n- The latter issue makes is sometimes tricky to follow the ideas presented. \nExample:\n -- last two lines in Section 3. \n\n- Last paragraph in Section 1 is pretty informative about the pros and cons of the method. It also rather admits the first issue mentioned here in the review.  \n\nMinor:\n- p4: \"Eg. \" --> eg. "}, "signatures": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575087799431, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper865/Reviewers"], "noninvitees": [], "tcdate": 1570237745858, "tmdate": 1575087799442, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Review"}}}, {"id": "B1gUZkOTKB", "original": null, "number": 3, "cdate": 1571811069825, "ddate": null, "tcdate": 1571811069825, "tmdate": 1572972542574, "tddate": null, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "invitation": "ICLR.cc/2020/Conference/Paper865/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe proposed paper adapts Attentive Pooling Network (ATN) for graphs, by noting that the order of\nneighbors of any node in a graph does not matter unlike the neighboring words in a sentence (for\nwhich APN was developed). A simple modification of removing the layer which encodes higher order\nsequential properties in APN, eg n-gram like statistics, the APN is adapted to GAP. This allows\nencoding context from the neighboring nodes for a specific pair to be compared. Applications on Link\nPrediction and Node Clustering are demonstrated on three benchmark datasets.\n\nDetailed comments:\n- The paper is simple and easy to read and the modification of APN to GAP is also small while being\nwell motivated and empirically important.\n\n- There are some confusions in the writing: p4 first paragraph says that \"In principle one can learn\nusing all pairs of nodes, however that is not scalable, and hence we restrict learning between pairs\nin E.\" However from and around Eq2 it appears that r_s.r_t^- is also computed, where (s,r^-) is not\nan edge.\n\n- Also the statement below Eq2 \"The goal is to learn, in an unsupervised fashion...\" is not correct\n  specially for link prediction task, as having a training graph (with edges) is having annotations.\n        \n- Although, the removal of the `encoding' step from APN makes sense, it would also be possible that\n  the encoding operation is learned to be an identity function automatically if the training data is\n  presented appropriately. I would assume that learning in such a case might take longer, and might\n  not achieve the performance achieved by GAP. An ablation experiment could be reported to support\n  GAP further where encoder is kept in APN, but at the training same pair is presented multiple\n  times with the order of the neighborhoods randomized.      \n       \n- Similar to the experiment above, the order of the nodes could be arbitrarily fixed by some simple\n  logic. Eg order the neighboring nodes sorted by the feature similarity with the current node. This\n  can then be fed to APN and a baseline could be reported.\n\n- I do not directly work with Link Prediction or Node Clustering tasks, so am not familiar with the\n  literature and the baselines reported. However, it might be that many baselines do not use a\n  discriminative objective. Perhaps just using the discriminative objective gives a lot of boost and\n  using the context from neighbors is not very important? From Fig2 and Fig3a it seems that\n  neighborhood size does not make a big difference? This should also be ablated. One experiment\n  could be to use just the current feature and have a small MLP on it, and learn using the proposed\n  discriminative objective. If any other experiment can be designed in similar lines, it should be\n  included as well.\n\n- Why are run time comparison given on simulated data and not real data?\n\n- The experimental setup for training edge selection should be detailed more. In particular, I\n  would recommend that true generalization in terms of nodes and edges should be ensured, by having\n  no test node (i) appear in the train set and (ii) has an edge which connects it to a training\n  node. If this is not used then the alternative scheme used should be explained and argued for.\n\n\nI am not a direct expert in the area and felt that the paper was somewhat lacking. I am putting my initial rating\nto the conservative side. I am very open to revising the rating based on the author responses and the other \nreviewers' comments."}, "signatures": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper865/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GRAPH NEIGHBORHOOD ATTENTIVE POOLING", "authors": ["Zekarias Tilahun Kefato", "Sarunas Girdzijauskas"], "authorids": ["zekarias@kth.se", "sarunasg@kth.se"], "keywords": ["Network Representation Learning", "Attentive Pooling Networks", "Context-sensitive Embedding", "Mutual Attention", "Link Prediction", "Node Clustering"], "abstract": "Network representation learning (NRL) is a powerful technique for learning low-dimensional vector representation of high-dimensional and sparse graphs. Most studies explore the structure and meta data associated with the graph using random walks and employ a unsupervised or semi-supervised learning schemes. Learning in these methods is context-free, because only a single representation per node is learned. Recently studies have argued on the sufficiency of a single representation and proposed a context-sensitive approach that proved to be highly effective in applications such as link prediction and ranking.\nHowever, most of these methods rely on additional textual features that require RNNs or CNNs to capture high-level features or rely on a community detection algorithm to identifying multiple contexts of a node.\nIn this study, without requiring additional features nor a community detection algorithm, we propose a novel context-sensitive algorithm called GAP that learns to attend on different part of a node\u2019s neighborhood using attentive pooling networks. We show the efficacy of GAP using three real-world datasets on link prediction and node clustering tasks and compare it against 10 popular and state-of-the-art (SOTA) baselines. GAP consistently outperforms them and achieves up to \u22489% and \u224820% gain over the best performing methods on link prediction and clustering tasks, respectively.", "pdf": "/pdf/99b5bb527c624fdddd1407b47ebf76448b7a96a1.pdf", "code": "https://drive.google.com/open?id=1LW80Hoj3uWkWfCxVZtQctkrhxXcmlN7T", "paperhash": "kefato|graph_neighborhood_attentive_pooling", "original_pdf": "/attachment/f2f69d9d98c3f91d2f7da2163cfdac5634869f34.pdf", "_bibtex": "@misc{\nkefato2020graph,\ntitle={{\\{}GRAPH{\\}} {\\{}NEIGHBORHOOD{\\}} {\\{}ATTENTIVE{\\}} {\\{}POOLING{\\}}},\nauthor={Zekarias Tilahun Kefato and Sarunas Girdzijauskas},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeqATVYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeqATVYwr", "replyto": "BkeqATVYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper865/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575087799431, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper865/Reviewers"], "noninvitees": [], "tcdate": 1570237745858, "tmdate": 1575087799442, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper865/-/Official_Review"}}}], "count": 8}