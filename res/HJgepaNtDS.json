{"notes": [{"id": "HJgepaNtDS", "original": "r1eA4OlOvr", "number": 806, "cdate": 1569439160322, "ddate": null, "tcdate": 1569439160322, "tmdate": 1577168287669, "tddate": null, "forum": "HJgepaNtDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "9WJxoyJ3gt", "original": null, "number": 1, "cdate": 1576798706681, "ddate": null, "tcdate": 1576798706681, "tmdate": 1576800929565, "tddate": null, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Decision", "content": {"decision": "Reject", "comment": "This paper received two weak rejects (3) and one accept (8).  In the discussion phase, the paper received significant discussion between the authors and reviewers and internally between the reviewers (which is tremendously appreciated).  In particular, there was a discussion about the novelty of the contribution and ideas (AnonReviewer3 felt that the ideas presented provided an interesting new thought-provoking perspective) and the strength of the empirical results.  None of the reviewers felt really strongly about rejecting and would not argue strongly against acceptance.   However, AnonReviewer3 was not prepared to really champion the paper for acceptance due to a lack of confidence.  Unfortunately, the paper falls just below the bar for acceptance.  Taking the reviewer feedback into account and adding careful new experiments with strong results would make this a much stronger paper for a future submission.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714624, "tmdate": 1576800264368, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper806/-/Decision"}}}, {"id": "H1e8tSQ2jr", "original": null, "number": 9, "cdate": 1573823870352, "ddate": null, "tcdate": 1573823870352, "tmdate": 1573823870352, "tddate": null, "forum": "HJgepaNtDS", "replyto": "H1x2Fqg3sr", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Answer", "comment": "We thank you for your consideration and great help to improve the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "H1x2Fqg3sr", "original": null, "number": 8, "cdate": 1573812868287, "ddate": null, "tcdate": 1573812868287, "tmdate": 1573812868287, "tddate": null, "forum": "HJgepaNtDS", "replyto": "BygXSjZijH", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Thanks for your reply", "comment": "7/ I see, those bias are quite critical for applications. Thanks for the clarification\n\n8/ I see. Thanks for the clarification\n\n9/ Thanks. I've read carefully the paper and I honestly think the paper is more clear and precise.\n\nI will reconsider my review during the discussion phase."}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "BygXSjZijH", "original": null, "number": 7, "cdate": 1573751610659, "ddate": null, "tcdate": 1573751610659, "tmdate": 1573751610659, "tddate": null, "forum": "HJgepaNtDS", "replyto": "ryxs6AZ9jS", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Answer", "comment": "Dear reviewer,\n\nThank you again for your insights and questions.\n\n7)  Thank you for pointing this out. We updated the pdf accordingly. A bias of the order $10^{-3}$  has been added as it is done in [1] in order to compare with them. We then used the same bias for all the experiments. \n\n\n8) The learnability and flexibility indeed discard interpretations. On the other hand, compared to plain 1d CNN filter, we have filters that, for some experiments, resemble classical time-frequency atoms such as chirplet in the bird detection task. \n\n1)9)  Thank you for having brought into discussion this point. I understand and agree that the group theory section can be restricted and the overall approach simplified. We modified the PDF by restricting the group theoretical aspect to the equivariance section only and introducing more of the references your originally proposed. The other sections of the paper are now simplified and use the invertible transformation map point of view. \n\n\n\n\n[1]  Spline Filters For End-to-End Deep Learning, Randall Balestriero, Romain Cosentino, Herve Glotin, Richard Baraniuk\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "ryxs6AZ9jS", "original": null, "number": 6, "cdate": 1573686978971, "ddate": null, "tcdate": 1573686978971, "tmdate": 1573686978971, "tddate": null, "forum": "HJgepaNtDS", "replyto": "H1gfQCe9sH", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Answer", "comment": "Dear authors,\n\nThanks for your reply.\n\n7) OK. This should be explicit in the text, I think this is missing and extremely confusing. I've just realized it was in the Appendix, but I didn't check until now that a logarithm was incorporated as (to my understanding/knowledge) this is stated no-where and the caption of the Table should have been self-suffisant(it's written \"representation+linear classifier\") Has the logarithm a bias incorporated, i.e., does it behave as a thresholding? Is the threshold chosen through supervision? Was it critical?\n\n8) I think I understand this - but standard properties such as the fact to obtain an isometry, to avoid losing signal structures OR the trade-offs in bandwidth seem not really at the core of this paper. Instead, what is claimed(and that you just said) is that the supervision will find itself the best set of hyper-parameters(i.e., some implicit optimality assumption) - doesn't it also discard possible interpretations?\n\n1)9) A standard wavelet transform isn't built with randomly sampled elements of a group: the set of elements has in general a (finite/discrete) group structure (at least for 1D and 2D), in order to achieve equivariance. Sampling along the orbit of a group to obtain this structure isn't trivial at all or suffisant.(for instance there is no discrete approximation of 3D rotations by a discrete group) Those group structures are often necessary to obtain non-trivial invariants. Thus, I'm not sure that this method is specifically designed for group invariance via the scattering transform... but this is not the point of this paper.\n\nAgain, my concern is simply that the vocabulary/framework from group representations is neither fully used in this work nor necessary to describe the results of this paper. Restraining the theory to the action of a parametrized subset of diffeomorphism wouldn't hurt the (numerical and theoretical) results obtained here(in this paper). And there is a significant literature discussing this(cf my original review). Also, I'd like to recall that a group action on a vector space is simply a representation, but I think none of those specificity are used here."}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "H1gfQCe9sH", "original": null, "number": 5, "cdate": 1573682714141, "ddate": null, "tcdate": 1573682714141, "tmdate": 1573682714141, "tddate": null, "forum": "HJgepaNtDS", "replyto": "r1lr0HHtjr", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Reponse to review #2 (2)", "comment": "We thank you for your prompt reply and interest. \n\n1) 9)  Our approach aims at building a recipe allowing the learnability of the samples of a group governing the filterbank\u2019s orbit and derive its equivariance property. It is clear that this approach can be directly used, for instance, to develop learnable invariant representations a la Scattering Network by taking an averaging operator (or a max) over the samples of the group. Because of the representation theory formulation, we know that the filters are sampled along an orbit, and we know which point of such orbit has been sampled (via the parameters $(a_k,b_k)$). We can thus characterize the invariance by considering which sample has been learned on the orbit.  \n\n7)  In our setting, it was the linear transformation followed by a non-linearity. We meant a change of basis before the non-linearity. Without the non-linearity, we obviously agree that it will not alter the classification of the linear classifier.\n\n8) We agree that in some cases, this representation (WT) is best suited, as for many biological signals. However, given a signal and a specific task, it is not clear which representation and thus which time-frequency trade-off should be used. It usually requires expert knowledge of the features of interest in the signal or cross-validation. Having an adaptive representation allows alleviating this issue as it is empirically shown in the different experiments and especially in the artificial dataset.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "r1lr0HHtjr", "original": null, "number": 4, "cdate": 1573635533402, "ddate": null, "tcdate": 1573635533402, "tmdate": 1573635533402, "tddate": null, "forum": "HJgepaNtDS", "replyto": "S1xAJ69uiB", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Thanks for the precisions", "comment": "Dear authors,\n\nThanks, I've also read your revisions via the pdf comparisons. Some points are addressed.\n\n1) Again, the method which is developed in this paper can be summarized as: a/ parametrize a subset of the diffeomorphisms b/ consider its action on some mother wavelet(s) c/ learn the parameters. I do not understand which theoretical properties \"group representations\" bring, and this rebuttal didn't help me much to understand.\n\n3) Adding one reference sounds fine.\n\n4)5) Thanks.\n\n6) This is what I understood. Then, clearly, the group structure is not used in this \"theory\". The case of the dilation is specific: the action of scales \\{j\\in \\mathbb{N}\\}  on mother wavelets is a group, but due to aliasing issues, one has to sample them more. This indeed has no connexion with \"group theory\" but this is classical.\n\n7) Are you really stating that linear separability can be improved by a linear operator? Thanks for the reference about the STFT(I'm used to the name \"windows fourier transform\"), indeed, I got confused that one compares linear representations with a linear classifier. Am I misunderstanding something? I would appreciate a clarification.\n\n8) Thanks. All I meant, again, is that usually the adaptive bandwidth property of dilated wavelets is better suited for describing low/high frequencies structure of a signal, compared to the windows fourier transform for which a trade-off has to be done. Your sentence still suggests that this is a disadvantage of the wavelets transform, whereas I claim this is often an advantage... (page 93/109 of the aforementioned book)\n\n9) Cf 1). What are those \"insights\"? While I think this approach is interesting, I still believe it could be widely simplified."}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "SylIRA5uiB", "original": null, "number": 3, "cdate": 1573592782181, "ddate": null, "tcdate": 1573592782181, "tmdate": 1573592782181, "tddate": null, "forum": "HJgepaNtDS", "replyto": "BJgjzdW3KH", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Response to Review#1", "comment": "We thank the reviewer for his/her feedback. In the following, we answer each point separately, and we updated the paper accordingly.\n\n\u201d\u201d\u201dWhile in Section 3.2 the authors do explain the connections to the time-warping operation, they never explicitly justify why such a group is interesting.\u201d\u201d\u201d \n\n    ---> The last paragraph of the introduction is dedicated to such justification. We also added:\n\nThis specific transformation of a filter induces a non linear transformation of the instantaneous phase of the filter allowing to span filters a la chirplets. These filters are of interest in a variety of domains such as biology and medicine, mechanics and vibrations, and sonar systems [3], and especially in bird song.\n\n\u201d\u201d\u201dAt least, it is not clear why they are not interested in a semi-group of (non-strictly) increasing functions, which is more flexible and used in DTW.\u201d\u201d\u201d\n\n    ---> As we can see from the experiments, for some cases, the LGT model is too flexible, and adding some constraints (nLGT,cLGT,cnLGT) on the transform helps to increase the accuracy. As such, more flexibility might require even more constraints on the model, and thus we did not consider it here.\n\n\u201d\u201d\u201dThe authors implement the more general group using piece-wise linear functions, which makes enforcing the strictly increasing property easier. This idea is nice, however I am concerned with speed of such transformations in practice. Unfortunately the authors do not report runtime numbers in the experiments.\u201d\u201d\u201d\n\n    ---> In practice, a piecewise linear function can be implemented by a single layer Neural Network with ReLU units. As such, the training can be achieved efficiently.\n\n\u201d\u201d\u201dWhile the paper has verbose and wordy writing, it also spends a major part of the paper describing the common knowledge about group theory and wavelets.\u201d\u201d\u201d\n\n    ---> In the updated version, we simplified some of the writings and reduced the background section. \n\n\u201d\u201d\u201dInstead, some crucial design decisions are not well-justified. For example, the description of the constraints in cLGT suddenly appears.\u201d\u201d\u201d\n\n    ---> Thanks for the comment. We adjusted the revised paper, and the justifications of the different constraints can be found in section 3.4.\n\n\u201d\u201d\u201dThere are several major problems in the experiments. First, the results in Tables 1 and 2 do not seem to be statistically significant and Table 3 does not have the intervals.\u201d\u201d\u201d\n\n    ---> For the benchmarks, we proposed to compare it with already existing methods. To do so, we use the same experimental and evaluation procedures as the original published works in NIPS2018 and ICML2018. Also, we do not claim to have a statistically significant improvement across the dataset as the experiments are achieved in order to perform a model comparison. As such, in Table 3, there are no intervals since the method applied for the different benchmarks uses early stopping on the valid set. \n \n\u201d\u201d\u201dSecond, the Haptics dataset is too small. Also, choosing a single dataset from the UCR sets only sends the message that this dataset is one of the few datasets on which the algorithm has worked better.\u201d\u201d\u201d\n\n    ---> We recall that the bird detection dataset contains about 20 hours of audio signal. As such, the bird detection task aims at comparing it with a learnable mother filter method (ICML2018) and the UCR dataset with the article that is the closest to our work (NIPS2018). Finally, the toy example is here to build intuitions. For each dataset, there is a specific level of knowledge regarding the filters: 1) (bird) large dataset with expert knowledge, 2) (UCR) small dataset with no expert knowledge, 3) (toy example) small dataset with perfect knowledge. Thus, we believe that these three datasets are sufficient to compare and show the efficiency of the developed algorithm.\n\n\u201d\u201d\u201dOther than improving the experiments, the authors can significantly improve the writing by decreasing the emphasis on the background knowledge and elaborating more on the new proposed ideas.\u201d\u201d\u201d\n\n    ---> In the updated version, we reduced the emphasis on the background knowledge, especially we moved the wavelet example in the appendix, and offered more analysis regarding the method and its results. \n\n[3] P. Flandrin. Time frequency and chirps. In Wavelet Applications VIII,\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "rJxUSAqOsS", "original": null, "number": 2, "cdate": 1573592637844, "ddate": null, "tcdate": 1573592637844, "tmdate": 1573592637844, "tddate": null, "forum": "HJgepaNtDS", "replyto": "r1gr5RqnYH", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Reponse to Review #3", "comment": "We thank the reviewer for his/her feedback. In the following, we answer each point separately, and we updated the paper accordingly.\n\n\"\"\"I do wonder, however, what the interpretation is behind some of the learned LGTs(...)\u201d\u201d\u201d\n\n    ---> For any learned transformation, we use a convolution of the filter with the signal; it is thus a shift-covariant transformation. Besides, wavelet transforms are dilation-covariants. In our case, if the transformation learned is affine, we recover such covariance. However, if the transformation is non-linear, we are losing this covariance property. We updated the paper to make these points clear in section 3.5 Group Equivariance.\n\n\u201d\u201d\u201dExperimentally, I think there was a nice selection of toy and harder examples (...) more analysis of the interpretation of the learned LGT in the main text though.\u201d\u201d\u201d \n\n    ---> Thank you for this input, we updated the paper accordingly.\n\n\u201d\u201d\u201dThe explanation of what a group is is quite high-level (...), homomorphisms are mentioned. I would guess that someone who has never seen a group beforehand, would have no idea about homomorphisms.\u201d\u201d\u201d \n\n    ---> We have revised the paper accordingly (sec 2.2) to make this point more intuitive and reduced the emphasis on the homomorphism.\n\n\u201d\u201d\u201dIn equation 6, is \\star a convolution or a cross-correlation? It looks like a cross-correlation to me.\u201d\u201d\u201d \n\n    ---> We updated the notations so that it corresponds to a convolution\n\n\u201d\u201d\u201dWould it be possible to move some of the material on the learned filter transformations to the main text and write some analysis, even if it is only qualitative? I would find that fascinating.\u201d\u201d\u201d\n\n    ---> We proposed a qualitative analysis of Figure 4 as well as includes more filters for the bird detection experiment. For the filters, we offer these qualitative aspects:\n         One can notice that all the learned filters in Figure 5 contain either an increasing chirp or a decreasing chirp, corresponding respectively to the convexity or concavity of the instantaneous phase of the filter and thus of the piece-wise linear map. Such a feature is being used and is crucial in the detection and analysis of bird song [2]. \n\n[2] D. Stowell and M. D Plumbley. Framewise heterodyne chirp analysis of birdsong.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "S1xAJ69uiB", "original": null, "number": 1, "cdate": 1573592294409, "ddate": null, "tcdate": 1573592294409, "tmdate": 1573592294409, "tddate": null, "forum": "HJgepaNtDS", "replyto": "r1xHWpnatr", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment", "content": {"title": "Response to review#2", "comment": "We thank the reviewer for his/her feedback. In the following, we answer each point separately, and we updated the paper accordingly.\n\nAnswers to the \"Cons\" section:\n\n1) We added in Section 3 the equivariance property of the group where we make use of the representation formulation. Besides, our formulation is required to develop theoretical insights regarding these learnable filters, such as the Haar measure (although in our case, it should be a quasi-invariant measure instead of an invariant). From this measure, we can look for constraints to build a resolution of the identity. Recently, the theoretical study of such a non-uniform filter bank has been investigated in [1] from a frame theory approach. Our framework enables the development of such a theory from a coherent state (representation theory) point of view. We made this clear in Section 2.\n\n2) We added some of the papers you mentioned in the new paragraph on the equivariance properties of the group in Section 3. \n\n3) We performed the experiments with four different settings. We updated the paper to emphasize the following points:\nThe case without constraints (LGT) reaches better accuracy than the domain expert benchmark (MFSC).\nIncluding more constraints on the model (cnLGT) reduces overfitting and further improves the results to outperform the other benchmarks.\n\n4) Thanks for your input on this, it has been corrected in the updated version.\n\n5) We updated Figure 2 to improve its clarity.\n\n 6) As we mentioned, we do not propose to approximate G_inc but to sample it. Increasing piecewise linear functions do not form a group under the composition operation. In the same way that WT uses the dyadic sequence $\\left \\{1,\\dots,2^{j/Q}, j \\in \\left \\{0,\\dots, J \\times Q -1 \\right \\} \\right \\}$ to sample the dilation parameter of the affine group while this discretization does not form a group under the multiplication operation.\n\n7)        -As you know, STFT is a linear time-frequency transform as opposed to the Spectrogram which is the square modulus of the STFT. Please refer to A wavelet tour of signal processing, S. Mallat, for more details. \n        \n            -We are not clear about your point. All those different groups transform correspond to representing the data in a new \u201cbasis,\u201d then each new \u201cbasis\u201d will impact the linear separability of the data and thus the linear classifier performances. \n\n8)        -The Heisenberg uncertainty principle is optimal for the Gabor    transform, which is a special case of STFT with a Gaussian window. Then for the wavelet transform, the area of each tile will depend on the wavelet family and parameterization.\n          -As you know, in the case of WT, the area of the tiles remains the same, but the resolution in time and frequency depends on the dilation parameter. That is, the constant ratio bandwidth to center frequency of the wavelet filters implies that high-frequency filters will have \u201cpoor\u201d frequency resolution and \u201chigh\u201d time resolution. For STFT, the window is the same across the time-frequency plane leading to filters with the same time and frequency resolution. We updated the paper to make that clear.\n\n9) We focused on giving insights from the group theory formulation as it is one of the primary building blocks to create a time-frequency transform. Besides, as we believe that there is no paper in the machine learning community discussing this approach for learnable time-frequency transformation, it is essential to explain it in detail. We updated the article to provide more insights on the experiments from a signal processing point of view.\n\n10) The typos have been corrected.\n\n[1] Continuous warped time-frequency representations - Coorbit spaces and discretization, N. Holighaus et al.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJgepaNtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper806/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper806/Authors|ICLR.cc/2020/Conference/Paper806/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165935, "tmdate": 1576860532299, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper806/Authors", "ICLR.cc/2020/Conference/Paper806/Reviewers", "ICLR.cc/2020/Conference/Paper806/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Comment"}}}, {"id": "r1gr5RqnYH", "original": null, "number": 2, "cdate": 1571757709153, "ddate": null, "tcdate": 1571757709153, "tmdate": 1572972549988, "tddate": null, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "*Paper summary* \n\nThe authors design a learnable time-series pre-processing, which they refer to as a learnable group transform (LGT). This is a generalization of the wavelet transform, which maps a time-series signal onto the affine group. In the wavelet transform, multiple scaled and shifted versions of a mother wavelet are \"inner-producted\" with a signal; the resulting coefficents are the output of the transform. In the LGT, a more flexible transform that just scaling and shifting is applied to the shape of the mother wavelet, which is piece-wise linearly stretched. This elegantly encompasses time-warping and many other wavelet-style transforms into one learnable preprocessing step.\n\n*Paper decision* \n\nI would like to recommend this paper be accepted. It is clearly written and the idea is simple; that said, the idea is an elegant generalization of the wavelet transform. (I admit my own expertise is not in time-series data, so I may be mistaken). The experiments are also simple, but straightforward and easy to reimplement.\n\n*Supporting arguments* \n\nWhat I like about this paper is that the idea is a straightforward generalization of the wavelet transform through the lens of group theory. Furthermore, other transforms, such as the short-time fourier transform, or methods such as time-warping are easily encompassed by the method. By making the transform learnable, the authors reduce the number of in-built assumptions in the problem. \n\nI believe the idea is novel; although, since this is not my area of expertise, I defer to other reviewers who may wish to contest this.\n\nI do wonder, however, what the interpretation is behind some of the learned LGTs. Typically, a group transform is favored because of certain symmetry properties of the task at hand. For instance, wavelet transforms are shift-covariant, reflecting the shift-covariance of underlying signal statistics.\n\nExperimentally, I think there was a nice selection of toy and harder examples. I found the visualized filters and group transforms in the appendix really interesting. I think it would have been nicer to see some more analysis of the interpretation of the learned LGT in the main text though. Further, it would have been nicer to see some ablation studies conducted, such as varying the number of degrees of freedom in the LGT and seeing how that affects performance.\n\n\n*Smaller questions/notes for the authors*\n\n- The explanation of what a group is is quite high-level and I think if you did not know what it was beforehand, it would be hard to understand what one is. For instance, just after introducing groups, homomorphisms are mentioned. I would guess that someone who has never seen a group beforehand, would have no idea about homomorphisms.\n\n- In equation 6, is \\star a convolution or a cross-correlation? It looks like a cross-correlation to me.\n\n- I really liked the connection drawn between the group transform and time-warping. This is an aspect I personally had never considered.\n\n- Would it be possible to move some of the material on the learned filter transformations to the main text and write some analysis, even if it is only qualitative? I would find that fascinating.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575668338342, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper806/Reviewers"], "noninvitees": [], "tcdate": 1570237746733, "tmdate": 1575668338355, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Review"}}}, {"id": "BJgjzdW3KH", "original": null, "number": 1, "cdate": 1571719187423, "ddate": null, "tcdate": 1571719187423, "tmdate": 1572972549939, "tddate": null, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper defines a set of learnable basis functions and a joint learning algorithm to estimate them. It is based on the premise that the common learning approach in time-series is to first represent them in some spectral domain; thus, the main problem is to define and estimate the basis functions. However, this premise is not accurate and many learning algorithms operate just in the actual time domain (even in speech).\n\nThe paper advocates for a special group of strictly increasing transformations of the basis functions. While in Section 3.2 the authors do explain the connections to the time-warping operation, they never explicitly justify why such a group is interesting. At least, it is not clear why they are not interested in a semi-group of (non-strictly) increasing functions, which is more flexible and used in DTW.\n\nThe authors implement the more general group using piece-wise linear functions, which makes enforcing the strictly increasing property easier. This idea is nice, however I am concerned with speed of such transformations in practice. Unfortunately the authors do not report runtime numbers in the experiments.\n\nWhile the paper has verbose and wordy writing, it also spends a major part of the paper describing the common knowledge about group theory and wavelets. Instead, some crucial design decisions are not well-justified. For example, the description of the constraints in cLGT suddenly appears.\n\nThere are several major problems in the experiments. First, the results in Tables 1 and 2 do not seem to be statistically significant and Table 3 does not have the intervals. Second, the Haptics dataset is too small. Also, choosing a single dataset from the UCR sets only sends the message that this dataset is one of the few datasets on which the algorithm has worked better.\nOverall, the key message out of the experiments is that if you project the data to a parameterized basis set and constrain the parameters, you will get better generalization, which is not very novel. \n\nOther than improving the experiments, the authors can significantly improve the writing by decreasing the emphasis on the background knowledge and elaborating more on the new proposed ideas."}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575668338342, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper806/Reviewers"], "noninvitees": [], "tcdate": 1570237746733, "tmdate": 1575668338355, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Review"}}}, {"id": "r1xHWpnatr", "original": null, "number": 3, "cdate": 1571831037211, "ddate": null, "tcdate": 1571831037211, "tmdate": 1572972549894, "tddate": null, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "invitation": "ICLR.cc/2020/Conference/Paper806/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "A typical Wavelet Transform is built through the dilation and/or rotation of a mother wavelet, which can been viewed as a group action on a mother wavelet. This work proposes to extend this construction beyond the Euclidean group, and to supervisedly learn operators that will be applied on a mother wavelet. Competitive numerical performances are obtained.\n\nOverall, I think that re-thinking the way a Wavelet Transform is designed, is an interesting direction of research, but I think some of the theoretical tools developed in this paper are not dedicated to achieve this purpose. In particular, the group/representation properties seem to not be used, and the authors could simply consider a specific subset of invertible mapping on $\\mathbb{R}^2$ which would be applied on the mother wavelet and lead to a Wavelet Transform. In other words, the overall formulation could be simplified.\n\n\nPros:\n- In general, the numerical experiments are at the level of the state of the art.\n- Parametrizing a subset of the group of increasing function and its application to signal processing tools is novel, to my knowledge.\n\nCons:\n- Some very relevant elements in the literature review are missing. Learning or using an underlying group of symmetry that will be combined with a deep neural network is not novel, cf: https://arxiv.org/abs/1601.04920 ; in particular for reducing the number of parameters, filters or samples: https://arxiv.org/abs/1809.06367 ; http://proceedings.mlr.press/v48/cohenc16.pdf ; https://arxiv.org/abs/1809.10200 ; https://arxiv.org/abs/1605.06644 - I think the authors should discuss at least one or two of those papers, if not all.\n- The performance on the bird detection task is good but the improvement compared to other work is not clear, given that some supervision in the first layer is incorporated.\n- Subsections 2.2 and 2.3 are difficult to parse because the authors introduce a lot of equations or notion that are not useful to understand their algorithm/method. The equation (6) seems wrong to me (one should consider t->s_i(-t) and not t->s_i(t) and b seems missing in the second line).\n- Figure 2 is difficult to read because of the illustrative graphics. Maybe a block schema would be easier to parse.\n- It seems to me that no-where the group properties are used, such as the stability to composition. In this paper, the authors simply try to parametrize a diffeomorphism to dilate the mother wavelet. From my understanding of 3.3, the subset of function used to approximate $G_{inc}$ do not form a subgroup as well, contrary to the Euclidean case, where for instance discrete rotations in the case of images are a finite group.\n- In subsection 4.1(Table 1), a comparison with a wavelet transform followed by a linear operator is compared with the proposed method. I find this result surprising :\u2028LGT/nLGT/cLGT/cnLGT and the WT are some linear methods whereas the STFT is non linear. As the WT should be unitary, if the linear classifier method is reasonably trained, then both methods should lead to the same result, except if the data are poorly conditioned. In which case, this experiment would not be meaningful. I think the authors should comment more this result because it is surprising.\n- I slightly disagree with the sentence \"in the case of WT, the precision in frequency degrades as the frequency increases\". Actually, the heisenberg principle is optimally optimized by wavelets, meaning that the area of the frequency/spatial support on a spectrogram is constant. On the contrary, the STFT has a lack of localisation (and thus the \"precision\" is not constant along frequencies). Maybe this could be rephrased slightly.\n- Given the filter learned in Figure 5, one can wonder if a foveal approach (i.e., Foveal Wavelets) could perform similarly? It would be interesting to display the littlewood-paley plot(i.e., the sum of the modulus of the filters in the Fourier domain) of this representation to understand the nature of this operator in the Fourier domain.\n- I think group actions could be considered instead of representations: it would be simpler to understand for a potential reader.\n\nTypos: \n- abstract \"in order to transform the mother ..\" > \"in order to transform a mother..\"\n- page 7 \"this variation is as not captured as well\" > \"this variation is not captured as well\".\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper806/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnable Group Transform For Time-Series", "authors": ["Romain Cosentino", "Behnaam Aazhang"], "authorids": ["rc57@rice.edu", "aaz@rice.edu"], "keywords": ["Group Transform", "Time-Frequency Representation", "Wavelet Transform", "Group Theory", "Representation Theory", "Time-Series"], "abstract": "We propose to undertake the problem of representation learning for time-series by considering a Group Transform approach. This framework allows us to, first, generalize classical time-frequency transformations such as the Wavelet Transform, and second, to enable the learnability of the representation. While the creation of the Wavelet Transform filter-bank relies on the sampling of the affine group in order to transform the mother filter, our approach allows for non-linear transformations of the mother filter by introducing the group of strictly increasing and continuous functions. The transformations induced by such a group enable us to span a larger class of signal representations. The sampling of this group can be optimized with respect to a specific loss and function and thus cast into a Deep Learning architecture. The experiments on diverse time-series datasets demonstrate the expressivity of this framework which competes with state-of-the-art performances.", "pdf": "/pdf/6cae6bbacca6012f5cab4bf0c3ff2cd455769c70.pdf", "paperhash": "cosentino|learnable_group_transform_for_timeseries", "original_pdf": "/attachment/f28f0371bad7b912878dadb47f587b2530abb9d4.pdf", "_bibtex": "@misc{\ncosentino2020learnable,\ntitle={Learnable Group Transform For Time-Series},\nauthor={Romain Cosentino and Behnaam Aazhang},\nyear={2020},\nurl={https://openreview.net/forum?id=HJgepaNtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJgepaNtDS", "replyto": "HJgepaNtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper806/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575668338342, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper806/Reviewers"], "noninvitees": [], "tcdate": 1570237746733, "tmdate": 1575668338355, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper806/-/Official_Review"}}}], "count": 14}