{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488588000544, "tcdate": 1478290121959, "number": 421, "id": "B1MRcPclx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1487965870845, "tcdate": 1487965723990, "number": 10, "id": "B1V7CZRYe", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Revised on 24 Feb 2017", "comment": "Final version uploaded:\n- fixed typos\n- more spacious formatting\n- added acknowledgments"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396573561, "tcdate": 1486396573561, "number": 1, "id": "r1Io2zUOl", "invitation": "ICLR.cc/2017/conference/-/paper421/acceptance", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper proposes a simple recurrent architecture for question-answering, achieving good performance on several reasoning benchmarks. All three reviewers agree on the merit of the contribution.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396574082, "id": "ICLR.cc/2017/conference/-/paper421/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396574082}}}, {"tddate": null, "tmdate": 1484981541797, "tcdate": 1484981541797, "number": 9, "id": "BJ07BKlDe", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Revised on 20 Jan 2017", "comment": "- Added joint training result for bAbI QA 1k (in Appendix A Table 2)\n- Retouched the explanations of \"query-reduction\" in Section 1 and 2.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1484863335882, "tcdate": 1482202653340, "number": 3, "id": "BkBmAGL4g", "invitation": "ICLR.cc/2017/conference/-/paper421/official/review", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer2"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "The paper proposed a simple and effective model for QA. The paper is easy to read and result is impressive on the synthetic and real dataset. The one question is the paper is called query-reduction, but there is no place to show this reduction explicitly.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512593048, "id": "ICLR.cc/2017/conference/-/paper421/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer1", "ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512593048}}}, {"tddate": null, "tmdate": 1483414538921, "tcdate": 1483414538921, "number": 8, "id": "SyQz39_Sx", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Our response to the reviews of R1, R2, and R3", "comment": "We thank all reviewers for supporting our paper! We also thank them for their insightful suggestions and comments that have improved our paper.\n\nR1: We will add the training results for all tasks simultaneously in the upcoming revision.\n\nR2: We will explicitly clarify the \u201creduction\u201d in the upcoming revision.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1482181247923, "tcdate": 1482181247923, "number": 2, "id": "r1OKc6B4l", "invitation": "ICLR.cc/2017/conference/-/paper421/official/review", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer3"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "The paper proposes a simplistic recurrent architecture that has a very small temporal dependence in its definition (which, in turn, allows it to be parallelized across the temporal axis). Paper is clear to follow, the architecture has appropriate motivation and the experiments seem to be very thorough and over an appropriate range of synthetic and real datasets. Results are very impressive on its own especially considering the simplicity of the model. Activation and gate visualizations are informative. Overall, the work is sufficient as a conference contribution.\n\nI appreciate the effort by authors in responding to questions and incorporating revisions.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512593048, "id": "ICLR.cc/2017/conference/-/paper421/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer1", "ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512593048}}}, {"tddate": null, "tmdate": 1481969705290, "tcdate": 1481969663467, "number": 1, "id": "B1DWg9f4x", "invitation": "ICLR.cc/2017/conference/-/paper421/official/review", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer1"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "This work introduces a new RNN model and shows how it can be used for QA in bAbI-like settings.  I think the model is simple and interesting, and the results are strong.  I would like the authors to also show results training on all tasks simultaneously, but other than that, I think it is an interesting model and it is nicely described and tested. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512593048, "id": "ICLR.cc/2017/conference/-/paper421/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer1", "ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512593048}}}, {"tddate": null, "tmdate": 1481861820257, "tcdate": 1481861131324, "number": 7, "id": "BkXz_kZ4l", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "Bk5Za0gEl", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "10k best result: 10 random seeds", "comment": "Hi Mikael,\nThank you for your suggestion! In fact, the best performing result (6 layers, avg error 0.3%) was obtained with 10 random seeds. We did not change \"50\" in the paper because other setups (e.g. 2 layer and 3 layer models) were obtained with 50 random seeds. We will soon report these results with 10 random seeds instead and change the number in the paper as well.\n\nAs an answer to your question, we did not observe much difference between results with 10 random seeds and 50 random seeds. Unfortunately we do not have a record of the difference; perhaps we can try 6-layer model with 50 random seeds to quantify the gain. But we agree that number of seeds should be similar for fair comparison, and we will stick to 10 random seeds now on."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1481858306280, "tcdate": 1481858306280, "number": 6, "id": "Bk5Za0gEl", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Mikael_Henaff1"], "readers": ["everyone"], "writers": ["~Mikael_Henaff1"], "content": {"title": "Number of seeds", "comment": "Hi, \n\nI noticed that on the 10k bAbI tasks you take the best out of 50 random seeds, whereas the methods you compare against use less (MemN2N: 10, DMN+: 10, GMemN2N: 30, DNC: 20). What is the performance difference between using 50 seeds vs. using 10? Ideally, it seems that as a community we should agree on a maximum number of seeds allowed for these tasks to make the comparison fair."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1481691041764, "tcdate": 1481691041756, "number": 5, "id": "B19jJLAQe", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1x2xLpXl", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Our response to R1's question", "comment": "We trained the same architecture for each task independently. Thank you for pointing this out and we will explicitly mention this in our next revision of the paper.\n\nSukhbaatar et al. (2015) try both taskwise and joint training and the better result is taken; in bAbI QA 1k, joint training performs better (by 1.5%), and in 10k, taskwise training performs better (by 0.9%). Xiong et al. (2016a) and Perez and Liu (2016) report taskwise results only. Graves et al. (2016) report joint result on 10k only.\n\nIn case the reviewer is interested in how our model performs in joint training setting, we are currently running the experiments and will report them once they are available. Please note that 10k joint training will take a considerable amount of time."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1481625768410, "tcdate": 1481625768403, "number": 3, "id": "B1x2xLpXl", "invitation": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer1"], "content": {"title": "all tasks simultaneous?", "question": "Do you train one model for all of the tasks, or is it the same architecture for each task, but a different model?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481625768884, "id": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2", "ICLR.cc/2017/conference/paper421/AnonReviewer1"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481625768884}}}, {"tddate": null, "tmdate": 1481240272054, "tcdate": 1481240272047, "number": 4, "id": "rJd00wwQe", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "S1Hbr_yXl", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Our response to R2's questions", "comment": "Thank you for your questions!\n\n#1\nFirst, please note that we have shown in \u2018interpretations\u2019 in Section 5.3 that we could decode the reduced query vectors to the desired natural language sentences in some tasks. We are not sure if we completely understand reviewer\u2019s question. \n\nIf the reviewer means \u201ccan we guarantee that the reduced query is easier to answer\u201d, we agree that the word \u201ceasier\u201d could be misleading and we used it for high-level intuition. It is probably more accurate to say the reduced query becomes \u201cmore informed\u201d of the story as it observes each trigger through time.\n\nIf the reviewer means \u201cis the query being updated by each trigger at all\u201d, this must be the case since we only use the last reduced query (hidden state) of QRN to answer. Hence the reduced query must have been updated to incorporate all necessary information from the story. \n\nIf the reviewer means \u201chow such a simple MLP can semantically reduce the query\u201d, please note that our reduce function can be an arbitrary function depending on the application, and we just show one simple example that works well on the datasets. QRN is not about how to define the reduce function, but rather how to connect the components (reduce function, update gate, previous hidden state, etc.) together so that each component is inclined to learn its role correctly. We hypothesize that the simplification of the recurrent update helps each component to learn more easily.\n\n\n#2\nThank you for suggesting an important citation that we missed.\nWe just updated the related work, and here we write what we added to it.\n\nQRN can be distinguished from Strongly-Typed Recurrent Neural Networks (STRNN) in three ways. First, QRN\u2019s update gate simulates attention mechanism, measuring the relevance between the input sentence and query. On the other hand, the gates in STRNN can be considered as the simplification of LSTM/GRU by removing their dependency on previous hidden state. Second, QRN is an RNN that is natively compatible with context-based QA tasks, where the QRN unit accepts two inputs, i.e. each context sentence and query. This is different from STRNN which has only one input. Third, we show that QRN is timewise-parallelizable on GPUs. Our parallelization algorithm is also applicable to STRNN.\n\nOur work is similar to STRNN in that the gates and the candidate hidden states do not depend on the previous hidden state, which simplifies the recurrent update. We believe many of the benefits due to the simplification mentioned in STRNN paper are also applicable to QRN (some of them are already discussed in the paper)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1481240194899, "tcdate": 1481240194892, "number": 3, "id": "ryoK0ww7g", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "HJ2onWRzl", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Our response to R3's question", "comment": "Thank you for your question!\n\nWe first define a term \u201crelevance\u201d, to be distinguished from \u201cattention\u201d, to better explain the difference between sigmoid attention and softmax attention.\n\n\u201cRelevance\u201d between the query and a sentence is the absolute measure of whether the sentence is relevant to the query.\n\nThe \u201cattention\u201d weight of a sentence by the query is whether the sentence is ultimately used to get the correct answer of the query with regards to the entire story.\n\nAn \u201cattended\u201d sentence is always a \u201crelevant\u201d sentence to the query, but a \u201crelevant\u201d sentence might not be \u201cattended\u201d for the final answer. For instance, consider the top-left table (task 2) of Figure 3. The first three sentences are all relevant to the query, but only the third sentence is useful for the final answer.\n\nWith these terms defined, the update gate in QRN only measures the relevance between the query and each sentence. The sigmoid \u201cattention\u201d of each sentence is controlled by the recurrent update of the hidden state with the update gate. This means that sigmoid attention can perform time-based (address-based) attention (memory access) by differentiating similar sentences at different time steps. Hence the sigmoid attention is able to just attend on the third sentence even though they are all equally relevant to the query.\n\nOn the other hand, vanilla softmax attention mechanism is unable to distinguish between \u201crelevance\u201d and \u201cattention\u201d. That is, the first three sentences in task 2 (top left) of Figure 3 will be equally attended (e.g. 0.3 each). In other words, vanilla softmax attention cannot distinguish similar sentences at different time steps."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1481240137472, "tcdate": 1481240137466, "number": 2, "id": "HkbURDDml", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Revised on 8 Dec 2016", "comment": "What have changed:\n- Related work now includes discussions about previous work that R2 mentioned\n- \"easier-to-answer\" to \"more informed\" in abstract, after R2's comment\n- bAbI 10k results average error improved from 0.7 to 0.3 with repeating the training procedures 10+ times (previously only 5 times, see 'Training' in Section 5.2)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}, {"tddate": null, "tmdate": 1480717565495, "tcdate": 1480717565430, "number": 2, "id": "S1Hbr_yXl", "invitation": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer2"], "content": {"title": "Clarification on query-reduction", "question": "1. The paper mentioned that 'reduces the original query to an easier-to-answer query as it observes each trigger (context sentence) through time', I do not get the point why the model could have this ability. \n2. The model is similar to strong-typed RNN with question as another input in ICML 2016, you also should cite this paper -- \"Strongly-Typed Recurrent Neural Network\"."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481625768884, "id": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2", "ICLR.cc/2017/conference/paper421/AnonReviewer1"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481625768884}}}, {"tddate": null, "tmdate": 1480625316132, "tcdate": 1480625316128, "number": 1, "id": "HJ2onWRzl", "invitation": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["ICLR.cc/2017/conference/paper421/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper421/AnonReviewer3"], "content": {"title": "Clarification on local vs global attention", "question": "I am impressed by the results compared to the simplicity of the model.\n\nYou mention that the difference between your update gates and the softmax gating in previous work is that it gives local sigmoid attention computed only on the current memory. However when you unfold the recursion in eqn 3, multiplication of z_t or (1-z_t) values throughout time will act like weights to a weighted average across all memory (summing up to 1). Is that not very similar to a softmax gating, just that it uses a different function to compute the attention weights? And uses the same parameters that the softmax would use? I am not sure if that is a significant difference. Please clarify if I'm missing anything here."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481625768884, "id": "ICLR.cc/2017/conference/-/paper421/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper421/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper421/AnonReviewer3", "ICLR.cc/2017/conference/paper421/AnonReviewer2", "ICLR.cc/2017/conference/paper421/AnonReviewer1"], "reply": {"forum": "B1MRcPclx", "replyto": "B1MRcPclx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper421/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481625768884}}}, {"tddate": null, "tmdate": 1479289658101, "tcdate": 1479289658096, "number": 1, "id": "HJGHjjtWe", "invitation": "ICLR.cc/2017/conference/-/paper421/public/comment", "forum": "B1MRcPclx", "replyto": "B1MRcPclx", "signatures": ["~Minjoon_Seo1"], "readers": ["everyone"], "writers": ["~Minjoon_Seo1"], "content": {"title": "Revised on Nov 16", "comment": "About revision:\n- improved result on bAbI QA 10k (3.2% -> 0.7%)\n- retouched the wording of some paragraphs, fixed typos"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Query-Reduction Networks for Question Answering", "abstract": "In this paper, we study the problem of question answering when reasoning over multiple facts is required. We propose Query-Reduction Network (QRN), a variant of Recurrent Neural Network (RNN) that effectively handles both short-term (local) and long-term (global) sequential dependencies to reason over multiple facts. QRN considers the context sentences as a sequence of state-changing triggers, and reduces the original query  to a more informed query as it observes each trigger (context sentence) through time. Our experiments show that QRN produces the state-of-the-art results in  bAbI QA and dialog tasks, and in a real goal-oriented dialog dataset. In addition, QRN formulation allows parallelization on RNN's time axis, saving an order of magnitude in time complexity for training and inference.  ", "pdf": "https://arxiv.org/pdf/1606.04582.pdf", "paperhash": "seo|queryreduction_networks_for_question_answering", "keywords": ["Natural language processing", "Deep learning"], "conflicts": ["washington.edu", "allenai.org"], "authors": ["Minjoon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi"], "authorids": ["minjoon@cs.washington.edu", "shmsw25@snu.ac.kr", "ali@cs.washington.edu", "hannaneh@cs.washington.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287584454, "id": "ICLR.cc/2017/conference/-/paper421/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1MRcPclx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper421/reviewers", "ICLR.cc/2017/conference/paper421/areachairs"], "cdate": 1485287584454}}}], "count": 18}