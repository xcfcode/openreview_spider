{"notes": [{"id": "BkgnhTEtDS", "original": "r1eguNeODB", "number": 795, "cdate": 1569439155616, "ddate": null, "tcdate": 1569439155616, "tmdate": 1583912051869, "tddate": null, "forum": "BkgnhTEtDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "-2oG8guO3X", "original": null, "number": 1, "cdate": 1576798706298, "ddate": null, "tcdate": 1576798706298, "tmdate": 1576800929898, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The paper extracts feature interactions in recommender systems and studies the effect of these interactions on the recommendations. While the focus is on recommender systems the authors claim that the ideas can be generalised to other domains also. \n\nAll reviewers found the empirical results and analysis thereof to be very interesting and useful. This paper saw a healthy discussion between the authors and reviewers and all reviewers agreed that this paper makes a useful contribution. I recommend that the authors address all the concerns of the reviewers in the final version of the paper. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795718577, "tmdate": 1576800269081, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper795/-/Decision"}}}, {"id": "rklPOdey9H", "original": null, "number": 2, "cdate": 1571911791113, "ddate": null, "tcdate": 1571911791113, "tmdate": 1573879170544, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "The paper proposes a method to detect which features in the input of recommender systems are interacted each other, i.e., combining them behaves useful information, and examines to feed extracted interactions directly into the recommender systems to measure effects on actual recommendation.\n\nThe interaction detector consists of 1. perturbing the input vectors,  2. training NNs to utilize its internal non-linear representation as a signal of interaction, and 3. aggregating detected interactions over training set. 1. and 2. are consisting of known methods so that the proposed method is an application of them. For 3. authors introduced a simple heuristic (Algorithm 1).\n\nAs long as I heard how the NID work to detect interaction from this paper, it is sensitive not only the true interaction between features but also set of features holding similar signals (e.g., if a hidden unit behaves as a feature A, it may be natural to aggregate all features that implies A by itself, regardless of the meaning of their interaction). This is not a desired case as long as the paper specified the interactions in section 3. Maybe it requires more detailed explanation about how good applying NID for this task is.\n\nExperiments are conducted to show the behavior of the interaction detector and actual improvement of utilizing extracted interactions as additional features. Experiments look less informative for comparing the proposed method with other existing methods for similar motivations (e.g., some methods introduced in related work) since there is only a trivial baseline by the original LIME's method.\n\nIn the case-study of Figure 4(b), I thought that the proposed method is a bit biased for frequent but meaningless features, because it detected \"I\" or \"a\" that intuitively occur with any labels. It is maybe because the Algorithm 1. that simply aggregates all detected interactions regardless of their actual importance. For further improvement, it may be necessary to introduce some weighting strategy to detected interactions.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576070908317, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper795/Reviewers"], "noninvitees": [], "tcdate": 1570237746959, "tmdate": 1576070908334, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Review"}}}, {"id": "SyeDbrwtir", "original": null, "number": 3, "cdate": 1573643518745, "ddate": null, "tcdate": 1573643518745, "tmdate": 1573809734317, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "HklcwLdRFr", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment", "content": {"title": "Author Response", "comment": "Thank you for your supportive comments. We clarified the meanings of p, d and the I symbol, and we fixed the typos.\n\nWe are very grateful that you recognize value in this work. Interpretability research has made progress in both theoretical and applied topics. Indeed this work is in the applied category. One of the focuses on the applied research end has been interpreting black-box models [1,2,3,4], which gave us strong motivation to study this direction. A glaring gap in this direction was the lack of discourse on interpreting feature interactions, which are important as we showed in experiments. We could not stop there, so we investigated how to leverage these interpretations: a type of problem that very few interpretability works have studied, especially for improving predictions automatically.\n\n\n[1] Marco Ribeiro, Sameer Singh, Carlos Guestrin. Why should I trust you?: Explaining the predictions of any classifier. In Proceedings of KDD, 2016.\n[2] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, Rory Sayres. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In Proceedings of ICML, 2018.\n[3] Pang Wei Koh, Percy Liang. Understanding black-box predictions via influence functions. In Proceedings of ICML, 2017.\n[4] Christoph Molnar. Interpretable machine learning. A guide for making black box models explainable. 2019.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper795/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgnhTEtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper795/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper795/Authors|ICLR.cc/2020/Conference/Paper795/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166101, "tmdate": 1576860541393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment"}}}, {"id": "Bker94DYoH", "original": null, "number": 2, "cdate": 1573643404628, "ddate": null, "tcdate": 1573643404628, "tmdate": 1573643404628, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "rklPOdey9H", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment", "content": {"title": "Author Response", "comment": "Thank you for your comments and observations. We address them below:\n\n>> \u201cit is sensitive not only the true interaction between features but also set of features holding similar signals\u201d\n\nThis concern is actually one of the advantages of our proposal to use interaction detection and LIME together. The features generated by LIME are randomly sampled (Section 4.1), so they are uncorrelated by default. Therefore, NID focuses on identifying interaction effects rather than correlations. We added a comment on this in Section 4.1.\n\n>> \u201cExperiments look less informative for comparing the proposed method with other existing methods for similar motivations (e.g., ...\u201d\n\nWe have added experiments in Appendix E comparing MADEX to baselines with similar motivations on local interpretation of feature subsets. MADEX performs well compared to the baselines, especially on interpreting neural network models.\n\n>> \u201cIn the case-study of Figure 4(b), I thought that the proposed method is a bit biased for frequent but meaningless features, because it detected \"I\" or \"a\"... it may be necessary to introduce some weighting strategy to detected interactions\u201d\n\nWe have several responses to this comment. 1) words such as \u201ca\u201d and \u201cI\u201d are often \u201cstop words\u201d in natural language processing, and it is standard practice to omit them [1,2]. 2) The interactions outputted by MADEX are actually ranked/weighted in our experiments, based on the usage of top-k thresholding in Section 5.3.1. \n\nTo address your comment, we provide results in Appendix C.1 on randomly selected sentences excluding stop words, and we only show top-ranked word interactions. The interactions are meaningful for sentiment, such as (family, oriented), and (inarticulate, disappointing). In addition, we ran a more thorough interaction occurrence experiment in Appendix C.2 and found that the frequent word interactions are especially meaningful, i.e. (well, worth), (too, bad), (pretty, good), etc.\n\n\n[1] Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schutze. Introduction to Information Retrieval. Cambridge University Press, 2008.\n[2] Jure Lescovec, Anand Rajaraman, Jefferey Ullman. Mining of Massive Datasets. Cambridge University Press, 2014."}, "signatures": ["ICLR.cc/2020/Conference/Paper795/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgnhTEtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper795/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper795/Authors|ICLR.cc/2020/Conference/Paper795/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166101, "tmdate": 1576860541393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment"}}}, {"id": "BJlHAmvYoB", "original": null, "number": 1, "cdate": 1573643213389, "ddate": null, "tcdate": 1573643213389, "tmdate": 1573643213389, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "ryxiVxxs9H", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment", "content": {"title": "Author Response", "comment": "Thank you for your thorough comments and suggestions. Our responses to your points are below:\n\n>> \u201cIn general the exposition was quite lacking in the methodological section\u201d\n\nWe revised the methodology section to clarify MADEX and the input/output of Section 4.3. We now use source/target nomenclature consistently through the paper. \n\n>> \u201chow this would work if the underlying feature itself were not known\u201d\n\nDid you mean if we can use GLIDER for text or image models? We did not claim that global interaction detection or encoding could work for these models, hence the \u201cR\u201d for recommendation in GLIDER. Nonetheless, we added preliminary experiments in Appendix C.2 showing that MADEX frequently detects meaningful word interactions from the Sentiment-LSTM model across multiple sentences, i.e., (well, worth), (too, bad), (pretty, good), etc. Doing the same for image models is very challenging and left for future work. \n\n>> \u201cBy assuming (effectively perfect) information about the features used, this is no longer really a \"blackbox\" model\u201d\n\nThere are many different models that use dense and sparse features, especially in recommendation. One can see this variety of model architectures already in literature [1-5]. In real-world commercial settings, recommender architectures can also be heavily engineered; therefore, it is useful to have methods that treat the recommender system as a black-box model. We made a note of our meaning of \u201cblack-box recommender model\u201d in the notations section. \n\n>> \u201cabout the scalability of dense features and their bucketization\u201d\n\nWe added scalability experiments on dense feature bucketization in Appendix B. Our requirement that a valid cross feature ID occurs more than $T$ times (Section 4.3) restricts the growth in parameters as the number of buckets increases. \n\n>> \u201camount of novelty in the work\u201d\n\nThere is very limited work on improving prediction performance by model interpretations, especially in the automatic way we propose. In this perspective, our work takes a step towards bridging interpretability with the field of AutoML via automatic feature engineering. Moreover, this work exposes feature interactions learned by general prediction models, which is a crucial step for interpretability applications such as scientific discovery (e.g., identifying DNA sequence interactions (Section 5.3.2)) and trustworthy machine learning (e.g., understanding how ads are targeted to users via ads-user interactions).\n\n>> \u201cto understand higher-order interactions and the ability of the model to find them empirically\u201d\n\nWe added frequencies of higher-order interactions detected from recommender, image, and text models in Appendix F. Higher-order interactions are common, especially from the image model.\n\n>> \u201csignificance testing being performed in general\u201d\n\nWe ran significance testing. For the global interactions in Figure 2, we test the significance of the top-1 occurrence counts using order statistics. For the Criteo dataset, any count > 43 is significant (p value < 0.05). Ours was 572. For the Avazu dataset, any count > 33 is significant. Ours was 423.\n\n>> \u201clack of mention of the stopping criteria of the model\u201d\n\nModels are early stopped and selected based on best performance on validation sets. The Experiment Setup section mentioned early stopping.\n\n\n[1] Cheng, et al. Wide & deep learning for recommender systems. In Proc of the 1st workshop on deep learning for recommender systems, pp. 7\u201310. ACM, 2016.\n[2] Guo, et al. Deepfm: a factorization machine based neural network for ctr prediction. In Proc of IJCAI. 2017.\n[3] Wang, et al. Deep & cross network for ad click predictions. In Proc of the ADKDD\u201917, 2017.\n[4] Lian, et al. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In Proc of SIGKDD, 2018. \n[5] Song, et al. Autoint: Automatic feature interaction learning via self-attentive neural networks. In Proc of CIKM, 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper795/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgnhTEtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper795/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper795/Authors|ICLR.cc/2020/Conference/Paper795/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166101, "tmdate": 1576860541393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper795/Authors", "ICLR.cc/2020/Conference/Paper795/Reviewers", "ICLR.cc/2020/Conference/Paper795/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Comment"}}}, {"id": "HklcwLdRFr", "original": null, "number": 1, "cdate": 1571878497980, "ddate": null, "tcdate": 1571878497980, "tmdate": 1572972551454, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposed a model for extracting global feature interactions from the source model which was later being encoded in the target model to enhance its prediction performance.\n\nStrong points:\n1. The paper laid out the necessary background knowledge very clear even for the audiences outside this area.\n\n2. The paper performed reasonable amount of experiments to compare the proposed model with various baseline models with various data sets, which are strong enough to support the claims made in this paper.\n\nComments:\n1. The theoretical innovation of this paper is trivial. The local detection model for feature interactions, i.e. MADEX is simply employing the previous work, LIME and NID. Its global extension, i.e. GLIDER and the proposed encoding method are straightforward. \n\n2. The descriptions on the feature dimensions of the original data and the generated binary representation data x\u2019 are rather confusing and inconsistent throughout the paper. If I understand it correctly, the data sample from the original feature space x \\in R^p, and a  binary representation x\u2019 \\in R^d, where d <= p. However, when d first appears in the first paragraph of section 3, it is defined as the dimension of the original feature space and later in that paragraph the dimension became p in \u201cf(.): R^p -> R\u201d. There is no clarification on the differences between d and p till section 4.1 where it states \u201cx \\in R^p \u201d. However, the dimension of the data instance from the original feature space changed to d again in section 4.2 where it states \u201cx =[x_1, x_2, \u2026, x_d]\u201d. \n\n3. \u201cWhat\u2019s more, the same approach to interpreting interactions can provide new insights into domains even beyond recommendation.\u201d should be \u201cWhat\u2019s more, the same approach to interpret interactions can provide new insights into domains even beyond the recommendation.\u201d\n\n4. \u201cAn interaction, I, is a subset of all input features...\u201d, but according to the following sections, I is the indices of a feature subset instead of the features themselves.\n \n5. \u201c...by requiring the same cross feature ID to occur more that T times in a batch of samples,...\u201d, \u2018that\u2019 should be \u2018than\u2019.\n\nOverall, although there is no significant theoretical innovation, it is a decent application paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576070908317, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper795/Reviewers"], "noninvitees": [], "tcdate": 1570237746959, "tmdate": 1576070908334, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Review"}}}, {"id": "ryxiVxxs9H", "original": null, "number": 3, "cdate": 1572696115397, "ddate": null, "tcdate": 1572696115397, "tmdate": 1572972551367, "tddate": null, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "invitation": "ICLR.cc/2020/Conference/Paper795/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper is focused on identifying/discovering feature interactions in blackbox models (with a focus on recommendations). Specifically the technique works by first corrupting datapoints and then using this \"local dataset\" to find interacting features via lasso-regularized multi-level perceptron approach (NID from Tsang et al). Using an expanded feature space and repeated calls to the above steps this is then used to find the most commonly occurring patterns. \n\nThe empirical section is quite interesting, with some nice mix of qualitative and quantitative results. The quantitative results in particular are quite intriguing -- across recommendation and non-recommendation tasks.\n\nOverall the paper makes for an interesting read. On the whole I lean slightly positive -- largely due to the empirical section and the quantitative gains observed by adding the feature interactions as features to the model.\n\nThat said I had quite a few concerns about the work:\n\n- In general the exposition was quite lacking in the methodological section. I had to re-read the paper a few times to be able to make out to fully understand the underlying methodology. I would make the overall pipeline very clear and explain out the MADEX pipeline very clearly. The feature expansion section (4.3) in particular was not very clear -- as to how it fit in with the rest of the pipeline and something that could do with more work.  Nomenclature like source and target model are used somewhat arbitrarily and again can be clarified.\n\n- Another concern I had with the approach is how this would work if the underlying features itself were not known. Say for example you had a text understanding model -- the tokenization and vocabulary/OOV etc .. may all be components of the blackbox. Likewise for vision models, what features are being used may vary.\n\nBy assuming (effectively perfect) information about the features used, this is no longer really a \"blackbox\" model. I would have wanted to see some deeper discussion on this topic.\n\nI also had some concerns about the scalability of dense features and their bucketization in this approach. I'm not entirely convinced the method would work as well and efficiently in such feature spaces. I would have wanted to see some more empirical evidence and understanding on this topic.\n\nIf possible it would have also been great to understand higher-order interactions and the ability of the model to find them empirically. \n\n- One thing I wasn't entirely certain of was the amount of novelty in the work since it leverages existing works like NID (Tsang et al) and LIME (Ribeiro et al) for some of the key aspects of the method. It would be nice to see some discussion on this front as well.\n\n- I also would have liked to see significance testing being performed in general across the experiments.\n\n- Another smaller concern stemmed from a lack of mention of the stopping criterion of the model. In particular I'm wondering how models were stopped further training / best checkpoint was picked. This would be good to elaborate on to make sure that the models were all compared fairly from a computational perspective.\n\n- I also had some concerns with the scalability of the approach in large features spaces but am willing to give the authors the benefit of doubt on this one based on the 3 hour number they quoted from their experiments (which indicates something that is not prohibitively slow)\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper795/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": ["Michael Tsang", "Dehua Cheng", "Hanpeng Liu", "Xue Feng", "Eric Zhou", "Yan Liu"], "authorids": ["tsangm@usc.edu", "dehuacheng@fb.com", "hanpengl@usc.edu", "xfeng@fb.com", "hanningz@fb.com", "yanliu.cs@usc.edu"], "keywords": ["Feature Interaction", "Interpretability", "Black Box", "AutoML"], "TL;DR": "Proposed methods to extract and leverage interpretations of feature interactions", "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.", "pdf": "/pdf/92ef1a91a48f542fa2a673a944c268a080d1745a.pdf", "paperhash": "tsang|feature_interaction_interpretability_a_case_for_explaining_adrecommendation_systems_via_neural_interaction_detection", "code": "https://github.com/mtsang/interaction_interpretability", "_bibtex": "@inproceedings{\nTsang2020Feature,\ntitle={Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection},\nauthor={Michael Tsang and Dehua Cheng and Hanpeng Liu and Xue Feng and Eric Zhou and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgnhTEtDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/7a0b4cd40ba95919d32ebd8a0e58d6b9da05b91b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgnhTEtDS", "replyto": "BkgnhTEtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper795/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576070908317, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper795/Reviewers"], "noninvitees": [], "tcdate": 1570237746959, "tmdate": 1576070908334, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper795/-/Official_Review"}}}], "count": 8}