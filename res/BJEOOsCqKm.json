{"notes": [{"id": "BJEOOsCqKm", "original": "BkxwqAtcF7", "number": 370, "cdate": 1538087792342, "ddate": null, "tcdate": 1538087792342, "tmdate": 1545355430293, "tddate": null, "forum": "BJEOOsCqKm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1eSRW94lV", "original": null, "number": 1, "cdate": 1545015757174, "ddate": null, "tcdate": 1545015757174, "tmdate": 1545354485975, "tddate": null, "forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "invitation": "ICLR.cc/2019/Conference/-/Paper370/Meta_Review", "content": {"metareview": "This paper focuses on the problem of detecting visual anomalies within textures. For that purpose, the authors consider several parametric texture models and train anomaly detection models on the corresponding outputs. \n\nReviewers were generally positive about the topic under study, but were unanimous in signaling a severe weaknesses in the experimental setup. In particular, in R2 words, \"my main concern is that the performance evaluation is not suitable to achieve meaningful results\", and \"showing quantitative results from only two textures does not feel like a very comprehensive analysis\". Moreover, the authors did not respond to reviewers feedback. Therefore, the AC recommends rejection at this time.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Interesting question but insufficient analysis"}, "signatures": ["ICLR.cc/2019/Conference/Paper370/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper370/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper370/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353241259, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper370/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper370/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper370/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353241259}}}, {"id": "ryeS-s13RQ", "original": null, "number": 4, "cdate": 1543400189262, "ddate": null, "tcdate": 1543400189262, "tmdate": 1543400189262, "tddate": null, "forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "invitation": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "content": {"title": "Interesting task but lack of novelty", "review": "This paper focuses on novelty detection and shows that psychophysical representations can outperform VGG-encoder features in some part of this task.\n\nNovelty:\nIt is the first time I have seen this novelty detection task. This task could be part of the novelty of the paper. Another novelty comes from the new objective function they introduce.\n\nWeakness:\n1. The motivation of the new objective function is not clear to me. It seems that they first design the objective function and then build the interval-based decision function. There is not much intuition given.\n2. The experiment lacks of real data. Synthesized anomalies never exists in application. If it is a paper about application, real data is needed.\n3. The baseline is too simple. CNN could definitely beat SVM in image classification. Also using extracted features could be better than directly performing SVM on pixels.\n4. Do not see the results of OC-SVM in Table 1 even though they say they beat it.\n5. Also, I do not see any other reference work for this novelty detection problem. If it is a new problem, a clear definition of the problem is needed. If it is not, more references are needed.\n\nThe writing of the paper is clear and easy to understand. But based on all the weakness above and lack of novelty, I think the paper should be rejected for now.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper370/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "cdate": 1542234476769, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper370/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335708987, "tmdate": 1552335708987, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper370/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJeLro9L67", "original": null, "number": 3, "cdate": 1542003518084, "ddate": null, "tcdate": 1542003518084, "tmdate": 1542003518084, "tddate": null, "forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "invitation": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "content": {"title": "Experimentally Limited", "review": "This paper considers detecting anomalies in textures. For this task they use VGG-19 features and two human-inspired features from Portilla & Simoncelli and Schutt & Wichmann.\nWith these features, they train one-class anomaly detectors. One such anomaly detector is a one-class SVM, and they introduce a loss for one-class neural networks.\n\nThe novelty in this paper comes from the problem setup which I have not seen treated before. The loss function they propose also appears original.\n\nHowever, comparisons are limited. They compare against OC-SVMs, but these are known to be weaker than several types of anomaly detectors [1]. This paper would also do well to ground itself in more recent research on deep anomaly detection [2]. Likewise, the problem setting is limited. In all, experimentation could use more breadth and depth.\n\n[1] Andrew F. Emmott, Shubhomoy Das, Thomas Dietterich, Alan Fern, Weng-Keen Wong. Systematic Construction of Anomaly Detection Benchmarks from Real Data. ODD, 2013.\n[2] Dan Hendrycks and Kevin Gimpel. A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. ICLR, 2017.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper370/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "cdate": 1542234476769, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper370/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335708987, "tmdate": 1552335708987, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper370/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryxnz02qnm", "original": null, "number": 2, "cdate": 1541226003935, "ddate": null, "tcdate": 1541226003935, "tmdate": 1541534052008, "tddate": null, "forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "invitation": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "content": {"title": "Interesting topic but insufficient analysis and evaluation", "review": "The submission investigates the problem of detecting perceptual anomalies in visual textures.\nIt proposes features from three different models, the Portilla & Simoncelli texture model (PS), the Spatial Vision model by Schuett and Wichmann (SW) and CNN features from the VGG network. From these features it trains two anomaly detectors: one out of the box one-class SVM and a 3 layer neural network. The network is optimised with a loss function that encourages output values for the original texture to be larger than for a white-noise image obtained by shuffling its pixels. At the same time the range of output values for the original texture is encouraged to be small.\n \nThe performance of the different approaches is evaluated using synthetic anomalies. However no distinction between perceptually striking and perceptually negligible anomalies is made and quantitative results are only reported for all synthetically generated anomalies.\nTwo attempts are made to control if an approach specifically picks up on perceptually striking anomalies.\na) detection rate on gaussian noise as a proxy for perceptually negligible anomalies\nb) anecdotal evidence from visual inspection.\n\nI do not think that either of the two controls is sufficient to make a clear statement about which method is best in detecting perceptually striking anomalies. Therefore my main concern is that the performance evaluation is not suitable to achieve meaningful results.\n\nFurthermore the technical depth of the submission appears fairly limited. The main original contribution is the CNN loss that is introduced. However, the loss does not strike me as particularly compelling. It resembles a classifier between textures and white noise samples with the same pixel-wise statistics. I am not sure why this should be particularly suited to detect perceptual anomalies.\n\nFinally, showing quantitative results from only two textures does not feel like a very comprehensive analysis.\n\nIn general  the submission tackles an interesting research topic. However, to show meaningful results I believe that one has to collect psychophysical data for the anomalies of interest to distinguish between anomalies that are perceptually detectable and those that are not.\nWith such a test set one could then start testing hypothesis on which feature representation is most appropriate to model the perceptual results or optimise features directly to match human psychophysical results (similar to the study by Berardino et al. 2017 [1]). In its current form I am not sure what I can learn from the submission both in terms of anomaly detection and feature spaces particularly suited to detect perceptual anomalies in visual textures. \n\n[1] Eigen-distortions of hierarchical representations\nA Berardino, V Laparra, J Ball\u00e9, E Simoncelli\nAdvances in neural information processing systems, 3530-3539", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper370/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "cdate": 1542234476769, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper370/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335708987, "tmdate": 1552335708987, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper370/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Sye37yv8h7", "original": null, "number": 1, "cdate": 1540939555804, "ddate": null, "tcdate": 1540939555804, "tmdate": 1541534051796, "tddate": null, "forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "invitation": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "content": {"title": "Psychophysical vs. learnt texture representations in novelty detection ", "review": "\n\nThe authors describe an anomaly/novelty detection method based on handcrafted features + VGG based features. \n\nI think the paper is out of the scope of the conference (the only part dealing with learned representations uses VG), plus it addresses a problem whose relevance is not correctly motivated. Finally, the method is quite basic, and is not compared to any state of the art method for novelty detectiobn.  \n\nIn \"... the detection of visual anomalies perceived by human observer is an open challenge\u2026 \" can you provide references of people working in this particular problem?\n\nThe review of related work seems obsolete, can you provide more recent references (in addition to \"historical\" ones). More importantly, please provide references of anomaly detection from textures\n", "rating": "1: Trivial or wrong", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper370/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Psychophysical vs. learnt texture representations in novelty detection", "abstract": "Parametric texture models have been applied successfully to synthesize artificial images. Psychophysical studies show that under defined conditions observers are unable to differentiate between model-generated and original natural textures. In industrial applications the reverse case is of interest: a texture analysis system should decide if human observers are able to discriminate between a reference and a novel texture. For example, in case of inspecting decorative surfaces the de- tection of visible texture anomalies without any prior knowledge is required. Here, we implemented a human-vision-inspired novelty detection approach. Assuming that the features used for texture synthesis are important for human texture percep- tion, we compare psychophysical as well as learnt texture representations based on activations of a pretrained CNN in a novelty detection scenario. Additionally, we introduce a novel objective function to train one-class neural networks for novelty detection and compare the results to standard one-class SVM approaches. Our experiments clearly show the differences between human-vision-inspired texture representations and learnt features in detecting visual anomalies. Based on a dig- ital print inspection scenario we show that psychophysical texture representations are able to outperform CNN-encoded features.", "keywords": ["novelty detection", "learnt texture representation", "one-class neural network", "human-vision-inspired anomaly detection"], "authorids": ["m.grunwald@htwg-konstanz.de", "matthias.hermann@htwg-konstanz.de", "f.freiberg@htwg-konstanz.de", "mfanz@htwg-konstanz.de"], "authors": ["Michael Grunwald", "Matthias Hermann", "Fabian Freiberg", "Matthias O. Franz"], "TL;DR": "Comparison of psychophysical and CNN-encoded  texture representations in a one-class neural network novelty detection application.", "pdf": "/pdf/d3b8ba69ac8f3cb3e17b5f592e57e42c05bfd029.pdf", "paperhash": "grunwald|psychophysical_vs_learnt_texture_representations_in_novelty_detection", "_bibtex": "@misc{\ngrunwald2019psychophysical,\ntitle={Psychophysical vs. learnt texture representations in novelty detection},\nauthor={Michael Grunwald and Matthias Hermann and Fabian Freiberg and Matthias O. Franz},\nyear={2019},\nurl={https://openreview.net/forum?id=BJEOOsCqKm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper370/Official_Review", "cdate": 1542234476769, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJEOOsCqKm", "replyto": "BJEOOsCqKm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper370/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335708987, "tmdate": 1552335708987, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper370/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 6}