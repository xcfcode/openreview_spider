{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521582949536, "tcdate": 1520217254828, "number": 1, "cdate": 1520217254828, "id": "BJ1237qdz", "invitation": "ICLR.cc/2018/Workshop/-/Paper210/Official_Review", "forum": "ByYzNv1vM", "replyto": "ByYzNv1vM", "signatures": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer3"], "content": {"title": "A simple example of separation", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper provides an example of a function which can not be approximated with a depth 2 neural network (unless there are exponentially many hidden units) but can be approximated with a depth three neural network. While there are a few recent papers that do this. The main novelty of this paper is to study the effect of input distributions and show this separation holds for a variety of such distributions. Overall this seems like a short interesting example/paper. While I did not check proofs in detail the overall strategy seems sound.\n\n\n- The conditions on the distributions are a bit unintuitive. More descriptions examples and why these conditions are relevant would be useful.\n\n- There needs to be more discussion why the stated theorem achieves the objective claimed earlier on in the intro.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Recent work has shown strong separation between the expressive power of depth-$2$ and depth-$3$ neural networks. These separation results exhibit a function and an input distributions, so that the function is well-approximable in $L_{2}$-norm on the input distribution by a depth-$3$ neural network of polynomial size but any depth-$2$ neural network that well-approximates it requires exponential size. A limitations of these results is that they work only for certain careful choices of functions and input distributions that are arguably not natural enough.\n\nWe provide a simple proof of $L_{2}$-norm separation between the expressive power of depth-$2$ and depth-$3$ sigmoidal neural networks for a large class of input distributions, assuming their weights are polynomially bounded. Our proof is simpler than previous results, uses known low-degree multivariate polynomial approximations to neural networks, and gives the first depth-$2$-vs-depth-$3$ separation that works for a large class of input distributions.", "pdf": "/pdf/c681cf9d7ca6ec052e030ad19a4fe3165ae75156.pdf", "TL;DR": "Depth-2 vs depth-3 separation in L_2-norm for sigmoidal neural networks over a large class of distributions ", "paperhash": "deshpande|depth_separation_and_weightwidth_tradeoffs_for_sigmoidal_neural_networks", "_bibtex": "@misc{\ndeshpande2018depth,\ntitle={Depth separation and weight-width trade-offs for sigmoidal neural networks},\nauthor={Amit Deshpande and Navin Goyal and Sushrut Karmalkar},\nyear={2018},\nurl={https://openreview.net/forum?id=SJICXeWAb},\n}", "keywords": ["depth separation", "sigmoidal neural networks", "low-degree polynomials"], "authors": ["Amit Deshpande", "Navin Goyal", "Sushrut Karmalkar"], "authorids": ["amitdesh@microsoft.com", "navingo@microsoft.com", "s.sushrut@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582949341, "id": "ICLR.cc/2018/Workshop/-/Paper210/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper210/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper210/AnonReviewer2"], "reply": {"forum": "ByYzNv1vM", "replyto": "ByYzNv1vM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper210/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper210/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582949341}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582655141, "tcdate": 1520782913574, "number": 2, "cdate": 1520782913574, "id": "HycHATGYM", "invitation": "ICLR.cc/2018/Workshop/-/Paper210/Official_Review", "forum": "ByYzNv1vM", "replyto": "ByYzNv1vM", "signatures": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer2"], "content": {"title": "Simpler proof of depth separation, quite robust to the underlying distribution", "rating": "8: Top 50% of accepted papers, clear accept", "review": "Summary: In this paper, authors show a depth separation between width 2 and width 3 sigmoidal neural networks. While there have been several results of such flavor in the recent literature, all of these results are strongly tied to the underlying distributions. In particular, it\u2019s not clear from the previous results if the depth separation is robust under a larger class of distributions.\nIn this paper, the authors build on the work of Daniely(2016), giving a much simpler proof of his depth separation (though with worse parameters and a requirement of bounded weights), but the results in this paper hold for a much larger class of distributions.\n\nOpinion: I think a simpler proof of depth separation and robustness to the underlying input distribution make the results, though weaker and not entirely new, interesting enough to merit acceptance.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Recent work has shown strong separation between the expressive power of depth-$2$ and depth-$3$ neural networks. These separation results exhibit a function and an input distributions, so that the function is well-approximable in $L_{2}$-norm on the input distribution by a depth-$3$ neural network of polynomial size but any depth-$2$ neural network that well-approximates it requires exponential size. A limitations of these results is that they work only for certain careful choices of functions and input distributions that are arguably not natural enough.\n\nWe provide a simple proof of $L_{2}$-norm separation between the expressive power of depth-$2$ and depth-$3$ sigmoidal neural networks for a large class of input distributions, assuming their weights are polynomially bounded. Our proof is simpler than previous results, uses known low-degree multivariate polynomial approximations to neural networks, and gives the first depth-$2$-vs-depth-$3$ separation that works for a large class of input distributions.", "pdf": "/pdf/c681cf9d7ca6ec052e030ad19a4fe3165ae75156.pdf", "TL;DR": "Depth-2 vs depth-3 separation in L_2-norm for sigmoidal neural networks over a large class of distributions ", "paperhash": "deshpande|depth_separation_and_weightwidth_tradeoffs_for_sigmoidal_neural_networks", "_bibtex": "@misc{\ndeshpande2018depth,\ntitle={Depth separation and weight-width trade-offs for sigmoidal neural networks},\nauthor={Amit Deshpande and Navin Goyal and Sushrut Karmalkar},\nyear={2018},\nurl={https://openreview.net/forum?id=SJICXeWAb},\n}", "keywords": ["depth separation", "sigmoidal neural networks", "low-degree polynomials"], "authors": ["Amit Deshpande", "Navin Goyal", "Sushrut Karmalkar"], "authorids": ["amitdesh@microsoft.com", "navingo@microsoft.com", "s.sushrut@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582949341, "id": "ICLR.cc/2018/Workshop/-/Paper210/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper210/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper210/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper210/AnonReviewer2"], "reply": {"forum": "ByYzNv1vM", "replyto": "ByYzNv1vM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper210/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper210/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582949341}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573547417, "tcdate": 1521573547417, "number": 19, "cdate": 1521573547079, "id": "ryQ2AACFf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ByYzNv1vM", "replyto": "ByYzNv1vM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Recent work has shown strong separation between the expressive power of depth-$2$ and depth-$3$ neural networks. These separation results exhibit a function and an input distributions, so that the function is well-approximable in $L_{2}$-norm on the input distribution by a depth-$3$ neural network of polynomial size but any depth-$2$ neural network that well-approximates it requires exponential size. A limitations of these results is that they work only for certain careful choices of functions and input distributions that are arguably not natural enough.\n\nWe provide a simple proof of $L_{2}$-norm separation between the expressive power of depth-$2$ and depth-$3$ sigmoidal neural networks for a large class of input distributions, assuming their weights are polynomially bounded. Our proof is simpler than previous results, uses known low-degree multivariate polynomial approximations to neural networks, and gives the first depth-$2$-vs-depth-$3$ separation that works for a large class of input distributions.", "pdf": "/pdf/c681cf9d7ca6ec052e030ad19a4fe3165ae75156.pdf", "TL;DR": "Depth-2 vs depth-3 separation in L_2-norm for sigmoidal neural networks over a large class of distributions ", "paperhash": "deshpande|depth_separation_and_weightwidth_tradeoffs_for_sigmoidal_neural_networks", "_bibtex": "@misc{\ndeshpande2018depth,\ntitle={Depth separation and weight-width trade-offs for sigmoidal neural networks},\nauthor={Amit Deshpande and Navin Goyal and Sushrut Karmalkar},\nyear={2018},\nurl={https://openreview.net/forum?id=SJICXeWAb},\n}", "keywords": ["depth separation", "sigmoidal neural networks", "low-degree polynomials"], "authors": ["Amit Deshpande", "Navin Goyal", "Sushrut Karmalkar"], "authorids": ["amitdesh@microsoft.com", "navingo@microsoft.com", "s.sushrut@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518730172798, "tcdate": 1518461969436, "number": 210, "cdate": 1518461969436, "id": "ByYzNv1vM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ByYzNv1vM", "original": "SJICXeWAb", "signatures": ["~Amit_Deshpande1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Recent work has shown strong separation between the expressive power of depth-$2$ and depth-$3$ neural networks. These separation results exhibit a function and an input distributions, so that the function is well-approximable in $L_{2}$-norm on the input distribution by a depth-$3$ neural network of polynomial size but any depth-$2$ neural network that well-approximates it requires exponential size. A limitations of these results is that they work only for certain careful choices of functions and input distributions that are arguably not natural enough.\n\nWe provide a simple proof of $L_{2}$-norm separation between the expressive power of depth-$2$ and depth-$3$ sigmoidal neural networks for a large class of input distributions, assuming their weights are polynomially bounded. Our proof is simpler than previous results, uses known low-degree multivariate polynomial approximations to neural networks, and gives the first depth-$2$-vs-depth-$3$ separation that works for a large class of input distributions.", "pdf": "/pdf/c681cf9d7ca6ec052e030ad19a4fe3165ae75156.pdf", "TL;DR": "Depth-2 vs depth-3 separation in L_2-norm for sigmoidal neural networks over a large class of distributions ", "paperhash": "deshpande|depth_separation_and_weightwidth_tradeoffs_for_sigmoidal_neural_networks", "_bibtex": "@misc{\ndeshpande2018depth,\ntitle={Depth separation and weight-width trade-offs for sigmoidal neural networks},\nauthor={Amit Deshpande and Navin Goyal and Sushrut Karmalkar},\nyear={2018},\nurl={https://openreview.net/forum?id=SJICXeWAb},\n}", "keywords": ["depth separation", "sigmoidal neural networks", "low-degree polynomials"], "authors": ["Amit Deshpande", "Navin Goyal", "Sushrut Karmalkar"], "authorids": ["amitdesh@microsoft.com", "navingo@microsoft.com", "s.sushrut@gmail.com"]}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730172798, "tcdate": 1509127118150, "number": 571, "cdate": 1518730172789, "id": "SJICXeWAb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "SJICXeWAb", "original": "rJBCmebA-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Depth separation and weight-width trade-offs for sigmoidal neural networks", "abstract": "Some recent work has shown separation between the expressive power of depth-2 and depth-3 neural networks. These separation results are shown by constructing functions and input distributions, so that the function is well-approximable by a depth-3 neural network of polynomial size but it cannot be well-approximated under the chosen input distribution by any depth-2 neural network of polynomial size. These results are not robust and require carefully chosen functions as well as input distributions.\n\nWe show a similar separation between the expressive power of depth-2 and depth-3 sigmoidal neural networks over a large class of input distributions, as long as the weights are polynomially bounded. While doing so, we also show that depth-2 sigmoidal neural networks with small width and small weights can be well-approximated by low-degree multivariate polynomials.", "pdf": "/pdf/635d9c6ffb297f0dcd37f8bdb4e5381143637648.pdf", "TL;DR": "depth-2-vs-3 separation for sigmoidal neural networks over general distributions", "paperhash": "deshpande|depth_separation_and_weightwidth_tradeoffs_for_sigmoidal_neural_networks", "_bibtex": "@misc{\ndeshpande2018depth,\ntitle={Depth separation and weight-width trade-offs for sigmoidal neural networks},\nauthor={Amit Deshpande and Navin Goyal and Sushrut Karmalkar},\nyear={2018},\nurl={https://openreview.net/forum?id=SJICXeWAb},\n}", "keywords": ["depth separation", "neural networks", "weights-width trade-off"], "authors": ["Amit Deshpande", "Navin Goyal", "Sushrut Karmalkar"], "authorids": ["amitdesh@microsoft.com", "navingo@microsoft.com", "sushrutk@cs.utexas.edu"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 4}