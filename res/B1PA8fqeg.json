{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396413465, "tcdate": 1486396413465, "number": 1, "id": "rkBb2G8dl", "invitation": "ICLR.cc/2017/conference/-/paper175/acceptance", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The reviewers were consistent in their review that they thought this was a strong rejection.\n Two of the reviewers expressed strong confidence in their reviews.\n The main arguments made by the reviewers against acceptance were:\n Lack of novelty (R2, R3)\n Lack of knowledge of literature and development history; particularly with respect to biological inspiration of ANNs (R3)\n Inappropriate baseline comparison (R2)\n Not clear (R1)\n \n The authors did not provide a response to the official reviews. Therefore I have decided to follow the consensus towards rejection."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396413970, "id": "ICLR.cc/2017/conference/-/paper175/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396413970}}}, {"tddate": null, "tmdate": 1482676824816, "tcdate": 1482676824816, "number": 3, "id": "r1ZD5L6Nl", "invitation": "ICLR.cc/2017/conference/-/paper175/official/review", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/conference/paper175/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper175/AnonReviewer2"], "content": {"title": "", "rating": "3: Clear rejection", "review": "The multiagent system is proposed as a generalization of neural network. The proposed system can be used with less restrictive network structures more efficiently by computing only those necessary computations in the graph. Unfortunately, I don't find the proposed system different from the framework of artificial neural network. Although for today's neural network structures are designed to have a lot of matrix-matrix multiplications, but it is not limited to have such architecture. In other words, the proposed multiagent system can be framed in the artificial neural network with more complicated layer/connectivity structures while considering each neuron as layer. The computation efficiency is argued among different sparsely connected denoising autoencoder in multiagent system framework only but the baseline comparison should be against the fully-connected neural network that employs matrix-matrix multiplication.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482676825490, "id": "ICLR.cc/2017/conference/-/paper175/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper175/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper175/AnonReviewer1", "ICLR.cc/2017/conference/paper175/AnonReviewer3", "ICLR.cc/2017/conference/paper175/AnonReviewer2"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482676825490}}}, {"tddate": null, "tmdate": 1482264169312, "tcdate": 1482264169312, "number": 2, "id": "SJ-ORWDEl", "invitation": "ICLR.cc/2017/conference/-/paper175/official/review", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/conference/paper175/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper175/AnonReviewer3"], "content": {"title": "Lack of novelty and of knowledge of the relevant literature and development history", "rating": "1: Trivial or wrong", "review": "The paper reframes feed forward neural networks as a multi-agent system.\n\nIt seems to start from the wrong premise that multi-layer neural networks were created expressed as full matrix multiplications. This ignores the decades-long history of development of artificial neural networks, inspired by biological neurons, which thus started from units with arbitrarily sparse connectivity envisioned as computing in parallel. The matrix formulation is primarily a notational convenience; note also that when working with sparse matrix operations (or convolutions) zeros are neither stored not multiplied by.\n\nBesides the change in terminology, essentially renaming neurons agents, I find the paper brings nothing new and interesting to the table.\n\nPulling in useful insights from a different communitiy such as multi-agent systems would be most welcome. But for this to be compelling, it would have to be largely unheard-of elements in neural net research, with clear supporting empirical evidence that they significantly improve accuracy or efficiency. This is not achieved in the present paper.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482676825490, "id": "ICLR.cc/2017/conference/-/paper175/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper175/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper175/AnonReviewer1", "ICLR.cc/2017/conference/paper175/AnonReviewer3", "ICLR.cc/2017/conference/paper175/AnonReviewer2"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482676825490}}}, {"tddate": null, "tmdate": 1482186658381, "tcdate": 1482186658381, "number": 1, "id": "Sk9jkkINe", "invitation": "ICLR.cc/2017/conference/-/paper175/official/review", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/conference/paper175/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper175/AnonReviewer1"], "content": {"title": "", "rating": "2: Strong rejection", "review": "Unfortunately, the paper is not clear enough for me to understand what is being proposed. At a high-level the authors seem to propose a generalization of the standard layered neural architecture (of which MLPs are a special case), based on arbitrary nodes which communicate via messages. The paper then goes on to show that their layer-free architecture can perform the same computation as a standard MLP. This logic appears circular. The low level details of the method are also confusing: while the authors seem to be wanting to move away from layers based on matrix-vector products, Algorithm 4 nevertheless resorts to matrix-vector products for the forward and backwards pass. Although the implementation relies on asynchronously communicating nodes, the \u201clocking\u201d nature of the computation makes the two entirely equivalent.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482676825490, "id": "ICLR.cc/2017/conference/-/paper175/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper175/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper175/AnonReviewer1", "ICLR.cc/2017/conference/paper175/AnonReviewer3", "ICLR.cc/2017/conference/paper175/AnonReviewer2"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482676825490}}}, {"tddate": null, "tmdate": 1481185657046, "tcdate": 1481185657039, "number": 2, "id": "SJ-YF5I7l", "invitation": "ICLR.cc/2017/conference/-/paper175/public/comment", "forum": "B1PA8fqeg", "replyto": "HJw9DQb7l", "signatures": ["~Hiroki_Kurotaki1"], "readers": ["everyone"], "writers": ["~Hiroki_Kurotaki1"], "content": {"title": "Our model is free from global information including layer structure", "comment": "> What novelty does your work contribute precisely beyond reframing existing approaches in slightly different terminology?\n\nOur novelty is to reinterpret the famous feedforward neural network as a multiagent system. This means our model avoids using global information as much as possible. For example, in Algorithm 2, our method doesn't depend on the number of the units.\n\n> You claim that your method is more biologically plausible can you justify that point?\n\nIn our method, the layer restriction imposed on the standard feedforward network is removed. This property is similar to biological neural network which has no layer structure.\n\n> You show the equivalence of SDAE with your reimplementation, but can you clarify what are the advantages of your methods, either theoretically or through experiments by comparing the computation time of both methods.\n\nOur multiagent model is free from global level manipulation and processing, but we can omit these advantage and limit the localty property of our model to make it match with the standard SDAE which has global operations. In Algorithm 3, we limit the order of processing messages using the global information, the number of hidden units. In this case, our model no longer has advantage over standard SDAE because the both models do exactly same computation as proved in Section 3, which shows that our model has a strong relationship with the slightest modification.\n\n> For your sparse connect SDAE. Please clarify: Are connections dropped on a previously trained model? Using what precise rule? Do you retrain it with the dropped connections? Or do you stochastically drop connections during training (as in dropconnet)? \n\nConnections are dropped before the training to ensure computational advantage during the training.\n\n> Can you give more details about your experimentations, architecture of the network and hardware used ?\n\nWe append the detailed description of experiments in Appendix B.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287699718, "id": "ICLR.cc/2017/conference/-/paper175/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1PA8fqeg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper175/reviewers", "ICLR.cc/2017/conference/paper175/areachairs"], "cdate": 1485287699718}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481185582872, "tcdate": 1478268623030, "number": 175, "id": "B1PA8fqeg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "B1PA8fqeg", "signatures": ["~Hiroki_Kurotaki1"], "readers": ["everyone"], "content": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1480894213561, "tcdate": 1480894213556, "number": 1, "id": "HJR-wXGQe", "invitation": "ICLR.cc/2017/conference/-/paper175/public/comment", "forum": "B1PA8fqeg", "replyto": "ry8U3CCGg", "signatures": ["~Hiroki_Kurotaki1"], "readers": ["everyone"], "writers": ["~Hiroki_Kurotaki1"], "content": {"title": "We defined it in Algorithm 2 and Table 1", "comment": "> From Sec 3.2 this seems to include any computation graph. \n> Unfortunately, these are only ever vaguely described in relation to MLPs and SDAs, which is problematic.\n\nWe defined the properties the nodes in our model can contain and update in Table 1. We also defined The initialization processes in Algorithm 2. These definitions differentiate our proposed model from general computation graphs and describe the relationship to MLPs and SDAs.\n\n> The authors should be able to define these concisely and in isolation, before comparing them to existing methods.\n\nAlgorithm 2 and Table 1 shows our proposed model in isolated and independent form. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287699718, "id": "ICLR.cc/2017/conference/-/paper175/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1PA8fqeg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper175/reviewers", "ICLR.cc/2017/conference/paper175/areachairs"], "cdate": 1485287699718}}}, {"tddate": null, "tmdate": 1480828815098, "tcdate": 1480828815093, "number": 2, "id": "HJw9DQb7l", "invitation": "ICLR.cc/2017/conference/-/paper175/pre-review/question", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/conference/paper175/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper175/AnonReviewer3"], "content": {"title": "Clarifications", "question": "What novelty does your work contribute precisely beyond reframing existing approaches in slightly different terminology?\n\nYou claim that your method is more biologically plausible can you justify that point ?\n\nYou show the equivalence of SDAE with your reimplementation, but can you clarify what are the advantages of your methods, either theoretically or through experiments by comparing the computation time of both methods.\n\nFor your sparse connect SDAE. Please clarify: Are connections dropped on a previously trained model? Using what precise rule? Do you retrain it with the dropped connections? Or do you stochastically drop connections during training (as in dropconnet)? \n\nCan you give more details about your experimentations, architecture of the network and hardware used ?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959423815, "id": "ICLR.cc/2017/conference/-/paper175/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper175/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper175/AnonReviewer1", "ICLR.cc/2017/conference/paper175/AnonReviewer3"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959423815}}}, {"tddate": null, "tmdate": 1480678478281, "tcdate": 1480678478274, "number": 1, "id": "ry8U3CCGg", "invitation": "ICLR.cc/2017/conference/-/paper175/pre-review/question", "forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "signatures": ["ICLR.cc/2017/conference/paper175/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper175/AnonReviewer1"], "content": {"title": "What is a multiagent network ?", "question": "From Sec 3.2 this seems to include any computation graph. Unfortunately, these are only ever vaguely described in relation to MLPs and SDAs, which is problematic. The authors should be able to define these concisely and in isolation, before comparing them to existing methods."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multiagent System for Layer Free Network", "abstract": "We propose a multiagent system that have feedforward networks as its subset \nwhile free from layer structure with matrix-vector scheme.\nDeep networks are often compared to the brain neocortex or visual perception system.\nOne of the largest difference from human brain is the use of matrix-vector multiplication based on layer architecture.\nIt would help understanding the way human brain works\nif we manage to develop good deep network model without the layer architecture while preserving their performance.\nThe brain neocortex works as an aggregation of the local level interactions between neurons, \nwhich is rather similar to multiagent system consists of autonomous partially observing agents\nthan units aligned in column vectors and manipulated by global level algorithm.\nTherefore we suppose that it is an effective approach for developing more biologically plausible model while preserving compatibility with deep networks to alternate units with multiple agents.\nOur method also has advantage in scalability and memory efficiency.\nWe reimplemented Stacked Denoising Autoencoder(SDAE) as a concrete instance with our multiagent system and verified its equivalence with the standard SDAE from both theoritical and empirical perspectives.\nAdditionary, we also proposed a variant of our multiagent SDAE named \"Sparse Connect SDAE\",\nand showed its computational advantage with the MNIST dataset.", "pdf": "/pdf/178fcd04b04cfd4a5634b05a095634c85332be7b.pdf", "TL;DR": "We propose a multiagent system that have feed-forward networks as its subset but free from layer scheme.", "paperhash": "kurotaki|multiagent_system_for_layer_free_network", "keywords": [], "conflicts": ["weblab.t.u-tokyo.ac.jp", "k.u-tokyo.ac.jp", "g.ecc.u-tokyo.ac.jp"], "authors": ["Hiroki Kurotaki", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["kurotaki@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959423815, "id": "ICLR.cc/2017/conference/-/paper175/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper175/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper175/AnonReviewer1", "ICLR.cc/2017/conference/paper175/AnonReviewer3"], "reply": {"forum": "B1PA8fqeg", "replyto": "B1PA8fqeg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper175/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959423815}}}], "count": 9}