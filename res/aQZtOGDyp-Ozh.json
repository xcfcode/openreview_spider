{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363658220000, "tcdate": 1363658220000, "number": 2, "id": "7XaieIunN4X1I", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "aQZtOGDyp-Ozh", "replyto": "aQZtOGDyp-Ozh", "signatures": ["Joan Bruna"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "I would like to thank the reviewers for their time and constructive comments.\r\nIndeed, the paper, in its current form, explores the connection between deep convolutional networks and group invariance; but it lacks practical examples to motivate why this connection might be useful or interesting.\r\nI completely agree in that the paper is difficult to read and could be made much more accessible. Together with the practical aspects mentioned in the last section, this will be my priority. \r\nThank you again."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes. \r\nWe show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.", "pdf": "https://arxiv.org/abs/1301.3537", "paperhash": "bruna|learning_stable_group_invariant_representations_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Joan Bruna", "Arthur Szlam", "Yann LeCun"], "authorids": ["joan.bruna@gmail.com", "aszlam@ccny.cuny.edu", "ylecun@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362379800000, "tcdate": 1362379800000, "number": 1, "id": "s1Kr1S64z0s8a", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "aQZtOGDyp-Ozh", "replyto": "aQZtOGDyp-Ozh", "signatures": ["anonymous reviewer 3316"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "review": "This short paper presents a discussion on the nature and the type of invariances that are represented and learned by convolutional neural networks.  It claims that the invariance a layer in a convolutional neural network can be expressed with a Lie group, and that the invariance of a deep convolutional neural network can be expressed with a product of groups.\r\n\r\nThis is a discussion paper that is difficult to understand without being familiar with group theory.  It would be easier to read if there were even toy examples that illustrate the concepts presented in this work.  In its current form the paper is incomplete; to be useful, it needs to use these ideas to somehow improve the training or generalization of convolutional neural networks.  On a related note, it is hard to understand the significance of the results.  So the invariance of a deep convolutional neural network can be expressed with a semi-direct product of some groups; this is nice, but what does it lead to, how can it be used?  \r\n\r\nTo summarize, paper has intriguing ideas, but they are not sufficiently developed, and their significance is not clearly explained."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes. \r\nWe show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.", "pdf": "https://arxiv.org/abs/1301.3537", "paperhash": "bruna|learning_stable_group_invariant_representations_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Joan Bruna", "Arthur Szlam", "Yann LeCun"], "authorids": ["joan.bruna@gmail.com", "aszlam@ccny.cuny.edu", "ylecun@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361928660000, "tcdate": 1361928660000, "number": 3, "id": "uLsKzjPT0lx8V", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "aQZtOGDyp-Ozh", "replyto": "aQZtOGDyp-Ozh", "signatures": ["anonymous reviewer bf60"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "review": "I fully admit that I don't know enough about group theory to evaluate this submission. However, I do know about convolutional networks, so it is troubling that I can't understand it.\r\n\r\nSince this is only a workshop paper, we're not going to look for a new reviewer.\r\n\r\nWhen you do eventually pursue conference publication, I would suggest that you consider the audience and adapt the presentation somewhat, so that people who are familiar with convolutional networks but not with group theory will be able to get an idea of what the paper is about, and can read about the appropriate subjects to be able to understand it better.\r\n\r\nI would also suggest providing a high level summary of the paper that makes it clear what you consider your original contributions to be. I had a hard time telling what was original content and what was just describing what convolutional networks are in group theory notation."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes. \r\nWe show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.", "pdf": "https://arxiv.org/abs/1301.3537", "paperhash": "bruna|learning_stable_group_invariant_representations_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Joan Bruna", "Arthur Szlam", "Yann LeCun"], "authorids": ["joan.bruna@gmail.com", "aszlam@ccny.cuny.edu", "ylecun@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358488800000, "tcdate": 1358488800000, "number": 62, "id": "aQZtOGDyp-Ozh", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "aQZtOGDyp-Ozh", "signatures": ["joan.bruna@gmail.com"], "readers": ["everyone"], "content": {"title": "Learning Stable Group Invariant Representations with Convolutional\r\n    Networks", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Transformation groups, such as translations or rotations, effectively express part of the variability observed in many recognition problems. The group structure enables the construction of invariant signal representations with appealing mathematical properties, where convolutions, together with pooling operators, bring stability to additive and geometric perturbations of the input. Whereas physical transformation groups are ubiquitous in image and audio applications, they do not account for all the variability of complex signal classes. \r\nWe show that the invariance properties built by deep convolutional networks can be cast as a form of stable group invariance. The network wiring architecture determines the invariance group, while the trainable filter coefficients characterize the group action. We give explanatory examples which illustrate how the network architecture controls the resulting invariance group. We also explore the principle by which additional convolutional layers induce a group factorization enabling more abstract, powerful invariant representations.", "pdf": "https://arxiv.org/abs/1301.3537", "paperhash": "bruna|learning_stable_group_invariant_representations_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Joan Bruna", "Arthur Szlam", "Yann LeCun"], "authorids": ["joan.bruna@gmail.com", "aszlam@ccny.cuny.edu", "ylecun@gmail.com"]}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 4}