{"notes": [{"id": "H1gfFaEYDS", "original": "SyeDBn3PDH", "number": 662, "cdate": 1569439098445, "ddate": null, "tcdate": 1569439098445, "tmdate": 1583912044854, "tddate": null, "forum": "H1gfFaEYDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "rkgkgZjYiB", "original": null, "number": 4, "cdate": 1573658855492, "ddate": null, "tcdate": 1573658855492, "tmdate": 1578953962745, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "Sygb7qk0tr", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment", "content": {"title": "Responses to the comments by Rev#3", "comment": "We thank the reviewer for the constructive feedback.\n\n++++++++++++++++++++++\n#3a (The illustration of the problem in VAE is interesting. However, one missing point is to theoretically quantify the effect of the proposed regularization (in some simple cases). In particular, it is claimed that the regularization could make the encoder smoother and the experimental results clearly justifies it. \nWhat would be better is to show in which sense/measure the encoder is smoother and provide some theoretical guarantee about it. (for instance smaller Lipschitz constant?)\n..........\n\nWe agree with the reviewer and we provide a more formal argument in appendix E.3.\n\nUnder the assumption of constant encoder variance, the selection mechanism finds a point in the vicinity of the original data point that maximally changes the distance between the means of latent representations. The SE ELBO in this case forces the means to be close hence in effect promoting a reduction in the corresponding local Lipschitz constant of the encoders mean mapping.  \n\n++++++++++++++++++++++\n#3b) (I just have one question about the evaluation on the robustness of the VAE representation. In particular, a linear classifier is concatenated right after the VAE representation and it is not clear to me where it is concatenated. Is it right after the layer of \\mu and \\Sigma or in later layers? If it is in the later layers, the VAE is outputting a distribution, then how does the accuracy measured?)\n..........\n\nWe adopt a two step experimental protocol, where we first train encoder-decoder pairs agnostic to any downstream task. Then we fix the representation, that is we freeze the encoder parameters and only use the deterministic mean mapping of the encoder as the latent representation, then train a simple linear classifier based only on the encoder means using standard techniques. \n\nWe have updated the first paragraph of the experimental section as above.\n\nIn all the experiments the results are based on the means, where the linear classifier is concatenated just right after the final encoder layer, by omitting the variances. The adversarial accuracy reported for the accuracy of the linear layer attached to the encoder. The smoothness is only enforced at the output of the encoder. The decoder, or representations emerging at other layers than the encoder outputs are never used in our evaluation.\n\n++++++++++++++++++++++\n#3c) (think it is unnecessary to introduce the new term selection strategy because it is just an adversarial training with respect to a different loss. In particular, the loss is the Wasserstein distance between the latent space vectors instead of a supervised loss. For simplicity, it could be just named as latent space adversarial training. (this is just a suggestion, which will not change my decision)\n..........\n\nThe term \u2018latent space adversarial training\u2019 is certainly an accurate description of the approach and we will consider it. The reason we have used the term selection mechanism is twofold:\n*\tAdversarial training in the context of unsupervised learning is an overloaded term with connotation to GAN\u2019s or adversarial objectives.\n\n*\tThe selection mechanism can be quite general beyond adversarial attacks such as small perturbations constrained in an \\epsilon-norm-ball. For example, in domains such as image recognition, we indeed wish to generate examples that are semantically related to the original data point. While we don\u2019t investigate these extensions in the present paper, we prefer to use a more general term as a 'selection mechanism'. "}, "signatures": ["ICLR.cc/2020/Conference/Paper662/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1gfFaEYDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper662/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper662/Authors|ICLR.cc/2020/Conference/Paper662/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168132, "tmdate": 1576860533775, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment"}}}, {"id": "HklWVgsFoB", "original": null, "number": 3, "cdate": 1573658665060, "ddate": null, "tcdate": 1573658665060, "tmdate": 1578953944438, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "HJg8AR0-9H", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment", "content": {"title": "Response to the comment by Rev#2", "comment": "We thank the reviewer for their time to review the paper.\n\n+++++++++++++\n#2a (The only problem of the paper is the improvement on the experiment is marginal. Although adversarial accuracy is far better (like 0% vs 50%), it is apparent that the vanilla VAE is fragile to the adversarial examples because the added noise is intended so. Thus I can not say this is a fair comparison and because the superiority of the proposed algorithm is shown in only this point, I am not sure the proposed algorithm is surely useful.)\n....................\n\n\nRepresentation learning is increasingly used as a paradigm in large scale AI systems, where a representation is trained on large amounts of unlabeled data and then used for several downstream prediction tasks. In this context, if it happens that a representation is overly sensitive to small changes in the input, it can have catastrophic consequences for the downstream tasks the representation is used for. Thus, we believe that the adversarial accuracy on downstream tasks, which measures the performance of the model under imperceptible perturbations of the input, is a valuable metric by which to judge a representation learning method. Since VAEs are a popular paradigm in representation learning, we focused on adversarial accuracy of representations learned by VAEs in this work.\nWe would welcome any other concrete suggestion to make a more fair comparison.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper662/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1gfFaEYDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper662/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper662/Authors|ICLR.cc/2020/Conference/Paper662/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168132, "tmdate": 1576860533775, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment"}}}, {"id": "rylXL1jYjr", "original": null, "number": 2, "cdate": 1573658443133, "ddate": null, "tcdate": 1573658443133, "tmdate": 1578953918975, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "rJe5MJ5_9B", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment", "content": {"title": "Responses to the comments by Rev#1", "comment": "We thank the reviewer for their kind remarks and constructive feedback.\n\n+++++++++++++++++++++++++++++\n#1a) Improve and clarify section 2.2 [the example illustrating the problem with the VAE objective]: Alternative explanation for limitations of VAE additional to the von-Mises example \n.............................\n\nWe believe that the von-Mises example serves as an illustrative example where the densities can be computed precisely and visualized, so that the problem of non-smoothness in the decoder can be easily understood. We have rewritten this section and clarified the explanation of non-smoothness further in the revised draft. We have added a short clarification to the appendix E.1. See also response #1c).\n\n+++++++++++++++++++++++++++++\n#1b) Clarification of the relation between the Batch ELBO and the standard ELBO. (reference to derivation?) \n.............................\n\nThe Batch ELBO can be derived by considering the target p(X|Z) p(Z) and proposing an approximation of form \\hat{p}(X) q(Z|X). \n\nStarting from the original VAE ELBO that applies to a single data point, the batch ELBO will contain a sum over all data points. Viewing \\pi(X) as an empirical distribution,and writing the average Batch log likelihood as an additional expectation wrt to the empirical distribution of the original ELBO will lead to (1). We have added a short clarification to the appendix E.2.\n\n\n+++++++++++++++++++++++++++++\n#1c) Further justification and improving the presentation by avoiding abrupt changes and further justification of points 1 [remarks about the smoothness of the decoder] and 2 [remark on non-smoothness of the encoder]: clarification of point 1, improving point 2 [non-smooth encoders] establishing connection. \n#1 (In this context, I found the explanation after Eq. 2 to be intuitive in regards to inefficiency of encoders. If I understand correctly, to put it in even simpler terms, the encoding neural network is overfitting mapping from input data points to the latent representations, not performing any learning for the unseen data points at all; on the other hand,  decoder explores the space of latent variables well because it is modeled as a Gaussian?)\n.............................\n\nWe observe that at the end of the training, the mean mapping of the decoder, from latent space to observables, is approximately a smooth function empricially - the same observation was also made in previous papers (Kingma and Welling 2013, Rezende and Mohamed 2014). \n\nThe smoothness of the decoder is implicitly enforced by the conditionally Gaussian (unimodal) encoder distribution and the nature of the ELBO loss. \nThe intuition in a nutshell is the following: After the encoder converges, the latent state vectors will be approximately on a fixed ellipsoid (the typical set of a Gaussian) in the latent space as given by the encoder mapping. The ELBO objective will force the decoder mapping to be invariant on this ellipsoid. \n\nWe have added an appendix section (E.2) to the new version of the paper that provides the above description more formally and in more detail.\n \n+++++++++++++++++++++++++++++\n#1d) Comments about the trends literature of kernel function based methods, or markov random fields, to improve the neural network models. \n.............................\n\nWe agree with the reviewers observation and we observe the same trend. In several applications, certain specifications or domain specific prior knowledge need to be incorporated into highly flexible neural network models and indeed our approach can be viewed as a particular proposal in this direction. \n\n+++++++++++++++++++++++++++++\n#1e) (One practical challenge is to generate fictive data points which are not very near to existing data points. I am not sure if GANs can achieve that, either. Having such points is critical to deal with more structured noise. Any comments on this? )\n.............................\n\nAs the reviewer has correctly identified, the selection mechanism can be quite general beyond small perturbations constrained in an \\epsilon-norm-ball. In domains such as image recognition, we indeed wish to generate examples that are semantically related to the original data point. There are many different ways of accomplishing this, for example by differential renderers, black box generative models, or decoders trained GANs. To support these, our general methodology would clearly need to be extended but we believe that the pairwise coupling idea can be adopted to these situations. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper662/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1gfFaEYDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper662/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper662/Authors|ICLR.cc/2020/Conference/Paper662/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168132, "tmdate": 1576860533775, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper662/Authors", "ICLR.cc/2020/Conference/Paper662/Reviewers", "ICLR.cc/2020/Conference/Paper662/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Comment"}}}, {"id": "oVPgWgNkJc", "original": null, "number": 1, "cdate": 1576798702650, "ddate": null, "tcdate": 1576798702650, "tmdate": 1576800933351, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper proposes an novel way of expanding our VAE toolkit by tying it to adversarial robustness. It should be thus of interest to the respective communities.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795718117, "tmdate": 1576800268547, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper662/-/Decision"}}}, {"id": "Sygb7qk0tr", "original": null, "number": 1, "cdate": 1571842585158, "ddate": null, "tcdate": 1571842585158, "tmdate": 1572972567707, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies the vulnerability of representations learned by variational auto-encoders (VAE). It first show that the learned representation of VAE is susceptible to small changes, similar to the adversarial examples in supervised learning setting. Then propose a regularization method, called smooth encoder, to improve the robustness of the representation. Experiments are conducted on several benchmark datasets to show the effectiveness of the method. \n\nOverall I find the idea interesting and the experimental results promising. The following are my detailed comments.\n\na About the theory\nThe illustration of the problem in VAE is interesting. However, one missing point is to theoretically quantify the effect of the proposed regularization (in some simple cases). In particular, it is claimed that the regularization could make the encoder smoother and the experimental results clearly justifies it. What would be better is to show in which sense/measure the encoder is smoother and provide some theoretical guarantee about it. (for instance smaller Lipschitz constant?)\n\nb About the Experiment\nThe experimental section is clear and promising. I just have one question about the evaluation on the robustness of the VAE representation. In particular, a linear classifier is concatenated right after the VAE representation and it is not clear to me where it is concatenated. Is it right after the layer of \\mu and \\Sigma or in later layers? If it is in the later layers, the VAE is outputting a distribution, then how does the accuracy measured?\n\nMinor comment:\nI think it is unnecessary to introduce the new term selection strategy because it is just an adversarial training with respect to a different loss. In particular, the loss is the Wasserstein distance between the latent space vectors instead of a supervised loss. For simplicity, it could be just named as latent space adversarial training. (this is just a suggestion, which will not change my decision)"}, "signatures": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575779558091, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper662/Reviewers"], "noninvitees": [], "tcdate": 1570237748900, "tmdate": 1575779558105, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Review"}}}, {"id": "HJg8AR0-9H", "original": null, "number": 2, "cdate": 1572101838246, "ddate": null, "tcdate": 1572101838246, "tmdate": 1572972567664, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper analyzes the shortcoming of VAE objective, and propose a regularization method based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. It is lead to Wasserstein distance between representations. Experiments are made on three datasets; ColorMNIST, MNIST, and CelebA, which shows superior performance on adversarial accuracy while similar accuracy to VAE on nominal accuracy.\nThe paper is well-organized and well-written. The point is clear and the proposed algorithm is valid. The only problem of the paper is the improvement on the experiment is marginal. Although adversarial accuracy is far better (like 0% vs 50%), it is apparent that the vanilla VAE is fragile to the adversarial examples because the added noise is intended so. Thus I can not say this is a fair comparison and because the superiority of the proposed algorithm is shown in only this point, I am not sure the proposed algorithm is surely useful. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575779558091, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper662/Reviewers"], "noninvitees": [], "tcdate": 1570237748900, "tmdate": 1575779558105, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Review"}}}, {"id": "rJe5MJ5_9B", "original": null, "number": 3, "cdate": 1572540177989, "ddate": null, "tcdate": 1572540177989, "tmdate": 1572972567618, "tddate": null, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "invitation": "ICLR.cc/2020/Conference/Paper662/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This is a very interesting paper, I believe, a solid contribution to Variational Autoencoders. The basic argument is that encoders in VAEs are highly susceptible to noise in input data, whereas decoders are not. This argument is supported with a full fledged section 2.2, reformulating ELBO objective of VAEs, and introducing a VAE with discrete latent variables and discrete observations, so as to easily understand why and where VAEs fail.\n\nTo make encoders robust to noise in inputs, it is proposed to generate new fictive data points in the neighborhood of original data points so as to ensure that the latent representations of a data point and its fictive version are similar in \"some sense\" as part of the proposed regularization term. The implementation of this idea is solid in the paper, relating it to theoretical concepts such as  \"entropy regularized entropy transport problem\", \"Wasserstein distance\", etc. The most important point is that, it is easy to extend an encoder of an existing VAE with the proposed algorithm, while letting a decoder be untouched as the latter is shown to be robust/smooth anyways (in sec 2.2). It is also discussed on how to generate fictive samples, including but not restricted to approaches like projected gradient descent based adversarial attacks.\n\nSection 2.2 can be improved further, in terms of presentation. This is the most important section which can be of interest to the community to understand VAEs' limitations, a good contribution on its own. Though challenging, I encourage the authors to improve the exposition in this section as much as possible.\n\nIntroduction is written beautifully. Good job, done!\n\nFor instance, some explanation about variables, m_j, u_i, their distribution.\n\nHow do you relate the Eq. 1 with the standard ELBO. (some reference to derivation?)\n\nIs it not possible to explain limitations of present VAEs without introducing the particular von Mise like parameterization (last equation of page 3). I am not suggesting that you should remove it. The connections between the two could be more explicit, though I understand that it is already mentioned in the paper, \"parameterization emulates a high capacity network that can model any functional relationship between latent states and observations...\". \n\nIn this context, I found the explanation after Eq. 2 to be intuitive in regards to inefficiency of encoders. If I understand correctly, to put it in even simpler terms, the encoding neural network is overfitting mapping from input data points to the latent representations, not performing any learning for the unseen data points at all; on the other hand, decoder explores the space of latent variables well because it is modeled as a Gaussian?\n\nSome of the new equations should be numbered for easy reference. \n\nOn page 4, the flow is a bit abrupt. Right after Fig. 3, there are points 1 and 2 added without any note on what these two points (items in latex) are about.\n\nI found point 1 very confusing in page 4. On the other hand, point 2 is beautifully written. Though, it could be made explicit in the latter on why encoders found in VAE are not smooth, referring to Fig 2, 3.\n\nThere are minor grammar mistakes making some of sentences incoherent or confusing, in the paper. Something to do with style of language. I think, overall, language can be improved. Though, technical flow of the paper is great, and introduction is written very well, pointing out very important bold insights about the literature on unsupervised representation learning. I would say, it is a very well written paper, which is an enjoyable read, despite some of the grammar mistakes which can be easily fixed by proof reading.\n\nExperimental evaluation is sufficient. \n\nLast but not the least, one could argue that we are going to the literature of kernel function based methods, or markov random fields, to improve the neural network models. This is a general trend we are observing. It is interesting to see new models such as the proposed one, getting the best from both worlds. It may be worthwhile to point  out something along these lines in the paper so that other works like this can be accomplished which are bold, and advance representation learning, digging mathematical concepts from diverse domains. If I am mistaken, please feel free to point out. It is not going to be change the review. I am inspired from this work.\n \nOne practical challenge is to generate fictive data points which are not very near to existing data points. I am not sure if GANs can achieve that, either. Having such points is critical to deal with more structured noise. Any comments on this? "}, "signatures": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper662/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["taylancemgil@google.com", "sumedhg@google.com", "dvij@google.com", "pushmeet@google.com"], "title": "Adversarially Robust Representations with Smooth Encoders", "authors": ["Taylan Cemgil", "Sumedh Ghaisas", "Krishnamurthy (Dj) Dvijotham", "Pushmeet Kohli"], "pdf": "/pdf/028b6b32416c54e7f696c014e41d55866a6752a6.pdf", "TL;DR": "We propose a method for computing adversarially robust representations in an entirely unsupervised way.", "abstract": "This paper studies the undesired phenomena of over-sensitivity of representations learned by deep networks to semantically-irrelevant changes in data. We identify a cause for this shortcoming in the classical Variational Auto-encoder (VAE) objective, the evidence lower bound (ELBO). We show that the ELBO fails to control the behaviour of the encoder out of the support of the empirical data distribution and this behaviour of the VAE can lead to extreme errors in the learned representation. This is a key hurdle in the effective use of representations for data-efficient learning and transfer. To address this problem, we propose to augment the data with specifications that enforce insensitivity of the representation with respect to families of transformations. To incorporate these specifications, we propose a regularization method that is based on a selection mechanism that creates a fictive data point by explicitly perturbing an observed true data point. For certain choices of parameters, our formulation naturally leads to the minimization of the entropy regularized Wasserstein distance between representations. We illustrate our approach on standard datasets and experimentally show that significant improvements in the downstream adversarial accuracy can be achieved by learning robust representations completely in an unsupervised manner, without a reference to a particular downstream task and without a costly supervised adversarial training procedure. \n", "keywords": ["Adversarial Learning", "Robust Representations", "Variational AutoEncoder", "Wasserstein Distance", "Variational Inference"], "paperhash": "cemgil|adversarially_robust_representations_with_smooth_encoders", "_bibtex": "@inproceedings{\nCemgil2020Adversarially,\ntitle={Adversarially Robust Representations with Smooth Encoders},\nauthor={Taylan Cemgil and Sumedh Ghaisas and Krishnamurthy (Dj) Dvijotham and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1gfFaEYDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/64ab4e9f100d17ad503cde1b67d98e06a590ee1f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1gfFaEYDS", "replyto": "H1gfFaEYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper662/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575779558091, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper662/Reviewers"], "noninvitees": [], "tcdate": 1570237748900, "tmdate": 1575779558105, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper662/-/Official_Review"}}}], "count": 8}