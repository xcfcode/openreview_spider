{"notes": [{"id": "r1lnxTEYPS", "original": "Hylg0fS8wr", "number": 354, "cdate": 1569438964359, "ddate": null, "tcdate": 1569438964359, "tmdate": 1577168249971, "tddate": null, "forum": "r1lnxTEYPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "0nIsh9jka7", "original": null, "number": 1, "cdate": 1576798694031, "ddate": null, "tcdate": 1576798694031, "tmdate": 1576800941470, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Decision", "content": {"decision": "Reject", "comment": "This paper tackles the problem of detecting out of distribution (OoD) samples. To this end, the authors propose a new approach based on typical sets, i.e. sets of samples whose expected log likelihood approximate the model's entropy. The idea is then to rely on statistical testing using the empirical distribution of model likelihoods in order to determine whether samples lie in the typical set of the considered model. Experiments are provided where the proposed approach show competitive performance on MNIST and natural image tasks.\n\nThis work has major drawbacks: novelty, theoretical soundness, and robustness in settings with model misspecification. Using the typicality notion has already been explored in Choi. et al. 2019 (for flow-based model), which dampers the novelty of this work. The conditions under which the typicality notion can be used are also not clear, e.g. in the small data regime. Finally, the current experiments are lacking a characterization of robustness to model misspecification. Given these limitations, I recommend to reject this paper.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729779, "tmdate": 1576800282442, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper354/-/Decision"}}}, {"id": "HJep8WdqtH", "original": null, "number": 1, "cdate": 1571615061229, "ddate": null, "tcdate": 1571615061229, "tmdate": 1574524843214, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "I've read the authors' rebuttal and other reviews; I'd like to keep my score as is. My main concerns are the novelty of the work, the theoretical soundness of the method for small data settings and its robustness in settings with model misspecification. \n\n#################################\n\nThe paper proposes a new approach based on the notion of typical set in probability and tackles the challenging problem of detecting OOD using deep generative models. The main claim of the paper is that assigning high likelihood to OOD samples in DGMs is due to the mismatch between model\u2019s typical set and its high probability density areas. \n\nI liked the idea of proposing a hypothesis testing approach for finding OOD samples generated from a model; however, my main concern is that the approach has some major practical limitation that the authors have also rightly mentioned in their discussion. It seems that even with a hypothesis testing tool for OOD detection, the model capacity and other properties of the model are more fundamental and critical for OOD detection in DGMs. In other words, how this tool can be useful in practice if the models are misspecified and how robust is the tool with respect to model properties. This major limitation has not been addressed in the experiments. \n\nThis paper, does a good job in finding the OOD data points if the likelihood histograms do not overlap using the typicality notion. However, this idea had already been proposed and explored in Choi. et al. 2019 (although for a flow-based model). This makes the technical novelty of the work less significant. \n\nOverall, I think the paper needs some improvement in terms of discussing the robustness of the test with respect to model properties; otherwise, it is just another typicality set explanation of why DGMs may produce high likelihood values for OOD samples which has already been mentioned in previous work. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575664660444, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper354/Reviewers"], "noninvitees": [], "tcdate": 1570237753374, "tmdate": 1575664660457, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Review"}}}, {"id": "B1gx24IkqS", "original": null, "number": 3, "cdate": 1571935400213, "ddate": null, "tcdate": 1571935400213, "tmdate": 1574346877848, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "This paper is concerned with how to determine whether a set of data points are from a given distribution. It uses the so-called typical set to transform the problem to determining whether the data points lie in the typical set of the given distribution. It proposes a statistical test using the empirical distribution of model likelihoods to determine whether inputs lie in the typical set if the considered model. \n\nThe motivation of the work is very clear, and the paper is well organized. The basic idea of using the typical set to check whether given data points are from a given distribution seems sensible, as guaranteed by Theorem 2.1.\n\nMy concern is about the performance of the proposed method compared to alternatives. First, a standard approach to the considered problems seems to be the two-sample tests (or its approximations or variations), so it would be desirable to compare the typical set-based approach with the two-sample test approaches theoretically. In particular, given that you have to allow some error when using typical sets, what is exactly the advantage of the proposed approach?  Second, according to the empirical results (Section 5), the proposed method does not seem to clearly outperform alternatives such as KS-test. In this case, a better justification of the reliability of the proposed approach would be helpful.\n\nI acknowledge I read the authors' response and other reviews and would like to keep my original rating. (I agree that the t-Test and KS-test were probably first used by the authors, but at the same time it is natural to adopt them; that is why I considered them as baselines.)", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575664660444, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper354/Reviewers"], "noninvitees": [], "tcdate": 1570237753374, "tmdate": 1575664660457, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Review"}}}, {"id": "rJe18aQpKH", "original": null, "number": 2, "cdate": 1571794247005, "ddate": null, "tcdate": 1571794247005, "tmdate": 1574093567639, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "Thanks for the authors for your detailed reviews.\n\nMy major concerns about the proposed method are whether \"the typicality set\" could be faithfully applied in the small data regime. The authors point me to the interesting Figure 4, which shows that it basically achieves converged performance when $m = 50$ or smaller numbers for some problems. I think this experiment is a strong support for the proposed method. \n\nHowever, I don't agree that the M=1 Gaussian case acts as a strong support for the method. As I said, for some other wired distribution, it is difficult to interpret what the M=1 Typicality set becomes. \n\nThe authors also clarify the difference between different baselines. \n\nOverall, I will increase my score to \"Weak Accept\".\n\n##########################\n\nRecent works have shown that out-of-distribution samples can have higher likelihoods than in-distribution samples for some generative models. To explain this phenomenon and to tackle the problem for OOD detection, this paper adopts \"typical sets\" for identifying in-distribution samples. Specifically, a \"typical set\" is a set of examples whose expected log likelihood approximate the model's entropy. For a Gaussian distribution, the paper finds that a single point typical set locates exactly in the \\sqrt{d} radius, which is usually favored over the high-likelihood origin. Then the paper uses the \"typical set\" to perform OOD for a batch of examples. Empirically they demonstrate competitive performance over MNIST and natural image tasks. \n\nTypical set seems natural for out-of-distribution detection. An important property is that, if one draws a large number of independent samples from the distribution, it is very likely that these samples belong to the typical set (basically Theorem 2.1).  However,  for small n, this property doesn't hold anymore, which leaves here a questionmark whether \"Typical set\" can be used for OOD detection in small n regime. As the author argues, for Gaussian distribution when n=1 the typical locations are those \\sqrt{d} radius points. But this doesn't justify the \"Typical set\". If the distribution is some non-Gaussian wired distribution, the typical locations doesn't seem to make sense at all.\n\nFollowing the previous argument above, the Typical set method requires to perform OOD for a batch of examples. In contrast, the Annulus method can be directly applied to one single test example. \n\nEmpirically, the Typically set doesn't demonstrate obvious advantages compared to the baselines. For both MNIST and natural image tasks, it seems that all methods behave similarly. For comparing such big tables, I would recommend adding a column showing the average ranks among all methods. Beyond that, standard OOD tasks usually evaluate methods using AUROC and AUPR (Hendrycks and Gimpel, 2017). Is it possible to also include such metrics ?\n\nTheorem 2.1 is confusing. It is beneficial to define what P is, and verbally state what the theorem conveys. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575664660444, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper354/Reviewers"], "noninvitees": [], "tcdate": 1570237753374, "tmdate": 1575664660457, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Review"}}}, {"id": "HkegdfbwoB", "original": null, "number": 4, "cdate": 1573487207803, "ddate": null, "tcdate": 1573487207803, "tmdate": 1573489761565, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "B1gx24IkqS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to R3", "comment": "Thank you for your feedback, R3.  We are glad that you found the work\u2019s motivation \u201cvery clear\u201d and the paper \u201cwell organized.\u201d  Hopefully we can dispel your reservations below.\n\n1. Performance in Comparison to Baselines:  Firstly, let us clarify that the only relevant baseline from the goodness-of-fit-testing literature is the Kernelized Stein Discrepancy (KSD).  As stated in Sec 3.1, we are aware of no other GoF test that can be widely applied across all types of deep generative models.  As for our test vs KSD, they perform roughly the same in all cases except for the PixelCNN trained on FashionMNIST.  KSD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.  Yet an additional factor that differentiates the two is runtime: KSD is drastically slower, requiring an $\\mathcal{O}(dM^{2})$ evaluation time (with M representing the batch size) in addition to the cost of computing derivatives through the model.  Our method is $\\mathcal{O}(M)$ after the likelihoods have been computed from the model.  With runtime considered, the results clearly favor our method.\nSecondly, the t-Test and KS-test baselines are not really \u2018competitors\u2019 as they are (i) proposed by us and (ii) closely based on our typicality test.  The t-test is just the typicality test with $\\epsilon = 0$, and the KS-test is comparing all moments, whereas our typicality test is comparing just the first.  Thus, these tests should perform comparably!  The fact that the KS-test and ours perform so similarly can be seen as positive evidence for our method since it validates that the first moment (i.e. entropy) is truly the critical one for testing OOD.  \nThirdly, the Maximum Mean Discrepancy (MMD) baseline is not a `'valid' competitor as it is performing a two-sample test, not a GoF test.  We provide MMD only as a reference point to see how testing against $p^{*}$ compares to testing against $p_{\\theta}$.  Lastly, the annulus method [Choi et al., 2019] is simply what our test reduces to in the special case of the $(\\epsilon, M=1)$-typical set for isotropic Gaussians (which we state on p 6).\n\n2.  \u201cA standard approach to the considered problems seems to be the two-sample tests\u201d: This is incorrect.  Two-sample tests assume the setting $q$ vs $p^{*}$, with $p^{*}$ being the inaccessible underlying generative process.  Rather, we are testing  $q$ vs $p_{\\theta}$, with $p_{\\theta}$ being a model to which we have access.  Yet we do report an MMD baseline in the experiments in anticipation of readers wondering how a two-sample test would perform in the same setting.  We find it to perform comparably except in the same setting mentioned for KSD above: for the PixelCNN trained on FashionMNIST, MMD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.  Note that this performance was only able to be achieved when we derived the MMD kernel from the generative model.  Otherwise, performance was strictly worse than our test.   Moreover, MMD is much more expensive to compute as it is $\\mathcal{O}(MNd)$ (as mentioned on p 6).    \n\n3.  \u201cGiven that you have to allow some error when using typical sets, what is exactly the advantage of the proposed approach?\u201d:  We are not sure what you mean exactly by \u201callow for some error.\u201d  But to summarize our contributions once more: (1) we propose typicality as an explanation for the OOD phenomenon in deep generative models, (2) derive a GoF test widely applicable across all deep generative model classes and with better runtime than KSD, (3) show that this test, despite it using only the first moment of the empirical likelihoods (which makes runtime cheap), is able to detect the OOD set in many of the cases reported by [Nalisnick et al., 2019].    \n\nAgain, thanks for taking the time to read our paper.  We look forward to further discussion."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "HkgW0N-woB", "original": null, "number": 6, "cdate": 1573487816664, "ddate": null, "tcdate": 1573487816664, "tmdate": 1573487816664, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "rJe18aQpKH", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to R1", "comment": "Thank you for taking the time to read our paper, R1.  We are glad that you found our approach \u201cnatural for out-of-distribution detection.\u201d  Please consider the following rebuttals to your critiques.\n\n1. Small $M$ Behavior:  You are correct in that Thm 2.1 only holds for sufficiently large $M$, and therefore it is not obvious that a typicality-based test behaves correctly in the small-$M$ regime.  Firstly, we emphasize that GoF testing for deep generative models is still a completely open problem even in the large-M regime.  As KSD is the primary competitor and scales as $\\mathcal{O}(M^{2})$, even a procedure that performs well for large M is a contribution.  And as can be seen in Figure 4, our test works near perfectly for $M>50$, and this prompted us to focus the main experimental section on the $M \\in \\{2, 10, 25 \\}$ regime.  \nNow returning to the main point, we have two pieces of evidence for the test\u2019s correctness for small $M$.  The first is theoretical: examining the Gaussian case, the $(\\epsilon=0, M=1)$-typical set is $\\mathcal{A}_{0}^{1}[N(x;\\mu, \\sigma)] = \\{x \\mid || x - \\mu ||_{2} = \\sigma \\sqrt{d} \\}$, the shell of radius $\\sigma \\sqrt{d}$.  This is quite a narrow region of the support, which speaks to the inapplicability of Thm 2.1.  Yet as we are given only one test instance, such a restriction seems to be the most appropriate choice.  It is clearly better than picking the mode, for instance.  Our second piece of evidence is experimental: Our test performs reasonably well in the $M=10$ regime and in cases can achieve near perfect OOD classification for $M=2$.  In the case of Glow trained on SVHN, 98% of CIFAR-10 batches and 100% of ImageNet batches were correctly classified at $M=2$.  Hence, our test must be checking sensible regions of data space or such good results could not be possible.  In turn, we find the claim that \u201cthe typical locations doesn't seem to make sense at all [for small $M$]\u201d completely speculative.  Can you please provide some reasoning in support of your claim?   \n\n2.  Performance in Comparison to Baselines:  Firstly, let us clarify that the only relevant baseline from the goodness-of-fit-testing literature is the Kernelized Stein Discrepancy (KSD).  As stated in Sec 3.1, we are aware of no other GoF test that can be widely applied across all types of deep generative models.  As for our test vs KSD, they perform roughly the same in all cases except for the PixelCNN trained on FashionMNIST.  KSD is unable to detect MNIST as OOD, and our test is unable to detect NotMNIST as OOD.  Yet an additional factor that differentiates the two is runtime: KSD is drastically slower, requiring an $\\mathcal{O}(dM^{2})$ evaluation time (with M representing the batch size) in addition to the cost of computing derivatives through the model.  Our method is $\\mathcal{O}(M)$ after the likelihoods have been computed from the model.  With runtime considered, the results clearly favor our method.\nSecondly, the t-Test and KS-test baselines are not really \u2018competitors\u2019 as they are (i) proposed by us and (ii) closely based on our typicality test.  The t-test is just the typicality test with $\\epsilon = 0$, and the KS-test is comparing all moments, whereas our typicality test is comparing just the first.  Thus, these tests should perform comparably!  The fact that the KS-test and ours perform so similarly can be seen as positive evidence for our method since it validates that the first moment (i.e. entropy) is truly the critical one for testing OOD.  \nThirdly, the Maximum Mean Discrepancy (MMD) baseline is not a `valid\u2019 competitor as it is performing a two-sample test, not a GoF test, which is the topic of our paper.  We provide MMD only as a reference point to see how testing against $p^{*}$ compares to testing against $p_{\\theta}$.  Lastly, the annulus method [Choi et al., 2019] is simply what our test reduces to in the special case of the $(\\epsilon, M=1)$-typical set for isotropic Gaussians (which we state on p 6).\n\n3.  \u201cThe Typical set method requires to perform OOD for a batch of examples. In contrast, the Annulus method can be directly applied to one single test example.\u201d:  Pitting the annulus method vs our typicality test is a false dichotomy.  The annulus method (as mentioned above) is a special case of our test, and the only reason it can be used for one-sample is that it\u2019s assuming the $(\\epsilon, M=1)$-typical set.   \n\n4.  AUROC metrics:  As far as we are aware, AUROC metrics in the literature are computed for point-wise rejection rules.  Thus they would not be comparable to our hypothesis testing / batch-wise methodology, which we believe to be the first of its kind for deep generative models.  Yet, we thank the reviewer for the suggestion, and we will look into adding ROC-based metrics to our revised draft.  \n\n5.  Thm 2.1:  Thank you for the feedback.  We will add more discussion of the intuition.\n\nAgain, thanks for sharing your thoughts.  We look forward to further discussion."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "SyxuDmbwsS", "original": null, "number": 5, "cdate": 1573487456241, "ddate": null, "tcdate": 1573487456241, "tmdate": 1573487456241, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "HJep8WdqtH", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to R2", "comment": "Thank you for your comments, R2.  We are glad to hear that you \u201cliked the idea of proposing a hypothesis testing approach\u201d and appreciate that the method \u201cdoes a good job in finding the OOD data points.\u201d  We hope to address your doubts below.\n\n1. Novelty w.r.t. Annulus Method:  It is incorrect to state that Choi et al. [2019] have previously \u201cexplored\u201d a typicality-based solution.  Their annulus method is what our test reduces to in the *special case* of the $(\\epsilon, M=1)$-typical set for isotropic Gaussians (which we state on p 6).  Choi et al. make no mention of the general entropy-based definition of typicality (our Def 2.1).  Nor do they give any methodology for testing the $(\\epsilon, M>1)$-typical set in Gaussians, let alone any other class of deep generative model (eg PixelCNN, VAEs).   Previous to our work, the question of how to test for typicality *in every class of deep generative model except Gaussian flows* was completely wide open and unaddressed.  \n\n2. Behavior Under Misspecified Models:  While model misspecification is certainly a concern when building generative models, the topic of our paper is not model building.  Rather, we focus on testing a given, pre-trained generative model.  Or to be precise, we are testing $q$, some unknown distribution we observe only through samples, vs $p_{\\theta}$, the pre-trained model.  Model misspecification tests $p^{*}$, the distribution of the training data, vs $p_{\\theta}$ (or $p_{\\theta}$ vs $p_{\\theta\u2019}$).  Clearly these are much different settings, making an analysis of misspecification well out-of-scope for our paper.\n\nAgain, thank you for taking the time to read our draft.  We look forward to further discussion of these points."}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "r1g_qGinFS", "original": null, "number": 4, "cdate": 1571758735885, "ddate": null, "tcdate": 1571758735885, "tmdate": 1571759029301, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "S1eMVHqnYS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment", "content": {"comment": "Now I think I understand the motivation example, which is indeed insightful and interesting. \n\nI don't think it is easy to quantify the transition, either. One way is to get closed form of the probability of the typical set for any finite $M$, when $p$ is given. But of course, this can be pretty hard. Is it simpler to get a somewhat tight lower bound? Or using experiments (like Monte-Carlo) for given $p$ to estimate it? Just random thoughts, but this is a good question to think about. Actually in many information theory problems, one really does not care about the exact number to be 'sufficiently large'. For example, in lossless source coding, Shannon allowed the code length to be infinite. \n\nNice work!", "title": "Thanks again"}, "signatures": ["~Shengyu_Zhu1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Shengyu_Zhu1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504210285, "tmdate": 1576860580534, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment"}}}, {"id": "S1eMVHqnYS", "original": null, "number": 3, "cdate": 1571755305678, "ddate": null, "tcdate": 1571755305678, "tmdate": 1571755324985, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "BkgdQXF3tS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"title": "Thanks for the Clarification", "comment": "Thanks for the clarification.  I think we understand your point now (but please correct us if not).\n\nAs for at what value of $M$ does the AEP kick-in, it must do so at $M > 50$ since we observe that type-I and type-II error are essentially nonexistent in nearly all cases tested.  For $M \\le 50$, it\u2019s hard to say.  Please let us know if you have any ideas about how to directly quantify the transition.\n\nYet you do make a good point about Thm 2.1 in the small $M$, small $\\epsilon$ regime.  Theorem 2.1 indeed does not apply in this regime, and the sentence that you quoted has the potential of being interpreted too generally.  Yet we believe it\u2019s important to emphasize (for other readers, at least) that just because Thm 2.1 doesn\u2019t apply here, that doesn\u2019t mean that the procedure is ill-behaved.  Returning to the isotropic Normal example once more, the $(\\epsilon=0, M=1)$-typical set is $\\mathcal{A}_{0}^{1}[N(x;\\mu, \\sigma)] = \\{x \\mid || x - \\mu ||_{2} = \\sigma \\sqrt{d} \\}$, the shell of radius $\\sigma \\sqrt{d}$.  Clearly this set is a poor summary of what we expect to be generated by $N(x;\\mu, \\sigma)$, which speaks to the inapplicability of Thm 2.1.  But since we are testing only one sample ($M=1$), it makes sense that our procedure would become conservative, only letting the test pass if $\\tilde{x}$ falls in a very restricted region.  We will incorporate this discussion into the paper during the next revision.  Thanks again for the discussion. "}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "BkgdQXF3tS", "original": null, "number": 3, "cdate": 1571750688157, "ddate": null, "tcdate": 1571750688157, "tmdate": 1571751867671, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "Bye1z-83Fr", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment", "content": {"title": "More about question", "comment": "Once again, thanks for your prompt response. It was regarding your last paragraph. Let me quote this sentence right after Eq. (2):\n\n'The intuition is that if $\\tilde X$ indeed sampled from $p_\\theta$, then with high probability it must reside in the typical set (Theorem 2.1)'.\n\nAEP or Theorem 2.1 requires $N$ or here $M$ to be large enough, or let's say 'sufficiently large'. Then the probability of the typical set is $> 1-\\epsilon$ for any fixed $\\epsilon>0$. The exact number being 'sufficiently large' depends on the distribution and also $\\epsilon$. My question is, with $M=150$ or any given number, is this $M$ indeed 'sufficiently large' so that the probability of the typical set is high? I don't think that this statement can be verified by the AEP or Theorem 2.1, but the experiment with In-Distribution testing should be able to.\n\nPlease let me know if question is clear now and also if my understanding is correct. Thanks."}, "signatures": ["~Shengyu_Zhu1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Shengyu_Zhu1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504210285, "tmdate": 1576860580534, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment"}}}, {"id": "Bye1z-83Fr", "original": null, "number": 2, "cdate": 1571737862856, "ddate": null, "tcdate": 1571737862856, "tmdate": 1571737862856, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "rJglnNe2FH", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"title": "Requesting Clarification", "comment": "Thanks for continuing the discussion, Shengyu.  We agree that the AEP cannot be used when $M$ is small.  However, we are not sure of exactly what you're asking in your last statement.  Are you referring to Thm 2.1: $P(\\mathcal{A}^{N}_{\\epsilon}[p(x)]) > 1 - \\epsilon$ (with $N$ now serving for $M$)?  "}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "rJglnNe2FH", "original": null, "number": 2, "cdate": 1571714216037, "ddate": null, "tcdate": 1571714216037, "tmdate": 1571714333537, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "BJg0bvGoKH", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment", "content": {"title": "Thanks for your response", "comment": "Thanks for your quick response. It was my bad to misunderstand the proof: it is $\\mathbf E_q[-\\log p(x)]$ which I mistakenly thought as $\\mathbf E_q[-\\log q(x)]$. And also I did not look at the appendix for more experiments. So thanks again for your response. \n\nI agree with you that a small $\\epsilon$ can give more stringent condition, but still the AEP cannot be used with a small number $M$. Of course AEP only gives a lower bound. Here you want to show that even with small number the probability of typical set (through In-Distribution) is also high. Is this correct?"}, "signatures": ["~Shengyu_Zhu1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Shengyu_Zhu1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504210285, "tmdate": 1576860580534, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment"}}}, {"id": "BJg0bvGoKH", "original": null, "number": 1, "cdate": 1571657477551, "ddate": null, "tcdate": 1571657477551, "tmdate": 1571657544218, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "HkgtMunUFB", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment", "content": {"comment": "Hi Shengyu, \n\nThanks for taking the time to read our paper and share your thoughts.  It\u2019s much appreciated.\n\nI\u2019m not sure that we follow your line of reasoning about the small-$M$ regime.  Let\u2019s return to the $M=1$ Gaussian example but now with d=1 (with $d$ denoting dimensionality) so that there\u2019s no dimension-wise factorization to consider.  In this case the test would simplify to: $ \\mid \\sigma^{2} - (x - \\mu)^{2} \\mid \\le 2 \\sigma^{2} \\epsilon$.  Intuitively this expression is testing if $x$\u2019s distance from the mean is roughly $\\sigma$, with the bound relaxing as a function of $\\sigma$.  This seems like reasonable behavior to us.  One interesting stress test to consider is the case of $x \\approx \\mu$, which could easily happen in the $d=1$ case.  We\u2019d then have to set $\\epsilon \\ge \\frac{1}{2}$ for the bound to hold.  Yet still $\\epsilon = 1/2$ does not seem like an unreasonably high setting for $\\epsilon$ that would signal that our test is problematic.\n\nIn general, we don\u2019t agree that \u201cit is quite strange to consider only one or few samples when talking about typicality.\u201d  You seem to imply that $\\epsilon$ must be set large, but this is not the case.  Rather, it\u2019s just that the criterion for what is a \u2018typical\u2019 batch of samples becomes more stringent.  To see this, consider the general bound $ \\mid \\frac{1}{M} \\sum_{m=1}^{M} -\\log p(x_{m}) - \\mathbb{H}[p]  \\mid \\le \\epsilon$ (Equation 3).  For small $M$, this means that those few samples must approximate the entropy very well for the test to pass.  In the Gaussian example (for general $d$), it must be that all $x_{m}$\u2019s fall very close to the annulus radius.  For large $M$, a few samples can be far from the annulus just so long as the mean log density is still close to the entropy---hence the small-$M$ case being \u2018more stringent\u2019 as there is more contribution from any given sample.  \n\nAs for your comment on the proof, we appreciate you taking the time to read even the appendix.  However, we don\u2019t quite agree that the subset condition is equivalent to saying the distributions $p$ and $q$ have the same entropy.  Consider the case $p=N(\\mu=-1000, \\sigma=1)$ vs $q=N(\\mu=1000, \\sigma=1)$.  These distributions have the same entropy, but clearly $\\mid \\mathbb{E}_{q}[ -\\log p(x)] - \\mathbb{H}[p]  \\mid >> 0$.\n\nLastly, we do indeed have results for $M > 25$.  Please see Appendix E.3, Figure 4 for results showing when $M$ is as large as $150$.  Our procedure achieves near perfect discrimination of the OOD set on almost all of the dataset pairs (which, of course, is due to the AEP kicking in, as you mention). Since our method achieved excellent OOD performance for high-values of $M$, we thought the more interesting and practically relevant experimental question was to understand how OOD detection changes as $M$ is decreased.  That\u2019s why we focused on $M \\le 25$ in the main experimental section.  We will update the text to clarify this.   ", "title": "Author Response"}, "signatures": ["ICLR.cc/2020/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper354/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper354/Authors|ICLR.cc/2020/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172679, "tmdate": 1576860547180, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Official_Comment"}}}, {"id": "HkgtMunUFB", "original": null, "number": 1, "cdate": 1571371025108, "ddate": null, "tcdate": 1571371025108, "tmdate": 1571561497000, "tddate": null, "forum": "r1lnxTEYPS", "replyto": "r1lnxTEYPS", "invitation": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment", "content": {"comment": "Dear authors,\n\nIt is interesting to see another paper on typicality on ICLR. Yet I don't quite understand the motivation example for typicality, and also the problem of testing typicality.\n\nTypical set indicates that a small set, compared to the whole support, takes most of the probability (e.g., when considering finite sample space, this can be understood as number of different sample sequences). In my experience, typicality is meaningful if you have a large number of i.i.d. samples so that law of large numbers can be used (Theorem 2.1 in your manuscript) and $\\epsilon$ defining the typical set is small so that sample sequences contained in the $\\epsilon$-typical set is 'close' to be typical. In this sense, it is quite strange to consider only one or few samples when talking about typicality. For the Gaussian example with $\\mathcal N(0, I)$ with high dimension, as you also point out in footnote, it is OK to consider so because each dimension can be considered independent and has the same marginal distribution. For images, this does not hold true: different pixels are not independent and are very likely to have different marginal distributions.\n\nFor the problem defined in Eq.~(2): if the deviation parameter $\\epsilon$ is large, then the sample sequence in a typical set is not that 'typical'; on the other hand, if $\\epsilon$ is small and the number of sample is also small, say,  $M=25$  (which I found to be the largest number considered in this paper; correct me if I'm wrong), AEP or law of large numbers cannot be used and the probability of typical set can be low, which seems somewhat contradictory to the meaning of typicality. \n\nBy the way, in Section 3.2., the condition that $\\mathcal A_{\\epsilon}[q(x)]$ is not a subset of $\\mathcal A_{\\epsilon}[p(x)]$, with your proof in Appendix A.2 where $M$ is sufficiently large,  seems equivalent to say that $p$ and $q$ do not have the same entropy: with $\\epsilon <  |H(p)-H(q)|/2$, this adopted condition in the paper hold with high probability when $M \\to\\infty$.", "title": "Interesting work. Some questions about the motivation example and the problem of testing typicality."}, "signatures": ["~Shengyu_Zhu1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Shengyu_Zhu1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Balaji Lakshminarayanan"], "authorids": ["e.nalisnick@eng.cam.ac.uk", "matsukaw@deshaw.com", "ywteh@google.com", "balajiln@google.com"], "keywords": ["Deep generative models", "out-of-distribution detection", "safety"], "TL;DR": "We propose detecting out-of-distribution inputs to deep generative models via a goodness-of-fit test based on the model entropy.", "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data [Nalisnick et al., 2019; Choi et al., 2019].  We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density.  In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed [Bishop, 1994].  To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods.  The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated.  We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. [2019].", "pdf": "/pdf/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "paperhash": "nalisnick|detecting_outofdistribution_inputs_to_deep_generative_models_using_typicality", "original_pdf": "/attachment/7e71c3a6e00f6b3f41205ba1c24e4cc2d6a0ded8.pdf", "_bibtex": "@misc{\nnalisnick2020detecting,\ntitle={Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\nauthor={Eric Nalisnick and Akihiro Matsukawa and Yee Whye Teh and Balaji Lakshminarayanan},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lnxTEYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lnxTEYPS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504210285, "tmdate": 1576860580534, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper354/Authors", "ICLR.cc/2020/Conference/Paper354/Reviewers", "ICLR.cc/2020/Conference/Paper354/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper354/-/Public_Comment"}}}], "count": 15}