{"notes": [{"id": "EArH-0iHhIq", "original": "mKPIKbtQ3w-", "number": 3312, "cdate": 1601308367682, "ddate": null, "tcdate": 1601308367682, "tmdate": 1614985744011, "tddate": null, "forum": "EArH-0iHhIq", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "mMJHcVCOZIQ", "original": null, "number": 1, "cdate": 1610040393250, "ddate": null, "tcdate": 1610040393250, "tmdate": 1610473987904, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper looks into generalization performance of NNs in supervised learning setting. The authors propose a regularizer to enhance neuron diversity in each layer(within-layer activation diversity) as a regularizer to improve generalization.  The proposed idea is an extension of Cogswell's work with different regularization terms. The appearance of the term related to the layer output diversity in the generalization bound provides theoretical support for the proposed idea.They use Radamacher complexity as a tool to show this and bound the estimation error.\n\npros.\n-The paper looks into an interesting problem. Designing a regularizer to improve generalization performance of NNs is of huge importance.\n-The paper is well-presented and clear.\n\ncons.\n-The main drawback of the paper is lack of proper comparison to other regularizers and showing the uniqueness/superiority of this regularizer and how it improves over existing methods either theoretically or with experiments. Without that the significance of this work is limited. \n-The authors response to Reviewer 2's comment was not convincing enough. I encourage the authors to improve this in the next iteration of the paper. \n- i suggest doing a better job in including the related work as also mentioned by the reviewer.\n-The experiment section can use more explanation and details on choice of hyper parameters, etc \n- showing performance improvement for a deep architecture would definitely  improve the paper. In the current version only 2 and 3 layer toy examples are shown."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040393237, "tmdate": 1610473987886, "id": "ICLR.cc/2021/Conference/Paper3312/-/Decision"}}}, {"id": "PSTTIdq8EOf", "original": null, "number": 3, "cdate": 1603930358601, "ddate": null, "tcdate": 1603930358601, "tmdate": 1607329591856, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review", "content": {"title": "A neat extension encouraging layer output diversity with theoretical backing", "review": "This paper proposes adding regularization terms to encourage diversity of the layer outputs in order to improve the generalization performance. The proposed idea is an extension of Cogswell's work with different regularization terms. In addition, the authors performed detailed generalization analysis based on the Rademacher complexity. The appearance of the term related to the layer output diversity in the generalization bound provides theoretical support for the proposed idea.\n\nThe main weakness of this paper, in my humble opinion, is the lack of important details or rigor in the experiments presented. For example, the authors didn't mention how the hyperparameter selection was conducted, what optimizer (and its parameters) was used, how many runs per result and the confidence interval, whether any test was done to establish statistical significance, why state-of-the-art architecture was not used for the image classification tasks, etc. Without these important details and rigorous comparison, it's hard to have high confidence in the reproducibility of the results.\n\nDetails:\n1) Intro section. The line of work in \"double descent\" shows that overparameterization doesn't necessarily lead to overfitting. For completeness, it'll be good to mention this line of work and qualify the claim on overfitting.\n2) End of section 2. The authors claim that the proposed diversity term induces \"within-layer\" feedback. The regularization term is computed on the outputs of a layer, which do depend on the parameters of the lower layers. So when backpropagation happens, it will affect the parameters of the lower layers. Therefore, \"within-layer\" feedback doesn't sound accurate to me.\n3) Section 3.1, last bullet point. Should $\\tau$ be introduced here?  Otherwise, where does the $\\tau$ later used in Lemma 3.5, Lemma 3.6 and Theorem 3.7 come from?\n4) Section 5. The proposed regularization terms don't seem cheap to compute for large networks with wide layers. It'll be helpful to measure the training cost increase.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078092, "tmdate": 1606915770587, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3312/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review"}}}, {"id": "tHSOqzp7Z_q", "original": null, "number": 8, "cdate": 1606247744079, "ddate": null, "tcdate": 1606247744079, "tmdate": 1606247744079, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "o05wMyqHb6j", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "Thank you for the catching this! The assumption defined in the paper lower-bounds $(\\phi_n(x)\u2212\\phi_m(x ))^2$ for a neuron-pair (m,n) by $d_{min}$ with a probability $\\tau$ and in (Eq. 22) this lower-bound was erroneously used over the sum of different pairs. However, a given network topology, the number of neurons in each layer is fixed, so we can still use the assumption defined in the paper to bound the distance of a single neuron-pair (m,n) and reformulate the probability of the sum to reflect all neuron-pairs: As each neuron-pair verifies the assumption with a probability $\\tau$, then with a probability at least $\\tau^Q$, the sum is lower-bounded by $M(M-1)*d_{min}$, where M is the number of neurons and $Q = \\frac{M(M-1)}{2}$ is the number of neuron-pairs for M neurons in the layer. We have now corrected the theorems and proofs in the revised paper using $\\tau^Q$."}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "o05wMyqHb6j", "original": null, "number": 7, "cdate": 1606214594152, "ddate": null, "tcdate": 1606214594152, "tmdate": 1606214594152, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "82i9Le5EC0", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Still not convinced", "comment": "Thank you for your reply.\nI however still remain skeptical regarding the theoretical developments. \nIn particular, the way \\tau is manipulated is not convincing.  \nOn page 2, \\tau is defined by assuming that \u2018with a high probability \\tau; the distance between the output of each pair of neurons, is lower bounded by d_{min} for any input x\u2019. \nIn the appendix (Section 7.1), when deriving one of the key contribution of the paper, Eq. (22) refers to this definition of \\tau to justify that, with a probability \\tau, the sum of the products between the activations of all pairs of distinct neurons is upper bounded by a function that decreases with d_{min}^2. Actually, this directly results from the fact that the definition of \\tau is used to state that, with a probability \\tau, the mean (over all pairs of different neurons) of the squared distance between the neuron activations is lower bounded by d_{min}^2\nThis statement is incorrect. Indeed, this is not because a distance lower bound d_min is valid with probability \\tau on individual pairs of activations, that the squared sum of the distances over all the N distinct pairs of neurons is lower bounded by N times d_min^2, with probability \\tau. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "CZ48wRpYz3f", "original": null, "number": 3, "cdate": 1605517483931, "ddate": null, "tcdate": 1605517483931, "tmdate": 1605555235969, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "PSTTIdq8EOf", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "We thank the Reviewer for the positive feedback and finding our contribution neat and theoretically founded. Below we want to address some questions that we think are important to clarify first:\n\n*1-For example, the authors didn't mention how the hyperparameter selection was conducted, what optimizer (and its parameters) was used*\n\nAs stated in the end of the first paragraph of Section 5.2, the hyperparameter tuning protocol used in the classification is the same protocol used in the regression Section 5.1. However, we agree with the Reviewer that this can be confusing and some details are missing. To this end, we described the training protocol in the classification, i.e., Section 5.2, and provided more details about the training protocol. \nThe models were trained for 150 epochs using stochastic gradient descent with a learning rate of $0.01$ and categorical cross entropy loss. For hyperparameter tuning, we kept the model that performs best on the validation set and use it in the test phase. We experimented with three different activation functions for the hidden layers: Sigmoid, Rectified Linear Units (ReLU), and LeakyReLU. Moreover, in the revised version of the paper, we now report average results over 4 trials with the standard deviation indicated alongside.\n\n\n*2-Intro section. The line of work in \"double descent\" shows that overparameterization doesn't necessarily lead to overfitting. For completeness, it'll be good to mention this line of work and qualify the claim on overfitting.*\n\nWe indeed missed several relevant citations to prior works on 'double descent' as you mention, and we thank you  for pointing them out to us. We have updated the Introduction of the paper to reflect the connections to prior work more explicitly. The following references were mentioned:  (Belkin et al., 2019); (Advani et al., 2020); (Nakkiran et al., 2020).\n\n\n\n*3-End of section 2. The authors claim that the proposed diversity term induces \"within-layer\" feedback. The regularization term is computed on the outputs of a layer, which do depend on the parameters of the lower layers. So when back-propagation happens, it will affect the parameters of the lower layers. Therefore, \"within-layer\" feedback doesn't sound accurate to me.*\n\nWe completely agree with the Reviewer that the regularization term is computed on the outputs of a layer, which does depend on the parameters of the lower layers. Indeed, the error induced by this additional term is back-propagated to the earlier layers, similar to any regularization technique. Here, the term 'within-layer' feedback refers to two things: (i) This feedback is computed using neurons within the same layer. (ii) Using this additional loss term, each neuron within the same layer provides a 'direct' feedback to the adjacent neurons. In the standard back-propagation, neurons also provide feedback to their same layer: after the forward pass, the signal goes backward to the layer providing a feedback form all the layers. However, this can be seen as an indirect feedback, whereas the additional term introduced in our paper provides a direct one.\n\n\n*4-Section 3.1, last bullet point. Should $\\tau$ be introduced here? Otherwise, where does the  later used in Lemma 3.5, Lemma 3.6 and Theorem 3.7 come from?*\n\nThe Reviewer is right. $\\tau$ should be re-introduced in the assumptions. Thank you for pointing this out. We modified the last bullet point accordingly.\n\n\n*5-Section 5. The proposed regularization terms don't seem cheap to compute for large networks with wide layers. It'll be helpful to measure the training cost increase.*\n\nThank you for the suggestion. We agree with the reviewer that it will be helpful to provide computational complexity analysis of our approach. We updated the manuscript, we report the theoretical computational complexity of the three variants in Section 2: \n\"For a layer with $C$ neurons and a batch size of $N$, the additional computational cost is O($C^2(N+1)$) for direct variant and O($C^3 + C^2N)$) for both the determinant and log of the determinant variants.\" \nWe also report the time cost increase of the training in the experimental Section:\n\"Compared to the vanilla approach, we note that the model training time cost  on CIFAR100 increases by $9%$% for the  direct approach, by $36.1%$% for the determinant variant, and by $ 36.2$% for the log of determinant variant.\"\n\n\n\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "82i9Le5EC0", "original": null, "number": 6, "cdate": 1605518623286, "ddate": null, "tcdate": 1605518623286, "tmdate": 1605519137417, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "p4gcjKqbZNg", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer1 (2/2)", "comment": "*B: The theoretical developments build on the assumption that (i) there exists a lower bound, valid for any input, to the distance between the output of each pair of neurons, and (ii) the proposed diversity loss increases this lower bound. Those two assumptions are central to the theoretical developments, but are quite arguable. For example, a pair of neuron that is not activated by a sample, which is quite common, leads to a zero lower bound.*\n\n*(i) there exists a lower bound, valid for any input, to the distance between the output of each pair of neurons.* \\\nWe agree that the above assumption mentioned by the Reviewer is impractical especially if the intermediate layer has ReLU activation (for a given sample, there is a large chance that two neurons will have a zero activation and thus $d_{min}$ in practice would correspond to zero). However, we note that in our theoretical analysis, we consider a relaxed variant of this assumption by introducing the relative probability $\\tau$. In fact, we formulate our claim as 'With a probability $\\tau, $ the distance between the output of each pair of neurons, $( \\phi_n(\\textbf{x}) - \\phi_m(\\textbf{x}))^2 $, is lower bounded by $d_{min}$ for any input $\\textbf{x}$'. Thus, by introducing $\\tau$, the assumption becomes practical and the findings of the Theorems remain valid and practical.  \\\n*(ii) the proposed diversity loss increases this lower bound. For example, a pair of neuron that is not activated by a sample, which is quite common, leads to a zero lower bound.* \\\n1- Note that empirically the additional loss term is computed per-batch and, thus, if two given pairs of neurons in the same layers are both not activated for all the samples within the batch then the additional loss term is (1/N)*N=1. This is the maximum value of the additional loss term that we are trying to minimize. Thus, during the training the model will be more keen on separating their activation to minimize the additional loss. \\\\\n2- We note that $d_{min}$, defined as the minimum distance between the pair of neurons with a given probability $\\tau$, is indeed lower bounded by zero. Moreover, for the case $d_{min}=0$, the upper-bound of the estimation error (Theorems 3.7, 3.8, 3.9, 3.10, 3.11) is maximized and hence the generalization gap increases, i.e., we do not have a good generalization gap anymore, whereas maximizing this term yields a tighter upper-bound and a better generalization. \nIt should be noted that Theorems 3.7-3.11 only claim that  a larger minimum distance between the neurons activations within the same layer for an input $\\textbf{x}$ with a high probability $\\tau$ yields a tighter bound and thus might help improving the generalization ability.\n\n*C: Experimental validation are not convincing. Only shallow networks are considered (2 or 3 layers), and the optimization strategy, including the grid search strategy for hyper parameters selection, is not described.*\n\nAs stated in the end of the first paragraph of Section 5.2, the hyperparameter tuning protocol used in the classification is the same protocol as in the regression Section 5.1. However, we agree with the Reviewer that this can be confusing. To this end, we describe the training protocol for the classification in Section 5.2 and provide more details about the training protocol: \\\nThe models were trained for 150 epochs using stochastic gradient descent with a learning rate of $0.01$ and categorical cross entropy loss. For hyperparameter tuning, we kept the model that performs best on the validation set and use it in the test phase. We experiment with three different activation functions for the hidden layers: Sigmoid, Rectified Linear Units (ReLU), and LeakyReLU. Moreover, in the revised version of the paper, we now report average competitive results over 4 trials with the standard deviation indicated alongside.\nThe main focus of the paper is to provide some theoretical insights on how the generalization error is related to the neuron activation outputs and to show how employing a diversity strategy can help close the generalization gap. \n\n*Minor issue: positioning with respect to related works is limited. For example, layer redundancy (which is the opposite of diversity) has been considered in the context of network pruning: https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Filter_Pruning_via_Geometric_Median_for_Deep_Convolutional_Neural_Networks_CVPR_2019_paper.pdf*\n\nThank you for pointing this out. We followed the Reviewer's suggestion and updated the related work section by citing the following references on pruning using the redundancy concept: (Kondo & Yamauchi, 2014; (He et al., 2019); (Singh et al.,2020); (Lee et al., 2020).\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "yFCtAf4Hg6R", "original": null, "number": 4, "cdate": 1605517634767, "ddate": null, "tcdate": 1605517634767, "tmdate": 1605518694436, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "rOJ7gTfoxz9", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer2", "comment": "We thank the Reviewer for finding our approach interesting both theoretically and empirically. We hope to provide clarifications and additional results to address the highlighted issues. Please, let us know if there are further questions.\n\n*Other constants appearing in the theorems:*\n\nIndeed, the foundation developed in our paper (Theorems 3.7 to 3.12) can be used beyond the diversity strategy and many other novel (or old) approaches can be theoretically motivated or inspired using our theory to improve the generalization ability of neural networks.  \nFrom this perspective, the theoretical contribution of our paper can be seen as generic and can motivate future works. However, we should note that the focus of the paper is more toward the within-layer activation diversification strategy, which to the best of our knowledge has never been theoretically studied before, as opposed to weight decay for example which has been theoretically motivated in [1] or dropout with has been theoretically motivated in [2]. \nNote that weight decay in particular can be motivated using our paradigm: As it can be seen in Theorems 3.7-3.12 and as already pointed out by the Reviewer, the upper-bounds found are inversely proportional to $C_3$ and $C_4$, which control the norm of the weight matrices. We agree with the remark of the Reviewer that $C_4$ and $C_5$ yield a quadratic decay compared to the linear decay with respect to $d_{min}$. However, one also should note that both of these constants have a strict lower-bound of 0 (which corresponds to a weight matrix of zero), and thus minimizing them has a certain practical limit, whereas $d_{min}$ does not have any upper limit in the case of ReLU activation for example (ReLu does not have an upper-bound and thus one can always find a distribution of activations within the same layer such that the minimum distance between each two neurons is 'well' spread). It is worth mentioning that both techniques are not mutually exclusive and one can, for example, employ a weight decay over the weight matrices and a within-layer diversity strategy over the activations of the layers. Note that in this work, we do not compete with or claim superiority to weight decay.  Our aim is to motivate a new direction of research, where  activation diversity is the centre of interest and to provide some insights to how the generalization error is related to the neuron outputs.\n\n[1] Bartlett, Peter L. and Mendelson, Shahar. \"Rademacher and Gaussian complexities: Risk bounds and structural results.\" Journal of Machine Learning Research 3.Nov (2002): 463-482. \\\n[2] Wan, Li, et al. \"Regularization of neural networks using dropconnect.\" International conference on machine learning. 2013. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "p4gcjKqbZNg", "original": null, "number": 5, "cdate": 1605518408058, "ddate": null, "tcdate": 1605518408058, "tmdate": 1605518408058, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "G69F_m1IJYG", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer1 (1/2)", "comment": "We thank the Reviewer for characterizing the problem tackled in our paper as important. \nThe Reviewer challenged the foundations of our approach. While we agree that statistical-based theory clearly does not fully explain the generalization of neural networks, we believe that the motivation of our approach is indeed well-founded. Below we list a few related points:\n\n*A: The theoretical developments presented in the paper build on the Rademacher complexity, but ignore the conclusions drawn by Zhang et al. in Section 2.2 of their ICLR 2017 paper (Understanding deep learning requires rethinking generalization).*\n\n1-As the Reviewer pointed out, in  (Zhang et al. 2017), it is argued that a deep learning network can learn any arbitrary function and thus its Rademacher complexity is expected to be close to one in practice. This claim is verified empirically: a deep learning network is able to achieve reasonable accuracy on CFAR10 with random labelling. It should be noted that this finding is not considered surprising. In fact,  the issue has been discussed widely  (see $https://openreview.net/forum?id=Sy8gdB9xx$). Moreover, the reasoning made in Zhang et al. (Rademacher equal to 1) relies on the assumptions that the norm of all functions in the hypothesis set H is bounded by 1, which is not always the case in neural network context. Thus, statistical-based theoretical analysis in general and Rademacher complexity in particular are still valid  tools for studying the generalisation of neural networks in general cases [1,2,3]. \\\nIn addition, we would like to draw the attention of the Reviewer to the fact that the models used in Zhang et al. to achieve a reasonable accuracy on random labelling are relatively large (Alexnet and Inception V3), while in our paper Theorems 3.7, 3.8, 3.9, 3.10, 3.11, and 3.12 are valid for any neural network configuration with any given Rademacher complexity. In fact, Theorem 3.7 and 3.8 consider only networks with a single hidden layer.\n\n2- We note that we are not characterizing the generalization of the model using the Rademacher complexity of the model directly,  but we are using the Rademacher complexity of the loss hypothesis set to characterize the estimation error. This is different from the case argued in Zhang et al. (see the answer of Xiang Zhang in $https://openreview.net/forum?id=Sy8gdB9xx$ for more elaboration about this point). Note that the upper-bound in Lemma 3.2 has two terms and only the first term is depending on the Rademacher complexity. In the formulation of Theorems 3.7, 3.8, 3.9, 3.10, 3.11, and 3.12, it can be seen that actually both terms are inversely proportional to $d_{min}$. Thus, if we approximate the Rademacher complexity of the large network by 1 (as argued in Zhang et al.), the total upper-bound is still inversely proportional to $d_{min}$ as $d_{min}$ still appears in the second term and thus the finding of theorem remains valid.\n\n[1] Foster, Dylan J., et al. Hypothesis Set Stability and Generalization. Advances in Neural Information Processing Systems. 2019. \\\n[2] Wei, Colin, et al. Regularization matters: Generalization and optimization of neural nets vs their induced kernel. Advances in Neural Information Processing Systems. 2019. \\\n[3] Poggio, Tomaso, Andrzej Banburski, and Qianli Liao. \"Theoretical issues in deep networks: Approximation, optimization and generalization.\" arXiv preprint arXiv:1908.09375(2019). \n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "rJW_nIR5PBH", "original": null, "number": 2, "cdate": 1605517013281, "ddate": null, "tcdate": 1605517013281, "tmdate": 1605517751510, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "BayzwwLdUuX", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment", "content": {"title": "Response to AnonReviewer4", "comment": "Thank you for finding our paper well-presented and intuitive.  Your comments are clear and show both the main strengths of the paper and  how it can be improved in the future. \n\n*1-The definition of within-layer diversity seems to be simply the concentration of the values of each individual neuron. How does that affect the distribution of the layer output on the unit ball? Will this lead to a output similar to 'binarized' output?.* \n\nThe  within-layer diversity  can be defined as the global pair-wise distance between the neurons in the same layers. By promoting diversity, we encourage different neurons within the same layer to learn different features. As the Reviewer mentioned, the paper conducts a generic theoretical analysis (valid for any neural network) and shows that diversity can improve generalization.  We agree with the Reviewer that it would be interesting to study the distribution of the layer output on the unit ball and to develop links between our approach and the binarized neural network. However, we believe that the theory developed in this study contributes to opening the door for studying the relationship between the distribution of the neurons outputs and the generalization ability of the model in neural networks. The suggestions of the Reviewer are definitely interesting future research directions starting from the analysis provided in our paper.\n\n\n*2-The experiment seems insufficient to support the argument. Only very simple neural networks on two toy examples are provided. More ablation study of the neural/layer output distribution would help better understanding this issue.*\n\nWe completely agree with the Reviewer that more extensive experimental analysis can provide better insights on the links neurons outputs and generalization. In (Cogswell et al., 2016), a related approach based on the neurons output was proposed and an intensive experimental analysis on the relation between layer output distribution and generalization  was provided. In this manuscript, the main focus was to provide theoretical insights on how activation diversity can help improve generalization and in the experiments, we focused on how our approach interact with the different activation functions. To provide more experimental insights on the matter, we now report average competitive results over 4 trials with the standard deviation indicated alongside.\n\nSince it is difficult to proceed with such extensive experimental analysis in the ICLR2021 rebuttal period, we added this problem to section 6. CONCLUSION AND DISCUSSION."}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "EArH-0iHhIq", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3312/Authors|ICLR.cc/2021/Conference/Paper3312/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923838844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Comment"}}}, {"id": "G69F_m1IJYG", "original": null, "number": 1, "cdate": 1603723879169, "ddate": null, "tcdate": 1603723879169, "tmdate": 1605024024254, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review", "content": {"title": "fragile foundations ", "review": "Strong point: the paper addresses an important problem.\n\nThree main weaknesses, which justify the score:\n\u2022\tThe theoretical developments presented in the paper build on the Rademacher complexity, but ignore the conclusions drawn by Zhang et al. in Section 2.2 of their ICLR 2017 paper (Understanding deep learning requires rethinking generalization).\n\u2022\tThe theoretical developments build on the assumption that (i) there exists a lower bound, valid for any input, to the distance between the output of each pair of neurons, and (ii) the proposed diversity loss increases this lower bound. Those two assumptions are central to the theoretical developments, but are quite arguable. For example, a pair of neuron that is not activated by a sample, which is quite common, leads to a zero lower bound.\n\u2022\tExperimental validation are not convincing. Only shallow networks are considered (2 or 3 layers), and the optimization strategy, including the grid search strategy for hyperparameters selection, is not described.\n\nMinor issue: positioning with respect to related works is limited. For example, layer redundancy (which is the opposite of diversity) has been considered in the context of network pruning: https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Filter_Pruning_via_Geometric_Median_for_Deep_Convolutional_Neural_Networks_CVPR_2019_paper.pdf \n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078092, "tmdate": 1606915770587, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3312/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review"}}}, {"id": "rOJ7gTfoxz9", "original": null, "number": 2, "cdate": 1603856914155, "ddate": null, "tcdate": 1603856914155, "tmdate": 1605024024177, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review", "content": {"title": "Missing many potential comparison partners", "review": "The paper proposed three ways of diversifying outputs of neurons, and the analysis showed that the generalisation bound becomes tighter when the neurons become more diversified. It is an interesting finding, along with theoretical results and empirical results. Although, from a practical perspective, there are still many concerns.\n\nIt is clear that by increasing d_min, the generalisation bound gets tighter. However, it is also obvious that there are other factors that one can control to make the bound tighter, and regularising other factors might be simpler in terms of implementation and optimisation. \n\n1. The constant C_4 in the upper bound of the weight vector connecting the hidden-layer to the output neuron. \\sqrt(J) decays linearly with C_4, and the first term in the generalisation bound for regression tasks decays quadratically w.r.t. C_4. Compared with a linear decay w.r.t. d_min, C_4 seems to be a better option to regularise neural networks. In practice, one can empose an \\ell_2 regularisation on the top linear layer to control the overall norm of the weight matrix so that C_4 is controlled. \n\n2. The constant C_5 = L_\\phi C_1 C_3 + \\phi(0). As we can see in the generalisation bound for regression tasks, \\sqrt(J) decays quadratically w.r.t. C_5, which is even faster than the decay rate w.r.t. C_4. To control C_5, one can choose an activation function that has a small L_\\phi, or to control the weight vectors to the activation function to have a small norm C_3. Both of them can be done relatively easily compared to optimising pair-wise similarity. \n\nOverall, I think there are other regularisations suggested by the bound that could be put into practice, which might also lead to good generalisation, and also simpler optimisation problem. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078092, "tmdate": 1606915770587, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3312/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review"}}}, {"id": "BayzwwLdUuX", "original": null, "number": 4, "cdate": 1604014778819, "ddate": null, "tcdate": 1604014778819, "tmdate": 1605024024016, "tddate": null, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "invitation": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review", "content": {"title": "Well written paper, could use more ablation study", "review": "In this paper, the authors propose a technique to encourage the within-layer\nactivation diversity and therefore improve the model performance.\nSpecifically, they design a within-layer loss that add penalty to the similar\nneurons. They also showed that encouraging the within-layer diversity will\nhelp reduce the generalization error. \n\nThe paper is well-presented and authors provided enough intuition as well as\ntheoretical evidence why the diversity would help. Although I did not check\nall the proofs, the results seem to be right. \n\nThe definition of within-layer diversity seems to be simply the\nconcentration of the values of each individual neuron. How does that affect\nthe distribution of the layer output on the unit ball? Will this lead to a\noutput similar to 'binarized' output?\n\nThe experiment seems insufficient to support the argument. Only very simple\nneural networks on two toy examples are provided. More ablation study of the\nneural/layer output distribution would help better understanding this issue.\n\nOverall I think this paper provides some insights to how the generalization\nerror is related to the neuron outputs and vote for accept.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3312/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3312/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON NEURAL NETWORK GENERALIZATION VIA PROMOTING WITHIN-LAYER ACTIVATION DIVERSITY", "authorids": ["~Firas_Laakom1", "~Jenni_Raitoharju1", "~Alexandros_Iosifidis2", "~Moncef_Gabbouj1"], "authors": ["Firas Laakom", "Jenni Raitoharju", "Alexandros Iosifidis", "Moncef Gabbouj"], "keywords": ["Deep learning"], "abstract": "During the last decade, neural networks have been intensively used to tackle various problems and they have often led to state-of-the-art results. These networks are composed of multiple jointly optimized layers arranged in a hierarchical structure. At each layer, the aim is to learn to extract hidden patterns needed to solve the problem at hand and forward it to the next layers. In the standard form, a neural network is trained with gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. Thus at each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. By penalizing similarities and promoting diversity, we encourage each neuron to learn a distinctive representation and, thus, to enrich the data representation learned within the layer and to increase the total capacity of the model. We theoretically study how the within-layer activation diversity affects the generalization performance of a neural network in a supervised context and we prove that increasing the diversity of hidden activations reduces the estimation error. In addition to the theoretical guarantees, we present an empirical study confirming that the proposed approach enhances the performance of neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "laakom|on_neural_network_generalization_via_promoting_withinlayer_activation_diversity", "one-sentence_summary": "We propose an additional loss for neural network training promoting within-layer neurons' diversity and provide a theoretical analysis of its impact on the generalization error.", "pdf": "/pdf/ea9a1e58a8ac48bfa2b4106cee821485c8de2965.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aJk3PzXPmv", "_bibtex": "@misc{\nlaakom2021on,\ntitle={{\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORK{\\}} {\\{}GENERALIZATION{\\}} {\\{}VIA{\\}} {\\{}PROMOTING{\\}} {\\{}WITHIN{\\}}-{\\{}LAYER{\\}} {\\{}ACTIVATION{\\}} {\\{}DIVERSITY{\\}}},\nauthor={Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},\nyear={2021},\nurl={https://openreview.net/forum?id=EArH-0iHhIq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "EArH-0iHhIq", "replyto": "EArH-0iHhIq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3312/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078092, "tmdate": 1606915770587, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3312/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3312/-/Official_Review"}}}], "count": 13}