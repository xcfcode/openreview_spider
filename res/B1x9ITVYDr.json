{"notes": [{"id": "B1x9ITVYDr", "original": "BJe6QFtvvr", "number": 569, "cdate": 1569439057538, "ddate": null, "tcdate": 1569439057538, "tmdate": 1577168264136, "tddate": null, "forum": "B1x9ITVYDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "oHNuQ1t2SM", "original": null, "number": 1, "cdate": 1576798700026, "ddate": null, "tcdate": 1576798700026, "tmdate": 1576800935868, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Decision", "content": {"decision": "Reject", "comment": "After reading the author's response, all the reviwers still think that this paper is a simple extension of gradient masking, and can not provide the robustness in neural networks.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795717230, "tmdate": 1576800267493, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper569/-/Decision"}}}, {"id": "HJgxdIHqFB", "original": null, "number": 1, "cdate": 1571604072182, "ddate": null, "tcdate": 1571604072182, "tmdate": 1574038274299, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "The paper studies the problem of the robustness of the neural network-based classification models under adversarial attacks. The paper improves upon the known framework on defending against l_0, l_2 norm attackers. \n\nThe main idea of the algorithm is to use the \"compress sensing\" framework to preprocess the image: Using F, the discrete Fourier transformation matrix, and the algorithm tries to reproduce on every given input x, a vector y with the smallest number of non-zero coordinate such that Fy approximates x. The main algorithms proposed in this paper are sparse iterative hard thresholding (IHT) or base pursuit (BP) which are all quite simple and standardized. \n\nThe intuition of the approach is that l_0, l_2 attackers on the original input x can not allude the sparse vector y by too much, thus the recovered vector Fy could have better robustness property comparing to the original input x. \n\n\nThe main concern for me is the experiment in this paper. The author does not provide enough details about how the attacker is trained in their task. It seems that the authors only use the attacker trained on a standard neural network. However, since the authors have a preprocessing algorithm (IHT, BP) on top of the given input, the attacker should in principle tries to attack this pre-processing process as well. Since the pre-processing process is not differentiable, it is, therefore, unclear to me how to define the true robustness of the approach of the authors. \n\nAn analog of my argument is if we create an artificial network that has a pre-processing layer that zeros out most of the input pixel, however, if we train an attacker without this knowledge (so it tries to attack a network without this pre-processing), the l_2, l_0 attacker might not be very good for the true network. \n\n\nAfter Rebuttal: I have read the authors' responses and acknowledge the sensibility of the statement. However, I still think the algorithm in this paper is merely a \"clever\" version of gradient masking, which does not give the neural networks real robustness, it is just harder to design attacks on all these discrete operations.\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574942906407, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper569/Reviewers"], "noninvitees": [], "tcdate": 1570237750230, "tmdate": 1574942906422, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Review"}}}, {"id": "S1x280xqsS", "original": null, "number": 5, "cdate": 1573682772312, "ddate": null, "tcdate": 1573682772312, "tmdate": 1573682772312, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment", "content": {"title": "Revision Uploaded", "comment": "Dear Reviewers, \n\nWe have uploaded a revision with the following changes:  \n\nAbstract:\n-Clarified that we use a modified version of DS.\n\nSection 2:\n-Specified that we use standard BP, (k,t)-sparse IHT, and DS with an additional constraint. \n-Minor changes to structure. \n\nSection 3.1:\n-Fixed typo pointed out by Reviewer 2\n-Updated last paragraph to address Reviewer 1's concern on training procedure.\n\nSection 3.2: \n- Added an explanation justifying the use of each algorithm. \n- Noted that the experiment section would illustrate why DS with additional constraint performs better. \n- Updated paragraph on reverse engineering attacks to account for Reviewer 3's concerns.\n\nSection 3.3\n- Added discussions on how to interpret the results for each theorem to address Reviewer 1's concerns. They are provided after the statement of each theorem. \n- Added comparison of  (3) and (4) to Theorem 2.2 of Bafna et al. (2018), discussed proof techniques for (5) and (6), and  provided motivation for Theorem 2. This was also done to address Reviewer 1's concerns. \n\nSection 3.4\n-Added paragraph on related works in compressive sensing to address Reviewer 2's concern.\n\nSection 4.1.2:\n-Fixed typo in Figure 2 description as pointed out by Reviewer 2.\n\nSection 4.3:\n- Updated first and second paragraphs to account for additional constraint.\n- Added Figure 4 to illustrate the benefit of additional constraint as suggested by Reviewer 2.\n- Updated Table 4 to illustrate the benefit of additional constraint as suggested by Reviewer 2."}, "signatures": ["ICLR.cc/2020/Conference/Paper569/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1x9ITVYDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper569/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper569/Authors|ICLR.cc/2020/Conference/Paper569/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169484, "tmdate": 1576860541492, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment"}}}, {"id": "SylWlBkgjr", "original": null, "number": 4, "cdate": 1573020905166, "ddate": null, "tcdate": 1573020905166, "tmdate": 1573020905166, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "H1xdXAoCYB", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment", "content": {"title": "Response to Review 2", "comment": "Dear Reviewer, \n\nThank you for the comments and questions. We appreciate the feedback you have provided. We have attempted to address your concerns below and also ask for clarifications as required. \n\nReviewer wrote: \u201cIn Section 3.2 Recovery Algorithms, the author clearly ... could be necessary. \u201c\n \nSince our aim was to provide guarantees against l_0, l_2, and l_{\\infty} attacks, we needed recovery algorithms that could be analyzed theoretically for each type of attack. The algorithm we choose depends on the norm used to bound the attack vector. We explain in detail below.  \n\nl_0 attacks:\nOnce the problem has been reformulated as in equation (2), the vector that we need to recover is (k,t) sparse. This is only possible since the attack vector is t-sparse, that is it is bounded in l_0 norm. Therefore, IHT works due to the sparsity of the attack vector which is only guaranteed in the l_0 attack case. In particular, we cannot use IHT for the l_2 or l_{\\infty} attack case as the recovery guarantees would be poor (if derivable at all).\n\nWe also provide recovery guarantees for BP as the results of Theorem 2 hold for larger values of k and t. This acts as an improvement over equation (3) and (4) in Theorem 1. \n\nl_2 attacks: \nNoting that l_2 norm behaves very nicely with unitary matrices (acts as an isometry) we use BP for l_2 norm attacks as it allows us to leverage the fact that the matrix F is unitary. Using this and the fact that constraints in BP are designed to handle l_2 norm noise, we are able to get the required recovery guarantees.\n\nl_{\\infty} attacks: \nFirst we note that both BP and DS can be posed as semi-definite programming problems. However, the constraints of DS are designed to handle l_{\\infty} norm noise while those in BP are designed to handle l_2 norm noise. Therefore, we use DS when the attacker is only bounded in l_{\\infty} norm.\n\nEssentially, each recovery algorithm treats the attack vector as noise and each algorithm is best suited to handle noise bounded in a specific norm (l_0, l_2, or l_{\\infty}).  \n\nIn general the time complexity of IHT is better than the time complexity of BP and DS as the latter are semi-definite programming problems and require expensive matrix operations. However, if required, we can provide an analysis on the time and space complexity of each. \n\n\nReviewer wrote \u201cI think maybe the paper should involve some related work here regarding theory of compressive coding besides Bafna et al. (2018). And how they are combined to the defense against adversarial inputs. It would help the readers to have better understanding towards the novelty and breakthroughs in this aspect.\u201d\n\nYes, we agree and will definitely add more related work on compressive sensing. We were apprehensive in doing so earlier due to space constraints. \n\nCould you please clarify what you mean by the below? \n\nFor the experiments, it would be better to have the comparisons between the proposed algorithm and related methods. \n\nIf your concern is that we should compare our results to those of other defense methods, then we can definitely do so. We can add a comparison in the next revised version of the paper. \n\n\nReviewer wrote \u201cAlso, the proposed IHT and DS are modified versions. What are the differences in experiments?\u201d \n\nWe have only modified the DS algorithm and use the same IHT as used by Bafna et al (and introduced by Baraniuk et al). For DS, we have added the additional constraint that improves reconstruction quality. We can definitely run an experiment that visually (or in a norm) shows the improvement in reconstruction with the added constraint. \n\nThank you for pointing out the minor comments, we will address both points in the revised version of the paper. \n\n\n[1] Mitali Bafna, Jack Murtagh, and Nikhil Vyas. Thwarting adversarial examples: An l 0-robust sparse fourier transform. In Advances in Neural Information Processing Systems, pp. 10075\u201310085, 2018.\n\n[2] Richard G. Baraniuk, Volkan Cevher, Marco F. Duarte, and Chinmay Hegde. Model based compressive sensing. IEEE Trans. Information Theory, 56(4):1982\u20132001, 2010.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper569/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1x9ITVYDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper569/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper569/Authors|ICLR.cc/2020/Conference/Paper569/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169484, "tmdate": 1576860541492, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment"}}}, {"id": "B1gXsVkejS", "original": null, "number": 3, "cdate": 1573020827489, "ddate": null, "tcdate": 1573020827489, "tmdate": 1573020827489, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "HJgxdIHqFB", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment", "content": {"title": "Response to Review 3", "comment": "Dear Reviewer, \n\nThank you for the comments and questions. We appreciate the feedback you have provided. \n\nWe would like to get clarity on your main concern before we attempt to address it. Could you please clarify what you mean by: \n\n\"However, since the authors have a preprocessing algorithm (IHT, BP) on top of the given input, the attacker should in principle tries to attack this pre-processing process as well.\"\n\nMore specifically, is your concern that we have not performed a reverse engineering attack? That is, we have not created an attack that takes CRD (Compressive Recovery Defense) into account before creating an adversarial input? \n\nIf this is indeed the question, then we would like to note that we expect creating such a reverse engineering attack to be quite difficult. \n\nWe explain why by making some observations first: \n\n1. IHT can use random initialization which will make the recovery non-deterministic. Therefore, a reverse engineering attack that uses standard backpropagation based approaches may not be effective. \n2. BP and DS can be cast as semi-definite programming problems. If solved with interior point methods, one can use random initialization of the central path parameter and/or add randomness to the stopping criterion. This will make the recovery non-deterministic once again. Hence, standard attack methods may not be effective. \n\nGiven the above, and the fact that we do not have domain expertise on creating attacks, we did not think it would be feasible for us to create a reverse engineering attack against CRD in the present paper. We feel that tackling this interesting problem is better left to a separate paper. \n\n\nWe will wait to get more clarity on your concern before providing further feedback. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper569/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1x9ITVYDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper569/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper569/Authors|ICLR.cc/2020/Conference/Paper569/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169484, "tmdate": 1576860541492, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment"}}}, {"id": "HJgGL4yesr", "original": null, "number": 2, "cdate": 1573020746191, "ddate": null, "tcdate": 1573020746191, "tmdate": 1573020746191, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "SylPwe8AKB", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment", "content": {"title": "Response to Review 1: Part 2", "comment": "Interesting observations: \n1. In order to prove the RIP property (Theorem 7), we bound the eigenvalues of the matrix by using normality and the Gersgorin disc theorem. The authors of [1] use direct algebraic manipulation (i.e. triangle inequality and AM-GM inequality) to prove the RIP property (Lemma 3.6 in [1]). In fact, if one replaces certain constants in Lemma 3.6 of [1], the RIP property results  of Theorem 7 and Lemma 3.6 of [1] are identical.\n2. Equations (5) and (6) of Theorem 1 show that in order to provide guarantees for larger values of k and t, one must incur a penalty. Based on our efforts, we could not find a technique that allowed us to provide guarantees for larger values of k and t without incurring some penalty. \n\n\nTheorem 2: \nTheorem 2 provides guarantees for larger values of k and t. In order to achieve this, we rely on Theorem 4.33 of [3]  (Theorem 12 in our paper) and don\u2019t use a RIP based argument. Instead, we show that the matrix in question does indeed satisfy the hypotheses of Theorem 12 and hence allows to get the bounds of Theorem 2. An examination of the proof of Theorem 2 may reveal it is not entirely trivial. \n\nTheorem 3 and Theorem 4: \nThese theorems are based on standard arguments that rely on the robust null space property of the matrix. We first prove the required robust null space property and then follow the classical argument. The general argument used here has indeed been used commonly in compressive sensing literature.  \n\n\nReviewer Wrote: \u201cAlso, it would be nice if the authors could discuss the theoretical results in more detail, e.g., how to interpret them and new insights it brings to us.\u201d\n\nWe will include such a discussion in the revised version of the paper. \n\n\n\n\n[1] Mitali Bafna, Jack Murtagh, and Nikhil Vyas. Thwarting adversarial examples: An l 0-robust sparse fourier transform. In Advances in Neural Information Processing Systems, pp. 10075\u201310085, 2018.\n\n[2] Richard G. Baraniuk, Volkan Cevher, Marco F. Duarte, and Chinmay Hegde. Model based compressive sensing. IEEE Trans. Information Theory, 56(4):1982\u20132001, 2010.\n\n[3] Simon Foucart and Holger Rauhut. A Mathematical Introduction to Compressive Sensing. 2017."}, "signatures": ["ICLR.cc/2020/Conference/Paper569/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1x9ITVYDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper569/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper569/Authors|ICLR.cc/2020/Conference/Paper569/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169484, "tmdate": 1576860541492, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment"}}}, {"id": "Hye14Eygjr", "original": null, "number": 1, "cdate": 1573020710898, "ddate": null, "tcdate": 1573020710898, "tmdate": 1573020710898, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "SylPwe8AKB", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment", "content": {"title": "Response to Review 1: Part 1", "comment": "Dear Reviewer, \n\nThank you for the comments and questions. We appreciate the feedback and have tried to address each concern.  Please note that our response is split into two comments.\n\nReviewer wrote: \u201cMoreover, some experimental details are missing. In last paragraph in Section 3.1, the authors say ``We then use both x and x\u2032 to train the network''. How do you do so? Just add both x and x' to the training set?\u201d\n\nYes, we simply include both x and x\u2019 in the training set and then train the neural network using stochastic gradient descent. We will state this more clearly in the revised version. \n\nReviewer wrote: \u201cThis paper extends the compressive sensing framework introduced in Bafna et al. to handle l1 and l2 attacks.\u201d\n\nActually, our extension handles l_2 and l_{\\infty} attacks. We have stated nothing about l_1 attacks. \n\nReviewer wrote: \u201cHowever, the proposed recovery algorithms are all classical ones, and it is unclear how novel the analysis is, since the authors do not discuss the technical challenges they overcome or the difference between their proof techniques and the previous ones.\u201d\n\nFirst, we note that we have deliberately used classic recovery algorithms as they are more easily accessible (only for Dantzig Selector have we introduced a simple novel modification). Moreover, since our aim was to provide guarantees against l_0, l_2, and l_{\\infty} attacks, we needed recovery algorithms that could be analyzed theoretically for each type of attack.\n\nAlgorithm 1 ((k,t)-Sparse Iterative Hard Thresholding): This algorithm was introduced in Baraniuk et al [2] and used by Bafna et al [1] for the compressive defense framework. \n\nAlgorithm 3 (Dantzig Selector with additional constraint):\nThis is the only algorithm that we have modified in a novel way. We provided an explanation of the additional constraint (paragraph 3 on page 3). This is indeed the only novel algorithmic contribution that we make in this paper.   \n\nThe main contributions of this work are not in providing a novel recovery algorithms. Instead the main contributions are: \n(a) proving recovery guarantees for the compressive recovery defense (CRD) with existing recovery algorithms \n(b) showing experimentally that the defense does indeed improve performance. \n\nWe will make this more clear in the revised version of the paper. \n\nBelow we compare our theoretical results and proof techniques to [1], explain why they are non-trivial, and point out some interesting observations. Then we comment on the proofs of Theorems 2, 3, and 4.  We will add this information to the revised version of the paper. \n\nSummary of [1] : \nThe authors of [1] provide a defense against against l_0 attacks only. They use IHT to perform recovery with recovery guarantees stated in Theorem 2.2 of [1].  The recovery guarantees provided rely on Theorem 4 of [2]. More specifically, the authors  of [1] show that the matrix used in IHT satisfies the RIP property with \\delta <= 0.1. This satisfies the constraints of Theorem 4 in [2] and hence the authors of [1] are able to use the results of Theorem 4 in [2] to get results of Theorem 2.2 of [1].\n\nComparison to [1]: \n1. Our results cover l_0, l_2, and l_{\\infty} attacks. \n2. For l_0 attacks, we provide recovery guarantees for IHT (Theorem 1) as well as BP (Theorem 2). \n3. We provide recovery guarantees for BP as they hold for larger values of k (coefficients to recover) and t (adversarial noise budget). For instance, in the case of MNIST and Fashion-MNIST, IHT (equation (4) of Theorem 1) allows us to set k = 4 and  t = 3, whereas BP (equation (7) of Theorem 2) allows us to set k = 8 and t = 8. We note that even the results of Theorem 1 hold for values of k,t greater than or equal to Theorem 2.2. of [1]. \n4. Since [1] only covers l_0 attacks with IHT, we improve upon the results of [1] in two ways: \n\ni) Equations (3) and (4) of Theorem 1 allow larger values of k and t than Theorem 2.2 of [1]. This is because the authors of [1] use Theorem 4 of [2] to prove their results and this theorem is more restrictive on the values of k and t. We do not rely on Theorem 4 of [2], instead we prove the RIP property using a different proof technique (Theorem 7) and then use Theorem 6.18 of [3] to get equations (3) and (4) of Theorem 1.\n\nii) Equations (5) and (6) of Theorem 1 provide guarantees for larger values of k and t than equations (3) and (4) by incurring a penalty term in the error bound. To achieve this, we first prove Lemma 9 and then use the result of Lemma 9 to get (5) and (6). The proof of Lemma 9 as well as its application to get (5) and (6) require a novel approach. This can be seen in the proof of Theorem 1. \n\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper569/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1x9ITVYDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper569/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper569/Authors|ICLR.cc/2020/Conference/Paper569/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169484, "tmdate": 1576860541492, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper569/Authors", "ICLR.cc/2020/Conference/Paper569/Reviewers", "ICLR.cc/2020/Conference/Paper569/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Comment"}}}, {"id": "SylPwe8AKB", "original": null, "number": 2, "cdate": 1571868767082, "ddate": null, "tcdate": 1571868767082, "tmdate": 1572972579008, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper extends the compressive sensing framework introduced in Bafna et al. to handle l1 and l2 attacks. The authors provide theoretical analysis for several recovery algorithms (IHT, BP, DS) and provide experimental result on CIFAR-10, MNIST and Fashion-MNIST. \n\nMy major concern is how significant the provided results are. It is indeed interesting to extend the compressive sensing framework to handle l1 and l2 attacks. However, the proposed recovery algorithms are all classical ones, and it is unclear how novel the analysis is, since the authors do no discuss the technical challenges they overcome or the difference between their proof techniques and the previous ones. Also, it would be nice if the authors could discuss the theoretical results in more detail, e.g., how to interpret them and new insights it brings to us. \n\nMoreover, some experimental details are missing. In last paragraph in Section 3.1, the authors say ``We then use both x and x\u2032 to train the network''. How do you do so? Just add both x and x' to the training set? "}, "signatures": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574942906407, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper569/Reviewers"], "noninvitees": [], "tcdate": 1570237750230, "tmdate": 1574942906422, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Review"}}}, {"id": "H1xdXAoCYB", "original": null, "number": 3, "cdate": 1571892767894, "ddate": null, "tcdate": 1571892767894, "tmdate": 1572972578964, "tddate": null, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "invitation": "ICLR.cc/2020/Conference/Paper569/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper extends the compressive recovery defense framework introduced by Bafna et al. (2018), which is mainly against l_0 attacks, to l_2 and l_\u221e attacks. They provide guarantees for some recovery algorithms in the case of different kinds of norm bounded noises. The difference between their work and the previous work is clearly clarified. \n\nOverall, this paper is a follow-up work towards Bafna et al. (2018) but with better theoretical guarantees and ample experiment results to support their robustness against various popular attacks. Given their contribution and inspiration for future work, I think this paper could be accepted to the 2020 ICLR conference. \n\nIn Section 3.2 Recovery Algorithms, the author clearly states three algorithms including IHT, BP, DS, and their modification from the standard ones, but fails to compare the differences between these algorithms. It is not clear about the author\u2019s motivations to proposes these different recovery algorithms and whether their performance varies from each other also remains unknown. Maybe some analysis about their disadvantages and advantages in varied conditions of attacks could be necessary. \n\nIn the Section 3.4 Comparison to Related Work, the author mentions many works aiming at defending against adversarial inputs. However, Bafna et al. (2018) is the only work here that has something to do with compressive sensing. I think maybe the paper should involve some related work here regarding theory of compressive coding besides Bafna et al. (2018). And how they are combined to the defense against adversarial inputs. It would help the readers to have better understanding towards the novelty and breakthroughs in this aspect. \n\nFor the experiments, it would be better to have the comparisons between the proposed algorithm and related methods. Also, the proposed IHT and DS are modified versions. What are the differences in experiments? \n\nMinor comments:\n- Page 2: the line above the equation 1 \u2018meaning that x_t (k)\u2026..\u2019, it could be (x_t ) \u0302(k)\n- Page 6: in the explanation of figure 2, the adversarial inputs are second column and fifth column not fourth column. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper569/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Compressive Recovery Defense: A Defense Framework for $\\ell_0, \\ell_2$ and $\\ell_\\infty$ norm attacks.", "authors": ["Jasjeet Dhaliwal", "Kyle Hambrook"], "authorids": ["jasjeet.dhaliwal@sjsu.edu", "kyle.hambrook@sjsu.edu"], "keywords": ["adversarial input", "adversarial machine learning", "neural networks", "compressive sensing."], "abstract": "We provide recovery guarantees for compressible signals that have been corrupted with noise and extend the framework introduced in \\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$, $\\ell_2$, and $\\ell_{\\infty}$-norm attacks. In the case of $\\ell_0$-norm noise, we provide recovery guarantees for Iterative Hard Thresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we provide recovery guarantees for BP, and for the case of $\\ell_\\infty$-norm bounded noise, we provide recovery guarantees for Dantzig Selector (DS). These guarantees theoretically bolster the defense framework introduced in \\cite{bafna2018thwarting} for defending neural networks against adversarial inputs. Finally, we experimentally demonstrate the effectiveness of this defense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$-norm attacks.   ", "pdf": "/pdf/4afdb3539972a76c50b7e3195242e6e87bcfa928.pdf", "code": "https://github.com/anonymousiclrcompressive/iclr2020", "paperhash": "dhaliwal|compressive_recovery_defense_a_defense_framework_for_\\ell_0_\\ell_2_and_\\ell_\\infty_norm_attacks", "original_pdf": "/attachment/5d5056f7ee0b8fcf0d61a8da082e322774c2c886.pdf", "_bibtex": "@misc{\ndhaliwal2020compressive,\ntitle={Compressive Recovery Defense: A Defense Framework for {\\$}{\\textbackslash}ell{\\_}0, {\\textbackslash}ell{\\_}2{\\$} and {\\$}{\\textbackslash}ell{\\_}{\\textbackslash}infty{\\$} norm attacks.},\nauthor={Jasjeet Dhaliwal and Kyle Hambrook},\nyear={2020},\nurl={https://openreview.net/forum?id=B1x9ITVYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1x9ITVYDr", "replyto": "B1x9ITVYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper569/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574942906407, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper569/Reviewers"], "noninvitees": [], "tcdate": 1570237750230, "tmdate": 1574942906422, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper569/-/Official_Review"}}}], "count": 10}