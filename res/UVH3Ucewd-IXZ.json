{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392843720000, "tcdate": 1392843720000, "number": 4, "id": "xNu3xNM93fI1d", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "UVH3Ucewd-IXZ", "replyto": "UVH3Ucewd-IXZ", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Computation for Section 3.3 have just completed and I have uploaded the revision to arxiv with updated Table 1. Temporarily, while arxiv is processing the paper I am keeping the current version at http://cs.unm.edu/~pliz/iclr2014.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392822120000, "tcdate": 1392822120000, "number": 1, "id": "Toelaad_lZoit", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "UVH3Ucewd-IXZ", "replyto": "g5Jf9H1coI92C", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for the effort you have put in reviewing our paper and the useful comments that lead to multiple changes in the manuscript.\r\n\r\nAs you have noticed classification experiments do suffer from the double dipping, which we used as admitted in the previous version for the reasons of computational efficiency. To address this concern for Section 3.3 we have completely redone the experiment to evaluate the performance via a 10-fold cross validation. The paper has been changed accordingly.  Besides that we have added the k-nearest neighbor classification results to Section 3.3.  Now the performance numbers more accurately reflect the truth as we only report them on the hold out test data in Table 1. Unfortunately, the computation time has delayed our response to reviewers' comments.\r\n\r\nIn Section 3.4 (3.3 in your review) our goal is indeed as stated in the first paragraph: investigate if deep learning has potential in assisting discovery.  We indeed deliberately train the DBN (pre-train and fine tune) and most likely overfit (as you have noted f1 score of 1) on the complete dataset. We're not testing here anymore abilities of the DBN to classify subjects correctly, but rather, as you've noted positively asses if deep learning can be used for goals beyond generalization accuracy. Thank you for pointing out the fact that similar structures in Sections 3.3 and 3.4 may lead a reader to expect the same findings (or refutations).  To reinforce the differences of study 3.4 from 3.3 we have modified the text and stressed the point that we do overfit (possibly) but generalization is nor the goal or the metric in this section. Please see the diff file for the changes we have made.\r\n\r\nThank you for requesting the details of the RBM training, as they will only make the paper more useful to a reader. We did, however, present the manipulated energy function for real-valued input in expression (1).  Here is the information that we have added to the paper:\r\n\r\n1.  Note, that in practical implementations if the activation nonlinearity belongs to the exponential family we need not worry about the changes in the energy as it is consistently described as a function of sufficient statistics of the model. See for example (Welling 2005) and reference [16] in our paper. As mentioned on page 4 (last line of Section 2.3) we use the following implementation for our experiments: https://github.com/nitishsrivastava/deepnet and consequently defer to all implementation decisions made thereof.  The tanh, for example, is sampled from Bernoulli distribution where the value of failure is set to -1. If we were implementing the algorithm we could have chosen other sampling methods. For example, uniformly sampling in the [-1,1] range and taking arctanh of the samples.\r\n\r\n    Welling, Max, Michal Rosen-Zvi, and Geoffrey E.  Hinton.  'Exponential Family Harmoniums with an Application to Information Retrieval.' Nips. Vol. 17. 2004.  APA\r\n\r\n2. The weights were updated using the truncated Gibbs sampling method called contrastive divergence with a single sampling step (CD-1).\r\n\r\n3. L1 regularization was used in the convential way for re-enforcing sparsity of the features, i.e.  via an additive L1-norm regularizer on the wights W: +lambda ||W||_1.\r\n\r\nWe have referred to the paper by Le et al.  in the modified version.  Although we are familiar with this paper, the ICA method presented there is not a widely used one in the neuroimaging community and we were comparing to a more standard approach. The L1 penalty may describe the Fast ICA algorithm but is this true for ICA algorithms in general? For example, the Infomax algorithm we are comparing against (one of he most popular ones in neuroimaging) does not reply of L1 or any other explicit sparsity measures.\r\n\r\nWe have hand optimized the learning rate and sparsity parameters in an effort to maximize the convergence rate while keeping the optimization stable (grid search to the maximum stable value) and for sparsity we were looking for a parameter that achieves 30% sparsity (with the implicit sparsity setting as in the used L1 regularizer the right value is not 0.7). We have modified the paper to reflect this. The network sizes in the DBN experiments were chosen to balance computational complexity and representational capacity.  From RBM experiments we have learned that even with a larger number of hidden units (72, 128 and 512) RBM tends to only keep around 50 features driving the rest to zero. That is how the number of hidden units in the first layers was selected. Classification rate and reconstruction error still improved a little when increasing the number of features, this lead us to increase the number of hidden units in the third layer.\r\n\r\nWe have added a supplementary material section to support the claims that we've made but haven't previously included the supporting data to keep the paper at a reasonable size. We there show the improved block structure and actual test of the modularity supporting one of the claims you've pointed to. We rephrased the paper to highlight the subjective measure of the improved locality of RBM features, and included a longer list of these features in the supplement to support our observation.\r\n\r\nThe footnote was removed.\r\n\r\nNote: besides the updated version on arxiv we have placed the version with all changes highlighted at http://cs.unm.edu/~pliz/diff.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392822060000, "tcdate": 1392822060000, "number": 1, "id": "B2r9B231Rt2GZ", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "UVH3Ucewd-IXZ", "replyto": "VVX0xVF70w4Cr", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your comments and suggestions. We have heavily modified the paper which should have covered most if not all of your concerns. However, multiple datasets, architectures and concepts are still there as all of them are necessary for our goal of validating an approach in a field that has not used it before. As our goal is to evaluate architectures from deep learning area we use three: RBM, DBM and, as you've mentioned, DNN.  To be able to generalize our findings we have applied the approaches to three datasets that are collected at multiple sites and are both static (sMRI) and dynamic (fMRI) in nature.\r\n\r\nsMRI as well as fMRI were introduced in Section 1. We now have also added a couple of sentences to explain what the data represents.\r\n\r\nIn Section 2.3 we briefly state that we have 249 scans/volumes per subject. We have also added, following your advice, the information on the sampling rate (or time of response (TR) in the literature).\r\n\r\nIndeed, by the nature of our work the data is highly domain specific.  However, we compare to the state of the art in the neuroimaging field (ICA) when investigating the RBM model. The goals of investigating the deeper models do not require external comparison as we investigate if a deep learning literature claim holds on our data type (Section 3.3) and if deep learning is able to facilitate discovery (Section 3.4). Both questions are positively answered by our work and for this do not require a comparison.\r\n\r\nWe apologize for not stressing it enough, but the intro paragraph of Section 2 does state that the goal of this section is feature learning.  This, as you have noted, is an unsupervised task.  The caption of Figure 1c states that what shown is the average correlation to the ground truth for spatial maps, time courses and cross-correlations.  Since this is a simulation study (the one in Section 2.2), we are able to measure these correlations.\r\n\r\nWe have modified the paper to emphasize that we are using the conventional RBM architecture for each layer where all units in a layer are connected to all units in the other layer. As for DNN, we feel it is more of a stylistic convention and it is implied and understood, that when DBN is used as a feed-forward network for classification it is essentially a neural network (a DNN). Having one extra acronym in an already acronym-heavy paper may confuse the reader.\r\n\r\nPlease see our response to reviewer 0657 above, where we explain why adding parameters is in itself not a problem if it does not lead to overfitting. As our new experiments in Section 3.3 demonstrate the model does not overfit with the increasing depth as classification on hold out data only improves.  We feel this is the correct control experiment you are asking for. Note, that Section 3.4 pursues a very different goal and overfitting is orthogonal to that goal, we neither care nor even measure it there (see updated version of the manuscript).\r\n\r\nAs a matrix factorization method ICA simultaneously estimates two factors: the mixing matrix and the independent components. Conventional and widely used ICA algorithms are applied to fMRI and MRI data spatially for the reasons of computational efficiency and model determination: a 60000 by 60000 mixing matrix for only a couple of hundreds samples long time courses is very hard to estimate and invert.  Note, however, the paper by Le et.  al cited by reviewer 4ea9 that is capable of being applied the way we apply RBM.  However, most widely used ICA algorithms in neuroimaging are not.  For RBM there is only a single set of parameters: the W. Activation sequences of the hidden units can be hardly treated as time courses.  Thus, we've used the W as our spatial features, which also concurs with the usage in the image processing community where W form receptive fields.\r\n\r\nWe did not use a GPU implementation of ICA and noted so in the new version of the paper.\r\n\r\nThe questionable sentence was not included in the rewritten version of our manuscript.\r\n\r\nNote: besides the updated version on arxiv we have placed the version with all changes highlighted at http://cs.unm.edu/~pliz/diff.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392167520000, "tcdate": 1392167520000, "number": 3, "id": "VVX0xVF70w4Cr", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "UVH3Ucewd-IXZ", "replyto": "UVH3Ucewd-IXZ", "signatures": ["anonymous reviewer d143"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep learning for neuroimaging: a validation study", "review": "The English in the paper is poor making it hard to read. \r\n\r\nThere is a lot of material and the changing architectures, datasets and tasks make the whole thing hard to follow. \r\n\r\nYou introduce sMRI without explaining it. \r\n\r\nYou don't describe the temporal nature of your data. (I presume it's one volume every T ms, but you have to say that and tell us what T is. \r\n\r\nThe datasets are specialist and results aren't compared to other authors, so it's hard to really understand performance. \r\n\r\nThe task in 2.2 is not explained. What are the classes in the GT. is this really an unsupervised task? The results (what is being measured) in Fig 1c are not clear. Please elucidate. \r\n\r\nConventionally I believe a DBN is a stacked RBM - when you add a classification layer, please call it a DNN.\r\nFor the RBM / DBN please specify the connectivity. Are inputs / hidden connected all:all?\r\n\r\n\r\nBy adding a second layer you don't explicitly show that depth helps the improvement could equally be because adding more parameters helps. You need to show the correct control experiment. Adding a 3rd layer may similarly be causing you to overfit because you added too many parameters. \r\n\r\nYou don't explain the reasoning behind applying ICA spatially and the DBN temporally. \r\n\r\nIs the ICA implementation on a GPU too? \r\n\r\nYou say 'The training accuracy at the fine tuning stage for the 335 subjects was: 82%, 87%, and 86.5% respectively.'\r\nWhat are these 3 numbers? You can't say respectively in this sentence."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392144300000, "tcdate": 1392144300000, "number": 2, "id": "g5Jf9H1coI92C", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "UVH3Ucewd-IXZ", "replyto": "UVH3Ucewd-IXZ", "signatures": ["anonymous reviewer 4ea9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep learning for neuroimaging: a validation study", "review": "Summary:\r\n\r\nThe paper applies deep learning methods to various problems in MRI data analysis, showing that DBNs can recover similar features as other standard techniques, and can possibly improve classification performance in certain tasks.\r\n\r\nMajor comments:\r\n\r\nThe classification experiments in this paper are hard to follow, and as written it seems they may be flawed:\r\n\r\nFor the results in Section 3.2, it sounds like the models may possibly have been pretrained on the testing data, and worse, possibly fine-tuned on the testing data as well. In particular, the model is pretrained and fine-tuned on 335 of 389 examples, and then, subsequently, the top layer activations of these fine-tuned models are supplied to a new shallow classifier that is trained on a different train/test split of half the 389 subjects in each. Each of these splits will thus necessarily contain many examples from the training set used for pretraining/fine-tuning. This means there will be many test examples on which the underlying DBN model has already been fine-tuned with the correct label. Hence the performance numbers are inaccurate. \r\n\r\nFor the results in Section 3.3, all data examples are used for pretraining/finetuning, and hence it is not clear to what extent the learned classifiers will generalize to new examples. This is particularly important to check given that the three layer network attains perfect accuracy, which may indicate overfitting. These concerns are moderated by the fact that dimensionality reduction applied to the learned representation shows an interesting structuring by disease severity, and this data was not used in the training process. I also recognize that, in this data analysis application, there are other important goals beyond generalization accuracy. If the trained model identifies particular features that are interpretable in the light of other known data, that can be very helpful. Drawing out these other uses of DBNs is an interesting direction to pursue.\r\n\r\nMore details of the RBM model and training procedure should be included in the paper. RBMs typically use 0-1 valued inputs, and the sigmoidal form of the activation function arises by manipulating the energy function. Some details which would strengthen the paper: How was the switch to Tanh activations performed? Were weights updated using contrastive divergence to approximately maximize log likelihood? If so, how many sampling steps were used (e.g., CD-1, CD-10)? Was sampling used, or were the updates based on the mean field approximation? How were tanh units sampled from? How was L1 regularization added? E.g., was it ||tanh(Wx)||_1, or ||sigmoid(Wx)||_1 or ||Wx||_1? \r\n\r\nDepending on how the switch to tanh units was performed, the RBM algorithm can be nearly identical to ICA. See, for example, Q.V. Le, A. Karpenko, J. Ngiam, A.Y. Ng. ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning. NIPS, 2011. This connection should be cited and discussed. In particular, the statement 'In general, RBM performed competitively with ICA, while providing--perhaps, not surprisingly due to the used L1 regularization--sharper and more localized features' may need some adjustment. L1 regularization is the objective to be minimized in ICA too--if anything, the difference is due to less stringent orthogonalization.\r\n\r\nSome of the given parameter values are confusing. The learning rate is given as epsilon = 0.08, but this is not in the 'workable range' of [1e-4, 1e-3]. Were these parameters hand optimized? How were network sizes chosen?\r\n\r\nSome claims are stated without providing the relevant data. E.g., 'Moreover, the block structure of the correlation matrix (not shown) of feature time courses provide a grouping that is more physiologically supported than that provided by ICA.' More discussion of this, maybe in a supplementary materials section after the main paper, would be welcome. It is also stated that RBM bases are more 'spatially concentrated' but this is not quantified or clearly established in the presented data.\r\n\r\nThe text is often unclear and hard to follow (particularly section 3.2).\r\n\r\nPros/cons:\r\n+ Interesting new application area for DL\r\n+ Some results that hold promise\r\n\r\n- Flawed experiments mix train/test data\r\n- Insufficient details of model and training method\r\n\r\n\r\nMinor comments:\r\n\r\nThe first page footnote should be removed"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390990980000, "tcdate": 1390990980000, "number": 1, "id": "VslF-s_mF8-qC", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "UVH3Ucewd-IXZ", "replyto": "cUHZQQoWZzQ1D", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Above two comments are identical, please do not bother reading both. I must have double-clicked the button."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390987800000, "tcdate": 1390987800000, "number": 1, "id": "0F8eF0qrnVL_s", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "UVH3Ucewd-IXZ", "replyto": "GGNxGzRU2OzPC", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you very much for your time and effort put in reviewing our article. Apologies for a late response. oppenreview.net did not send a notification of the comment. I appreciate your comments some of which are addressed below. While the techniques addressed are indeed 'popular' in the areas where classification and representation learning are important (as in neuroimaging) it seems unwise to ignore their success just because many people are using them. Instead, our paper focuses on validating deep learning within a range of tasks that are 'very important for brain imaging and neuroscience discovery'. Our results, we believe, speak for themselves. Specific concerns that were raised are addressed below.\r\n\r\nNote that we use the term 'oracle' in the sense of a person (or a device) giving correct answers without explanation of how to get them without implying or requiring any theory.\r\n\r\nThank you for mentioning another interesting area that may fair better against deep learning and needs validation as well. Are you referring to 'Do Deep Nets Really Need to be Deep?' submitted to the current conference? I will definitely need a closer look at the paper, but however promising it seems that the proposed method still requires outputs of a trained deep net and results presented in our paper will be of great use for neuroimaging practitioners.\r\n\r\nThank you for catching our failure to define SM as spatial map in the paper. This omission has been corrected but we will wait for other reviewers to comment before uploading the new version.\r\n\r\nWe have performed comparisons with the most widely used ICA approaches and several non-ICA approaches that are not as popular but have been applied in neuroimaging as well.\r\n\r\nIt is unclear why would one worry about parameter increase if it does not lead to overfitting. In our case (i.e. Table 1) no overfitting is observed as we report cross-validation results on hold out data. From the literature we know that when the deep learning community claims performance increase with depth they exactly mean testing performance (and this claim we have validated positively for neuroimaging data). It is clear training data will only be overfit with more parameters, but hold out data does not have this problem. Note also, parameter increase is linear in the number of layers. For example for our 50-50-100 networks we have 50*60465 parameters for depth 1 net, 50*60465 + 50*50 for depth 2 net and 50*60465 + 50*50 + 50*100 for depth 3. This is 0.08% (sic!) increase in parameters from depth 1 to depth 2, 0.16% (sic!) from depth 2 to depth 3 and only 0.24% from depth 1 to depth 3. Yet classification performance increases by much more. I may have misunderstood your question, but it does not seem to me there is a problem here."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390987800000, "tcdate": 1390987800000, "number": 2, "id": "cUHZQQoWZzQ1D", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "UVH3Ucewd-IXZ", "replyto": "GGNxGzRU2OzPC", "signatures": ["Sergey Plis"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you very much for your time and effort put in reviewing our article. Apologies for a late response. oppenreview.net did not send a notification of the comment. I appreciate your comments some of which are addressed below. While the techniques addressed are indeed 'popular' in the areas where classification and representation learning are important (as in neuroimaging) it seems unwise to ignore their success just because many people are using them. Instead, our paper focuses on validating deep learning within a range of tasks that are 'very important for brain imaging and neuroscience discovery'. Our results, we believe, speak for themselves. Specific concerns that were raised are addressed below.\r\n\r\nNote that we use the term 'oracle' in the sense of a person (or a device) giving correct answers without explanation of how to get them without implying or requiring any theory.\r\n\r\nThank you for mentioning another interesting area that may fair better against deep learning and needs validation as well. Are you referring to 'Do Deep Nets Really Need to be Deep?' submitted to the current conference? I will definitely need a closer look at the paper, but however promising it seems that the proposed method still requires outputs of a trained deep net and results presented in our paper will be of great use for neuroimaging practitioners.\r\n\r\nThank you for catching our failure to define SM as spatial map in the paper. This omission has been corrected but we will wait for other reviewers to comment before uploading the new version.\r\n\r\nWe have performed comparisons with the most widely used ICA approaches and several non-ICA approaches that are not as popular but have been applied in neuroimaging as well.\r\n\r\nIt is unclear why would one worry about parameter increase if it does not lead to overfitting. In our case (i.e. Table 1) no overfitting is observed as we report cross-validation results on hold out data. From the literature we know that when the deep learning community claims performance increase with depth they exactly mean testing performance (and this claim we have validated positively for neuroimaging data). It is clear training data will only be overfit with more parameters, but hold out data does not have this problem. Note also, parameter increase is linear in the number of layers. For example for our 50-50-100 networks we have 50*60465 parameters for depth 1 net, 50*60465 + 50*50 for depth 2 net and 50*60465 + 50*50 + 50*100 for depth 3. This is 0.08% (sic!) increase in parameters from depth 1 to depth 2, 0.16% (sic!) from depth 2 to depth 3 and only 0.24% from depth 1 to depth 3. Yet classification performance increases by much more. I may have misunderstood your question, but it does not seem to me there is a problem here."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390080000000, "tcdate": 1390080000000, "number": 1, "id": "GGNxGzRU2OzPC", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "UVH3Ucewd-IXZ", "replyto": "UVH3Ucewd-IXZ", "signatures": ["anonymous reviewer 0657"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep learning for neuroimaging: a validation study", "review": "The paper starts by describing the success of deep learning, which has been incredible, and from the very beginning sounds like the standard paper of 'let's try a successful technique from other areas in our problems.' While interesting, it has problems to start with, not all popular techniques should be applied to all problems.\r\n\r\nThe paper presents an interesting introduction, with philosophical components, and some I either don't understand or they are not accurate.\r\nOracle is the theoretical limits of a problem, and if there is something we are fulling lacking is theory for deep learning (though some old one exists), so not clear what the authors mean.\r\n\r\nSecond, the authors should be aware of works on model compression that show that deep learning might actually not be needed and shallow nets can achieve almost same results, a paper on the topic even submitted to this conference.\r\n\r\nI am not an RBM expert, only familiar with the subject, so I read it but I am not judging its correctness.\r\n\r\nWas SM (Figure 1) ever defined? I can't find it even with my search function in the editor. This is critical.\r\n\r\nNot critical if when comparing with ICA, you are using the last techniques developed by Smith and his team and available in the public code from Oxford (double ICA, etc). So are comparisons with the state-of-the-art?\r\nAlso, while is stated for Fig. 3 that RBM results are more supported by biology, no reference is providing to support this claim.\r\n\r\nThe multiplayer comparison in Section 3 makes no sense since parameters are significantly increasing when adding layers. The authors should look at work on model compression to see how these comparisons need to be made, and they might be surprised with the results, or maybe not, but increasing parameters by orders of magnitude is not fair.\r\n\r\nThe paper has major issues then, but the authors have done a lot of experimentation, and while under normal circumstances I would certainly recommend to reject, I think that their presence at the conference can lead to interesting discussions. The authors have not convinced me at all that their approach or deep networks in general is useful for their task, but I do believe in open discussions and I believe the community will benefit much more from the science that might come out from them defending their work at the meeting than from us rejecting outright the paper. Hopefully after the meeting we might be able to conclude if this is a direction worth investigating or not."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387796880000, "tcdate": 1387796880000, "number": 31, "id": "UVH3Ucewd-IXZ", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "UVH3Ucewd-IXZ", "signatures": ["splis@mrn.org"], "readers": ["everyone"], "content": {"title": "Deep learning for neuroimaging: a validation study", "decision": "submitted, no decision", "abstract": "Deep learning methods have recently enjoyed a number of successes in the tasks of classification and representation learning. These tasks are very important for brain imaging and neuroscience discovery, making the methods attractive candidates for porting to a neuroimager's toolbox. Successes are, in part, explained by a great flexibility of deep learning models. This flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "pdf": "https://arxiv.org/abs/1312.5847", "paperhash": "plis|deep_learning_for_neuroimaging_a_validation_study", "keywords": [], "conflicts": [], "authors": ["Sergey M. Plis", "Devon R. Hjelm", "Ruslan Salakhutdinov", "Vince D. Calhoun"], "authorids": ["splis@mrn.org", "dhjelm@mrn.org", "rsalakhu@cs.toronto.edu", "vcalhoun@mrn.org"]}, "writers": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 10}