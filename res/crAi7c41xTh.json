{"notes": [{"id": "crAi7c41xTh", "original": "79mKtVDAXr6", "number": 1062, "cdate": 1601308119549, "ddate": null, "tcdate": 1601308119549, "tmdate": 1614985656395, "tddate": null, "forum": "crAi7c41xTh", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "jI0N1Hkd0x", "original": null, "number": 1, "cdate": 1610040506154, "ddate": null, "tcdate": 1610040506154, "tmdate": 1610474113391, "tddate": null, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper shows that for a simple nonlinear (quadratically parametrized linear) model, stochastic gradient descent (SGD) with a certain label noise and learning rate schedule recovers the data generating model. In contrast, gradient descent with or without Gaussian noise fails. While the results are novel and interesting, they hold for a rather specialized model, which may not reveal anything about deep neural networks, which was the original motivation for this work. Given the narrow focus of the work, unfortunately, I cannot recommend that the paper be accepted. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040506141, "tmdate": 1610474113374, "id": "ICLR.cc/2021/Conference/Paper1062/-/Decision"}}}, {"id": "L9Y_gpxuSFx", "original": null, "number": 3, "cdate": 1604032349505, "ddate": null, "tcdate": 1604032349505, "tmdate": 1606768618926, "tddate": null, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review", "content": {"title": "Rigorous results but on a limited problem", "review": "This paper demonstrates that for a particular model SGD with label noise and proper learning rate schedule recovers the (sparse) data generating model while GD with or without Gaussian noise does not. In the latter case, it fails because a stationary distribution is not achieved. The proofs in the appendix are quite involved, and as a result I did not carefully study them. But the authors provide helpful intuition for the results in the main text. \n\nWhile I think there is value in the work, I am not sure whether the fairly specific setting studied has much to say about neural networks. (Of course, not every paper needs to be about neural networks, but that's certainly the motivation of the paper.) There are a number of aspects to the work that limit its generality: the model, the label noise, the objective of reconstruction of sparse ground truth from the same model class, and the dataset modeling. The authors justify the model by saying that other works that have studied it, but don't otherwise try to justify its relevance. In Figure 1, the authors argue that label noise behaves similar to SGD, but I don't find this thorough or convincing enough that any results on label noise and the mechanism by which it operates should generalize to SGD. Also, whether studying an objective of learning as identifying the sparse ground truth model seems far from standard training of a neural network. As an example of my concern that the specifics by which the results are achieved may not apply in other scenarios, do the authors believe that GD with Gaussian noise fails for neural networks because a stationary distribution is never achieved, whereas it is achieved for SGD?\n\nOverall, I think that the work is a bit too narrow and doesn't change our understanding of what non-spherical noise from SGD does to neural networks beyond what is already known.\n\n\nMinor presentation points:\n\nThe paper became rushed at the end, as if the authors ran out of space. Subsections 3.2 \"Stage 0\" and 3.3 \"Stage 1\" are then followed by a very short paragraph inside 3.3 titled \"Stage 2\". \n\nFigure 1 is fairly difficult to parse with the number of noisy curves overlapping each other. Perhaps the authors could make their point with the minimal amount of experimental data here and relegate the rest to the appendix.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128001, "tmdate": 1606915801792, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1062/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review"}}}, {"id": "GvpjwkH8wNq", "original": null, "number": 4, "cdate": 1604103738379, "ddate": null, "tcdate": 1604103738379, "tmdate": 1606174967603, "tddate": null, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review", "content": {"title": "Weak accept", "review": "### Problem\n\nThis paper considers the effect of label noise on stochastic gradient descent. The setup is that there is a vector $v \\in R^d$. We observe samples from $v^2\\cdot x$. We only have $n < d$ samples but $v$ is $r$-sparse for $r < n < d$ which makes recovery possible information theoretically. The main result is that stochastic gradient descent with label noise, and without any explicit regularization will recover the ground truth. whereas adding spherical Gaussian noise does not.\n\n### Pros and Cons\n\nThe problem is a clean toy problem with which to illustrate the gap between algorithms. It shows a clean separation between the power of label noise and that of random Gaussian noise. The model appears to be the simplest model where one can hope to see the regularization effects of noise (the simpler linear regression model wouldnt show these effects).  One possible criticism could be to ask if understanding this model is truly getting us closer to understanding what happens in deep nets. At this point it is hard to say, but proving such a result even in this simple model is not trivial, and is definitely a contribution.\n\n\n### Evaluation\nI think this is a solid theoretical contribution on an important problem, and the paper should be accepted.\n\n\n### Further comments\n\nI was a little confused by the comment that the coefficients are assumed to be in ${0,1}$ since they then satisfy $v_i^2 = v_i$ as this seems to linearize the model. The authors should probably clarify that this is actually not what is going on. It might be better to use a different setting of parameters even for exposition. \n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128001, "tmdate": 1606915801792, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1062/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review"}}}, {"id": "x6WzLamj0Rz", "original": null, "number": 6, "cdate": 1605412328640, "ddate": null, "tcdate": 1605412328640, "tmdate": 1605412500816, "tddate": null, "forum": "crAi7c41xTh", "replyto": "MNr1-ET5uw1", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the comments and feedback! We will incorporate feedback and comments into the next version of our paper.\n\nResponses to specific points below:\n\n\n\n*-- \u201cIt would be nicer to discuss if this analysis of the initial phase has something to do with singularities.\u201d*\n\nWe thank the reviewer for pointing out the potential connection between our theory and the idea of singularities in [Guo et al. 2018]. Our Theorem 3.1 shows that GD with label noise converges to parameters with small norm, which helps achieve better generalization. In comparison, [Guo et al. 2018] shows that for a RBF network, GD can sometimes be trapped around some parameter regime with small norm (termed \u201celimination singularity\u201d). \n\nConceptually, both our theory and the singularities theory involves a regime where the parameter has a small norm. However, the effect of the small norm is different: in our work the small norm is beneficial to recovering the ground truth, while in [Guo et al. 2018] small norm parameters make the optimization slower. One interesting future direction might be the potential tradeoff between better generalization and faster optimization. We have added [Guo et al. 2018] and the above connection to our related works section. \n\n*-- \u201cWhat is the second-order effect (of zero-mean noise) on a potential function?\u201d*\n\nThe \u201csecond-order effect\u201d refers to the noise\u2019s influence on the expectation of potential function under second-order Taylor approximation (see the last equation in Section 3.1, page 6). In general for any potential function on model parameters, adding zero-mean noise to parameters won\u2019t change the expectation of potential function under first order Taylor approximation. However, when the Hessian of the potential function is non-zero, adding zero-mean noise will change the expectation of potential function under second-order Taylor approximation. \n\nThis second-order effect is an essential step in the proof of Theorem 3.1. Concretely, we define a concave potential function $\\phi(\\cdot)$ and show that it decreases in expectation due to the second-order effect. The decreasing potential function is further translated into the convergence of parameters.\n\n*-- \u201cThe difference (affinity) between the deep neural network and the quadratically-parameterized model is mainly discussed numerically (Figure 1). It would be nicer to discuss gaps between them theoretically, if possible.\u201d*\n\nWe suspect that our high level intuition --- training with state-dependent noise follows a path with smaller noise --- may still hold for neural networks. However, to formally generalize our theory to neural nets, the fundamental obstacle is that we lack sufficient structures to analyze the optimization dynamics for a non-convex function.  The direct technical challenge is how to properly choose a potential function for which we can control iteratively. Analyzing  the global dynamics of nonconvex optimization for neural nets---with the regularization effect being taken into account --- appears to be a major open question in the area of deep learning theory.  \n\nReferences:\n\n[Guo et al. 2018] Guo, W., Wei, H., Ong, Y. S., Hervas, J. R., Zhao, J., Wang, H., & Zhang, K. (2018). Numerical analysis near singularities in RBF networks. The Journal of Machine Learning Research, 19(1), 1-39.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "crAi7c41xTh", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1062/Authors|ICLR.cc/2021/Conference/Paper1062/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864130, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment"}}}, {"id": "aIo1FpVXC4H", "original": null, "number": 5, "cdate": 1605412219625, "ddate": null, "tcdate": 1605412219625, "tmdate": 1605412470072, "tddate": null, "forum": "crAi7c41xTh", "replyto": "klJv4DqW8t7", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the comments and insightful questions!\n\nResponses to specific points below:\n\n*-- \u201cWhy are three stages with decreasing step-sizes needed for the analysis? Can we expect a similar result to hold if a constant, but, small step-size is chosen instead?\u201d*\n\nWe study three stages of decreasing step-sizes since the analysis can be simpler and more straightforward in this setting. Moreover, empirically, for the quadratically-parameterized model (and real datasets), though a small constant step-size can also work, its convergence is slower than decaying lr schedule. Thus, we chose to mostly focus on the decaying lr schedule. \n\nConcretely,  our current analysis shows a clear contrast between stages --- the effect of noise dominates the gradient in the first stage (and the second stage for sparse dimensions), vice versa in the last stage (and the second stage for non-sparse dimensions). Analyzing constant step-size is interesting and more challenging and is left for future work due to the more complicated interaction between noise and gradient. \n\n*-- \u201cThe generative model assumes that the label y has no added noise. Are the theoretical results robust to additive noise?\u201d*\n\nYes, our theory can be generalized (straightforwardly) to the setting where the label has additive noise, though in this case we can only recover the ground truth approximately because the noise precludes exact recovery. We would also like to clarify that even with the intrinsic noise in the label, additional artificial noise in the optimizer is still needed to achieve good generalization, both empirically and theoretically. This suggests that the artificial noise is more fundamental to the improved generalization.  \n\nWe will add this extension in the next revision. We primarily focused on artificial noise in the optimization procedure because we aimed to study the  implicit bias of the optimizers \n\n*-- \u201cThe authors point out on page 4 that the sample complexity is worse than LASSO (which is fine), but, do not remark why this is the case. It would be insightful if the authors could add a comment about why this is the case.\u201d*\n\nAs we briefly mentioned in the footnote 3, this is due to the technical limitation of analyzing nonconvex optimization. Most of the nonconvex optimization algorithms (even without overparameterization and implicit regularization) do not have the optimal sample complexity guarantees in the sparsity as the convex relaxations can. E.g., the works on nonconvex optimization for matrix completion or matrix sensing often suffers from a suboptimal dependency on the rank r ([Li et al. 2018], [Ge et al. 2016] and [Chi et al. 2019]), where [Ge et al. 2016] and [Chi et al. 2019] don\u2019t consider any overparameterization. Our direct prior work [Vaskevicius et al. 2019] also had the same limitations. We didn\u2019t focus on getting the optimal dependency in r because the main message is that we can get much better dependency in d, compared to GD. \n\nMore concretely, in both our analysis and the proof of LASSO\u2019s bound, one important step is to show that with high probability, the data matrix $E_i [x_i x_i^\\top]$ satisfies some property. For the proof of LASSO, the property that we need is the restricted eigenvalue of $E_i [x_i x_i^\\top]$ in some convex cone to be strictly positive (see page 295 of [Hastie et al. 2015]). However, our analysis requires that each off-diagonal element of the matrix to be smaller than O(1/r), which is a stronger assumption and hence can be guaranteed only with more data.  We believe this is fundamentally the same technical challenge showing up in [Li et al. 2018], [Ge et al. 2016] and [Chi et al. 2019]. \n\nReferences:\n\n[Hastie et al. 2015] Hastie, T., Tibshirani, R., & Wainwright, M. (2015). Statistical learning with sparsity: the lasso and generalizations. CRC press.\n\n[Li et al. 2018] Li, Y., Ma, T., & Zhang, H. (2018). Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory (pp. 2-47). PMLR.\n\n[Ge et al. 2016] Ge, R., Lee, J. D., & Ma, T. (2016). Matrix completion has no spurious local minimum. In Advances in Neural Information Processing Systems (pp. 2973-2981).\n\n[Chi et al. 2019] Chi, Y., Lu, Y. M., & Chen, Y. (2019). Nonconvex optimization meets low-rank matrix factorization: An overview. IEEE Transactions on Signal Processing, 67(20), 5239-5269.\n\n[Vaskevicius et al. 2019] Vaskevicius, T., Kanade, V., & Rebeschini, P. (2019). Implicit regularization for optimal sparse recovery. In Advances in Neural Information Processing Systems.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "crAi7c41xTh", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1062/Authors|ICLR.cc/2021/Conference/Paper1062/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864130, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment"}}}, {"id": "fSJbcONL3ti", "original": null, "number": 3, "cdate": 1605411883246, "ddate": null, "tcdate": 1605411883246, "tmdate": 1605412377625, "tddate": null, "forum": "crAi7c41xTh", "replyto": "L9Y_gpxuSFx", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment", "content": {"title": "Response (continued)", "comment": "Responses to specific points below:\n\n*-- \u201cDo the authors believe that GD with Gaussian noise fails for neural networks because a stationary distribution is never achieved?\u201d*\n\nYes, we believe that failing to converge to a good distribution is the reason why GD with Gaussian noise fails. We provide additional empirical results in Section A.3 that can corroborate the hypothesis. We plot the norm of the weight for a VGG19 network trained on CIFAR100 (Figure 2). Our result shows that the weight norm of GD with Gaussian noise keeps increasing and doesn\u2019t converge. In contrast, the weight norm of both GD without noise and GD with label noise converges (with the same decaying learning rate schedule as the Gaussian noise experiment). \n\nReferences:\n\n[Gunasekar et al. NeurIPS 2017] Gunasekar, S., Woodworth, B., Bhojanapalli, S., Neyshabur, B., & Srebro, N. (2017). Implicit Regularization in Matrix Factorization. In Advances in Neural Information Processing Systems. \n\n[Soudry et al. NeurIPS 2018] Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S., & Srebro, N. (2018). The implicit bias of gradient descent on separable data. The Journal of Machine Learning Research, 19(1), 2822-2878.\n\n[Li et al. COLT 2018] Li, Y., Ma, T., & Zhang, H. (2018). Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory (pp. 2-47). PMLR.\n\n[Vaskevicius et al. NeurIPS 2019] Vaskevicius, T., Kanade, V., & Rebeschini, P. (2019). Implicit regularization for optimal sparse recovery. In Advances in Neural Information Processing Systems.\n\n[Woodworth et al. COLT 2020] Woodworth, B., Gunasekar, S., Lee, J.D., Moroshko, E., Savarese, P., Golan, I., Soudry, D., & Srebro, N.. (2020). Kernel and Rich Regimes in Overparametrized Models. Proceedings of Thirty Third Conference on Learning Theory, in PMLR.\n\n[Wei et al. 2019] Wei, C., Lee, J. D., Liu, Q., & Ma, T. (2019). Regularization matters: Generalization and optimization of neural nets vs their induced kernel. In Advances in Neural Information Processing Systems.\n\n[Ghorbani et al. 2019]Ghorbani, B., Mei, S., Misiakiewicz, T., & Montanari, A. (2019). Limitations of lazy training of two-layers neural networks. In Advances in Neural Information Processing Systems.\n\n[Allen-Zhu et al. 2019] Allen-Zhu, Z., & Li, Y. (2019). What Can ResNet Learn Efficiently, Going Beyond Kernels?. In Advances in Neural Information Processing Systems (pp. 9017-9028)."}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "crAi7c41xTh", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1062/Authors|ICLR.cc/2021/Conference/Paper1062/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864130, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment"}}}, {"id": "yh24nauBw1", "original": null, "number": 4, "cdate": 1605411998222, "ddate": null, "tcdate": 1605411998222, "tmdate": 1605412035487, "tddate": null, "forum": "crAi7c41xTh", "replyto": "L9Y_gpxuSFx", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the comments and feedback! We will incorporate the minor comments into the next version of our paper and address the major ones below.\n\nThe main concern of the reviewer is whether \u201cthe fairly specific setting studied has much to say about neural networks\u201d. While we agree with the reviewer that there is a bit gap between our simplified model and deep nets, we would like to clarify that the goal of the work is not to study the mechanisms of implicit regularization in deep neural nets. Instead, our goal is to develop rigorous techniques and understanding for how the noise in optimization can improve the generalization at all in *any* reasonable machine learning setting. Prior to our work, no paper has shown a rigorous result on the improved sample complexity on any problems (including linear models) caused by the noise covariance, and we are the first paper that rigorously distinguishes the effect of spherical Gaussian noise and other non-spherical Gaussian noise. \n\nIn our opinion, the paper perhaps should not be evaluated based on the improvement in \u201cour understanding of what non-spherical noise from SGD does in deep learning\u201d, to which the paper does not claim to contribute. Instead, we believe our paper can be better and more fairly evaluated based on the theoretical contributions to proving rigorously that non-spherical Gaussian noise can have a superior implicit regularization effect on some machine learning models, according to which we think we made significant contributions compared to prior work. \n\nFor example, the pioneering works [Gunasekar et al. NeurIPS 2017 , Soudry et al. NeurIPS 2018, Li et al., COLT 2018] studies gradient descent\u2019s implicit bias for linear models or low-rank matrix factorization. [Woodworth et al. COLT 2020, Vaskevicius et al. NeurIPS 2019] studied the implicit bias of initialization on the same model as ours. As far as we know, these are all the major rigorous studies of implicit regularization with sample complexity guarantees (please see our related work section for a few other works) and they all work with simpler settings than deep neural nets. These works did not address why stochastic gradient descent with different noises presents different implicit biases, and our work proves it in the same setting as [Woodworth et al. COLT 2020, Vaskevicius et al. NeurIPS 2019]. \n\nArguably, developing rigorous theory is important and analyzing simplified models is an almost necessary first step toward developing rigorous theory for more complex models. It seems that analyzing even GD for deep neural nets is out of reach with our current mathematical techniques (unless we use the NTK approach which results in poor generalization performance as shown by many recent works [Wei et al. 2019, Allen-Zhu et al. 2019, Ghorbani et al. 2019]), let alone analyzing implicit regularization effects of the optimizers.  \n\nTherefore, we respectfully ask the reviewers to calibrate our paper against the theoretical works on implicit regularization. (We summarize prior works in the related work section, and would be happy to follow up on any comparisons.) That said, we will also conduct additional experiments on answering the reviewer\u2019s question regarding the relationship to the realistic setting below, though we do not think that\u2019s our main contribution. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "crAi7c41xTh", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1062/Authors|ICLR.cc/2021/Conference/Paper1062/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864130, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment"}}}, {"id": "t85NN1vJ95", "original": null, "number": 2, "cdate": 1605411612982, "ddate": null, "tcdate": 1605411612982, "tmdate": 1605411630782, "tddate": null, "forum": "crAi7c41xTh", "replyto": "GvpjwkH8wNq", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the comments and feedback!\n\nThe reviewer\u2019s main concern is that because we assume each entry of the ground truth $v^*$ lies in {0, 1}, \u201cit seems to make the model essentially linear\u201d.  We\u2019d like to clarify that this assumption is only made for simplicity of the exposition--- without much modification of the proof,  we can instead assume that each entry of $v^*$ is either 0 or from [c,C] for constants 0<c<C. \n\n(For instance, to generalize our Theorem 3.1 to the setting where different dimensions of $v^*$ have different values, we only need to change the learning rate accordingly by a constant factor, such that the contraction to 0 still holds. Similarly, we can modify Theorem 3.2 and Theorem 3.3 without changing much.)\n\nWe also would like to clarify that the model is *nonlinear* in the trainable parameters. We also don\u2019t make any restriction on whether the trainable parameters are sparse or in {0,1} (or in {0} and [c,C] in the extension). As a consequence, the objective function is non-convex in training parameters. Moreover, we note that the phenomenon of the implicit bias of the noise covariance cannot be empirically observed in standard linear regression models. \n \nGiven that we believe that we address the only concern of the reviewer, we respectfully ask the reviewer to consider increasing the score. Our main contribution is a rigorous theory for the quadratically-parameterized model that shows SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits and learns dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "crAi7c41xTh", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1062/Authors|ICLR.cc/2021/Conference/Paper1062/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864130, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Comment"}}}, {"id": "MNr1-ET5uw1", "original": null, "number": 1, "cdate": 1603872919812, "ddate": null, "tcdate": 1603872919812, "tmdate": 1605024540063, "tddate": null, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review", "content": {"title": "Solid contribution with theoretical insights on SGD with label noise", "review": "This paper considers the implicit regularization of stochastic gradient decent (SGD). The authors analyze SGD with label nose in the quadratically-parameterized model and prove that it converges to the sparse ground-truth even if started with large initialization. The authors also prove that SGD with Gaussian noise (Langevin dynamics) does not converge to the ground truth at zero under the overparameterized regime.\n\nThis is a solid contribution with theoretical insights on SGD with label noise. While the theoretical results are deep with long proofs, their outlines and meanings are well explained.\n\n- The difference (affinity) between the deep neural network and the quadratically-parameterized model is mainly discussed numerically (Figure 1). It would be nicer to discuss gaps between them theoretically, if possible. For example, the contraction of SGD in the initial phase (Thm 3.1) is reminiscent of the effect of singularities in neural networks discussed in references such as:\nGuo et al.: Numerical Analysis near Singularities in RBF networks, JMLR, 19(2018), 1-39.\nIt would be nicer to discuss if this analysis of the initial phase has something to do with singularities.\n\n- p.7, footnote 7: What is the second-order effect (of zero-mean noise)?\n\nMinor:\np.4, Langevin dynamics/diffusion: The last sentence is duplicated.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128001, "tmdate": 1606915801792, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1062/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review"}}}, {"id": "klJv4DqW8t7", "original": null, "number": 2, "cdate": 1603952318016, "ddate": null, "tcdate": 1603952318016, "tmdate": 1605024540001, "tddate": null, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "invitation": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review", "content": {"title": "the authors study an interesting problem and provide sound theoretical analysis", "review": "The authors study the problem quadratically parameterized (linear) regression and study the behavior of SGD to solve it when the stochasticity added is in terms of label noise. They show that SGD (with this kind of noise) with arbitrarily large initialization converges to the ground truth solution, whereas there exist settings where Langevin dynamics or gradient descent would fail to converge to this solution. The proofs are carried out carefully and are correct as best as I could verify. The authors also provide experiments on synthetic data to support and motivate their theory.\n\n\nSome questions/comments:\n1. Why are three stages with decreasing step-sizes needed for the analysis? Can we expect a similar result to hold if a constant, but, small step-size is chosen instead?\n2. The generative model assumes that the label y has no added noise. Are the theoretical result robust to additive noise?\n3. The authors point out on page 4 that the sample complexity is worse that LASSO (which is fine), but, do not remark why this is the case. It would be insightful if the authors could add a comment about why this is the case, and if this was experimentally observed as well.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1062/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1062/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shape Matters: Understanding the Implicit Bias of the Noise Covariance", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Jason_D._Lee1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Jason D. Lee", "Tengyu Ma"], "keywords": ["implicit regularization", "implicit bias", "algorithmic regularization", "over-parameterization", "learning theory"], "abstract": "The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise --- induced by mini-batches or label perturbation --- is far more effective than Gaussian noise. \nThis paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al.  We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overfits to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not. ", "one-sentence_summary": "We theoretically prove that in an over-parameterized setting, SGD with label noise recovers the ground-truth, whereas SGD with spherical Gaussian noise overfits.", "pdf": "/pdf/1eaa42a8029f10c2aaa236a956889a4fc8fbc67a.pdf", "supplementary_material": "/attachment/f07dca3abe9527c77d1a83576c6f4506a2c859a6.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "haochen|shape_matters_understanding_the_implicit_bias_of_the_noise_covariance", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ApRIL0oBr", "_bibtex": "@misc{\nhaochen2021shape,\ntitle={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},\nauthor={Jeff Z. HaoChen and Colin Wei and Jason D. Lee and Tengyu Ma},\nyear={2021},\nurl={https://openreview.net/forum?id=crAi7c41xTh}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "crAi7c41xTh", "replyto": "crAi7c41xTh", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1062/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128001, "tmdate": 1606915801792, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1062/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1062/-/Official_Review"}}}], "count": 11}