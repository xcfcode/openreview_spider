{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028643959, "tcdate": 1490028643959, "number": 1, "id": "S1nP_tTsx", "invitation": "ICLR.cc/2017/workshop/-/paper164/acceptance", "forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028644499, "id": "ICLR.cc/2017/workshop/-/paper164/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028644499}}}, {"tddate": null, "tmdate": 1489618205912, "tcdate": 1489618205912, "number": 2, "id": "r1UQHBPjg", "invitation": "ICLR.cc/2017/workshop/-/paper164/public/comment", "forum": "rJv6ZgHYg", "replyto": "HkhwFAgsx", "signatures": ["~David_Krueger1"], "readers": ["everyone"], "writers": ["~David_Krueger1"], "content": {"title": "More on our differences with Zhang et al.; Memorization *operationalized* not defined.", "comment": "\nI agree that a more rigorous definition of memorization would be valuable.\nAs I mentioned in response to the other reviewer, I believe that our use of \u201cmemorization\u201d is consistent with Zhang et al., and that our results and conclusions are different in some important ways, although certainly not completely contradictory.\nI think you can view both of our papers as operationalizing \u201cmemorization\u201d as \u201cthe way in which a DNN fits random (unstructured) data\u201d.\n\nZhang et al. emphasize these similarities in fitting data vs. noise:\n1. it\u2019s possible to achieve perfect (or near perfect) training accuracy \n2. training times are not radically different in these two scenarios\n\nWe emphasize these differences:\n1. the difference in training time is not a constant factor; rather it depends on capacity and the number of training examples.\n2. the response to regularization is different\n3. the complexity of what is learned is different\n\nRE your explanation of point 3, I agree that it is about the data, but:\n1. There are many ways to fit the training set, not a single target function.\n2. In particular, if it were the case that, \u201c3. Randomizing labels is solely a data transformation, leaving all other properties of the learning problem unchanged,\u201d\nas Zhang et al. claim, then we would expect that when training on random/real labels, a similar solution can and would be found.\n\n\nI agree that the suggested experiment would be interesting, but disagree that memorization would imply no generalization.\nK-NN, for instance, memorizes the data, but *can* still generalize somewhat.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368639421, "tcdate": 1487368639421, "id": "ICLR.cc/2017/workshop/-/paper164/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper164/reviewers"], "reply": {"forum": "rJv6ZgHYg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368639421}}}, {"tddate": null, "tmdate": 1489197412525, "tcdate": 1489197412525, "number": 2, "id": "HkhwFAgsx", "invitation": "ICLR.cc/2017/workshop/-/paper164/official/review", "forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "signatures": ["ICLR.cc/2017/workshop/paper164/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper164/AnonReviewer2"], "content": {"title": "Interesting observations but not convincing enough ", "rating": "5: Marginally below acceptance threshold", "review": "The paper tries to argue the incorrectness of the existing claim by Zhang that deep neural network learns to memorizing training data. \n\nFirstly, as pointed out by the first reviewer, the term memorization in the two papers are different. The claims are not completely contradict. For example, in Zhang's paper, they claim that \"neural networks are able to capture the remaining signal in the data, while at the same time fit the noisy part using brute-force\". In this paper, the authors claims \"we believe that DNNs first learn and then refine simple patterns, which are shared across examples, in order to quickly drive down training loss, and only incorporate more case-by-case memorization as a later resort\". Basically, the learning of DNNs are capable of identifying patterns in structured data, but with random noise where no shared patterns could be extracted across target classes, sample dependent hypotheses are learnt given enough capacity. Hence, the two papers are claim the same DNN learning behavior.\n\nOn the experimental setup, the datasets used for both papers have only a small amount of target classes. Even when randomizing the labels, it's still labeled as one of the 10 classes. DNNs learn to fit to the training data, which guides DNNs to find shared patterns within samples of the same target class. A naive thought if there are the same number of classes as the number of samples in the training data, how does DNNs learn. If DNNs still learn to model the boundaries, there will still be some generalization capability. Otherwise, if DNNs learn by memorization, it should no generalize at all. Because the target labels are not pushing the model to extract shared patterns. Just random thought not sure useful or not.\n\nRegarding the claim \"DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence\". Personally, I believe that relates more to the data, as with noise data, true function DNNs try to learn are very different from the clean data. Hence, it's not all about how DNNs learn. The difference in the target function DNNs have to learn also affects. \n\nThe experiments in this papers do shown different perspectives from what Zhang reported. It would be of interest of many readers, but it would be a more stronger case if clearer definitions of terms such as memorization are defined and more experiments to support the claims. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489197413145, "id": "ICLR.cc/2017/workshop/-/paper164/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper164/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper164/AnonReviewer1", "ICLR.cc/2017/workshop/paper164/AnonReviewer2"], "reply": {"forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper164/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper164/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489197413145}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489186325551, "tcdate": 1489186293853, "number": 1, "id": "ryAeRieil", "invitation": "ICLR.cc/2017/workshop/-/paper164/public/comment", "forum": "rJv6ZgHYg", "replyto": "SylkOteox", "signatures": ["~David_Krueger1"], "readers": ["everyone"], "writers": ["~David_Krueger1"], "content": {"title": "Clarifying the notion of memorization and our differences with Zhang et al.", "comment": "\nWe believe there is a conflict, although we agree that DNNs ability to both \n1) generalize on real data\nand \n2) fit noise \nposes a challenge for traditional learning theory.\n\nFirst, to clarify, we intend to use the same intuitive notion of memorization as Zhang et al.\nWhile neither of us provide a rigorous definition of memorization, we can characterize what properties we expect learning-via-memorization to have.\n\nFor instance, in our view, the data distribution should not have a strong, consistent effect on the learning problem for an algorithm using \u201cbrute-force memorization\u201d.\nZhang et al. seem to share this view, claiming that \u201c3. Randomizing labels is solely a data transformation, leaving all other properties of the learning problem unchanged.\"\nHowever, in sections 2.1 and 2.3, we contradict this claim, demonstrating qualitative differences in the learning problem on real vs. random data.\n\nFurthermore, our results in section 2.1, contradict the claim: \u201cIn fact, training time increases only by a small constant factor compared with training on the true labels.\u201d\nWe show that the (factor of) increase in training time is *not* constant; it is sensitive to both capacity and number of training examples.\n\nWe thank you for the feedback, and apologize for not making these points clearer in the paper.\nWe hope this comment clarifies our stance with respect to memorization and the previous work of Zhang et al. in a way that highlights our contributions."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368639421, "tcdate": 1487368639421, "id": "ICLR.cc/2017/workshop/-/paper164/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper164/reviewers"], "reply": {"forum": "rJv6ZgHYg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368639421}}}, {"tddate": null, "tmdate": 1489176536346, "tcdate": 1489176536346, "number": 1, "id": "SylkOteox", "invitation": "ICLR.cc/2017/workshop/-/paper164/official/review", "forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "signatures": ["ICLR.cc/2017/workshop/paper164/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper164/AnonReviewer1"], "content": {"title": "No consensus on what memorization means", "rating": "6: Marginally above acceptance threshold", "review": "This paper reads as a rebuttal to the recent work by Zhang. In this paper, it was shown that neural nets are in principle able to shatter the input data in the conducted experiments, which means that any labelling can be represented by the network:\n\n\"The experiments we conducted emphasize that the effective capacity of several successful neural network architectures is large enough to shatter the training data. Consequently, these models are in principle rich enough to memorize the training data.\"\n\nThis paper, however defines memorization as a failure to generalize.\n\nHence, both papers are based on different definitions of what memorization means. I felt it would have been much better if the authors of this paper had followed along the definition of Zhang et al. My fear is that this confusion is actually hurting, as it suggest a conflict where \u2013 in my opinion \u2013 none exists.\n\n\nNevertheless, the paper has some interesting experiments.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489197413145, "id": "ICLR.cc/2017/workshop/-/paper164/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper164/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper164/AnonReviewer1", "ICLR.cc/2017/workshop/paper164/AnonReviewer2"], "reply": {"forum": "rJv6ZgHYg", "replyto": "rJv6ZgHYg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper164/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper164/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489197413145}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487651022705, "tcdate": 1487368638636, "number": 164, "id": "rJv6ZgHYg", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "rJv6ZgHYg", "signatures": ["~David_Krueger1"], "readers": ["everyone"], "content": {"title": "Deep Nets Don't Learn via Memorization", "abstract": "We use empirical methods to argue that deep neural networks (DNNs) do not achieve their performance by \\textit{memorizing} training data, in spite of overly-expressive model architectures. \nInstead, they learn a simple available hypothesis that fits the finite data samples.\nIn support of this view, we establish that there are qualitative differences when learning noise vs.~natural datasets, showing that: (1) more capacity is needed to fit noise, (2) time to convergence is longer for random labels, but \\emph{shorter} for random inputs, and (3) DNNs trained on real data examples learn simpler functions than when trained with noise data, as measured by the sharpness of the loss function at convergence.\nFinally, we demonstrate that for appropriately tuned explicit regularization, e.g.~dropout, we can degrade DNN training performance on noise datasets without compromising generalization on real data. ", "pdf": "/pdf/d27e2ab092c428edc98248eef5f2d1f054bf33e3.pdf", "TL;DR": "Deep Nets Don't Learn via Memorization", "paperhash": "krueger|deep_nets_dont_learn_via_memorization", "authorids": ["davidscottkrueger@gmail.com"], "keywords": ["Deep learning", "Optimization"], "conflicts": ["umontreal.ca", "polymtl.ca", "uj.edu.pl", "iai.uni-bonn.de"], "authors": ["David Krueger*", "Nicolas Ballas*", "Stanislaw Jastrzebski*", "Devansh Arpit*", "Maxinder S. Kanwal", "Tegan Maharaj", "Emmanuel Bengio", "Asja Fischer", "Aaron Courville"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 6}