{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458078988963, "tcdate": 1458078988963, "id": "MwV0Wnnljfqxwkg1t7Gw", "invitation": "ICLR.cc/2016/workshop/-/paper/171/review/11", "forum": "r8lrDJ89Pf8wknpYt5zq", "replyto": "r8lrDJ89Pf8wknpYt5zq", "signatures": ["ICLR.cc/2016/workshop/paper/171/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/171/reviewer/11"], "content": {"title": "This paper proposes a method to learn factorial representations. Given two inputs, it learns by reconstructing the second input using the representation of the first one, except that one component is taken from the features of the second input using gating variables.", "rating": "7: Good paper, accept", "review": " quality:\noverall the paper is clearly written and the toy experiments demonstrate the claims. The topic is very relevant to this venue.\n\nclarity:\ngood.\n\noriginality:\nmedium. This work is related to Memisevic's work on learning relations between pairs of images. The mechanism to compute the transformation is different, but the paper should comment and discuss this.\n\nsignificance of this work:\nalthough premature as a publication, this work can already bring good discussion on how to learn factorial representations.\n\npros:\n+ very relevant topic\n+ somewhat novel model\n\ncons:\n- missing references\n- toy nature of the experiments", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Understanding Visual Concepts with Continuation Learning", "abstract": "We introduce a neural network architecture and a learning algorithm to produce fac- torized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.", "pdf": "/pdf/r8lrDJ89Pf8wknpYt5zq.pdf", "paperhash": "whitney|understanding_visual_concepts_with_continuation_learning", "conflicts": ["mit.edu"], "authors": ["William F. Whitney", "Michael Chang", "Tejas Kulkarni", "Joshua B. Tenenbaum"], "authorids": ["wfwhitney@gmail.com", "mbchang@mit.edu", "tejask@mit.edu", "jbt@mit.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580088431, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580088431, "id": "ICLR.cc/2016/workshop/-/paper/171/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "r8lrDJ89Pf8wknpYt5zq", "replyto": "r8lrDJ89Pf8wknpYt5zq", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/171/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457498613253, "tcdate": 1457498613253, "id": "yovVL3AYjsr682gwszRO", "invitation": "ICLR.cc/2016/workshop/-/paper/171/review/10", "forum": "r8lrDJ89Pf8wknpYt5zq", "replyto": "r8lrDJ89Pf8wknpYt5zq", "signatures": ["ICLR.cc/2016/workshop/paper/171/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/171/reviewer/10"], "content": {"title": "Interesting and novel approach to disentanglement of feature learning - toward symbolic representation learning.", "rating": "7: Good paper, accept", "review": "In recent years, many generative models have been proposed to learn distributed representations automatically from data. One criticism of these models are that they produce representations that are \"entangled\": no single component of the representation vector has meaning on its own. This paper proposes a novel neural architecture and associated learning algorithm for learning disentangled representations. The paper demonstrates the network learning visual concepts on pairs of frames from Atari Games and rendered faces.\n\nNovelty - The proposed architecture uses a gating mechanism to select an index to hidden elements that store the \"unpredictable\" parts of the frame into a single component. The architecture bears some similarity to other \"gated\" architectures, e.g. relational autoencoders, three-way RBMs, etc. in that it models input-output pairs and encodes transformations. However, these other architectures do not use an explicit mechanism to make the network model \"differences\". This is novel. The paper claims that the objective function is novel: \"given the previous frame x_{t-1} of a video and the current frame x_t, reconstruct the current frame x_t. This is essentially the same objective as relational autoencoders (Memisevic) and similar to gated and conditional RBMs which have been used to model pairs of frames. Therefore I would recommend de-emphasizingthe novelty of the objective.\n\nClarity - The paper is well written and clear.\n\nSignificance - This paper opens up many possibilities for explicit mechanisms of \"relative\" encodings to produce symbolic representations. There isn't much detail in the results (it's an extended abstract!) but I think the work is exciting and I'm looking forward to reading a follow up paper.\n\nQuality - Based on the above, I would say that this is a high-quality workshop paper in terms of the ideas and definitely of interest to the ICLR audience.\n\nPros \n- Attacks a major problem of current generative models (entanglement) \n- Proposes a simple yet novel solution \n- Results show visually that the technique seems to work on two non-trivial datasets\n\nCons \n- Experiments are really preliminary - no quantitative results \n- Doesn't mention mechanisms like dropout which attempt to prevent co-adaptation of features\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Understanding Visual Concepts with Continuation Learning", "abstract": "We introduce a neural network architecture and a learning algorithm to produce fac- torized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.", "pdf": "/pdf/r8lrDJ89Pf8wknpYt5zq.pdf", "paperhash": "whitney|understanding_visual_concepts_with_continuation_learning", "conflicts": ["mit.edu"], "authors": ["William F. Whitney", "Michael Chang", "Tejas Kulkarni", "Joshua B. Tenenbaum"], "authorids": ["wfwhitney@gmail.com", "mbchang@mit.edu", "tejask@mit.edu", "jbt@mit.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580088902, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580088902, "id": "ICLR.cc/2016/workshop/-/paper/171/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "r8lrDJ89Pf8wknpYt5zq", "replyto": "r8lrDJ89Pf8wknpYt5zq", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/171/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455831367580, "tcdate": 1455831367580, "id": "r8lrDJ89Pf8wknpYt5zq", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "r8lrDJ89Pf8wknpYt5zq", "signatures": ["~William_F_Whitney1"], "readers": ["everyone"], "writers": ["~William_F_Whitney1"], "content": {"CMT_id": "", "title": "Understanding Visual Concepts with Continuation Learning", "abstract": "We introduce a neural network architecture and a learning algorithm to produce fac- torized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.", "pdf": "/pdf/r8lrDJ89Pf8wknpYt5zq.pdf", "paperhash": "whitney|understanding_visual_concepts_with_continuation_learning", "conflicts": ["mit.edu"], "authors": ["William F. Whitney", "Michael Chang", "Tejas Kulkarni", "Joshua B. Tenenbaum"], "authorids": ["wfwhitney@gmail.com", "mbchang@mit.edu", "tejask@mit.edu", "jbt@mit.edu"]}, "nonreaders": [], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 3}