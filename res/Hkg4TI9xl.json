{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1543468347892, "tcdate": 1478286631603, "number": 331, "id": "Hkg4TI9xl", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Hkg4TI9xl", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "content": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396524194, "tcdate": 1486396524194, "number": 1, "id": "HJV_hzL_x", "invitation": "ICLR.cc/2017/conference/-/paper331/acceptance", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper presents an approach that uses the statistics of softmax outputs to identify misclassifications and/or outliers. The reviewers had mostly minor comments on the paper, which appear to have been appropriately addressed in the revised version of the paper.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396525982, "id": "ICLR.cc/2017/conference/-/paper331/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396525982}}}, {"tddate": null, "tmdate": 1484352376740, "tcdate": 1484352376740, "number": 6, "id": "B1bYsJDUg", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "Paper Update", "comment": "We have updated the paper to make mention of the statistical significance of the AUROCs. We also added Chinese speech from THCHS-30 as out-of-distribution examples. Finally, we added more information about the logit of the blank symbol, the training of the abnormality module, and we revised Appendix B."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1484351976259, "tcdate": 1484351976259, "number": 5, "id": "HylgqywIl", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "BkIlDCr4g", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "Response", "comment": "Thank you!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1484351761038, "tcdate": 1484351761038, "number": 4, "id": "ByKfYyvIl", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "ryGs_6r4g", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "Response", "comment": "Thank you for your analysis of our paper.\n\nWhen performing detection, we compute the softmax probabilities while ignoring the blank symbol's logit. However, in training we leave the blank symbol alone. With the blank symbol's presence, the softmax distributions at most time steps predict a blank symbol with high confidence, but without the blank symbol we can better differentiate between normal and abnormal distributions. We now added this elaboration to the paper.\n\nWe tested the model in confusable settings for vision and NLP (CIFAR-10 and SUN, MNIST and Omniglot, IMDB and Movie Reviews, WSJ and Webblog). Your comment made us realize we should add a test for speech. We used Chinese speech and found that we could still detect the speech reliably (but not as easily), and the abnormality module still generalized to detecting this speech better than softmax probabilities alone. These results are in the updated paper.\n\nWe updated the paper to provide more detail of the abnormality module per your suggestion.\n\nFinally, thank you for the links. We can differentiate between our work and their work if you want."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1484351624445, "tcdate": 1484351624445, "number": 3, "id": "HJlqu1wLg", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "ByBs9JfEx", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "Response", "comment": "Thank you for your analysis of our paper.\n\n1. A common pattern is that the clean examples have a high mean and small standard deviation, and erroneous and out-of-distribution examples have a low mean with high standard deviation. For example, for a previous CIFAR-10 model the prediction probability of correctly classified examples is 0.98 with a standard deviation of 0.066, and the erroneously classified examples have a mean of 0.784 with standard deviation 0.19, and the SUN images have a mean prediction confidence of 0.786 with a standard deviation of 0.19. We will consider adding new out-of-distribution data to test a threshold on for the final paper.\n\n2. We made a note about statistical significance in the updated paper thank to this comment. The null hypothesis that AUROC = 0.5 is tested by the Wilcoxoon rank-sum test, and we reject the null with high statistical significance (p < 1e-3) for all AUROCs computed. For example, the smallest test set has 500 examples, and the smallest AUROC is 0.61, so a loose upper bound on the p-values is 1 - Phi(500*500(0.61-0.5)/sqrt(500*500(500+500+1)/12)) ~ 1E-9, where Phi is the CDF of the standard normal. Error detection on CIFAR-10, for example, has a p-value which is approximately 1 - Phi(34) ~ 1E-253. We could not find a statistical test for AUPRs, however.\n\n3. The bidirectional LSTM has access to the entire sequence of MFCCs. Each probability used in detection is from the softmax computed at each timestep of the sequence. No decoding is necessary for obtaining a probability useful for detection.\n\n4. When performing detection, we compute the softmax probabilities while ignoring the blank symbol's logit. However, in training we leave the blank symbol alone. With the blank symbol's presence, the softmax distributions at most time steps predict a blank symbol with high confidence, but without the blank symbol we can better differentiate between normal and abnormal distributions. We now added this elaboration to the paper.\n\n5. We trained a GMM/HMM with HTK and used the average log likelihood per frame for detection outputted from HVite. We compared the AUROC values of this generative model with the maximum softmax probabilities of the bidirectional LSTM in the paper. The results are as follows.\n\nTIMIT/TIMIT+Airport\nGMM/HMM Log Likelihood AUROC: 88\nLSTM w/ Softmax Prob AUROC:   99\n\nTIMIT/TIMIT+Babble\nGMM/HMM Log Likelihood AUROC: 75\nLSTM w/ Softmax Prob AUROC:   100\n\nTIMIT/TIMIT+Car\nGMM/HMM Log Likelihood AUROC: 92\nLSTM w/ Softmax Prob AUROC:   98\n\nTIMIT/TIMIT+Exhibition\nGMM/HMM Log Likelihood AUROC: 99\nLSTM w/ Softmax Prob AUROC:   100\n\nTIMIT/TIMIT+Restaurant\nGMM/HMM Log Likelihood AUROC: 81\nLSTM w/ Softmax Prob AUROC:   98\n\nTIMIT/TIMIT+Street\nGMM/HMM Log Likelihood AUROC: 95\nLSTM w/ Softmax Prob AUROC:   100\n\nTIMIT/TIMIT+Subway\nGMM/HMM Log Likelihood AUROC: 96\nLSTM w/ Softmax Prob AUROC:   100\n\nTIMIT/TIMIT+Train\nGMM/HMM Log Likelihood AUROC: 97\nLSTM w/ Softmax Prob AUROC:   100\n\nThe largest AUROC improvement of the softmax probability over the GMM/HMM is 25%."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1482196441561, "tcdate": 1482180762080, "number": 2, "id": "ryGs_6r4g", "invitation": "ICLR.cc/2017/conference/-/paper331/official/review", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/conference/paper331/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper331/AnonReviewer3"], "content": {"title": "Paper explores the problem of classifier accuracy estimation and out of domain probability estimation.", "rating": "6: Marginally above acceptance threshold", "review": "The authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out-of-domain. They contrast the performance of the proposed method with directly using the softmax output probabilities, and not their statistics, as a measure of confidence.\n\nIt would be great if the authors elaborate on the idea of ignoring the logit of the blank symbol.\n\nIt would be interesting to see the performance of the proposed methods in more confusable settings, ie., in cases where the out-of-domain examples are more similar to the in-domain examples. e.g., in the case of speech recognition this might correspond to using a different language's speech with an ASR system trained in a particular language. Here the acoustic characteristics of the speech signals from two different languages might be more similar as compared to the noisy and clean speech signals from the same language.\n\nIn section 4, the description of the auxiliary decoder setup might benefit from more detail.\n\nThere has been recent work on performance monitoring and accuracy prediction in the area of speech recognition, some of this work is listed below. \n1. Ogawa, Tetsuji, et al. \"Delta-M measure for accuracy prediction and its application to multi-stream based unsupervised adaptation.\" Proceedings of ICASSP. 2015.\n\n2. Hermansky, Hynek, et al. \"Towards machines that know when they do not know.\" Proceedings of ICASSP, 2015.\n\n3. Variani, Ehsan et al. \"Multi-stream recognition of noisy speech with performance monitoring.\" INTERSPEECH. 2013.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512620698, "id": "ICLR.cc/2017/conference/-/paper331/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper331/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper331/AnonReviewer2", "ICLR.cc/2017/conference/paper331/AnonReviewer3", "ICLR.cc/2017/conference/paper331/AnonReviewer1"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512620698}}}, {"tddate": null, "tmdate": 1482184429634, "tcdate": 1482184429634, "number": 3, "id": "BkIlDCr4g", "invitation": "ICLR.cc/2017/conference/-/paper331/official/review", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/conference/paper331/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper331/AnonReviewer1"], "content": {"title": "Important topic", "rating": "6: Marginally above acceptance threshold", "review": "The paper address the problem of detecting if an example is misclassified or out-of-distribution. This is an very important topic and the study provides a good baseline. Although it misses strong novel methods for the task, the study contributes to the community.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512620698, "id": "ICLR.cc/2017/conference/-/paper331/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper331/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper331/AnonReviewer2", "ICLR.cc/2017/conference/paper331/AnonReviewer3", "ICLR.cc/2017/conference/paper331/AnonReviewer1"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512620698}}}, {"tddate": null, "tmdate": 1481927324613, "tcdate": 1481927324613, "number": 1, "id": "ByBs9JfEx", "invitation": "ICLR.cc/2017/conference/-/paper331/official/review", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/conference/paper331/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper331/AnonReviewer2"], "content": {"title": "Paper provides a simple baseline for out-of-domain/misclassification detection. Statistics on maximum softmax probabilities for in/out domain examples appear to be sufficient to classify examples as out-of-domain.", "rating": "6: Marginally above acceptance threshold", "review": "The authors present results on a number of different tasks where the goal is to determine whether a given test example is out-of-domain or likely to be mis-classified. This is accomplished by examining statistics for the softmax probability for the most likely class; although the score by itself is not a particularly good measure of confidence, the statistics for out-of-domain examples are different enough from in-domain examples to allow these to be identified with some certainty. \n\nMy comments appear below:\n1. As the authors point out, the AUROC/AUPR criterion is threshold independent. As a result, it is not obvious whether the thresholds that would correspond to a certain operating point (say a true positive rate of 10%) would be similar across different data sets. In other words, it would be interesting to know how sensitive the thresholds are to different test sets (or different splits of the test set). This is important if we want to use the thresholds determined on a given held-out set during evaluation on unseen data (where we would need to select a threshold).\n\n2. Performance is reported in terms of AUROC/AUPR and models are compared against a random baseline. I think it\u2019s a little hard to look at the differences in AUC/AUPR to get a sense for how much better the proposed classifier is than the random baseline. It would be useful, for example, if the authors could also report how strongly statistically significant some of these differences are (although admittedly they look to be pretty large in most cases).\n\n3. In the experiments on speech recognition presented in Section 3.3, I was not entirely clear on how the model was evaluated. In Table 9, for example, is an \u201cexample\u201d the entire utterance or just a single (stacked?) speech frame. Assuming that each \u201cexample\u201d is an utterance, are the softmax probabilities the probability of the entire phone sequence (obtained by multiplying the local probability estimates from a Viterbi decoding?)\n\n4. I\u2019m curious about the decision to ignore the blank symbol\u2019s logit in Section 3.3. Why is this required?\n\n5. As I mentioned in the pre-review question, at least in the speech recognition case, it would have been interesting to compare performance obtained using a simple generative baseline (e.g., GMM-HMM). I think that would serve as a good indication of the ability of the proposed model to detect out-of-domain examples over the baseline.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512620698, "id": "ICLR.cc/2017/conference/-/paper331/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper331/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper331/AnonReviewer2", "ICLR.cc/2017/conference/paper331/AnonReviewer3", "ICLR.cc/2017/conference/paper331/AnonReviewer1"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512620698}}}, {"tddate": null, "tmdate": 1481600236641, "tcdate": 1481600236636, "number": 2, "id": "HkHeTkpQx", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "ry4ufPuQx", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "RE: Network structure", "comment": "Thank you for the question. We found that higher-accuracy structures improved AUROCs and AUPRs. For example, we switched from a 40-2 WideResNet to a 40-4 WideResNet for CIFAR-100 and the testing error went from 25.1% to 20.7%. At the same time, the CIFAR-100/SUN AUROC went from 80 to 91, and the CIFAR-100/Gaussian AUROC went from 84 to 88. However, for most experiments we simply used standard architecture settings and default optimizer hyperparameters.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1481600187454, "tcdate": 1481600187447, "number": 1, "id": "SJ7phypXl", "invitation": "ICLR.cc/2017/conference/-/paper331/public/comment", "forum": "Hkg4TI9xl", "replyto": "B1QLVPJXe", "signatures": ["~Dan_Hendrycks1"], "readers": ["everyone"], "writers": ["~Dan_Hendrycks1"], "content": {"title": "RE: Generative Baseline", "comment": "Thank you for the question. Using generative models as a baseline is a great idea, but we never pursued this avenue since we wanted a baseline simple to compute from prominent model designs from several fields. The intractability of estimating the normalizing sum for the probabilities [1] restricts the usable deep generative models to approaches like Deep Boltzmann Machines for some vision and NLP tasks. ASR seems exceptional because generative models like HMM-GMMs perform competitively, and our impression is that generative solutions are overall not as prominent in other fields due to less accuracy, simplicity, or fragility [2]. Consequently, we sought a baseline which works for discriminative classifiers and can be easily computed even as architectures evolve.\n\nHowever, if a company uses a deep system, they could still use the probabilities from a DBM or a HMM-GMM as auxiliary information for error detection, and that seems like an interesting avenue.\n\n\n[1] This paper describes the issue and tries to partially alleviate the problem: Taesup Kim, Yoshua Bengio. Deep Directed Generative Models with Energy-Based Probability Estimation. https://arxiv.org/pdf/1606.03439.pdf\n[2] Risks of Semi-Supervised Learning: How Unlabeled Data Can Degrade Performance of Generative Classifiers http://sites.poli.usp.br/p/fabio.cozman/Publications/Chapter/cozman-cohen-ssl2006.pdf\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287617491, "id": "ICLR.cc/2017/conference/-/paper331/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hkg4TI9xl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper331/reviewers", "ICLR.cc/2017/conference/paper331/areachairs"], "cdate": 1485287617491}}}, {"tddate": null, "tmdate": 1481302636213, "tcdate": 1481302636206, "number": 2, "id": "ry4ufPuQx", "invitation": "ICLR.cc/2017/conference/-/paper331/pre-review/question", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/conference/paper331/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper331/AnonReviewer1"], "content": {"title": "Network structure", "question": "Did you try different network structures / settings? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481302636730, "id": "ICLR.cc/2017/conference/-/paper331/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper331/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper331/AnonReviewer2", "ICLR.cc/2017/conference/paper331/AnonReviewer1"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481302636730}}}, {"tddate": null, "tmdate": 1480713291205, "tcdate": 1480713291199, "number": 1, "id": "B1QLVPJXe", "invitation": "ICLR.cc/2017/conference/-/paper331/pre-review/question", "forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "signatures": ["ICLR.cc/2017/conference/paper331/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper331/AnonReviewer2"], "content": {"title": "Generative Baseline", "question": "It would be interesting to also include a generative baseline for out-of-domain classification. For example, on the TIMIT dataset, one could train a generative GMM-HMM system where phone durations are modeled using a Hidden-Markov-Model and output probabilities are modeled using Gaussian Mixture Models. One could then estimate a in/out domain classification score by computing the data-likelihood on test examples. Have the authors also considered other/similar generative model baselines in addition to using the softmax probabilities directly? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks", "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.", "pdf": "https://arxiv.org/pdf/1610.02136.pdf", "TL;DR": "Methods to Detect When a Network Is Wrong", "keywords": ["Computer vision"], "authors": ["Dan Hendrycks", "Kevin Gimpel"], "conflicts": ["uchicago.edu", "ttic.edu"], "authorids": ["dan@ttic.edu", "kgimpel@ttic.edu"], "paperhash": "hendrycks|a_baseline_for_detecting_misclassified_and_outofdistribution_examples_in_neural_networks"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481302636730, "id": "ICLR.cc/2017/conference/-/paper331/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper331/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper331/AnonReviewer2", "ICLR.cc/2017/conference/paper331/AnonReviewer1"], "reply": {"forum": "Hkg4TI9xl", "replyto": "Hkg4TI9xl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper331/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481302636730}}}], "count": 13}