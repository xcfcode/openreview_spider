{"notes": [{"id": "Mos9F9kDwkz", "original": "T7qtwzBBzUZ", "number": 3496, "cdate": 1601308387841, "ddate": null, "tcdate": 1601308387841, "tmdate": 1616056403125, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "SwsuiWChqrL", "original": null, "number": 2, "cdate": 1615928349210, "ddate": null, "tcdate": 1615928349210, "tmdate": 1615967690816, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "z_NUaD0stnp", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Comment", "content": {"title": "Re: Questions about the optimization methods", "comment": "Hi Jiaxin!\n\n> Generally, the paper said only the atomic queries are used to train the model. What are atomic queries? Are they 1-projection queries? If the model is only trained on 1-projection queries, it is basically training a link predictor. Then why you describe two optimization methods for complex queries? This is really confusing. Or actually, the model was trained on multiple complex query types?\n\nYes, we train a neural link predictor to be able to answer atomic queries! The problem is that you still need to find the optimal variable assignments for each query -- depending on how you cast it, you can see either as a combinatorial optimisation problem (if you search for the optimal variable-to-entity mapping) or a continuous optimisation problem (in case you search for the optimal variable-to-entity embedding mapping), hence the two optimisation methods.\n\n> What is your inference method for your model?\n\nThe two optimisation methods are used for inference!\n\n> Why not just use a pre-trained link predictor?\n\nWe do that! :) We had to experiment with several configurations to find the optimal hyperparameters. Then we used the best models we trained for answering complex queries (we uploaded all models online, the link is available on the GitHub repo).\n\n> Will you release the code for the experiments?\n\nYes, it's online! The link should be visible in the abstract."}, "signatures": ["~Pasquale_Minervini2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Pasquale_Minervini2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Mos9F9kDwkz", "readers": {"values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs"}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}}, "multiReply": true, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["everyone"], "tcdate": 1610649450816, "tmdate": 1610649450816, "id": "ICLR.cc/2021/Conference/Paper3496/-/Comment"}}}, {"id": "z_NUaD0stnp", "original": null, "number": 1, "cdate": 1615392005246, "ddate": null, "tcdate": 1615392005246, "tmdate": 1615392005246, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Comment", "content": {"title": "Questions about the optimization methods", "comment": "I am a researcher that is interested in the area of complex query answering. However, the descriptions of the experiments are so vague that it is hard to reproduce the experiment according to the paper only. So I have to ask some questions here about the experimental settings and evaluation details. \n\n\n1. Generally, the paper said only the atomic queries are used to train the model. What are atomic queries? Are they 1-projection queries? If the model is only trained on 1-projection queries, it is basically training a link predictor. Then why you describe two optimization methods for complex queries? This is really confusing. Or actually, the model was trained on multiple complex query types?\n\n2. What is your inference method for your model? It seems that your model can be optimized in two ways as mentioned in the paper. But during the inference time, only the beam search method can be used to do inference. My question is whether both CQD-CO and CQD-Beam models are evaluated by the Beam search method.\n\n3. Why not just use a pre-trained link predictor? It seems that a pre-trained link predictor can be also used to do inference by using beam search. Also, I think this might be the most appropriate baseline to evaluate the effectiveness of both optimization methods. \n\nAlthough I am really confused by some descriptions in the paper, I really think this is a great paper. Because it points out an important new direction of solving complex query answering.  \n\n\nWill you release the code for the experiments?"}, "signatures": ["~Jiaxin_Bai1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Jiaxin_Bai1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Mos9F9kDwkz", "readers": {"values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs"}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}}, "multiReply": true, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["everyone"], "tcdate": 1610649450816, "tmdate": 1610649450816, "id": "ICLR.cc/2021/Conference/Paper3496/-/Comment"}}}, {"id": "9D0ueVgdUEH", "original": null, "number": 1, "cdate": 1610040406511, "ddate": null, "tcdate": 1610040406511, "tmdate": 1610474003210, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Oral)", "comment": "The reviewers unanimously agree that this paper is a strong accept; it makes important progress in developing our ability to query relational embedding  models."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040406497, "tmdate": 1610474003194, "id": "ICLR.cc/2021/Conference/Paper3496/-/Decision"}}}, {"id": "w_unFNZGW2i", "original": null, "number": 1, "cdate": 1603558350138, "ddate": null, "tcdate": 1603558350138, "tmdate": 1606754999290, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review", "content": {"title": "nice improvement of the SOTA", "review": "The paper proposes Continuous Query Decomposition (CQD), an approach for answering Existential Positive First-Order (EPFO)\nqueries over incomplete knowledge graphs exploiting a neural link predictor for 1-hop-only queries.\nEntities are embedded in a low dimensional space and entity vectors are used to compute the score of query atoms that\nare then combined using a t-norm for conjunction and t-conorm for disjunction.\nAnswers to queries are found either with continuous optimisation by gradient descent to find embeddings for query variables\nor combinatorial optimisation where top-k entities for query variables are looked for yielding a beam search.\nCQD is compared with Graph Query Embedding (GQE) and Query2Box over three datasets on a large number of queries.\nThe result show that CQD outperforms the baselines on Hit@3 on average.\nCQD also offers the possibility of explaining the results of queries by showing the top scoring entities for query variables and the score of atoms.\n\nCQD tackles the difficult problem of answering queries that are beyond simple 1-hop completion queries. It improves\nover previous work which need to train the model over a large number of queries (Hamilton et al., 2018;Daza & Cochez, 2020;\nRen et al., 2020) and do not consider disjunctive queries (Hamilton et al., 2018; Daza & Cochez, 2020).\nThese advantages are obtained by not embedding the query into a low dimensional space but using continuous or combinatorial\noptimization to answer queries, considering the query as a formula in fuzzy logic and applying t-norms and t-conorms.\nWhile the use of fuzzy logic in query answering is not new, they way in which it is combined with entity embeddings and\nneural link predictors is original to the best of my knowledge.\n\nThe fact that queries are not embedded (and so learning does not need large numbers of queries) is a strong point of CQD,\nwith competing methods (Hamilton et al., 2018;Daza & Cochez, 2020; Ren et al., 2020) requiring many queries for tuning the query embeddings.\nSince queries are not embedded, the results of CQD are also easier to explain. \n\nThe experiments are sufficiently extensive to support the claim of the paper that CQD is also outperforming competitors in \nterms of the quality of solutions. However, the authors should justify why they used embedding size 500 for their methods\nand 400 for the baselines.\n\nFrom a technical point of view the article seems sound but the authors say that \"Then, after we identified the optimal \nrepresentation for variables $A, V_1, \\ldots  V_m$, we replace the query target embedding $e_A$ with the embedding \nrepresentations $e_c \\in R^k$ of all entities $c \\in E$, and use the resulting complex query score to compute the \nlikelihood that such entities answer the query.\"\nIn this way the authors throw away vector $e_A$ that may have information about the problems, isn't there a method to\nexploit the information in $e_A$?\n\nI have a few remarks about the presentation:\nCitation Raedt, 2008 should be De Raedt, 2008.\nIn Figure 1 the edges of the graphs have the opposite direction with respect to the caption and main text.\nPage 6: \"we only make use of type 1-chain queries to train the neural link\npredictor\": do the authors mean 1-hop queries? 1-chain appears here for the first time.\n\"In all cases, we use a rank of 500.\": for rank do the authors mean the embedding size? This should be clarified\nPage 7: \"Since\na query can have multiple answers, we implement a filtered setting, whereby for a given answer, we\nfilter out other correct answers from the ranking before computing H@3.\": this sentence is not clear. Does it mean\nthat answers that follow from the KG without completion are removed from the ranking?\n\n----After reading the other reviews and the authors' comments, I still think the paper is excellent and should be accepted.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074818, "tmdate": 1606915774420, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3496/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review"}}}, {"id": "ByZB__4hwC", "original": null, "number": 7, "cdate": 1606224955210, "ddate": null, "tcdate": 1606224955210, "tmdate": 1606226355950, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "BSnnFjCdUL-", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "Response to Reviewer 2 (2)", "comment": "- The proposed two optimization methods are independent of neural link predictors. Can you use the same neural link predictor for your models and GQE for fair comparison?\n\nWe just updated our submission with additional experiments on adopting DistMult rather than ComplEx as the underlying neural link prediction model - results are available in the appendix (Sect. C). We find that results with DistMult are slightly less accurate than with Complex, as we expected, while still more accurate than the GQE and Q2B baselines.\n \nA bilinear interaction model similar to DistMult was also considered as a projection operator by GQE, with significantly less accurate results. We believe that our improvements in terms of accuracy can be attributed not just to the use of a competitive neural link predictor, but also to the compositional nature of our model, which allows it to generalise from atomic to complex queries thanks to the use of t-norms and t-conorms."}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "F9dOacxrtgx", "original": null, "number": 6, "cdate": 1605537449614, "ddate": null, "tcdate": 1605537449614, "tmdate": 1605537449614, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Cr9qg30TVsq", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "thanks for the clarifications", "comment": "Your comment cleared my doubts"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "CGldkk2zr0f", "original": null, "number": 2, "cdate": 1603831587298, "ddate": null, "tcdate": 1603831587298, "tmdate": 1605224800203, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review", "content": {"title": "Surprisingly simple idea that seems to work", "review": "The paper attempt to answer conjunctive queries that are in the form of a chain of facts bound together with unobserved variables. The authors suggest that you can use any relational learning method to embed entities and relations in a k-dimensional space and then use the t-norm in order to create a loss function that will be used in order to find the result of the query.  The paper investigates continuous optimization through stochastic gradient descent and a greedy method for combinatorial optimization. The results demonstrate that the greedy optimization method performs better. In addition, they claim that their method outperforms other methods with the advantage of using less training data.\n\nHere are some comments \n* I think the authors cover the relevant work sufficiently \n* The idea is very simple and builds upon other work that is well studied and well understood by the community\n* I think that there is an excessive mathematical formalism that is a bit unnecessary. There is no reason for that, the fact that the idea is very simple does not mean that we have to add extra formalism.\n* In terms of generalization, I think it is very interesting that the users train only on 1-hop  queries and evaluate up to 5-hop. In the introduction, the authors claim they use less data than the other methods, but they don\u2019t make it very clear in the experimental section. I think they need to be more explicit about that. They need to clarify that less data means just the 1-hop queries\n* I have two reservations about the paper. I suspect that part of the success of their approach is the ComplEx embeddings. I would appreciate an ablation study with at least one more method for relational learning, let\u2019s say TransE to see how sensitive it is on the embeddings. To be fair the authors study in depth the performance of their algorithm in other variations, such as the length of the chain\n* The other concern is about timing results. It would help to know how the whole algorithm compares in terms of time to answer the query compared to the others. I think it is of particular interest the difference between the two optimization techniques. I suspect that the greedy one might be two slow for longer chains. From the preliminary analysis, it seems to grow as k^d where k is the width of the beam per relation and d is the length of the chain.\n\nIn general, I think it is a very practical paper\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074818, "tmdate": 1606915774420, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3496/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review"}}}, {"id": "Cr9qg30TVsq", "original": null, "number": 5, "cdate": 1605200964144, "ddate": null, "tcdate": 1605200964144, "tmdate": 1605200964144, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "w_unFNZGW2i", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "Thank you for your valuable comments and feedback. Please find our response to your questions next. We did incorporate your remarks about the presentation in the updated version.\n\n- 1-chain appears here for the first time. \"In all cases, we use a rank of 500.\": for rank do the authors mean the embedding size?\n\nYes! We do refer to the embedding size as the rank - we clarified this in the updated version.\n\nWe searched for the optimal embedding size by tuning it on a held-out validation set - we now provide a detailed description of the hyperparameter search process, as well as results with different embedding sizes (see Appendix, Sec. A).\nOverall, we note that even with a lower rank of 100, our method still produces more accurate ranking results than baselines with larger embedding sizes (GQE and Q2B).\n\n- From a technical point of view the article seems sound but the authors say that \"Then, after we identified the optimal representation for variables A,V_1,\u2026V_m, we replace the query target embedding e_A with the embedding representations e_c\u2208Rk of all entities c\u2208E, and use the resulting complex query score to compute the likelihood that such entities answer the query.\" [..] isn't there a method to exploit the information in eA?\n\nIndeed, we discard the embedding of the target variable, because ultimately our aim is to score actual entities in the KG. \nIn a previous iteration of the project, we were ranking entities according to their distance from the vector e_A. However, we quickly realised this makes strong assumptions on the geometry of the embedding space induced by the neural link predictor, and also produced less accurate results.\n\n- Page 7: \"Since a query can have multiple answers, we implement a filtered setting, whereby for a given answer, we filter out other correct answers from the ranking before computing H@3.\": this sentence is not clear. Does it mean that answers that follow from the KG without completion are removed from the ranking?\n\nWe use the same evaluation protocol as GQE and Q2B: when ranking the candidate answers for a query and the gold answer is x, we remove the other entities that correctly answer the query and are different from x. This setting is used for not penalising the model for ranking other correct answers higher than x, since all these answers are valid.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "te9aaMuCX8T", "original": null, "number": 4, "cdate": 1605199268723, "ddate": null, "tcdate": 1605199268723, "tmdate": 1605199586762, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "KimDoIp84Rp", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thank you for your valuable feedback and comments! We next address your comments.\n\n- What is particularly important/challenging about EPFO queries, beyond existential and conjunctive ones?\n\nWe consider a query as determined by a series of arbitrary constraints expressed in some language: a more expressive language makes it possible to answer a broader set of queries. \n\nThe simplest case is link prediction, where the constraint is a single predicate, whereas recent methods have started considering existentially quantified variables and conjunctions of predicates [1] and disjunctions [2], which together with conjunctions form EPFO queries). Considering EPFO queries is thus a step towards answering increasingly more expressive queries.\n\n- Could you talk more, give more insights about the 8 complex queries types? Why are they important?\n\nThe 8 query structures that we experiment with allow us to compare with other works in the complex query answering literature that use such queries for evaluation - see e.g. [1, 2].\n\n- The query \u201cWhat international organisations contain the country of nationality of Thomas Aquinas?\u201d sounds really artificial. Maybe there is a better example involving entities and relations, similar to the drugs one?\n\nThat\u2019s right - thank you for pointing this out: we added a more realistic example in the updated version of the paper.\n\n- Could you say a bit more with respect to how the KG incompleteness is accounted for in the evaluation?\n\nThe queries we evaluated on are standard datasets proposed and used by e.g. [1, 2]: some edges are removed at random from the KG, and the queries are generated in such a way that one needs the missing edges in order to answer them. Then, a neural model is trained to answer the queries while accounting for the missing edges.\n\n[1] Hamilton et al. 2018, \u201cEmbedding Logical Queries on Knowledge Graphs\u201d, NeurIPS 2018.\n\n[2] Ren et al. 2020, \u201cQuery2box: Reasoning over Knowledge Graphs in Vector Space using Box Embeddings\u201d, ICLR 2020.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "mSaYMOeIjKi", "original": null, "number": 3, "cdate": 1605198353931, "ddate": null, "tcdate": 1605198353931, "tmdate": 1605198353931, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "CGldkk2zr0f", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for your questions and valuable feedback.\n\n- I think that there is an excessive mathematical formalism that is a bit unnecessary. There is no reason for that, the fact that the idea is very simple does not mean that we have to add extra formalism.\n\nIndeed, we agree with you: we tried our best to explain our method as simple as possible (by providing plenty of examples and visual intuitions), while still using the same terminology as related work in this area (to unambiguously specify what kind of queries our method can answer), and without loss in generality.\nWe also think that the notation allows us to conveniently re-state the problem as an optimisation problem where scores are computed using t-norms and t-conorms.\nWhich parts do you think that can be improved in terms of clarity?\n\n- In the introduction, the authors claim they use less data than the other methods, but they don\u2019t make it very clear in the experimental section. I think they need to be more explicit about that. They need to clarify that less data means just the 1-hop queries.\n\nThank you for pointing this out, we agree that we could have been more explicit about the fact that our method only requires 1-hop queries for training: we have added details about this and actual numbers to contrast with the amount of data required by other methods.\n\n- I have two reservations about the paper. I suspect that part of the success of their approach is the ComplEx embeddings.\n\nWe agree that ComplEx is a significant contributor to the statistical accuracy in our model, which we chose since it is a fairly simple but still extremely competitive neural link predictor [1]. As an additional analysis, in the updated version of the paper (Tab. 3) we report results with ComplEx with different rank values (embedding sizes), showing we can significantly reduce the embedding size in the underlying neural link predictor without losing too much in ranking accuracy. Furthermore, we are now in the process of running additional experiments with DistMult, another neural link prediction model, which should be ready in the next two days.\n\n[1] \u201cYou CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings\u201c - ICLR 2019, https://openreview.net/forum?id=BkxSmlBFvr\n\n- The other concern is about timing results. It would help to know how the whole algorithm compares in terms of time to answer the query compared to the others. I think it is of particular interest the difference between the two optimization techniques. I suspect that the greedy one might be two slow for longer chains. From the preliminary analysis, it seems to grow as $k^d$ where k is the width of the beam per relation and d is the length of the chain.\n\nThank you for pointing this out as well - we just included accurate timing results in the updated version of the paper (Appendix, Sect. B). We found that the time required for the combinatorial optimisation is on par or higher than Q2B, but always below 50ms per query.\nIndeed the greedy algorithm tends to be slower on longer chains: the neural link predictor is invoked once for each of the hops in the chain, for obtaining a list of top-k candidates to use in the next step in the chain. In our experiments, identifying the top-k candidates for each step in a chain was not an issue, since all candidate entities can be scored in parallel very efficiently on GPU.\nA potential bottleneck in terms of space complexity can be the number of candidate variable assignments, which at the moment is given by $k^d$ (we did not experience any issues related to this, since in the datasets we considered $d$ is at most 3). A solution for handling longer chains may consist in trading complexity with completeness, and e.g. set an upper bound to the number of candidate variable assignments being considered.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "BSnnFjCdUL-", "original": null, "number": 2, "cdate": 1605198244174, "ddate": null, "tcdate": 1605198244174, "tmdate": 1605198244174, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Fm1mCn1WNX4", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for your questions and valuable feedback.\n\n- For the first method, continuous optimization in sec 3.1, what is the difference between this method and the previous works GQE, Q2B, etc. apart from different neural link predictors? \n\nGiven a complex query, GQE and Q2B produce an embedding representation of such a query and use it for ranking all candidate answers according to a matching score between the query and the answer embeddings. On the other hand, our model decomposes a complex query into simpler (atomic) queries, which are answered individually using a neural link predictor, and then intermediate scores are aggregated using t-norms and t-conorms -- continuous relaxations of the logical conjunction and disjunction operators.\n\nBy doing so, we are also able to produce explanations for why a given answer was selected in terms of the intermediate answers for the atomic queries -- we elaborate on this aspect in the updated version of this paper.\n\nYou mention that \u201cEspecially for path queries, e.g., given a two-hop query, (Obama,BornIn,V1) \u2227 (V1,CapitalOf,V2), then the optimal e_V1 will be eObama+eBornIn\u201d. We completely agree with this: if we select TransE as our underlying neural link predictor, indeed CQD-CO would be quite related to the model you just proposed.\n\nHowever, doing the same for other neural link predictors such as DistMult and ComplEx is not as simple, since the values of e_V1 and e_V2 identified by optimising the query score would not be meaningful (it\u2019s possible to maximise the query score by just increasing the norm of e_V1 and e_V2). Our aim is proposing a solution that is not model-dependent (i.e. that can be used with any neural link predictor); with interesting explainability properties; and does not require training on complex queries (we can aggregate intermediate results with t-norms and t-conorms, without learning additional parameters) while still achieving SOTA results.\n\n-  For the second method, the time complexity seems exponential with respect to the number of hops.\n\nIndeed, for a multi-hop query, the second method produces $k^m$ variable assignments -- this was not an issue in our experiments since in the complex query answering datasets considered by GQE and Q2B, the m in multi-hop queries is at most three. We argue that, for higher values of m, we can control the space complexity of the method by using a more space-efficient variant of the method, where the number of variable assignments is bounded to some constant.\n\nFurthermore, answering each hop for and identifying the top-k candidates can be done in constant time on GPU, since all candidate entities can be scored in parallel very efficiently (in ComplEx, the scoring function is a trilinear dot product, thus scoring all entities can be reduced to a matrix-vector multiplication).\nWe updated our paper including actual timing measurements in the appendix.\n\n- How did you calibrate the output of ComplEx so that $\\phi_{p}(e_{s}, e_{o}) is in [0,1]?\n\nWe use the sigmoid to map ComplEx scores to values in [0, 1].\n\n- Can you list the inference time of both models (continuous, combinatorial) and compare it with GQE/Query2box?\n\nWe included explicit timing results for combinatorial optimisation in the updated version of the paper - see Sect. B in the Appendix. For the continuous optimisation version, we found that it can take between 1 to 10 seconds to answer all the queries in FB15k, FB15k-237, and NELL, thanks to the fact that those operations can be efficiently parallelised on GPU.\n\n- For 1p performance, it is equivalent to the performance of ComplEx on link prediction right?\n\nYes, the performance of our method on 1p (atomic) queries is determined by the accuracy of the neural link predictor. However, upon further investigation, we noticed that Q2B uses a different evaluation procedure for atomic queries: we updated the results table, and we find that our method produces more accurate results on atomic queries as well.\n\n- The table 3 is confusing, why are the numbers (e.g., 5.5, 46.76) larger than 1, I think the model normalized the output of $\\phi$ to [0,1]?\n\nThank you for pointing this out -- we reported the logits rather than the normalised values. We solved the issue in the updated version of the paper, and added an additional example.\n\n- The proposed two optimization methods are independent of neural link predictors. Can you use the same neural link predictor for your models and GQE for fair comparison?\n\nWe chose ComplEx because it is a very simple yet extremely effective neural link predictor, but indeed it would be interesting to test our method with different models. To account for this, in the updated version of the paper we included experiments with different ranks for ComplEx - showing we can decrease the rank from 1000 to 100 without significantly decreasing the predictive accuracy of the model - and are now in the process of running additional experiments with DistMult (which is also considered in GQE).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Mos9F9kDwkz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3496/Authors|ICLR.cc/2021/Conference/Paper3496/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836958, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Comment"}}}, {"id": "Fm1mCn1WNX4", "original": null, "number": 3, "cdate": 1603949651508, "ddate": null, "tcdate": 1603949651508, "tmdate": 1605023990096, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review", "content": {"title": "A new method on reasoning on KG, nice empirical results", "review": "The paper aims to answer complex queries on knowledge graphs. Different from previous methods that aim to embed the queries, the method views the query answering problem as an optimization / search problem where the goal is to find the most plausible entities on the reasoning path. The merits are that the method only needs to train on 1 hop path queries (link prediction), saving the effort of training on complex queries as in previous work, and proposes two solutions, which both achieve nice results on standard multi-hop reasoning benchmarks. It also demonstrates interpretability of the model by showing some examples of the intermediate entities found in the reasoning path when answering a complex multi-hop query.\n\nI think the paper is clear and easy to follow. I have some questions regarding the two methods. For the first method, continuous optimization in sec 3.1, what is the difference between this method and the previous works GQE, Q2B, etc. apart from different neural link predictors? Especially for path queries, e.g., given a two hop query, $(\\text{Obama}, \\text{BornIn}, V_1)\\wedge(V_1, \\text{CapitalOf}, V_2)$, then the optimal $e_{V_1}$ will be $e_{Obama}+e_{BornIn}$, because the distance will be 0, and $\\phi_p$ will be 1 (here it assumes TransE model, and of course it can be generalized to DisMult, ComplEx, etc.). Then the first formulation is in essence very much similar to GQE, because GQE/Q2B also models $\\mathbf{e}_{V_1}$ in the exact same way and the difference only lies in (1) you use ComplEx (2) t-norm modeling of conjunction? However, it seems that t-norm demonstrates less expressiveness for modeling conjunction because both GQE/Q2B models conjunction using a MLP with additional learnable parameters, which can also approximate t-norm and even be more adaptive depending on the training queries/KG.\nFor the second method, the time complexity seems exponential with respect to the number of hops. For a m hop query, and each step you keep the top-k, then do you end up with $k^m$ entities?\n\nAdditional questions:\n1. How did you calibrate the output of ComplEx so that $\\phi_p(e_s, e_o)$ is in [0,1]? Better to add more details on neural link predictors. \n2. Some ablation studies that use different t-norm and t-conorm other than the Godel and product may make the argument stronger.\n3. There exists a tradeoff between the inference time and training queries. For GQE/Q2B, they can leverage complex queries to train the conjunction operator (MLP), so that during inference, there is no need to do any optimization. But for the proposed method, it saves the effort of training on complex queries, however, during inference, the method needs an online optimization process to instantiate the variables on the path. Especially for CQD-CO, the authors mention that they need to optimize online for 1000 iterations, which is too expensive for answering a query. Can you list the inference time of both models (continuous, combinatorial) and compare it with GQE/Query2box?\n4. For 1p performance, it is equivalent to the performance of ComplEx on link prediction right?\n5. The table 3 is confusing, why are the numbers (e.g., 5.5, 46.76) larger than 1, I think the model normalized the output of $\\phi$ to [0,1]?\n6. The proposed two optimization methods are independent of neural link predictors. Can you use the same neural link predictor for your models and GQE for fair comparison? You can train a TransE model for the neural link predictor, and accordingly define $\\phi_p$, then it will be clear to show whether the gain comes from a different neural link predictor (TransE vs ComplEx), or comes from the t-norm and the two optimization methods. And of course another choice is the other way around, e.g., use the ComplEx version of GQE and make the same comparison.\n\nMinor points to fix:\n1. In the method section, bold $\\mathbf{e}$ denotes vector embedding while normal $e$ denotes a logic formula, which is subtle and confusing. Authors can change the notation of one of them.\n2. Also, the notation $e_i^j$ is abused, in Eq. 2, it represents a logic formula, however, in Eq. 3, it represents the output of $\\phi_p$, which is a scalar.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074818, "tmdate": 1606915774420, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3496/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review"}}}, {"id": "KimDoIp84Rp", "original": null, "number": 4, "cdate": 1604003412392, "ddate": null, "tcdate": 1604003412392, "tmdate": 1605023990028, "tddate": null, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "invitation": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review", "content": {"title": "Complex logical query evaluation with link predictors", "review": "Summary: \nThis paper proposes Continuous Query Decomposition (CQD) a novel method for evaluating complex queries over incomplete KGs. Each variable of a logical query (involving existential quantifiers, conjunctions and disjunctions) is mapped to an embedding. A link predictor, trained on single edge prediction, is used to score the atomic query involving the variable. The full query is evaluated using continuous versions of the logical operators and gradient-based or combinatorial optimization.\nEvaluating complex logical queries on (necessarily incomplete) KGs and other graph-structured data is an important problem for data mining purposes. The paper proposes an elegant and effective method. \n\nStrong points\nElegant, efficient solution.\nSOTA results.\nProvides aspects of explainability, although this could be discussed and illustrated better.\n\nDetailed comments\n- What is particularly important/challenging about EPFO queries, beyond existential and conjunctive ones? Obviously it is an extension that covers more FOL, but a qualitative discussion would help the reader, particularly with respect to applications to KGs.\n- Could you talk more, give more insights about the 8 complex queries types? Why are they important?\n- The query \u201cWhat international organisations contain the country of nationality of Thomas Aquinas?\u201d sounds really artificial. Maybe there is a better example involving entities and relations, similar to the drugs one?\n- Could you say a bit more with respect to how the KG incompleteness is accounted for in the evaluation?\n- The paper mentions \u201c.. in many complex domains, an open challenge is developing techniques for answering complex queries involving multiple and potentially unobserved edges, entities, and variables, rather than just single edges.\u201d It would be great to articulate this more for sake of providing context and motivation.\n\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper3496/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3496/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Complex Query Answering with Neural Link Predictors", "authorids": ["erik.arakelyan.18@alumni.ucl.ac.uk", "dfdazac@gmail.com", "~Pasquale_Minervini1", "~Michael_Cochez2"], "authors": ["Erik Arakelyan", "Daniel Daza", "Pasquale Minervini", "Michael Cochez"], "keywords": ["neural link prediction", "complex query answering"], "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and existential quantifiers ($\\exists$), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods --- black-box neural models trained on millions of generated queries --- without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online, at https://github.com/uclnlp/cqd.", "one-sentence_summary": "We show how to answer complex queries by answering their sub-queries via neural link predictors, aggregating results via t-norms and t-conorms, and identifying the optimal variable substitutions by solving an optimisation problem.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "arakelyan|complex_query_answering_with_neural_link_predictors", "pdf": "/pdf/f3977c5e4b8a00127c9aed2b62ae904f29f06744.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\narakelyan2021complex,\ntitle={Complex Query Answering with Neural Link Predictors},\nauthor={Erik Arakelyan and Daniel Daza and Pasquale Minervini and Michael Cochez},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Mos9F9kDwkz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Mos9F9kDwkz", "replyto": "Mos9F9kDwkz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3496/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074818, "tmdate": 1606915774420, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3496/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3496/-/Official_Review"}}}], "count": 14}