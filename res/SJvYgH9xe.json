{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488521653306, "tcdate": 1478279295268, "number": 235, "id": "SJvYgH9xe", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "SJvYgH9xe", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "content": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1486926576635, "tcdate": 1486926576635, "number": 8, "id": "rkFl74Rdl", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "HJOasQ0dx", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Not a typo", "comment": "Thanks for the comment, and taking the time for a close read. I took a look and that equation is actually correct - our decomposition is of the numerator of p_i, which is the LHS. We described this in the first sentence of section 3.2. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1486924735885, "tcdate": 1486924735885, "number": 7, "id": "HJOasQ0dx", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "A typo in the published version?", "comment": "The equation between (8) - (9) seems to be incorrect, as the left hand side of which should be p_i."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396450222, "tcdate": 1486396450222, "number": 1, "id": "BJ9QhGIdx", "invitation": "ICLR.cc/2017/conference/-/paper235/acceptance", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "Timely topic (interpretability of neural models for NLP), interesting approach, surprising results.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396450738, "id": "ICLR.cc/2017/conference/-/paper235/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396450738}}}, {"tddate": null, "tmdate": 1485240001654, "tcdate": 1482190196881, "number": 3, "id": "Sy6u6yLNx", "invitation": "ICLR.cc/2017/conference/-/paper235/official/review", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer3"], "content": {"title": "review", "rating": "7: Good paper, accept", "review": "EDIT: the revisions made to this paper are very thorough and address many of my concerns, and the paper is also easier to understand. i recommend the latest version of this paper for acceptance and have increased my score.\n\nThis paper presents a way of interpreting LSTM models, which are notable for their opaqueness. In particular, the authors propose decomposing the LSTM's predictions for a QA task into importance scores for words, which are then used to generate patterns that are used to find answers with a simple matching algorithm. On the WikiMovies dataset, the extracted pattern matching method achieves accuracies competitive with a normal LSTM, which shows the power of the proposed approach. \n\nI really like the motivation of the paper, as interpreting LSTMs is definitely still a work-in-progress, and the high performance of the pattern matching was surprising. However, several details of the pattern extraction process are not very clear, and  the evaluation is conducted on a very specific task, where predictions are made at every word. As such, I recommend the paper in its current form as a weak accept but hope that the authors clarify their approach, as I believe the proposed method is potentially useful for NLP researchers.\n\nComments:\n- Please introduce in more detail the specific QA tasks you are applying your models on before section 3.3, as it's not clear at that point that the answer is an entity within the document.\n- 3.3: is the softmax predicting a 0/1 value (e.g., is this word the answer or not?)\n- 3.3: what are the P and Q vectors? do you just mean that you are transforming the hidden state into a 2-dimensional vector for binary prediction?\n- how does performance of the pattern matching change with different cutoff constant values?\n- 5.2: are there questions whose answers are not entities? \n- how could the proposed approach be used when predictions aren't made at every word? is there any extension for, say, sentence-level sentiment classification?\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512654447, "id": "ICLR.cc/2017/conference/-/paper235/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper235/AnonReviewer2", "ICLR.cc/2017/conference/paper235/AnonReviewer1", "ICLR.cc/2017/conference/paper235/AnonReviewer3"], "reply": {"forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512654447}}}, {"tddate": null, "tmdate": 1485217058828, "tcdate": 1485217058828, "number": 6, "id": "rksQ6zEvg", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "H1MBlrxPg", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Response", "comment": "Thanks for your reply. We'd like to emphasize that our goal in this paper was not to achieve high predictive performance, but rather to introduce and validate a general approach for analysing the behaviour of a trained LSTM. Convincing researchers and practitioners that a particular visualization is sufficiently informative and trustworthy to actually use is not an easy or well-defined task, so we provided multiple qualitative and quantitative verifications through predictive performance, showing extracted phrases, and heat maps.\n\nTo this end, our pattern matching model is deliberately simple in order to provide better insight into the trained LSTM. Thus, we wouldn't expect it to outperform existing, performance-optimized algorithms. However, we do agree that naive Bayes is a pertinent baseline, so we have uploaded a revision including the result, and adding a paragraph reflecting this comment.\n\nYou seem to imply that the update was disappointing, inasmuch as our predictive performance was inferior to NB. In our update, we broadened the class of problems that can be analysed from a particular QA problem to general document classification, which is a substantial widening of the potential use cases of this work. Taking both the quantitative and qualitative evidence presented into account, we assert that this work, and the update in particular, makes a compelling case that our introduced visualizations and pattern extraction are worth using on a broad range of problems."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1484963898338, "tcdate": 1484963898338, "number": 3, "id": "H1MBlrxPg", "invitation": "ICLR.cc/2017/conference/-/paper235/official/comment", "forum": "SJvYgH9xe", "replyto": "Byj_wIDIx", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer1"], "content": {"title": "Thanks for performing the additional sentiment experiments", "comment": "Thanks for performing the additional experiments and deriving rules for classification. However, the sentiment rules discovered seem to be significantly worse than the LSTM and CNN. In the SST dataset, a unigram Naive Bayes model (82.6%) performs significantly better than the automatic rules based classifiers (77.4%) [1], so at least for this dataset it seems that using the unigrams would yield a more interpretable and better performing rules based model vs the LSTM cell decomposition.\n\nI will keep my previous rating, however I would like the authors to note this in the paper.\n\n[1] Socher et al. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672534, "id": "ICLR.cc/2017/conference/-/paper235/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672534}}}, {"tddate": null, "tmdate": 1484963302619, "tcdate": 1481969798398, "number": 2, "id": "BkAtgqfEl", "invitation": "ICLR.cc/2017/conference/-/paper235/official/review", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer1"], "content": {"title": "Nice idea to improve understanding of LSTM models", "rating": "7: Good paper, accept", "review": "This work proposes a pattern extraction method to both understand what a trained LSTM has learnt and to allow implementation of a hand-coded algorithm that performs similarly to the LSTM. Good results are shown on one dataset for one model architecture so it is unclear how well this approach will generalize, however, it seems it will be a useful way to understand and debug models.\n\nThe questions in WikiMovies seem to be generated from templates and so this pattern matching approach will likely work well. However, from the experiments it's not clear if this will extend to other types of Q&A tasks where the answer may be free form text and not be a substring in the document. Is the model required to produce a continuous span over the original document?\n\nThe approach also seems to have some deficiencies in how it handles word types such as numbers or entity names. This can be encoded in the embedding for the word but from the description of the algorithm, it seems that the approach requires an entity detector. Does this mean that the approach is unable to determine when it has reached an entity from the decomposition of the output of the LSTM? The results where 'manual pattern matching' where explicit year annotations are used, seem to show that the automatic method is unable to deal with word types.\n\nIt would also be good to see an attention model as a baseline in addition to the gradient-based baseline.\n\nMinor comments:\n- P and Q seem to be undefined.\n- Some references seem to be bad, e.g. in section 5.1: 'in 1' instead of 'in table 1'. Similarly above section 7: 'as shown in 3' and in section 7.1.\n- In the paragraph above section 6.3: 'adam' -> 'Adam'.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512654447, "id": "ICLR.cc/2017/conference/-/paper235/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper235/AnonReviewer2", "ICLR.cc/2017/conference/paper235/AnonReviewer1", "ICLR.cc/2017/conference/paper235/AnonReviewer3"], "reply": {"forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512654447}}}, {"tddate": null, "tmdate": 1484381474444, "tcdate": 1484381474444, "number": 5, "id": "Sk5m6LPIl", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "Byr5-Lx4x", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Response", "comment": "Thank you for your helpful question and review! I've replied to your points below, and hope that you enjoy our new findings.\n\nQ: It would have been interesting to try extend the approach on other natural language processing tasks, such as machine translation. Presumably the rules learned here will be quite different.\n\nA: In response to your question, we added results on sentiment analysis, and reformulated our framework into a general document classification setting. Although I agree machine translation would be interesting, it's complexity would necessitate more space than a conference paper affords. However, with our new results, we feel that we have covered a sufficiently broad class of problems. \n\n\nQ: - Eq. (12) is over-parametrized with two vectors $P$ and $Q$. The same function can be computed with a single vector. This becomes clear when you divide both the numerator and denominator by $e^{P h_t}$.\n\nA: A valid point. However, that over-parametrized form of the softmax is a reasonably standard layer used in most classification neural nets, so we feel we are justified in sticking to standard practices.\n\n\nQ: - Section 4.1. Is it correct that this section is focused on the forward LSTM? If so, please clarify it in the text.\nA: It was, but for simplicity we have now removed bidirectional LSTMs from the paper. \n\nQ: - In Eq. (13), define $c_0 = 0$.\nA: Good point, we added this in 3.1 in the revision\n\nQ: - Eq. (13) is exactly the same as Eq. (15). Is there a mistake?\nA: The indices are a little hard to keep track of, but the two equations are actually different, as reflected in the former equation (16), now equation (11). The indices have been simplified in the revision, and are hopefully more reader-friendly. \n\nQ: - In Table 1, third column should have word \"film\" highlighted.\n- \"are shown in 2\" -> \"are shown in Table 2\".\nA: Both good points. Table 1 no longer exists, but we have fixed the references.\n\nQ: - Since there are some problems representing numbers, it may help to replace each digit with the hashtag symbol #.\nA: This would have been a good point for our prior model, but our new approach seems to do a much better job at dealing with numbers, with an increased accuracy in the movie to year category of 84% from 64%. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1484380545820, "tcdate": 1484376921393, "number": 2, "id": "S1WwsrP8l", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Updated paper", "comment": "In response to helpful comments from reviewers, we have just uploaded a revision. The main changes are as follows\n\n- In response to requests for extensions to other datasets, we now have results on 2 different binary sentiment analysis datasets - Stanford Sentiment Treebank and Yelp reviews\n\n- We introduced a simpler, more general approach for extracting rules from LSTMs trained on document classification, and demonstrate that with some easy modifications it can replace our prior, more complex, rule extraction mechanism on WikiMovies.\n\n- Our rules now take the form of simple phrases, rather than allowing for variable-sized gaps between words as before\n\n- Our LSTM baseline on WikiMovies is now SOTA by nearly 4%, and the automatically extracted patterns outperform the manual patterns in the earlier version.\n\n- We added a discussion on instances correctly classified by the LSTM, but incorrectly classified by our rules-based algorithm\n\n- For simplicity, we changed our WikiMovies baseline to a unidirectional LSTM, and removed bidirectional LSTMs from the paper. Extension of our new approach to bidirectional LSTMs would be straightforward, but we feel would add unneeded complexity to the presentation\n\nAll told, we feel that these algorithms and results are simpler, more powerful and more general than our prior work, and we look forward to discussing them."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1484380019510, "tcdate": 1484380019510, "number": 4, "id": "Byj_wIDIx", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "BkAtgqfEl", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Response", "comment": "Thanks for the review! I've replied to your concerns below\n\nQ: Good results are shown on one dataset for one model architecture so it is unclear how well this approach will generalize\n\nA: An excellent point, which our other reviewers also pointed out. In our update, we give a general framework for document classification, and show additional results on a standard LSTM for 2 different sentiment analysis datasets. We feel these are more convincing as to the generality of our approach.\n\n\nQ: The questions in WikiMovies seem to be generated from templates and so this pattern matching approach will likely work well. However, from the experiments it's not clear if this will extend to other types of Q&A tasks where the answer may be free form text and not be a substring in the document. Is the model required to produce a continuous span over the original document?\n\nA: I agree that it would be an interesting direction for future work to extend this to QA datasets with free form questions and/or answers, such as the Stanford QA Dataset, but it probably lies outside the scope of this paper. However, the problem of answering non-freeform questions is still an open, actively studied problem in it's own right. In addition to WikiMovies from EMNLP 2016, another recent example of this is the WikiReading paper in ACL 2016. Combined with our new results on sentiment, we feel that our results cover a sufficiently broad scope of problems.\n\n\nQ: The approach also seems to have some deficiencies in how it handles word types such as numbers or entity names. This can be encoded in the embedding for the word but from the description of the algorithm, it seems that the approach requires an entity detector. Does this mean that the approach is unable to determine when it has reached an entity from the decomposition of the output of the LSTM? The results where 'manual pattern matching' where explicit year annotations are used, seem to show that the automatic method is unable to deal with word types.\n\nA: As we made clearer in our revision, WikiMovies provides a list of entities, allowing us to only check whether a subset of the words are answers. However, for many entities, our approach does demonstrate an ability to identify them as important phrases. Generally, in the movie to X questions, many instances of X (actors, directors, languages, etc) emerge as top patterns, along with the general entity character. For instance, in table 4, starring Ben Afleck emerges as a pattern for identifying actors, and many language names emerge when searching for languages. \nThe point regarding the explicit year annotations is valid, but seems to have been resolved by our updated approach, as reflected by the automatic movie to year scores at 84%, very close to the 87% accuracy that the manual pattern matching achieved, and a substantial boost from the 65% the prior automatic approach yielded.\n\n\nQ: It would also be good to see an attention model as a baseline in addition to the gradient-based baseline.\n\nA:The primary goal of this paper is to provide an approach for interpreting existing models, not devise new ones. For the problems we consider, attention is not generally used, and we don't feel it is reasonable to add additional complexity onto a model in order to make it more interpretable. \n\n\nQ: P and Q seem to be undefined.\nA: We have fixed this - P and Q have been replaced by W_1 and W_2, denoting the rows of the cell to output matrix\n\n\nQ: \n- Some references seem to be bad, e.g. in section 5.1: 'in 1' instead of 'in table 1'. Similarly above section 7: 'as shown in 3' and in section 7.1.\n- In the paragraph above section 6.3: 'adam' -> 'Adam'.\nA: Thank you for pointing these out, they have been fixed in the revision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1484377999146, "tcdate": 1484377999146, "number": 3, "id": "Skw9JIwIg", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "Sy6u6yLNx", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Response", "comment": "Thanks for the helpful comments! Many of your concerns were incorporated into our update, I'll address them below. \n\nQ:\nHowever, several details of the pattern extraction process are not very clear, and  the evaluation is conducted on a very specific task, where predictions are made at every word. \nhow could the proposed approach be used when predictions aren't made at every word? is there any extension for, say, sentence-level sentiment classification?\n\nA:\nIn response to your concerns, we included extensions for sentence-level, and multi-sentence (Yelp) sentiment classification, and phrased the pattern extraction in terms of general document classification, a very general task. Doing so required forced us to come up with a cleaner pattern extraction process, which we hope is better communicated in the new writeup. We'd welcome comments on the presentation. \n\nQ: \n- Please introduce in more detail the specific QA tasks you are applying your models on before section 3.3, as it's not clear at that point that the answer is an entity within the document.\n\nA:\nAlthough the sections got shuffled around in the update, we now introduce the dataset, followed by the LSTM-model, followed by the pattern extraction modifications, so that the flow of information should be clear. \n\nQ:\n- 3.3: what are the P and Q vectors? do you just mean that you are transforming the hidden state into a 2-dimensional vector for binary prediction?\nA:\nYes, that is exactly what we mean. To make this clearer, we denoted the transform matrix as W and replaced P and Q with W_1 and W_2.\n\nQ:\n- how does performance of the pattern matching change with different cutoff constant values?\nA:\nThis is a valid concern for our prior model, where the cutoff played a relatively critical role. Under the new framework, although we do still have a cutoff, it plays a different, lesser role, as it serves to limit the amount of computation required by our search process. If you think this is still relevant in our new model, I could to run some experiments to figure out, although I strongly suspect the changes would be minimal.\n\nQ:\n- 5.2: are there questions whose answers are not entities? \nA:\nNo, there are no such questions. Part of the WikiMovies dataset is a list of ~43k \"entities\" which contains all possible answers. This was not properly communicated in the original work - we have fixed this in the update."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1481822670673, "tcdate": 1481822670668, "number": 2, "id": "SkDAbIl4g", "invitation": "ICLR.cc/2017/conference/-/paper235/official/comment", "forum": "SJvYgH9xe", "replyto": "ByWMK-CQx", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "content": {"title": "Re: Our contribution is importance scores - pattern matching results serve as validation", "comment": "Thanks for clarifying this."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672534, "id": "ICLR.cc/2017/conference/-/paper235/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672534}}}, {"tddate": null, "tmdate": 1481822605255, "tcdate": 1481822605248, "number": 1, "id": "Byr5-Lx4x", "invitation": "ICLR.cc/2017/conference/-/paper235/official/review", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper proposes a novel method for extracting rule-based classifiers from trained LSTM models. The proposed method is applied to a factoid question-answering task, where it is demonstrated that the extracted rules perform comparatively to the original LSTM. The analysis of the extracted rules illustrate the features the LSTM model picks up on.\n\nAnalyzing and visualizing the computations carried out by RNNs in order to understand the functions they compute is an important direction of research. This sort of analysis will help us understand the pitfalls of RNNs, and how we can improve them. Although the approach taken is relatively inflexible - each rule is defined as an ordered sequence of words - the authors experiment with three different scores for picking salient words (state-difference, cell-difference and gradient) and their approach yields comparable performance, which suggests that the extracted rules mimic the RNN closely. The results are also somewhat surprising, since most of the rules consist only of two or three words.\n\nIt would have been interesting to try extend the approach on other natural language processing tasks, such as machine translation. Presumably the rules learned here will be quite different.\n\nOther comments:\n- Eq. (12) is over-parametrized with two vectors $P$ and $Q$. The same function can be computed with a single vector. This becomes clear when you divide both the numerator and denominator by $e^{P h_t}$.\n- Section 4.1. Is it correct that this section is focused on the forward LSTM? If so, please clarify it in the text.\n- In Eq. (13), define $c_0 = 0$.\n- Eq. (13) is exactly the same as Eq. (15). Is there a mistake?\n- In Table 1, third column should have word \"film\" highlighted.\n- \"are shown in 2\" -> \"are shown in Table 2\".\n- Since there are some problems representing numbers, it may help to replace each digit with the hashtag symbol #.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512654447, "id": "ICLR.cc/2017/conference/-/paper235/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper235/AnonReviewer2", "ICLR.cc/2017/conference/paper235/AnonReviewer1", "ICLR.cc/2017/conference/paper235/AnonReviewer3"], "reply": {"forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512654447}}}, {"tddate": null, "tmdate": 1481672968775, "tcdate": 1481672968769, "number": 1, "id": "ByWMK-CQx", "invitation": "ICLR.cc/2017/conference/-/paper235/public/comment", "forum": "SJvYgH9xe", "replyto": "HJF3k70fx", "signatures": ["~W._James_Murdoch1"], "readers": ["everyone"], "writers": ["~W._James_Murdoch1"], "content": {"title": "Our contribution is importance scores - pattern matching results serve as validation", "comment": "Thank you for the question, and apologies for the delayed response. Although our results on WikiMovies are interesting in their own right, their primary purpose was to provide empirical validation of the information contained in our proposed importance scores. \n\nGiven a trained LSTM, we currently have very limited means for explaining it's predictions. Empirically, we found that examining our importance scores provides sensible explanations, but we wanted to provide stronger verification of the information contained in these scores. We feel that the rule extraction fulfills this role.\n\nTo contrast with Chen et. al, they specified and trained a model completely independently of any other model, as is generally done in ML. In this work, we extracted the parameters of our pattern matching model solely from our importance scores, which are derived from a trained LSTM's parameters. Thus, the training data is only observed indirectly through the importance scores. We interpret the fact that we're able to achieve competitive accuracy by only looking at the importance scores, and not the training data, as a verification of our empirical observations that they are a highly informative metric. \n\nAs for more complex tasks, we are currently finalizing results on sentiment analysis, and will be adding them soon. Modifications to the algorithm are relatively minimal, and could be adapted to any text-based classification task."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287672662, "id": "ICLR.cc/2017/conference/-/paper235/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJvYgH9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper235/reviewers", "ICLR.cc/2017/conference/paper235/areachairs"], "cdate": 1485287672662}}}, {"tddate": null, "tmdate": 1480630193053, "tcdate": 1480630193049, "number": 1, "id": "HJF3k70fx", "invitation": "ICLR.cc/2017/conference/-/paper235/pre-review/question", "forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "signatures": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "content": {"title": "More Complex Tasks", "question": "It's known that many types of QA problems can be solved by matching simple patterns. See, for example, \"A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task\" by Chen et al. At a first glance, WikiMovies seems to be in the same category as these in terms of complexity.\n\nDo you think you can apply or extend your rule extraction approach to more complex tasks? If so, which tasks and what kinds of extensions would your method require?\n\nApologies in advance if you already discussed this or if I misunderstood something."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatic Rule Extraction from Long Short Term Memory Networks", "abstract": "Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear.   As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns.  In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.", "pdf": "/pdf/1b6c5951af988d823360f9fc2cd91120a011302f.pdf", "TL;DR": "We introduce a word importance score for LSTMs, and show that we can use it to replicate an LSTM's performance using a simple, rules-based classifier.", "paperhash": "murdoch|automatic_rule_extraction_from_long_short_term_memory_networks", "conflicts": ["fb.com", "berkeley.edu"], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authors": ["W. James Murdoch", "Arthur Szlam"], "authorids": ["jmurdoch@berkeley.edu", "aszlam@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959390529, "id": "ICLR.cc/2017/conference/-/paper235/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper235/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper235/AnonReviewer2"], "reply": {"forum": "SJvYgH9xe", "replyto": "SJvYgH9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959390529}}}], "count": 16}