{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124436376, "tcdate": 1518472652167, "number": 332, "cdate": 1518472652167, "id": "SkV0ptkvf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SkV0ptkvf", "signatures": ["~Yash_Sharma1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "nonreaders": [], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1522096970950, "tcdate": 1522096970950, "number": 7, "cdate": 1522096970950, "id": "B1QIoCLqM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "HJcvf6JYM", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "Thank you for your comments. One clarification, when epsilon=0.5, for the L1/L2 optimized attacks (EAD, C&W), an all-gray adversarial example would not be generated as the L1/L2 distortion would be high. As we showed in earlier works, for an L1-optimized attacks, visually good adversarial examples can be constructed which have high epsilon because by minimizing L1, less pixels are modified. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582896597, "tcdate": 1520501860003, "number": 1, "cdate": 1520501860003, "id": "rJnD4K0df", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Review", "forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "signatures": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer3"], "content": {"title": "This paper provides experiments that show the limits of feature squeezing defense ", "rating": "6: Marginally above acceptance threshold", "review": "By increasing the strength of adversarial attacks by tuning their parameters out of the standard range, the provided experiments on MIST and CIFAR-10 show that feature squeezing defense can be by passed.\n\nThe issue of this claim is that if there are no limit range for the adversarial attacks parameters, it is obviously possible to change the input image in a way that the image class changes.\nThe author uses an implicit limit range that corresponds to a soft criteria corresponding to visual similarity. \nCould you quantify \"visual similarity\" ?\nWhat means L_2, L_2, or L_\\infty norms in terms of visual similarity ?\n\nWhen a classifier is built to discriminate images between 10 classes on an input space that contains much more that the 10 classes, is it surprising that some \"small\" perturbations can change the predicted classes ?\nFor most of input images the true class should be I don't know.\n\nOverall I think that paper could be interesting to feed the discussions at the workshop.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582896402, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper332/AnonReviewer2"], "reply": {"forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582896402}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582847804, "tcdate": 1520583265744, "number": 2, "cdate": 1520583265744, "id": "HJcvf6JYM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Review", "forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "signatures": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer2"], "content": {"title": "Feature squeezing is vulnerable, but this was already known", "rating": "3: Clear rejection", "review": "This paper shows that the \"feature squeezing\" defense against adversarial examples can be defeated using standard attacks, as long as the budget for the adversary is increased. Previous limitations on adversary strength may have been overly conservative, and there are visually indistinguishable adversarial examples that violate commonly-used constraints.\n\nAnalyzing the weaknesses of proposed defenses is a valuable contribution. I disagree with the comment thread about making the adversary stronger -- it's fine to evaluate against a stronger adversary (with looser constraints on the examples), as long as you can show that the resulting examples are sufficiently visually similar to the original images.\n\nHowever, I thought that this paper fell short in two critical ways:\n\n1. When the main innovation is a stronger or less-constrained adversary, it's very important to demonstrate that this adversary still generates good images. This was shown qualitatively with a small number of images, but since this claim is central, it needs a more thorough evaluation. This could be done with a user study, for example. (I was also confused by the epsilon=0.5 case -- shouldn't the adversary be able to create an all-gray image, which would always confuse a classifier? But I may have missed something, so I'll give it the benefit of the doubt.)\n\n2. In the paper \"Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong\" (He et al., 2017), the authors showed that feature squeezing is indeed vulnerable to adversarial attacks. This workshop paper needs to distinguish its contribution from previously published work. Feature squeezing was claimed to be effective, but that claim has already been disproven.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582896402, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper332/AnonReviewer2"], "reply": {"forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582896402}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573594259, "tcdate": 1521573594259, "number": 219, "cdate": 1521573593925, "id": "rkG1J1k5z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1519934040137, "tcdate": 1519931155456, "number": 3, "cdate": 1519931155456, "id": "SksMy0HOM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "rkzf6TSOM", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "Per our first response, what we demonstrate is the hyperparameter setting used for the attacks in the original work is weak, and with stronger settings one can find adversarial examples which bypass the proposed joint detection method \"with minimal visual distortion.\"  So, our generated adversarial examples bypass feature squeezing detection while also remaining visually similar to the original images. Please refer to Figures 1 and 2 for evidence. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "tmdate": 1519934028099, "tcdate": 1519932344468, "number": 5, "cdate": 1519932344468, "id": "rJla70Suz", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "SJiHB9VuM", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "Thanks for your update. Per our first response, what we demonstrate is the hyperparameter setting used for the attacks in the original work is weak, and with stronger settings one can find adversarial examples which bypass the proposed joint detection method \"with minimal visual distortion.\"  So, our generated adversarial examples bypass feature squeezing detection while also remaining visually similar to the original images. Please refer to Figures 1 and 2 for evidence. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "tmdate": 1519933922797, "tcdate": 1519925614054, "number": 2, "cdate": 1519925614054, "id": "SJIdF3ruf", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "HyLwrnSdM", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "The threat model proposed by the original authors is the following: \"In evaluating robustness, we assume a powerful adversary who has full access to a trained target model, but no ability to influence that model. For now, we assume the adversary is not aware of feature squeezing being performed on the operator\u2019s side. The adversary tries to find inputs that are misclassified by the model using white-box\nattack techniques\".  Therefore, there is indeed no adversary strength constraint (e.g.,  $\\epsilon$ ) in the threat model."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "tmdate": 1519933896693, "tcdate": 1519932049951, "number": 4, "cdate": 1519932049951, "id": "rkcqfRr_f", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "SJNl0aS_G", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "Based on your comment \"Just because the authors of the paper do not label their threat model clearly does not mean that the threat model does not include an $\\epsilon$ constraint\", we suggest you contact the feature squeezing paper authors for justification. If they revise their threat model description with an explicit distortion constraint, we will follow up the changes accordingly.\n\nHowever, we would like to point out that even if the threat model only considers weak attacks (e.g., small $\\epsilon$ constraint), our Figures 1 and 2 still clearly demonstrate the existence of visually similar adversarial examples when one makes the attack stronger, by increasing the adversary strength. We believe the fundamental question is: can feature squeezing be effective against stronger attacks when the resulting adversarial examples are still similar to the original ones?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"ddate": null, "tddate": 1519933155260, "tmdate": 1519933612400, "tcdate": 1519933079796, "number": 6, "cdate": 1519933079796, "id": "ByxsUCH_f", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "ryKebASuf", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response ", "comment": "We would like to remind you that according to the feature squeezing paper, $\\epsilon$ is not part of the threat model. \n\nIn addition, if $\\epsilon$=255 ($L_\\infty$ constraint), as long as one can generate visually similar adversarial examples like those generated by the one-pixel attack (https://arxiv.org/pdf/1710.08864.pdf),  wouldn't one consider it as a powerful adversarial attack?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "tmdate": 1519931633357, "tcdate": 1519931633357, "number": 6, "cdate": 1519931633357, "id": "ryKebASuf", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "SksMy0HOM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Threat model", "comment": "$\\epsilon$ is part of the _threat model_. It's not a parameter that the attacker is able to choose.\n\nIf the attacker is allowed to choose epsilon, why not choose epsilon=255 and use the provably optimal 1-line attack that I gave above that's guaranteed to defeat all current and future defenses?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}, {"tddate": null, "ddate": null, "tmdate": 1519931014746, "tcdate": 1519930634294, "number": 4, "cdate": 1519930634294, "id": "rkzf6TSOM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "SJIdF3ruf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "No epsilon constraint", "comment": "Here's a simple attack that also works in the \"threat model\" without an $\\epsilon$ constraint:\n\ndef compute_attack(image, target_class):\n    return instance of target class\n\nNo need to use anything as complicated as EAD.\n\nUnbounded distortion is not a reasonable or useful threat model."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}, {"tddate": null, "ddate": null, "tmdate": 1519930958754, "tcdate": 1519850819222, "number": 2, "cdate": 1519850819222, "id": "SJiHB9VuM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "r1ooXU7OM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Thanks", "comment": "Thank you for the clarification. This is a pretty neat result!\n\nEDIT: I didn't read the response closely enough. I do see this as violating the threat model (/ an unbounded threat model is not reasonable or useful). Given the other discussion, this result doesn't seem particularly meaningful. Any unbounded attack should be able to achieve 100% success rate against a non-constant classifier."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}, {"tddate": null, "ddate": null, "tmdate": 1519930860014, "tcdate": 1519930860014, "number": 5, "cdate": 1519930860014, "id": "SJNl0aS_G", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "SJIdF3ruf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "Table 2 gives an evaluation of attacks under various $l_p$ and $\\epsilon$ \"distortion\" levels, and thus gives a clear picture of the claims that the paper makes. Just because the authors of the paper do not label their threat model clearly does not mean that the threat model does not include an $\\epsilon$ constraint, it is just implicit based on the evaluation. The authors make no claims on $\\epsilon$ values larger than the values listed in Table 2. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}, {"tddate": null, "ddate": null, "tmdate": 1519924573894, "tcdate": 1519924573894, "number": 3, "cdate": 1519924573894, "id": "HyLwrnSdM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "r1ooXU7OM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Increasing $\\epsilon$ changes the threat model", "comment": "Increasing $\\epsilon$ is stepping outside the threat model proposed by the original authors. You are not invalidating any claims by the authors of the feature squeezing paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}, {"tddate": null, "ddate": null, "tmdate": 1519768482937, "tcdate": 1519768482937, "number": 1, "cdate": 1519768482937, "id": "r1ooXU7OM", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "forum": "SkV0ptkvf", "replyto": "Hkv4Q7muf", "signatures": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper332/Authors"], "content": {"title": "Response", "comment": "Thanks for your valuable comments. We use the same threat model as used in the original feature squeezing work (a powerful adversary with full access to the trained target model, but unaware of feature squeezing being performed on the operator's side). What we demonstrate is the hyperparameter setting used for the attacks in the original work is weak, and with stronger settings one can find adversarial examples which bypass the proposed joint detection method with minimal visual distortion. For example, $\\kappa$ = 10 was used for the C&W attack in the original work, by increasing $\\kappa$ we show that feature squeezing can be bypassed. Similarly for the $\\epsilon$ parameter in PGD. The definition of adversary strength used in the paper is equivalent to the one used in the feature squeezing work. \n\nOne note, regarding the paper cited, in its introductory work, no threat model was defined explicitly for the Madry Defense Model, it was solely tested in the white-box and black-box cases. In the competition, a black-box setting (transfer attack) was posed with an $L_\\infty$ distortion constraint placed on the attacker. The cited paper argues that this constraint was used because the network as is could not be adversarially trained by PGD with larger $L_\\infty$ distortion, and the addition of that constraint implies that visually imperceptible adversarial examples cannot be generated with $L_\\infty$ distortion greater than the given constraint. The cited paper shows that by using $L_1$-based adversarial examples, despite their high $L_\\infty$ distortion, visually imperceptible adversarial examples which successfully transfer to the Madry Defense Model can be generated. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222445497, "id": "ICLR.cc/2018/Workshop/-/Paper332/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper332/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper332/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers", "ICLR.cc/2018/Workshop/Paper332/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222445497}}, "tauthor": "sharma2@cooper.edu"}, {"tddate": null, "ddate": null, "tmdate": 1519756078987, "tcdate": 1519756078987, "number": 1, "cdate": 1519756078987, "id": "Hkv4Q7muf", "invitation": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "forum": "SkV0ptkvf", "replyto": "SkV0ptkvf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Increasing adversary strength", "comment": "Typically, phrasing like \"stronger attack configurations\" is used to talk about using strong (potentially adaptive) iterative attacks, but _within the threat model posed_.\n\nCan \"increasing adversary strength\" as used in this paper be understood as stepping outside the threat model considered in the original Feature Squeezing paper, similar to what was done in this work (https://arxiv.org/abs/1710.10733)? If so, this paper does not invalidate any claims made in the Feature Squeezing paper, right? All this result shows is that Feature Squeezing doesn't work under the different threat model considered in this workshop paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bypassing Feature Squeezing by Increasing Adversary Strength", "abstract": "Feature Squeezing is a recently proposed defense method which reduces the search space available to an adversary by coalescing samples that correspond\nto many different feature vectors in the original space into a single\nsample. It has been shown that feature squeezing defenses can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. However, we demonstrate on the MNIST and CIFAR-10 datasets that by increasing the adversary strength of said state-of-the-art attacks, one can bypass the detection framework with adversarial examples of minimal visual distortion. These results suggest for proposed defenses to validate against stronger attack configurations.", "paperhash": "sharma|bypassing_feature_squeezing_by_increasing_adversary_strength", "keywords": ["Adversarial Attacks", "Adversarial Defenses", "Feature Squeezing", "EAD", "PGD"], "_bibtex": "@misc{\n  sharma2018bypassing,\n  title={Bypassing Feature Squeezing by Increasing Adversary Strength},\n  author={Yash Sharma and Pin-Yu Chen},\n  year={2018},\n  url={https://openreview.net/forum?id=SkV0ptkvf}\n}", "authorids": ["sharma2@cooper.edu", "pin-yu.chen@ibm.com"], "authors": ["Yash Sharma", "Pin-Yu Chen"], "TL;DR": "By increasing the adversary strength of PGD and EAD, via the $\\epsilon$ and $\\kappa$ hyperparameters respectively, one can bypass the feature squeezing detection framework with adversarial examples of minimal visual distortion.", "pdf": "/pdf/eead3d95723e5cb366a8817e3e282854e8ab4835.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622846, "id": "ICLR.cc/2018/Workshop/-/Paper332/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper332/Reviewers"], "reply": {"replyto": null, "forum": "SkV0ptkvf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622846}}}], "count": 17}