{"notes": [{"id": "doeyA2PBjdy", "original": "ZT_ZqtV9Mxi", "number": 1177, "cdate": 1601308132121, "ddate": null, "tcdate": 1601308132121, "tmdate": 1614985723184, "tddate": null, "forum": "doeyA2PBjdy", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "lr7J4ve__kY", "original": null, "number": 1, "cdate": 1610040417549, "ddate": null, "tcdate": 1610040417549, "tmdate": 1610474015860, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "Pruning is an important problem in practice. The angle of this study is also interesting. The key concept proposed by this submission is called the \"utility imbalance\" of the weights.  There are many concerns raised by the reviewers. Let us summarize some of them here: (1) hard to follow even for the domain experts; (2) the definition and motivation on \"utility imbalance\" are unclear ; (3) loss landscape visualizations are too much simplified to be informative.  There are also lots of concerns on writings. The rebuttal did help clarifying some details. However, most of the concerns still remain. We hope the detailed comments from the reviewers will be useful for the authors to polish this work. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040417534, "tmdate": 1610474015843, "id": "ICLR.cc/2021/Conference/Paper1177/-/Decision"}}}, {"id": "FDVmqRmfEZE", "original": null, "number": 3, "cdate": 1603959200395, "ddate": null, "tcdate": 1603959200395, "tmdate": 1606801560404, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review", "content": {"title": "The assumption does not always hold; imbalance is not surprising; the study on imbalance is quite limited", "review": "The paper proposes to answer the question why \"a network with the same number of weights as that of the pruned network cannot achieve similar performance when trained from scratch\". Then it proposes an hypothesis that the small model \"does not utilize all of its weights either\". To prove this hypothesis, it goes on to define and study the \"utility imbalance\" of the weights and its changing with the pretraining, pruning, etc. Some visualization analysis was provided too.\n\nI appreciate the detail empirical studies conducted in this paper, but I have some serious concerns:\n\n1. The paper cites [1] for the assumption that \"a network with the same number of weights as that of the pruned network cannot achieve similar performance when trained from scratch\". This is the basis for the whole study of the paper. This assumption seems to be in contradiction with conclusion in [2] for some cases, including the experimental setting this paper studies. In fact, it is well documented both in [1] and [2] that a network trained from scratch can reach a similar performance as a pruned-retrained network, under relatively large learning rates, in the case of unstructured pruning for CIFAR-10, or any structured pruning. The learning rate used is 0.1 for the CIFAR-10, which this paper also uses. This basically makes the assumption of this study (and thus the goal of proving the hypothesis) at least not valid in some cases. I am aware that this issue on learning rate was mentioned in section 2.1.1, but that still doesn't address the basic assumption and aimed goal of this study. \n\n2. The paper demonstrated there is imbalance in the network weights' \"utility\", but did not try to investigate which part of the weights are of higher utility. I think this is a more important problem than its relation with network size. For example, in [2], the authors showed the imbalance usage within 3x3 convolutional kernels.\n\n3. The utility imbalance is not really a surprising phenomenon. After or during training, only with these utility imbalance we can prune network according to various criteria, and beat random pruning. Thus this should not be surprising to the literature. For imbalance at initialization, the paper directly cites [1] without much further study.\n\n4. The paper only discusses the conclusion at [1] for the utility imbalance at initialization. I think some experiments could help better understand the cause of imbalance at initialization. For example, do shallower layer's weights on average has larger utility? or those weights with large magnitudes? I wouldn't be surprised if the imbalance can be explained by the differences with initialized weight magnitudes. So again the question is how much of the imbalance is explained by the lottery hypothesis, and how much is due to other reasons. This goes back to point 2, where my concern is the paper did not investigate which weights are of higher utility, either at initialization, during optimization or after.\n\n5. The paper title is a bit too vague. The conclusions are kind of vague too. The conclusion section mentioned a lot of content was studied/discussed/defined/investigated, but didn't give what the findings are. This is also a reflection that the paper/study itself didn't have a strong conclusion either.\n\nIn total, there are some interesting analysis on the changing process of the defined imbalance. However, the paper seems to lack a central conclusion that can help future practices, or help people gain deeper understanding. Network weight imbalance is expected, not surprising. The paper did not dig further with the imbalance by investigating which subsets of weights are more useful, and did not give much explanation with experiments on why the imbalance exists. Last but not least, the assumption and the attempted hypothesis does not always hold in the first place, in particular even in paper's experimental setting (large lr). \n\n[1] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks [2] Rethinking the Value of Network Pruning\n\n\nI appreciate the author response but unfortunately they are still a bit vague (1,3), or not supported with experiments (2,4). I still maintain my rating of 4.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124925, "tmdate": 1606915777515, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review"}}}, {"id": "nwL0qw6KYNZ", "original": null, "number": 4, "cdate": 1604288274859, "ddate": null, "tcdate": 1604288274859, "tmdate": 1606798317727, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review", "content": {"title": "Inscrutable Claims and Inscrutable Methods", "review": "# After Rebuttal\n\nI have read the response to my review and the responses to the other reviews. The summaries of the paper in the other reviews helped to clarify my understanding of the research question the authors were aiming to answer and how they went about doing so. I have re-read the paper and the revisions have helped to make this story clearer.\n\nWith that said, I remain concerned with many technical aspects of the paper, for example:\n* The scale of the networks studied.\n* I still don't understand why this particular definition of utility imbalance is well-motivated.\n* I generally don't think that two dimensional loss landscape visualizations are informative since they discard an enormous amount of information from the full loss landscape. To show that minima are related, I think it is better to use interpolation (mode connectivity).\n\nI am also still concerned about the writing. The revisions, alongside the other reviews, were enough for me to get a sense for the research question and technical story, but I still struggled to make sense of the details.\n\nSince the other reviewers appear to have better understood the paper, I have raised my score to a 4 and decreased my certainty to a 2. I suggest that the AC weight my review much less heavily than the other reviewers, who seem to have better understood the technical details.\n\n# Overall\n\nThis paper is inscrutable. The research question is unclear and the hypothesis is vague and imprecise. The metric being examined (\"utility imbalance\") is never justified in name or in definition, and broad, sweeping, unsubstantiated claims are made that it has to do with how the network uses its weights or the sharpness of the minima (among other aspects of deep learning). Section 3 seems completely unrelated to the previous analysis, and I don't understand how Sections 2 and 3 relate to form a cohesive story. I can't make sense of this paper - its question, its claims, or its method - and I'm an expert reader on topics of pruning and lottery tickets. I can't imagine what a non-expert reader would be able to glean from this paper.\n\n# Score\n\nI therefore strongly recommend rejection (score of 2).\n\n# To Improve My Score\n\nTo Improve my score, the authors need to:\n* Explain what the research question is, precisely.\n* Explain what the hypothesis is, precisely.\n* Explain (in detail) what the justification is for \"utility imbalance\" and why it corresponds to meaningful behaviors of a neural network. The authors will need to include evidence that this corresponds to the claimed attributes of a neural network, which will include a precise definition of what it means for a network to \"utilize\" a weight and how this metric measures that.\n* Explain why this is called \"utility imbalance\"\n* Explain jhow the results in sections 2 and 3 related to each other and the larger narrative/takeaway that they provide.\n* Explain why the network under study changes mid-way through the paper. Is there a reason for this? When I see this in papers, it's usually because the authors tried this on both networks and are only showing the positive results and are hiding bad results; to assuage this concern, the authors should show all results for both networks.\n\nFrom there, I'll need to re-read the experiments to see if I can make sense of them. In its current state, I do not believe that this paper makes a contribution to the scientific literature.\n\n# Notes\n\n## Abstract\n\nWhat do the authors mean by \"the pruning mechanism\"?\n\n## Intro\n\nWhat prior work has claimed that \"the reason for training the large network [is] to obtain a good minimum\"? I don't recall having previously seen this specific claim, nor the implied negation of this claim: that training a pruned network finds a \"bad minimum.\" What makes a minimum \"good\" or \"bad\" and how can we measure this?\n\n\"Cannot achieve similar performance when trained from scratch\" - this only occurs with a new random initialization, as Frankle & Carbin 2018 show (at least for the small-scale networks they examine).\n\nWhat do you mean by a \"utility imbalance\"? Which networks aren't \"utilizing all their weights,\" the unpruned networks or the pruned networks?\n\nAfter reading the introduction, I really have no idea what the paper is about. I don't understand the research question, the main hypothesis, the methodology, or the findings. the authors should make efforts to clarify this story. I'm confused, and that means I'm going to have a hard time making sense of the rest of the paper.\n\nI also can't make sense of Figure 1. I don't know which network this refers to, and I still don't know what a \"utility imbalance\" is.\n\n## Section 2\n\nWhy is there an assumption that a large network \"does not utilize all its weights and thus can easily be compressed?\" There are many possible reasons that one can prune a network, and we often find in the literature that pruning reduces accuracy. The entire point of retraining is to recover this accuracy. But since accuracy went down, it seems that these weights did serve some purpose.\n\nIs N_small the same pruned architecture, or is it a different pruned architecture, a smaller dense network, etc.?\n\nWhat does it mean for a network to \"utilize all its weights\"?\n\nIn Definition 1, does the pruned network include retraining?\n\nWhy is this measure of utility imbalance meaningful or useful? Networks whose outputs have very different distributions may get similar accuracy, so KL divergence doesn't seem to be esxpecially meaningful here. I also don't see what this has to do with utility.\n\n#### Section 2.1.1\n\nI don't follow this logic, and I'm an exceedingly well-informed reader when it comes to lottery tickets. What is the purpose of this section? Is utility being used in a formal way or an informal way? If formal, I don't see a proof or derivation to support the claims here. This seems like an argument without any evidence.\n\n#### Section 2.1.2\n\nIt is unacceptable that the name and details of the network used for this paper are buried in an appendix. The network in question, a small convolutional network, appears to be similar to the small convolutional networks used by Frankle & Carbin. These networks are not representative of larger-scale settings for lottery ticket behavior see (\"Linear Mode Connectivity and the Lottery Ticket Hypothesis\" (Frankle et al., 2020)), and the results in this paper should not be taken to be general.\n\nThe first paragraph of 2.1.2 suggests that the \"utility imbalance\" metric has anything to do with the specified claim made by Frankle & Carbin, and I see no reason to believe that.\n\nI don't know how to interpret the \"utility imbalance.\" It has a fancy name and it has a fancy definition, but I have no idea what it means. Graphs of the utility imbalance therefore aren't very enlightening.\n\nWhy does the utility have anything to do with the network \"utilizing the weights more effectively\"?\n\nWhat does the utility imbalance have to do with the sharpness of the loss landscape?\n\nWhy are the weights and SGD being anthropomorphized? e.g., \"The weights is struggling to be utilized more, rather than SGD purposely differ the utility among the weights?\" \n\nI'm completely lost in this section, as the above comments hopefully convey. I have no idea what is being measured, why it is being measured, or why the results have anything to do with the claims. These experiments are also being conducted on a single, non-standard network, so I don't understand why these results should generally be true.\n\n## Section 2.2\n\nWhat does it mean to \"utilize a weight\"?\n\nWhy were the weights rescaled? I don't understand what \"This was to control the number of feature maps and thus avoid any architectural bias.\" means.\n\nWhy did the experiment suddenly switch networks from what was being used in 2.1?\n\nI made a good-faith effort to read the rest of the section from here, but I wasn't able to make much sense of why the evidence substantiated the claims. Please see my general comment at the beginning of the paper.\n\n## Section 3\n\n\"Empirically, the generalization gap is known to be closely related to the geometry of the loss basin.\" This is hotly contested in the literature. I'm not sure you can say this so strongly.\n\nFigure 6 needs a legend to explain what the networks are. The text never explains what W*, Wp, and Wr are.\n\nI have no idea how this section relates to the rest of the paper.", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124925, "tmdate": 1606915777515, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review"}}}, {"id": "FMtByR5XIKV", "original": null, "number": 10, "cdate": 1606195073127, "ddate": null, "tcdate": 1606195073127, "tmdate": 1606195166914, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "21c10zLX0bW", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "Thank you for the discussion", "comment": "Here is are answers for the questions. Rather than which weight finally becomes important or an exact portion of important weights, our interest is on 1) average importance of weights and 2) variance among importance of weights during/after training. Therefore, we measured how critical the weights become (on average) and how different importance among the weights become (variance) during training, regardless of the state after training. \n\nIn addition, we regard random ablation can measure the imbalance of the importance among weights. For example, let's assume we have two networks, network A and B, and each network achieves 100% training accuracy. And we randomly ablate 10% of the weights in each network and measure the training accuracy respectively. The experiment is repeated for hundreds of times. And then the ablated networks from network A achieve 60% accuracy on average, and so do the networks from network B. However, the importance imbalance among the weights in the two networks can be different. If the randomly ablated networks from network A achieve 30\\~90% accuracy and the networks from network B achieve 59\\~61% accuracy, we can say that the importance of the weights is more imbalanced in network A. In other words, it can be inferred that network A relies on a few strong weights, so that it achieves 30% accuracy when the important ones are gone and 90% accuracy when they are retained. On the other hand, network B consists of the weights with the similar influence. In this way, we don't measure the portion of the important weights, but the deviation of importance among the weight sets. The ablation ratio has nothing to do with the ratio of important weights. \n\nThank you."}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "21c10zLX0bW", "original": null, "number": 9, "cdate": 1606118379134, "ddate": null, "tcdate": 1606118379134, "tmdate": 1606118379134, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "-EH7vpBJxZW", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "Thank you for the clarifications", "comment": "Some additional comments/questions:\n\n\"We measured the weight utility and the utility imbalance throughout training in 2.1.2.\" --> I agree that you evaluated the utility imbalance measure at different points in training, however, the measure at each point only captures which weights are useful at that exact moment. For instance, the utility imbalance measure at epoch 100 can answer the question \"which weights at epoch 100 will harm the network if ablated right now\" but not \"which weights' movements were important in getting the model from random initialization at epoch 0 to the better performing model at epoch 100.\"\n\n\"If the measurement were based on a certain criterion, we cannot tell whether a result of an experiment is due to the importance of the weight or the characteristic of the criterion\" --> This is a good point. However, I'm still not convinced that random ablations can measure the imbalance between important and unimportant weights. Let's say a network as 100k weights, and only 10k of them were useful (for simplicity, let's say \"useful\" is binary). If you ablate a random 10% of the weights, you will ablate an expected number of 1000 useful weights and 9000 unimportant weights for each set. There will be some variance between different random sets, but since each set will very likely ablate both useful and unimportant weights, it cannot capture the fact that only 10% of the weights were useful."}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "qjvB0XPigk1", "original": null, "number": 4, "cdate": 1605089823867, "ddate": null, "tcdate": 1605089823867, "tmdate": 1605535373728, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "FDVmqRmfEZE", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "The answers for the concerns", "comment": "We appreciate your earnest review. These are our answers to your concerns: \n1.\tWe are sorry for the confusion caused by using the expression \u2018cannot\u2019. The assumption we made is based on the most basic settings for training a neural network. There are some cases that small network trained without pretraining can achieve the accuracy similar to that of large network, as you indicated. However, those cases need special conditions, i.e., for [1], one needs to know which weights belong to the winning tickets in advance; and for [2], one needs to train small network much longer to achieve the accuracy of large, unpruned networks. Our assumption rather considers the case where small network and large network are trained under the same conditions, i.e. for [1], the unpruned network vs. pruned and randomly reinitialized network; and for [2], the unpruned network vs. Scratch-E cases, where the accuracies of the unpruned network were generally higher than those of Scratch-E. However, thanks to your advice, we recognized that our assumption needs to be clarified. \n2.\tThe problem of finding which weight is important, or more utilized, is a fundamental question in this area. When regarding the important set of weights, it becomes NP-hard and when regarding weights individually, there are some characteristics related to the importance, e.g., magnitude of weight, but they are only sufficient conditions and might be never fulfilled. We agree that the subject is important and should continue to be studied despite the difficulties. \n3.\tThe utility imbalance is already well-known and is not a surprising phenomenon. What we tried to convey in this paper was the cause of the utility imbalance and the characteristics of it. \n4.\tThank you for the excellent idea, \u2018how much of the imbalance is explained by the lottery hypothesis, and how much is due to other reasons.\u2019 We will study it. \n5.\tThe choice of the words was not intended. It happened since we are non-English speakers. Our findings are described in the lists of contributions in 1. Introduction. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "wWkO7EfSO-q", "original": null, "number": 8, "cdate": 1605253771232, "ddate": null, "tcdate": 1605253771232, "tmdate": 1605253792544, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "IhHoT9AZjQF", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "Answers for the review", "comment": "We appreciate your genuine review. Here are some opinions and answers for your concerns and questions:\n1.\tRegarding \u2018\u2026 I don't think that such variability can explain why smaller nets cannot achieve the same accuracy as that of pruned net \u2026\u2019: We appreciate your point. If there is a utility imbalance among the weights in a network, it means some of the weights are less utilized. However, when a network utilizes the larger portion of the weights, as the pruned-and-retrained network does in 2.2.2, it achieved better performance. However, we see that the definition of the weight utility does not directly remind of what we described above. We will consider that. We appreciate for the point once again. \n2.\tRegarding \u2018\u2026the accuracy surface is drawn based on only THREE points\u2026\u2019: The study of drawing loss surface is commonly done with 2~3 points [1,2,3]. However, we also see your point. \n3.\tRegarding \u2018\u2026 pruned-then-retrained and trained net are lying on similar surface is trivial to show since \u2026\u2019: We conducted this study due to [4]. We were curious whether the pruned-and-retrained network stays in the basin of the pretrained network, even if we retrain the pruned network with large learning rate. The pruned network might have escaped from the original basin and the retrained network could have gone to the other basin with the comparable accuracy. However, from the visualization, we could see that the pretrained network and the pruned-and-retrained network shares the same basin, as the two points connected in any dimension are already connected no matter what happens in other dimensions. On the other hand, with drastic pruning, it is probable that the two networks are in the different basins, as we cannot guarantee the same thing happened in other dimensions. \n4.\tRegarding \u2018\u2026 I'm just curious what would be that measure for iterative pruning schemes.\u2026\u2019: For weight pruning, we used [5]; and for channel pruning we used the criterion in [6]. To avoid misunderstanding, they were described in Experiment details subsection in Section 5.\n5.\tWe appreciate the other advices and opinions as well. \n\n[1] Garipov, Timur, et al. \"Loss surfaces, mode connectivity, and fast ensembling of dnns.\" Advances in Neural Information Processing Systems. 2018.\n\n[2] Li, Hao, et al. \"Visualizing the loss landscape of neural nets.\" Advances in Neural Information Processing Systems. 2018.\n\n[3] Evci, Utku, et al. \"The Difficulty of Training Sparse Neural Networks.\" (2019).\n\n[4] Renda, Alex, Jonathan Frankle, and Michael Carbin. \"Comparing Rewinding and Fine-tuning in Neural Network Pruning.\" International Conference on Learning Representations. 2019.\n\n[5] Han, Song, et al. \"Learning both weights and connections for efficient neural network.\" Advances in neural information processing systems. 2015.\n\n[6] Liu, Zhuang, et al. \"Learning efficient convolutional networks through network slimming.\" Proceedings of the IEEE International Conference on Computer Vision. 2017.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "-EH7vpBJxZW", "original": null, "number": 7, "cdate": 1605253517578, "ddate": null, "tcdate": 1605253517578, "tmdate": 1605253673866, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "PDmhyQfHb79", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "Answers for the review", "comment": "We appreciate your generous and sincere review. We are grateful to the pros in the review. Here are the answers for the cons and the questions:\n\n(Cons 1,2) Thank you for recommending genuine papers. We will refer to those. \n\n(Con 3) We measured the weight utility and the utility imbalance throughout training in 2.1.2. Please let us know if this is not what you mean. \n\n(Con 4) The random ablation was chosen for the following reasons. 1) If the measurement were based on a certain criterion, we cannot tell whether a result of an experiment is due to the importance of the weight or the characteristic of the criterion. For example, if we set the magnitude of weight as the criterion and acquire a result from an experiment, then we cannot be sure whether the result came out because the weight is important or the weight has large magnitude. 2) Also, since there is no absolute criterion for the weight importance, there is a limitation for a criterion to represent it. For example, it is quite well-known that the magnitude of weight is highly related to the importance of weight (Han, 2015), however, there are also some weights with small magnitude but still important. On the other hand, ablation is a direct way of measuring the weight importance, although it can only measure as a group and show overall trend when sampled repetitively.\n\n(Con 5)\n1) Answer for \u2018\u2026 the existence of a connector in one particular dimension does not mean that two points are necessarily in the same basin.\u2019: This is a very good point. We described as those since if two points are connected in any dimension, then it means they are already connected no matter what happens in other dimension. On contrary, if we observe two points being in the different basins, we can only say that there is a possibility that they are separated, since they may be connected in other dimensions as you depicted.  \n\n2) Answer for \u2018\u2026 if the pretrained model and the pruned+retrained model are in the same basin, that would mean the pruned+retrained model achieves the exact same accuracy as the full model\u2026\u2019: Even if the two models are in the same basin, they can have different accuracy. This is because one basin consists of a part of continuously-varying loss surface. \n\n3) Answer for \u2018why use accuracy rather than loss?\u2019: With accuracy surface, we can intuitively know how abruptly the loss surface changes. There is no particular reason other than that. Actually, the loss surface looked better \ud83d\ude0a \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "Bgypd_S8Lg", "original": null, "number": 6, "cdate": 1605253463128, "ddate": null, "tcdate": 1605253463128, "tmdate": 1605253646563, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "PDmhyQfHb79", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "(Continued from above)", "comment": "(Question 1, 2) Here are intuitive explanations for the definitions. We should have described it in the paper. We are sorry if it made you confused and distressed. \n\n(Weight utility, def1) Let\u2019s say there is a trained network. It has various weights with various importance. And then we ablate a weight. If we ablate an important weight, the outputs of the original network and the ablated network will differ a lot. In this case we say the weight is highly utilized. On the other hand, if the weight is less important, the outputs will vary less and we say the weight is less utilized by the network. Since ablating a single weight merely affects network, we extend this concept to a set of weights. \n\n(Definition of utility imbalance, def2) \nIf two weight sets have different utility, or importance, we can say that there is utility imbalance between the sets. \n\n(Measure of utility imbalance, def3)\nLet\u2019s say there are some weight sets we draw from a network. And we measure the utility of each weight set. If the utility of the weight sets differs from each other, then we can say there is utility imbalance between the sets. Likewise, we can measure how much the utility values of the sets deviate from each other. Intuitively, one can measure variance among the utility of the sets, where we actually used standard deviation. \n\n (Q 3) About Figure 1. (Left) Let\u2019s say we have two weight sets A and B with the same size in a network. And we get 80% and 20% accuracies when ablating set A and B from the network respectively. Then we can say the network relies more on the weights in set B than those in A, and thus we can also say there is utility imbalance between A and B. Likewise, the accuracies in the Figure 1 variate even when ablated by the same portion (as is represented by min-max bar). For example, when we ablate 10% of the weights, the accuracies vary from about 20~80% in the left figure. (Right) We obtained the figure by following procedure: the weights were sorted by their magnitudes and chunked into parts by the given ratio. And each chunk was ablated sequentially. For example, after sorting the weights by their magnitude, we divide them into 10 chunks, which corresponds to 0.1 in the legend, and ablated each of them to get each point in the figure. Each value in the magnitude axis represents the maximum magnitude of the weight in each chunk. \n\n(Q 4) Lottery Ticket Hypothesis (LTH, Frankle & Carbin, 2018) states that there is a subnetwork from initialization that can achieve similar performance to that of the original network given the similar training time. If there is such a subnetwork, then the other weights in the network seem to have small effect on training the whole network. However, we recognized that there is a logical leap. There can be a counter example like the case you suggested earlier (https://arxiv.org/abs/1906.10732). We should provide more evidence. Thank you for pointing out. \n\n(Q 5) The \\(\\delta\\) in 2.1.2 is just an expression for weight change. It is unrelated to the one in the definition. Also, we appreciate your great point about KL-divergence. Other measurements such as Euclidean distance between the logits may be more proper than probability-based measure to assert our claims. On the other hand, we described as \u2018each of the weights is struggling to be utilized more\u2019 to indicate that the utility of each weight keeps increasing, rather than the utility of some weights are suppressed to go to a better minimum for a greater good. \n\n(Q 6) Okay. Just \u2018heuristic\u2019 can be better. Thank you. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "R4DZpKGT4ml", "original": null, "number": 5, "cdate": 1605253314826, "ddate": null, "tcdate": 1605253314826, "tmdate": 1605253314826, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "nwL0qw6KYNZ", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment", "content": {"title": "Answers for the review", "comment": "Okay. I am the first author of this paper. As I wrote the part you have trouble with, I will answer to your questions. \n\n(Q1, 5) We tried to validate the commonly used method, i.e. pretraining a large network and pruning and retraining it. We investigated the method in two parts: pretraining part and pruning-and-retraining part. Each part was studied with distinct measurement/method. \n(Q2, 3, 4) I see your point and please refer to the intuitive explanations for the definitions we provided for AnonReviewer4, i.e. (Weight utility, def1), (Definition of utility imbalance, def2), (Measure of utility imbalance, def3). Also, we recommend you to have a look at the first answer we provided for AnonReviewer2.\n(Q6) The networks and the optimizers used for the entire experiments were the same. We only provided the additional setting in 2.1.2, since we needed to show that the characteristics of the weight utility solely come from SGD, not from skip connection, Batch Normalization, momentum nor weight decay. Moreover, the experiments in 2.1.2 were even done with the setting which is the same as that of all the others, and the corresponding results were provided in Appendix A.2.4, \u2018An experiment with the advanced settings\u2019. We recommend you to check it. \n\nI am deeply sorry that you had such a hard time reading this paper. I see how it happened and hope I do better next time. However, it is unfair to raise an ethical issue. Even if it came from a misunderstanding, you could have just asked us to conduct additional experiments. Nonetheless, I do appreciate your hard work and good points you made. Thank you\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "doeyA2PBjdy", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1177/Authors|ICLR.cc/2021/Conference/Paper1177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862768, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Comment"}}}, {"id": "IhHoT9AZjQF", "original": null, "number": 1, "cdate": 1603871131526, "ddate": null, "tcdate": 1603871131526, "tmdate": 1605024511011, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review", "content": {"title": "Study of a pruning after training using weights' utilization measure", "review": "This paper addresses the following important question related to \"pruning after training\" framework: why, in general, smaller network trained from the scratch does not achieve the same accuracy as the pruned network (obtained from pretrained net)? For that matter, authors introduce a new mechanism (\"weights' utility measure and utility imbalance\") to measure a discrepancy between subnetworks (subset of weights) within each network and it seems that having a large value of that measure accounts for the networks not utilizing all of their weights.\n\nIn general, I liked the approach chosen by authors to study the effects of pretraining and weight utilization in pruning. For example, it is interesting to observe that the accuracy difference can be monotonically increasing during neural net training and that the neural networks utilization is proportion to their size. Moreover, such difference (described by utility imbalance measure) is observed independent of network size. As far as I know, such study is novel. However, I don't think that the utility imbalance measure is a unique mechanism for such analysis and one can choose other possible options. In fact, a huge variation of the neural net accuracy depending on which subnetwork (subset of weights) you choose is so obvious that there is no need to show it explicitly (fig. 1). Moreover, the core idea behind pruning is to find such best subset of weights. Therefore, I don't think that such variability can explain why smaller nets cannot achieve the same accuracy as that of pruned net. \n\nAs for the second part of the paper (loss function surface), the accuracy surface is drawn based on only THREE points, specifically the loss of the pretrained net, pruned net and retrained net after pruning. I don't think that this information is sufficient to obtain an accurate visualization. Moreover, again, I believe that the pruned-then-retrained and trained net are lying on similar surface is trivial to show since: 1) pruned-then-retrained almost always perform better than just pruning; 2) if we don't prune too much then we can expect similar performance as the original net. Therefore, I don't see much contribution here.\n\nMinor concerns: \\\n . some parts of the paper is relatively hard to follow (e.g. in Section 2, jumping from experiment setting to discussing results and vice versa);\\\n . colors in some figures (e.g. fig. 1 and fig. 2) are really hard to distinguish since they are very similar.\\\n . section 2.2.2 describes utility imbalance in a pruned network (before or after retraining). I'm just curious what would be that measure for iterative pruning schemes. For example, as in (Han et al., 2015) and [1,2].\n\n[1] Zhang et al. Adam-ADMM: A unified, systematic framework of structured weight pruning for DNNs. 2018.\\\n[2] Carreira-Perpin\u02dcan, M. and Y. Idelbayev. Learning-compression algorithms for neural net pruning. 2018.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124925, "tmdate": 1606915777515, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review"}}}, {"id": "PDmhyQfHb79", "original": null, "number": 2, "cdate": 1603872928754, "ddate": null, "tcdate": 1603872928754, "tmdate": 1605024510947, "tddate": null, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "invitation": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review", "content": {"title": "Interesting direction but conclusions are not supported by the selected measurements", "review": "Summary: This paper dives into why small pruned networks don\u2019t train as well as large networks. They come up with a measure of weight utilization and claim that networks of all sizes only use a portion of their weights during training, and the imbalance increases during optimization. Additionally, they visualize the accuracy surface on the plane defined by the pretrained, pruned, and retrained networks and find that the retrained networks end up in the same basin as the pretrained networks.\n\n\nOverall: The paper is going in an interesting direction, but I find the paper to be unclear and I do not see how their chosen measurements lead to their claims. Thus, I do not recommend acceptance. \n\n\nPros:\n* It is important to understand the mechanisms of how pruning works, as well as the role of overparameterization in neural networks.\n* It is also interesting to see how the ratio of weights used change with respect to network size or sparsity.\n* Visualizing the loss/accuracy landscape between the three networks (pretrained, pruned, pruned+retrained) is interesting and I have not seen that before.\n\nCons:\n* The need for overparameterization to achieve good performance has been studied before (https://arxiv.org/abs/1805.12076, https://arxiv.org/abs/1804.08838), though I do see the benefit of analyzing this from a different angle.\n* There are also studies of how neural networks do not use all of their weights during training (https://arxiv.org/abs/1909.01440)\n* The given utility measure is not the best way to measure how useful certain weights were. Some weights could have been very important for moving around during training, even if they end up unimportant or at a low magnitude. For instance, overparameterization provides more degrees of freedom that may be necessary in optimization (e.g. as discussed in https://arxiv.org/abs/1906.10732). You could include additional measures such as LCA (from https://arxiv.org/abs/1909.01440) to measure how \u201cuseful\u201d certain weights were throughout training.\n* Suggestion: rather than choosing random subsets of weights to prune/ablate in definition 3, why not prune based off of some existing measure? E.g. prune by magnitude, using the n% lowest for $W_i$ (what magnitude pruning would choose) and perhaps the n% highest for $W_j$ for comparison. Your current measure won\u2019t be able to pinpoint if the network heavily relies on, say, a specific 10% of its weights, because pruning a random subset of weights means that you prune both the important weights and the unimportant weights. Currently, this measure only evaluates the network\u2019s sensitivity to random pruning.\n* Section 3 results: while it is useful to visualize the accuracy surface in 2D, a 2D picture does not tell the full story for high dimensional spaces: the existence of a connector in one particular dimension does not mean that two points are necessarily in the same basin. Further, if the pretrained model and the pruned+retrained model are in the same basin, that would mean the pruned+retrained model achieves the exact same accuracy as the full model, which is not the case unless the sparsity is low. Perhaps it would be interesting to see these visualizations at different pruning levels, where accuracy begins to drop. Also, why use accuracy rather than loss?\n\nThere are also several points in the writing that are unclear. While I do not want to penalize the paper for writing style, these issues make it difficult to understand the ideas in the paper. If it is just my misunderstanding, I will gladly read any explanations that the authors can provide.\n* Definition 3: don\u2019t you need a $\\delta$ for utility imbalance? How do you convert standard deviation to utility imbalance? How do you \u201cshow that the utility imbalance among the weights exist\u201d if utility imbalance is not a binary measure?\n* Please give a more intuitive description of utility and utility imbalance. What does it mean for networks to have high utility imbalance given the definition you provided? I don\u2019t agree that having a large standard deviation in utility of the random $W_i$ signifies that the neural network utilizes the weights unevenly; the implication I see is that the network\u2019s output is very sensitive to which random subset of weights you prune.\n* Figure 1 left: why would a drop in accuracy after removing weights imply the utility imbalance? Right: what does \u201cablation regarding the magnitude of weights\u201d mean? How do you choose which weights to ablate?\n* Section 2.1.1: this explains why magnitude pruning works well but does not explain how initialization causes utility imbalance.\n* Section 2.1.2: how is $|\\Delta\\delta|$ the \u201camount of ablation\u201d? How can $\\delta$ be added to $W$ if $\\delta$ is used in $|U(W_i) - U(W_j)| \\geq \\delta$? Also, my guess would be that utility increases over training because at the beginning of training, the network is close to random, so removing some subset of weights won\u2019t change it as much (can\u2019t get much worse than random) as ablating a more trained network. Thus it is only natural that it increases - I don\u2019t see how this supports the claim that the loss landscape became sharper. Also, what does \u201ceach of the weights is struggling to be utilized more\u201d mean?\n* Section 3 paragraph 3: what are the \u201cassumptions for the heuristic\u201d?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1177/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1177/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An empirical study of a pruning mechanism", "authorids": ["~Minju_Jung2", "~Hyounguk_Shon2", "~Eojindl_Yi1", "~SungHyun_Baek1", "~Junmo_Kim1"], "authors": ["Minju Jung", "Hyounguk Shon", "Eojindl Yi", "SungHyun Baek", "Junmo Kim"], "keywords": [], "abstract": "Many methods aim to prune neural network to the maximum extent. However, there are few studies that investigate the pruning mechanism. In this work, we empirically investigate a standard framework for network pruning: pretraining large network and then pruning and retraining it. The framework has been commonly used based on heuristics, i.e., finding a good minima with a large network (pretraining phase) and retaining it with careful pruning and retraining (pruning and retraining phase). For the pretraining phase, the reason for which the large network is required to achieve good performance is examined. We hypothesize that this might come from the network relying on only a portion of its weights when trained from scratch. This way of weight utilization is referred to as imbalanced utility. The measures for weight utility and utility imbalance are proposed. We investigate the cause of the utility imbalance and the characteristics of the weight utility. For the pruning and retraining phase, whether the pruned-and-retrained network benefits from the pretrained network indded is examined. We visualize the accuracy surface of the pretrained, pruned and retrained networks and investigate the relation between them. The validation accuracy is also interpreted in association with the surface. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jung|an_empirical_study_of_a_pruning_mechanism", "pdf": "/pdf/a2167f42d9797c4ee71214207f82ce60b1df4875.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=j1EvfLWbf", "_bibtex": "@misc{\njung2021an,\ntitle={An empirical study of a pruning mechanism},\nauthor={Minju Jung and Hyounguk Shon and Eojindl Yi and SungHyun Baek and Junmo Kim},\nyear={2021},\nurl={https://openreview.net/forum?id=doeyA2PBjdy}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "doeyA2PBjdy", "replyto": "doeyA2PBjdy", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124925, "tmdate": 1606915777515, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1177/-/Official_Review"}}}], "count": 13}