{"notes": [{"id": "Skx24yHFDr", "original": "HJxLlkadwH", "number": 1669, "cdate": 1569439540026, "ddate": null, "tcdate": 1569439540026, "tmdate": 1577168227584, "tddate": null, "forum": "Skx24yHFDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Bu5HQgvfx", "original": null, "number": 1, "cdate": 1576798729374, "ddate": null, "tcdate": 1576798729374, "tmdate": 1576800907166, "tddate": null, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Decision", "content": {"decision": "Reject", "comment": "This paper presents a neural topic model with the goal of improving topic discovery with a PLSA loss. Reviewers point out major limitations including the following:\n\n1) Empirical comparison is done only with LDA when there are many newer models that perform much better.\n2) Related work section is incomplete, especially for the newer models.\n3) Writing is unclear in many parts of the paper.\n\nFor these reasons, I recommend that the authors make major improvements to the paper before resubmitting to another venue.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726473, "tmdate": 1576800278614, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Decision"}}}, {"id": "rJlIw4RqKB", "original": null, "number": 1, "cdate": 1571640414060, "ddate": null, "tcdate": 1571640414060, "tmdate": 1572972438556, "tddate": null, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "First, some minor issues.  I didn't understand equation (3).  It seems to be a variant of equation (4), and seems to be in disagreement with equation (6).  Might be better if the equation was just dropped.  For equation (9), you should have brackets \"()\" around the argument to the exp.\n\nSecond, in terms of comparisons, the paper lacks adequate related work.  Some non-parametric but non-neural\nmodels not implemented in GPUs substantially beat LDA, and will run on all the big data sets you list, though perhaps\nnot quickly!   There has also been a number of neural and hybrid topic models developed.  \nDocNADE and LLA (Zaheer etal), for instance, work very well in PPL.  Then there are many new deep topic models.  Some use the amortised inference that you adopt in section 5.    Some incorporate word embeddings or document metadata to\nfurther improve performance metrics.  Note some of the earlier ICLR/NeurIPS papers with deep models didn't\ndo extensive comparative empirical testing, so may not work well against DocNADE or more recent algorithms.\n\nIn terms of related work, topic models is a bit of a mine-field because there is a huge amount of work in\na huge number of venues, and few authors do a good job of covering related work.  What you have listed are mainly the\nolder works.  Recent work also includes Poisson Matrix Factorisation and its variants, as well as hierarchical\nvariants of LDA, much better than the 2004 paper you mention.\n\nTo do the coherence comparisons, easiest way is to use the Palmetto software.\nYou can also evaluate models by using them as features in a classification task.\n\nIt was interesting that you only did one layer for your networks, i.e.,  equations (4)-(6).  Why was this?\nI would have liked to have seen the impact of more layers. However, your model is remarkably simple \nso if it works well, that is good.\n\nAnyway, the experimental evaluation shows good results on all three datasets for your models, but its hard to be sure\nsince you only have one comparison, an old LDA, and nothing recent.  So promising work, but\nrelated work and experimental work need to be improved.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603406359, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1669/Reviewers"], "noninvitees": [], "tcdate": 1570237734008, "tmdate": 1575603406374, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review"}}}, {"id": "S1lgvje0Yr", "original": null, "number": 2, "cdate": 1571846999743, "ddate": null, "tcdate": 1571846999743, "tmdate": 1572972438520, "tddate": null, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes a neural topic model that aim to discover topics by minimizing a version of the PLSA loss. According to PLSA, a document is presented as a mixture of topics, while a topic is a probability distribution over words, with documents and words assumed independent given topics. Thanks to this assumption, each of these probability distributions (word|topic, topic|document, and word|document) can essentially be expressed as a matrix multiplication of the other two, and EM is usually adopted for the optimization. This paper proposes to embed these relationships in a neural network and then optimize the model using SGD.\n\nI believe the paper should be rejected because: 1) most aspects of this paper are a little dated 2) novelty is little 3) experimental section is very limited and unconvincing.\n\nTo elaborate on the experimental section:\n- Only LDA has been presented as baseline. There's plenty of neural topic models to compare against (you mentioned some in your related work section) but no comparison with any of those is presented. If the concern is their training time on large datasets, they should be at least presented as comparison for the smaller datasets. For the large datasets there's other approaches that would scale and should be presented as baselines: 1) train on a sample of the dataset 2) co-occurrence based topic methods on sliding windows of text are extremely fast (eg see \"A Biterm Topic Model\", \"A Practical Algorithm for Topic Modeling with Provable Guarantees\", and \"A Reduction for Efficient LDA Topic Reconstruction\" which could fit your scenario with large datasets where topics most likely have small overlap with each other and are almost separable by anchor words.)\n- Even regarding just LDA: what hyper-parameters \\alpha and \\beta did you set for LDA? Tuning \\beta to a small value might have an impact for large datasets.\n- Metrics: only perplexity is presented and metrics but it's well known that perplexity on its own is quite limited and often is not correlated to human judgment. Consider adding topic coherence measures as well.\n- The section on continuous document embeddings is confusing and the explanation should be improved and the formalism tightened.\n\n\nOther (did not impact the score):\n- Biases: you're adding biases to your probability estimation equations. This is not in line  with the PLSA assumption. What happens if no biases are used?\n\nThe paper has several typos and grammatical errors, e.g.:\n- page 2, L#1: networks -> network\n- page 4, sec 3.2: set unobserved -> set of unobserved\n- page 5, sec 5: pratise -> practice\n- several places: it's -> its\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603406359, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1669/Reviewers"], "noninvitees": [], "tcdate": 1570237734008, "tmdate": 1575603406374, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review"}}}, {"id": "rJg_OocPcS", "original": null, "number": 3, "cdate": 1572477808416, "ddate": null, "tcdate": 1572477808416, "tmdate": 1572972438476, "tddate": null, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "I am unimpressed with the quality of writing and presentation, to begin with. There are numerous grammatical errors and typos that make the paper a very difficult read. The presentation also follows an inequitable pattern where the backgrounds and related works are overemphasized and the actual contribution of the paper seems very limited. In its current form, this paper is not ready for publication in ICLR.\n\nThe idea of representing a document as an average of the embeddings of the words is a rather crude idea. Paragraph2vec and many of its derivatives have shown significant improvements with document modelling. The perplexity improvements are nice to have, but I would have liked to see the embeddings being applied to some supervised problems to assess their utilities. \n\nThere are quite a few computationally expensive normalization terms. I am curious to understand how these summations do not slow the training process down without further approximations. The authors may present some computational complexity measures to convince readers about the practical applications of the proposed models.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1669/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603406359, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1669/Reviewers"], "noninvitees": [], "tcdate": 1570237734008, "tmdate": 1575603406374, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Official_Review"}}}, {"id": "H1xBYH9OdH", "original": null, "number": 2, "cdate": 1570444668562, "ddate": null, "tcdate": 1570444668562, "tmdate": 1570448377677, "tddate": null, "forum": "Skx24yHFDr", "replyto": "B1ebr8W2DH", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Official_Comment", "content": {"comment": "Dear Pankaj\nAgain thank you for your feedbacks on our paper.  Here we respond to your concerns.\nFirst we accounted about missing reference you mentionned and added them to the paper. We note that Larochelle & Lauly was already cited in the related work section.\n\nAbout your question about related to the perplexity that are high. This is due to the fact that our vocabulary are not filtered: we used all the words appearing in the document. Just to show that, we designed an experiment on TwentyNewsGroup dataset where we used as vocabulary word appearing more than: 20, 40, 60, 80, and 100 times. These results will be added to the paper. When using words appearing more than 100, perplexity are much lower. But this did not change any conclusions.\n\nAbout your concerns related to coherence scores, we added results about UMAss coherence scores (Mimno et al Optimizing semantic coherence in topic models. EMNLP 2011).\n\nAbout your concerns related to comparison with neural topics models, some comparisons with such methods will be added to the paper. In the first version we compared mainly to LDA because it remains the most popular unsupervised topic model.\n\nWe will also display TSNE based document embedding for the TwentyNewGroupDataset which show that documents cluster according to their categories\n\nHope these responses answer your concerns.", "title": "Responses to Pankaj Gupta about missing references, comparisons, and evaluation"}, "signatures": ["ICLR.cc/2020/Conference/Paper1669/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skx24yHFDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference/Paper1669/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1669/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1669/Reviewers", "ICLR.cc/2020/Conference/Paper1669/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1669/Authors|ICLR.cc/2020/Conference/Paper1669/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152614, "tmdate": 1576860556227, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference/Paper1669/Reviewers", "ICLR.cc/2020/Conference/Paper1669/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Official_Comment"}}}, {"id": "r1xnaL5yur", "original": null, "number": 1, "cdate": 1569855171874, "ddate": null, "tcdate": 1569855171874, "tmdate": 1569855221939, "tddate": null, "forum": "Skx24yHFDr", "replyto": "B1ebr8W2DH", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Official_Comment", "content": {"comment": "Thanks for your feedbacks Pankaj. They will be taken into accounts in the coming days. I will come back to you as soon as they are done.", "title": "Adding references, experiments and comparison"}, "signatures": ["ICLR.cc/2020/Conference/Paper1669/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skx24yHFDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference/Paper1669/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1669/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1669/Reviewers", "ICLR.cc/2020/Conference/Paper1669/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1669/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1669/Authors|ICLR.cc/2020/Conference/Paper1669/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152614, "tmdate": 1576860556227, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference/Paper1669/Reviewers", "ICLR.cc/2020/Conference/Paper1669/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Official_Comment"}}}, {"id": "B1ebr8W2DH", "original": null, "number": 1, "cdate": 1569621560636, "ddate": null, "tcdate": 1569621560636, "tmdate": 1569621560636, "tddate": null, "forum": "Skx24yHFDr", "replyto": "Skx24yHFDr", "invitation": "ICLR.cc/2020/Conference/Paper1669/-/Public_Comment", "content": {"comment": "Following are the missing references, especially in Neural topic modeling:\n\n[1] Hugo Larochelle and Stanislas Lauly. A neural autoregressive topic model. In NIPS 2012.\n[2] Pankaj Gupta, Yatin Chaudhary, Florian Buettner, and Hinrich Schuetze. Document informed neural autoregressive topic models with distributional prior. In AAAI 2019. \n[3] Pankaj Gupta, Yatin Chaudhary, Florian Buettner, and Hinrich Schuetze. textTOvec: Deep Contextualized Neural Autoregressive Topic Models of Language with Distributed Compositional Prior. In ICLR 2019.\n[4] Akash Srivastava and Charles Sutton. Autoencoding variational inference for topic models. In  ICLR 2017.\n\nPlease include the reference [3] for the mentions of combining topic and language models (e.g. in conclusion). \n\nAdditional Comments: \n1. Why are the perplexity values are too high? \n2. Please include a quantitative comparison with other neural topic models [e.g., 1, 2, 3, 4]. \n3. What do the high perplexity scores signify? \n4. To better demonstrate the applicability of topic models, could you include additional evaluation such as topic coherence for quality of topics, document clustering or classification or retrieval, similar to [2, 3, 4]? \n \n ", "title": "Missing References, missing comparisons with recent Neural topic models, incomplete evaluation"}, "signatures": ["~pankaj_gupta1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~pankaj_gupta1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sileye.ba@outlook.com"], "title": "Discovering Topics With Neural Topic Models Built From PLSA Loss", "authors": ["sileye ba"], "pdf": "/pdf/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "TL;DR": "We propose a neural topic model that is built using documents, words, and topics embedding together with PLSA independence assumptions. ", "abstract": "In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis (PLSA) assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation (LDA) model which is classically used to address topic discovery tasks.", "keywords": ["neural network", "topic model", "neural topic model", "bag-of-words", "PLSA"], "paperhash": "ba|discovering_topics_with_neural_topic_models_built_from_plsa_loss", "original_pdf": "/attachment/44830d12133a5e0c4ea4037b9313113ccf4d7456.pdf", "_bibtex": "@misc{\nba2020discovering,\ntitle={Discovering Topics With Neural Topic Models Built From {\\{}PLSA{\\}} Loss},\nauthor={sileye ba},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx24yHFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skx24yHFDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504191474, "tmdate": 1576860589376, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1669/Authors", "ICLR.cc/2020/Conference/Paper1669/Reviewers", "ICLR.cc/2020/Conference/Paper1669/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1669/-/Public_Comment"}}}], "count": 8}