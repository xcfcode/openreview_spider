{"notes": [{"id": "CF-ZIuSMXRz", "original": "7NTxpmbqmjK", "number": 1432, "cdate": 1601308159507, "ddate": null, "tcdate": 1601308159507, "tmdate": 1612846373535, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "I1sEb64uZk2", "original": null, "number": 1, "cdate": 1610040419201, "ddate": null, "tcdate": 1610040419201, "tmdate": 1610474017774, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper studies extensions of the Scattering Graph Transform to spatio-temporal domains. By exploring several design choices for spatio-temporal wavelet filters, the authors provide a solid and broad study of such predefined represenatations, including stability analysis as well as extensive empirical evaluations. \nReviewers were generally favorable, and highlighted the importance of this method as providing a simple yet powerful baseline for spatio-temporal graph prediction tasks that requires no training. Despite some concerns about lack of analysis of the empirical results, the AC believes this work will provide a valuable baseline for future research and therefore recommends acceptance as a poster. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040419187, "tmdate": 1610474017758, "id": "ICLR.cc/2021/Conference/Paper1432/-/Decision"}}}, {"id": "Emxkm0mMscu", "original": null, "number": 9, "cdate": 1606191582448, "ddate": null, "tcdate": 1606191582448, "tmdate": 1606191582448, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "Revision of our manuscript", "comment": "We again thank all reviewers for their constructive suggestions on improving our manuscript. We have uploaded a revision of the manuscript. Detailed changes in revision are:\n* More discussion about the comparison between separable and joint graph filters at the end of Section 3.2\n* Motivation of using spatio-temporal graph wavelets at the begining of Section 3.3\n* More details about the experimental setup\n* More discussion about the experimental results\n* More experiments to get the standard deviations of classification accuracy in appendix\n* Correct some typos\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "ZMEV6AN21mQ", "original": null, "number": 3, "cdate": 1605482381007, "ddate": null, "tcdate": 1605482381007, "tmdate": 1605853869879, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "IJZg2Qdgm9", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "A few remarks on the comments raised by the Reviewer 4 (post 1)", "comment": "[Response split into two posts: 1/2] We thank Reviewer 4 for her/his valuable feedback and suggestions for improving the manuscript. We addressed all the comments as described below.\n\n(Q1) \"The family spanned by separable transforms might be smaller than e.g. the strong product...\"\n\nThe flexibility of separable graph filters means that we can design different graph filters ($\\mathbf\\{h\\}$ and $\\mathbf\\{g\\}$ in Eq.(1)) with independent filter length ($P$ and $Q$ in Eq.(1)) in the spatial and temporal domains. On the other hand, for joint graph filters, filter coefficients and length in the spatial and temporal domains are bonded together ($\\mathbf\\{h\\}$ and $K$ in Eq.(2));  that is, we cannot change the filter in the spatial domain without changing the corresponding one in the temporal domain. This thus makes the separable graph filters more flexible than the joint graph filters.\n\nHowever, in terms of the representation power of these two formulations, the family spanned by joint graph filters (either Kronecker, Cartesian or strong product) and the family spanned by separable graph filters do not have a clear relationship that one is a subset of the other. We can show this through a toy example. Consider a graph filter with a strong product graph and the filter order $K=3$, we can write the kernel of strong product graph filter as $\\mathbf\\{H\\}(\\mathbf\\{\\Lambda\\}_s\\otimes \\mathbf\\{\\Lambda\\}_t+\\mathbf\\{\\Lambda\\}_s\\otimes \\mathbf\\{I\\}_T+\\mathbf\\{I\\}_N\\otimes \\mathbf\\{\\Lambda\\}_t)=\\sum_\\{k=0\\}^2 h_k(\\mathbf\\{\\Lambda\\}_s\\otimes \\mathbf\\{\\Lambda\\}_t+\\mathbf\\{\\Lambda\\}_s\\otimes \\mathbf\\{I\\}_T+\\mathbf\\{I\\}_N\\otimes \\mathbf\\{\\Lambda\\}_t)^k$. By expanding the expression and rearranging the coefficients, we can have the following coefficient matrix \n$$\nC=\\begin\\{bmatrix\\}\n        h_0 & h_1 & h_2 \\\\\\\\\n        h_1 & h_1+2h_2 & 2h_2 \\\\\\\\\n        h_2 & 2h_2 & h_2\n    \\end\\{bmatrix\\},\n$$\nwhere $C_\\{ij\\}$ means the coefficient of term $\\mathbf\\{\\Lambda\\}_s^\\{i-1\\}\\otimes \\mathbf\\{\\Lambda\\}_t^\\{j-1\\}$. On other hand, the kernel of separable graph filter with $P=Q=3$ can be written as $\\mathbf\\{A\\}(\\mathbf\\{\\Lambda\\}_s)\\otimes \\mathbf\\{B\\}(\\mathbf\\{\\Lambda\\}_t)=(\\sum_\\{k=0\\}^2 a_k \\mathbf\\{\\Lambda\\}_s^k)\\otimes (\\sum_\\{k=0\\}^2 b_k \\mathbf\\{\\Lambda\\}_t^k)$. By the same rearranging procedure, we can have the coefficient matrix for separable graph filter as \n$$\nD=\\begin\\{bmatrix\\}\n        a_0b_0 & a_0b_1 & a_0b_2 \\\\\\\\\n        a_1b_0 & a_1b_1 & a_1b_2 \\\\\\\\\n        a_2b_0 & a_2b_1 & a_2b_2\n    \\end\\{bmatrix\\} = \\begin\\{bmatrix\\}\na_0 \\\\\\\\\na_1 \\\\\\\\\na_2\n\\end\\{bmatrix\\} \\begin\\{bmatrix\\}\nb_0 & b_1 & b_2\n\\end\\{bmatrix\\}.\n$$ \nIf the family spanned by one method is a subset of the other, then one of the coefficient matrix must be a special case of the other one. On one hand, it is obvious that $D$ is always a rank 1 matrix, while $C$ could have rank 1, 2, or 3. So $C$ is not a special case of $D$. On the other hand, $C$ is always a symmetric matrix, but $D$ can be either symmetric or non-symmetric. Furthermore, the ratio between several pairs of elements in $C$ is fixed, for example $C_\\{32\\}/C_\\{31\\}$ is always 2 in this case; however, $D_\\{32\\}/D_\\{31\\}=b_1/b_0$ can be an arbitrary value. So $D$ is also not a special case of $C$. Therefore, the families spanned by two different methods do not have any simple relationship that one is a subset of the other. This conclusion also holds for the Kronecker and Cartesian products.\n\nIn short, the joint and separable graph filters are two different design methods for spatio-temporal graphs. Though the representation power of separable graph filters is not necessarily much stronger than joint ones, separable design enjoys the flexibility, computation efficiency and straightforward interpretation."}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "6Gbm6WWkmiV", "original": null, "number": 4, "cdate": 1605484995608, "ddate": null, "tcdate": 1605484995608, "tmdate": 1605853264510, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "IJZg2Qdgm9", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "A few remarks on the comments raised by the Reviewer 4 (post 2)", "comment": "[Response split into two posts: 2/2]\n\n(Q2) \u201cdo you think this forced equality is an issue for the joint approach\u201d\n\nWe thank Reviewer 4 for this insightful question, and we will include the discussion here in our revision. The number of scales is essentially the number of graph filters used at each layer. For most spatio-temporal graph signals, the number of time stamps is much larger than the number of spatial locations such as joints. Thus it is intuitive to use more scales/filters in the temporal domain than in the spatial domain. Such a claim is also supported by the experimental results shown in Table 1, where separable ST-GST (5, 20, 3) performs better than separable ST-GST (5, 10, 3). \n\nAs for joint ST-GST, at each scale, the joint graph filter forces the spatial and temporal domains to share the same set of filter coefficients and length. Therefore, such kind of \u201c``forced equality\u201d with respect to spatial and temporal domains exists not only for the number of scales, but also for the filter coefficients and filter length at each scale. All these limitations can restrict the performance of the joint ST-GST and make it not comparable to the performance of the separable ST-GST. Moreover, we believe that the fundamental limitation of joint ST-GST is the shared filter coefficients and length, as the product graph contains both spatial and temporal connections, and so we cannot adapt the filter coefficients and length separately along space and time (see also response to (Q1)). We have run a toy experiment to support our claim. Note that 20 independent trails are run for each setting to obtain the mean and standard deviation of classification accuracy. For MSR Action3D dataset, with the other environment setting the same as stated in our manuscript, separable ST-GST (5, 5, 3) can achieve the accuracy of $73.4\\\\%\\\\pm 0.8\\\\%$, while joint-Kronecker-product ST-GST (5, 3) with $46.3\\\\%\\\\pm 1.2\\\\%$, joint-Cartesian-product ST-GST (5, 3) with $42.2\\\\%\\\\pm 1.1\\\\%$ and joint-strong-product ST-GST (5, 3) with $45.0\\\\%\\\\pm 1.2\\\\%$. We can see that even if the number of scales/filters is the same for the spatial and temporal domains, separable ST-GST still outperforms all joint ST-GST methods by a huge margin.\n\n(Q3) \"Add standard deviations in low-data regime to understand the differences between the different joint approaches\"\n\nWe thank Reviewer 4 for this valuable suggestion. Due to the time limit of discussion phase we are not able to run all our experiments multiple times now, but we have rerun part of our experiments on MSR Action3D dataset, especially for joint approaches, to obtain the standard deviations of classification accuracy. The new results with standard deviations are listed here. Note that 20 independent trails are run for each setting here.\n\n* Separable ST-GST (5, 5, 3): $73.4\\\\%\\\\pm 0.8\\\\%$\n* Separable ST-GST (5, 20, 3): $86.7\\\\%\\\\pm 0.4\\\\%$\n* Joint-Kronecker-product ST-GST (5, 3): $46.3\\\\%\\\\pm 1.2\\\\%$\n* Joint-Cartesian-product ST-GST (5, 3): $42.2\\\\%\\\\pm 1.1\\\\%$\n* Joint-strong-product ST-GST (5, 3): $45.0\\\\%\\\\pm 1.2\\\\%$\n* Joint-Kronecker-product ST-GST (15, 3): $59.6\\\\%\\\\pm 0.5\\\\%$\n* Joint-Cartesian-product ST-GST (15, 3): $58.6\\\\%\\\\pm 1.0\\\\%$\n* Joint-strong-product ST-GST (15, 3): $60.0\\\\%\\\\pm 1.0\\\\%$\n\nWe can see that the standard deviations are comparable in all these methods, and therefore the conclusion that separable ST-GST consistently outperforms joint ST-GST still holds. If time permits, we will run more experiments and update these results in revised version of this paper.\n\n(Q4) \"Detailed experiment setting\"\n\nIn our experiments, we use the lazy random walk matrix as the graph shift, which is also adopted in geometric graph wavelets. In Section 3.2, we consider graph adjacency matrix (broadly used in graph signal processing literature) for simplicity in notation, because the corresponding eigen-decompositions for three kinds of product graphs have the simple, clear and compact forms (see reference [Big Data Analysis with Signal Processing on Graphs (2014)]). Although similar conclusion can be drawn for the lazy random walk matrix by following the same procedure, the results are much more involved and hard to interpret. Note that other valid and commonly used choices for graph shift are graph Laplacian matrix and its normalized version. We will update the paper to reflect this.\nAs for the choice of nonlinear activation, we use absolute value function. The main reason is that absolute value function is energy-preserving. This follows the same setting with [Invariant Scattering Convolution Networks (2013)] and [Stability of graph scattering transforms (2019)]."}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "cYqH6N0yLh4", "original": null, "number": 6, "cdate": 1605498013283, "ddate": null, "tcdate": 1605498013283, "tmdate": 1605498013283, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "kmONksS5qT", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "Response to the questions raised by Reviewer 3", "comment": "We thank Reviewer 3 for her/his valuable comments and insightful questions for improving the manuscript. We addressed all the comments as described below, and will include this discussion into our revision.\n\n(Q1) \"Motivation of using wavelets to analyze spatio-temporal graph signals\"\n\nHere is our motivation for adopting wavelets into the framework. To design our spatio-temporal graph scattering transform, we need spatio-temporal graph filter banks at each scattering layer, which do not exist before. Meanwhile, for time-series, wavelets are one of the best tools to design filter banks, allowing us to trade-off between the time-frequency resolutions and touching the lower bound of uncertainty principle of the time-frequency representations. Inspired by this, we choose to expand the wavelet techniques to the spatio-temporal graph domain and efficiently design spatio-temporal graph filter banks based on wavelets.\n\n(Q2) \"The performance of joint ST-GST is not comparable to separable ST-GST\"\n\nAs for the experimental results, we actually expect that the performance of joint ST-GST is not comparable to that of separable ST-GST based on our mathematical derivations, which is also the point we are highlighting in the paper. As stated at the end of Section 3.2, separable ST-GST is more flexible in design. The flexibility of separable ST-GST means that we can design different graph filters ($\\mathbf{h}$ and $\\mathbf{g}$ in Eq.(1)) with independent reception fields ($P$ and $Q$ in Eq.(1)) in the spatial and temporal domains. On the other hand, for joint graph filters, filter coefficients and the reception fields in the spatial and temporal domains are bonded together ($\\mathbf{h}$ and $K$ in Eq.(2));  that is, we cannot change the filter or reception field in the spatial domain without changing the corresponding one in the temporal domain. This thus makes the separable graph filters more flexible than the joint graph filters. Moreover, we can choose different number of scales/filters for spatial and temporal domains in separable ST-GST, which is not achievable in joint ST-GST.\n\nIn short, separable ST-GST is more recommended to use in practice because of its flexibility in design, computation efficiency and straightforward interpretation."}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "JOVCyMzH27d", "original": null, "number": 5, "cdate": 1605486913923, "ddate": null, "tcdate": 1605486913923, "tmdate": 1605486913923, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "oQr0DQ6LseM", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "Response to the questions raised by Reviewer 2", "comment": "We thank Reviewer 2 for her/his valuable comments for improving the manuscript. We addressed all the comments as described below.\n\nAs shown in Table 2, in large-scale dataset where the training data is **abundant**, ST-GST can outperform many simple deep learning methods, such as deep LSTM, PA-LSTM and ST-LSTM+TG; however, it can hardly outperform the SOTA networks, such as ST-GCN. But in practice, obtaining a huge amount of training data with high-quality labels could be extremely expensive. Most spatio-temporal graph neural network based methods can be easily trapped into bad local optima due to overfitting when the size of training set is limited, resulting in a significant drop of classification accuracy. On the other hand, since ST-GST is a non-trainable framework, filter coefficients are mathematically designed instead of trained by data, so ST-GST can perform much better than ST-GCN when the training ratio (fraction of data used for training in training set) is low. For example, Figure 3(a) shows that ST-GST outperforms ST-GCN by $15\\\\%$ when training ratio is $5\\\\%$ for NTU-RGB+D dataset. Another advantage of ST-GST compared to ST-GCN is that it requires less computation resources because no training process is involved in ST-GST. Moreover, since ST-GST is a mathematically designed framework, we are able to perform theoretical analysis and the related conclusions potentially shed some light on the design of spatio-temporal graph neural networks. The stability of ST-GST may improve the design of ST-GCNs, which are often vulnerable to small perturbations added to training data.\n\nTo further improve the empirical performance of ST-GST on large-scale datasets, we also plan to introduce some trainable parameters into our current scattering architecture for future work. In this case we may be able to boost the classification accuracy, and find a trade-off between stability and empirical performance. One potential direction is related with this paper [Scattering GCN: Overcoming Oversmoothness in Graph Convolutional Networks (2020)]."}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "O8QBHtNKyDN", "original": null, "number": 2, "cdate": 1605473879891, "ddate": null, "tcdate": 1605473879891, "tmdate": 1605473879891, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "JyDOKd6n_PA", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment", "content": {"title": "A response to Reviewer 1", "comment": "We thank Reviewer 1 for her/his review of the manuscript. We are also happy to answer any other additional questions or comments that Reviewer 1 may have."}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "CF-ZIuSMXRz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1432/Authors|ICLR.cc/2021/Conference/Paper1432/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Comment"}}}, {"id": "kmONksS5qT", "original": null, "number": 1, "cdate": 1603275897160, "ddate": null, "tcdate": 1603275897160, "tmdate": 1605024446034, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review", "content": {"title": "The Joint Kronecker, Joint Cartesian and Joint Strong, have not achieved the satisfied performance", "review": "The authors propose wavelets for both separable and joint spatio-temporal graphs. And then the authors design a spatio-temporal graph scattering transform (ST-GST), which is a non-trainable counterpart of spatio-temporal graph convolutional networks and a nonlinear version of spatiotemporal graph wavelets. Finally, the proposed SF-GST is conducted by experiments, and the results show that it appears to be effective. However, The authors did not give the explanation of the motivation about why did the STG should be scattered by wavelets. Besides, from the results in Table 1,  the joint versions based on the proposed method. i.e., Joint Kronecker, Joint Cartesian and Joint Strong, have not achieved the satisfied performance, though only separable versions performs best.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118760, "tmdate": 1606915777974, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1432/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review"}}}, {"id": "oQr0DQ6LseM", "original": null, "number": 2, "cdate": 1603879789558, "ddate": null, "tcdate": 1603879789558, "tmdate": 1605024445959, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review", "content": {"title": "Good extension of scattering transform to the spatio-temporal domain", "review": "The authors extend scattering transform to the spatio-temporal domain. The result ST-GST performs well with small size dataset.\n\nPros:\n1.  The authors propose a novel spatio-temporal graph scattering transform.\n2. The authors empirically shows that ST-GST outperform spatio-temporal graph convolutional networks and other non-deep methods in small-scale datasets.\n\n\nQuestions:\n1. We know that scattering-transform cannot do as well as CNN on larger dataset like Imagenet. Does ST-GST also have similar limitations?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118760, "tmdate": 1606915777974, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1432/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review"}}}, {"id": "IJZg2Qdgm9", "original": null, "number": 3, "cdate": 1603894254113, "ddate": null, "tcdate": 1603894254113, "tmdate": 1605024445890, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review", "content": {"title": "A very good extension of the graph scattering transform to the spatio-temporal case", "review": "1/ Summary of the paper\n\nThis paper proposes a novel spatio-temporal graph scattering transform (ST-GST) as an intermediate representation of time-varying signals on graphs, which can then be fed into a simple ML model. Building on previously introduced Graph Scattering Transform (GST), the authors investigate the technical question of how to use both the spatial and temporal dimensions, proposing either a joint construction (GST applied on product graph) or a separate one (keeping both dimensions separate conceptually, while mixing). Theoretical results valid in both cases guarantee stability to noise in the input signal or the spatial graph.\nNumerical experiments show that the proposed method outperforms graph convolutional networks in the small data regime, and get a performance close to the state-of-the-art in the large data regime.\n\n2/ Acceptance decision\n\nAccept. This is a very good paper with novel contributions on the algorithmic side, theoretical guarantees and convincing numerical experiments.\n\n3/ Supporting arguments\n\n- In terms of novelty, this paper is the first to tackle the investigate the construction of a fixed representation of spatio-temporal graphs based on priors, using the graph scattering transform approach.\n- In terms of technical contributions, the paper delves into the interesting technical question of how to build such a transform, a proposes convincing arguments to support its final approach, the separable ST-GST. Further, the authors provide theoretical guarantees of the stability of the ST-GST representation with respect to input and spatial graph variations, based on assumptions on the pre-defined filters used in the transform.\n- Experimental results show that in the very low data regime (MSR Action3D dataset with only 288 training samples), the proposed approach improves upon the graph convolutional networks SOTA by ~5% of accuracy (87 vs 82.2). In the large data regime, the proposed method reaches a performance close to SOTA (73.1 vs 75.8% accuracy). The authors also show that the gap between GCN and ST-GST widens as the number of samples decreases.\n- This paper is well motivated and well written. Although it is quite dense and with involved mathematical operations, it is quite easy to follow.\n\n4/ Additional comments\n\n- The authors do a very nice job of putting the joint and separable graph filters under similar notations (Eq. 1 and 2). When it comes to comparing both approaches at the end of Sec 3.2, I am not sure to understand correctly the statement that the separable approach is more \u00ab\u00a0flexible\u00a0\u00bb than the joint one. While I understand that separability brings an easier interpretability of filter responses in the spatial and temporal domain, it seems also that in terms of polynomials with atoms of the form $\\lambda_s^p \\otimes \\Lambda_t^q$ for various $p$, $q$, the family spanned by separable transforms might be smaller than e.g. the strong product (although I\u2019m not sure). Do you have any more insights in this direction?\n- In the numerical results of Table 1, the separable approach gets the better results with much more scales in the temporal dim (20) than in the spatial one (5). In the joint approaches, a single number of scales (15) is used, and it spans both dimensions. Beyond the computational requirements of the joint approach, do you think this forced equality is an issue for the joint approach?\n- In order to compare the significance of results in the low-data regime, standard deviations would have been appreciated, especially to understand the differences between the different joint approaches.\n- Minor details: which graph shift is used in the experiments reported in the last page of the main paper? In Section 3.2, the authors state $S = A$ (for both spatial, temporal and joint cases), but appendix A defines $S$ as a lazy random walk for geometric graph wavelets and Appendix C states that geometric graph wavelets are used in the main paper. Similarly, which non linear activation is used eventually?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118760, "tmdate": 1606915777974, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1432/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review"}}}, {"id": "JyDOKd6n_PA", "original": null, "number": 4, "cdate": 1604001836268, "ddate": null, "tcdate": 1604001836268, "tmdate": 1605024445824, "tddate": null, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "invitation": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review", "content": {"title": "Official review", "review": "I will add it tomorrow", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1432/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1432/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatio-Temporal Graph Scattering Transform", "authorids": ["~Chao_Pan2", "~Siheng_Chen1", "~Antonio_Ortega1"], "authors": ["Chao Pan", "Siheng Chen", "Antonio Ortega"], "keywords": ["scattering transform", "spatio-temporal graph", "graph neural networks", "skeleton-based action recognition"], "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transform to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and  nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that  the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is  better and computationally more efficient to design the transform based on separable  spatio-temporal graphs than the joint ones; and iii) nonlinearity in ST-GST is critical to empirical performance.", "one-sentence_summary": "We put forth a novel mathematically designed framework \"ST-GST\" to analyze spatio-temporal data.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pan|spatiotemporal_graph_scattering_transform", "supplementary_material": "/attachment/f2a9bd450f0133b73b7f811386e5491fb704e24d.zip", "pdf": "/pdf/7235bad64aa2f91b72c24d2ccadf7a03fb3e47e3.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\npan2021spatiotemporal,\ntitle={Spatio-Temporal Graph Scattering Transform},\nauthor={Chao Pan and Siheng Chen and Antonio Ortega},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=CF-ZIuSMXRz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "CF-ZIuSMXRz", "replyto": "CF-ZIuSMXRz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1432/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118760, "tmdate": 1606915777974, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1432/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1432/-/Official_Review"}}}], "count": 12}