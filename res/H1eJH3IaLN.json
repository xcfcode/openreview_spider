{"notes": [{"id": "H1eJH3IaLN", "original": "H1l9pTP28V", "number": 4, "cdate": 1551883318653, "ddate": null, "tcdate": 1551883318653, "tmdate": 1556119926589, "tddate": null, "forum": "H1eJH3IaLN", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "content": {"title": "EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper4/Authors"], "keywords": ["Network Embedding", "Link Prediction", "Edge Sampling", "Evaluation", "Reproducibility"], "TL;DR": "In this paper we introduce EvalNE, a Python toolbox for automating the evaluation of network embedding methods on link prediction and ensuring the reproducibility of results.", "abstract": "Network embedding (NE) methods aim to learn low-dimensional representations of network nodes as vectors, typically in Euclidean space. These representations are then used for a variety of downstream prediction tasks. Link prediction is one of the most popular choices for assessing the performance of NE methods. However, the complexity of link prediction requires a carefully designed evaluation pipeline to provide consistent, reproducible and comparable results. We argue this has not been considered sufficiently in recent works. The main goal of this paper is to overcome difficulties associated with evaluation pipelines and reproducibility of results. We introduce EvalNE, an evaluation framework to transparently assess and compare the performance of NE methods on link prediction. EvalNE provides automation and abstraction for tasks such as hyper-parameter tuning, model validation, edge sampling, computation of edge embeddings and model validation. The framework integrates efficient procedures for edge and non-edge sampling and can be used to easily evaluate any off-the-shelf embedding method. The framework is freely available as a Python toolbox. Finally, demonstrating the usefulness of EvalNE in practice, we conduct an empirical study in which we try to replicate and analyse experimental sections of several influential papers.", "pdf": "/pdf/16196241416092fa34264de206e77a86cd674f30.pdf", "paperhash": "anonymous|evalne_a_framework_for_evaluating_network_embeddings_on_link_prediction", "_bibtex": null}, "signatures": ["ICLR.cc/2019/Workshop/RML"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "cdate": 1551883316747, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1551883316747, "tmdate": 1551883316747, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}, "tauthor": "OpenReview.net"}, {"id": "rygrHnxeKV", "original": null, "number": 1, "cdate": 1554152508709, "ddate": null, "tcdate": 1554152508709, "tmdate": 1554627188407, "tddate": null, "forum": "H1eJH3IaLN", "replyto": "H1eJH3IaLN", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper4/Official_Review", "content": {"title": "Interesting evaluation", "review": "The paper presents EvalNE, a framework to evaluate the performance of node embedding methods on link prediction tasks, The framework abstracts away many challenges that naturally arise when evaluating node embedding approaches. For instance, the framework supports various techniques to sample nodes for training the node embedding model. It also comes with different baselines-  both learning-based and heuristics-based, thus encouraging reproducibility of prior work on new datasets.\n\nOne caveat is that there is no \"one-size fits all\" solution. For example, I can think of cases where we would want the graph to be sparse (or maybe even disconnected). Nonetheless, the work is a useful contribution for standardizing evaluation of node embedding techniques.\n\nThere are minor grammatical errors like \"this errors\", \"samplig\", \"out knowledge\" etc\n", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper4/Authors"], "keywords": ["Network Embedding", "Link Prediction", "Edge Sampling", "Evaluation", "Reproducibility"], "TL;DR": "In this paper we introduce EvalNE, a Python toolbox for automating the evaluation of network embedding methods on link prediction and ensuring the reproducibility of results.", "abstract": "Network embedding (NE) methods aim to learn low-dimensional representations of network nodes as vectors, typically in Euclidean space. These representations are then used for a variety of downstream prediction tasks. Link prediction is one of the most popular choices for assessing the performance of NE methods. However, the complexity of link prediction requires a carefully designed evaluation pipeline to provide consistent, reproducible and comparable results. We argue this has not been considered sufficiently in recent works. The main goal of this paper is to overcome difficulties associated with evaluation pipelines and reproducibility of results. We introduce EvalNE, an evaluation framework to transparently assess and compare the performance of NE methods on link prediction. EvalNE provides automation and abstraction for tasks such as hyper-parameter tuning, model validation, edge sampling, computation of edge embeddings and model validation. The framework integrates efficient procedures for edge and non-edge sampling and can be used to easily evaluate any off-the-shelf embedding method. The framework is freely available as a Python toolbox. Finally, demonstrating the usefulness of EvalNE in practice, we conduct an empirical study in which we try to replicate and analyse experimental sections of several influential papers.", "pdf": "/pdf/16196241416092fa34264de206e77a86cd674f30.pdf", "paperhash": "anonymous|evalne_a_framework_for_evaluating_network_embeddings_on_link_prediction", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper4/Official_Review", "cdate": 1554124268749, "expdate": 1556236800000, "duedate": 1555372800000, "reply": {"forum": "H1eJH3IaLN", "replyto": "H1eJH3IaLN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/RML/Paper4/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554124268749, "tmdate": 1554627185517, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Paper4/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}, {"id": "SygUJS-BtE", "original": null, "number": 1, "cdate": 1554482398304, "ddate": null, "tcdate": 1554482398304, "tmdate": 1554482398304, "tddate": null, "forum": "H1eJH3IaLN", "replyto": "H1eJH3IaLN", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper4/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EvalNE: A Framework for Evaluating Network Embeddings on Link Prediction", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper4/Authors"], "keywords": ["Network Embedding", "Link Prediction", "Edge Sampling", "Evaluation", "Reproducibility"], "TL;DR": "In this paper we introduce EvalNE, a Python toolbox for automating the evaluation of network embedding methods on link prediction and ensuring the reproducibility of results.", "abstract": "Network embedding (NE) methods aim to learn low-dimensional representations of network nodes as vectors, typically in Euclidean space. These representations are then used for a variety of downstream prediction tasks. Link prediction is one of the most popular choices for assessing the performance of NE methods. However, the complexity of link prediction requires a carefully designed evaluation pipeline to provide consistent, reproducible and comparable results. We argue this has not been considered sufficiently in recent works. The main goal of this paper is to overcome difficulties associated with evaluation pipelines and reproducibility of results. We introduce EvalNE, an evaluation framework to transparently assess and compare the performance of NE methods on link prediction. EvalNE provides automation and abstraction for tasks such as hyper-parameter tuning, model validation, edge sampling, computation of edge embeddings and model validation. The framework integrates efficient procedures for edge and non-edge sampling and can be used to easily evaluate any off-the-shelf embedding method. The framework is freely available as a Python toolbox. Finally, demonstrating the usefulness of EvalNE in practice, we conduct an empirical study in which we try to replicate and analyse experimental sections of several influential papers.", "pdf": "/pdf/16196241416092fa34264de206e77a86cd674f30.pdf", "paperhash": "anonymous|evalne_a_framework_for_evaluating_network_embeddings_on_link_prediction", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper4/Decision", "cdate": 1554482374907, "reply": {"forum": "H1eJH3IaLN", "replyto": "H1eJH3IaLN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554482374907, "tmdate": 1554482378246, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}], "count": 3}