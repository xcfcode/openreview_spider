{"notes": [{"id": "SJeLO34KwS", "original": "ByxV947B8S", "number": 43, "cdate": 1569438830406, "ddate": null, "tcdate": 1569438830406, "tmdate": 1577168291415, "tddate": null, "forum": "SJeLO34KwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "PXinSegCOe", "original": null, "number": 1, "cdate": 1576798685767, "ddate": null, "tcdate": 1576798685767, "tmdate": 1576800949180, "tddate": null, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Decision", "content": {"decision": "Reject", "comment": "As Reviewer 2 pointed out in his/her response to the authors' rebuttal, this paper (at least in current state) has significant shortcomings that need to be addressed before this paper merits acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795710696, "tmdate": 1576800259760, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper43/-/Decision"}}}, {"id": "HklLi_XXjr", "original": null, "number": 3, "cdate": 1573234845632, "ddate": null, "tcdate": 1573234845632, "tmdate": 1573807392878, "tddate": null, "forum": "SJeLO34KwS", "replyto": "Sklf99RT9S", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Thanks For Review #4", "comment": "Sorry for not being clear enough. \n\n1 For the \"error rate\":\n\n As pointed out, we do find that \"reducing error rate by 40%\" may be misunderstanding, we have corrected that to \" number of misclassified cases reduced by 40%\" in the revision. \n \n2 For matrix W:\n\nIn 2.1, the matrix $\\mathbf{W}$ is learned, which is a basic concept for GCNs. See \"Semi-supervised learning with Graph Convolutional Networks\" (https://arxiv.org/abs/1609.02907)\n\n3 For $\\sigma_s$ and $\\sigma_g$:\n\n$\\sigma_s$ and $\\sigma_g$ refer to different activations, detailed expressions are in the Appendix C.1. \n\n4 For the difference in activation:\n\nWe follow \"A Mean Field Theory of Batch Normalization\" (https://openreview.net/forum?id=SyMDXnCcF7) to use pre-activation as an approximate to post-activation. Pre-activation and post-activation does not do much difference on performance of GCNs. We experiment on post-activation just because previous methods use post-activation and we try to add Dimensional reweighting on top of them without changing their structures.\n\nThe theory in our paper can also be applied to post-activation, since the S in the paper is a diagonal and positive matrix, and $\\sigma$ is ReLU activation, thus $\\sigma(SH)=S\\sigma(H)$ , therefore $W\\sigma(SH)+b=WS\\sigma(H)+b$, which is the same as the post-activation format except for the activations on input features/output representations.  We have clarified this in the revision.\n\n5 For the \"variance\":\n\nSorry for that, this is just an inaccurate description, we have already fixed this in the revision. The proposed DrGCN method is not aimed to \"reduce the variance between dimensions\", instead, it is helpful by improving the training stability.\n\n6 Intuiative Explanation of K:\n\nFor the constructed quantity K, our idea is to construct a criterion of the stability of the update based on the result of learning. So the analysis of K is about quantifying the instability we have reduced through our reweighting scheme. \n\n7 For the Construction of S:\n\nOur theoretical analysis provides an insight into the stability of training W, but S is also a parameter to be learned. Directly learning S leads to overfit and does not yield good results. Here our insight of the construction of S is from a widely adopted method in \"Squeeze and Excitation Networks\".(http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html) Though this paper doesn't provide any theoretical analysis or quantified measures, and its method does not directly work for GCNs, it does provide insight on how the construction of S may be good in practice, so we just modified its method to satisfy the GCN structure. \n\nAlso $S$ generated this way is a diagonal positive matrix, therefore $S\\sigma(H)=\\sigma(SH)$\n\nThanks for the helpful comments. We have made a revision to fix the mentioned inappropriate expressions and we have uploaded it."}, "signatures": ["ICLR.cc/2020/Conference/Paper43/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "r1gZTR6jsS", "original": null, "number": 9, "cdate": 1573801657320, "ddate": null, "tcdate": 1573801657320, "tmdate": 1573804735741, "tddate": null, "forum": "SJeLO34KwS", "replyto": "H1l-npVijr", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Thanks for the suggestion.", "comment": "We have included this in Appendix J in the revision. \n\nBy the way, pre-activation can be viewed as post-activation of the previous layer. The only difference is that pre-activation does an activation on input features, which takes away some input information, so the result shall be a little worse.\n\nTherefore the theory in our paper can also be applied to post-activation, since the S in the paper is a diagonal and positive matrix, thus $\\sigma(SH)=S\\sigma(H)$, therefore $W\\sigma(SH)+b=WS\\sigma(H)+b$, which is the same as the post-activation format except for the activation on input features\\output representations.\n\nReally thanks for your suggestions that inspired us to realize this. "}, "signatures": ["ICLR.cc/2020/Conference/Paper43/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "H1l-npVijr", "original": null, "number": 8, "cdate": 1573764521071, "ddate": null, "tcdate": 1573764521071, "tmdate": 1573764521071, "tddate": null, "forum": "SJeLO34KwS", "replyto": "BklU7VlFjS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Thank you for running these experiments", "comment": "Thank you very much for running these experiments. I would suggest you include them in future revisions of your work."}, "signatures": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "BklU7VlFjS", "original": null, "number": 7, "cdate": 1573614622044, "ddate": null, "tcdate": 1573614622044, "tmdate": 1573629002491, "tddate": null, "forum": "SJeLO34KwS", "replyto": "rJl5YULOjr", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "A Quick Result on Pre-activation", "comment": "Hi, \n\nWe do a quick run for the pre-activation for GCN on coraR and citeseerR  (averaged among 20 runs and using the same hyperparameters as post-acv so maybe not fully-optimized.)\n\n                                CoraR   CiteseerR\nPre_acv                   84.7$\\pm$0.7 74.1$\\pm$0.4\nPre_acv+Dr            85.1$\\pm$0.6 74.8$\\pm$0.8\n--------------------------------------------------\nPost-acv(in paper)85.9$\\pm$0.5 74.9$\\pm$0.7 \nPost-acv+Dr           86.8$\\pm$0.5  77.5$\\pm$0.6\n\nIt seems that pre_acv is a little worse than post_acv, and we haven't tuned the hyperparameters and just pick the post_acv hyperparameters (as described in appendix C in paper).  \n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper43/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "rJl5YULOjr", "original": null, "number": 6, "cdate": 1573574274463, "ddate": null, "tcdate": 1573574274463, "tmdate": 1573574274463, "tddate": null, "forum": "SJeLO34KwS", "replyto": "HklLi_XXjr", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Clarification on pre-activation vs post-activation", "comment": "Hi, thanks for your replies. Regarding (4), how do you know if the experimental results for GCNs are fairly similar between pre-activation vs post-activation? Has pre-activation also been done in previous works? And if so, could you also do pre-activation experiments as well, since this is the setting you actually do analyze theoretically? I realize I am asking a bit late in the revision process, so I will not hold the authors to doing this before the deadline, but this is a recommendation I would make for future updates."}, "signatures": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "rygPQTXXjS", "original": null, "number": 5, "cdate": 1573235998726, "ddate": null, "tcdate": 1573235998726, "tmdate": 1573479958089, "tddate": null, "forum": "SJeLO34KwS", "replyto": "Hyxi-Xp6qS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Thanks for Review #1", "comment": "Thanks for your positive feedback on our paper. \n\n1 For the visible diagram of DrGCN\n\nUnfortunately we cannot attach figures in the reply. We have come up with a diagram in Appendix I in the revision. \n\nThanks for the helpful comment. "}, "signatures": ["ICLR.cc/2020/Conference/Paper43/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "SJl8GYmXsr", "original": null, "number": 4, "cdate": 1573234957736, "ddate": null, "tcdate": 1573234957736, "tmdate": 1573479909648, "tddate": null, "forum": "SJeLO34KwS", "replyto": "H1l1V3I-5B", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment", "content": {"title": "Thanks for Review #2", "comment": "Thanks for the comments. \n\n1. About the \"variance reduction\" statement:\n\nThanks for pointing out the inaccurate statement in section 4.3 and abstract, we have already fixed this in the revision. The proposed DrGCN method is not aimed to \"reduce the variance between dimensions\", instead, it's helpful by improving the training stability.\n\n2. About the innovation points of DrGCN:\n\n We propose K to measure the stability increment theoretically in section 3.2 to explain why our method may work, which is different from other feature normalization methods which only brings up a method with better performances. \n\nPrevious methods are not using any normalization methods on Graph Convolutional Networks and the idea of adding an existing feature normalization method like batch-norm or layer-norm on top of the previous SOTAs can achieve improvements in performance on some datasets. However the performances of BN and LN are not quite stable and vary by methods and datasets. Further details of the results of batch-norm and layer-norm are included in Table 12 in the Appendix. On the contrary, the performance gain from DrGCN is more reliable with the support of the stability measure K.\n\n3 About the completeness of the theory of DrGCN:\n\nFor the theoretical part, it is true that our analysis is based on fully-connected networks. We follow the idea that analyses on fully-connected networks can provide insight into more generalized neural network structures. \"A Mean Field Theory of Batch Normalization\" (https://openreview.net/forum?id=SyMDXnCcF7) And our analysis does provide insight since the quantified measure K matches experimental results perfectly. We have made this clear in the revision. \n\nAbout the analysis of the matrix S and the constructed quantity K. Our idea is to construct a criterion of the stability of the update based on the result of learning. So the analysis is about quantifying the instability we have reduced through our matrix S instead of which matrix is directly parametrized. As mentioned in the review, the theory does not fully analysis the effectiveness of DrGCN. However, the theory on the stability measure K for training W is complete and provides very useful insight into the method. Though DrGCN's effectiveness is not fully explained by the stability measure K, it is rather more efficient experimentally when K is small. \n\n4 About the construction of S:\n\nOur theoretical analysis provides an insight into the stability of training W, but S is also a parameter to be learned. Directly learning S leads to overfit and does not yield good results. Here our insight of the construction of S is from a widely adopted method in \"Squeeze and Excitation Networks\".(http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html) Though this paper doesn't provide any theoretical analysis or quantified measures, and its method does not directly work for GCNs, it does provide insight on how the construction of S may be good in practice, so we just modified its method to satisfy the GCN structure. \n\n5 About $\\tilde{A}$ for sampling GCNs:\n\nFor sampling GCNs, yes they do not use a fixed $\\tilde{A}$ on every step of the training process. However the framework does not require any of the weight matrices, including $\\tilde{A}$, to be fixed. W also updates on every step during the training process. The point is that the framework and the proposed DrGCN works for sampling GCNs too.\n\nThanks for the helpful comments. We have made a revision to fix all the mentioned inappropriate expressions and we have uploaded it . "}, "signatures": ["ICLR.cc/2020/Conference/Paper43/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeLO34KwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper43/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper43/Authors|ICLR.cc/2020/Conference/Paper43/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177219, "tmdate": 1576860530710, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper43/Authors", "ICLR.cc/2020/Conference/Paper43/Reviewers", "ICLR.cc/2020/Conference/Paper43/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Comment"}}}, {"id": "H1l1V3I-5B", "original": null, "number": 1, "cdate": 1572068391317, "ddate": null, "tcdate": 1572068391317, "tmdate": 1572972646035, "tddate": null, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a method, known as DrGCN, for reweighting the different dimensions of the node representations in graph convolutional networks (GCN). Specifically, the representation of every node is element-wise multiplied with a weight vector, which is parameterized as a function of the average input node representation, where the function is a two-layer neural network. \n\nAt a conceptual level, this is similar to various existing normalization schemes, such as batch normalization and weight normalization. While it is claimed in Section 4.3 that the difference is that \u201c[batch normalization] reduces variance between samples, while DrGCN reduces variance between dimensions\u201d, I am not sure if this characterization is accurate. Batch normalization actually makes each dimension have unit (sample) variance and so does not make the variance of each dimension small. What it does is to make the sample variance of each dimension equal, which is also what DrGCN tries to do, i.e.: reduce variance across dimensions (since samples in the case of GCNs are the representations of different nodes). DrGCN is also similar to weight normalization because like weight normalization, DrGCN learns a transformation on top of the vanilla representation (in the case of weight normalization, the vanilla representation is the normalized weight vector; in the case of DrGCN, the vanilla representation is the node representation before reweighting). The conceptual contribution therefore seems incremental. \n\nIncremental conceptual contributions would be fine if (1) they result in a surprising theoretical result, or if (2) they result in a surprising improvement in empirical performance. Unfortunately, neither seems to be demonstrated in this paper. \n\nIn the theoretical analysis, there are various occurrences of unjustified leaps of logic; as a result, what is claimed to be shown by the analysis is different from what is actually shown, and it is unclear what is actually shown is substantially related to the proposed method. For example, in Section 3.1, the paper says that \u201cGCNs are different from fully-connected networks only in \\tilde{A}, and degrade to fully-connected networks when \\tilde{A} = I. So, our analysis can be somehow be generalized to DrGCNs.\u201d The first sentence is true; in other words, it says that fully-connected networks are a special case of GCNs when \\tilde{A} = I. However, the second sentence does not follow - just showing a special case (which is what the subsequent analysis does) does not say much about the general case. Relatedly, the architecture that is analyzed is of the form H^l = W^l \\phi(S^l H^{l-1}) + b^l for l = 1, \u2026, k, whereas the architecture that is proposed is H^l = \\phi(W^l S^l H^{l-1} \\tilde{A}^{l} + b^{l}) for l = 1, \u2026, k. The latter cannot be cast as the former unless \\tilde{A} is diagonal. Also, the caveat of the mean field approximation are not stated - whatever result that is shown is only valid at the infinite width limit, which is different from what is claimed in the abstract, which says that \"We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field.\u201d Additionally, the analysis is done in the case where S is directly parameterized, whereas the proposed method parameterizes S as the output of a two-layer neural network. I presume the reason why latter was done in practice because it worked better empirically. Because this is not explained by the analysis, the theory is incomplete, and so this caveat should be clearly stated in the abstract. \n\nIn the experimental results, the performance improvement of DrGCN over layer normalization is not statistically significant. Also, DrGCN is only compared to other normalization schemes (batch normalization and layer normalization) on one dataset, and so there is insufficient evidence to conclude that DrGCN generally works better than existing methods empirically, \n\nAdditionally, in section 2.1, it is claimed that \u201csampling-based GCNs still lie within the framework of equation (2), as we can set all unsampled edges to 0 in \\tilde{A}\u201d. This does not seem to be accurate, because in sample-based GCNs, different edges are sampled in every minibatch, and so there is no fixed choice of \\tilde{A} that makes these GCNs equivalent to the formulation in eq. (2). \n\nAlso, if the goal is to reduce variance across dimensions (as the paper claims in Section 4.3), why was the average node representation fed into the two-layer neural network rather than its reciprocal?"}, "signatures": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575778452705, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper43/Reviewers"], "noninvitees": [], "tcdate": 1570237757979, "tmdate": 1575778452722, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Review"}}}, {"id": "Hyxi-Xp6qS", "original": null, "number": 2, "cdate": 1572881154554, "ddate": null, "tcdate": 1572881154554, "tmdate": 1572972645990, "tddate": null, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper is out of my research area. I could only provide little recommendation. I have tried to read this paper, but it was rather tedious with heavy notations. It would be more friendly to represent the models in visible way for example using diagrams as I can see that the model is a sequence matrix operators with non-linear transformations after that. The paper states that the proposed DrGCNs can improve the stability of GCN models via mean field theory. The experiments were conducted  on benchmark datasets and the proposed method was compared to several GCN variations. "}, "signatures": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575778452705, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper43/Reviewers"], "noninvitees": [], "tcdate": 1570237757979, "tmdate": 1575778452722, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Review"}}}, {"id": "Sklf99RT9S", "original": null, "number": 3, "cdate": 1572887177619, "ddate": null, "tcdate": 1572887177619, "tmdate": 1572972645948, "tddate": null, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "invitation": "ICLR.cc/2020/Conference/Paper43/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This paper proposes a method called \"Dimensional Reweighting\" for graph convolutional networks. The method involves a reparametrization of GCNs (by adding an extra reweighting block in each layer), which the authors show theoretically can reduce variance. The authors supplement this with extensive empirical experiments showing slightly improved performance by adding their method to existing methods.\n\nI would vote to weakly reject this paper for two key reasons - first, I think the writing can be improved and explanations can be clarified, especially for people less familiar with the field like myself. Second, I am not certain how significant the final experimental improvements are (other than on the Reddit dataset), as most of the numbers are not that far apart, and it seems that different methods in the literature already produce fairly different results.\n\nOverall, I think the structure of the paper is fairly good. I feel that a few things should be modified for clarity.\n- You claim a 40% improvement in error rate in the intro, which sounds enormous. I would say \"relative error rate\" to avoid overclaiming, because 40% improvement sounds like you are reducing (absolute) error from 60% to 20%, while in reality you are reducing error from 3.6% to 2.1%.\n- In section 2.1, did not know if the projection matrix W was learned or predefined.\n- I was not sure why you used sigma_g and sigma_s as opposed to just sigma in equation (5). Do you use different activation functions? Also, I did not find what activation function the authors end up using in their experiments.\n- I may have misunderstood something, but the theory does not seem to match the proposed method exactly. The mean-field theory analysis has the activation function after the reweighting by S but before multiplying by W, while the framework in Section 2.2 has the activation after the reweighting by S and after the multiplying by W. I am not sure how much this difference makes, or if it is significant, but I think it should be explained by the authors.\n- I also did not understand exactly what the \"variance\" the authors are reducing is. The authors talks about \"reducing the learning variance brought by perturbations on the input,\" but when is the input ever perturbed for GCNs? Explaining this more clearly would improve the motivation for this work.\n- I would appreciate a better intuitive explanation of the measure \"K.\" I gather that it is related to the \"variance\" being reduced, but it is different from that.\n\nThe experimental results are good overall, as the proposed method tends to give the best results (by a small margin) across the board. I especially appreciate that the authors performed many experiments over many different datasets and repeated runs 20 times to try to get confident estimates of how well each method performs. I also appreciate that the authors cleaned up the Citeseer and Cora datasets, and I hope the cleaned datasets will be useful for the research community.\nWith that said, I do not know how significant the improvement is. I think something that would be helpful would be to measure the \"variance\" that the method is supposed to be reducing (since it sounds like it is not exactly the same thing as K), and showing that in a table as well. This would show experimentally that the method achieves its intended goal.\n\nMinor comments\n- I would recommend that the authors proofread for English grammar and style in updated versions of the paper. For example, in the first paragraph of the introduction, the authors use \"is proposed\" instead of \"were proposed\" and typo \"broad\" as \"board.\"\n- Just curious, why did you choose a 2 layer network with 2 activation functions for the Dr block? Why not just have 1 hidden layer?"}, "signatures": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper43/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zoux18@mails.tsinghua.edu.cn", "jqy@stanford.edu", "zhangjianwei.zjw@alibaba-inc.com", "ericzhou.zc@alibaba-inc.com", "yaozijun@bupt.edu.cn", "yang.yhx@alibaba-inc.com", "jietang@tsinghua.edu.cn"], "title": "Dimensional Reweighting Graph Convolution Networks", "authors": ["Xu Zou", "Qiuye Jia", "Jianwei Zhang", "Chang Zhou", "Zijun Yao", "Hongxia Yang", "Jie Tang"], "pdf": "/pdf/527c97fd66dfc8eb44d55309ad1ac34782a861af.pdf", "TL;DR": "We propose a simple yet effective reweighting scheme for GCNs, theoretically supported by the mean field theory.", "abstract": "In this paper, we propose a method named Dimensional reweighting Graph Convolutional Networks (DrGCNs), to tackle the problem of variance between dimensional information in the node representations of GCNs. We prove that DrGCNs can reduce the variance of the node representations by connecting our problem to the theory of the mean field. However, practically, we find that the degrees DrGCNs help vary severely on different datasets. We revisit the problem and develop a new measure K to quantify the effect. This measure guides when we should use dimensional reweighting in GCNs and how much it can help. Moreover, it offers insights to explain the improvement obtained by the proposed DrGCNs. The dimensional reweighting block is light-weighted and highly flexible to be built on most of the GCN variants. Carefully designed experiments, including several fixes on duplicates, information leaks, and wrong labels of the well-known node classification benchmark datasets, demonstrate the superior performances of DrGCNs over the existing state-of-the-art approaches. Significant improvements can also be observed on a large scale industrial dataset.", "code": "https://drive.google.com/open?id=1VvqiJqXDxL-yLY2Y8iasEU8qxjvrYQdR", "keywords": ["graph convolutional networks", "representation learning", "mean field theory", "variance reduction", "node classification"], "paperhash": "zou|dimensional_reweighting_graph_convolution_networks", "original_pdf": "/attachment/5ee45d5f54f36912ae62e1b973a3c07f52ae6959.pdf", "_bibtex": "@misc{\nzou2020dimensional,\ntitle={Dimensional Reweighting Graph Convolution Networks},\nauthor={Xu Zou and Qiuye Jia and Jianwei Zhang and Chang Zhou and Zijun Yao and Hongxia Yang and Jie Tang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeLO34KwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeLO34KwS", "replyto": "SJeLO34KwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper43/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575778452705, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper43/Reviewers"], "noninvitees": [], "tcdate": 1570237757979, "tmdate": 1575778452722, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper43/-/Official_Review"}}}], "count": 12}