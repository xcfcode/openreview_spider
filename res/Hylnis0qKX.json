{"notes": [{"id": "Hylnis0qKX", "original": "B1e-lucqKm", "number": 657, "cdate": 1538087843832, "ddate": null, "tcdate": 1538087843832, "tmdate": 1545355418911, "tddate": null, "forum": "Hylnis0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["jiahongo@stanford.edu", "guanhua@stanford.edu", "enhaog@stanford.edu", "ktchen@stanford.edu", "pauly@stanford.edu", "gregz@stanford.edu"], "authors": ["Jiahong Ouyang", "Guanhua Wang", "Enhao Gong", "Kevin Chen", "John Pauly and Greg Zaharchuk"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "ouyang|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@misc{\nouyang2019taskgan,\ntitle={Task-{GAN} for Improved {GAN} based Image Restoration},\nauthor={Jiahong Ouyang and Guanhua Wang and Enhao Gong and Kevin Chen and John Pauly and Greg Zaharchuk},\nyear={2019},\nurl={https://openreview.net/forum?id=Hylnis0qKX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJeimXVvkE", "original": null, "number": 1, "cdate": 1544139554590, "ddate": null, "tcdate": 1544139554590, "tmdate": 1545354496203, "tddate": null, "forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper657/Meta_Review", "content": {"metareview": "This work presents a reconstruction GAN with an additional classification task in the objective loss function. Evaluations are carried out on medical and non-medical datasets. \n\nReviewers raise multiple concerns around the following:\n\n- Novelty (all reviewers)\n- Inadequate comparison baselines (all reviewers)\n- Inadequate citations. (R2 & R3)\n\nAuthors have not offered a rebuttal. Recommendation is reject. Work may be more suitable as an application paper for a medical conference or journal. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Reconstruction GAN with additional classification task, but lacking novelty, evaluation, and references."}, "signatures": ["ICLR.cc/2019/Conference/Paper657/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper657/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["jiahongo@stanford.edu", "guanhua@stanford.edu", "enhaog@stanford.edu", "ktchen@stanford.edu", "pauly@stanford.edu", "gregz@stanford.edu"], "authors": ["Jiahong Ouyang", "Guanhua Wang", "Enhao Gong", "Kevin Chen", "John Pauly and Greg Zaharchuk"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "ouyang|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@misc{\nouyang2019taskgan,\ntitle={Task-{GAN} for Improved {GAN} based Image Restoration},\nauthor={Jiahong Ouyang and Guanhua Wang and Enhao Gong and Kevin Chen and John Pauly and Greg Zaharchuk},\nyear={2019},\nurl={https://openreview.net/forum?id=Hylnis0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper657/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353135754, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper657/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper657/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper657/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353135754}}}, {"id": "SyeiqXvxTm", "original": null, "number": 3, "cdate": 1541596051355, "ddate": null, "tcdate": 1541596051355, "tmdate": 1541596051355, "tddate": null, "forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "content": {"title": "An interesting paper but incremental technical contribution ", "review": "In this paper, the authors propose a novel method of Task-GAN of image coupling by coupling GAN and a task-specific network, which alleviates  to  avoid hallucination or mode collapse. In general, the paper is addressing an important problem but I still have several concerns as follows:\n1. The technical contribution is rather incremental since there exist numerous works on introducing another discriminator to GAN, such as Triple-GAN. \n\n2. Actually, as the authors mentioned, GAN is not an appropriate model for image restoration when  accurate image completion is required. The authors are expected to make comparison with methods not based on GAN framework. \n\n3.  The authors should clarify the details on the Task network since it is non-trivial to model a task. \n\n ", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper657/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["jiahongo@stanford.edu", "guanhua@stanford.edu", "enhaog@stanford.edu", "ktchen@stanford.edu", "pauly@stanford.edu", "gregz@stanford.edu"], "authors": ["Jiahong Ouyang", "Guanhua Wang", "Enhao Gong", "Kevin Chen", "John Pauly and Greg Zaharchuk"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "ouyang|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@misc{\nouyang2019taskgan,\ntitle={Task-{GAN} for Improved {GAN} based Image Restoration},\nauthor={Jiahong Ouyang and Guanhua Wang and Enhao Gong and Kevin Chen and John Pauly and Greg Zaharchuk},\nyear={2019},\nurl={https://openreview.net/forum?id=Hylnis0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "cdate": 1542234409636, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper657/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335773835, "tmdate": 1552335773835, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper657/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Hkgnx5Gtn7", "original": null, "number": 2, "cdate": 1541118451827, "ddate": null, "tcdate": 1541118451827, "tmdate": 1541533800916, "tddate": null, "forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "content": {"title": "Novelty is limited and explanation is not clear", "review": "Authors propose to augment GAN-based image restoration with another task-specific branch such as classification tasks for further improvement.\n\nHowever, the novelty is limited and not well explained.\n1. The idea of adding a task-specific branch has been proposed in Huang et al\u2019s work.\nRui Huang, Shu Zhang, Tianyu Li, Ran He, Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis, ICCV 2017.\n\n2. It is not clear why for task-specific loss authors use mse loss instead of cross-entropy loss.\n3. It is not clear how much data is used to train the super-resolution model and whether there is overlap between training data for super-resolution task and test data for recognition task.\n4. The proposed method is not compared with other super-resolution methods.\n5. There are typos with citations. There should be parenthesis around citations.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper657/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["jiahongo@stanford.edu", "guanhua@stanford.edu", "enhaog@stanford.edu", "ktchen@stanford.edu", "pauly@stanford.edu", "gregz@stanford.edu"], "authors": ["Jiahong Ouyang", "Guanhua Wang", "Enhao Gong", "Kevin Chen", "John Pauly and Greg Zaharchuk"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "ouyang|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@misc{\nouyang2019taskgan,\ntitle={Task-{GAN} for Improved {GAN} based Image Restoration},\nauthor={Jiahong Ouyang and Guanhua Wang and Enhao Gong and Kevin Chen and John Pauly and Greg Zaharchuk},\nyear={2019},\nurl={https://openreview.net/forum?id=Hylnis0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "cdate": 1542234409636, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper657/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335773835, "tmdate": 1552335773835, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper657/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJl0F0-r2Q", "original": null, "number": 1, "cdate": 1540853382382, "ddate": null, "tcdate": 1540853382382, "tmdate": 1541533800712, "tddate": null, "forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "content": {"title": "Interesting applications but limited novelty and poorly selected baseline methods. ", "review": "This paper proposed a new method for image restoration based a task-discriminator in addition to the GAN network. It shows superior performance than the baseline methods without such task-discriminator on medical image restoration and image super-resolution. While the results are better, the idea seems straightforward and has limited novelty. Please see the following comments:\n\n1. Adding an task-discriminator in a GAN network seems straightforward to improve the specific task. And this idea has already used in existing papers, e.g. Cycada.  \n\nHoffman, J., Tzeng, E., Park, T., Zhu, J.Y., Isola, P., Saenko, K., Efros, A.A. and Darrell, T., 2017. Cycada: Cycle-consistent adversarial domain adaptation. ICML, 2018\n\n2. On the application side, the results are not very convincing because the baseline methods were not selected properly. For medical image reconstruction and image super-resolution, the proposed method was not compared with any of the state-of-the-art methods, but only with the same method without a task-discriminator as a baseline. For those tasks, there are many traditional methods and deep nets with different losses. For example, a simple L1/L2 or perceptual loss probably leads to better PSNR than the GAN loss, which is not compared at all. See the attached references. \n\n\nLedig, C., Theis, L., Husz\u00e1r, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A.P., Tejani, A., Totz, J., Wang, Z. and Shi, W., Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network. In CVPR 2017.\n\nJohnson, J., Alahi, A. and Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution. In ECCV 2016.\n\nKim, J., Kwon Lee, J. and Mu Lee, K., Accurate image super-resolution using very deep convolutional networks. In CVPR 2016.\n\n3. Some questions about medical image datasets. For the low-dose PET dataset, the input was randomly undersampled by a factor of 100. What is the random pattern? Is it uniform? In addition, why not acquire real low-dose data and show the quality results using the proposed model? For the multi-constast MRI data, how is the input generated and what is the ground-truth? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper657/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Task-GAN for Improved GAN based Image Restoration", "abstract": "Deep Learning (DL) algorithms based on Generative Adversarial Network (GAN) have demonstrated great potentials in computer vision tasks such as image restoration. Despite the rapid development of image restoration algorithms using DL and GANs, image restoration for specific scenarios, such as medical image enhancement and super-resolved identity recognition, are still facing challenges. How to ensure visually realistic restoration while avoiding hallucination or mode- collapse? How to make sure the visually plausible results do not contain hallucinated features jeopardizing downstream tasks such as pathology identification and subject identification?\nHere we propose to resolve these challenges by coupling the GAN based image restoration framework with another task-specific network. With medical imaging restoration as an example, the proposed model conducts additional pathology recognition/classification task to ensure the preservation of detailed structures that are important to this task. Validated on multiple medical datasets, we demonstrate the proposed method leads to improved deep learning based image restoration while preserving the detailed structure and diagnostic features. Additionally, the trained task network show potentials to achieve super-human level performance in identifying pathology and diagnosis.\nFurther validation on super-resolved identity recognition tasks also show that the proposed method can be generalized for diverse image restoration tasks.", "keywords": ["Task-GAN: Improving Generative Adversarial Network for Image Restoration"], "authorids": ["jiahongo@stanford.edu", "guanhua@stanford.edu", "enhaog@stanford.edu", "ktchen@stanford.edu", "pauly@stanford.edu", "gregz@stanford.edu"], "authors": ["Jiahong Ouyang", "Guanhua Wang", "Enhao Gong", "Kevin Chen", "John Pauly and Greg Zaharchuk"], "TL;DR": "Couple the GAN based image restoration framework with another task-specific network to generate realistic image while preserving task-specific features.", "pdf": "/pdf/ed29a570e5bd56040ba4f2170981bb81ec1ab790.pdf", "paperhash": "ouyang|taskgan_for_improved_gan_based_image_restoration", "_bibtex": "@misc{\nouyang2019taskgan,\ntitle={Task-{GAN} for Improved {GAN} based Image Restoration},\nauthor={Jiahong Ouyang and Guanhua Wang and Enhao Gong and Kevin Chen and John Pauly and Greg Zaharchuk},\nyear={2019},\nurl={https://openreview.net/forum?id=Hylnis0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper657/Official_Review", "cdate": 1542234409636, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hylnis0qKX", "replyto": "Hylnis0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper657/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335773835, "tmdate": 1552335773835, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper657/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}