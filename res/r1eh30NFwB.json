{"notes": [{"id": "r1eh30NFwB", "original": "ByeQijFuvB", "number": 1372, "cdate": 1569439412359, "ddate": null, "tcdate": 1569439412359, "tmdate": 1577168289553, "tddate": null, "forum": "r1eh30NFwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "rEaGuI3kDS", "original": null, "number": 1, "cdate": 1576798721767, "ddate": null, "tcdate": 1576798721767, "tmdate": 1576800914822, "tddate": null, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Decision", "content": {"decision": "Reject", "comment": "The paper received mixed reviews: WR (R1,R3) and WA (R2). AC has carefully read reviews and rebuttal and examined the paper. Unfortunately, the AC sides with R1 & R3, who are more experienced in this field than R2, and feels that paper does not quite meet the acceptance threshold. The authors should incorporate the comments of the reviewers and resubmit to another venue. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795707479, "tmdate": 1576800255696, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Decision"}}}, {"id": "rJgx7oKM5B", "original": null, "number": 3, "cdate": 1572145943639, "ddate": null, "tcdate": 1572145943639, "tmdate": 1574290453152, "tddate": null, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "This paper proposes adding additional flow layers on the decoder of VAEs. The authors make two claims\n1. The proposed model achieves better image quality than a standalone Glow.\n2. The proposed model is faster to train than Glows.\nThe intuition is a VAE can learn a distribution close enough to be target distribution, and the Glow only needs to do much less work than standalone Glow, hence faster. Some positive results are reported in the experiments, including better image quality, faster training time, and the Glow indeed sharpens the output of VAEs. \n\nThe paper indeed has some good results, particularly they can achieve it only with single-scale Glows with additive coupling layers. However, I think the claims are not sufficiently supported. Taking point 1 as an example, it is not clear to me why VAE+Glow is better than a standalone Glow. Imagine two models\n\nM1: VAE+Glow (proposed in the paper)\nM2: Glow0+Glow (standalone Glow)\n\nsharing the last \"Glow\" part. M1 is better than M2 implies \"VAE\" is more powerful than \"Glow0\", which I doubt. Similarly, for point 2, it is not clear to me why \"VAE\" is faster than \"Glow0\". I think comparing the proposed model with IAF make more sense, because the proposed model just adds flows to the decoder and the prior. But the relationship with Glows needs to be considered more thoroughly.\n\nAnother confusing detail for me is the two-stage training in Sec. 3.4. The explanation \"likely because the Glow layer is unable to train efficiently with a changing base distribution\" doesn't make sense. Because IAF does successfully train their q-net without 2-stage training. There might be other reasons?\n\nThe baselines are not strong enough. Most importantly, Flow++ [1] reports a likelihood 3.08 on Cifar10 with standalone flows, which should also be a part of the baseline. I also wonders whether the proposed model benefits from deeper model, like standalone flows do. Will standalone flows surpasses the proposed model as the number of layers goes to infinity?\n\n[1] Ho, Jonathan, et al. \"Flow++: Improving flow-based generative models with variational dequantization and architecture design.\" arXiv preprint arXiv:1902.00275 (2019).\n\nFinally, the paper is somewhat incremental. Particularly comparing with VAE-IAF, where this paper just adds flow layers to not only q but also p.\n\nUpdate\n=====\n\nAfter reading the rebuttal I found some of my concerns are unaddressed. (regarding to the two-stage training, and the novelty)\n\nPoint 1 is still not answered. The answer I expect to have is how \"The interaction between two models when they are being stacked may affect the overall performance in such a way that it is more than just the sum of its parts.\" Why are these two models perform particularly well when combined? The purpose of my initial question is for some in-depth analysis and intuition / theory.\n\nTherefore I will keep my score unchanged.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575402747398, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Reviewers"], "noninvitees": [], "tcdate": 1570237738341, "tmdate": 1575402747410, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review"}}}, {"id": "HJex9qu3tH", "original": null, "number": 1, "cdate": 1571748487830, "ddate": null, "tcdate": 1571748487830, "tmdate": 1574249813489, "tddate": null, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "The paper proposes a combination of a conditioned flow-based model with a VAE. The main contribution of the paper is a two-phase training that allows to train the model. Unfortunately, a joint training of the model failed. In general, combining VAEs with flow-based models is an important research direction. Unfortunately, the paper is not clearly written. A lot of details are missing that makes the paper impossible to reproduce and fully understand. Moreover, the most interesting part about training procedure, is discussed superficially. Finally, I find the comparison to SOTA methods disappointing. The authors skipped many recent papers. I do not expect to see SOTA results among all models, but at least comparable results within a group of approaches. However, the authors provide only a small subset of models that makes me wonder whether they are aware of other papers.\n\nRemarks:\n- The following statement is not fully correct:\n\"In our implementation we use a normalizing flow similar in structure to Real NVP Dinh et al. (2016) (which is a special case of autoregressive normalizing flows Papamakarios et al. (2017)), as it allows both efficient training and sampling\"\nReal NVP is a bipartite flow, while Masked Autoregressive Flow is an autoregressive flow. In special cases, these two flows coincide, but their original implementations are different.\n\n- The paper misses a lot of important details. For instance, a reader needs to figure out what is the objective function. Further, the authors do not mention how they deal with images represented by integers. Do they use dequantization as in other papers (e.g., Theis, L., van den Oord, A., and Bethge, M.  A note on the evaluation of generative models. In Workshop Track,ICLR, 2016)?  These are very important details to fully understand the proposed approach. Providing a very general diagram (Figure 1) and generic equations (2-4) are not sufficient. Currently, there are different implementations of flow components, and describing them would be definitely beneficial. Moreover, it is important to show how conditioning is used in the flow model.\n\n- Section 3.4 is incredibly interesting part of the paper and it should be further analyzed. The proposed two-phase is reasonable, but it leaves an open question why a joint training fails. I agree with the authors that a possible explanation is training instability. Nevertheless, I would be more than interested in seeing a more thorough analysis of this phenomenon.\n\n- I do not understand why the authors skipped reporting bpd for CelebA. \n\n- In general, the comparison in Table 2 is far from being complete. For instance, please see the following paper:\nHo, J., Chen, X., Srinivas, A., Duan, Y., & Abbeel, P. (2019). Flow++: Improving flow-based generative models with variational dequantization and architecture design. arXiv preprint arXiv:1902.00275.\nOn Cifar10, current non-autoregressive models are able to achieve 3.08 bpd (Flow++)  and 3.11 bpd (IAF-VAE). This is much better than the reported 3.17 bpd.\n\n- In Section 4.2.2, first line, a number to a figure is missing.\n\n======== AFTER REBUTTAL ========\nI would like to thank the authors for their rebuttal. However, I am not fully satisfied with some answers. First of all, the paper should be clearly written so that a reader could be able to find all necessary details and seamlessly implement the presented idea. If some details do not fit the main text, then they should be included in an appendix. Second, the objective function is an important component of any ML problem and, therefore, it should be included in the paper. Sometimes a verbal description is not sufficient. Third, by conditioning a flow I meant whether the based distribution was conditional or/and a single flow layer was conditioned on z. Currently, there are multiple ways to condition and I was curious which of them was used by the authors. Fourth, I do not believe that achieving nicely looking images is the ultimate task for generative models. However, this is an open discussion. Fifth, I agree, the discussion on why the joint training failed is an incredibly interesting question.\nAgain, I really appreciate all the answers, and I believe that the authors did their best to improve the paper. However, as a reviewer I must look for novelty and evaluate how the paper is readable for others. In my opinion, combining VAE with GLOW is not sufficiently novel idea. If the paper was very clearly written, I would think about rising the paper. However, right now, I decide to keep my original score.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575402747398, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Reviewers"], "noninvitees": [], "tcdate": 1570237738341, "tmdate": 1575402747410, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review"}}}, {"id": "HyxZH1Bnjr", "original": null, "number": 4, "cdate": 1573830457257, "ddate": null, "tcdate": 1573830457257, "tmdate": 1573830457257, "tddate": null, "forum": "r1eh30NFwB", "replyto": "SJx03SXs9S", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your comment. We were actually not aware of this paper before submission. Their model is indeed very similar. The main differences are the type of normalizing flow that is used in the decoder (we use Glow, they use Real NVP), the training method (we use a two-stage approach) and the prior distribution which is learned in ours."}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1eh30NFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1372/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1372/Authors|ICLR.cc/2020/Conference/Paper1372/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157000, "tmdate": 1576860531464, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment"}}}, {"id": "SJxeFpEnjH", "original": null, "number": 3, "cdate": 1573830007713, "ddate": null, "tcdate": 1573830007713, "tmdate": 1573830007713, "tddate": null, "forum": "r1eh30NFwB", "replyto": "HJex9qu3tH", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for their valuable feedback..\n\n\n> In special cases, these two flows coincide, but their original implementations are different\n\nWe are not quite sure how this statement differs from ours. Also, quoting directly from the MAF paper \"the coupling layer used in Real NVP is a special case of the autoregressive layer used in MAF.\"\nIn any case, the remark isn't very important to our paper.\n\n\n> For instance, a reader needs to figure out what is the objective function\n\nWe believe the objective function is already communicated. In words, it is a VAE objective (Eq. 1) with the decoder distribution given by a Glow model (section 3.3) with base distribution given by a diagonal Gaussian conditioned on the latent code. (Eq. 3 and 4). The prior distribution is given by a normalizing flow (section 3.2). Perhaps it could be communicated more clearly, but the information is there.\n\n\n> Further, the authors do not mention how they deal with images represented by integers\n\nWe use the same dequantization method as that used by Glow, i.e. for discrete pixel values in the range [0, 256) we add uniform noise in the range [0, 1).\n\n\n> Currently, there are different implementations of flow components, and describing them would be definitely beneficial\n\nWe use exactly the same implementation as Glow for the decoder flow. We acknowledge that information about the flow used in the prior distribution could be more thorough.\n\n\n> Moreover, it is important to show how conditioning is used in the flow model.\n\nDoes this refer to conditioning on the VAE latent code, or conditioning on the other dimensions within the flow?\nIf it's the former, this should be clear from Equation 4. If it's the latter, we use exactly the same conditioning as Glow.\n\n\n> Section 3.4 is incredibly interesting part of the paper and it should be further analyzed\n\nWe agree that our discussion of this phenomenon is superficial and that a more thorough analysis is warranted.\nUnfortunately we have been unable to produce any satisfactory results before the discussion deadline and so we will endeavour to give more attention to this section in future revisions.\n\n\n> On Cifar10, current non-autoregressive models are able to achieve 3.08 bpd (Flow++)  and 3.11 bpd (IAF-VAE)\n\nOur main concern is image quality, with which likelihood is not totally correlated. For example PixelCNN achieves\nbetter BPD than both models you mentioned, but its generated images are not high quality due to over-generalization. Therefore we prefer to focus on FID score. Please see our response to Reviewer 3 regarding Flow++.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1eh30NFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1372/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1372/Authors|ICLR.cc/2020/Conference/Paper1372/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157000, "tmdate": 1576860531464, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment"}}}, {"id": "Sylf32V2ir", "original": null, "number": 2, "cdate": 1573829801577, "ddate": null, "tcdate": 1573829801577, "tmdate": 1573829801577, "tddate": null, "forum": "r1eh30NFwB", "replyto": "B1e3Kw7atH", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank for the reviewer for their valuable feedback.\n\n\n> I am wondering how the performance will be for the Glow used, if without the VAE part?\n\nWithout the VAE part it will perform very poorly, since it would be only the final layer of the original Glow model which has only 12 channels and so would not be able to effectively capture long range dependencies or model high level structure.\n\n\n> For the bits/dim results for Glow in Table 2, was it computed by yourself or just from the Glow paper?\n\nThe bits/dim was taken from the Glow paper. We only calculated FID ourselves since it is not reported in the original paper.\n\n\n> For the Glow used in experiments, how does its architecture compare with the one used in the original paper?\n\nIt is exactly the same except for being only a single layer on top of the VAE, whereas in the original Glow they use 3 layers for CIFAR-10 with squeeze/split operations inbetween each.\n\n\n> I am a bit surprised to see the results in Table 3 and Figure 3, as Glow has a better FID score but the overall image quality is worse. Is it related to the size of the Glow used?\n\nApologies, we need to do more investigation to understand why our proposal performs worse on FID for the CelebA dataset."}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1eh30NFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1372/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1372/Authors|ICLR.cc/2020/Conference/Paper1372/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157000, "tmdate": 1576860531464, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment"}}}, {"id": "H1eIM2VhoH", "original": null, "number": 1, "cdate": 1573829646136, "ddate": null, "tcdate": 1573829646136, "tmdate": 1573829646136, "tddate": null, "forum": "r1eh30NFwB", "replyto": "rJgx7oKM5B", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewer for their valuable feedback.\n\n\n> sharing the last \"Glow\" part. M1 is better than M2 implies \"VAE\" is more powerful than \"Glow0\"\n\nIf \"Glow0\" is all layers except the last in the original Glow implementation (which is the comparison being made in our paper), then this is indeed true since \"Glow0\" would only model half the number of dimensions of the image with the other half being purely Gaussian noise.\n\nIf you are instead suggesting to add another layer to the original Glow implementation (effectively doubling the depth of the final layer), then we think it would be a more fair comparison to also double the depth of the Glow layer on top of the VAE. At this point however such excessively large models become impractical for common use.\n\nFurthermore, we don't agree with the statement that M1 is better than M2 implies \"VAE\" is more powerful than \"Glow0\". The interaction between two models when they are being stacked may affect the overall performance in such a way that it is more than just the sum of its parts.\n\n\n> it is not clear to me why \"VAE\" is faster than \"Glow0\"\n\nThe reason for this is that the architecture of VAEs is not constrained in any way, unlike that of Glow which is constrained to have triangular Jacobian. Because of this, VAEs are not required to be nearly as deep to achieve the same expressiveness.\n\n\n> I think comparing the proposed model with IAF make more sense\n\nThe underlying VAE of our model is for the most part equivalent to VLAE [1], which is equivalent to a deeper form of IAF. Therefore comparing our proposed model to IAF would be similar to comparing our full model to just the underlying VAE component of our model, which we have already done in Figure 4. The decoder likelihood of IAF assumes independence between pixels, and so results are not as sharp.\n\n\n> Flow++ [1] reports a likelihood 3.08 on Cifar10 with standalone flows, which should also be a part of the baseline\n\nWe would be happy to include Flow++ in our baselines. The main focus of our paper however is image quality and hence we consider FID score more important, and we cannot find a reported FID score for Flow++ and so we would have to train their model ourselves which we did not have time/resources to do before the submission deadline.\nAlso, if we were to compare against Flow++ we think it would make sense to stack a Flow++ layer on top of a VAE for comparison. We will certainly consider this approach in any future revisions."}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1eh30NFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1372/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1372/Authors|ICLR.cc/2020/Conference/Paper1372/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157000, "tmdate": 1576860531464, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Comment"}}}, {"id": "B1e3Kw7atH", "original": null, "number": 2, "cdate": 1571792771745, "ddate": null, "tcdate": 1571792771745, "tmdate": 1572972477251, "tddate": null, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposed a variant of the variational autoencoder, specifically by using a simplified normalizing flow model as the decoder. When compared with Glow, the proposed method is simpler and more efficient to train. The authors applied their algorithm on a few datasets, and showed better or competitive performance, both qualitatively and quantitatively.\n\nThis paper is in general well written. I think the idea looks interesting, although the novelty is a bit incremental, as it basically combined the two well-known models (VAE and Glow). The experimental results showed the promise of the new method, which could be more convincing if applied on larger scale datasets. My detailed comments and questions are as follows.\n1. Regarding training, the authors decomposed it into two phases, i.e., training VAE first and then Glow. The authors also mentioned that jointly training resulted in images with poor qualities. I am curious about how the authors designed the Glow model: Intuitively a larger model may have more modeling capacity, but at the cost of computational cost. Some ablation studies or explanation could be helpful.\n2. The authors claimed at the beginning of Section 3 that the their normalizing flow \"should not need to do as much work as a full marginal normalizing flow model such as Glow\". I am wondering how the performance will be for the Glow used, if without the VAE part? \n3. For the bits/dim results for Glow in Table 2, was it computed by yourself or just from the Glow paper? I saw the FID score was obtained by yourself.\n4. For the Glow used in experiments, how does its architecture compare with the one used in the original paper?\n5. I am a bit surprised to see the results in Table 3 and Figure 3, as Glow has a better FID score but the overall image quality is worse. Is it related to the size of the Glow used?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1372/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1372/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575402747398, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1372/Reviewers"], "noninvitees": [], "tcdate": 1570237738341, "tmdate": 1575402747410, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Official_Review"}}}, {"id": "SJx03SXs9S", "original": null, "number": 1, "cdate": 1572709814380, "ddate": null, "tcdate": 1572709814380, "tmdate": 1572709814380, "tddate": null, "forum": "r1eh30NFwB", "replyto": "r1eh30NFwB", "invitation": "ICLR.cc/2020/Conference/Paper1372/-/Public_Comment", "content": {"title": "Connection to an existing literature", "comment": "Hi,\n\nI wonder if you have seen Deep Variational Inference Without Pixel-Wise Reconstruction (https://arxiv.org/pdf/1611.05209.pdf). I think the picture that illustrates the model in these two works are very similar. Could you please explain their difference?\n\nThanks! "}, "signatures": ["~Zhisheng_Xiao1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Zhisheng_Xiao1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["rogan.o.morrow@gmail.com", "walon@cs.nctu.edu.tw"], "title": "Variational Autoencoders with Normalizing Flow Decoders", "authors": ["Rogan Morrow", "Wei-Chen Chiu"], "pdf": "/pdf/d8e0df2b7afeaa076f0e448e960df6d5365069c9.pdf", "abstract": "Recently proposed normalizing flow models such as Glow (Kingma & Dhariwal, 2018) have been shown to be able to generate high quality, high dimensional images with relatively fast sampling speed. Due to the inherently restrictive design of architecture , however, it is necessary that their model are excessively deep in order to achieve effective training. In this paper we propose to combine Glow model with an underlying variational autoencoder in order to counteract this issue. We demonstrate that such our proposed model is competitive with Glow in terms of image quality while requiring far less time for training. Additionally, our model achieves state-of-the-art FID score on CIFAR-10 for a likelihood-based model.", "keywords": [], "paperhash": "morrow|variational_autoencoders_with_normalizing_flow_decoders", "original_pdf": "/attachment/7bdb18ba1bc1e78af99438deef47e7f029e0f54c.pdf", "_bibtex": "@misc{\nmorrow2020variational,\ntitle={Variational Autoencoders with Normalizing Flow Decoders},\nauthor={Rogan Morrow and Wei-Chen Chiu},\nyear={2020},\nurl={https://openreview.net/forum?id=r1eh30NFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1eh30NFwB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504195678, "tmdate": 1576860565112, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1372/Authors", "ICLR.cc/2020/Conference/Paper1372/Reviewers", "ICLR.cc/2020/Conference/Paper1372/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1372/-/Public_Comment"}}}], "count": 10}