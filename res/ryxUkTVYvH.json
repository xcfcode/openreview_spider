{"notes": [{"id": "ryxUkTVYvH", "original": "rklyPo8HvB", "number": 302, "cdate": 1569438941841, "ddate": null, "tcdate": 1569438941841, "tmdate": 1577168254223, "tddate": null, "forum": "ryxUkTVYvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "4B-9IdtLzW", "original": null, "number": 1, "cdate": 1576798692751, "ddate": null, "tcdate": 1576798692751, "tmdate": 1576800942631, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Decision", "content": {"decision": "Reject", "comment": "This work performs fast controllable and interpretable face completion, by proposing a progressive GAN with frequency-oriented attention modules (FOAM).  The proposed FOAM encourages GANs to highlight more to finer details in the progressive training process. This paper is well written and is easy to understand. While reviewer #1 is overall positive about this work, the reviewer #2 and #141 rated weak reject with various concerns, including unconvincing experiments, very common framework, limited novelty, and the lack of ablation study. The authors provided response to the questions, but did not change the rating of the reviewers. Given the various concerns raised, the ACs agree that this paper can not be accepted at its current state.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795706521, "tmdate": 1576800254595, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper302/-/Decision"}}}, {"id": "BJeLaiLnoB", "original": null, "number": 4, "cdate": 1573837757823, "ddate": null, "tcdate": 1573837757823, "tmdate": 1573837757823, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "rkxBCAd6YH", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We thank the reviewer for the comments and appreciation, and would like to answer the reviewer\u2019s concerns as follows:\n\nQ1: Have you tried to train models without using facial landmarks? Are facial landmarks only for controlling facial expressions?\nYes, we have tried this. It performed worse on face completion tasks without the facial landmarks, especially when the masks were irregular (e.g. second and third images in Figure 6). The predicted facial landmarks (in our current pipeline) provide high level presentations of face structures, which helps the generation process, and enable the control of facial expressions.\n\nQ2:  As I carefully looked at the generated faces, many of them have asymmetric (unbalanced) eyes. Is it due to the predicted facial landmarks?\nThat is right, because the generation process is conditioned on these predicted landmarks. In this work, we have not specifically dealt with the symmetric issue. It will be an interesting topic  for future work, e.g., by introducing a symmetry-induced loss function and/or leveraging more powerful off-the-shelf facial landmark detectors. \n\nQ3: Is there any randomness (random input) involved during completion (generation)? Is this model possible to generate different faces from the same conditional input? &  What happens if the attributes are interpolated rather than zero or one?\nFor the model in this paper, there is no randomness involved. But we made a video demo (not included in this submission) to show the synthesized faces from interpolated attributes (some snapshots of the demo video is added as Figure 15 in the appendix). All of the faces are very natural, and the transitions between attributes (e.g. from smile to not smile, from male to female) are very smooth. It means this model is able to produce a variety of images. The results of soft attribute control will be added into result figures. Randomness can be achieved by attaching a random noise vector to the attribute vector.\n\nQ4: The order of Fig 4 and 5 seems weird.\nWe fixed the layout issue in the revision. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper302/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUkTVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper302/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper302/Authors|ICLR.cc/2020/Conference/Paper302/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173428, "tmdate": 1576860545637, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment"}}}, {"id": "H1x7gVU3sB", "original": null, "number": 2, "cdate": 1573835755456, "ddate": null, "tcdate": 1573835755456, "tmdate": 1573836767273, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "HyxSxA-Rtr", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "We thank the reviewer for the comments and appreciation, and would like to answer the reviewer\u2019s concerns as follows:\n\nQ1:  The novelty, however, is not strong as the simple summation provides reasonable performance as convinced in the progressive growing GAN paper. And there lacks quantitative analysis on ablation study as showed in Figure 4. Therefore, the contributions of each component are not convincing.\nWe would like to point out that the convincing performance by the simple summation in PGGAN is for general unconditional image synthesis, not necessarily  transferrable to the face completion problem. Our ablation study qualitatively supports the necessity of the proposed FOAM, as well as our intuitive analyses after Eqn.3 (page 4). That being said, we agree that it will be better to do a quantitative study in addition to Figure 4.  One challenge in evaluating face completion is that there is no well-accepted metric at present. We conduct a pilot human study for quantitative evaluation, but mainly focus on comparisons between the proposed method and previous state-of-the-art method due to the time-consuming setup of human study. Furthermore, based on the qualitative results shown in Figure 4, we suspect that if performed, the human study may provide consistent evaluation results on the proposed method.   "}, "signatures": ["ICLR.cc/2020/Conference/Paper302/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUkTVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper302/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper302/Authors|ICLR.cc/2020/Conference/Paper302/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173428, "tmdate": 1576860545637, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment"}}}, {"id": "Hyx1gy82oS", "original": null, "number": 1, "cdate": 1573834470774, "ddate": null, "tcdate": 1573834470774, "tmdate": 1573834632606, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "ryxuOhO2cB", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment", "content": {"title": "Response to Reviewer #141 ", "comment": "We thank the reviewer for the comments and appreciation, and would like to answer the reviewer\u2019s concerns as follows:\n\nQ1: \"There are so many works about face synthesis in recent years. Why do the authors only compare with GL and CTX?\"\nWe study face completion with arbitrary masks in this paper, which is a challenging conditional face synthesis, and different from general unconditional face synthesis. GL and CTX are two of the previous state-of-the-art face completion methods.  And, due to the lack of quantitative metrics for image completion (Yeh et al., Yu et al.), we resort to  evaluate these methods with a \u201cgold standard\u201d, i.e., the human study and careful statistical analyses (Figure 9 and appendix A.2). In the human pilot study, it is more accurate and feasible for the observers to compare the pairs of images (e.g. ours vs. CTX or real vs. synthesized). We can already see our method outperformed state-of-the-art method (CTX) significantly. \n\nQ2: \"the authors do not study how each component affects the final performance, which is very important for the reader to understand why it works.\"\nWe provide an ablation study (Figure 4) which qualitatively shows the impact of essential  components (the proposed FOAM and the well-executed loss functions)  of  our  method. \n\nQ3: \"the framework of the proposed method is very common. This paper only follow previous work and lacks new insights about the problem. \"\nWe agree that the overall proposed framework is common, which is based on progressive GANs, one of the most widely used framework in generative learning. But, we would like to point out that we do not only follow previous work. We present a novel FOAM module that are critical for interpretable and controllable high-resolution face completion without any post-processing. The proposed FOAM addresses the common stability issue in training progressive GANs (as compared in the ablation study, Figure 4). We propose a well-executed set of loss functions which are non-trivial for face completion with arbitrary masks. We also obtain state-of-the-art performance. "}, "signatures": ["ICLR.cc/2020/Conference/Paper302/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUkTVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper302/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper302/Authors|ICLR.cc/2020/Conference/Paper302/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173428, "tmdate": 1576860545637, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper302/Authors", "ICLR.cc/2020/Conference/Paper302/Reviewers", "ICLR.cc/2020/Conference/Paper302/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Comment"}}}, {"id": "rkxBCAd6YH", "original": null, "number": 1, "cdate": 1571815116546, "ddate": null, "tcdate": 1571815116546, "tmdate": 1572972612493, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a face completion network that synthesizes the missing part in the face images with GANs. Using facial landmarks and facial attributes, face completion became controllable as both are used as conditional information (input) for the generation (synthesis). Moreover, the proposed Frequency-Oriented Attention Module (FOAM) enables an interpretable coarse-to-fine progressive generative process. The proposed methods show significant improvement in the completion quality.\n\nOverall,  the method shows how the face completion can be controlled and how the face completion is done by improving details. The attentive framework makes possible to do kinds of band-pass filtering. The results are impressive but have some concerns as the following:\n\n- Have you tried to train models without using facial landmarks? Are facial landmarks only for controlling facial expressions?\n- As I carefully looked at the generated faces, many of them have asymmetric (unbalanced) eyes. Is it due to the predicted facial landmarks?\n- Is there any randomness (random input) involved during completion (generation)? Is this model possible to generate different faces from the same conditional input?\n- What happens if the attributes are interpolated rather than zero or one?\n- The order of Fig 4 and 5 seems weird."}, "signatures": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575610658109, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper302/Reviewers"], "noninvitees": [], "tcdate": 1570237754100, "tmdate": 1575610658121, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Review"}}}, {"id": "HyxSxA-Rtr", "original": null, "number": 2, "cdate": 1571851757020, "ddate": null, "tcdate": 1571851757020, "tmdate": 1572972612451, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. It combines the masks, landmarks, corrupted images as inputs to generate completed images in high-resolution. The proposed frequency-oriented attentive module (FOAM) encourages GANs to highlight much more to finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures.\n\nIntegrating the Progressive growing GAN (PGGAN) for high-resolution face completion is an interesting step-up work after the success of PGGAN on high-resolution image generation.\n\nBasically the FOAM is proposed to merge the images from different resolution levels instead of a weighted summation. The novelty, however, is not strong as the simple summation provides reasonable performance as convinced in the progressive growing GAN paper. And there lacks quantitative analysis on ablation study as showed in Figure 4. Therefore, the contributions of each component are not convincing.\n\nUsing Progressive Growing GAN for high-resolution face completion is also studied in [1]. Figure 17, Figure 18, indicates the author used the same structure as used by [1]. However,  [1] is not cited and there is no comparison between these two models in the paper.\n\n[1] Zeyuan Liu, et al  \"High Resolution Face Completion with Multiple Controllable Attributes via Fully End-to-End Progressive Generative Adversarial Networks \""}, "signatures": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575610658109, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper302/Reviewers"], "noninvitees": [], "tcdate": 1570237754100, "tmdate": 1575610658121, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Review"}}}, {"id": "ryxuOhO2cB", "original": null, "number": 3, "cdate": 1572797552057, "ddate": null, "tcdate": 1572797552057, "tmdate": 1572972612410, "tddate": null, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "invitation": "ICLR.cc/2020/Conference/Paper302/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #141", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper aims at the problem of face synthesis. The authors propose a progressive GAN with frequency-oriented attention modules for high resolution and fast controllable and interpretable face completion, which learns face structures from coarse to fine guided by the FOAM. Experiments are conducted to verify the effectiveness of the proposed method. This paper is well written and is easy to understand. \n\n1. The most interesting idea is the frequency-oriented attention modules ,while the idea of structure-aware seems very common in the area.\n\n2. The experiments are unconvincing. There are so many works about face synthesis in recent years. Why do the authors only compare with GL and CTX? Also, the authors do not study how each component affects the final performance, which is very important for the reader to understand why it works.\n\n3. In general, the framework of the proposed method is very common. This paper only follow previous work and lacks new insights about the problem. "}, "signatures": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper302/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive GANs", "authors": ["Zeyuan Chen", "Shaoliang Nie", "Tianfu Wu", "Christopher G. Healey"], "authorids": ["zchen23@ncsu.edu", "snie@ncsu.edu", "tianfu_wu@ncsu.edu", "healey@ncsu.edu"], "keywords": ["Face Completion", "GANs", "Conditional Image Synthesis", "Interpretability", "Frequency-Oriented Attention"], "TL;DR": "Structure-aware and frequency-oriented attentive GANs for high-resolution and fast face completion", "abstract": "Face completion is a challenging conditional image synthesis task. This paper proposes controllable and interpretable high-resolution and fast face completion by learning generative adversarial networks (GANs) progressively from low resolution to high resolution. We present structure-aware and frequency-oriented attentive GANs. The proposed structure-aware component leverages off-the-shelf facial landmark detectors and proposes a simple yet effective  method of integrating the detected landmarks in generative learning. It facilitates facial expression transfer together with facial attributes control, and helps regularize the structural consistency in progressive training. The proposed  frequency-oriented attentive module (FOAM) encourages GANs to attend to only finer details in the coarse-to-fine progressive training, thus enabling progressive attention to face structures. The learned FOAMs show a strong pattern of switching its attention from low-frequency to high-frequency signals. In experiments, the proposed method is tested on the CelebA-HQ benchmark. Experiment results show that our approach outperforms state-of-the-art face completion methods. The proposed method is also fast with mean inference time of 0.54 seconds for images at 1024x1024 resolution (using a Titan Xp GPU).", "pdf": "/pdf/61ad40edfa986c1b72ff38193c15d2ae0ae23e66.pdf", "paperhash": "chen|towards_controllable_and_interpretable_face_completion_via_structureaware_and_frequencyoriented_attentive_gans", "original_pdf": "/attachment/d270f4055dc40332090413cab9d02b4dc576c87d.pdf", "_bibtex": "@misc{\nchen2020towards,\ntitle={Towards Controllable and Interpretable Face Completion via  Structure-Aware and Frequency-Oriented Attentive {\\{}GAN{\\}}s},\nauthor={Zeyuan Chen and Shaoliang Nie and Tianfu Wu and Christopher G. Healey},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUkTVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUkTVYvH", "replyto": "ryxUkTVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper302/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575610658109, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper302/Reviewers"], "noninvitees": [], "tcdate": 1570237754100, "tmdate": 1575610658121, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper302/-/Official_Review"}}}], "count": 8}