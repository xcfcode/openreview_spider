{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124465632, "tcdate": 1518459543807, "number": 190, "cdate": 1518459543807, "id": "BkeoqIywz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BkeoqIywz", "signatures": ["~Zsolt_Zombori1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1522533025423, "tcdate": 1522533025423, "number": 5, "cdate": 1522533025423, "id": "HyFifYT5M", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "forum": "BkeoqIywz", "replyto": "HkNB1JIqM", "signatures": ["ICLR.cc/2018/Workshop/Paper190/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper190/Authors"], "content": {"title": "review is based on a misapprehension of our claims", "comment": "Training on 2000 data points without data augmentation is a different, harder task than training on 60000 data points with heavy data augmentation, and it is meaningless to compare the error rate between these two very different tasks. Obviously, our baseline system achieves error rate below 1% when trained on 50000 MNIST data points, even without data augmentation.\n\nWe strongly believe that improving the accuracy of deep learning models in the small data regime is an important goal, considering the well-known limitations of current deep learning models in this regime. That\u2019s where we have focused our efforts."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222447814, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers", "ICLR.cc/2018/Workshop/Paper190/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222447814}}, "tauthor": "daniel@renyi.hu"}, {"tddate": null, "ddate": null, "tmdate": 1522032444146, "tcdate": 1522032444146, "number": 4, "cdate": 1522032444146, "id": "HkNB1JIqM", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "forum": "BkeoqIywz", "replyto": "rk_fFIxqG", "signatures": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2"], "content": {"title": "Reference", "comment": "The reference regarding to my comment \"a vanilla CNN can achieve 1.19% error rate on MNIST whereas yours is 3.01%\" is: \n\nhttp://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354.\n\nSee the fifth entry from the bottom.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222447814, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers", "ICLR.cc/2018/Workshop/Paper190/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222447814}}}, {"tddate": null, "ddate": null, "tmdate": 1521901476737, "tcdate": 1521901476737, "number": 3, "cdate": 1521901476737, "id": "S1hj1yVcz", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "forum": "BkeoqIywz", "replyto": "B1iAx2fcf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"title": "decision process", "comment": "Dear D\u00e1niel,\n\nOur decisions (in either direction) don't indicate agreement with every point in every review. With hundreds of papers it was not possible to debate and correct every detail with the reviewers. As you have done, authors are free to set the record straight on any details they disagree with.\n\nHowever, two of the program chairs did read a large number of borderline papers -- and made decisions recognizing the variance in the reviews. As is always the case with a space-limited conference, we will have left out papers that will turn out to be important. However, we have done the best that we could, and the decisions are final.\n\nBest wishes,\nTara, Oriol, Marc'Arelio, and Iain."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222447814, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers", "ICLR.cc/2018/Workshop/Paper190/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222447814}}}, {"tddate": null, "ddate": null, "tmdate": 1521670416463, "tcdate": 1521670416463, "number": 1, "cdate": 1521670416463, "id": "rk_fFIxqG", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "forum": "BkeoqIywz", "replyto": "Hy2M0OTdM", "signatures": ["ICLR.cc/2018/Workshop/Paper190/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper190/Authors"], "content": {"title": "Please consider that our MNIST experiments only used 2000 training points", "comment": "\"a vanilla CNN can achieve 1.19% error rate whereas yours is 3.01%\"\nWe are not aware of such a claim in the literature, and would be grateful for a reference. Note that training happened on 2000 randomly sampled data points, rather than the standard 50000 data points.\n\nThank you for spotting the misstatement in Section 2!\n\n\"Second, on CIFAR10, the improvement of using SpectReg (0.03%) is negligible.\"\nIndeed, unlike the MNIST case, SpectReg does not help our network on CIFAR-10. We do not claim that it does, the SpectReg number is only provided for reference. However, DataGrad (double backpropagation) does bring an improvement of 0.43% on this dataset. DataGrad is an old (some would say forgotten) technique, but to our knowledge, our paper is the first where it was used in tandem with modern deep networks, and a classification accuracy improvement was demonstrated. We fully agree that repeated runs are the proper way to establish the significance of the CIFAR-10 improvement. In the meantime please see Table 5 of the longer arxiv version of our paper http://arxiv.org/abs/1712.09936, which shows a quite clear trend in our opinion."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222447814, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper190/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers", "ICLR.cc/2018/Workshop/Paper190/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222447814}}, "tauthor": "daniel@renyi.hu"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582913003, "tcdate": 1520434708257, "number": 1, "cdate": 1520434708257, "id": "Hy2M0OTdM", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Review", "forum": "BkeoqIywz", "replyto": "BkeoqIywz", "signatures": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2"], "content": {"title": "Experiments Need Improvement", "rating": "5: Marginally below acceptance threshold", "review": "This paper compares two gradient regularizers, i.e., (1) penalizing the 2-norm of gradient of loss w.r.t. input and (2) penalizing the 2-norm of randomly projected Jacobian of logits w.r.t. the input. Authors did experiments on MNIST and CIFAR10 to show that gradient regularizers help improve the generalization performance.\n\nMy main concerns are as below:\n(1) The experimental results are not impressive at all. First, the improvement on MNIST does not tell much about the true story since the baseline itself is worse than expectation (a vanilla CNN can achieve 1.19% error rate whereas yours is 3.01%).\nSecond, on CIFAR10, the improvement of using SpectReg (0.03%) is negligible. According to my experience, the variance introduced by random seed on CIFAR10 can sometimes lead to change of performance as large as 0.5%.  I recommend authors run the experiments multiple times and report the average for a fair comparison.\n(2) In section 2, authors claim \"spherical SpectReg is an unbiased estimator of the Frobenius norm of the Jacobian\". To be more precise, I think the statement should be \"squared spherical SpectReg is an unbiased estimator of the squared Frobenius norm of the Jacobian\".\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582912807, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper190/AnonReviewer1"], "reply": {"forum": "BkeoqIywz", "replyto": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582912807}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582836657, "tcdate": 1520598072100, "number": 2, "cdate": 1520598072100, "id": "HyeHnlgtz", "invitation": "ICLR.cc/2018/Workshop/-/Paper190/Official_Review", "forum": "BkeoqIywz", "replyto": "BkeoqIywz", "signatures": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer1"], "content": {"title": "elegant simple idea, incomplete experiments", "rating": "5: Marginally below acceptance threshold", "review": "The paper presents two idea on gradient regularization, one old (double backprop) and one new (spectral regzn of the Jac). Spectral regularization is a neat idea. Experiments on MNIST show it makes a marginal improvement on small data regimes. There is also a CIFAR experiment, which appears (?) to be on the whole dataset.  The results are far from conclusive. A stronger case would be made with something like Fig 1 for CIFAR.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582912807, "id": "ICLR.cc/2018/Workshop/-/Paper190/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper190/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper190/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper190/AnonReviewer1"], "reply": {"forum": "BkeoqIywz", "replyto": "BkeoqIywz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper190/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582912807}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573586295, "tcdate": 1521573586295, "number": 185, "cdate": 1521573585948, "id": "By90RR0Yz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BkeoqIywz", "replyto": "BkeoqIywz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient Regularization Improves Accuracy of Discriminative Models", "abstract": "Regularizing the gradient norm of the output of a neural network with respect to its inputs is a powerful technique, rediscovered several times. This paper presents evidence that gradient regularization can consistently improve classification accuracy on vision tasks, using modern deep neural networks, especially when the amount of training data is small. We introduce our regularizers as members of a broader class of Jacobian-based regularizers. We demonstrate empirically on real and synthetic data that the learning process leads to gradients controlled beyond the training points, and results in solutions that generalize well.", "paperhash": "varga|gradient_regularization_improves_accuracy_of_discriminative_models", "keywords": ["deep learning", "supervised learning", "classification", "regularization", "gradient penalty"], "_bibtex": "@misc{\n  varga2018gradient,\n  title={Gradient Regularization Improves Accuracy of Discriminative Models},\n  author={D\u00e1niel Varga and Adri\u00e1n Csisz\u00e1rik and Zsolt Zombori},\n  year={2018},\n  url={https://openreview.net/forum?id=BkeoqIywz}\n}", "authorids": ["daniel@renyi.hu", "csadrian@renyi.hu", "zombori@renyi.hu"], "authors": ["D\u00e1niel Varga", "Adri\u00e1n Csisz\u00e1rik", "Zsolt Zombori"], "TL;DR": "Penalizing the gradients of a neural network with respect to the inputs improves classification accuracy, especially for small datasets.", "pdf": "/pdf/d78655522026bbad80aa958f37a170402e4e4c52.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 8}