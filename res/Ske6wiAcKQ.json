{"notes": [{"id": "Ske6wiAcKQ", "original": "rJePDX_qK7", "number": 303, "cdate": 1538087780549, "ddate": null, "tcdate": 1538087780549, "tmdate": 1545355419882, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJeRxEAZJE", "original": null, "number": 1, "cdate": 1543787509658, "ddate": null, "tcdate": 1543787509658, "tmdate": 1545354495270, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Meta_Review", "content": {"metareview": "All reviewers agree in their assessment that this paper is not ready for acceptance into ICLR.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Reject"}, "signatures": ["ICLR.cc/2019/Conference/Paper303/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper303/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353263626, "tddate": null, "super": null, "final": null, "reply": {"forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper303/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper303/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper303/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353263626}}}, {"id": "BJlrdnMbAQ", "original": null, "number": 4, "cdate": 1542691948873, "ddate": null, "tcdate": 1542691948873, "tmdate": 1542691948873, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "Bked30s_hm", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "content": {"title": "Thanks for your review and comments! ", "comment": "Our work originally focuses on conversion task for Japanese and Chinese input method. As reviewer mentioned, it is a better contribution if the approach can be demonstrated on other classic tasks.  We choose a simple LSTM model as a baseline for our selective softmax for its simplicity. Choosing complex network architecture is against our core goal: real-time speed. We will clarify that LSTM model is not part of our contribution by updating the introduction part and methodology sections. \n\nWe feel sorry that the model acceleration section is not clearly written at the submission time and left all reviewers questions. We will update his section with a clear algorithm that answers questions reviewers asked. \n\nFor a quick answer right now. \n1. The \"match\" is a conventional dictionary or trie lookup that returns all possible candidates. The process itself is a O(n^2) scan called build lattice. It is the same process for n-gram and the neural model compared in the work.   \n2. The logits are stored for each frame and path, in that way, we can add the missing logits and run softmax again to calculate a new distribution. \n3. For the Japanese conversion task, the lattice is not necessarily well aligned. For example, a candidate word may be long and span a large part of the original sequence. In such case, all the frames within the span of the word need to be updated. That is the time we union the missing vocabularies. In practical, such long word is rare, most of the time, only the recent frames are updated.  \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper303/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621622856, "tddate": null, "super": null, "final": null, "reply": {"forum": "Ske6wiAcKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper303/Authors|ICLR.cc/2019/Conference/Paper303/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621622856}}}, {"id": "BkgoW2z-AQ", "original": null, "number": 3, "cdate": 1542691843384, "ddate": null, "tcdate": 1542691843384, "tmdate": 1542691843384, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "BJlxSBTA3X", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "content": {"title": "Thanks for reviewing and providing very detailed comments! ", "comment": "Use the original comment index here.\n\n1. We concern that the hierarchical softmax has lower performance and no gain in runtime speed. But as pointed out by several reviewers, we will add missing baseline for both hierarchical softmax and self-learning. \n\n2. We would like to focus on the conversion tasks based on the feedbacks. For prediction, there is also some academic work to find top-k candidates. In practice, since prediction only runs every time users finish typing, the delay is not a major issue comparing to the conversion task.\n\n3. We will remove it from the contribution and move it to experiment.  It shows the results to demonstrate that the model is already usable in real products\n    \n4.5.6\n    \nUnfortunately, we didn't make the model acceleration section clearly enough at the submission time. We will update his section with a clear algorithm that answers questions. \n\nFor the Japanese conversion task, the lattice is not necessarily well aligned. For example, in a new frame, we find all the candidates ending at the frame. A candidate word may be long and span a large part of the original sequence. Candidates may have a different span and probabilities paths over these new frames need to be updated.\n\n7.8\n\nThanks for the detailed comment. We will update."}, "signatures": ["ICLR.cc/2019/Conference/Paper303/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621622856, "tddate": null, "super": null, "final": null, "reply": {"forum": "Ske6wiAcKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper303/Authors|ICLR.cc/2019/Conference/Paper303/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621622856}}}, {"id": "HJlsGizZ07", "original": null, "number": 2, "cdate": 1542691603303, "ddate": null, "tcdate": 1542691603303, "tmdate": 1542691603303, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "SyelRMzX6X", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "content": {"title": "Thanks for your review! ", "comment": "It is a good point that the input method is a generic word and has some ambiguity in terms of mobile device, traditional desktop device.  Also, for Asian audiences and English audiences, input method has a slightly different context. We would like to clarify the specific challenge in this work as the conversion takes for input method editor in next version. We will extend the on-device keyboard researches as well. \n\nFor hierarchical softmax, the complexity of the softmax is log(|V|). Assume there are K target words in a frame. Hierarchal Softmax approach requires Klog(|V|) times matrix dot operations to find the probability distribution. The proposed method only runs K times matrix dot operations. Also, due to the word binary encoding choices of Hierarchical Softmax, we doubt its gain from both performance and task accuracy point of view. But as most reviewers pointed out, we believe an analytic comparison is necessary. We will add the experiment results. "}, "signatures": ["ICLR.cc/2019/Conference/Paper303/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621622856, "tddate": null, "super": null, "final": null, "reply": {"forum": "Ske6wiAcKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper303/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper303/Authors|ICLR.cc/2019/Conference/Paper303/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers", "ICLR.cc/2019/Conference/Paper303/Authors", "ICLR.cc/2019/Conference/Paper303/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621622856}}}, {"id": "SyelRMzX6X", "original": null, "number": 3, "cdate": 1541771976476, "ddate": null, "tcdate": 1541771976476, "tmdate": 1541771976476, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "content": {"title": "Weak baseline comparisons and insufficient comparison with prior work", "review": "This paper describes a search space reduction method for neural network based keyboard input methods. The paper discusses two different sampling methods to restrict the vocabulary size during beam search.  \n\nTitle: The title of the paper is too generic to describe what is actually being done in the paper. Input methods in mobile devices could have also meant speech based input or handwriting based input or swipe based input. It would be very convenient for the readers if the authors use more specific wording in the title to clarify that they are talking about neural network based keyboard typing input.\n\nComparison with prior work: Neural network based on-device keyboard input is a research topic with a lot of previous contributions and the existing literature survey seems lacking. Further it does not even cover popular techniques for inference speed-up like hierarchical softmax computation. It would be easier for the reader to appreciate the  contributions of this paper if the authors compare and contrast with more relevant prior work.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper303/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "cdate": 1542234492623, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335694023, "tmdate": 1552335694023, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJlxSBTA3X", "original": null, "number": 2, "cdate": 1541489975627, "ddate": null, "tcdate": 1541489975627, "tmdate": 1541534109765, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "content": {"title": "insufficient novelty, missing competitive baselines", "review": "The paper demonstrates the main challenge of using LSTM-based language models for input method in real time is the huge amount of computation in the softmax. The authors present a system to speed up the inference by avoiding computing the full softmax in the Japanese conversion task, where the number of output words can be limited from the mapping of the input sequence through a lexicon. The experiment result is encouraging in that the proposed incremental selective softmax approach significantly reduces latency over the standard inference with the full softmax computation while not hurting accuracy much. The paper also evaluates the effect of quantization for LSTM LM model compression in terms of size and accuracy.\n\nHowever, there are a few major problems of the paper as follows:\n\n1. The main weakness in the experiment setup is that it misses a few competitive baselines in terms of inference speed, notably hierarchical softmax[1] and self normalization[2]. In the Japanese conversion task in the paper, it only needs to evaluate the scores of limited output words that are given from the mapping of the input sequence through the lexicon. This is exactly like the rescoring setup in speech recognition and machine translation, where self-normalization is typically used for efficient inference to avoid computing the expensive softmax normalization term [2,3]. Assuming the number of selected output words is K and the entire vocabulary size is V, then the time complexity is O(K logV) for the hierarchical softmax, O(K) for self normalization, but O(V) for all the baselines in the paper. Self normalization is simple to implement and works well in practice, while the proposed incremental selective softmax approach in the paper needs an additional step to sample most frequent words to adjust the normalization term. Without showing the self normalization result, I am not convinced that the proposed approach is better and needed.\n\n[1] F. Morin and Y. Bengio. \"Hierarchical Probabilistic Neural Network Language Model,\" in Proc. of AISTATS, 2005,\n[2] J. Devlin et al., \"Fast and Robust Neural Network Joint Models for Statistical Machine Translation,\" in Proc. of ACL, 2014.\n[3] Y. Shi, W. Zhang, M. Cai and J. Liu, \"VARIANCE REGULARIZATION OF RNNLM FOR SPEECH RECOGNITION,\" in Proc. of ICASSP, 2014.\n\n2. The proposed approach would only be useful in speeding up the conversion task, but not applicable to the prediction task where it needs to evaluate all words and choose the top hypotheses. Also how is the latency of the prediction task compared to conversion task? Please also add it to the experiment result.\n\n3. The idea of using quantization for neural network model compression is not novel (even for language model), although it is listed as one of the main contributions in Section 1.\n\nSo in general, I think the paper is insufficient in novelty and missing competitive baselines.\n\nSome specific comments:\n4. Figure 2(b) is not clear what it means, and not referenced anywhere in the paper.\n5. The last 3 lines in Section 3: \"as each path has different missing vocabularies\": Why is that? The candidates of the output words should only depend on the input sequence and the lexicon, based on Eq(1)(2).\n6. It is not clear how to adjust the probability in the second pass of incremental selective softmax. The description \"we compute a union of all missing vocabularies, and then recompute the logits of them in batch.\" is unclear what it means.\n7. Section 4.2: \"is measure with numpy\" -> \"is measured with numpy\".\n8. Section 4.4: It is not clean how \"76x speedup\" is computed from Table 2 since all the time numbers are rounded. Consider also showing one digit after the decimal point.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper303/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "cdate": 1542234492623, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335694023, "tmdate": 1552335694023, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Bked30s_hm", "original": null, "number": 1, "cdate": 1541090991586, "ddate": null, "tcdate": 1541090991586, "tmdate": 1541534109519, "tddate": null, "forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "content": {"title": "Not enough novelty or significance, unsatisfactory experimental evaluations.", "review": "Summary: Authors proposed a model for input method for mobile or desktop devices. The goal is to convert the input sequence (from one language to another) or predict the next word. Their model is based on an LSTM with modified softmax activation function that is adjustable for large vocabulary sizes. They showed experimental results on Japanese BCCWJ data set.\n\nClarity: Paper is well-written and well-organized. Notions and methods are clearly expressed. \n\nOriginality: This paper builds on an LSTM model without enough work or idea to show novelty. \n\nSignificance: It is below average. Using LSTM is a well-known method for these types of tasks in the literature. Incremental selective softmax is potentially a good approach, however, this work lacks showing significant improvement. The experiments are limited and are done only on one data set.\n\nMore detailed comments:\n\n- My concerns about this work are both on modeling aspects and experiments. Authors mainly focus on highlighting the benefits comparing to n-gram models, and briefly discuss the ongoing developments in neural based models. For example sequential modelings using RNN's have shown promising results in capturing long-term dependencies [1]. Unfortunately authors did not include any discussion on how their approach would compare to that framework nor did they present any experimental comparisons to them.\n\n- Although mentioned briefly in the introduction and related work sections, no analytical or experimental comparisons are made to machine translation approaches when their work is closely related to it. I strongly suggest that authors compare their experimental results to some of benchmarks in neural based machine translation discussed in the related works.\n\n- In the incremental selection softmax, they use \"match\" to return all lexicon items matching the partial sequence. How is this done and what are the effects of it on the computational time of the algorithm? Also, It is not clear how authors correct old probabilities in IS softmax step. As mentioned, they add logits of missing vocabulary to the denominators, how do they keep the properties of softmax so that it sums up to 1? And later in the discussion authors mentioned that in practice they compute union of all missing vocabularies, it is not clear how this is done since the advantage of using IS softmax is expressed to be incremental increasing. \n\n[1] A.B. Dieng, C. Wang, J. Gao and J. Paisley. TopicRNN: A recurrent neural network with long-range semantic dependency, International Conference on Learning Representations (ICLR), 2017.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper303/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Real-time Neural-based Input Method", "abstract": "The input method is an essential service on every mobile and desktop devices that provides text suggestions. It converts sequential keyboard inputs to the characters in its target language, which is indispensable for Japanese and Chinese users. Due to critical resource constraints and limited network bandwidth of the target devices, applying neural models to input method is not well explored. In this work, we apply a LSTM-based language model to input method and evaluate its performance for both prediction and conversion tasks with Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax computation during conversion. To solve the issue, we propose incremental softmax approximation approach, which computes softmax with a selected subset vocabulary and fix the stale probabilities when the vocabulary is updated in future steps. We refer to this method as incremental selective softmax. The results show a two order speedup for the softmax computation when converting Japanese input sequences with a large vocabulary, reaching real-time speed on commodity CPU. We also exploit the model compressing potential to achieve a 92% model size reduction without losing accuracy.", "keywords": ["input method", "language model", "neural network", "softmax"], "authorids": ["jiayao@microsoft.com", "shu@nlab.ci.i.u-tokyo.ac.jp", "xinjianl@andrew.cmu.edu", "katsutoshi.ohtsuki@microsoft.com", "nakayama@ci.i.u-tokyo.ac.jp"], "authors": ["Jiali Yao", "Raphael Shu", "Xinjian Li", "Katsutoshi Ohtsuki", "Hideki Nakayama"], "pdf": "/pdf/c288bc4ba40dd3954c66b19fd8bae80380b3c358.pdf", "paperhash": "yao|realtime_neuralbased_input_method", "_bibtex": "@misc{\nyao2019realtime,\ntitle={Real-time Neural-based Input Method},\nauthor={Jiali Yao and Raphael Shu and Xinjian Li and Katsutoshi Ohtsuki and Hideki Nakayama},\nyear={2019},\nurl={https://openreview.net/forum?id=Ske6wiAcKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper303/Official_Review", "cdate": 1542234492623, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Ske6wiAcKQ", "replyto": "Ske6wiAcKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper303/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335694023, "tmdate": 1552335694023, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper303/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}