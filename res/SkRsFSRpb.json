{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730189439, "tcdate": 1508952486067, "number": 91, "cdate": 1518730189429, "id": "SkRsFSRpb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "SkRsFSRpb", "original": "S1piKBR6Z", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": ["rJ4dWt6HM"], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260091293, "tcdate": 1517249637759, "number": 378, "cdate": 1517249637742, "id": "r1CvVk6SM", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "The reviewers found the paper meaningful but noted that they were not convinced by the experiments as they stand and the presentation was dense for them.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515976851305, "tcdate": 1511765479588, "number": 2, "cdate": 1511765479588, "id": "HJlgLNYxf", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "signatures": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Missing some connections", "rating": "5: Marginally below acceptance threshold", "review": "==== UPDATE AFTER REVIEWER RESPONSE\n\nI apologize to the authors for my late response.\n\nI appreciate the reviewer responses, and they are helpful on a number of\nfronts. Still, there are several problematic points.\n\nFirst, as the authors anticipated, I question whether the geometric encoding\noperations can be included in an end-to-end learning setting. I can imagine\nseveral arguments why an end-to-end algorithm may not be preferred, but the\nauthors do not offer any such arguments.\n\nSecond, I am still interested in more discussion of the empirical investigation\ninto the behavior of the algorithm. For example, \"Shortest\" and \"Successful\"\nin Table 1 still do not really capture how close \"successful but not shortest\"\npaths are to optimal.\n\nThe authors have addressed a number of my concerns, but there\nare a few outstanding concerns. Also, other reviewers are much more familiar\nwith the work than myself. I defer to their judgement after the updates.\n\n==== Original review\n\nIn this work, the authors propose an approach to adapt latent representations to account for local geometry in the embedding space. They show modest improvement compared to reasonable baselines.\n\nWhile I find the idea of incorporating information geometry into embeddings very promising, the current work omits a number of key details that would allow the reader to draw deeper connections between the two (specific comments below). Additionally, the experiments are not particularly insightful.\n\nI believe a substantially revised version of the paper could address most of my concerns; still, I find the current version too preliminary for publication.\n\n=== Major comments / questions\n\nThe transformation from context vectors into Fisher vectors is not clear. Presumably, shortest paths in the training data have different lengths, and thus produce different numbers of context vectors. Does the GMM treat all of these independently (regardless of sample)? or is a separate GMM somehow trained for each training sequence? The same question applies to the VLAD-based approach.\n\nIn a related vein, it is not clear to what extent this method depends on the sequential nature of the considered networks. In particular, could a similar approach be applied to latent space embeddings from non-sequential models?\n\nIt is not clear if the geometric encoding operations are differentiable, or more generally, the entire training algorithm is not clear.\n\nThe choice to limit the road network graph feels quite arbitrary. Why was this done?\n\nDeep models are known to be sensitive to the choice of hyperparameters. How were these chosen? was a validation set used in addtion to the training and testing sets?\n\nThe target for training is very unclear. Throughout Sections 1 and 2, the aim of the paper appears to be to learn shortest paths; however, Section 3 states that the \u201cnetwork is capable of learning the adjacency matrix\u201d, and the caption for Figure 2 suggests that \u201c[t]he adjacency matrix is iteratively learnt (sic)....\u201d However, calculating such training error for back-propagation/optimization would seem to rely on *already knowing* the adjacency matrix.\n\nThe performed experiments are minimal and offer very little insight into what is learned. For example, does the model predict \u201cshort\u201d shortest paths better than longer ones? what do the \u201cvalid but not optimal\u201d paths look like? are they close to optimal? what do the invalid paths look like? does it seem to learn parts of the road network better than others? sparse parts of the network? dense parts?\n\n=== Minor comments / questions\n\nThe term \u201ccontext vector\u201d is not explicitly defined or described. Based on the second paragraph in the \u201cFisher encoding\u201d section, I assume these are the latent states for each element in the shortest path sequences.\n\nIs the graph directed? weighted? by Euclidean distance? (Roads are not necessarily straight, so the Euclidean distance from intersection to intersection may not accurately reflect the distance in some cases.)\n\nAre the nodes sampled uniformly at random for creating the training data?\n\nIs the choice to use a diagonal covariance matrix (as opposed to some more flexible one) a computational choice? or does the theory justify this choice?\n\nRoughly, what are the computational resources required for training?\n\nThe discussion should explain \u201ccondition number\u201d in more detail.\n\nDo the \u201cmore precise\u201d results for the Fisher encoding somehow rely on an infinite mixture? or, how much does using only a single component in the GMM affect the results?\n\nIt is not clear what \u201cfeatures\u201d and \u201cdictionary elements\u201d are in the context of VLAD.\n\nWhat value of k was used for K-means clustering for VLAD?\n\nIt is not possible to assess the statistical significance of the presented experimental results. More datasets (or different parts of the road network) or cross-validation should be used to provide an indication of the variance of each method.\n\n=== Typos, etc.\n\nThe paper includes a number of runon sentences and other small grammatical mistakes. I have included some below.\n\nThe first paragraph in Section 2.2 in particular needs to be edited.\n\nThe references are inconsistently and improperly (e.g., \u201cTuring\u201d should be capitalized) formatted.\n\nIt seems like that $q_{ik} \\in \\{0,1\\}$ for the hard assignments in clustering.\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642529938, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer2", "ICLR.cc/2018/Conference/Paper91/AnonReviewer1", "ICLR.cc/2018/Conference/Paper91/AnonReviewer3"], "reply": {"forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642529938}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642530032, "tcdate": 1511643310519, "number": 1, "cdate": 1511643310519, "id": "rkU2dUDlf", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "signatures": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Missing references and insufficient experiments", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes a method for augmenting sequence-to-sequence (seq2seq) methods with Fisher vector encodings, allowing the decoder to better model the geometric structure of the embedding space. Experiments are performed on a shortest-route problem, where augmenting standard seq2seq architectures with Fisher vectors improves performance.\n\nPros:\n- Combining deep learning with methods from information geometry is an interesting direction for research\n- Method is a generic drop-in replacement for improving any seq2seq architecture\n- Experimental results show modest performance improvements over vanilla seq2seq methods\n\nCons:\n- Missing references for prior work combining information geometry and deep learning\n- Insufficient explanation of the method\n- Only experimental results are a nonstandard route-finding task\n- Missing references and baselines for prior work on deep learning on graphs\n\nThe general research direction of combining deep learning with methods from information geometry is an exciting and fertile area for interesting work. Unfortunately this paper fails to cite or discuss much recent work in this area; for example natural gradient methods in deep learning have recently been explored in [1, 2, 3]; more closely related to the topic of this paper, [4] and [5] have combined Fisher vector encodings and deep networks for image classification tasks. Although these prior methods do not consider the use of recurrent networks, the authors should discuss how their method compares to the approaches of [4] and [5].\n\nThe method is not described in sufficient detail. How exactly is the Fisher encoding combined with the recurrent neural network? In particular, how is GMM fitting interleaved with learning the RNN? Do you backpropagate through the GMM fitting procedure in order to jointly learn the RNN parameters and the GMM for computing Fisher encodings? Or is GMM fitting an offline step done once, after which the RNN decoder is learned on top of the Fisher encodings? The paper should clarify along these points. As a side note, it also feels a little disingenuous to describe the method in terms of GMMs, but to perform all experiments with K=1 mixture components; in this setting the GMM degrades to a simple Gaussian distribution.\n\nThe proposed method could in theory be used as a drop-in replacement for seq2seq on any task. Given its generality, I am surprised at the nonstandard choice of route-finding in a graph of Minnesota roads as the only task on which the method is tested; as a minimum the method should have been tested on more than one graph.\n\nMore generally, I would have liked to see the method evaluated on multiple tasks, and on more well-established seq2seq tasks so that the method could be more easily compared with previously published work. Strong results on machine translation would be particularly convincing; the authors might also consider algorithmic tasks such as copying, repeat copying, sorting, etc. similar to those on which Neural Turing Machines were evaluated.\n\nI am not sure that seq2seq is the best approach for the route-finding task. In particular, since the input is encoded as a [source, destination] tuple it has a fixed length; this means that you could use a feedforward rather than recurrent encoder.\n\nThe paper also fails to cite or discuss recent work involving deep learning on graphs. For example Pointer Networks [6] use a seq2seq model with attention to solve convex hull, Delaunnay Triangulation, and traveling salesman problems; however Pointer Networks assume that the entire graph is provided as input to the model, while in this paper the network learns to specialize to a single graph. In that case, the authors might consider embedding the nodes of the graph using methods such as DeepWalk [7], LINE [8], or node2vec [9] as a preprocessing step rather than learning these embeddings from scratch.\n\nFrom Table 1, seq2seq + VLAD significantly outperforms seq2seq + FV. Given these results, are there any reasons why one should use seq2seq + FV instead of seq2seq + VLAD?\n\nOverall I think that this paper has some interesting ideas. However, due to a number of missing references, unclear description of the method, and limited experimental results I feel that the paper is not ready for publication in its current form.\n\n\nReferences\n\n[1] Grosse and Salakhutdinov, \u201cScaling Up Natural Gradient by Sparsely Factorizing the Inverse Fisher Matrix\u201d, ICML 2015\n\n[2] Grosse and Martens, \u201cA Kronecker-factored approximate Fisher matrix for convolution layers\u201d, ICML 2016\n\n[3] Desjardins et al, \u201cNatural Neural Networks\u201d, NIPS 2015\n\n[4] Simonyan et al, \u201cDeep Fisher Networks for Large-Scale Image Classification\u201d, NIPS 2013\n\n[5] Sydorov et al, \u201cDeep Fisher Kernels - End to End Learning of the Fisher Kernel GMM Parameters\u201d, CVPR 2014\n\n[6] Vinyals et al, \u201cPointer Networks\u201d, NIPS 2015\n\n[7] Perozzi et al, \u201cDeepWalk: Online Learning of Social Representations\u201d, KDD 2014\n\n[8] Tang et al, \u201cLINE: Large-scale Information Network Embedding\u201d, WWW 2015\n\n[9] Grover and Leskovec, \u201cnode2vec: Scalable Feature Learning for Networks\u201d, KDD 2016", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642529938, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer2", "ICLR.cc/2018/Conference/Paper91/AnonReviewer1", "ICLR.cc/2018/Conference/Paper91/AnonReviewer3"], "reply": {"forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642529938}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642529953, "tcdate": 1512289443931, "number": 3, "cdate": 1512289443931, "id": "HknoNEWZz", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "signatures": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Incremental contribution and detail missing.", "rating": "5: Marginally below acceptance threshold", "review": "In this paper, the authors propose to integrate the Fisher information metric with the  Seq2Seq network, which abridges the gap between deep recurrent neural networks and information geometry. By considering of the information geometry of the latent embedding, the authors propose to encode the RNN feature as a Fisher kernel of a parametric Gaussian Mixture Model, which demonstrate an experimental improvements compared with the non-probabilistic embedding. \n\nThe idea is interesting. However, the technical contribution is rather incremental. The authors seem to integrate some well-explored techniques, with little consideration of the specific challenges. Moreover, the experimental section is rather insufficient. The results on road network graph is not a strong support for the Seq2Seq model application. \n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642529938, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper91/AnonReviewer2", "ICLR.cc/2018/Conference/Paper91/AnonReviewer1", "ICLR.cc/2018/Conference/Paper91/AnonReviewer3"], "reply": {"forum": "SkRsFSRpb", "replyto": "SkRsFSRpb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642529938}}}, {"tddate": null, "ddate": null, "tmdate": 1515159421583, "tcdate": 1515159421583, "number": 3, "cdate": 1515159421583, "id": "rJLKk-67G", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "forum": "SkRsFSRpb", "replyto": "rkU2dUDlf", "signatures": ["ICLR.cc/2018/Conference/Paper91/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper91/Authors"], "content": {"title": "Response to reviewer 3", "comment": "We thank the Reviewer for his/her comments and for providing useful feedback. Since, we were constrained on time and resources (to train on a machine translation task), in our updated version, we have now introduced two benchmark problems such as copying and recalling sequences. On both problems, the GeoSeq2Seq network has been as successful as the Neural Turing Machine, albeit without a need for an external memory module.\n\nWe have also added a related work section as well as additional information for model construction. In our related work section, we have discussed all of the missing prior work suggested by the Reviewer including, natural neural networks, Fisher vectors for image classification, pointer networks, etc.\n\nAs the work of Sydorov et al. (2014) suggests it is indeed possible to learn the Fisher kernel parameters in an end-to-end manner. In our current work, we have first used the latent vectors learnt using a vanilla Seq2Seq training process to initiate a GMM, and thereof the Fisher kernel, subsequently a decoder is trained on the Fisher kernel to generate a prediction. \n\nIndeed, we agree with the reviewer that a Seq2Seq network may not be the best approach for route finding task; our motivation to use a route finding problem is to enable us to control task difficulty, and not for replacing algorithms such as meta-heuristics, integer programming, etc.\n\nThe idea to embed the nodes of the graph using methods like node2vec, DeepWalk and LINE are very useful and we anticipate them to finesse the accuracy of the GeoSeq2Seq. We would undoubtedly explore this avenue for our future work.\n\nWe have now explained why seq2seq + VLAD significantly outperforms seq2seq + FV and therefore it is preferable to use it instead of seq2seq+FV. We anticipate the performance being directly related to the condition number (the ratio of the largest to smallest singular value in the singular value decomposition of a matrix) of the Fisher Information Matrix."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825739471, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkRsFSRpb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper91/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper91/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper91/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers", "ICLR.cc/2018/Conference/Paper91/Authors", "ICLR.cc/2018/Conference/Paper91/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825739471}}}, {"tddate": null, "ddate": null, "tmdate": 1515159085394, "tcdate": 1515159085394, "number": 2, "cdate": 1515159085394, "id": "SkSV0xp7f", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "forum": "SkRsFSRpb", "replyto": "HJlgLNYxf", "signatures": ["ICLR.cc/2018/Conference/Paper91/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper91/Authors"], "content": {"title": "Response to reviewer 2", "comment": "We thank the Reviewer for his/her comments and for providing useful feedback. We have now included further information for constructing the Fisher Vectors, along with the relevant references in computer vision, where it has been routinely utilised. \n\nShortest paths in the training data do have different lengths, but we build one context vector for each source-destination tuple and all context vectors have the same fixed length (we choose either 256 or 512). We then train the GMM on the context vectors obtained from the training sequences and finally use the means and variances to build the Fisher vectors. Similarly, for the VLAD-based approach, we train the centers and assignments from K-means and KD-trees on the context vectors obtained from the training sequences and use them to generate the VLAD encoding.\n\nThe formulation of the Fisher information metric, in its current form, can be directly applied to latent space embeddings from non-sequential models. However, as mentioned in the discussion: The Riemannian metric for a recurrent network can be evaluated in two ways -- one where we describe the probability distribution over the entire sequence and another where we describe a conditional distribution at time i conditioned on time i-1. We anticipate that the latter is more suited to a dynamic scenario (where the structure of the graph may be slowly changing) while the former is more suitable for static graphs. Analytically, averaging over time and assuming ergodicity, both metric should be fairly close to one another, nonetheless, it is only with further experiments we can demonstrate the value of one over the other. \n \nIt is a very good question whether the geometric encoding operations are differentiable. We anticipate this goes on to enquire if end-to-end training of Fisher encoding for Seq2Seq models can be attained. Infact Sydorov et al. (2014) have shown just this for convolutional neural networks.\n\nThe selection of the road network graph was not arbitrary. In fact,  our motivation for using a route finding problem is to enable us to control task difficulty, and not for replacing algorithms such as meta-heuristics, integer programming, etc. In our updated version, we have added two other algorithmic tasks \u2013 copying and associative recall of sequences.\n\nIn the interest of time and resources, we have not utilised hyper-parameter optimization for this paper. In future, with more compute resources, we anticipate utilizing Bayesian optimization to obtain hyperparameters during the validation phase. Also, we were constrained by time and resources (to train on a machine translation task), in our updated version, we have now introduced two benchmark problems such as copying and recalling sequences. On both problems, the GeoSeq2Seq network has been as successful as the Neural Turing Machine, albeit without a need for an external memory module. Again due to limited computation resources, we had to limit our experiments to a diagonal covariance matrix and K=1 as the number of components of the Gaussian Mixture Model. There is no reason why a full covariance matrix or increases mixture components cannot be used.\n\nOf course, finding shortest routes consisting of few nodes is easier. Since the training set is built by sampling source and destination nodes uniformly at random, we can have routes with many nodes and our algorithm can reproduce the shortest path correctly (see for example Figure 3b). It is also possible to find a route between source and destination nodes that is not the shortest (i.e. the sum of the distances between the nodes in the path is greater than the ground truth one). We reported also the accuracy in this case, because in some application it may be enough to reach the destination even if the path is not the shortest. \u201cInvalid\u201d paths are routes that diverge in wrong directions and do not reach the destination. \n\nThe considered graph is undirected and weighted by Euclidean distance. Roads may not be straight but they can be approximated by straight parts from intersection (node) to intersection (node).\n\nWe have now included a formal definition of the condition number in the main text.\n\nSydorov et al, \u201cDeep Fisher Kernels - End to End Learning of the Fisher Kernel GMM Parameters\u201d, CVPR 2014"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825739471, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkRsFSRpb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper91/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper91/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper91/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers", "ICLR.cc/2018/Conference/Paper91/Authors", "ICLR.cc/2018/Conference/Paper91/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825739471}}}, {"tddate": null, "ddate": null, "tmdate": 1515158972349, "tcdate": 1515158972349, "number": 1, "cdate": 1515158972349, "id": "HyNaTgpmf", "invitation": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "forum": "SkRsFSRpb", "replyto": "HknoNEWZz", "signatures": ["ICLR.cc/2018/Conference/Paper91/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper91/Authors"], "content": {"title": "Response to reviewer 1", "comment": "We thank the Reviewer for his/her comments. The specific challenge that this paper sets to achieve is to come up with a methodology to increase the temporal memory of a recurrent neural network. In order to achieve this, we use utilise the 2nd order geometry of the latent embeddings, instead of invoking an external memory unit, as in the Neural Turing Machine. A road network graph gives us a straightforward way to control the length of temporal information required to be stored by the neural network. An additional benefit of using the road network graph is unlike other benchmark toy problems, a solution to the shortest route problem on graphs not only had an illustrious history but is also a real-life scenario. In our updated version, we have now introduced two benchmark problems such as copying and recalling sequences. We have also added a related work section as well as additional information for model construction."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks", "abstract": "The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\\%.", "pdf": "/pdf/7f663e8970562c400c33f84c08ee3ad1359f7826.pdf", "paperhash": "bay|geoseq2seq_information_geometric_sequencetosequence_networks", "_bibtex": "@misc{\nbay2018geoseqseq,\ntitle={GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks},\nauthor={Alessandro Bay and Biswa Sengupta},\nyear={2018},\nurl={https://openreview.net/forum?id=SkRsFSRpb},\n}", "authors": ["Alessandro Bay", "Biswa Sengupta"], "keywords": [], "authorids": ["alessandro.bay@cortexica.com", "biswasengupta@yahoo.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825739471, "id": "ICLR.cc/2018/Conference/-/Paper91/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "SkRsFSRpb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper91/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper91/Authors|ICLR.cc/2018/Conference/Paper91/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper91/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper91/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper91/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper91/Reviewers", "ICLR.cc/2018/Conference/Paper91/Authors", "ICLR.cc/2018/Conference/Paper91/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825739471}}}], "count": 8}