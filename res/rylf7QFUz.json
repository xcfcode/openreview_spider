{"notes": [{"tddate": null, "ddate": null, "tmdate": 1521670366288, "tcdate": 1521670366288, "number": 1, "cdate": 1521670366288, "id": "H1LkK8e9z", "invitation": "ICLR.cc/2018/Workshop/-/Paper34/Official_Comment", "forum": "rylf7QFUz", "replyto": "rylf7QFUz", "signatures": ["ICLR.cc/2018/Workshop/Paper34/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper34/Authors"], "content": {"title": "Some clarifications", "comment": "First, there seems to be criticism that the paper is not \"finished\". We do not disagree. We viewed the paper more as a combination of position paper and preliminary insight report. This felt appropriate for a workshop submission, but it is of course a judgment call and we respect the decision. We do think it could have generated useful discussion and constructive debate for those interested in compositionality and in designing improved tasks for research in this area.\n\nSecond, there seems to be an unintended interpretation of this paper as a strong \"us vs them\" sort of attack on the original paper (Still not systematic after all these years). This can perhaps be blamed on the titles as suggested by reviewers. But any reader of our paper will see that we think the SCAN tasks raise interesting issues, and we are mostly highlighting topics that seem worthy of further pursuit. This should be seen as more constructively complementary, rather than adversarial.\n\nTo elaborate on our alternate viewpoint on the interestingness of the SCAN tasks:\n\nParsing synthetic languages with regular grammars is not a particularly interesting ends in itself. We already know how to do this, even without machine learning. If we use domain-specific architectures, we can even achieve perfect accuracy with machine learning: See, e.g., https://arxiv.org/abs/1706.01284 (Towards Synthesizing Complex Programs from Input-Output Examples). Similarly, it is probably not too hard to come up with compositional architectures that can solve the SCAN tasks perfectly - but that may tell us preciously little about real-world challenges for machine learning.\n\nThe more interesting issue raised, in our opinion, is that of memorization vs rule learning. As we show, some of the SCAN tasks seem to be excellent test beds for this. It is very easy to achieve 100% train accuracy on the tasks, but the test accuracy can show extremely high variance. The natural hypothesis is that systematicity is not merely a consequence of the architectural choice, but also very strongly of how the architecture is trained.\n\nDeveloping regularization or optimization techniques that can favor rule learning over memorization seems like a very timely topic that could have major implications for other deep learning applications as well.\n\nIn support of this, let us mention that, since submitting the workshop paper, we have found that through different optimization algorithms we can routinely achieve ~90% accuracy with low variance on the addprim_jump task with the exact same architecture (Ptr-Luong) used in this workshop paper.\n\nFinally, the paper one reviewer suggested - Memorize or generalize? Searching for a compositional RNN in a haystack - has some similar findings and we second the recommendation for people interested in this topic. Note that we were not made aware of this paper and it did not appear on arXiv until after we had already submitted our workshop paper.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222450296, "id": "ICLR.cc/2018/Workshop/-/Paper34/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rylf7QFUz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper34/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper34/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper34/Reviewers", "ICLR.cc/2018/Workshop/Paper34/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222450296}}, "tauthor": "mkliegl@gmail.com"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582994059, "tcdate": 1519413374233, "number": 1, "cdate": 1519413374233, "id": "HyUtdJAvM", "invitation": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "forum": "rylf7QFUz", "replyto": "rylf7QFUz", "signatures": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer3"], "content": {"title": "As unsystematic as claimed", "rating": "4: Ok but not good enough - rejection", "review": "This extended article presents experimental work on the recently introduced SCAN tasks. The article ostensibly reports two main findings: 1) standard seq2seq architectures can do much better on these tasks than the basic models used in the original paper; 2) there is much variance in performance, such that the best model across random initializations even achieves 100% accuracy on a task where mean performance is at 17% (!).\n\nPoint 2) is very interesting. I think it would be worth, by itself, a more extended study. The authors might also want to take a look at https://arxiv.org/abs/1802.06467, which makes a similar point.\n\nHowever, I failed to find support for 1) in the reported experiments. Unlike I am misinterpreting the results reported in Table 1, the only considerable improvement that the authors report pertains to the addprim_jump task, where their best model attains 14% accuracy. Now, this is indeed better than the originally reported 1% accuracy, but it is absolutely not justifying the \"more systematic than claimed\" pun in the title! If anything, the results in this table justify the opposite conclusion: even after testing various state-of-the-art models, SCAN is still far from being \"cracked\". The systematicity challenge still stands.\n\nI am not sure about what the simplified_length experiment should demonstrate. To me, it shows that, by removing the most challenging cases from the SCAN length test set, performance greatly improves. Is this surprising? What should we learn from it?\n\nNote that the original Lake & Baroni paper was rejected, so the citation should be of the unpublished arXiv manuscript.\n\nTo summarize, I found the second part of the article interesting, and it would be great to see it extended. However, I am giving a low score because the title and the claims made in the first part seem actively misleading.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582993830, "id": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper34/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer1"], "reply": {"forum": "rylf7QFUz", "replyto": "rylf7QFUz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582993830}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582867070, "tcdate": 1520555970550, "number": 2, "cdate": 1520555970550, "id": "HkcavUyKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "forum": "rylf7QFUz", "replyto": "rylf7QFUz", "signatures": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer2"], "content": {"title": "Some intriguing results but more a pile of puzzling experiments than a result", "rating": "4: Ok but not good enough - rejection", "review": "Summary:\n\nThis paper revisits the SCAN tasks  introduced in a (rejected, invited to workshop track) ICLR 2018 paper, which convert simplified English to a simple formal semantics action sequence and suggests that sequence models can do them rather better than the results reported in the original paper (Lake and Baroni 2018). They emphasize model selection, regularization and ensembling.\n\nNovelty:\n\nNone really, but some interesting first cut results on this new dataset\n\nClarity:\n\nClear enough on what was done, not necessarily on what it means.\n\nSignificance:\n\nSome interesting puzzle, not a lasting result\n\nQuality: \n\nWritten up well enough but this seems a progress report on early results. Maybe that's what a workshop paper is meant to be, but this feels maybe too early.\n\n\nPros:\n\n- If the Lake and Baroni paper is being presented at the ICLR 2018 workshop track, this would be a nice complement: It not only could generate debate, but shows that you can do considerably better than Lake and Baroni report in their paper.\n\nCons:\n\n- This paper feels like someone who has done their first bunch of experiments and has some sort of interesting results in a we-don't-really-understand-what's-going-on way, but there isn't any new model, or new understanding or clear answer to the major puzzles. I suspect that the work would benefit from further development.\n\n- Although the numbers change, the basic character of L&B's results/claims don't change AFAICS: An LSTM (+attention + ptr) works for a \"mix and match\" case like addprim_turn_left but not for a \"systematic composition required\" case like addprim_jump.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582993830, "id": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper34/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer1"], "reply": {"forum": "rylf7QFUz", "replyto": "rylf7QFUz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582993830}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582800998, "tcdate": 1520623220248, "number": 3, "cdate": 1520623220248, "id": "HkndCUgFf", "invitation": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "forum": "rylf7QFUz", "replyto": "rylf7QFUz", "signatures": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer1"], "content": {"title": "Interesting new results on the SCAN task, not sure what to conclude", "rating": "6: Marginally above acceptance threshold", "review": "This paper presents the results of two experiments conducted on the SCAN data in response to Lake & Baroni\u2019s yet unpublished, \u201cStill not systematic\u2026\u201d paper (which in its latest version is now titled, \u201cGeneralization without systematicity\u2026\u201d) The first experiment examines the impact of two types of attention (additive or Bahdanau attention versus multiplicative or Luong attention), with and without a modification to have attention behave more like a pointer network. The second experiment looks at the impact of ensembling. As is apparently normal for the ICLR workshop track, this is an extremely dense 3-page paper that relies very heavily on its large appendices.\n\nPros:\n\nSome of the results are interesting, and imply that Lake and Barroni\u2019s hyper-parameter search was suboptimal.\n\nCons:\n\nThe most interesting results of Lake and Barroni still stand, more or less unchanged by this paper. It is difficult to tell what we should take away from this paper.\n\nClarity:\n\nOverall, this paper is paper is fairly clear, though I could live without the structure that this format seems to necessitate, where the summary of results comes first, and all details of the model and experiments come second in the appendix. This includes important experimental details, like how to interpret cryptic experiment names like \u201csimple_p1\u201d.\n\nFor replication, in Appendix B, instead of saying, \u201cwe do not use teacher forcing\u201d, it would be better to say what you do use.\n\nI think it would also be helpful to explain the reasoning behind ensembling across both time and across different initializations. Generally, people ensemble over time only to approximate ensembling across seeds. Furthermore, the figures seem to indicate a benefit of ensembling only earlier in time - which seems to strangely conflate the value of ensembling with the value of early stopping.\n\nQuality & Significance:\n\nUnlike the authors, I was mostly unimpressed by the jump from 0.08% accuracy to 14% accuracy in addprim_jump task using pointer networks. As the authors point out, even though it is a big relative improvement, we are still nowhere near to solving the problem. Furthermore, performance on other tasks is sacrificed for this gain. So I\u2019m not sure I agree with the statement that, \u201carchitectural inductive bias can indeed have a large impact.\u201d\nLikewise, the ensembling experiments are not particularly surprising, though I did like the observation in Appendix E that for some source sequences the ensembles can be very consistently wrong.\n\nWhat I did find interesting were the big jumps on all of the various low-data tasks (simple_p* and the \u201cnumber of composed commands used in training\u201d experiments), which appear to have happened for all of the tested attention types (pointer or no). I feel like some more space needs to be devoted to why the author\u2019s Bahdanau attention system is able to perform at 80% accuracy when Lake and Barroni\u2019s appears to be well under 5%. The authors do a good job of listing the differences in their training regime (mini-batches, teacher forcing, etc), but they don\u2019t devote any space to describing which differences led to such a dramatic improvement.\n\nThe authors\u2019 catch regarding Lake and Barroni\u2019s length experiment is also worthwhile, but it is more something one would hope to have appear in errata for the original paper. \n\nOverall grade\n\nI\u2019m not sure if this paper adds enough to the work of Lake and Barroni to get too excited. As I suggested above, by far the most significant result in my eyes is that the quality of paper\u2019s Bahdanau attention results implies a flaw in the original work\u2019s parameter search, which in turn impacted its ability to do well in low-data scenarios. But without an explanation for what training or architecture difference was crucial for this jump, I cannot get too excited about that either. \n\nOverall, I wonder if the most important statement in the paper isn\u2019t the \u201cSelection\u201d bullet in the Discussion. Because of their inherently one-shot nature, these experiments don\u2019t lend themselves to development-based early-stopping and hyper-parameter tuning. I feel like until we have a good answer to the selection problem, we will continue to see strange results like these, where architecturally very similar system do dramatically better or worse than reported in the literature.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582993830, "id": "ICLR.cc/2018/Workshop/-/Paper34/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper34/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper34/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper34/AnonReviewer1"], "reply": {"forum": "rylf7QFUz", "replyto": "rylf7QFUz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper34/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582993830}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573596073, "tcdate": 1521573596073, "number": 227, "cdate": 1521573595734, "id": "BJ4Jyy19z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rylf7QFUz", "replyto": "rylf7QFUz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518133243245, "tcdate": 1518052104443, "number": 34, "cdate": 1518052104443, "id": "rylf7QFUz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rylf7QFUz", "signatures": ["~Markus_Kliegl1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "More systematic than claimed: Insights on the SCAN tasks", "abstract": "We show that some standard attention-based architectures widely used in Neural Machine\nTranslation as well as a pointer-based variant achieve results on some of the compositional\nSCAN tasks that are far superior to those reported in Lake & Baroni (2018). We next show that\nthere is high variance in the test accuracy across both random initialization and training\nduration. We show that ensembling can be used to take advantage of this variance and improve\nresults but that, for many tasks, a large gap remains between ensemble performance and the\nperformance of an oracularly selected single best model. Based on these insights, we suggest\nsome possible directions for future research, emphasizing selection and regularization over the\nneed for more compositional architectures.", "pdf": "/pdf/dd7534999ab2bb2006276e921b19e11b03424824.pdf", "TL;DR": "We show NMT models do better than claimed on the SCAN tasks, but the high variance will require new techniques.", "paperhash": "kliegl|more_systematic_than_claimed_insights_on_the_scan_tasks", "authors": ["Markus Kliegl", "Wei Xu"], "keywords": ["sequence-to-sequence recurrent networks", "pointer networks", "compositionality", "systematicity", "generalization"], "authorids": ["mkliegl@gmail.com", "wei.xu@baidu.com"]}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 6}