{"notes": [{"id": "HyeQ676ktV", "original": null, "number": 1, "cdate": 1554138043148, "ddate": null, "tcdate": 1554138043148, "tmdate": 1554627187378, "tddate": null, "forum": "ryx0N3IaIV", "replyto": "ryx0N3IaIV", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper2/Official_Review", "content": {"title": "Interesting work, but relevance to RL is somewhat uncertain", "review": "Summary: This paper has an interesting investigation of significance testing for RL, however I am skeptical about whether significance testing is appropriate for comparing RL experiments.  \n\nNotes: \n  -Abstract asserts that checking statistical significance is the first step towards reproducibility, which seems somewhat debatable to me.  \n  -Paper should probably just say that it\u2019s about statistical significance in the title.  \n\nComments: \n  -This is a matter of judgement, but I feel like statistical significance is useful for cases where there is a tiny effect size, and we want to make sure that it isn\u2019t just random noise.  For example, one of the earliest uses for statistical significance was for studying the sex difference observed in the number of newborn babies (like 50.00001% are male).  In this case it\u2019s important to know if this result is statistically significant or just random noise.  In the case of different RL algorithms, I\u2019d be hard-pressed to imagine a situation where we\u2019d want to publish a new algorithm where the improvement isn\u2019t obviously statistically significant, especially because the power of the statistical test can easily be improved just by running more trials.  \n  -I can think of one exception to this, which is if we ran our RL algorithm in the real-world, and then we had a breakdown of many different evaluation categories, and then we wanted to identify which categories had significant or non-significant improvements.  \n  -One useful outcome of this is determining the sample sizes needed for certain levels of significance, which could be helpful for determining how many trials to run for RL experiments.  \n  -Some interesting recommendations are also made regarding the choice of significance tests.  \n", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper2/Authors"], "keywords": ["statistical testing", "reinforcement learning", "reproducibility", "replicability", "random seeds"], "TL;DR": "This paper compares statistical tests for RL comparisons (false positive, statistical power), checks robustness to assumptions using simulated distributions and empirical distributions (SAC, TD3), provides guidelines for RL students and researchers.", "abstract": "Consistently checking the statistical significance of experimental results is the first mandatory step towards reproducible science. This paper presents a hitchhiker's guide to rigorous comparisons of reinforcement learning algorithms. After introducing the concepts of statistical testing, we review the relevant statistical tests and compare them empirically in terms of false positive rate and statistical power as a function of the sample size (number of seeds) and effect size. We further investigate the robustness of these tests to violations of the most common hypotheses (normal distributions, same distributions, equal variances). Beside simulations, we compare empirical distributions obtained by running Soft-Actor Critic and Twin-Delayed Deep Deterministic Policy Gradient on Half-Cheetah. We conclude by providing guidelines and code to perform rigorous comparisons of RL algorithm performances.", "pdf": "/pdf/b25753ab70bcacf8dcaffa4eff7444d173ba16f1.pdf", "paperhash": "anonymous|a_hitchhikers_guide_to_statistical_comparisons_of_reinforcement_learning_algorithms", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper2/Official_Review", "cdate": 1554124269207, "expdate": 1556236800000, "duedate": 1555372800000, "reply": {"forum": "ryx0N3IaIV", "replyto": "ryx0N3IaIV", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/RML/Paper2/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554124269207, "tmdate": 1554627184968, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Paper2/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}, {"id": "rJlt4BZBFV", "original": null, "number": 1, "cdate": 1554482480607, "ddate": null, "tcdate": 1554482480607, "tmdate": 1554482480607, "tddate": null, "forum": "ryx0N3IaIV", "replyto": "ryx0N3IaIV", "invitation": "ICLR.cc/2019/Workshop/RML/-/Paper2/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper2/Authors"], "keywords": ["statistical testing", "reinforcement learning", "reproducibility", "replicability", "random seeds"], "TL;DR": "This paper compares statistical tests for RL comparisons (false positive, statistical power), checks robustness to assumptions using simulated distributions and empirical distributions (SAC, TD3), provides guidelines for RL students and researchers.", "abstract": "Consistently checking the statistical significance of experimental results is the first mandatory step towards reproducible science. This paper presents a hitchhiker's guide to rigorous comparisons of reinforcement learning algorithms. After introducing the concepts of statistical testing, we review the relevant statistical tests and compare them empirically in terms of false positive rate and statistical power as a function of the sample size (number of seeds) and effect size. We further investigate the robustness of these tests to violations of the most common hypotheses (normal distributions, same distributions, equal variances). Beside simulations, we compare empirical distributions obtained by running Soft-Actor Critic and Twin-Delayed Deep Deterministic Policy Gradient on Half-Cheetah. We conclude by providing guidelines and code to perform rigorous comparisons of RL algorithm performances.", "pdf": "/pdf/b25753ab70bcacf8dcaffa4eff7444d173ba16f1.pdf", "paperhash": "anonymous|a_hitchhikers_guide_to_statistical_comparisons_of_reinforcement_learning_algorithms", "_bibtex": null}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Paper2/Decision", "cdate": 1554482375289, "reply": {"forum": "ryx0N3IaIV", "replyto": "ryx0N3IaIV", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554482375289, "tmdate": 1554482377819, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["ICLR.cc/2019/Workshop/RML/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}}, {"id": "ryx0N3IaIV", "original": "SyxUub7h8E", "number": 2, "cdate": 1551883317678, "ddate": null, "tcdate": 1551883317678, "tmdate": 1551886664055, "tddate": null, "forum": "ryx0N3IaIV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "content": {"title": "A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms", "authors": ["Anonymous"], "authorids": ["ICLR.cc/2019/Workshop/RML/Paper2/Authors"], "keywords": ["statistical testing", "reinforcement learning", "reproducibility", "replicability", "random seeds"], "TL;DR": "This paper compares statistical tests for RL comparisons (false positive, statistical power), checks robustness to assumptions using simulated distributions and empirical distributions (SAC, TD3), provides guidelines for RL students and researchers.", "abstract": "Consistently checking the statistical significance of experimental results is the first mandatory step towards reproducible science. This paper presents a hitchhiker's guide to rigorous comparisons of reinforcement learning algorithms. After introducing the concepts of statistical testing, we review the relevant statistical tests and compare them empirically in terms of false positive rate and statistical power as a function of the sample size (number of seeds) and effect size. We further investigate the robustness of these tests to violations of the most common hypotheses (normal distributions, same distributions, equal variances). Beside simulations, we compare empirical distributions obtained by running Soft-Actor Critic and Twin-Delayed Deep Deterministic Policy Gradient on Half-Cheetah. We conclude by providing guidelines and code to perform rigorous comparisons of RL algorithm performances.", "pdf": "/pdf/b25753ab70bcacf8dcaffa4eff7444d173ba16f1.pdf", "paperhash": "anonymous|a_hitchhikers_guide_to_statistical_comparisons_of_reinforcement_learning_algorithms", "_bibtex": null}, "signatures": ["ICLR.cc/2019/Workshop/RML"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/RML"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/RML/-/Blind_Submission", "cdate": 1551883316747, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/RML"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1551883316747, "tmdate": 1551883316747, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/RML"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/RML"]}}, "tauthor": "OpenReview.net"}], "count": 3}