{"notes": [{"id": "HylwpREtDr", "original": "S1eEmGq_wH", "number": 1398, "cdate": 1569439423455, "ddate": null, "tcdate": 1569439423455, "tmdate": 1577168285327, "tddate": null, "forum": "HylwpREtDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "r1bonkIpQi", "original": null, "number": 1, "cdate": 1576798722295, "ddate": null, "tcdate": 1576798722295, "tmdate": 1576800914288, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Decision", "content": {"decision": "Reject", "comment": "The authors propose a method of selecting nodes to label in a graph neural network setting to reduce the loss as efficiently as possible. Building atop Sener & Savarese 2017 the authors propose an alternative distance metric and clustering algorithm. In comparison to the just mentioned work, they show that their upper bound is smaller than the previous art's upper bound. While one cannot conclude from this that their algorithm is better, at least empirically the method appears to have a advantage over state of the art.\n\nHowever, reviewers were concerned about the assumptions necessary to prove the theorem, despite the modifications made by the authors after the initial round. \n\nThe work proposes a simple estimator and shows promising results but reviewers felt improvements like reducing the number of assumptions and potentially a lower bound may greatly strengthen the paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721189, "tmdate": 1576800272169, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Decision"}}}, {"id": "BkxoJF8LjS", "original": null, "number": 3, "cdate": 1573443810601, "ddate": null, "tcdate": 1573443810601, "tmdate": 1573444921551, "tddate": null, "forum": "HylwpREtDr", "replyto": "ryxdKsggir", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Author Response", "comment": "We thank the reviewer for the comments. \n\n[for assumptions]\nWe would like to emphasize that our assumptions follow from the common settings in deep learning/active learning theory which is the general way of real data approximation. \n\nFor instance, both assumptions 2 and 3 are used in the paper by Sener & Savarese (2017) [3] and Lipschitz (assumption 2) is natural and common for loss functions such as hinge loss, mean squared error, and cross-entropy as long as the model output is bounded. This assumption is also widely used in deep learning theory e.g., [1,2]. As for assumption 3, although the constant $\\alpha$ can be unbounded, it can be made arbitrarily small without changing the predicted labels of the network; this is because dividing all input weights by a constant $t$ will also divide the output by a constant $t$. For the other assumptions, assumption 1 assumes a zero training loss, which is a typical setting in neural networks [3]. As for assumption 4, ReLU is activated with probability 1/2, which is justified by the observations in practice that usually half of all the ReLU neurons can activate. As mentioned in the paper, this is a common assumption in the literature. In a related paper on graph learning [4], the authors also assume that the ReLU activations are random.\n\nMoreover, our theoretical analysis only gives worst-case guarantees of our method, and its purpose is to justify our method against other clustering methods (e.g., the coreset approach, clustering the raw features, etc.). \n\nThe advantage of our method is evident in our strong experiment results that our simple method can beat previous baselines with elaborately designed heuristics.\n\nOur method is just a clustering of transformed features, which is very easy to implement. It is much simpler than previous active graph learning methods like AGE and ANRMAB, which combine several hand-made heuristics through weighting. \n\n[for Random in Figure 2]\nIn Figure 2, please notice that Degree, Uncertainty, Coreset are general active learning methods which cannot leverage  graph-based feature propagationwhile AGE, ANRMAB and our method (FeatProp) are graph-based active learning methods. Our method substantially outperform random sampling  on all the four benchmark datasets in this paper - see Table 4 in Appendix for details.\n\n[for application]\nThe main contribution of our paper is to enhance the effectiveness of active learning on graphs. The proposed method is generic and directly applicable to real-world applications where graphical data are available and labeled data are hard to acquire.  For example, our methods can be used to enrich user/item representations in recommendation systems and social networks.\n\nWe hope that our changes and comments can resolve your question towards our submission - and please reply if you still have further questions, and we would love to provide more details. If we resolve your questions, we are grateful if you can consider updating your review score. Thank you for your time and effort in reviewing our paper!\n\n[1] Allen-Zhu, Z., Li, Y., & Song, Z. (2019). A convergence theory for deep learning via over-parameterization. ICML 2019.\n[2] Du, S. S., & Lee, J. D. (2018). On the power of over-parametrization in neural networks with quadratic activation. ICML 2018.\n[3] Sener, O., & Savarese, S. (2017). Active learning for convolutional neural networks: A core-set approach. arXiv preprint arXiv:1708.00489.\n[4] Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K. I., & Jegelka, S. (2018). Representation Learning on Graphs with Jumping Knowledge Networks. ICML 2018\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "r1eNSF8LoH", "original": null, "number": 4, "cdate": 1573443899533, "ddate": null, "tcdate": 1573443899533, "tmdate": 1573444675613, "tddate": null, "forum": "HylwpREtDr", "replyto": "HkgnPPN0FB", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Author Response", "comment": "We thank the reviewer for the comments. \n\nWe agree that incorporating neighborhood information into the clustering process can also be helpful. For example, we can compute the distance based on a weighted combination of $S, S^2,...$. We will conduct additional experiments on this and report the results in our revised version of the paper.\n\nWe train our framework on all datasets with 5 different runs and show the averaged results. We will release our code shortly for people to reproduce our experiments. Currently, we take one sample near each cluster center and so the number of clusters is equal to the label budget. In general, the model performance increases with the number of clusters (labels), as shown in Figure 2.\n\nWe agree that varying the number of selected nodes from each cluster is an interesting idea. For example, we may set the number of nodes from each cluster to be proportional to the cluster size, or use hierarchical clustering. It would be meaningful future work to explore more in this aspect. \n\nWe hope that our changes and comments can resolve your question towards our submission - and please reply if you still have further questions. Thank you for your time and effort in reviewing our paper!\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "Bkxdy5LLjH", "original": null, "number": 6, "cdate": 1573444064007, "ddate": null, "tcdate": 1573444064007, "tmdate": 1573444064007, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Updates to our paper", "comment": "We thank all the reviewers for their time and effort in reviewing our paper. We have revised our paper according to the reviews and updated the version in the OpenReview system. \n\nUpdates:\nWe have revised our assumptions for Theorem 1 and provided more justification towards them. \nWe include a more detailed proof for the last step of applying Hoeffding\u2019s inequality in proof of Theorem 1.\n\nWe hope that these changes can resolve your questions and we are happy to answer any further questions about our paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "rJxaKYIUjB", "original": null, "number": 5, "cdate": 1573443972913, "ddate": null, "tcdate": 1573443972913, "tmdate": 1573443972913, "tddate": null, "forum": "HylwpREtDr", "replyto": "Bkxt7UNTYH", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Author Response", "comment": "We thank the reviewer for the comments.\n\nAbout applying Hoeffding\u2019s inequality in our proof: we\u2019ve updated the proof to include more details for this step, and please check out the highlighted part of Appendix B. Briefly, here the randomness in applying Hoeffding\u2019s inequality only comes from the random draws of the hidden labels, $y_i\\sim \\eta(i)$, for each unlabeled node $i$. This is determined after we fix the graph $G$ and feature matrix $X$. Since our model $A_0$ does not depend on the hidden labels (it cannot see them), making $l(A_0, y_i)$ being independent random variables, we can apply Hoeffding\u2019s inequality without any problem here. Actually, this step of using Hoeffding\u2019s inequality is also present in the coreset paper (Sener & Savarese, 2017, see the last two lines of their proof of Theorem 1). \n\nAbout the assumptions on theorem 1: our assumptions align with existing works in deep learning/active learning theory which is the general way of real data approximation. For instance, both assumptions 2 and 3 are used in the paper by Sener & Savarese (2017) [3] and Lipschitz (assumption 2) is natural and common for loss functions such as hinge loss, mean squared error, and cross-entropy as long as the model output is bounded. This assumption is also widely used in deep learning theory e.g., [1,2]. As for assumption 3, although the constant $\\alpha$ can be unbounded, it can be made arbitrarily small without changing the predicted labels of the network; this is because dividing all input weights by a constant $t$ will also divide the output by a constant $t$. For the other assumptions, assumption 1 assumes a zero training loss, which is a typical setting in neural networks [3]. As for assumption 4, ReLU is activated with probability 1/2, which is justified by the observations in practice that usually half of all the ReLU neurons can activate. As mentioned in the paper, this is a common assumption in the literature. In a related paper on graph learning [4], the authors also assume that the ReLU activations are random.\n\nMoreover, our theoretical analysis only gives worst-case guarantees of our method, and its purpose is to justify our method against other clustering methods (e.g., the coreset approach, clustering the raw features, etc.). \n\nThe advantage of our method is evident in our strong experiment results that our simple method can beat previous baselines with elaborately designed heuristics.\n\nWe hope that our changes and comments can resolve your question towards our submission - and please reply if you still have further questions, and we would love to provide more details. If we resolve your questions, we are grateful if you can consider updating your review score. Thank you for your time and effort in reviewing our paper!\n\n[1] Allen-Zhu, Z., Li, Y., & Song, Z. (2019). A convergence theory for deep learning via over-parameterization. ICML 2019.\n[2] Du, S. S., & Lee, J. D. (2018). On the power of over-parametrization in neural networks with quadratic activation. ICML 2018.\n[3] Sener, O., & Savarese, S. (2017). Active learning for convolutional neural networks: A core-set approach. arXiv preprint arXiv:1708.00489.\n[4] Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K. I., & Jegelka, S. (2018). Representation Learning on Graphs with Jumping Knowledge Networks. ICML 2018\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "ryxdKsggir", "original": null, "number": 3, "cdate": 1573026688019, "ddate": null, "tcdate": 1573026688019, "tmdate": 1573026688019, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #2", "review": "This paper introduces active learning for graphs using graph neural networks\n\nThe bound is not very meaningful as it requires unrealistic assumptions and is loose. \n\nFigure 2 shows that even random selection performs quite well compared to this elaborate method. \n\nThis Area if research and the data sets don\u2019t seem to have many actual real applications in the world with much impact. \n\n.................................................................\\.\\\\........................................,,..", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Reviewers"], "noninvitees": [], "tcdate": 1570237737965, "tmdate": 1574723083040, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review"}}}, {"id": "Bkxt7UNTYH", "original": null, "number": 1, "cdate": 1571796513258, "ddate": null, "tcdate": 1571796513258, "tmdate": 1572972473997, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose to incorporate active learning into the graph neural network training and claim some guarantee on the proposed method. \n\nI have some concerns about the correctness of the proof. For theorem 1, how is the Hoeffding applied so that the \\sqrt{n} term appears? My worry is naively applying Hoeffding as is done in the proof only gives a bound on a fixed model, but in the theorem A_t is not fixed. You may need to apply a union bound or more sophisticated set cover theory to claim the result. Or if I missed something could the authors add more details on the step using Hoeffding bound to the proof?\n\nOther than that I also feel the assumptions on theorem 1 are way too strong. Especially assumption 2 and 3. They are simply not true in application. The assumptions are so strong that the theorem, even if the proof can be fixed, is not interesting any more.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Reviewers"], "noninvitees": [], "tcdate": 1570237737965, "tmdate": 1574723083040, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review"}}}, {"id": "HkgnPPN0FB", "original": null, "number": 2, "cdate": 1571862371889, "ddate": null, "tcdate": 1571862371889, "tmdate": 1572972473955, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose an interesting method to actively select samples using the embeddings learned from GNNs. The proposed method combines graph embeddings and clustering to intelligently select new node samples. Theoretical analysis is provided to support the effectiveness and experimental results shows that this method can outperform many other active learning methods.  \nThis paper can be improved on the following aspects:\n1.\tThe proposed method conducts clustering using node embeddings. Although these embeddings have encoded graph structure to some extent, I would suggest explicitly incorporating the graph structure in clustering or at least comparing to a baseline on that. The proposed method conducts embedding learning and clustering in two consecutive but separate steps. It would be interesting to see that the clustering can also leverage the graph information.\n2.\tIt would be better to provide more details about network settings (some hyperparams have already been given in the paper), and more analysis would be helpful. For example, how the number of clusters affects the performance? \n3.\tIs it possible to create a scenario where there are more labeled data from one cluster but less data from another cluster? In this case, should we still take equal amount of samples from different clusters?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Reviewers"], "noninvitees": [], "tcdate": 1570237737965, "tmdate": 1574723083040, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Review"}}}, {"id": "BJeDgUOoKH", "original": null, "number": 2, "cdate": 1571681774572, "ddate": null, "tcdate": 1571681774572, "tmdate": 1571681774572, "tddate": null, "forum": "HylwpREtDr", "replyto": "H1e--mPYKS", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Reply", "comment": "Thanks for your suggestion! We will consider that in our revised version."}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "H1xdeRswFB", "original": null, "number": 1, "cdate": 1571433968285, "ddate": null, "tcdate": 1571433968285, "tmdate": 1571681709810, "tddate": null, "forum": "HylwpREtDr", "replyto": "SJgkKgUwtB", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment", "content": {"title": "Clarifications for our paper", "comment": "Hi Le,\n\nThanks for your interest in our paper. For the questions you raised, we would like to make some clarification:\n1. Sorry for the confusion here. For Uncertainty, Coreset, ANRMAB and AGE, we use an initial \u201cwarm-up\u201d set of 5 (instead of 10 - it is a typo in the paper) random nodes for training the model. This is because these methods require a seeding set so that after training on this set, the model could provide node-wise uncertainty and other information which is needed for a later node pool selection. For our one-time selection method, we indeed only need to pick the 40-cluster centers for the selection.\n2. We do not constrain the methods to the original split. This is the typical case for AL settings where the algorithm is allowed to choose any data points to label instead of relying on a split that already injects some selection bias. And as is known to some readers, the original split is biased [1] and methods may have different results for the average of random splits which is more recommended, we, therefore, use an averaged score (where the split is also not fixed) for evaluation.\n3. Yes for K-Medoids and Featprop; here the algorithm is requiring that the centers have to be from data points themselves, which leads to $s$ being the set of $b$ centers.\n\n[1] Pitfalls of Graph Neural Network Evaluation https://arxiv.org/abs/1811.05868"}, "signatures": ["ICLR.cc/2020/Conference/Paper1398/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1398/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1398/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1398/Authors|ICLR.cc/2020/Conference/Paper1398/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156611, "tmdate": 1576860533300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Official_Comment"}}}, {"id": "SJgkKgUwtB", "original": null, "number": 1, "cdate": 1571410039112, "ddate": null, "tcdate": 1571410039112, "tmdate": 1571555683427, "tddate": null, "forum": "HylwpREtDr", "replyto": "HylwpREtDr", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Public_Comment", "content": {"comment": "Thanks for your great work, seems that Active Learning works on Graph. \nBut I don't think it could convince me for the reasons below:\n1. Suppose we want 40 nodes, for  K-Medoids you need to choose 40 nodes initially. But in your settings, just start with random 10 nodes?\n2. Do you use the original data split setting in the original dataset(Cora, CiteSeer, PubMed)? Why you use 160 as your max training settings for all 4 datasets? It's 140 for Cora,120 for CiteSeer and 60 for PubMed in [1]. It's more convinced that you could reach the same results but fewer nodes in the same setting.\n3. In Algorithm I: after step 2 with b centers, how could I get s  as centers, do you mean that s=b?\nHope you could provide mode details about my questions, thanks again!\n\n\n[1] Kipf T N, Welling M. Semi-supervised classification with graph convolutional networks[J]. arXiv preprint arXiv:1609.02907, 2016.", "title": "Need more details about your setting!"}, "signatures": ["~Le_Wang6"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Le_Wang6", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504195298, "tmdate": 1576860566936, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Public_Comment"}}}, {"id": "H1e--mPYKS", "original": null, "number": 2, "cdate": 1571545848883, "ddate": null, "tcdate": 1571545848883, "tmdate": 1571550240255, "tddate": null, "forum": "HylwpREtDr", "replyto": "H1xdeRswFB", "invitation": "ICLR.cc/2020/Conference/Paper1398/-/Public_Comment", "content": {"comment": "Thanks for your reply and thanks for your time.\n\nYour comment is clear and I could understand your whole algorithm. \n\nAnd for 2: I don't mean that you should use original settings,  you could select nodes from the whole dataset. But maybe the max number of training nodes should be the same, e.g for Cora [14,42,70,98,126,140].", "title": "Reply"}, "signatures": ["~Le_Wang6"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Le_Wang6", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuexinw@andrew.cmu.edu", "yichongx@cs.cmu.edu", "aarti@cs.cmu.edu", "awd@cs.cmu.edu", "yiming@cs.cmu.edu"], "title": "Active Learning Graph Neural Networks via Node Feature Propagation", "authors": ["Yuexin Wu", "Yichong Xu", "Aarti Singh", "Artur Dubrawski", "Yiming Yang"], "pdf": "/pdf/1a056637dd35c7944cfe240dba93469ee8cd15ec.pdf", "TL;DR": "This paper introduces a clustering-based active learning algorithm on graphs.", "abstract": "Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data. However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs. Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning. With a theoretical bound analysis we justify the design choice of our approach. In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.", "keywords": ["Graph Learning", "Active Learning"], "paperhash": "wu|active_learning_graph_neural_networks_via_node_feature_propagation", "original_pdf": "/attachment/a0f5252af629d4440ea7969c1bc83c952217b10a.pdf", "_bibtex": "@misc{\nwu2020active,\ntitle={Active Learning Graph Neural Networks via Node Feature Propagation},\nauthor={Yuexin Wu and Yichong Xu and Aarti Singh and Artur Dubrawski and Yiming Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=HylwpREtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylwpREtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504195298, "tmdate": 1576860566936, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1398/Authors", "ICLR.cc/2020/Conference/Paper1398/Reviewers", "ICLR.cc/2020/Conference/Paper1398/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1398/-/Public_Comment"}}}], "count": 13}