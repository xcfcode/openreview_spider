{"notes": [{"id": "rkegcC4YvS", "original": "H1xyc__uDH", "number": 1271, "cdate": 1569439368318, "ddate": null, "tcdate": 1569439368318, "tmdate": 1577168256582, "tddate": null, "forum": "rkegcC4YvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Kz6c7rAlct", "original": null, "number": 1, "cdate": 1576798719026, "ddate": null, "tcdate": 1576798719026, "tmdate": 1576800917512, "tddate": null, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Decision", "content": {"decision": "Reject", "comment": "The paper introduces a method for removing what they call representation error and apply the method to super resolution and compressive sensing. \n\nThe reviewers have provided constructive feedback. The reviewers like aspects of the paper but are also concerned with various shortcomings. The consensus is that the paper is not ready for publication as it stands.\n\nRejection is therefore recommended with strong encouragement to keep working on the method and submit elsewhere.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713201, "tmdate": 1576800262768, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Decision"}}}, {"id": "BJgwdLAaKr", "original": null, "number": 1, "cdate": 1571837550902, "ddate": null, "tcdate": 1571837550902, "tmdate": 1574557131593, "tddate": null, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "[Update after rebuttal period]\nI am sorry that the response cannot address my confusion. I still doubt the motivation of this paper and the actual experimental performance compared with state-of-the-art methods are still ignored. Thus I decrease my score.\n\n[Original reviews]\nThis paper proposed to modeling image as the combination of a GAN with a Deep Decoder, to remove the representation error of a GAN when used as a prior in inverse problems. The proposed methods are evaluated on two image restoration tasks, including compressive sensing and image super-resolution. The effectiveness of the combination is also presented.\n\nAuthors devote themselves to remove the representation error of the GAN image prior. Intuitively, the manner of the proposed linear combination model is rough and less reasonable. In Alg.1, the detailed algorithmic process is presented, it is clear that authors need to pre-train the used GAN and Deep Decoder, then combine them to train one network. If the motivation of this paper is to remove the representation error of GAN, GAN should be viewed as the main body. However, the authors view GAN and Deep Decoder as the same position against the original intention.\n\nAdditionally, in the experimental part, the ablation studies indeed reflect the effectiveness of the proposed algorithm, but it looks like the Deep Decoder plays a key role in all cases. In other words, the GAN image prior just plays a supporting role. This is also far away from motivation.\n\nMore importantly, I cannot see the surprising results because of this work only compare themselves with some basic version or na\u00efve methods. All state-of-the-art approaches to different tasks are ignored, which is the other big disadvantage. \n\nIn Table 2, what is the meaning of \u2018CSGM\u2019\uff1f The authors should describe it.\n\nIn a word, from the algorithmic and experimental perspective, this paper cannot achieve satisfying performance.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Reviewers"], "noninvitees": [], "tcdate": 1570237739808, "tmdate": 1574723088667, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review"}}}, {"id": "H1evWKPssB", "original": null, "number": 3, "cdate": 1573775615504, "ddate": null, "tcdate": 1573775615504, "tmdate": 1573775615504, "tddate": null, "forum": "rkegcC4YvS", "replyto": "BJgwdLAaKr", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for your comments and corrections. We have updated table 2 to use \"GAN\" instead of \"CSGM\" to reflect that the value for that column represents the dimensionality of each GAN Prior's latent representation.\n\nIn response to your comments about the motivation of our model: our goal in this paper is to propose a simple model which can leverage benefits from a GAN Prior's learned approximation of the data distribution, without being tied to that distribution. The dependence of a GAN prior on its data distribution is a significant flaw, where we would ideally like to have strictly improved performance given examples of the class of images being recovered.\n\nSo, it is intentional that the GAN only plays a supporting role, for those images where is has learned useful representations.\n\nWe demonstrate that our model significantly reduces the representation error of the GAN, and comparisons to the Deep Decoder only indicate that the GAN Prior contributes its own benefits where it is possible. On out of distribution images, it is expected that the GAN Prior would be useless \u2013 our model is robust to this failure.\n\nWe appreciate your comments and look forward to improving this method further.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkegcC4YvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1271/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1271/Authors|ICLR.cc/2020/Conference/Paper1271/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158572, "tmdate": 1576860544715, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment"}}}, {"id": "B1e9ROPooS", "original": null, "number": 2, "cdate": 1573775569722, "ddate": null, "tcdate": 1573775569722, "tmdate": 1573775569722, "tddate": null, "forum": "rkegcC4YvS", "replyto": "SJlxZVMlqr", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thank you for your comments and corrections. We have updated the paper with a diagram of our model, and moved the hyperparameter descriptions to a section of the appendix. \n\nOur intention in the superresolution section is to demonstrate that our hybrid model is applicable for inverse problems besides compressed sensing. However, we agree with your concerns that improvement of the hybrid model over the deep decoder is not very significant. Since we already demonstrate that the hybrid model is no worse than a deep decoder via the out of distribution experiments, we have decided to remove the superresolution section from the paper.\n\nIn response to your concerns about n_pre, we observed that when n_pre is set to zero, there is some variance in the experimental results. The intuition is that both the GAN and Deep Decoder are randomly initialized, and so they can interfere with each other early in the inversion procedure. The results are otherwise not sensitive to choice of n_pre (within the same order of magnitude)"}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkegcC4YvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1271/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1271/Authors|ICLR.cc/2020/Conference/Paper1271/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158572, "tmdate": 1576860544715, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment"}}}, {"id": "Sklns_wsir", "original": null, "number": 1, "cdate": 1573775524402, "ddate": null, "tcdate": 1573775524402, "tmdate": 1573775524402, "tddate": null, "forum": "rkegcC4YvS", "replyto": "rkxEiTqbqB", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for your comments and corrections. We have fixed the typos you pointed out.\n\nIn response to your questions:\n1. Anecdotally, we observe the invertible models perform significantly better (4-6 dB psnr) in most measurement regimes (> 2% measurement ratio). The improvement is slightly less for lower measurement ratios (1-2 db psnr). This comes at a cost of significantly more expensive inversion, and a larger representation size. \n2. In our experiments, the GAN as DIP, Deep Decoder, and Hybrid models all take roughly 200 seconds (3.33 minutes). "}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkegcC4YvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1271/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1271/Authors|ICLR.cc/2020/Conference/Paper1271/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158572, "tmdate": 1576860544715, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Authors", "ICLR.cc/2020/Conference/Paper1271/Reviewers", "ICLR.cc/2020/Conference/Paper1271/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Comment"}}}, {"id": "SJlxZVMlqr", "original": null, "number": 2, "cdate": 1571984376459, "ddate": null, "tcdate": 1571984376459, "tmdate": 1572972490563, "tddate": null, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem. The combined model jointly infers the latent code for the trained GAN and the parameters in the untrained deep decoder. It also jointly infers the mixing coefficient alpha and beta during test time for each image, thus learning how much we should rely on GAN. The proposed hybrid model is helpful on compressed sensing experiments on the CelebA dataset; however, it is only marginally better than deep decoder on image super resolution and out-of-distribution compressed sensing.\n\nDetailed comments:\n-\tThe writing is clear and I was able to understand the model part of the paper. The algorithm box is helpful. However, I would still appreciate if the authors can provide an overall model figure in the model section to help understanding. \n-\tJointly learning the mixing coefficient is an interesting part of the model.\n-\tThe motivation in the abstract and intro could be strengthened. A smaller version of Figure 1 can be probably moved to the beginning of the paper to illustrate the problem of GAN. But even with the help of Figure 1, it is still unclear what is the fundamental problem for GAN. Simply combining a GAN with an untrained decoder model doesn\u2019t help elucidate the source of the problem. \n-\tThe proposed Hybrid model seems to help on compressed sensing experiments on CelebA. However, it doesn\u2019t help much on out-of-distribution experiments. Moreover, in the super-resolution task, as shown in Figure 5, the improvement over deep decoder is also not significant.\n-\tThe out-of-distribution experiments seems lack of thorough study. In particular, the paper only studies the transfer between CelebA -> Caltech-UCSD Bird dataset. It would be better if the paper can study a variety of other image datasets as well. Also some visualization on the Bird dataset should also be included.\n-\tEffect of n_pre needs to be further investigated. Why not directly train both models together? It would be good if the authors could comment on how sensitive the n_pre is and what is the intuition.\n-\tFor figures, I would recommend rename \u201cHybrid\u201d to \u201cHybrid (Ours)\u201d to highlight the paper\u2019s contribution, and use a brighter color.\n-\tFigure 5 should be renamed as a Table. \n-\tHyperparameter details should be moved to the Experiment section.\n\nConclusion:\nThe paper proposes a simple combination of a trained GAN and an untrained decoder model for the task of image restoration. Although the method is clear and straightforward, in the experiments, the influence of the new model component seems marginal. Moreover, the motivation is not strong enough. Therefore, I recommend weak reject."}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Reviewers"], "noninvitees": [], "tcdate": 1570237739808, "tmdate": 1574723088667, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review"}}}, {"id": "rkxEiTqbqB", "original": null, "number": 3, "cdate": 1572085148383, "ddate": null, "tcdate": 1572085148383, "tmdate": 1572972490517, "tddate": null, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "invitation": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a method for reducing the representation error generative convolutional neural networks by combining them with untrained deep decoder. The method is evaluated on compressive sensing and super-resolution, where a better performance than the isolated use of Deep Decoders and GAN priors. The main contribution of the paper is not the performance, but the simplicity of this approach.\n\n\n\nFor the title, I would suggest to replace the word Removing with Reducing.\nFurthermore, the clarification of \"GAN prior\" is very nice in the introduction, maybe you could already clarify it in the abstract.\n\nYou should perform a critical grammar check. There are too many commas, for example:\n\"At sufficiently difficult superresolution problems, the Hybrid model outperforms, the Deep\nDecoder, Bicubic upsampling, the BEGAN prior, and the BEGAN as DIP prior.\" -> there should be no comma after \"outperforms\"\nThe sentence from Page 3 to 4 reads strangely, probably a word is missing after \"For our GAN prior, we use the BEGAN architecture, and we demonstrate similar results\"\n\"Philosophically, they hybrid\" -> \"Philosophically, the hybrid\"\n\nFig 6 caption - shouldn't it be 49152 instead of 49512?\n\nYou perform various very good analysis experiments, which is well appreciated. Still, it would be good to think about some more experiments (and include at least one of them in the paper):\n1. You compare to IGAN and show that you achieve similar performance. You describe that a state-of-the-art approach are invertible generative models and that they are very time consuming (e.g., 15 minutes for a 64x64 image). How good would the invertible models be in terms of performance? Could you perform tests as well?\n2. It would be great if you report the runtime of all experiments as well - maybe also the memory usage."}, "signatures": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1271/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Removing the Representation Error of GAN Image Priors Using the Deep Decoder", "authors": ["Max Daniels", "Reinhard Heckel", "Paul Hand"], "authorids": ["daniels.g@husky.neu.edu", "rh43@rice.edu", "p.hand@northeastern.edu"], "keywords": ["deep decoder", "deep image prior", "GAN", "inverse problems"], "TL;DR": "A linear combination of a GAN and a Deep Decoder is an effective natural signal prior for inverse problems, outperforming both components on both in- and out-of-distribution images.", "abstract": "Generative models, such as GANs, have demonstrated impressive performance as natural image priors for solving inverse problems such as image restoration and compressive sensing. Despite this performance, they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because they maintain explicit low-dimensional learned representations of a natural signal class. In this paper, we demonstrate a method for removing the representation error of a GAN when used as a prior in inverse problems by modeling images as the linear combination of a GAN with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior.  No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method.  For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images.  This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.", "pdf": "/pdf/56299323b2e5f0c8e7f4d71399a49fccc8259f71.pdf", "paperhash": "daniels|removing_the_representation_error_of_gan_image_priors_using_the_deep_decoder", "original_pdf": "/attachment/2d8af15697ce1dec784d7d7985988bd40bba695c.pdf", "_bibtex": "@misc{\ndaniels2020removing,\ntitle={Removing the Representation Error of {\\{}GAN{\\}} Image Priors Using the Deep Decoder},\nauthor={Max Daniels and Reinhard Heckel and Paul Hand},\nyear={2020},\nurl={https://openreview.net/forum?id=rkegcC4YvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkegcC4YvS", "replyto": "rkegcC4YvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1271/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1271/Reviewers"], "noninvitees": [], "tcdate": 1570237739808, "tmdate": 1574723088667, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1271/-/Official_Review"}}}], "count": 8}