{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124473556, "tcdate": 1518453013420, "number": 150, "cdate": 1518453013420, "id": "BJazbHkPG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BJazbHkPG", "signatures": ["~Ryan_Spring1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Scalable Estimation via LSH Samplers (LSS)", "abstract": "The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.", "paperhash": "spring|scalable_estimation_via_lsh_samplers_lss", "keywords": ["Locality Sensitive Hashing", "LSH", "Estimation", "Sampling", "Softmax", "Attention"], "_bibtex": "@misc{\n  spring2018scalable,\n  title={Scalable Estimation via LSH Samplers (LSS)},\n  author={Ryan Spring and Anshumali Shrivastava},\n  year={2018},\n  url={https://openreview.net/forum?id=BJazbHkPG}\n}", "authorids": ["rdspring1@rice.edu", "anshumali@rice.edu"], "authors": ["Ryan Spring", "Anshumali Shrivastava"], "TL;DR": "Locality-Sensitive Hashing is an efficient, informative sampler, capable of accurately estimating the softmax normalization constant in sub-linear time.", "pdf": "/pdf/4477865b70e6455130fb326d46279fb43eb1fd0b.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582772575, "tcdate": 1520637025019, "number": 1, "cdate": 1520637025019, "id": "SkFPEqeKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "forum": "BJazbHkPG", "replyto": "BJazbHkPG", "signatures": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer2"], "content": {"title": "A novel sampling based approach to estimate the partition function", "rating": "7: Good paper, accept", "review": "Estimating the partition function is a challenging problem and new approaches to do this more efficiently are likely to be significant in a number of areas. \nPros\nSimple to implement approach\nAsymptotic guarantees\nShows good results on limited benchmarks\n\nCons\nmotivation is somewhat lacking given that there are many different approaches to partition function estimation (hashing-based, sampling-based, etc.)\n\nOverall, the paper shows promise of solid future work given the initial experimental results and the idea itself.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Scalable Estimation via LSH Samplers (LSS)", "abstract": "The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.", "paperhash": "spring|scalable_estimation_via_lsh_samplers_lss", "keywords": ["Locality Sensitive Hashing", "LSH", "Estimation", "Sampling", "Softmax", "Attention"], "_bibtex": "@misc{\n  spring2018scalable,\n  title={Scalable Estimation via LSH Samplers (LSS)},\n  author={Ryan Spring and Anshumali Shrivastava},\n  year={2018},\n  url={https://openreview.net/forum?id=BJazbHkPG}\n}", "authorids": ["rdspring1@rice.edu", "anshumali@rice.edu"], "authors": ["Ryan Spring", "Anshumali Shrivastava"], "TL;DR": "Locality-Sensitive Hashing is an efficient, informative sampler, capable of accurately estimating the softmax normalization constant in sub-linear time.", "pdf": "/pdf/4477865b70e6455130fb326d46279fb43eb1fd0b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582772381, "id": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper150/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer1"], "reply": {"forum": "BJazbHkPG", "replyto": "BJazbHkPG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582772381}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582591707, "tcdate": 1521090676827, "number": 2, "cdate": 1521090676827, "id": "HyaOlKwKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "forum": "BJazbHkPG", "replyto": "BJazbHkPG", "signatures": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer3"], "content": {"title": "simple and yet interesting sampling approach for softmax", "rating": "7: Good paper, accept", "review": "This workshop paper showcases that locality sensitive hashing (LSH), an approximate nearest-neighbor (ANN) approach, could be used as an efficient adaptive sampler. The idea is somewhat simple but very interesting and appealing. Authors should cite works of others on the similar venue. More specifically the following paper:\nhttps://openreview.net/pdf?id=SJ3dBGZ0Z\nIn the time performance analysis it may be better to represent the speed improvement relative to the Exact Gumble rather than showing the absolute numbers. Also it would be interesting to observe the MAE/speedup trade-off. \nFormatting suggestions:\nLSH Sampling -> LSH sampling? \nIS should be introduced on page 1. \nMax-Gumbel -> Gumbel-Max?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Scalable Estimation via LSH Samplers (LSS)", "abstract": "The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.", "paperhash": "spring|scalable_estimation_via_lsh_samplers_lss", "keywords": ["Locality Sensitive Hashing", "LSH", "Estimation", "Sampling", "Softmax", "Attention"], "_bibtex": "@misc{\n  spring2018scalable,\n  title={Scalable Estimation via LSH Samplers (LSS)},\n  author={Ryan Spring and Anshumali Shrivastava},\n  year={2018},\n  url={https://openreview.net/forum?id=BJazbHkPG}\n}", "authorids": ["rdspring1@rice.edu", "anshumali@rice.edu"], "authors": ["Ryan Spring", "Anshumali Shrivastava"], "TL;DR": "Locality-Sensitive Hashing is an efficient, informative sampler, capable of accurately estimating the softmax normalization constant in sub-linear time.", "pdf": "/pdf/4477865b70e6455130fb326d46279fb43eb1fd0b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582772381, "id": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper150/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer1"], "reply": {"forum": "BJazbHkPG", "replyto": "BJazbHkPG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582772381}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582588213, "tcdate": 1521229960421, "number": 3, "cdate": 1521229960421, "id": "BylcejKYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "forum": "BJazbHkPG", "replyto": "BJazbHkPG", "signatures": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer1"], "content": {"title": "Good research direction. Needs better application.", "rating": "4: Ok but not good enough - rejection", "review": "Summary:\n\nThis paper proposes a new sampling scheme to estimate the partition function by using LSH. The proposed sampler produces samples which are correlated and unnormalized. However authors propose a way to use these samples to derive an unbiased estimator for the partition function. There are some experimental results on estimating the denominator of the softmax function.\n\nMy comments:\n\nWhile the idea of using LSH to estimate the partition function in sub-linear time is good, I feel that the motivating example of larger softmax in the attention mechanism is not very convincing. A simple solution to approximate softmax in the attention mechanism is to find top-k candidates and take soft-max only based on these top-k candidates. Such an approach has been already explored in Rae et al. 2016, and Chandar et al., 2016. In attention-based application, it is often not necessary to estimate the partition function as long as the performance is improved in other ways.\n\nThe experimental setup is not very clear. The word embeddings change during training. How do authors update the LSH? Is it the case the authors compare different approaches only using a single snapshot? If so, it is not very useful for this application.\n\nWhile the problem and research direction is good, I recommend the authors to choose a different application where the solution would be really useful.\n\n\nReferences:\n\nRae et al. 2016, Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes.\nChandar et al., 2016, Hierarchical Memory Networks.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Scalable Estimation via LSH Samplers (LSS)", "abstract": "The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.", "paperhash": "spring|scalable_estimation_via_lsh_samplers_lss", "keywords": ["Locality Sensitive Hashing", "LSH", "Estimation", "Sampling", "Softmax", "Attention"], "_bibtex": "@misc{\n  spring2018scalable,\n  title={Scalable Estimation via LSH Samplers (LSS)},\n  author={Ryan Spring and Anshumali Shrivastava},\n  year={2018},\n  url={https://openreview.net/forum?id=BJazbHkPG}\n}", "authorids": ["rdspring1@rice.edu", "anshumali@rice.edu"], "authors": ["Ryan Spring", "Anshumali Shrivastava"], "TL;DR": "Locality-Sensitive Hashing is an efficient, informative sampler, capable of accurately estimating the softmax normalization constant in sub-linear time.", "pdf": "/pdf/4477865b70e6455130fb326d46279fb43eb1fd0b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582772381, "id": "ICLR.cc/2018/Workshop/-/Paper150/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper150/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper150/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper150/AnonReviewer1"], "reply": {"forum": "BJazbHkPG", "replyto": "BJazbHkPG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper150/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582772381}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573550963, "tcdate": 1521573550963, "number": 34, "cdate": 1521573550619, "id": "SJwh0ACKM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BJazbHkPG", "replyto": "BJazbHkPG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Scalable Estimation via LSH Samplers (LSS)", "abstract": "The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.", "paperhash": "spring|scalable_estimation_via_lsh_samplers_lss", "keywords": ["Locality Sensitive Hashing", "LSH", "Estimation", "Sampling", "Softmax", "Attention"], "_bibtex": "@misc{\n  spring2018scalable,\n  title={Scalable Estimation via LSH Samplers (LSS)},\n  author={Ryan Spring and Anshumali Shrivastava},\n  year={2018},\n  url={https://openreview.net/forum?id=BJazbHkPG}\n}", "authorids": ["rdspring1@rice.edu", "anshumali@rice.edu"], "authors": ["Ryan Spring", "Anshumali Shrivastava"], "TL;DR": "Locality-Sensitive Hashing is an efficient, informative sampler, capable of accurately estimating the softmax normalization constant in sub-linear time.", "pdf": "/pdf/4477865b70e6455130fb326d46279fb43eb1fd0b.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}