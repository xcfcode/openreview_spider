{"notes": [{"id": "S1g_EsActm", "original": "SkgvAc6OKX", "number": 12, "cdate": 1538087727546, "ddate": null, "tcdate": 1538087727546, "tmdate": 1545355417325, "tddate": null, "forum": "S1g_EsActm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "he|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["heliangbo@tsinghua.edu.cn", "sh759811581@tsinghua.edu.cn"], "authors": ["Liangbo He", "Hao Sun"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@misc{\nhe2019attention,\ntitle={{ATTENTION} {INCORPORATE} {NETWORK}: A {NETWORK} {CAN} {ADAPT} {VARIOUS} {DATA} {SIZE}},\nauthor={Liangbo He and Hao Sun},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g_EsActm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Bylf8M_i1V", "original": null, "number": 1, "cdate": 1544417865820, "ddate": null, "tcdate": 1544417865820, "tmdate": 1545354497580, "tddate": null, "forum": "S1g_EsActm", "replyto": "S1g_EsActm", "invitation": "ICLR.cc/2019/Conference/-/Paper12/Meta_Review", "content": {"metareview": "All reviewers agree that the paper should be rejected and there is no rebuttal.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "metareview: no rebuttal"}, "signatures": ["ICLR.cc/2019/Conference/Paper12/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper12/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "he|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["heliangbo@tsinghua.edu.cn", "sh759811581@tsinghua.edu.cn"], "authors": ["Liangbo He", "Hao Sun"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@misc{\nhe2019attention,\ntitle={{ATTENTION} {INCORPORATE} {NETWORK}: A {NETWORK} {CAN} {ADAPT} {VARIOUS} {DATA} {SIZE}},\nauthor={Liangbo He and Hao Sun},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g_EsActm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper12/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353370846, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1g_EsActm", "replyto": "S1g_EsActm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper12/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper12/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper12/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353370846}}}, {"id": "BkeITkMjnQ", "original": null, "number": 3, "cdate": 1541246910457, "ddate": null, "tcdate": 1541246910457, "tmdate": 1541534361575, "tddate": null, "forum": "S1g_EsActm", "replyto": "S1g_EsActm", "invitation": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "content": {"title": "A method to deal with the problem of fixed input image sizes in CNNs classifiers", "review": "This paper presents a strategy to overcome the limitation of fixed input image sizes in CNN classifiers. To this end, the authors incorporate some local and local attention modules, which fit inputs of arbitrary size to the fixed-size fully connected layer of a  CNN. The method is evaluated on three public classification benchmarks: CIFAR-10, ImageNet and Kaggle-Furniture128. \n\nThe results are better than those of the baseline architecture with fixed input size.\n\nEven though the need of handling arbitrary input size is an interesting problem, I have several major concerns about this paper:\n\n- One of the main problems of this paper is its presentation, both the writing and methodology. The writing is very poor, with continuous errors and many wrong definitions and concepts. For example, authors talk about \u2018data argumentation\u2019, \u2018pooling reduces the size of the hidden layers\u2019,\u2019back-to-back convolutional layers\u2019\n\nFurther, the paper is not well structured, which makes it very hard to follow.\n\nMethodology:\n\nAnother major concern is that I do not see how this approach allows the network to be input-size independent. If one looks at table 1, in both AIN-121 and AIN-169 the GAIL module employs kernel sizes equal to M/32xN/32, with M and N denoting the input image sizes. In this case, for each image, the kernel size will be different and, consequently, the number of learnable parameters. It is not clear to me how this is solved in this paper, as it ultimately results in a \u2018different\u2019 architecture for each different input size.\n\nWhen doing the sum on the proposed module, what does the result represent? absolute sum? mean of the sum? I also believe that a lot of information is lost when performing this operation (for example going from 32 to 1), in addition of the other spatial reductions during the network forward pass. Please comment on this and give a more detailed information about the proposed module.\n\nEvaluation: \nIn CIFAR-10, authors say that \u2018keep MOST of the setting similar to ResNet\u2019. What is then difference with the training with ResNet? For a fair comparison both settings should remain the same. In addition, what is the benefit of evaluating this approach on CIFAR-10, as the images are all of the same size? Furthermore, improvement is marginal with respect to the baselines (and it is not clear what is the reason behind the improvement), while increasing the model complexity by nearly 50%.\n\nKaggle-Furniture128: Why the learning is stopped exactly at epochs 38 and 53? Is this the same for all the networks? DenseNet and ResNet are pre-trained with what dataset?\n\nImageNet: In table 4, while the results for the baselines are evaluated on the validation set, the test set is used for evaluating the proposed approach. Furthermore, some results on the test set are obtained with \u2018augmentations\u2019. The reported values should correspond to the original test set without any kind of modification.\n\nMinor comments:\n\nThe authors assess the input fixed-size problem as a main problem in image processing. Despite being a limitation, some other image processing tasks, such as semantic segmentation, do not suffer from this problem, as CNNs are fully convolutional, and can accommodate images of arbitrary size.\n\nMany inconsistencies between terms: LAIL and then LAIN and GAIL and GAIN.'", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper12/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "he|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["heliangbo@tsinghua.edu.cn", "sh759811581@tsinghua.edu.cn"], "authors": ["Liangbo He", "Hao Sun"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@misc{\nhe2019attention,\ntitle={{ATTENTION} {INCORPORATE} {NETWORK}: A {NETWORK} {CAN} {ADAPT} {VARIOUS} {DATA} {SIZE}},\nauthor={Liangbo He and Hao Sun},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g_EsActm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "cdate": 1542234558033, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g_EsActm", "replyto": "S1g_EsActm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper12/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335629193, "tmdate": 1552335629193, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper12/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJlj-O9v2X", "original": null, "number": 2, "cdate": 1541019651423, "ddate": null, "tcdate": 1541019651423, "tmdate": 1541534361326, "tddate": null, "forum": "S1g_EsActm", "replyto": "S1g_EsActm", "invitation": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "content": {"title": "Another architecture variant of ConvNets without sufficient experimental benchmark", "review": "I was excited about the title and abstract but my expectation started to fall as I parsed through the main text. Here are some of my major concerns:\n\n1. The entire text is plagued by syntax errors that sometimes inhibit the narrative and prevent the proper understanding.\n\n2. Section 3 explains the architecture clearly, but fails to justify, perhaps in theory or at least in intuition, why AIN could have any advantage with such a distinct choice of parameterization. Nor can I find any solid evidence from the experiments that this is indeed the case. \n\n3. Section 4 seems ad-hoc, simply presenting tables without ablation study makes it hard to trust the proposed architecture.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper12/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "he|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["heliangbo@tsinghua.edu.cn", "sh759811581@tsinghua.edu.cn"], "authors": ["Liangbo He", "Hao Sun"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@misc{\nhe2019attention,\ntitle={{ATTENTION} {INCORPORATE} {NETWORK}: A {NETWORK} {CAN} {ADAPT} {VARIOUS} {DATA} {SIZE}},\nauthor={Liangbo He and Hao Sun},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g_EsActm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "cdate": 1542234558033, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g_EsActm", "replyto": "S1g_EsActm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper12/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335629193, "tmdate": 1552335629193, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper12/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Skg-gEMl37", "original": null, "number": 1, "cdate": 1540527081159, "ddate": null, "tcdate": 1540527081159, "tmdate": 1541534361124, "tddate": null, "forum": "S1g_EsActm", "replyto": "S1g_EsActm", "invitation": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "content": {"title": "Hard to understand and weak methodological contribution", "review": "General comment\n==============\nThe authors describe an attention mechanism for training with images of different sizes. The paper is hard to understand due to major grammatical errors and unclear descriptions. Methods for training with images of different sizes have been proposed before, e.g. spatial pyramid networks. I also have concerns about their evaluation. Overall, I believe that the paper is not ready to be submitted to a conference or journal.\n\nMajor comments\n=============\n1. Methods for training with images already exists, e.g. spatial pyramid pooling (http://arxiv.org/abs/1406.4729) or fully-convolutional networks (https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf). These are not cited in the paper and not included as baselines in their evaluation.\n\n2. The attention mechanisms looks similar to classificat soft-attention (https://arxiv.org/abs/1502.), which is not cited in the paper.\n\n3. The paper contains major spelling and grammatical errors, making it hard to understand important aspects.\n\n4. I can not see a clear improvement of their method over ResNet and DenseNet when the same number of model parameters is about the same. Without making sure that the number of model parameters is about the same, it is unclear if the performance gain is due the increased number of model parameters or the methodology.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper12/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ATTENTION INCORPORATE NETWORK: A NETWORK CAN ADAPT VARIOUS DATA SIZE", "abstract": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224\u00d7224\u00d73. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of input images and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure.", "paperhash": "he|attention_incorporate_network_a_network_can_adapt_various_data_size", "authorids": ["heliangbo@tsinghua.edu.cn", "sh759811581@tsinghua.edu.cn"], "authors": ["Liangbo He", "Hao Sun"], "keywords": ["attention mechanism", "various image size"], "pdf": "/pdf/3760fb7e13f529371f30a46e9c3fa552297df62b.pdf", "_bibtex": "@misc{\nhe2019attention,\ntitle={{ATTENTION} {INCORPORATE} {NETWORK}: A {NETWORK} {CAN} {ADAPT} {VARIOUS} {DATA} {SIZE}},\nauthor={Liangbo He and Hao Sun},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g_EsActm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper12/Official_Review", "cdate": 1542234558033, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g_EsActm", "replyto": "S1g_EsActm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper12/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335629193, "tmdate": 1552335629193, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper12/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}