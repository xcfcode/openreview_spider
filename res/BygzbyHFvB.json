{"notes": [{"id": "BygzbyHFvB", "original": "HklOmKs_DS", "number": 1535, "cdate": 1569439482086, "ddate": null, "tcdate": 1569439482086, "tmdate": 1583912044960, "tddate": null, "forum": "BygzbyHFvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "S5FRMZhf59", "original": null, "number": 1, "cdate": 1576798725875, "ddate": null, "tcdate": 1576798725875, "tmdate": 1576800910623, "tddate": null, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "The paper proposes a new algorithm for adversarial training of language models.  This is an important research area and the paper is well presented, has great empirical results and a novel idea. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795711370, "tmdate": 1576800260562, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Decision"}}}, {"id": "Bkljp70sjB", "original": null, "number": 4, "cdate": 1573802947434, "ddate": null, "tcdate": 1573802947434, "tmdate": 1573802947434, "tddate": null, "forum": "BygzbyHFvB", "replyto": "SyeaSzBZcS", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment", "content": {"title": "Thank you for your feedback!", "comment": "Thank you for the generous acknowledgement of our work! We agree that it is a good idea to add \u201cnatural\u201d into the title. However, we are only focusing on Natural Language Understanding tasks in this paper and have not tried deploying such a technology to pretraining language models for better feature representations. Therefore, we have changed the title to \u201cFreeLB: Enhanced Adversarial Training for Natural Language Understanding\u201d."}, "signatures": ["ICLR.cc/2020/Conference/Paper1535/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BygzbyHFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1535/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1535/Authors|ICLR.cc/2020/Conference/Paper1535/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154574, "tmdate": 1576860548986, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment"}}}, {"id": "Bklg57RosH", "original": null, "number": 3, "cdate": 1573802887934, "ddate": null, "tcdate": 1573802887934, "tmdate": 1573802887934, "tddate": null, "forum": "BygzbyHFvB", "replyto": "rkeZXiHs9r", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment", "content": {"title": "Thank you for your feedback!", "comment": "Thank you for the acknowledgement of our work and the valuable suggestions! We try to address all of your specific concerns and comments below.\n\n> \"- In tables 4 and 5, why are only results on RTE, CoLA, and MRPC presented? If this is because there was not noticeable difference on the other GLUE datasets, please mention it in the text.\"\nWe were not able to finish the experiments on all tasks by the time of submission, since each evaluation is relatively expensive, taking at least 5 runs. During the discussion period, we have focused on providing more results of YOPO on other GLUE tasks, as shown in Table 8 in the Appendix. YOPO is an important variant of adversarial training method to compare with, and the results indicate a deteriorating performance with the increase of shallow-layer updates, something YOPO advocates. We have not been able to finish the experiments for evaluating the effect of variational dropout and comparing the embedding space invariance (Table 5) on the remaining GLUE tasks, but will definitely add them into our next version. We are not able to provide results on SuperGLUE for the moment due to its huge scale, but we have achieved more improvements on CommonsenseQA and ARC. The results have been integrated into the new version.\n\n> \"- \u2026 did you do any error analysis on the models? Did they make different types of errors than models fine-tuned the vanilla way?\"\nWe have compared the models with and without FreeLB based on the diagnostic information provided by the GLUE benchmark. For the ensembled RoBERTa-large models, except for Named Entities (35.0/45.9), Quantifiers (63.9/66.1), Common Sense (59.5/60.5), Interval/Numbers (31.3/38.9), Universal (Logic) (75.3/85.0), Relative Clauses (32.8/37.3), FreeLB demonstrates improvements on all the remaining 30 diagnostic metrics (Matthew\u2019s Corr), with the most significant improvements in Morphological Negation (80.8/72.9), Negation (38.8/35.5), Conjunction (74.1/67.3), Disjunction (8.8/-3.1), Existential (Logic) (48.7/42.2), Temporal (Logic) (49.1/41.0), Anaphora/Coreference (54.2/48.8), Coordination Scopes (48.8/41.7). \nFor the single BERT-base model, comparing with Jacob Devlin\u2019s submission, except for Lexical Entailment (31.4/35.9), Symmetry/Collectivity (0/26.5), Redundancy (59.2/67.7), Structure Ellipsis/Implicits (35.2/39.4), Structure Datives (53.1/67.3),  Structure Intersectivity (27/30.4), Structure Restrictivity (-19/-13.5), Negation (15.6/24), Conjunction (-12.1/-8.3), Existential (Logic) (32.4/33.7), Downward Monotone (Logic) (-72.9/-66.5), FreeLB demonstrates improvement on all remaining 25 diagnostic metrics. Consistent with results for RoBERTa, in this case FreeLB also shows significant improvements in Anaphora/Coreference (37.2/32.2), Core Args (37.2/29, 51.6/48.9 for RoBERTa), Morphological Negation (64.2/45), and Coordination Scopes (40.9/29.8). We will add this analysis in the final version.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1535/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BygzbyHFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1535/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1535/Authors|ICLR.cc/2020/Conference/Paper1535/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154574, "tmdate": 1576860548986, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment"}}}, {"id": "BJeQ87CjiS", "original": null, "number": 2, "cdate": 1573802826658, "ddate": null, "tcdate": 1573802826658, "tmdate": 1573802826658, "tddate": null, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment", "content": {"title": "Thank the reviewers for their time!", "comment": "We would like to thank the reviewers for their time and their acknowledgement of our work. We have updated a new version, which corrected the spotted typos and includes more experimental results. Generally, by further exploring the hyperparameters, we have improved our highest single-model dev set accuracy from 78.64 to 78.81 on CommonsenseQA, and our ensembled model obtains an accuracy of 73.1, compared with RoBERTa (ensemble model) 72.5 in the leaderboard. We have also improved our dev/test set accuracy on ARC-Easy and ARC-Challenge from 84.56/85.35 (ensemble) and 67.56/67.32 (ensemble) to 84.91/85.44 (single-model) and 70.23/67.75 (single-model), remaining the first place on both leaderboards. We will add more ablation studies on all tasks of GLUE, and test our method on other important benchmarks in our future version. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1535/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BygzbyHFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1535/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1535/Authors|ICLR.cc/2020/Conference/Paper1535/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154574, "tmdate": 1576860548986, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1535/Authors", "ICLR.cc/2020/Conference/Paper1535/Reviewers", "ICLR.cc/2020/Conference/Paper1535/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Official_Comment"}}}, {"id": "SyeaSzBZcS", "original": null, "number": 1, "cdate": 1572061765500, "ddate": null, "tcdate": 1572061765500, "tmdate": 1572972455807, "tddate": null, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\n-\tThis paper modifies and extends the recent \u201cfree\u201d training strategies in adversarial training for representation learning for natural language.  The proposed \u201cFree\u201d Large-Batch Adversarial Training is well motived, in comparison with plain PGD-based adversarial training and the existing methods like FreeAT and YOPO, which virtually enlarges the batch size and minimize maximum risk at every ascent step. The contributions are solid. \n\n-\tThe proposed methods are empirically shown to be effective, in addition to being aligned with some recent theoretic analysis.  The models achieve SOTA on GLUE (by time the paper was submitted; it is not the best model now but that does not affect the contributions), ARC, and the commonsenseQA dataset.\n\n-\tThe paper conducted good analysis demonstrating the effectiveness of the proposed components, including detailed ablation analysis. \n\n-\tThe paper is well written. It is well structured and easy to follow.  A minor suggestion (just a personal view) is that the author(s) may consider using \u201cnatural  language\u201d instead of just \u201clanguage\u201d in the title and may consider using more specific words like \u201crepresentation\u201d instead of \u201cunderstanding\u201d. But this is minor. \n\nI recommend an accept. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1535/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1535/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576378235041, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1535/Reviewers"], "noninvitees": [], "tcdate": 1570237735965, "tmdate": 1576378235054, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Official_Review"}}}, {"id": "rkeZXiHs9r", "original": null, "number": 2, "cdate": 1572719385407, "ddate": null, "tcdate": 1572719385407, "tmdate": 1572972455764, "tddate": null, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "invitation": "ICLR.cc/2020/Conference/Paper1535/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper, the authors present a new adversarial training algorithm and apply it to the fintuning stage large scale language models BERT and RoBERTa. They find that with FreeLB applied to finetuning, both BERT and RoBERTa see small boosts in performance on GLUE, ARC, and CommonsenseQA. The gains they see on GLUE are quite small (0.3 on the GLUE test score for RoBERTa) but the gains are more substantial on ARC and CommonsenseQA. The paper also presents some ablation studies on the use of the same dropout mask across each ascent step of FreeLB, empirically seeing gains by using the same mask. They also present some analysis on robustness in the embedding space, showing that FreeLB leads to greater robustness than other adversarial training methods\n\nThis paper is clearly presented and the algorithm shows gains over other methods. I would recommend that the authors try testing their method on SuperGLUE because it's possible they're hitting ceiling issues with GLUE, suppressing any gains the algorithm may yield.\n\nQuestions,\n-  In tables 4 and 5, why are only results on RTE, CoLA, and MRPC presented? If this is because there was not noticeable difference on the other GLUE datasets, please mention it in the text.\n- I realize that this method is meant to increase robustness in the embedding space, but did you do any error analysis on the models? Did they make different types of errors than models fine-tuned the vanilla way?\n\nCouple typos,\n- Section 2.2, line 1: many -> much\n- Section 4.2, GLUE paragraph: 88 -> 88.8 "}, "signatures": ["ICLR.cc/2020/Conference/Paper1535/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1535/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["chenzhu@cs.umd.edu", "yu.cheng@microsoft.com", "zhe.gan@microsoft.com", "siqi.sun@microsoft.com", "tomg@cs.umd.edu", "jingjl@microsoft.com"], "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": ["Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu"], "pdf": "/pdf/d3d9bf10fada312c6d9525dec5b2122fd8483c9f.pdf", "abstract": "Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm, FreeLB, that promotes higher invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the GLUE benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of BERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44% and 67.75% on ARC-Easy and ARC-Challenge. Experiments on CommonsenseQA benchmark further demonstrate that FreeLB can be generalized and boost the performance of RoBERTa-large model on other tasks as well.", "keywords": [], "paperhash": "zhu|freelb_enhanced_adversarial_training_for_natural_language_understanding", "code": "https://github.com/zhuchen03/FreeLB", "_bibtex": "@inproceedings{\nZhu2020FreeLB:,\ntitle={FreeLB: Enhanced Adversarial Training for Natural Language Understanding},\nauthor={Chen Zhu and Yu Cheng and Zhe Gan and Siqi Sun and Tom Goldstein and Jingjing Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BygzbyHFvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c800f3af7b4a79bb352efe90d52ebf08bdf6a42d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BygzbyHFvB", "replyto": "BygzbyHFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1535/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576378235041, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1535/Reviewers"], "noninvitees": [], "tcdate": 1570237735965, "tmdate": 1576378235054, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1535/-/Official_Review"}}}], "count": 7}