{"notes": [{"id": "rJeGJaEtPH", "original": "BJer5ZrrPS", "number": 294, "cdate": 1569438938374, "ddate": null, "tcdate": 1569438938374, "tmdate": 1577168257374, "tddate": null, "forum": "rJeGJaEtPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "dIBw3_LrAU", "original": null, "number": 1, "cdate": 1576798692526, "ddate": null, "tcdate": 1576798692526, "tmdate": 1576800942838, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Decision", "content": {"decision": "Reject", "comment": "Two reviewers are negative on this paper while the other one is slightly positive. Overall, this paper does not make the bar of ICLR. A reject is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795717506, "tmdate": 1576800267828, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper294/-/Decision"}}}, {"id": "HJxFQjptoB", "original": null, "number": 4, "cdate": 1573669665393, "ddate": null, "tcdate": 1573669665393, "tmdate": 1573669665393, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "SJge34RuOB", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thanks for the great suggestions on how to improve the writeup. We have completely restructured the method presentation, significantly revised our derivation, and moved background work to the appendix. Please see the revised PDF for details, and let us know if you have further suggestions. For your convenience, we have colored the revised text with green.\n\nWhile it is true that the classification loss would fail when all classes are always present (e.g. MNIST_easy), this is true for all discriminative losses, e.g. hinge, cross-entropy. The suggested configuration of always having all classes -- numbers in MNIST -- equally present is equivalent to trying to learn a discriminative model with positive classes only. In other words, the answer to the classification is always going to be identical regardless of input. For example, when only pictures of cats are shown to a classifier when training to discriminate between cats and dogs, the classifier will learn to say cat regardless of the input. This is the limitation of a discriminative problem formulation, and not our loss function. Note that this is why we also show the reconstruction task, which does not suffer from this shortcoming.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper294/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeGJaEtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper294/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper294/Authors|ICLR.cc/2020/Conference/Paper294/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173540, "tmdate": 1576860544393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment"}}}, {"id": "rylaR56tiS", "original": null, "number": 3, "cdate": 1573669589201, "ddate": null, "tcdate": 1573669589201, "tmdate": 1573669589201, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "SkxcvDuXcH", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "We have revised the caption of Fig. 7, and the associated text to clarify this experiment.\n\nRegarding the experiments, note that our method is a significant step forward over existing approaches. Without strong supervision, state of the art methods cannot cope with even such simple scenarios, and part of our contribution is pointing out these limitations. Applying our method to MS COCO is in our plans, but it is essential to identify the shortcomings of existing techniques before moving to large scale experiments. We show our method already has significant advances over prior approaches. Note that using synthetic images to explore novel frameworks/learning schemes is very common for learning literature. For example, a very recent work [1], also shares a similar goal of encoding image with parts, but is not real-world ready.\n\nSVHN EXPERIMENTS\nNotice our experiments are significantly more challenging than the ones found in existing works -- the reason for which the results are different. More specifically, most works use SVHN with cropped images using *known* bounding boxes. They use 32x32 pixel crops where individual digits are centered, e.g. [2,3]. Previous multi-digit approaches [4,5] used slightly larger crops, but still centered the crops around the known bounding boxes. In contrast, we *do not* use any localization supervision in our SVHN results to make the setup more realistic.\n\nTEXTURE EXPERIMENTS: \nThe texture experiments are geared towards inverse graphics applications. Gabor filters and wavelets are a way of generating a procedural texture, and the experiment shows that the method is able to recover texture basis. Again, while not applied to real-world textures yet, our method is able to recover the required bases to synthesize a texture, opening up a new application area for deep learning in computer graphics.\n\nIoU THRESHOLD\nRegarding the steep decrease in accuracy that appears for high IoU threshold values, it is reasonable to expect this behavior in unsupervised learning. Since the network does not have to perfectly center the bounding boxes around the objects to accomplish its task successfully, it has no incentive to learn the boxes that align exactly with the ground truth. Also, the ground truth itself might be biased towards a certain way to align the boxes, which would explain why the supervised method does not suffer as much from a high IoU threshold.\n\n[1] Kosiorek A. R., Sabour S., Teh Y. W., and Hinton, G. E. (2019). Stacked Capsule Autoencoders. NeurIPS.\n[2] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., & Bengio, Y. (2013). Maxout networks. ICML.\n[3] Lin, M., Chen, Q., & Yan, S. (2013). Network in network. ICLR.\n[4] Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., & Shet, V. (2013). Multi-digit number recognition from street view imagery using deep convolutional neural networks. arXiv preprint arXiv:1312.6082.\n[5] Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial transformer networks. In Advances in neural information processing systems (pp. 2017-2025).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper294/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeGJaEtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper294/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper294/Authors|ICLR.cc/2020/Conference/Paper294/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173540, "tmdate": 1576860544393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment"}}}, {"id": "S1lOrqTKjr", "original": null, "number": 2, "cdate": 1573669439972, "ddate": null, "tcdate": 1573669439972, "tmdate": 1573669524269, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "B1gBC5jEcr", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We have added a thorough discussion on limitations to the conclusions, and updated Fig.1 as requested. For your convenience, we have colored the revised text with green.\n\nLIMITATIONS:\n1) Regarding the number of K, while a limitation, we point out that it could be removed via an additional network that is specialized in determining K. Nonetheless, we show in our revised Section. 5.2 that, even with the wrong K, the network is able to learn. This is because we can dynamically change the number of K at test time. For example, learning with K=6, with a varying number of instances (3 to 9), and then testing with 9 gives only 2% performance degradation.\n2) The patches are defined by location and scale for now. However, it is also possible to solve this in a way similar to region proposal nets, where an additional network is trained to refine bounding boxes.\n3) Note the use of synthetic images to explore new architectures / training regimes is very common in the learning literature. For example [1] also aims to encode images with parts, but is not applicable to complex images yet.\n\nRELATED WORKS:\n1) We have added \u201cAttention-based Deep Multiple Instance Learning\u201d and \"Weakly supervised object recognition with convolutional neural networks\" to the related work section.\n2) About the comparison to \u201cAttention-based Deep Multiple Instance Learning\u201d, note this method requires that a set of potential candidate points to be given, and the method classifies given candidates in a more traditional multiple instance learning setup. The method performance would therefore depend highly on these candidates, which for our tasks it is non trivial to form. Therefore, we would like to note that it is not straightforward to form a proper pipeline using the method for our tasks *within the response period*.\n\n[1] Kosiorek A. R., Sabour S., Teh Y. W., and Hinton, G. E. (2019). Stacked Capsule Autoencoders. NeurIPS.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper294/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeGJaEtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper294/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper294/Authors|ICLR.cc/2020/Conference/Paper294/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173540, "tmdate": 1576860544393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper294/Authors", "ICLR.cc/2020/Conference/Paper294/Reviewers", "ICLR.cc/2020/Conference/Paper294/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Comment"}}}, {"id": "SJge34RuOB", "original": null, "number": 1, "cdate": 1570460839632, "ddate": null, "tcdate": 1570460839632, "tmdate": 1572972613641, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The article introduces the novel MIST architecture which tries to solve the problem of multiple-instance classification and image generation from multiple objects. It employs two submodels, where the first generates a heatmap of intereting region and the second model is a task-specific model that works on image-patches, for example a classifier or an autoencoder. Both models are connected by a patch-extraction routine. The main contribution of this paper is to provide a way to propagate errors through this non-differentiable patch-extraction scheme. This is done by introducing slack-variables.\n------------------\n\nThe paper is overall relatively easy to follow and the results are very good. However, it suffers from the fact that it does not differentiate between model-architecture and the overall approach. While the main contribution is described in Section 4, the paper spends a lot of space beforehand to introduce the task-dependent models as well as the heatmap architecture - things that i can imagine will vary a lot in different applications. The real important part is how to train the model and this is unfortunately only half described. A good deal of abstraction from the network architecture would have made the paper a lot better.  Further, I think that the loss-function for the classification task does not work in the general case.\n\n\nOn my first read-through, i completely misunderstood Section 4. Here is an unsorted list of issues i had with this:\n- since E_K is not truly invertible, writing the approximate inverse as E_K^{-1} is misleading. \n- It might help to stress that you treat {x_k} as continuous and the sampling as differentiable.\n- In (7) it would be better to explicitly write E_K^{-1}(x_k) instead of introducing \\bar{h}. The line below is not clear.\n- It is also misleading, because the choice of \\bar{h}=E_K^{-1}(x_k) is not the minimizer of (5) given that all other variables are fixed. You can see this by observing that assuming that when {x_k}=E_K(H(I)) holds, we can choose all other pixels\nto be exactly the value returned by H(I).\n- I am not sure where the alternating part comes from because this usually involves taking your solution from (7) and feeding it into (6). \n- I am pretty sure that in (6)+(7), as well as lines 3+6 of the algorithm, you actually don't want to optimize for tau or eta from scratch but only perform a single SGD step. I think that is what you are doing, but right now it is written as \"find a complete new model for each batch\".\n- Since this is performed batch-wise: is x_k a variable kept between iterations or do you use H(I) for an initial estimate of x_k for the batch?\n\nRegarding the classification objective:\n-since (3) uses the MSE of the mean class-label and the mean-prediction, a dataset where all objects always appear with the exact same amount will not work since than for each image the mean label is identical.\n- Therefore, the MNIST-easy dataset should be unsolvable for the proposed architecture since every digit occurs exactly once.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088268029, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper294/Reviewers"], "noninvitees": [], "tcdate": 1570237754220, "tmdate": 1575088268046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Review"}}}, {"id": "SkxcvDuXcH", "original": null, "number": 2, "cdate": 1572206434332, "ddate": null, "tcdate": 1572206434332, "tmdate": 1572972613600, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a method for multi-instance object classification and reconstruction that does not require any location-based supervision. The main contribution is the introduction of a differentiable top-K region proposal that allows to train the whole model with only a supervision of the total number of instances (and their class) in the image. They test the performance of their method in simple visual tasks like cluttered MNIST, street digit recognition and finding the basis of procedural texture generation.\n\nThe paper is well written and motivated. The proposed method is clear and well formalized. Their reported results seem substantially better than the baselines they compare against. The additional experiments in their Appendix Fig. 7, analyzing the evolution of the heatmap loss, is interesting, although I think the heatmap visualization could be improved to better understand what the model is learning across iterations (improve legend to include at what iteration the heatmap is taken, give on what image this is evaluated).\n\nUnfortunately, their tasks seem quite easy, and it is hard to assess the impact of their method when working with more real-world data-sets, where the number of instances of every class is more loosely defined (we could always describe more objects in a real image from the COCO dataset for example). It seems of great importance to evaluate the limitations of their method in this direction, as the source of supervision might be too weak in the cases where the generated dataset might not have all the combinations of number of instances per image (as the cluttered MNIST has given that it\u2019s procedurally generated). The results on SVHN are a little bit confusing, and it\u2019s unclear what the \u201cSupervised\u201d method is, specially knowing that there are available methods that do obtain much better performance on this task using all the supervision available. It should also be better explained why the performance drops so drastically when the IoU threshold is increased. Finally, the texture generation experiments are very hard to interpret and are even further from real-world tasks.\n\nGiven my concerns on how this unsupervised approach can scale to real-life datasets, I suggest a weak reject, but I think the  proposed method has some interest for the community and I strongly encourage the authors to provide further evidence of performance of their method on more complex vision tasks."}, "signatures": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088268029, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper294/Reviewers"], "noninvitees": [], "tcdate": 1570237754220, "tmdate": 1575088268046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Review"}}}, {"id": "B1gBC5jEcr", "original": null, "number": 3, "cdate": 1572285133460, "ddate": null, "tcdate": 1572285133460, "tmdate": 1572972613551, "tddate": null, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "invitation": "ICLR.cc/2020/Conference/Paper294/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper presents a way to solve a localization task for in images without providing any localization supervision. This allows tackling image reconstruction and classification problems that involve multiple object instances. At the core of the approach is a suggestion to resolve the non-differentiable top-k selection process: It is done by introducing axuilliary variables which allows the derivation of an alternating optimization procedure for their framework.\n\nI like the paper and I think the problem it's tackeling is at the core for all many important image understanding tasks. When thinking about reasons that speak against the paper, I'm mostly concerned about the fact that the idea is not yet fully worked out:\n* The biggest unresolved aspect is the number 'k' of instances needs to be provided. Assuming real-world relevant instance detection tasks, images in the test set never have 'k' provided.\n* All patches need to be squared -- again, for real-world tasks this is not the case.\n* In the case of image reconstruction, what is the 'reconstruction error' exactly? Assuming a scene with background clutter, how would this work here? It seems that the demonstrated examples have a black background so working additively is not a problem.\n\nThe conclusion mentions 'a first step', so I understand that the authors may be aware of the shortcomings. As such, I'd like to have limitations (and potential resolutions) to be pointed out in the paper.\n\nWith respect to related work, I'm missing \"Attention-based Deep Multiple Instance Learning\", by Ilse et al. I'm not certain if it could be applied to the reconstruction task, but it seems that it should be a baseline for the classification task. When talking about weak supervision, the paper \"Weakly supervised object recognition with convolu-tional neural networks\" by Oquab should also be mentioned in the related work section.\n\nOn a more detailed level, Figure 1 has no symbols for the newtork H_n and T_tau."}, "signatures": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper294/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MIST: Multiple Instance Spatial Transformer Networks", "authors": ["Baptiste Angles", "Simon Kornblith", "Shahram Izadi", "Andrea Tagliasacchi", "Kwang Moo Yi"], "authorids": ["baptiste.angles@gmail.com", "skornblith@google.com", "shahrami@google.com", "taglia@google.com", "kyi@uvic.ca"], "keywords": [], "abstract": "We propose a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant top-K patches, and feeds these patches to a task-specific network -- e.g., auto-encoder or classifier -- to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, we lift the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. Our method is able to learn to detect recurrent structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art.", "pdf": "/pdf/0062ad31fe39bfc40ab35ace3f797da17d9e4dc1.pdf", "paperhash": "angles|mist_multiple_instance_spatial_transformer_networks", "original_pdf": "/attachment/ddd2f0971b57c7a8553d966f6c0601237b2eac2a.pdf", "_bibtex": "@misc{\nangles2020mist,\ntitle={{\\{}MIST{\\}}: Multiple Instance Spatial Transformer Networks},\nauthor={Baptiste Angles and Simon Kornblith and Shahram Izadi and Andrea Tagliasacchi and Kwang Moo Yi},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeGJaEtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeGJaEtPH", "replyto": "rJeGJaEtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088268029, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper294/Reviewers"], "noninvitees": [], "tcdate": 1570237754220, "tmdate": 1575088268046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper294/-/Official_Review"}}}], "count": 8}