{"notes": [{"tddate": null, "ddate": null, "tmdate": 1519653588283, "tcdate": 1509047643423, "number": 175, "cdate": 1518730186428, "id": "H1Xw62kRZ", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "H1Xw62kRZ", "original": "Bk7vpnyAb", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "nonreaders": [], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "tmdate": 1518710209314, "tcdate": 1518710209314, "number": 5, "cdate": 1518710209314, "id": "HJFpTXmPf", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "forum": "H1Xw62kRZ", "replyto": "BkOqpd0SG", "signatures": ["ICLR.cc/2018/Conference/Paper175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper175/Authors"], "content": {"title": "Answers to Further questions", "comment": "Hello, thank you for your interest in this paper.\n\n1) Yes, this is the exact dataset (train, test, val) that we use for our experiments. (bit.ly/karel-dataset)\n\n2) It doesn't matter in this case if we sample programs first or I/O examples first since they are independently sampled here. Program and Input grid are independently sampled, and output grids are the results of applying the program to the Input grid.\n\n3) You are absolutely right. Our previous reply was mistakenly giving you statistics about an earlier version of the dataset which we didn't use for this paper. I'm terribly sorry about this mistake and apologize for the confusion. For this dataset, the programs contain up to 75 tokens and have a maximum nesting depth of 8 (counting the function definition as 1)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825738068, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper175/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper175/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper175/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825738068}}}, {"tddate": null, "ddate": null, "tmdate": 1517354384153, "tcdate": 1517354384153, "number": 2, "cdate": 1517354384153, "id": "BkOqpd0SG", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Public_Comment", "forum": "H1Xw62kRZ", "replyto": "SyzhcVbXf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Further questions about data", "comment": "Thank you for the additional clarifications about the dataset. I have some further questions that I am hoping you will be able to answer.\n\n> We have already released the karel dataset (link omitted because of double-blind constraints)\nNow that the double-blind period is over, can you confirm whether what you used for this paper is the same dataset as http://bit.ly/karel-dataset?\n\nIn your reply above, you state\n> The input grids are generated by randomly sampling... A program is then sampled\nHowever, the current version of the paper states (on page 8, section 6.1)\n> randomly sampling programs from the DSL... or each program, we a set of IO pairs are generated by sampling random input grids\nwhich seems to be in the opposite order. Could you clarify which of these two procedures was followed?\n\n> maximum nesting depth (nested loops or conditionals) of 4 and a maximum number of tokens that is set to be 20\nI looked through the train.json file in the dataset from http://bit.ly/karel-dataset, but I found an example which doesn't fit the constraints (line 144701 in the file, GUID 8a4df93b40edfa61):\n> DEF run m( REPEAT R=5 r( turnLeft WHILE c( rightIsClear c) w( REPEAT R=3 r( REPEAT R=4 r( IFELSE c( not c( frontIsClear c) c) i( REPEAT R=2 r( WHILE c( not c( rightIsClear c) c) w( turnLeft w) r) turnRight i) ELSE e( move e) r) r) putMarker IF c( leftIsClear c) i( turnRight i) w) r) turnLeft m)\nThis is 60 tokens long and has a maximum nesting depth of 7 (REPEAT R=5 -> WHILE rightIsClear -> REPEAT R=3 -> REPEAT R=4 -> IFELSE not frontIsClear -> REPEAT R=2 -> WHILE not rightIsClear).\n\nFor this paper, did you use a different version of the dataset which contains simpler programs than this example from http://bit.ly/karel-dataset?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791691743, "id": "ICLR.cc/2018/Conference/-/Paper175/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Area_Chair"], "cdate": 1512791691743}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260100485, "tcdate": 1517249224032, "number": 40, "cdate": 1517249224019, "id": "rkl0GyTSz", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "Below is a summary of the pros and cons of the proposed paper:\n\nPros:\n* Proposes a novel method to tune program synthesizers to generate correct programs and prune search space, leading to better and more efficient synthesis\n* Shows small but substantial gains on a standard benchmark\n\nCons:\n* Reviewers and commenters cited a few clarity issues, although these have mostly been resolved\n* Lack of empirical comparison with relevant previous work (e.g. Parisotto et al.) makes it hard to determine their relative merit\n\nOverall, this seems to be a solid, well-evaluated contribution and seems to me to warrant a poster presentation.\n\nAlso, just a few notes from the area chair to potentially make the final version better:\n\nThe proposed method is certainly different from the method of Parisotto et al., but it is attempting to solve the same problem: the lack of consideration of the grammar in neural program synthesis models. The relative merit is stated to be that the proposed method can be used when there is no grammar specification, but the model of Parisotto et al. also learns expansion rules from data, so no explicit grammar specification is necessary (as long as a parser exists, which is presumably necessary to perform the syntax checking that is core to the proposed method). It would have been ideal to see an empirical comparison between the two methods, but this is obviously a lot of work. It would be nice to have the method acknowledged more prominently in the description, perhaps in the introduction, however.\n\nIt is nice to see a head-nod to Guu et al.'s work on semantic parsing (as semantic parsing from natural language is also highly relevant). There is obviously a lot of work on generating structured representations from natural lanugage, and the following two might be particularly relevant given their focus on grammar-based formalisms for code synthesis from natural language:\n\n* \"A Syntactic Neural Model for General-purpose Code Generation\" Yin and Neubig ACL 2017.\n* \"Abstract Syntax Networks for Code Generation and Semantic Parsing\" Rabinovich et al. ACL 2017\n", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642404191, "tcdate": 1511841643706, "number": 1, "cdate": 1511841643706, "id": "Hk4_Jw9xG", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "signatures": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Good paper, could be more clearly written.", "rating": "5: Marginally below acceptance threshold", "review": "The authors consider the task of program synthesis in the Karel DSL. Their innovations are to use reinforcement learning to guide sequential generation of tokes towards a high reward output, incorporate syntax checking into the synthesis procedure to prune syntactically invalid programs. Finally they learn a model that predicts correctness of syntax in absence of a syntax checker. \n\nWhile the results in this paper look good, I found many aspects of the exposition difficult to follow. In section 4, the authors define objectives, but do not clearly describe how these objectives are optimized, instead relying on the read to infer from context how REINFORCE and beam search are applied. I was not able to understand whether syntactic corrected is enforce by way of the reward introduced in section 4, or by way of the conditioning introduced in section 5.1. Discussion of the experimental results coould similarly be clearer. The best method very clearly depends on the taks and the amount of available data, but I found it difficult to extract an intuition for which method works best in which setting and why. \n\nOn the whole this seems like a promising paper. That said, I think the authors would need to convincingly address issues of clarity in order for this to appear. \n\nSpecific comments \n\n- Figure 2 is too small \n\n- Equation 8 is confusing in that it defines a Monte Carlo estimate of the expected reward, rather than an estimator of the gradient of the expected reward (which is what REINFORCE is). \n\n- It is not clear the how beam search is carried out. In equation (10) there appear to be two problems. The first is that the index i appears twice (once in i=1..N and once in i \\in 1..C), the second is that \u03bb_r refers to an index that does not appear. More generally, beam search is normally an algorithm where at each search depth, the set of candidate paths is pruned according to some heuristic. What is the heuristic here? Is syntax checking used at each step of token generation, or something along these lines? \n \n- What is the value of the learned syntax in section 5.2? Presumaly we need a large corpus of syntax-checked training examples to learn this model, which means that, in practice, we still need to have a syntax-checker available, do we not?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642404090, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer2", "ICLR.cc/2018/Conference/Paper175/AnonReviewer3", "ICLR.cc/2018/Conference/Paper175/AnonReviewer1"], "reply": {"forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642404090}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642404146, "tcdate": 1511904311368, "number": 2, "cdate": 1511904311368, "id": "H1JSNUjeG", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "signatures": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "The paper presents a reinforcement learning-based approach for program synthesis. The proposed approach claims two advantages over a baseline maximum likelihood estimation-based approach. MLE-based methods penalize syntactically different but semantically equivalent programs. Further, typical program synthesis approaches don't explicitly learn to produce correct syntax. The proposed approach uses a syntax-checker to limit the next-token distribution to syntactically-valid tokens.\n\nThe approach, and its constituent contributions, i.e. of using RL for program synthesis, and limiting to syntactically valid programs, are novel. Although both the contributions are fairly obvious, there is of course merit in empirically validating these ideas.\n\nThe paper presents comparisons with baseline methods. The improvements over the baseline methods is small but substantial, and enough experimental details are provided to reproduce the results.  However, there is no comparison with other approaches in the literature. The authors claim to improve the state-of-the-art, but fail to mention and compare with the state-of-the-art, such as [1]. I do find it hard to trust papers which do not compare with results from other papers.\n\nPros:\n1. Well-written paper, with clear contributions.\n2. Good empirical evaluation with ablations.\n\nCons:\n1. No SOTA comparison.\n2. Only one task / No real-world task, such as Excel Flashfill.\n\n[1]: \"Neural Program Meta-Induction\", Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642404090, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer2", "ICLR.cc/2018/Conference/Paper175/AnonReviewer3", "ICLR.cc/2018/Conference/Paper175/AnonReviewer1"], "reply": {"forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642404090}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642404107, "tcdate": 1512092401565, "number": 3, "cdate": 1512092401565, "id": "HkcxQ4Rxf", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "signatures": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Good paper, accept", "rating": "7: Good paper, accept", "review": "This is a nice paper. It makes novel contributions to neural program synthesis by (a) using RL to tune neural program synthesizers such that they can generate a wider variety of correct programs and (b) using a syntax checker (or a learned approximation thereof) to prevent the synthesizer from outputting any syntactically-invalid programs, thus pruning the search space. In experiments, the proposed method synthesizes correct Karel programs (non-trivial programs involving loops and conditionals) more frequently than synthesizers trained using only maximum likelihood supervised training.\n\nI have a few minor questions and requests for clarification, but overall the paper presents strong results and, I believe, should be accepted.\n\n\nSpecific comments/questions follow:\n\n\nFigure 2 is too small. It would be much more helpful (and easier to read) if it were enlarged to take the full page width.\n\nPage 7: \"In the supervised setting...\" This suggests that the syntaxLSTM can be trained without supervision in the form of known valid programs, a possibility which might not have occurred to me without this little aside. If that is indeed the case, that's a surprising and interesting result that deserves having more attention called to it (I appreciated the analysis in the results section to this effect, but you could call attention to this sooner, here on page 7).\n\nIs the \"Karel DSL\" in your experiments the full Karel language, or a subset designed for the paper?\n\nFor the versions of the model that use beam search, what beam width was used? Do the results reported in e.g. Table 1 change as a function of beam width, and if so, how? \n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642404090, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper175/AnonReviewer2", "ICLR.cc/2018/Conference/Paper175/AnonReviewer3", "ICLR.cc/2018/Conference/Paper175/AnonReviewer1"], "reply": {"forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642404090}}}, {"tddate": null, "ddate": null, "tmdate": 1514388137971, "tcdate": 1514388137971, "number": 4, "cdate": 1514388137971, "id": "SyzhcVbXf", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "forum": "H1Xw62kRZ", "replyto": "Sy8bJjuMM", "signatures": ["ICLR.cc/2018/Conference/Paper175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper175/Authors"], "content": {"title": "Reply to Commenter", "comment": "We thank the commenter for their interest in our paper.\n\nMore details about the generation of the dataset are available in a previous paper that was making use of the Karel Dataset [1]. We have already released the karel dataset (link omitted because of double-blind constraints) and also plan on releasing the code used to run the experiments. What follows are the answers to the specific questions:\n\n1, 2, 3 -> The input grids are generated by randomly sampling for each cell whether the cell contains an obstacle / a marker / several markers. The agent\u2019s position is also selected at random.\nA program is then sampled with a maximum nesting depth (nested loops or conditionals) of 4 and a maximum number of tokens that is set to be 20. We execute the programs on the inputs grids to generate the output grids. If the program hasn\u2019t halted before performing 200 actions, if there is a collision with an obstacle or if the program doesn\u2019t do anything when run on the sampled grid (i.e. the input grid is unchanged), we discard the program and sample a new one.\n\n4 -> The 52 tokens are: <s> (start of sequence), not, DEF, run, REPEAT, WHILE, IF,  IFELSE,  ELSE, markersPresent, noMarkersPresent, leftIsClear, rightIsClear, frontIsClear, move, turnLeft, turnRight, pickMarker, putMarker, m(, m) (open and close parens for a function), c(, c) (open and close parens for a conditional),  r(, r) (open and close parens for a repeat instruction), w(, w) (open and close parens for a while conditional), i(,i) (open and close parens for a if statement conditional), e(, e) (open and close parens for an else clause) + 20 scalar values from 0 to 19.\n\n5 -> The batch size used for the supervised setting was 128. For the RL type experiments, a batch was composed of 16 samples. We used 100 rollouts per samples for the Reinforce method and a beam size of 64 for methods based on the beam search.\n\n6-> We have added more details in the paper regarding how the beam search is performed.\n\n[1] Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli. Neural Program Meta-Induction. In NIPS, 2017\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825738068, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper175/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper175/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper175/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825738068}}}, {"tddate": null, "ddate": null, "tmdate": 1514387885928, "tcdate": 1514387885928, "number": 3, "cdate": 1514387885928, "id": "S1UnKVWXf", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "forum": "H1Xw62kRZ", "replyto": "HkcxQ4Rxf", "signatures": ["ICLR.cc/2018/Conference/Paper175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper175/Authors"], "content": {"title": "Reply to Reviewer 1", "comment": "We thank the reviewer for the comments on the part of the paper that need clarification. We incorporated his feedback in the new version. Here are answers to the raised questions:\n\n-> Figure 2 is too small\nThe size of Figure 2 was increased to make it full page width.\n\n-> \u201cThe syntaxLSTM can be trained without supervision in the form of known valid programs\u201d\nWhile the syntaxLSTM can be trained without access to known valid programs when RL-based training is employed (because gradient will flow to it through the softmax defining the probability of each token), we point out in the experiments section that we weren\u2019t successful in training models using only RL training. As a result, it would not be accurate to claim that it can be trained without any valid programs as supervision. \n\n-> Is the Karel DSL the full Karel language?\nThe exact description of our DSL is in Appendix B. It doesn\u2019t exactly match the full Karel language, as most notably there is no possibility to define subroutines. We made this clearer in the paper.\n\n-> What was the beam width used?\nAll of our experiments used a beam width of 64. We didn\u2019t study the effect of this hyperparameter and chose it as the maximum width we could afford based on available GPU memory. In the limit, using an extremely large beam size would be equivalent to computing the complete sum for the expected reward but this is not feasible for any applications where program would be longer than a few tokens.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825738068, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper175/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper175/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper175/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825738068}}}, {"tddate": null, "ddate": null, "tmdate": 1514387808589, "tcdate": 1514387808589, "number": 2, "cdate": 1514387808589, "id": "ByKvFVW7f", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "forum": "H1Xw62kRZ", "replyto": "H1JSNUjeG", "signatures": ["ICLR.cc/2018/Conference/Paper175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper175/Authors"], "content": {"title": "Reply to Reviewer 3", "comment": "We thank the reviewer for the comments on the paper, and for pointing out the missing related work.\n\nIt is difficult to perform an exact comparison between the two papers as they are solving two different problems. The model developed in [1] (Devlin et al, 2017) performs program induction: i.e. it produces the output world on a new input world where the desired program semantics are encoded in the network itself. On the other hand, in our case, we perform program synthesis, i.e. generate a program in the Karel DSL that performs the desired transformation from input to output. \n \nUsing the terminology of Devlin et al., what we describe is closest to the meta-induction approach: strong cross task knowledge sharing but no task specific learning. Overall, our MLE baseline architecture will correspond to the Devlin et al. meta-induction architecture if the decoder was trained to generate program tokens instead of output worlds. This precision was added to the paper\n\n-> No real-world task such as FlashFill?\nThe FlashFill DSL considered in previous neural program synthesis work such as RobustFill is essentially a functional language comprising of compositions of a sequence of functions. In this work, we wanted to increase the complexity of the DSL one step further to better understand what neural architectures are more appropriate for learning programs with such complexity. Concretely, the Karel DSL consists of complex control-flow such as nested loops and conditionals, which are not present in the FlashFill DSL. The difference of performance of meta-induction on FlashFill (~70% from  Figure 7 of [2]) vs. KarelDSL (~40% from Figure 4 of [1]) points towards Karel being a more complex dataset.\n\n Learning Karel programs can also be considered close to a real-world task as this language is used to teach introductory programming to Stanford students, and the program synthesis models can be used to help students if they are having difficulty in writing correct programs.\n\n\n[1] Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli. Neural Program Meta-Induction. In NIPS, 2017\n[2] Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. Robustfill: Neural program learning under noisy I/O. In ICML, 2017 \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825738068, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper175/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper175/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper175/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825738068}}}, {"tddate": null, "ddate": null, "tmdate": 1514387706136, "tcdate": 1514387706136, "number": 1, "cdate": 1514387706136, "id": "r1GbKVb7G", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "forum": "H1Xw62kRZ", "replyto": "Hk4_Jw9xG", "signatures": ["ICLR.cc/2018/Conference/Paper175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper175/Authors"], "content": {"title": "Reply to Reviewer 2", "comment": "We thank the reviewer for the detailed comments on how to improve the exposition of our paper, which we included in the revised version.\n\n- Figure 2\u2019s size was increased to make the model clearer.\n\n- Reinforce vs. Monte Carlo estimate of the expected reward:\nEquation 8 indeed describes how we estimate the expected reward, we also added the form of the estimator of the expected gradient for a sample i to make what me meant clearer\n\nBeam search and Approximate probabilities\nEquation 10 indeed had a typo. The i in \u201ci \\in 1..C\u201d should have been a \u201cr\u201d, making the product a product of the probability of the C programs sampled from the approximate probability distribution. At a search depth of d, the heuristic used to prune candidate paths is the probability of the prefix (which you can think of as the product of equation (5) but limited to the first d terms). \n\nWe arrive at a search depth d with a set of S candidates. For each of these S candidates, we obtain the probability of the next token using the softmax. Combining the probability of this token with the product of the whole path that comes before it, we obtain the probability for S * (nb_possible_token) possible paths. We only keep the S best ones (possibly removing the ones that have reached a termination symbol) and repeat the step at the depth d+1.\nWe end up at the end with a set of S samples which are going to be used as the basis for our approximate distribution. We have added more description of the process to make it clearer.\n\nWhen syntax checking is available, whether in its learned form or not, it is implicitly included as its contribution is introduced just before the softmax (see Figure 2 if you can zoom in). A token judged non-syntactically correct would have a probability of zero, so the probability of the path containing it would be zero and would therefore not be included into the promising paths going to the next stage.\n\n\n- Is there value in learning syntax?\nIt might be possible to have access to a large amount of programs in a language without having access to a syntax checker, such as for example if we have downloaded a large amount of programs from a code repository. Moreover, it might be useful even for common languages: Note that what we require is a bit different to a traditional syntax checker: answering the question \u201cis this program syntactically correct\u201d, which any compiler would give; as opposed to what we have in equation 13 which corresponds to \u201cDo these first t tokens contain no syntax error and may therefore be a valid prefix to a program\u201d. The syntax checker we need has to return a decision even for non-complete program, therefore it would require some work to transform current compilers to return such answers.\nFinally, as shown in our experiments, using a learned syntax checker might perform better than using a formal one, as it can capture what represents an \u201cidiomatic\u201d program vs. a technically correct one.\n\n\n\f\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825738068, "id": "ICLR.cc/2018/Conference/-/Paper175/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper175/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper175/Authors|ICLR.cc/2018/Conference/Paper175/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper175/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper175/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper175/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825738068}}}, {"tddate": null, "ddate": null, "tmdate": 1513909560318, "tcdate": 1513823998272, "number": 1, "cdate": 1513823998272, "id": "Sy8bJjuMM", "invitation": "ICLR.cc/2018/Conference/-/Paper175/Public_Comment", "forum": "H1Xw62kRZ", "replyto": "H1Xw62kRZ", "signatures": ["~Taehoon_Kim1"], "readers": ["everyone"], "writers": ["~Taehoon_Kim1"], "content": {"title": "Questions about reproducibility of the paper", "comment": "Dear authors, \n\nThanks for your interesting paper that I enjoyed a lot. It is great to read new approaches in the field of program synthesis and its promising results. I believe the contributions of the paper are clear but the experimental details are not sufficient to reproduce the results. Below is the list that I found missing in the paper:\n\n1. Sampling method for input/output grid world (ex. # of markers, # of obstacles, Code blocks like repeat(19) { repeat (15) { ... }} or repeat(17) { turnRight } might work as noises)\n2. Sampling method for Karel program (ex. max # of tokens, max depth of program)\n3. How to deal with corner cases like program with endless loop\n4. 52 tokens for Karel DSL\n5. Batch size\n6. Detailed on beam search\n\nBecause the sampling methods of world and program are critical to set the difficulty of the problem, I think the authors could discuss in more details about it to extend the suggested methods. Can the author offer some details on this?\n\nThe current attempt to reproduce the Karel dataset can be found https://github.com/carpedm20/karel and https://github.com/carpedm20/program-synthesis-rl-tensorflow."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis", "abstract": "Program synthesis is the task of automatically generating a program consistent with\na specification. Recent years have seen proposal of a number of neural approaches\nfor program synthesis, many of which adopt a sequence generation paradigm similar\nto neural machine translation, in which sequence-to-sequence models are trained to\nmaximize the likelihood of known reference programs. While achieving impressive\nresults, this strategy has two key limitations. First, it ignores Program Aliasing: the\nfact that many different programs may satisfy a given specification (especially with\nincomplete specifications such as a few input-output examples). By maximizing\nthe likelihood of only a single reference program, it penalizes many semantically\ncorrect programs, which can adversely affect the synthesizer performance. Second,\nthis strategy overlooks the fact that programs have a strict syntax that can be\nefficiently checked. To address the first limitation, we perform reinforcement\nlearning on top of a supervised model with an objective that explicitly maximizes\nthe likelihood of generating semantically correct programs. For addressing the\nsecond limitation, we introduce a training procedure that directly maximizes the\nprobability of generating syntactically correct programs that fulfill the specification.\nWe show that our contributions lead to improved accuracy of the models, especially\nin cases where the training data is limited.", "pdf": "/pdf/f58500ef2f2e08832b2b72e534cc740ee50ac0b0.pdf", "TL;DR": "Using the DSL grammar and reinforcement learning to improve synthesis of programs with complex control flow.", "paperhash": "bunel|leveraging_grammar_and_reinforcement_learning_for_neural_program_synthesis", "_bibtex": "@inproceedings{\nbunel2018leveraging,\ntitle={Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis},\nauthor={Rudy Bunel and Matthew Hausknecht and Jacob Devlin and Rishabh Singh and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Xw62kRZ},\n}", "keywords": ["Program Synthesis", "Reinforcement Learning", "Language Model"], "authors": ["Rudy Bunel", "Matthew Hausknecht", "Jacob Devlin", "Rishabh Singh", "Pushmeet Kohli"], "authorids": ["rudy@robots.ox.ac.uk", "mahauskn@microsoft.com", "jacobdevlin@google.com", "risin@microsoft.com", "pushmeet@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791691743, "id": "ICLR.cc/2018/Conference/-/Paper175/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "H1Xw62kRZ", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper175/Authors", "ICLR.cc/2018/Conference/Paper175/Reviewers", "ICLR.cc/2018/Conference/Paper175/Area_Chair"], "cdate": 1512791691743}}}], "count": 12}