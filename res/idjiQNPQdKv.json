{"notes": [{"id": "idjiQNPQdKv", "original": "5uQWxFUUpv6", "number": 20, "cdate": 1615310252289, "ddate": null, "tcdate": 1615310252289, "tmdate": 1615313021813, "tddate": null, "forum": "idjiQNPQdKv", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/SSL-RL/-/Blind_Submission", "content": {"title": "Automatic Goal Generation using Dynamical Distance Learning", "authorids": ["ICLR.cc/2021/Workshop/SSL-RL/Paper20/Authors"], "authors": ["Anonymous"], "keywords": ["Reinforcement Learning", "Curriculum learning", "goal conditioned RL", "self supervision"], "TL;DR": "A method for goal generation using dynamical distance functions thus automatically producing a curriculum.", "abstract": "Reinforcement Learning (RL) agents can learn to solve complex sequential decision making tasks by interacting with the environment. However, sample efficiency remains a major challenge. In the field of multi-goal RL, where agents are required to reach multiple goals to solve complex tasks, improving sample efficiency can be especially challenging. On the other hand, humans or other biological agents learn such tasks in a much more strategic way, following a curriculum where tasks are sampled with increasing difficulty level in order to make gradual and efficient learning progress. In this work, we propose a method for automatic goal generation using a dynamical distance function (DDF) in a self-supervised fashion. DDF is a function which predicts the dynamical distance between any two states within a markov decision process (MDP). With this, we generate a curriculum of goals at the appropriate difficulty level to facilitate efficient learning throughout the training process. We evaluate this approach on several goal-conditioned robotic manipulation and navigation tasks, and show improvements in sample efficiency over a baseline method which only uses random goal sampling.", "pdf": "/pdf/58cdc9b8f259c4e8d780fc95fde6415e09cd24a9.pdf", "paperhash": "anonymous|automatic_goal_generation_using_dynamical_distance_learning", "_bibtex": "@inproceedings{\nanonymous2021automatic,\ntitle={Automatic Goal Generation using Dynamical Distance Learning},\nauthor={Anonymous},\nbooktitle={Submitted to Self-Supervision for Reinforcement Learning Workshop - ICLR 2021},\nyear={2021},\nurl={https://openreview.net/forum?id=idjiQNPQdKv},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/SSL-RL"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/SSL-RL"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/SSL-RL"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/SSL-RL"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/SSL-RL"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/SSL-RL"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615310247528, "tmdate": 1615313016556, "id": "ICLR.cc/2021/Workshop/SSL-RL/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}