{"notes": [{"id": "iQxS0S9ir1a", "original": "2k3f2NymIbf", "number": 1932, "cdate": 1601308212949, "ddate": null, "tcdate": 1601308212949, "tmdate": 1614985715851, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "qyI-W9HTG9g", "original": null, "number": 1, "cdate": 1610040426772, "ddate": null, "tcdate": 1610040426772, "tmdate": 1610474026344, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper introduces a notion of distributional generalization, which aims at characterizing aspects of underlying distribution that are learned by a trained predictor. Authors make several interesting conjectures and support them with empirical evidence. Reviewers agreed on the novelty of the ideas; however, the work seems to be preliminary in its current form. Unfortunately, I cannot recommend acceptance at this time. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040426759, "tmdate": 1610474026327, "id": "ICLR.cc/2021/Conference/Paper1932/-/Decision"}}}, {"id": "9P_EBzS9-6o", "original": null, "number": 8, "cdate": 1606167768875, "ddate": null, "tcdate": 1606167768875, "tmdate": 1606167768875, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "rgZ5zTaH6F7", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Revised PDF uploaded", "comment": "We have updated the PDF with the following additions, following reviewer comments:\n\n- Added Appendix C.7 and Figure 15, to illustrate the concrete quantitative prediction of Conjecture 1. We show experimentally that the TV-distance between the joint distributions $(L(x), f(x))$ and $(L(x), y)$ is at most $\\epsilon$, as predicted by our conjecture. We hope this addresses concerns of Reviewer 1 and Reviewer 4 that the conjecture is only qualitative.\n- Added Appendix D.3, which explores (and eventually refutes) two potential mechanisms which could explain the \u201cAgreement Property\u201d. This shows the subtlety of this property, and helps support future work into the mechanisms behind it.\n- We expanded the Conclusion to discuss how our work relates to the study of Classical Generalization. We also discuss how our results should update certain folklore intuitions about \u201cmemorization\u201d in interpolating models.\n- We added a brief list of open questions raised by our work (Section 6.1)\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "1H3WjRabGE", "original": null, "number": 3, "cdate": 1605156778504, "ddate": null, "tcdate": 1605156778504, "tmdate": 1605233452902, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "9YWrlrqZGX9", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Response to R4", "comment": "Thank you for recognizing that our conjectures are interesting, and our experiments thorough.\nRegarding the lack of theoretical justification, please see our common response to all reviewers, which clarifies that this paper should be seen as primarily an empirical work.\n\nWe address your other concerns below:\n\nRegarding the practical usefulness: The primary objective of this paper is scientific \u2014 to help understand the behavior of methods used in practice. We do not aim to directly improve current methods, but rather to provide a lens for studying and understanding them.\nThis is in the same vein as papers such as [Zhang et al], which have led to further theoretical and empirical insights into generalization in deep learning.\n\nFor Conjecture 2 specifically: We did investigate whether this property can be used for calibrated uncertainty estimates, but unfortunately this does not work for very interesting and subtle reasons (briefly, Conjecture 2 holds \u201con average\u201d over inputs, but not \u201cpointwise\u201d, which is what you need for pointwise uncertainty estimates). We omitted these experiments from the submitted version, but we will update the Appendix to include these investigations.\n\nFor Conjecture 1: \nWe agree it would be valuable to enumerate the set of all distinguishable features. This may be infeasible, because this set could be very large (even exponentially large in natural parameters).\nInstead, we give a procedure for \u201ctesting\u201d if a given partition L is a distinguishable feature (Definition 1). So, for any candidate feature, you can efficiently test if it is distinguishable or not.\n\nRegarding the claim that the current formulation of the conjecture is \u201ctoo loose\u201d:\nNote that Conjecture 1 makes a precise, quantitative claim about the total-variation distance between two distributions, in terms of testable problem parameters (the epsilon-distinguishability of the feature).  This Conjecture captures the correct quantitative behavior for all of the experiments in Section 3.1. Each of the experiments in 3.1 highlights a different aspect of interpolating classifiers, and our Conjecture correctly predicts all of these behaviors.\n\nWe hope that given your positive impression of our conjectures and experiments, the score can be increased to \u2018accept\u2019 if you are satisfied with our answers to your questions.\n\n\n\n\n[Zhang et al.] \u201cUnderstanding deep learning requires rethinking generalization\u201d.  ICLR 2017."}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "XC-ZsMPHeh1", "original": null, "number": 6, "cdate": 1605157131923, "ddate": null, "tcdate": 1605157131923, "tmdate": 1605157131923, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "_623CXN_77", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Response to R3", "comment": "Thank you for your review; we are glad you appreciate the empirical contribution of this work.\n\nWe also agree that Conjecture 1 suggests some deeper connection between interpolating classifiers and hierarchal learners \u2014 we hope our work can inspire future study into these mechanisms. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "TenhOrFCNe", "original": null, "number": 5, "cdate": 1605157035455, "ddate": null, "tcdate": 1605157035455, "tmdate": 1605157035455, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "vN3RJYOK_G", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Response to R1", "comment": "Thanks for your feedback. We believe there may have been some misunderstandings about crucial aspects of our results, which we clarify below. \n\n\n- Re. \"The role of L\u201d:  The notion of L is not defined just for experimental convenience \u2014 it is fundamental to the result. Formally, specifying a set of L is equivalent to specifying a notion of closeness between two probability distributions (known as an \u201cIntegral Probability Metric\u201d in the literature). There are many cases where the train and test distributions are NOT close in total variation, as you suggest. But they can be close in other weaker metrics, which is captured by L. (See the \u201ccoarse partition\u201d experiments in Section 3.1). For instance, we know that fully connected networks don\u2019t generalize on images (so they will not be close in total variation distance). Our conjecture gives us a precise way to characterize how fully connected networks may be expected to generalize (for eg: they will still match the marginal probabilities as shown in Figure 7 or in the Animal-Object partition in Figure 14)\nFinally, you claim that the existence of distinguishable features is a strong assumption. This is not true, since the constant function L=0 is always a distinguishable feature (as we explain in Section 3.1). \n- Re \u201ccounterexample in which classifier has classical generalizability but not distributional generalizability\u201d: This is trivially impossible \u2014 if the function generalizes perfectly then f(x)=y everywhere, which means that the joint distributions (x, y) and (x, f(x)) are identical. This implies that distributional generalization trivially holds (since for every function L, (L(x), y) and (L(x), f(x)) will also be identical)\n- Re. \u201cIt is not clear to me why interpolated classifiers will induce this closeness.\u201d: The first approximate-equality in the Meta-conjecture is not specific to interpolating classifiers, but is simply the statement of distributional generalization. We explain this in the Introduction, and Section 5 shows how to apply this to non-interpolating models, which should answer your question.\n- Re. your question on total-variation distances: Conjecture 1 makes a quantitative prediction about the total-variation distance between coarsened train and test distributions (it is upper bounded by epsilon). Our experiments confirm that this closeness is within the predicted bounds. To further illustrate this, we will include an additional plot that shows the total variation distance as a function of the epsilon. \n- Re Notation: We use standard notation for sampling from probability distributions, but we will clarify the notation further in the next update. For clarification, $D^n$ denotes a product distribution over n samples from the distribution D. $S$ is a random variable over $(X \\times Y)^n$ that is sampled from the distribution $D^n$. The notation $A \\equiv B$ means distributions $A$ and $B$ are identical. \n- Re \u201cRigorous proofs\u201d: Please see our common response regarding the notion of theoretical justification \u2014  this is primarily an empirical paper.\n\nWe are glad our work convinced you that \u201cdistributional generalization is really a thing.\u201d\nWe believe this is a significant contribution towards understanding interpolating classifiers.\nTo help us understand your score, could you please clarify if your concerns are about the validity of the results, or their novelty?\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "aSFKTkEcnAf", "original": null, "number": 4, "cdate": 1605156854267, "ddate": null, "tcdate": 1605156854267, "tmdate": 1605156854267, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "oVm6p6iuAA3", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Response to R2", "comment": "Thank you for your feedback, and for recognizing that our results are \u201cboth interesting and surprising.\u201d\n\nRegarding your main concerns:\n\nRe. \u201cconditions on the distribution, algorithm, and model class\u201d:\nThis limitation is not unique to our work, but common to almost all works in the science of deep learning. That is, precisely stating these conditions amounts to formalizing exactly what is \u201creal\u201d about real-world distributions (as opposed to synthetic ones), and what is special about models and optimizers used in practice (as opposed to contrived ones). \nSome papers approach this by considering toy models of real distributions & architectures, such as gaussian inputs and random features. However, instead of passing to toy models, we prefer to deal only with real data and models throughout. This buys us realism, but comes at the necessary cost of formalism.\n\nRe. \u201cwhy studying this form of generalization would be useful for understanding interpolating classifiers and generalization in general\u201d: \n\nSeveral main reasons:\n\n1. First, if we care about understanding interpolating classifiers, then the first step is to understand their empirical behaviors. That is, we should first understand what structural properties are true about these classifiers before we can prove them theoretically. Our empirical work characterizes classifier outputs in a more fine-grained way(*) than any previous work we are aware of. \n2. Potential mechanism: As Reviewer 3 also suggests, our work indicates that interpolating classifiers implicitly learn to behave differently on \u2018distinguishable features' even when they are not provided labels for these features explicitly. Mechanisms behind this type of empirical behavior may be useful in understanding the \u201cimplicit bias\u201d of deep learning. \n3. In theory, it can sometimes be easier to prove a stronger statement than a weaker one, because the stronger statement is \u201cmore true\u201d and holds more universally. This is the hope behind our work: though Distributional Generalization (DG) is stronger than classical generalization, it appears to be more robust, and holds more universally. Thus, DG may be an easier object to reason about even if we care about classical generalization.\n\n(*): For example, as noted by R1, most prior works consider only a single scalar \u2014 Test Risk or Test Error \u2014 while we study the entire Test Distribution.\n\nWe will include additional discussion about this in the next revision.\n\n\nRegarding your questions:\n\n1. Regarding locality: The notion of locality is often used in kernels in the context of Nadaraya-Watson kernel smoothers (as discussed in the full related works in Appendix A). However, these are very different objects from what we consider in this paper, which are kernel regressors. We are not aware of prior work on the locality properties of kernel regressors. \n2. Regarding the agreement property: We agree this is a very surprising property. It did not depend on the number of classes in our experiment. We actually attempted to uncover the mechanisms behind the agreement property in the course of this research \u2014 we did not succeed, but we refuted several potential mechanisms. We will include these investigations in an Appendix in the next revision, in case you are interested."}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "rgZ5zTaH6F7", "original": null, "number": 2, "cdate": 1605156665539, "ddate": null, "tcdate": 1605156665539, "tmdate": 1605156683334, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment", "content": {"title": "Common Response to All Reviewers", "comment": "We thank all the reviewers for their feedback. We clarify some common criticisms raised by several reviewers:\n\n1. \"Theoretical justification\": Our paper should be seen as primarily an empirical work, which stands as an independent contribution even without a theoretical proof for the conjectures. Our motivation for stating the formal conjecture is to precisely characterize the experimental observations, and to make future testable predictions. We hope this conjecture can eventually be proven, but that is not our objective in this work. (It is extremely rare in deep learning to have fully rigorous proofs about realistic experimental setups)\n    There have been numerous examples of works in deep learning like [Zhang et al.], [Nakkiran et al.] where extensive experiments were used to identify interesting behavior that should be further understood theoretically. \n    \n2. \u201cUsefulness in understanding existing algorithms\u201d: Our paper advances our understanding simply because it teaches us something new about existing algorithms \u2014 something previously unknown, and fairly universal. Moreover, our work suggests deeper mechanisms at play in interpolating classifiers, which we don\u2019t yet understand. For example, as Reviewer 3 points out, interpolating classifiers implicitly learn to behave differently on \u201cdistinguishable features\u201d even when they are not provided labels for these features explicitly. While understanding the exact mechanisms is beyond the scope of our paper, this empirical behavior is one characterization of the \u201cimplicit bias\u201d of deep learning. \n\n[Zhang et al.] \u201cUnderstanding deep learning requires rethinking generalization\u201d.  ICLR 2017.\n\n[Nakkiran et al.] \u201cDeep Double Descent: Where Bigger Models and More Data Hurt\u201d.  ICLR 2020. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iQxS0S9ir1a", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1932/Authors|ICLR.cc/2021/Conference/Paper1932/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923854153, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Comment"}}}, {"id": "_623CXN_77", "original": null, "number": 1, "cdate": 1603834453035, "ddate": null, "tcdate": 1603834453035, "tmdate": 1605024325938, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review", "content": {"title": "Review", "review": "This paper proposes an extended notion of generalization. The new proposed notion asks that for a family of tests $T: X \\times Y \u2192 [0,1]$, $T(x, f(x))$  will be similar for train/test examples. The paper proposes three interesting conjectures that are related to distributional generalization. The paper proves Conjecture 1 for nearest-neighbor classifiers. The paper also gives empirical evidence supporting their conjectures.\n\nI think this is a nice contribution. It raises some new questions on generalization, and points to some interesting properties that interpolating classifiers satisfy (at least empirically) that deserve to be studied in more detail. In particular, Conjecture 1 seems to suggest that there is a form of hierarchical learning that interpolating classifiers are doing without being told to explicitly do so. \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107610, "tmdate": 1606915779998, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1932/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review"}}}, {"id": "vN3RJYOK_G", "original": null, "number": 2, "cdate": 1603855581991, "ddate": null, "tcdate": 1603855581991, "tmdate": 1605024325876, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review", "content": {"title": "Review of Distributional Generalization", "review": "> Summarize what the paper claims to contribute\n\nThis paper generalizes the classical notion of generalization to the notion that the output of the classifier should be close when applied to the training data and the testing data. Two conjectures were made to predict the behavior of the distributional generalization for a few models and data. The first conjecture, Feature Calibration Conjecture, asserts that the distribution of the outputs are similar up to \u201cdistinguishable features\u201d. The second conjecture, Agreement Conjecture, asserts that test accuracy matches the classification stability for interpolated classifiers. A number of experiments surrounding these conjectures were conducted to illustrate the Distributional Generalization\n\n> List strong and weak points of the paper. Be as comprehensive as possible.\n+ Great idea to look into distribution of the output beyond the error. I think this is long overdue and this paper has a lot of potential.\n+ Comprehensive numerical studies which show some interesting findings.\n- Many vague and ambiguous notations which make the paper hard to read.\n- Barely any theoretical justification. \n- \"Too many\" ideas. I would suggest the authors to divide the paper into 3 papers and dig deeper in each topic. \n\n> Provide supporting arguments for your recommendation.\n\n1. Notation. While the display on the bottom of page 2 is supposed to be an informal conjecture, it may be too informal. Does x\u2208TestSet indicate a distribution or a set? What does \u2261 mean here? It was mentioned that the joint distribution of X and Y is D, and D^n denote n iid samples from D. But is D^n a sample of training data points, or a distribution? Later on it was mentioned that \"S \u223c D^n\" which does not make sense if D^n is a sample. \n2. There are only two theoretical results in the paper with rigorous proofs. But they are established for nearest neighbor classifier only and some assumptions are imposed which warrants the results straightforwardly. However, most of the conjectures are made for many classifiers beyond nearest neighbor. \n3. Indistinguishability and interpolated classifier: in the Indistinguishability meta-conjecture on page 2, the second equality is clearly due to interpolated classifier. I wonder if the closeness indicated in the first approximation (between trainset and testset) is a merit of the interpolated classifier, or the general good generalization performance of a classifier. It is not clear to me why interpolated classifiers will induce this closeness.\n4. The role of L. From what I can see, this intermediate feature L is introduced because \\mathcal{X} can be a large high-dimensional space which can make visualization or quantification of the closeness difficult. This function L is introduced so that it is easier to see how (L(x), f(x)) is distributed. For constant partition (L(x) = 0), the distributional generalization reduces to the marginal distribution of \"f(x)\". In my opinion, if a classifier is true generalizable, the distribution of (x, f(x)) itself, without L, should be the same between the test and training domains. From the statement of Theorem 1, it seems to me that  Conjecture 1 holds for nearest neighbor BECAUSE some distinguishable features exist, which may already be a strong assumption. So strong that the very existence of the distinguishable features warrants the generalizability. Unfortunately because there are only conjectures and no rigorous proofs, this part is still not clear to me.\n\n> Ask questions you would like answered by the authors to help you clarify your understanding of the paper and provide the additional evidence you need to be confident in your assessment. \n\nWhile the numerical studies have convinced me that distributional generalization is really a thing here, I am not sure that I am that impressed. After all, the precision was only two decimal points. Can the total-variation distance be calculated? Is there a counterexample in which one classifier does have classical generalizability but not distributional generalizability? Focus on a narrower set of topics but dig deeper may go a long way here.  \n\n> Minor comments\n\nPage 3: \u201cdo we this same procedure\u201d is a typo\nPage 4: how is \u201clearnable\u201d defined?\nPage 5: f\u2190Train F (D^n) is not defined, esp. given that it is unclear if D^n is a distribution or a set. Should D^n be replaced by S?\nPage 5: Indistinguishably is a typo\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107610, "tmdate": 1606915779998, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1932/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review"}}}, {"id": "oVm6p6iuAA3", "original": null, "number": 3, "cdate": 1603874388077, "ddate": null, "tcdate": 1603874388077, "tmdate": 1605024325814, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review", "content": {"title": "Interesting observations", "review": "This paper proposes a new notion of generalization called distributional generalization which states that the outputs of the classifier for train and test are close as distributions not just their corresponding accuracy numbers. They propose conjectures about their the distributional closeness that they expect and how it depends on the model, number of data points and the algorithm. This paper gives experiments to support their conjectures for different model classes including neural networks, kernel methods and decision trees.\n\nI find the notion of distributional generalization interesting. The first experiment of this paper is that the label noise introduced in the training set in one subgroup of a particular class is also localized in the same subgroup in the test set although the classifier does not have any explicit information about the subgroups which is interesting. The paper formally states that the distribution of train and test outcomes are similar in distribution with respect to tests which themselves can learned by that model class with the current number of samples.\n\nI recommend accepting this paper because the notion of distributional generalization that this paper introduces is both interesting and surprising. Moreover, this paper has shown that it holds widely across different interpolating classifiers like decision trees, neural networks and kernel methods.\n\nThe paper includes an extensive set of experiments that are easy to follow.\n\nOne concern is as itself mentioned in the paper that this work does not talk about what conditions on the distribution, algorithm and the model class are necessary for this conjecture to hold either empirically or theoretically and the conjecture is not precisely defined. Any insights on this part would be good to include. \n\nAnother concern is that although this is an interesting observation, the paper does not talk about why and how studying this form of generalization would be useful for understanding interpolating classifiers and generalization in general. \n\nQuestions:\n1) The authors suspect locality to be the underlying reason behind distributional generalization and find this observation to be true for kernel methods also. Do the authors know if there is some work on the locality aspects of kernel methods arguing that some particular kernels are more local than others and how this relates to the observations in this paper?\n2) Regarding the agreement property in section 4, I find it a little surprising that the conjecture says that the correlation and the accuracy are the same. Does this relate to the number of classes present?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107610, "tmdate": 1606915779998, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1932/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review"}}}, {"id": "9YWrlrqZGX9", "original": null, "number": 4, "cdate": 1603888730425, "ddate": null, "tcdate": 1603888730425, "tmdate": 1605024325758, "tddate": null, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "invitation": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review", "content": {"title": "Recommendation to Reject", "review": "This paper introduces a new notion of \"distributional generalization\" as a tool to quantify the difference between the outputs from training and testing data sets using a certain machine learning algorithm. The authors formulate two conjectures for the so-called \"Interpolating classifiers\": the Feature Calibration Conjecture and Agreement Conjecture. The conjectures are supported numerically by some real data experiments and are proven for the 1-nearest-neighbor classifier under some technical conditions. \n\nStrengths: \n1. Two conjectures are interesting and have the potential to explain some unexplained phenomena for some existing machine learning algorithms.\n2. Numerical experiments are quite thorough, using different data sets and different machine learning algorithms.\n\nWeaknesses:\n1. The justifications of the conjectures are almost purely empirical (except in the 1-nearest-neighbor (1-N-N) classifier case). However, the 1-NN classifier is just a toy example that has limited use in machine learning literature. In fact, one even does not need to train the 1-NN classifier given a training data set. This is probably why it is easy to analyze 1-NN under the considered setting.\n2. While observations from data experiments are interesting and I enjoyed reading them, the paper fails to directly demonstrate how these observations can be used to improve performances or our understandings of existing algorithms. For example, how Conjecture 2 is useful? can we use it to evaluate the uncertainty (or confidence interval) of the test accuracy?\nHow can we find distinguishable features in Conjecture 1 in practice? using trees?\n\nConclusion:\nAlthough I find the proposed conjectures interesting and may have potential values, the current formulation, and justification for these conjectures are a bit too superficial and loose. It is difficult for me to envision a scenario where these conjectures can make a meaningful impact.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1932/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1932/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Distributional Generalization: A New Kind of Generalization", "authorids": ["~Preetum_Nakkiran1", "~Yamini_Bansal1"], "authors": ["Preetum Nakkiran", "Yamini Bansal"], "keywords": ["understanding deep learning", "generalization", "interpolating methods", "empirical investigation"], "abstract": "We introduce a new notion of generalization--- Distributional Generalization--- which roughly states that outputs of a classifier at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our understanding of interpolating classifiers.", "one-sentence_summary": "We introduce a new notion of generalization (\"Distributional Generalization\"), to characterize empirical observations of interpolating classifiers.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "nakkiran|distributional_generalization_a_new_kind_of_generalization", "pdf": "/pdf/83b8f83a27d27f15b90866b2dfe44deff0fe8c48.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jTQFicoaG5", "_bibtex": "@misc{\nnakkiran2021distributional,\ntitle={Distributional Generalization: A New Kind of Generalization},\nauthor={Preetum Nakkiran and Yamini Bansal},\nyear={2021},\nurl={https://openreview.net/forum?id=iQxS0S9ir1a}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iQxS0S9ir1a", "replyto": "iQxS0S9ir1a", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1932/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107610, "tmdate": 1606915779998, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1932/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1932/-/Official_Review"}}}], "count": 12}