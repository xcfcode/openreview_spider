{"notes": [{"id": "S1gUCFx4dN", "original": "BJlidIdzd4", "number": 7, "cdate": 1553365454294, "ddate": null, "tcdate": 1553365454294, "tmdate": 1562082913175, "tddate": null, "forum": "S1gUCFx4dN", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Blind_Submission", "content": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Blind_Submission", "cdate": 1552732853551, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*", "values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/drlStructPred"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/drlStructPred"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1552732853551, "tmdate": 1554911328507, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}, "tauthor": "OpenReview.net"}, {"id": "SJg56IvdFV", "original": null, "number": 1, "cdate": 1554704065591, "ddate": null, "tcdate": 1554704065591, "tmdate": 1554910464395, "tddate": null, "forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Decision", "cdate": 1554496488146, "reply": {"forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554496488146, "tmdate": 1554910461693, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "SJlei_HIt4", "original": null, "number": 4, "cdate": 1554565272162, "ddate": null, "tcdate": 1554565272162, "tmdate": 1554910458026, "tddate": null, "forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "content": {"title": "Novel approach to improving VAEs", "review": "This paper is written clearly and is well thought out in its approach and results. Their contributions are clear, although ambitious as they aim to improve image reconstruction by providing a VAE a reconstructed image based on a grid image created via program synthesis. Their work does show improvement over most state of the art based on the Frechet distance as a performance measure in both their synthetic baseline as well as the Facades baseline other than VED which outperforms the proposed model. It can also be argued though that their improvements may be contributed to the augmented input overfitting the original structure. For samples in their work in which they are compared to VED, it is clear that their work does better represent the original structure, but it is not clear if their method has created a faithful reconstruction of the image or simply  a grid of an average part of the inputs which overfit to the given input. Overall, I believe this work is interesting and may be moving in the right direction for improving image reconstruction algorithms although it is an early start.", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "cdate": 1553778228253, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778228253, "tmdate": 1554911862952, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "B1gdsdortV", "original": null, "number": 3, "cdate": 1554524319524, "ddate": null, "tcdate": 1554524319524, "tmdate": 1554910457147, "tddate": null, "forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "content": {"title": "Interesting task.", "review": "This work consider the problem of generating or completing images with repeated structures. The main idea is to have a generative model which generates image x from hidden programs P, which is in turn generated from hidden embedding z.\n\nThe proposed model is mainly a VAE of programs P extended with components for the image x -- 1) domain greedy heuristics to generate P from x, and 1) CycleGAN to generate x from x_structure which is generated from P in a deterministic fashion.\n\nI find the task very interesting with potentially practical applications. The result on synthetic data looks pretty good (much better than VAE and SpatialGAN). The result on real dataset (1855 Facades) still need to be improved. It could be that the data set is just too small for the proposed model. It could also be search failure when generating P from x. Or there might be other reasons?\n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "cdate": 1553778228253, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778228253, "tmdate": 1554911862952, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "BJg_lNmBKN", "original": null, "number": 2, "cdate": 1554490351681, "ddate": null, "tcdate": 1554490351681, "tmdate": 1554910456001, "tddate": null, "forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "content": {"title": "Interesting technique to incorporate programs representing global structures in generative models", "review": "This paper presents a technique to incorporate programs (representing global structure in images) into the generative model thereby capturing more global structure in image generation and image completion tasks. For image generation tasks, it first samples a latent vector z that is used to then sample a program (s,c). The sampled program is then executed to generate x_struct, which is afterwards used to generate the image x using image completion techniques such as GLCIC and CycleGAN. For image completion tasks, it first samples a partial program P_part from a partial image x_part, and then extrapolates the partial program to generate a full program P. The full program is generated to obtain x_part+struct, which is then completed to obtain the full image. The approach is evaluated on synthetic and a real-world dataset of building facades, and it outperforms several baseline models.\n\nOverall, I really liked the idea of introducing programs as structural biases in the generative models, where the programs comprise of both symbolic (for loops) and neural (sub-images) components. While there are some recent approaches that have looked at learning such neuro-symbolic programs, this seems to be one of the first approaches for learning generative models of images. The idea of conditioning the image completion models on output obtained by evaluating such intermediate programs and extrapolating programs for completion tasks is also quite nice.\n\nAlthough this is an interesting first step, many of the design choices seem a bit restrictive for more general image generation tasks. For example, the paper only considers one for-loop template:\nfor (i,j):\n  draw (a*i+b, a'*i+b', ??)\nIt might be interesting to extend the class of templates to include nested loops with conditionals to capture more general global structures together with corner cases.\n\nThe search algorithm for synthesizing programs performs an exhaustive search and it is not clear if such an enumerative strategy would scale to richer program templates.\n\nFor the VAE decoder, is it the case that the sequence decoder decodes the for loop structure program directly?\n\nIt would also be good to provide a bit more details about the program extrapolation part for image completion model. For example, is there an assumption that all images are of equal size for the extrapolation model or is the model conditioned on the final expected size of the image?", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "cdate": 1553778228253, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778228253, "tmdate": 1554911862952, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "SyxlnxOXFE", "original": null, "number": 1, "cdate": 1554378920036, "ddate": null, "tcdate": 1554378920036, "tmdate": 1554910453756, "tddate": null, "forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "content": {"title": "The paper presents an program synthesis method for image generation, experiments focus on domain specific/synthetic datasets where the models are expected to work well, but does have potential to be applied on more general datasets", "review": "The paper presents an image generation model, focusing on learning a program that explores the regularities within the data, such as cycling patterns. The model aims at learning two hidden variables, one that defines the structure of the program and another that defines how the model fills the patches defined within the program. \n\nI believe this is a good direction for research in image generation, or any generation tasks of similar nature. Such models would allow for computationally efficient models, especially for generating higher resolution images, since there is a quadratic increase of the number of parameters needed. It would be great that in the future versions of the paper the authors could show that larger images can be learned with similar numbers of model parameters. \n\nFinally, I would like to see results on medium to larger scale datasets, such as CIFAR-10 or Imagenet. Not only samples are more diversified, it would also allow for an analysis of the sample efficiency of the proposed method compared to existing methods.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING NEUROSYMBOLIC GENERATIVE MODELS VIA PROGRAM SYNTHESIS", "authors": ["Halley Young", "Osbert Bastani", "Mayur Naik"], "authorids": ["halleyy@seas.upenn.edu", "obastani@seas.upenn.edu", "mhnaik@seas.upenn.edu"], "keywords": ["structure", "deep learning", "generative models", "structured prediction"], "TL;DR": "Applying program synthesis to the tasks of image completion and generation within a deep learning framework", "abstract": "Significant strides have been made toward designing better generative models in recent years. Despite this progress, however, state-of-the-art approaches are still largely unable to capture complex global structure in data. For example, images of buildings typically contain spatial patterns such as windows repeating at regular intervals; state-of-the-art generative methods can\u2019t easily reproduce these structures. We propose to address this problem by incorporating programs representing global structure into the generative model\u2014e.g., a 2D for-loop may represent a configuration of windows. Furthermore, we propose a framework for learning these models by leveraging program synthesis to generate training data. On both synthetic and real-world data, we demonstrate that our approach is substantially better than the state-of-the-art at both generating and completing images that contain global structure.\n", "pdf": "/pdf/303256eb2c29ab532fe9b3ebcbebebba04bfde2a.pdf", "paperhash": "young|learning_neurosymbolic_generative_models_via_program_synthesis"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper7/Official_Review", "cdate": 1553778228253, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "S1gUCFx4dN", "replyto": "S1gUCFx4dN", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper7/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778228253, "tmdate": 1554911862952, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper7/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}], "count": 6}