{"notes": [{"id": "Skx73lBFDS", "original": "B1gd4gZYwr", "number": 2530, "cdate": 1569439914641, "ddate": null, "tcdate": 1569439914641, "tmdate": 1577168236593, "tddate": null, "forum": "Skx73lBFDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "_mmUJ7DqbB", "original": null, "number": 1, "cdate": 1576798751359, "ddate": null, "tcdate": 1576798751359, "tmdate": 1576800884332, "tddate": null, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "invitation": "ICLR.cc/2020/Conference/Paper2530/-/Decision", "content": {"decision": "Reject", "comment": "The paper presents a linear classifier based on a concatenation of two types of features for protein function prediction. The two features are constructed using methods from previous papers, based on peptide sequence and protein-protein interactions. \n\nAll the reviewers agree that the problem is an important one, but the paper as it is presented does not provide any methodological advance, and weak empirical evidence of better protein function prediction. Therefore the paper would require a major revision before being suitable for ICLR.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795710383, "tmdate": 1576800259375, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2530/-/Decision"}}}, {"id": "HJl3xM52tr", "original": null, "number": 1, "cdate": 1571754484243, "ddate": null, "tcdate": 1571754484243, "tmdate": 1572972326548, "tddate": null, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "invitation": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This work tries to predict the protein functional activation on a tissue by combining the information from amino acid sequence, and tissue-specific protein-protein interaction network. The authors claim that with this joint representation, their model outperforms current methods (Omhnet) on 10 out of 13 tissues by a larger margin(19% on average).\n\nNotations:\nThe notations in experiment is a little bit confusing. In Table 1, the authors refer to different representations with Ohmnet128, Ohmnet64, Ohmnet-Unirep, etc. However, these are not consistent to the ones introduced in Section 4.1: Ohmnet, Ohmnet64-Unirep64, etc. And \"0-pad\" is introduced in section 3.3 while they denote one method as \"Ohmnet64-0Padded\" in section 4.1. It would be difficult for the reader to infer the meaning of these abbreviations.\n\nMethod:\n\n--amino acid sequence representation:\nIt would be better to report the explained variance when using Principle Component Analysis (PCA) to project the 1024-dimensional output vector of SeqVec to 64 dimensional space.  And the authors can show us more results of different projected dimensions (with different explained variance of the PCA).\n\nExperiments:\n\n--model:\nMaybe the authors can provide us more information about the model they use. For classification, what exactly the linear model is? For learning representation, is there any modification of the structure and hyperparameter of UniRef, SeqVec and OhmNet? And is there any regularization? Showing training details like batch size, epochs would be helpful, too.\n\n--data:\nIt would be better to show the details of the data this paper uses, like what the data looks like, what is the size, the distribution, and the pre-processing. What's more, since validation set is used for tuning, it would be better to report the results on test set.\n\n--result:\nIn the second paragraph of Section 4.1, it would be more clear to use a table instead of words to show the results. What's more, what's exactly the 13 tissues this paper is using? Why they are chosen? Exactly what is the AUROC of each protein in each tissue?  What the learning curves look like?\n\nAnother big issue is, what \"current methods\" is this paper comparing its result with? It seems like the authors are comparing their implementation of Ohmnet-SeqVec + linear model with Ohmnet + linear model, and report that the former one is of 19% higher AUROC than the latter. But how about the results of other models/methods on the same task in the literature. Is there anyone using similar joint representation and what is their results? \n\n--conclusion:\nSince the proposed methods only achieve best results  in 10 out of 13 tissues, it is improper to claim \"\u2026 we make consistently better tissue-specific function predictions in 13 complex tissues \u2026\".\n\nIn conclusion, I find this is an interesting paper, that the authors tries to combine amino acid sequence representation and tissue information to predict the activation of protein on specific tissue. However, the authors should perform more rigorous experiment, and show us more implementation details. What's more, comparing results with the start-of-art methods on the same task setting is important, too.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574934106008, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2530/Reviewers"], "noninvitees": [], "tcdate": 1570237721548, "tmdate": 1574934106023, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review"}}}, {"id": "S1x_LgRTtr", "original": null, "number": 2, "cdate": 1571835983643, "ddate": null, "tcdate": 1571835983643, "tmdate": 1572972326511, "tddate": null, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "invitation": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper introduces a method to incorporate both sequence information and graph information to learn the protein representations. The idea is very straightforward. Basically, it used the embedding from OhmNet [Marinka et al, 2017] for the graph information and used the sequence information from UniRep [Ethan et al, 2019] or SeqVec [Michael et al, 2019]. It uses one experiment to show the performance of the combination of the two pieces of information.\n\nThis paper should be rejected for the following reasons: \n(1) The paper is obviously in the preliminary form without too much polish.\n (2) The simple combination of the results from two published articles is not that interesting\n(3) the presentation of the paper and idea is not in an acceptable form (the authors should at least draw a figure to show the big idea of the paper).\n(4) the experiment is not convincing (there is only one experiment and it is not compared with the other state-of-the-art methods; since an embedding of a protein can be of broad usage, the authors should give its performance on four tasks: protein function prediction (GO term) [Maxat et al, 2018], enzyme function prediction (EC number) [Yu et al, 2018], protein secondary structure prediction [Sheng et al, 2016], protein contact map prediction [Jinbo Xu, 2019]) \n(5) The learned embedding is not well discussed. The author should at least visualize the embeddings and check the physical and biological meaning of those embeddings, if possible. \n\nSince this manuscript would be for sure and have to be largely rewritten in the future, I would not give too many detailed suggestions but some high-level suggestions if the authors would like to refine this manuscript further and submit it somewhere else or ICLR next year:\n(1) Further improve the idea of combining different sources of information. Combining different pieces of information will definitely be helpful but the authors should figure out a way to use them in a more natural way.\n(2) Compared with other methods, which can combine different sources of information.\n(3) Run more experiments on various tasks instead of one: protein function prediction (GO term), enzyme function prediction (EC number), protein secondary structure prediction, protein contact map prediction\n(4) Refine the representation of the paper.\n\nReferences:\n[Marinka et al, 2017] Predicting multicellular function through multi-layer tissue networks, 2017, https://arxiv.org/abs/1707.04638\n[Ethan et al, 2019] Unified rational protein engineering with sequence-based deep representation learning, 2019, Nature Methods\n[Michael et al, 2019] Modeling the Language of Life \u2013 Deep Learning Protein Sequences, 2019, https://www.biorxiv.org/content/10.1101/614313v2\n[Maxat et al, 2018] DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier, 2018, Bioinformatics\n[Yu et al, 2018] DEEPre: sequence-based enzyme EC number prediction by deep learning, 2018, Bioinformatics\n[Sheng et al, 2016] Protein Secondary Structure Prediction Using Deep Convolutional Neural Fields, 2016, Scientific Reports\n[Jinbo Xu, 2019] Distance-based protein folding powered by deep learning, 2019, PNAS"}, "signatures": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574934106008, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2530/Reviewers"], "noninvitees": [], "tcdate": 1570237721548, "tmdate": 1574934106023, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review"}}}, {"id": "S1gcZeCCFB", "original": null, "number": 3, "cdate": 1571901442227, "ddate": null, "tcdate": 1571901442227, "tmdate": 1572972326463, "tddate": null, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "invitation": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "In this study, the authors develop a method to predict the function of proteins from their structure as well as the network of proteins with which they interact in a given tissue. The method consists in training a linear classifier on the output of two existing embedding methods, UniRep/SeqVec and OhmNet, respectively embedding the amino acid sequences and the tissue-specific protein-protein interaction networks. This method improves prediction of protein function by 19% compared to OhmNet alone.\n\nAlthough the topic is important and the article clearly written, I would tend to reject this article because there is no innovation in ML that would justify presentation at ICLR.\n\nStrengths:\n- the article is well-written and straight-forward. Prior art is well-described.\n- timely and important topic (prediction of protein function), where ML is likely to have an big impact.\n- positive scientific result (prediction is improved compared to prior art).\n\nWeakness:\n- the ML aspect of this work is entirely based on prior art, the main innovation consisting in fitting a linear classifier on concatenated features extracted by two existing embedding methods (UniRep/SeqVec and OhmNet).\n\n\nAdditional feedback:\n- In the ablation studies, why not include the condition SeqVec-Random and UniRep-random?\n-\"The average AUROC score from Random is a big higher than what could be expected from such representations thanks to the spikes (Placenta, Epidermis) which might also result from the huge functional class imbalance within those two tissues which, given the uniformity of the data, gets them more often than not on the right side of the hyperplane. \"\n=> unclear sentence.\n- \"is a big higher\" => typo\n- \"beta sheets .\" => typo\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2530/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2530/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574934106008, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2530/Reviewers"], "noninvitees": [], "tcdate": 1570237721548, "tmdate": 1574934106023, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2530/-/Official_Review"}}}, {"id": "BJgIvFnadr", "original": null, "number": 1, "cdate": 1570781533521, "ddate": null, "tcdate": 1570781533521, "tmdate": 1570783820808, "tddate": null, "forum": "Skx73lBFDS", "replyto": "Skx73lBFDS", "invitation": "ICLR.cc/2020/Conference/Paper2530/-/Public_Comment", "content": {"comment": "The approach described in this work fuses protein information (obtained via embeddings) and network information (obtained via observed protein-protein interactions) to predict protein function according to GO. The proposed method betters the existing ones by a margin of 19%.\n\n- About the writing:\n\nIn general, I find the manuscript is written in good English. Nevertheless, at times, I feel more consideration should have been put in the choice of words in order to ease a non biological audience into the manuscript. En example of this is \"Proteins are generally understood through four levels of structures\", and following use of the word \"structure\" (e.g. in primary structure) in the Introduction. In protein space, structure has a very precise meaning. I would have personally preferred the word representation, or alike. On this note: sometimes the writing gets rapidly technical, and I fear that the audience might not fully grasp important concepts. An example of this is the description of quaternary structure in the introduction, which could be easily explained by simply describing proteins forming interactions amongst themselves or other proteins. Furthermore, the authors seem to sometimes loose consistency, e.g. UniRep becomes Unirep, SeqVec becomes Seqvec, OhmNet becomes Ohmnet. There also seem to be artifacts of editing, e.g.:\n\n... thanks to spikes (Placenta, Epidermis) ....\n\nbut never before have actual tissues been discussed and there is no reference to a figure which might display said spikes. More on this to follow.\n\nAnother example are the two last paragraphs of the Introduction, which share the same beginning \"In this work,..\", where instead I would have expected a natural following of the last paragraph to the second last.\n\n- Background/related work:\n\nWhile this particular approach (embeddings+graph) is the first I've heard of, I can hardly imagine there not existing any other approach using a mix of protein-level (1D) and network-level (4D) information. It would have been nice to see at least one paragraph spent on any previous work that aims at solving protein function prediction using these information.\n\nI find the manuscript is generally lacking in citations, breath and detail. For example, the authors describe sequence homology (as a way to infer function), but never reference important work introducing or exploring this concept (from the top of my head: Sander 1991, Rost 1992). Another example, in the Introduction, relates to the concept of secondary structure, which is described in Kabsch&Sander 1983.\n\nSome claims (e.g. in the Introduction) lack proper validation (either external or in the manuscript), e.g. \"Recent availability of high-throughoutput experimental data and machine learning based computational methods can be useful for unveiling and understanding such patterns.\": Why? Where is this shown?\n\n- Science & results:\n\nWhile I see the appeal of the approach, I am not convinced that the authors are currently able to prove this. I am lacking many things: a proper description of the goal (I personally get confused about tissue-specific functions vs. GO, vs. prediction of the tissue,...), hard numbers on the targets (binary classification of GO terms: how many? which ones? Supplementary table),...\n\nIn my general confusion, I stumbled across a giant red flag for protein-related prediction tasks: the split of test and training sets. The authors describe this as a stratified random split. I sincerely hope that the stratification has NOT been made by looking at homology, and instead I wish the authors had discussed reduction of homology in their training and test sets, potentially picking very far related proteins between the different sets. Not to mention: I'm missing the size of test and train, and what \"stratification\" means in this context, how many samples per label,...\n\nDummy vectors: I'm not sure that the boundaries in the vector spaces of OhmNet and SecVeq are [-1, 1].\n\nThe authors at some point introduce a \"Ohmnet64-0Padded\" and \"Ohmnet64-Random64\" feature vectors, but I was unable to find any results for using these in the manuscripts.\n\nIn Table 1: I'm missing something that approximates an error estimate. I would have preferred to see the actual curves, in order to gaze an understanding about how their behavior in different conditions of sensitivity/specificity.\n\nAs mentioned above, \"spikes\" are mentioned, but no graph is presented. I'm missing the exact tissues for which each predictor was better (e.g. 6/13 and 4/13 --> hard numbers don't tell me if they are not overlapping).\n\nThese last considerations make me personally very suspicious about the results presented.\n\n- Conclusion\n\nI find the manuscript explores an interesting idea, but I *urge* the authors to rework the manuscript from top to bottom to (i) explain the background better, (ii) explain the problem they are trying to solve better, (iii) present the datasets, labels, classes better, and (iv) the results more clearly.", "title": "Interesting idea but needs major rework"}, "signatures": ["~Christian_Dallago1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Christian_Dallago1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hassanmohamed@alum.mit.edu", "mohamed-konoufo.coulibali.1@ulaval.ca", "pelkins@alum.mit.edu", "aabdalla@alum.mit.edu"], "title": "Combining graph and sequence information to learn protein representations", "authors": ["Hassan Kan\u00e9", "Mohamed Coulibali", "Pelkins Ajanoh", "Ali Abdalla"], "TL;DR": "We learn protein representations by integrating data from physical interaction and amino acid sequence", "abstract": "Computational methods that infer the function of proteins are key to understanding life at the molecular level. In recent years, representation learning has emerged as a powerful paradigm to discover new patterns among entities as varied as images, words, speech, molecules. In typical representation learning, there is only one source of data or one level of abstraction at which the learned representation occurs. However, proteins can be described by their primary, secondary, tertiary, and quaternary structure or even as nodes in protein-protein interaction networks. Given that protein function is an emergent property of all these levels of interactions in this work, we learn joint representations from both amino acid sequence and multilayer networks representing tissue-specific protein-protein interactions. Using these representations, we train machine learning models that outperform existing methods on the task of tissue-specific protein function prediction on 10 out of 13 tissues. Furthermore, we outperform existing methods by 19% on average.", "keywords": ["NLP", "Protein", "Representation Learning"], "pdf": "/pdf/bce08842ef00a7182222b1dfa6b03b21ed03187a.pdf", "paperhash": "kan\u00e9|combining_graph_and_sequence_information_to_learn_protein_representations", "original_pdf": "/attachment/f9266489d81f66d5cf461c01bc2aa896786326e0.pdf", "_bibtex": "@misc{\nkan{\\'e}2020combining,\ntitle={Combining graph and sequence information to learn protein representations},\nauthor={Hassan Kan{\\'e} and Mohamed Coulibali and Pelkins Ajanoh and Ali Abdalla},\nyear={2020},\nurl={https://openreview.net/forum?id=Skx73lBFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skx73lBFDS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504178972, "tmdate": 1576860585801, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2530/Authors", "ICLR.cc/2020/Conference/Paper2530/Reviewers", "ICLR.cc/2020/Conference/Paper2530/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2530/-/Public_Comment"}}}], "count": 6}