{"notes": [{"tddate": null, "ddate": null, "tmdate": 1519434902932, "tcdate": 1509118548120, "number": 445, "cdate": 1518730177501, "id": "HJhIM0xAW", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "HJhIM0xAW", "original": "ryoLGRgCb", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Learning a neural response metric for retinal prosthesis", "abstract": "Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.", "pdf": "/pdf/5748c2fc8bad28c747dd863460f846c9dbf614ad.pdf", "TL;DR": "Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.", "paperhash": "shah|learning_a_neural_response_metric_for_retinal_prosthesis", "_bibtex": "@inproceedings{\np2018learning,\ntitle={Learning a neural response metric for retinal prosthesis},\nauthor={Nishal P Shah and Sasidhar Madugula and EJ Chichilnisky and Yoram Singer and Jonathon Shlens},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJhIM0xAW},\n}", "keywords": ["Metric learning", "Computational Neuroscience", "Retina", "Neural Prosthesis"], "authors": ["Nishal P Shah", "Sasidhar Madugula", "EJ Chichilnisky", "Yoram Singer", "Jonathon Shlens"], "authorids": ["nishalps@stanford.edu", "sasidhar@stanford.edu", "ej@stanford.edu", "singer@google.com", "shlens@google.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260096378, "tcdate": 1517249406554, "number": 186, "cdate": 1517249406540, "id": "BJvtXy6SG", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "This work shows interesting potential applications of known machine learning techniques to the practical problem of how to devise a retina prosthesis that is the most perceptually useful. The paper suffers from a few methodological problems pointed out by the reviewers (e.g., not using the more powerful neural network encoding in the subsequent experiments of the paper), but is still interesting and inspiring in its current state.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a neural response metric for retinal prosthesis", "abstract": "Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.", "pdf": "/pdf/5748c2fc8bad28c747dd863460f846c9dbf614ad.pdf", "TL;DR": "Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.", "paperhash": "shah|learning_a_neural_response_metric_for_retinal_prosthesis", "_bibtex": "@inproceedings{\np2018learning,\ntitle={Learning a neural response metric for retinal prosthesis},\nauthor={Nishal P Shah and Sasidhar Madugula and EJ Chichilnisky and Yoram Singer and Jonathon Shlens},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJhIM0xAW},\n}", "keywords": ["Metric learning", "Computational Neuroscience", "Retina", "Neural Prosthesis"], "authors": ["Nishal P Shah", "Sasidhar Madugula", "EJ Chichilnisky", "Yoram Singer", "Jonathon Shlens"], "authorids": ["nishalps@stanford.edu", "sasidhar@stanford.edu", "ej@stanford.edu", "singer@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642449954, "tcdate": 1511385546375, "number": 1, "cdate": 1511385546375, "id": "HyzRKw7xf", "invitation": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "signatures": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Really neat idea, but execution could use some work", "rating": "5: Marginally below acceptance threshold", "review": "The authors develop new spike train distance metrics that cluster together responses to the same stimulus, and push responses to different stimuli away from each other. Two such metrics are discussed: neural networks, and quadratic metrics. They then show that these metrics can be used to classify neural responses as coming from the same vs different stimuli, and that they outperform the naive Hamming distance metric at this task. Moreover, they show that this metric implicitly captures some structure in the neural code: more similar responses correspond to more similar visual stimuli. Finally, they discuss the implications of their metric for retinal prosthesis, and show some (fairly preliminary) data for how it could be used.\n\nOverall, I love the concepts in this paper. I have some reasonably substantive concerns over the execution, outlined below. But I encourage the authors to consider following through on these suggestions to improve their paper: the paper's key idea is really good, and I think it's worth the effort to flesh that idea out more thoroughly.\n\nMy specific suggestions / criticisms are:\n\n1) The quadratic metric seems only marginally better than the Hamming one (especially in Figs. 3 and 4), whereas the neural nets do much better as a metric (Fig. 3). However, most of the analyses (Figs. 4,5) use the quadratic metric. Why not use the better neural network metric for the subsequent studies of image similarity, and retinal stimulation? \n\n2) For Figs. 4, 5, where you use linear decoders to test the stimuli corresponding to the neural responses, how good are those decoders (i.e., MSE between decoded stim and true stim.)? If the decoders are poor, then the comparisons based on those decoders might not be so meaningful. I encourage you to report the decoding error, and if it's large, to make a better decoder and use it for these studies.\n\n3) Similarly, for Fig. 4, why not measure the MSE between the actual image frames corresponding to these neural responses? Presumably, you have the image frames corresponding to the target response, and for each of the other responses shown (i.e., the responses at different distances from the target). This would avoid any complications from sub-optimal decoders, and be a much more direct test.\n\n(I understand that, for Fig. 5, you can't do this direct comparison, as the electrically stimulated patterns don't have corresponding image frames, so you need to decode them.)", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a neural response metric for retinal prosthesis", "abstract": "Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.", "pdf": "/pdf/5748c2fc8bad28c747dd863460f846c9dbf614ad.pdf", "TL;DR": "Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.", "paperhash": "shah|learning_a_neural_response_metric_for_retinal_prosthesis", "_bibtex": "@inproceedings{\np2018learning,\ntitle={Learning a neural response metric for retinal prosthesis},\nauthor={Nishal P Shah and Sasidhar Madugula and EJ Chichilnisky and Yoram Singer and Jonathon Shlens},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJhIM0xAW},\n}", "keywords": ["Metric learning", "Computational Neuroscience", "Retina", "Neural Prosthesis"], "authors": ["Nishal P Shah", "Sasidhar Madugula", "EJ Chichilnisky", "Yoram Singer", "Jonathon Shlens"], "authorids": ["nishalps@stanford.edu", "sasidhar@stanford.edu", "ej@stanford.edu", "singer@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642449859, "id": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper445/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer2", "ICLR.cc/2018/Conference/Paper445/AnonReviewer3", "ICLR.cc/2018/Conference/Paper445/AnonReviewer1"], "reply": {"forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper445/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642449859}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642449917, "tcdate": 1511697701742, "number": 2, "cdate": 1511697701742, "id": "S1AQa7uxz", "invitation": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "signatures": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Interesting approach to learning neural response metrics", "rating": "6: Marginally above acceptance threshold", "review": "In their paper, the authors propose to learn a metric between neural responses by either optimizing a quadratic form or a deep neural network. The pseudometric is optimized by positing that the distance between two neural responses to two repeats of the same stimulus should be smaller than the distance between responses to different stimuli. They do so with the application of improving neural prosthesis in mind. \n\nFirst of all, I am doubtful about this application: I don't think the task of neural prosthesis can ever be to produce idential output pattern to the same stimuli. Nevertheless, a good metric for neural responses that goes beyond e.g. hamming distance or squared error between spike density function would be clearly useful for understanding neural representations.\n\nSecond, I find the framework proposed by the authors interesting, but not clearly motivated from a neurobiological perspective, as the similarity between stimuli does not appear to play a role in the optimized loss function. For two similar stimuli, natural responses of neural population can be more similar than the responses to two repetitions of the same stimulus.\n\nThird, the results presented by the authors are not convincing throughout. For example, 4B suggests that indeed the Hamming distance achieves lower error than the learned representation.\n\nNevertheless, it is an interesting approach that is worthwhile pursuing further. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a neural response metric for retinal prosthesis", "abstract": "Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.", "pdf": "/pdf/5748c2fc8bad28c747dd863460f846c9dbf614ad.pdf", "TL;DR": "Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.", "paperhash": "shah|learning_a_neural_response_metric_for_retinal_prosthesis", "_bibtex": "@inproceedings{\np2018learning,\ntitle={Learning a neural response metric for retinal prosthesis},\nauthor={Nishal P Shah and Sasidhar Madugula and EJ Chichilnisky and Yoram Singer and Jonathon Shlens},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJhIM0xAW},\n}", "keywords": ["Metric learning", "Computational Neuroscience", "Retina", "Neural Prosthesis"], "authors": ["Nishal P Shah", "Sasidhar Madugula", "EJ Chichilnisky", "Yoram Singer", "Jonathon Shlens"], "authorids": ["nishalps@stanford.edu", "sasidhar@stanford.edu", "ej@stanford.edu", "singer@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642449859, "id": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper445/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer2", "ICLR.cc/2018/Conference/Paper445/AnonReviewer3", "ICLR.cc/2018/Conference/Paper445/AnonReviewer1"], "reply": {"forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper445/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642449859}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642449874, "tcdate": 1511823152358, "number": 3, "cdate": 1511823152358, "id": "B1OVwz9ez", "invitation": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "signatures": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Application of metric-learning to neural population recordings in the context of prosthetics", "rating": "7: Good paper, accept", "review": "* Summary of paper: The paper addresses the problem of optimizing metrics in the context of retinal prosthetics: Their goal is to learn a metric which assumes spike-patterns generated by the same stimulus to be more similar to each other than spike-patterns generated by different stimuli. They compare a conventional, quadratic metric to a neural-network based representation and a simple Hamming metric, and show that the neural-network based on achieves higher performance, but that the quadratic metric does not substantially beat the simple Hamming baseline. They subsequently evaluate the metric (unfortunately, only the quadratic metric) in two interesting applications involving electrical stimulation, with the goal of selecting stimulations which elicit spike-patterns which are maximally similar to spike-patterns evoked by particular stimuli.\n\n* Quality: Overall, the paper is of high quality. What puzzled me, however is the fact that, in the applications using electrical stimulation in the paper (i.e. the applications targeted to retinal prosthetics, Secs 3.3 and 3.4), the authors do not actually used the well-performing neural-network based metric, but rather the quadratic metric, which is no better than the baseline Hamming metric?  It would be valuable for them to comment on what additional challenges would arise by using the neural network instead, and whether they think they could be surmonted.\n\n* Clarity: The paper is overall clear, but specific aspects could be improved: First, it took me a while to understand (and is not entirely clear to me) what the goal of the paper is, in particular outside the setting studied by the authors (in which there is a small number of stimuli to be distinguished). Second, while the paper does not claim to provide a new metric-learning approach, it would benefit from more clearly explaining if and how their approach relates to previous approaches to metric learning.  Third, the paper, in my view, overstating some of the implications. As an example, Figure 5 is titled 'Learned quadratic response metric gives better perception than using a Hamming metric.': there is no psychophysical evaluation of perception in the paper, and even the (probably hand-picked?) examples in the figure do not look amazing.\n\n* Originality: To the best of my knowledge, this is the first paper addressing the question of learning similarity metrics in the context of retinal prosthetics. Therefore, this specific paper and approach is certainly novel and original. From a machine-learning perspective, however, this seems like pretty standard metric learning with neural networks, and no attempt is made to either distinguish or relate their approach to prior work in this field (e.g. Chopra et al 2005, Schroff et al 2015 or Oh Song et al 2016.)\n\nIn addition, there is a host of metrics and kernels which have been proposed for measuring similarity between spike trains (Victor-Purpura) -- while they might not have been developed in the context of prosthetics, they might still be relevant to this tasks, and it would have been useful to see a comparison of how well they do relative to a Hamming metric. The paper states this as a goal (\"This measure should expand upon...), but then never does that- why not?\n\n* Significance: The general question the authors are approaching (how to improve retinal prosthetics) is,  an extremely important one both from a scientific and societal perspective. How important is the specific advance presented in this paper? The authors learn a metric for quantifying similarity between neural responses, and show that it performs better than a Hamming metric. It would be useful for the paper to comment on how they think that metric to be useful for retinal prosthetics. In a real prosthetic device, one will not be able learn a metric, as the metric learning her requires access to multiple trials of visual stimulation data, neuron-by-neuron. Clearly, any progress on the way to retinal prosthetics is important and this approach might contribute that. However, the current presentation of the manuscripts gives a somewhat misleading presentation of what has been achieved, and a more nuanced presentation would be important and appropriate. \n\n\nOverall, this is a nice paper which could be of interest to  ICLR. Its strengths are that i) they identified a novel, interesting and potentially impactful problem that has not been worked on in machine learning before, ii) they provide a solution to it based on metric learning, and show that it performs better than a non-learned metrics. Its limitations are that i) no novel machine-learning methodology is used (and relationship to prior work in machine learning is not clearly described) ii) comparisons with previously proposed similarity measures of spike trains are lacking, iii) the authors do not actually use their learned, network based metric, but the metric which performs no better than the baseline in their main results, and  iv) it is not well explained how this improved metric could actually be used in the context of retinal prosthetics.\n\nMinor comments:\n\n  - p.2 The authors write that the element-wise product is denoted by $A \\bullet B = \\Tr(A^{\\intercal}) B$\n    This seems to be  incorrect, as the r.h.s. corresponds to a scalar.\n  - p.3 What exactly is meant by \u201cmining\u201d?\n  - p.4 It would be useful to give an example of what is meant by \u201csimilarity learning\u201d.\n  - p.4 \u201cPlease the Appendix\u201d -> \u201cPlease see the Appendix\u201d\n  - p.5 (Fig. 3) The abbreviation \u201cAUC\u201d is not defined.\n  - p.5 (Fig. 3B) The figure giving 'recall' should have a line indicating perfect performance, for comparison.\n  - Sec 3.3: How was the decoder obtained ?\n  - p.6 (Fig. 4) Would be useful to state that column below 0 is the target. Or just replace \u201c0\u201d by \u201ctarget\u201d.\n  - p.6 (3rd paragraph) The sentence \u201cFigure 4A bottom left shows the spatial profile of the linear decoding 20ms prior to the target response.\u201d is unclear. It took me a very long time to realize that \"bottom left\" meant \"column 0, 'decoded stimulus'\" row. It's also unclear why the authors chose to look at 20ms prior to the target response.\n  - p.6 The text says RMS distance, but the Fig. 4B caption says MSE\u2014 is this correct?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a neural response metric for retinal prosthesis", "abstract": "Retinal prostheses for treating incurable blindness are designed to electrically stimulate surviving retinal neurons,  causing them to send artificial visual signals to the brain. However, electrical stimulation generally cannot precisely reproduce  normal patterns of neural activity in the retina. Therefore, an electrical stimulus must be selected that produces a neural response as close as possible to the desired response. This requires a technique for computing a distance between the desired response and the achievable response that is meaningful in terms of the visual signal being conveyed. Here we propose a method to learn such a metric on neural responses, directly from recorded light responses of a population of retinal ganglion cells (RGCs) in the primate retina. The learned metric produces a measure of similarity of RGC population responses that accurately reflects the similarity of the visual input. Using data from electrical stimulation experiments, we demonstrate that this metric may improve the performance of a prosthesis.", "pdf": "/pdf/5748c2fc8bad28c747dd863460f846c9dbf614ad.pdf", "TL;DR": "Using triplets to learn a metric for comparing neural responses and improve the performance of a prosthesis.", "paperhash": "shah|learning_a_neural_response_metric_for_retinal_prosthesis", "_bibtex": "@inproceedings{\np2018learning,\ntitle={Learning a neural response metric for retinal prosthesis},\nauthor={Nishal P Shah and Sasidhar Madugula and EJ Chichilnisky and Yoram Singer and Jonathon Shlens},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJhIM0xAW},\n}", "keywords": ["Metric learning", "Computational Neuroscience", "Retina", "Neural Prosthesis"], "authors": ["Nishal P Shah", "Sasidhar Madugula", "EJ Chichilnisky", "Yoram Singer", "Jonathon Shlens"], "authorids": ["nishalps@stanford.edu", "sasidhar@stanford.edu", "ej@stanford.edu", "singer@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642449859, "id": "ICLR.cc/2018/Conference/-/Paper445/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper445/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper445/AnonReviewer2", "ICLR.cc/2018/Conference/Paper445/AnonReviewer3", "ICLR.cc/2018/Conference/Paper445/AnonReviewer1"], "reply": {"forum": "HJhIM0xAW", "replyto": "HJhIM0xAW", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper445/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642449859}}}], "count": 5}