{"notes": [{"id": "A5VV3UyIQz", "original": "Fk72E8t-_Fc", "number": 217, "cdate": 1601308032772, "ddate": null, "tcdate": 1601308032772, "tmdate": 1614262118823, "tddate": null, "forum": "A5VV3UyIQz", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "nD75ftYq1bg", "original": null, "number": 1, "cdate": 1610040538689, "ddate": null, "tcdate": 1610040538689, "tmdate": 1610474148948, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper touches upon explainable anomaly detection. To that extend, it modified hypersphere classifier towards fully convolutional data description (FCDD). This is, as also pointed out by two of the reviewers a direct application of a fully convolutional network within the hyperspherical classifier. However, the paper  also shows how to then upsample the receptive field using a strided transposed convolution with a fixed Gaussian kernel. Both together with tackling explainable anomaly detection is important. Moreover, the empirical evaluation is quite exhaustive and shows several benefits compared to state-of-the-art. So, yes, incremental, but incremental for a very interesting an important case. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040538675, "tmdate": 1610474148931, "id": "ICLR.cc/2021/Conference/Paper217/-/Decision"}}}, {"id": "1xfBFmGXaC2", "original": null, "number": 2, "cdate": 1605959947953, "ddate": null, "tcdate": 1605959947953, "tmdate": 1605961888380, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment", "content": {"title": "General Author Response", "comment": "We thank all the reviewers for their helpful comments and are pleased that our work has been well received overall:\n\n**R1: \"The approach is well-motivated and compares well to the state of the art AD-methods.\"** \\\n**R1: \"The paper provides sophisticated theoretical as well as empirical insights.\"** \\\n**R2: \"The paper is very well written (excellent grammar!) and easy to follow, with clear, complete and concise explanations.\"** \\\n**R2: \"The method is simple and elegant. It should be easy to reproduce it.\"**\n\nThere seem to be a few concerns from Reviewer 3 based on misunderstandings. We hope that our response and the other reviews help to alleviate these issues. We will also include and clarify these points in the final version. We will address the reviewers' comments individually.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper217/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "A5VV3UyIQz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper217/Authors|ICLR.cc/2021/Conference/Paper217/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873391, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment"}}}, {"id": "4uFVLZcsHS4", "original": null, "number": 5, "cdate": 1605961436752, "ddate": null, "tcdate": 1605961436752, "tmdate": 1605961436752, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "KL-9fT-IhEE", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment", "content": {"title": "Author Response to Reviewer 2", "comment": "Thank you for your review, we will incorporate your suggestions into the camera-ready version. We address a few points below.\n\n> **\"fig 5 should show the nominal class for visual reference\"** \\\nFigure 5 shows heatmaps for a model trained on the \"acorn\" class where (a) shows anomalous samples (no acorns) and (b) nominal ones (acorns). Therefore, we already show the nominal class for \"visual reference\" in this figure. We will also add nominal examples for the other figures in the camera-ready version. \n\n> **\"the qualitative examples on figure 1 should be compared with other methods\"** \\\nWe provide heatmaps for all other methods on all MVTec-AD classes in Figure 18.\n\n> **\"The comparison with other methods for MVTEC is only with published results. FCDD uses a confetti noise to create OE examples. However, it is not clear which OE methods (if any) were used in the published results. Therefore it is not clear if the improved SOT comes from a better OE method or from the FCDD itself.\"** \\\nUnlike standard OE we do not use an auxiliary dataset, which we agree would be an unfair advantage. We instead introduce a noise model which we tried to make general-purpose. We are unaware of other explainable anomaly detection methods with OE on MVTec-AD and we seem to be the first to incorporate an OE-style approach to explainable anomaly detection."}, "signatures": ["ICLR.cc/2021/Conference/Paper217/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "A5VV3UyIQz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper217/Authors|ICLR.cc/2021/Conference/Paper217/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873391, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment"}}}, {"id": "MO3U0FgT0Qv", "original": null, "number": 4, "cdate": 1605960498527, "ddate": null, "tcdate": 1605960498527, "tmdate": 1605960498527, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "qtMgzBrYPUB", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment", "content": {"title": "Author Response to Reviewer 1", "comment": "Regarding the output for \"toothbrushes\": Since for each class a separate anomaly detector is trained, one would have to adjust the normalization for each class to fit the distribution of the anomaly scores (cf., Appendix C). However, to keep the heatmaps comparable, we chose to use a unified normalization for all heatmaps in one figure. Tweaking the normalization for the \"toothbrush\" images shows that the heatmaps actually tend to mark the correct anomalous regions. We will include an explanation for the camera-ready version.\n\nThank you for your other suggestions on further improving clarity. We found them helpful and will include them in the camera-ready version. "}, "signatures": ["ICLR.cc/2021/Conference/Paper217/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "A5VV3UyIQz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper217/Authors|ICLR.cc/2021/Conference/Paper217/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873391, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment"}}}, {"id": "IOkTzBO22Mm", "original": null, "number": 3, "cdate": 1605960374805, "ddate": null, "tcdate": 1605960374805, "tmdate": 1605960374805, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "ngPoMXYW4mP", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment", "content": {"title": "Author Response to Reviewer 3", "comment": "Regarding \"spurious\" features: FCDD's core contribution is its ability to provide heatmaps as explanations in addition to the usual anomaly detection score, which makes FCDD's detection behavior transparent. For example, these explanations reveal the potential of one-class classification detectors to focus on image features which, while providing good discriminative power at training time, would not be desirable upon deployment/test time. A model has no way of knowing that such features are in fact undesirable and FCDD enables a practitioner to recognize and remedy (e.g. by cleaning or extending the training data) such behavior or other undesirable phenomena (e.g. to avoid unfair social bias).\n\nWe will clarify this point in a camera-ready version and remark that other reviewers found the \"Clever Hans\" section to be a good addition. \nIn light of this and the other reviews, we kindly ask you to reconsider your final score."}, "signatures": ["ICLR.cc/2021/Conference/Paper217/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "A5VV3UyIQz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper217/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper217/Authors|ICLR.cc/2021/Conference/Paper217/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873391, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Comment"}}}, {"id": "KL-9fT-IhEE", "original": null, "number": 1, "cdate": 1603743322824, "ddate": null, "tcdate": 1603743322824, "tmdate": 1605024738160, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Review", "content": {"title": "An elegant and simple approach to deep one-class classification that provides explainable decisions", "review": "This paper presents a one-class classification method using a fully convolutional model and directly using the output map as an explanation map. The method is dubbed FCDD for fully convolutional data descriptor. FCDD uses a hypersphere classifier combined with a pseudo-Huber loss. FCDD is trained using outliers exposure (OE) from a different but related dataset. The empirical study consists of 3 parts:\n * a quantitative comparison of anomaly detection (AD) with SOT methods on three datasets: Fashion-MNIST, CIFAR-10 and ImageNET. The proposed method is shown to be competitive with SOT.\n * a qualitative study showing that the explanation provided by FCDD is more useful compared to other methods.\n * a quantitative comparison of the explanation performance on the MVTec-AD dataset. This shows that FCDD beats other SOT approaches and can also be easily adapted to accept actual anomalies examples, which results in even improved numbers.\n\nPROS:\n\n * The paper is very well written (excellent grammar!) and easy to follow, with clear, complete and concise explanations. \n \n * The method is simple and elegant. It should be easy to reproduce it.\n \n * The results are competitive with SOT for AD and beats it for the quality explanation (with the caveat below).\n\nCONS:\n\n * The novelty is incremental: Combining fully-convolutional CNN with a hypersphere classifier.\n\n * The comparison with other methods for MVTEC is only with published results. FCDD uses a confetti noise to create OE examples. However, it is not clear which OE methods (if any) were used in the published results. Therefore it is not clear if the improved SOT comes from a better OE method or from the FCDD itself.\n\n *  The paper also describes a fixed-kernel (Gaussian) upsampling method using strided transposed convolutions, which I find unnecessary to be added to the paper.\n\n * the qualitative examples on figure 1 should be compared with other methods. \n \n * fig 5 should show the nominal class for visual reference.\n \n \n Overall this is a well written paper, presenting a simple and reproducible approach to explainable AD that beats the SOT. \n \n ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper217/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147902, "tmdate": 1606915810782, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper217/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Review"}}}, {"id": "qtMgzBrYPUB", "original": null, "number": 2, "cdate": 1603871671933, "ddate": null, "tcdate": 1603871671933, "tmdate": 1605024738078, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Review", "content": {"title": "This paper addresses the topic of explainability in Deep One-Class Classification. A new method, Fully Convolutional Data Description (FCDD), is presented in which the mapped samples themselves are explainable heatmaps. It is shown that FCDD can provide transparent explanations of anomalies while being better or close to the state of the art on standard AD-benchmarks. ", "review": "### **Evaluation**\n- The paper is tackling the topic of explainable Deep One-Class-Classification. In contrast to comparable methods, like for example gradient-based heatmaps, FCDD has a spatial context. This fact facilitates the interpretability. \n- The approach is well-motivated and compares well to the state of the art AD-methods.\n- The paper provides sophisticated theoretical as well as empirical insights. \n\n\n### **Detailed Comments for Authors**\n- The visualisations given in the paper are well suited for the addressed problem. The Appendix gives a good insight into the functioning of the FCDD as well as the decision process of the networks. However, in figure 18. the output for \"toothbrush\" is shown a huge anomaly blob for all samples, while the ground truth shows just minimal areas. Why is that the case? \nIn contrast to this, the mean AUC in table 2 is 0.94 (and 0.95 for semi-supervised FCDD), which is quite good comparing to the visual impression. \n- The section addressing the \"Clever Hans\" effect was a good addition, since it shows another perspective of the usage of the methods while clearly showing the learned characteristics. It might be beneficial to explain in more detail, why using the \"horse\" class as anomaly class, since it is kind of in inverse logic (it makes sense, but while reading one had to think twice about it). \n- For the heatmap-overviews given, it might be valuable to have a comparison of one sample of the nominal class and multiple of the anomaly one. In this way, the trained class is shown and directly comparable to the anomalies.  \n\n#### **Strong points of the submission.** \n- Very well written paper, which is easy to follow, based is based not least on good visualisation.\n- The paper provides a good and detailed description of the theoretical concepts.\n- It is positive that the examples also pointing some weaknesses of FCDD, like not recognising the anomaly, while simultaneously comparing to other methods. The method shows its strength in the spacial context. Given the extended appendix, the authors deliver a critical view on the possibilities as well as the potential limitations.    \n\n#### **Weak points of the submission.** \n- the conclusion is quite sparse, and even missing an own section.\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper217/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147902, "tmdate": 1606915810782, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper217/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Review"}}}, {"id": "ngPoMXYW4mP", "original": null, "number": 3, "cdate": 1603940359904, "ddate": null, "tcdate": 1603940359904, "tmdate": 1605024738001, "tddate": null, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "invitation": "ICLR.cc/2021/Conference/Paper217/-/Official_Review", "content": {"title": "Recommendation to Reject", "review": "########################################################################## \nSummary:\n\nThis paper presents a modified approach, on top of an existing method (DSVDD), for anomaly detection with a state of the art achievement in the unsupervised setting. In my opinion, the model itself is not a novel innovation. However, it fails when sprious image features exist. \n\n\n##########################################################################\nReasons for score:\u00a0\n\nThis paper has evidence to show better performance comparing to other, in terms of explanation.  But, however, to me personally, it doesn't meet a high standard, as the method is just a modification of what's already existing. And the heatmap as an explanation, demonstrated that model did pick up some superficial features for detection, such as color.  Lastly, as the authors also called out in the last session, it's not robust enough to overcome spurious features, which can be big problem for real applications. \n\n\n\n##########################################################################\nQuestions during rebuttal period:\u00a0\n\u00a0\nPlease address and clarify the cons above\u00a0\n\u00a0\n\n\u00a0", "rating": "4: Ok but not good enough - rejection", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper217/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper217/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explainable Deep One-Class Classification", "authorids": ["~Philipp_Liznerski1", "~Lukas_Ruff1", "~Robert_A._Vandermeulen2", "b_franks12@cs.uni-kl.de", "~Marius_Kloft1", "~Klaus_Robert_Muller1"], "authors": ["Philipp Liznerski", "Lukas Ruff", "Robert A. Vandermeulen", "Billy Joe Franks", "Marius Kloft", "Klaus Robert Muller"], "keywords": ["anomaly-detection", "deep-learning", "explanations", "interpretability", "xai", "one-class-classification", "deep-anomaly-detection", "novelty-detection", "outlier-detection"], "abstract": "Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD sets a new state of the art in the unsupervised setting. Our method can incorporate ground-truth anomaly maps during training and using even a few of these (~5) improves performance significantly. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.", "one-sentence_summary": "We introduce an approach to explainable deep anomaly detection based on fully convolutional neural networks. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liznerski|explainable_deep_oneclass_classification", "supplementary_material": "", "pdf": "/pdf/faaddd67b70d461702cda54ff0c68b47fbf56d03.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nliznerski2021explainable,\ntitle={Explainable Deep One-Class Classification},\nauthor={Philipp Liznerski and Lukas Ruff and Robert A. Vandermeulen and Billy Joe Franks and Marius Kloft and Klaus Robert Muller},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=A5VV3UyIQz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "A5VV3UyIQz", "replyto": "A5VV3UyIQz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper217/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147902, "tmdate": 1606915810782, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper217/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper217/-/Official_Review"}}}], "count": 9}