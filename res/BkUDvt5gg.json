{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396621988, "tcdate": 1486396621988, "number": 1, "id": "HJI02fUOg", "invitation": "ICLR.cc/2017/conference/-/paper500/acceptance", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "Without revisions to this paper or a rebuttal from the authors, it is hard to accept this paper. The main contribution of the paper is removing the blank from CTC to create a somewhat different criterion, but this is not particularly novel (see, for example, http://www.isca-speech.org/archive/Interspeech_2016/pdfs/1446.PDF). None of the reviewers were willing to argue for acceptance in the deliberation phase, so unfortunately the recommendation must be to reject this paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396622672, "id": "ICLR.cc/2017/conference/-/paper500/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396622672}}}, {"tddate": null, "tmdate": 1481326463587, "tcdate": 1481324561914, "number": 8, "id": "B19f_3dQx", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "citations missing", "comment": "Dear authors,\n\nHere are some missing relevant citations.\n\nYou should definitely cite the original paper that used CTC with characters.\nGraves et al., \"Towards End-to-End Speech Recognition with Recurrent Neural Networks\", in ICML 2014.\n\nYou should probably also cite and have a related work section with attention-based models such as:\nChan et al., \"Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition\", in ICASSP 2016.\nBahdanau et al., \"End-to-End Attention-based Large Vocabulary Speech Recognition\", in ICASSP 2016.\n\nboth of which are highly relevant to end-to-end ASR.\n\nQuestion:\nWhy did you use Librispeech as opposed to WSJ and/or SWBD. Most end-to-end ASR papers publish on WSJ, especially since there is an established benchmark for comparison (i.e., Graves et al., 2014, Bahdanau et al., 2016, Chan et al., 2016). SWBD also has much stronger benchmarks from the general speech community, and even for end-to-end ASR (i.e., see MSR's CTC paper by Zweig et., \"Advances in All-Neural Speech Recognition\", 2016). You should also definitely comment and compare to Zweig's paper, since they used a similar encoding mechanism.\n\nQuestion:\nIs \"Letter Error Rate\" (LER) the common terminology? From Alex Graves papers and others I see \"Character Error Rate\" (CER). What is the difference?\n\nQuestion:\nVery cool that you can combine wav+cnns+ctc->ASR, but still a little bit disappointed that handcrafted features perform better. Do you expect this to change with more data?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481325127859, "tcdate": 1481325127851, "number": 2, "id": "rJgU53uXl", "invitation": "ICLR.cc/2017/conference/-/paper500/official/review", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer2"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "\u200bThere have been numerous works \u200bon learning from raw waveforms and training letter-based CTC networks for speech recognition, however, there are very few works on combining both of them with purely ConvNet as it is done in this paper. It is interesting to see results on a large scale corpus such as Librispeech that is used in this paper, though some baseline results from hybrid NN/HMM systems should be provided. To readers, it is unclear how this system is close to state-of-the-art only from Table 2.\n\nThe key contribution of this paper may be the end-to-end sequence training criterion for their CTC variant (where the blank symbol is dropped), which may be viewed as sequence training of CTC as H. Sak, et al. \"Learning acoustic frame labeling for speech recognition with recurrent neural networks\", 2015. However, instead of generating the denominator lattices using a frame-level trained CTC model first, this paper directly compute the sequence-level loss by considering all the competing hypothesis in the normalizer. Therefore, the model is trained end-to-end. From this perspective, it is closely related to D. Povey's LF-MMI for sequence-training of HMMs. As another reviewer has pointed out, references and discussions on that should be provided. \n\nThis approach should be more expensive than frame-level training of CTCs, however, from Table 1, the authors' implementation is much faster. Did the systems there use the same sampling rate? You said at the end of 2.2 that the step size for your model is 20ms. Is it also the same for Baidu's CTC system. Also, have you tried increasing the step size, e.g. to 30ms or 40ms, as people have found that it may work (equally) better, while significantly cut down the computational cost.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512564186, "id": "ICLR.cc/2017/conference/-/paper500/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper500/AnonReviewer3", "ICLR.cc/2017/conference/paper500/AnonReviewer2", "ICLR.cc/2017/conference/paper500/AnonReviewer1"], "reply": {"forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512564186}}}, {"tddate": null, "tmdate": 1481301636602, "tcdate": 1481300301055, "number": 1, "id": "rJrUKI_7e", "invitation": "ICLR.cc/2017/conference/-/paper500/official/review", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This submission proposes a letter-level decoder with a variation of the CTC approach they call ASG, where the blank symbol is dropped and replaced by letter repetition symbols, and where explicit normalization is dropped. Both the description of a letter-level model (though not novel), as well as the CTC-variant are interesting. \n\nThe approach is evaluated on the LibriSpeech task. The authors claim that their approach is competitive. They compare their modelling variant ASG to CTC, but a comparison of the letter-level approach to available word-level results are missing. Compared to the results obtained in Panayotov et al. 2015, the performance obtained here seems only comparable to word-level GMM/HMM models, but worse than word-level hybrid DNN/HMM models, though Panayotov et al. also appled speaker adaptation, which was not done, as far as I can see. I suggest to add a comparison to Panyotov's results (in addition to mentioning Baidu's results on Librispeech, which are not comparable due to much larger amounts of training data), to allow readers to get a quantitative idea. As pointed out by the authors in the text, Baidu's GPU implementation for CTC is more aimed at larger vocabularies, therefore the comparison to GPU in Tables 1a-c do not seem to be helpful for this work, without further discussing the implementations.\n\nYou are using quite a huge analysis window (nearly 2s). Even though other authors also use windows up to 0.5s to 1s (e.g. MRASTA features), some comments on how you arrive at such a large window, and what advantages you observe for it, would be interesting.\n\nThe submission is well written, though more details on the experiences with using non-normalized (transition) scores and beam pruning would be desirable. Table 1 would be better readable if the units of the numbers shown in a/b/c would be shown within the tables, and not only in the caption.\n\nPrior (partial) publications of this work (your NIPS end-to-end workshop paper) should clearly be mentioned/referenced.\n\nWhat do you mean by transition \"scalars\"?\n\nI do not repeat further comments here, which were already given in the pre-review period.\n\nMinor comments:\n - Sec. 2.3, end of 2nd sentence: train properly the model -> train the model properly\n   End of same paragraph: boostrap -> bootstrap (such errors should be avoided by performing an automatic spell check)\n - Sec. 2.3: Bayse -> Bayes\n - definition of logadd is wrong (see comment) - (applies also for your NIPS end-to-end workshop paper).\n - line before Eq. (3): all possible sequence of letters -> all possible sequences of letters (plural)\n - Sec. 2.4, first line: threholding -> thresholding (spell check..)\n - Figure 4: mention the corpus used here - dev?\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512564186, "id": "ICLR.cc/2017/conference/-/paper500/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper500/AnonReviewer3", "ICLR.cc/2017/conference/paper500/AnonReviewer2", "ICLR.cc/2017/conference/paper500/AnonReviewer1"], "reply": {"forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512564186}}}, {"tddate": null, "tmdate": 1481297462937, "tcdate": 1481297462930, "number": 7, "id": "Bykr0Su7e", "invitation": "ICLR.cc/2017/conference/-/paper500/official/comment", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Publication at NIPS/end-to-end workshop", "comment": "A slightly more compressed version of this submission will be presented at the NIPS end-to-end workshop on Dec. 10, 2016. The NIPS submission seems to be a clear subset of this submission and should at least be mentioned in this paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550308, "id": "ICLR.cc/2017/conference/-/paper500/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550308}}}, {"tddate": null, "tmdate": 1481227222643, "tcdate": 1481227222637, "number": 7, "id": "rJk124PQx", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "ryT2_zDQe", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "More on normalization.", "comment": "Yes, in theory when comparing scores of same-length paths normalized or un-normalized acoustic model scores will not matter, but do matter for transitions. My answer was addressing the acoustic model side, as asked by Reviewer 3. Note that we find training with normalized transition scores much harder and more unstable than the un-normalized version. We can try to squeeze in a comment about this."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481227107428, "tcdate": 1481227107421, "number": 6, "id": "BJsDsND7x", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "rymoaGsGx", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "Missing context around our approach.", "comment": "Thanks a lot for mentioning these references, we should have added more context about our method. [Bengio, 1993] is a survey and mentions several techniques, including conditional maximum likelihood (CML) approaches like MMI. [Johansen et al, 1996] and [Povey et al, 2016] both refer to MMI (Compared to CML, MMI algorithm updates only the acoustic model (not the language model), but common usage often mix up the two names). MMI maximizes the logarithm of the ratio of two likelihoods (constrained model on the numerator, unconstrained on the denominator). In contrast, our approach considers only un-normalized scores, both for the acoustic model output scores and transition scores, which follows a line of research running parallel to hybrid approaches and MMI-like systems. More precisely, in [Bottou, 1991] it was first mentioned concerns about using normalized probabilities in discriminative sequence models. In the very last section of [Bengio, 1993],  a research direction to address the issue is mentioned, but no solution is proposed. The first solution came with [Denker and Burges, 1994], then a more general framework (GTNs) was proposed in [Bottou and LeCun, 1997] and [LeCun et al, 1998]. CRFs also follow this line of research, with [Lafferty et al, 2001]. While we should have added more context about our approach (we will fix this), we found relevant to relate it to CTC, given that many people using sequence-level end-to-end-training now rely on CTC.\n\nNote that in [Povey et al, 2016], un-normalized probabilities are mentioned (\"We interpret the neural net output as the log of a pseudo-likelihood\") concerning the acoustic model. A 4-gram (phone) language model is used in the normalization, but seemed to be trained generatively beforehand. In contrast, in Figure 3c we have a 2-gram (letter) language model, trained discriminatively, jointly with the rest of the architecture. (Extension to a 4-gram letter language model could be possible (say via sampling for efficiency) and is left to future work). It is hard to conclude on the actual other differences, as in [Povey et al, 2016] no equation is provided, a reference to the MMI research lineage being instead provided, and no links with the GTNs/CRFs research lineage was established (\"We don\u2019t give any equations here, because MMI training is well known\"). Finally, we did not cite [Povey et al, 2016], as it was published after the writing of our paper. We will add it (ASAP) with more context around our approach in a future revision.\n\n[Bottou, 1991] Une Approche th\u00e9orique de l'Apprentissage Connexionniste: Applications \u00e0 la Reconnaissance de la Parole.\n[Denker and Burges, 1994] Image Segmentation and Recognition.\n[Bottou and LeCun, 1997] Global Training of Document Processing Systems using Graph Transformer Networks.\n[LeCun et al, 1998] Gradient Based Learning Applied to Document Recognition.\n[Lafferty et al, 2001] Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481226867617, "tcdate": 1481226867490, "number": 5, "id": "BkoOqVD7l", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "BJDsh7jGl", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "HMMs and CRFs.", "comment": "Our system could be seen as from the CRF family, not from the HMM family. CRFs are discriminative models, compared to HMMs which are generative. All our scores (transitions or observations) are not normalized, the normalization being achieved at the sequence level. Compared to standard CRFs, our model is non-linear, and trained in a end-to-end manner. See [Lafferty et al, 2001]. We are not sure what the comment \"HMM-based system that people are using now\" is referring to; standard hybrid NN/HMM systems also use normalized probabilities, often skipping details when converting conditional probabilities from the neural net into emission probabilities. You can also read the answer to Reviewer 1 below for more context around our approach.\n\nConcerning d_y, it is the output size of a convolutional layer. In the instance of the last layer d_y is also the size of the letters alphabet (|L|).\n\n[Lafferty et al, 2001] Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481218229183, "tcdate": 1481218229179, "number": 6, "id": "ryT2_zDQe", "invitation": "ICLR.cc/2017/conference/-/paper500/official/comment", "forum": "BkUDvt5gg", "replyto": "Bk3jIGvXg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Normalization does matter for transitions scores", "comment": "If probabilities have different conditions, normaliation does matter. In this case normalization originally would be assumed for each condition separately."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550308, "id": "ICLR.cc/2017/conference/-/paper500/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550308}}}, {"tddate": null, "tmdate": 1481128868168, "tcdate": 1481128868164, "number": 4, "id": "rk3ojnrQg", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "HJFR8A0zx", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "logadd definition", "comment": "Thanks for pointing this out; there is a typo, indeed. We will fix it."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481128472337, "tcdate": 1481128472333, "number": 3, "id": "BJeX9nrQl", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "Sy9BdCRMx", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "t notation", "comment": "The t notation was used to represent time; it is true there is a different time scale between (1) and x_t; we will update with t and t', as you suggest this might be clearer."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481128209051, "tcdate": 1481128209045, "number": 2, "id": "HkFGFnHmx", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "rJrwyyyml", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "writers": ["~Ronan_Collobert1"], "content": {"title": "acoustic score normalization", "comment": "That is a very good question, thanks. Yes, we actually tried with and without normalization; performance (both speed and WER) was not affected, as long as the scaling factor was properly tuned for each use case. In practice, the beam search threshold was robust to different sentences and conditions on our dataset."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1481127501714, "tcdate": 1481127501709, "number": 1, "id": "rJ8ULhSQg", "invitation": "ICLR.cc/2017/conference/-/paper500/public/comment", "forum": "BkUDvt5gg", "replyto": "rJNG6CAfg", "signatures": ["~Gabriel_Synnaeve1"], "readers": ["everyone"], "writers": ["~Gabriel_Synnaeve1"], "content": {"title": "handling digits", "comment": "In many standard datasets (as LibriSpeech that we use here), numbers are spelled in plain letters. That is what we use and so we do not encounter a problem with this."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550443, "id": "ICLR.cc/2017/conference/-/paper500/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550443}}}, {"tddate": null, "tmdate": 1480679323999, "tcdate": 1480679260800, "number": 4, "id": "rJrwyyyml", "invitation": "ICLR.cc/2017/conference/-/paper500/official/comment", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Normalization in beam search", "comment": "When dropping the normalization of acoustic model scores, the range of scores obtained might vary and would have an effect on beam pruning and on its relation to the normalized LM scores. Did you analyse this?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550308, "id": "ICLR.cc/2017/conference/-/paper500/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550308}}}, {"tddate": null, "tmdate": 1480678668046, "tcdate": 1480678668043, "number": 3, "id": "rJNG6CAfg", "invitation": "ICLR.cc/2017/conference/-/paper500/official/comment", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Modified CTC/blank replacement", "comment": "Sec. 2.3: you use digits to label character repetitions. How do you handle numbers?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550308, "id": "ICLR.cc/2017/conference/-/paper500/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550308}}}, {"tddate": null, "tmdate": 1480677442480, "tcdate": 1480677442477, "number": 2, "id": "Sy9BdCRMx", "invitation": "ICLR.cc/2017/conference/-/paper500/official/comment", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "Notation", "comment": "It seems that you use inconsistent notation - the variable 't' is used for different time scales: in Eq. (1) t represents strided time frames, whereas in x_t above it enumerates frames directly."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287550308, "id": "ICLR.cc/2017/conference/-/paper500/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers", "ICLR.cc/2017/conference/paper500/areachairs"], "cdate": 1485287550308}}}, {"tddate": null, "tmdate": 1480677145434, "tcdate": 1480677072582, "number": 3, "id": "HJFR8A0zx", "invitation": "ICLR.cc/2017/conference/-/paper500/pre-review/question", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer3"], "content": {"title": "logadd?", "question": "I suppose that your definition of the logadd function is wrong, correct would be log(e^a+e^b) if a and b are log-probabilities (with your definition you would end up with a times b). Please confirm."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959246470, "id": "ICLR.cc/2017/conference/-/paper500/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper500/AnonReviewer1", "ICLR.cc/2017/conference/paper500/AnonReviewer2", "ICLR.cc/2017/conference/paper500/AnonReviewer3"], "reply": {"forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959246470}}}, {"tddate": null, "tmdate": 1480436894995, "tcdate": 1480436894991, "number": 2, "id": "BJDsh7jGl", "invitation": "ICLR.cc/2017/conference/-/paper500/pre-review/question", "forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "signatures": ["ICLR.cc/2017/conference/paper500/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper500/AnonReviewer2"], "content": {"title": "How is this model different from conventional HMM based model?", "question": "Fig 3(a) looks like a monophone HMM with self-loop and using a character-level lexicon, and eq(3) is very similar to sequence-training of HMMs. So the question is how it is different from the HMM based system that people are using now?\n\nd_y in section 2.2 is reused, see eq(1) and last paragraph of section 2.2."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959246470, "id": "ICLR.cc/2017/conference/-/paper500/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper500/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper500/AnonReviewer1", "ICLR.cc/2017/conference/paper500/AnonReviewer2", "ICLR.cc/2017/conference/paper500/AnonReviewer3"], "reply": {"forum": "BkUDvt5gg", "replyto": "BkUDvt5gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper500/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959246470}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478297439889, "tcdate": 1478297438980, "number": 500, "id": "BkUDvt5gg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BkUDvt5gg", "signatures": ["~Ronan_Collobert1"], "readers": ["everyone"], "content": {"title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "abstract": "This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding. It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes. We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC (Graves et al., 2006) while being simpler. We show competitive results in word error rate on the Librispeech corpus (Panayotov et al., 2015) with MFCC features, and promising results from raw waveform.", "pdf": "/pdf/d5a0b5529d3e8ef3cd62319541458c8b929d4bd2.pdf", "TL;DR": "We propose convnet models and new sequence criterions for training end-to-end letter-based speech systems.", "paperhash": "collobert|wav2letter_an_endtoend_convnetbased_speech_recognition_system", "conflicts": ["fb.com"], "keywords": ["Deep learning", "Speech", "Structured prediction"], "authors": ["Ronan Collobert", "Christian Puhrsch", "Gabriel Synnaeve"], "authorids": ["locronan@fb.com", "cpuhrsch@fb.com", "gab@fb.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 18, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 19}