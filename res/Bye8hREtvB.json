{"notes": [{"id": "Bye8hREtvB", "original": "BJxd2uYuDS", "number": 1357, "cdate": 1569439405857, "ddate": null, "tcdate": 1569439405857, "tmdate": 1577168214482, "tddate": null, "forum": "Bye8hREtvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "KN0yKKJfOM", "original": null, "number": 1, "cdate": 1576798721350, "ddate": null, "tcdate": 1576798721350, "tmdate": 1576800915239, "tddate": null, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes learning a latent embedding for image manipulation for PixelCNN by using Fisher scores projected to a low-dimensional space.\nThe reviewers have several concerns about this paper:\n* Novelty\n* Random projection doesn\u2019t learn useful representation\n* Weak evaluations\nSince two expert reviewers are negative about this paper, I cannot recommend acceptance at this stage.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727075, "tmdate": 1576800279291, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Decision"}}}, {"id": "BJleU5H-qB", "original": null, "number": 2, "cdate": 1572063815845, "ddate": null, "tcdate": 1572063815845, "tmdate": 1574874629654, "tddate": null, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "Motivated by the observation that powerful deep autoregressive models such as PixelCNNs lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using Fisher scores projected to a reasonably low-dimensional space as latent embeddings for image manipulations. A decoder based on a CNN, a Conditional RealNVP, or a Conditional Pyramid PixelCNN is used to decode high-dimensional images from these projected Fisher score.  Experiments with different autoregressive and decoder architectures are conducted on MNIST and CelebA datasets are conducted. \n\nPros:\n\nThis paper is well-written overall and the method is clearly presented.\n\n\nCons:\n\n1) It is well-known that the latent activations of deep autoregressive models don\u2019t contain much semantically meaningful information. It is very obvious that either a CNN decoder, a conditional RealNVP decoder, or a conditional Pyramid PixelCNN decoder conditioned on projected Fisher scores will produce better images because the Fisher scores simply contain much more information about the images than the latent activations. When the $\\alpha$ is small, the learned decoder will function similarly to the original pixelCNN, therefore, latent activations produce smaller FID scores than projected Fisher scores for small $\\alpha$\u2019s. These results are not surprising. Detailed explanations should be added here.\n\n2) The comparisons to baselines are unfair. As mentioned in 1), it\u2019s obvious that Fisher scores contain more information than latent activations for deep autoregressive models and are better suited for manipulations. Fair comparisons should be performed against other latent variable models such as flow models and VAEs with more interesting tasks, which will make the paper much stronger.\n\n3) In Figure 3, how is the reconstruction error calculated? It\u2019s squared error per pixel per image?\n\n4) On pp. 8, for semantic manipulations, some quantitative evaluations will strengthen this part.\n\nIn summary, this paper proposes a novel method based on projected Fisher scores for performing semantically meaningful image manipulations under the framework of deep autoregressive models. However, the experiments are not well-designed and the results are unconvincing. I like the idea proposed in the paper and strongly encourage the authors to seriously address the raised questions regarding experiments and comparisons.\n\n------------------\nAfter Rebuttal:\n\nI took back what I said. It's not that obvious that the \"latent activations of deep autoregressive models don\u2019t contain much semantically meaningful information\". But the latent activations are indeed a weak baseline considering that PixelCNN is so powerful a generator. If the autoregressive generator is powerful enough, the latent activations can theoretically encode nothing.  I have spent a lot of time reviewing this paper and related papers, the technical explanation about the hidden activation calculation of PixelCNN  used in this paper is unclear and lacking (please use equations not just words). \n\nRelated paper:  The PixelVAE paper ( https://openreview.net/pdf?id=BJKYvt5lg ) explains that PixelCNN doesn't learn a good hidden representation for downstream tasks\n\nAnother paper combining VAE and PixelCNN also mentions this point:\n\nECML 2018: http://www.ecmlpkdd2018.org/wp-content/uploads/2018/09/455.pdf\n\nPlease also check the related arguments about PixcelCNN (and the \"Unconditional Decoder\" results) in Variational Lossy Autoencoder (https://arxiv.org/pdf/1611.02731.pdf )\n\nAs I mentioned in the response to the authors' rebuttal, training a separate powerful conditional generative model from some useful condition information (Fisher scores) is feasible to capture the global information in the condition, which is obvious to me. This separate powerful decoder has nothing to do with PixelCNN, which is the major reason that I vote reject.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575878381301, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Reviewers"], "noninvitees": [], "tcdate": 1570237738554, "tmdate": 1575878381315, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review"}}}, {"id": "H1gGc4otjS", "original": null, "number": 4, "cdate": 1573659785705, "ddate": null, "tcdate": 1573659785705, "tmdate": 1573659964271, "tddate": null, "forum": "Bye8hREtvB", "replyto": "BkeWh3hmsS", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment", "content": {"title": "Thanks for the response", "comment": "\"> The paper uses the activation of the last layers of the PixelCNN as a baseline, which I consider to be a very weak baseline:   Our paper focuses on the question: is it possible to perform image interpolation using autoregressive models? Our experiments were designed to show that project Fisher scores provide better and more meaningful image manipulations than any other alternative latent spaces inherent to an autoregressive model, such as layer activations and noise space. In particular, the goal of our work is not to develop a new representation learning method; it is to develop an image interpolation method using autoregressive models. We believe that this is an interesting avenue of research because autoregressive models are not clearly suited for image interpolation, unlike VAEs and flows which have a clearly usable latent space.\"\n\nThe response from the authors to Review #4 is also highly related to my question. My major concern still remains. Since PixelCNN can have impressive performance as a generative model, it is really unsurprising that it can capture global semantic information considering its parameters as a whole and the associated Fisher scores. This paper just wants to prove this unsurprising point using a separate powerful decoder.\n\nThe authors also argue that \"Our paper does not focus on solving unsupervised learning using Fisher scores. Rather, it focuses on a novel method using Fisher scores to perform image manipulation using autoregressive models. We believe that a metric designed to evaluate interpolations is a more direct quantitative measurement of image manipulation quality, compared to standard representation learning evaluation methods.\"\n\nI still feel that this argument is not enough to convince me that showing the parameters of PixelCNN as a whole can capture global semantic information is interesting. \n\nTo summarize, from a reviewer's perspective, showing A can do B is not interesting (it's unsurprising); many other C, D, E, F, G can do B too; if you want to convince me, it's better to show that A can do B much better than C, D, E, F, G, which might seem to be controversial. But indeed, training a powerful conditional generative model from some useful condition information is feasible to capture the global information in the condition, which is obvious to me. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bye8hREtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1357/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1357/Authors|ICLR.cc/2020/Conference/Paper1357/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157223, "tmdate": 1576860561328, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment"}}}, {"id": "ryekfzLKjB", "original": null, "number": 3, "cdate": 1573638662688, "ddate": null, "tcdate": 1573638662688, "tmdate": 1573638662688, "tddate": null, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment", "content": {"title": "Thanks for your reviews. Please take a look at the rebuttal.", "comment": "Dear reviewers,\n\nThank you very much for your efforts in reviewing this paper.\n\nThe authors have provided their rebuttal. It would be great if you take a look at them, and see whether it changes your opinion in anyway. If there is still any unclear point or a serious disagreement, please bring it up. Also if you are hoping to see a specific change or clarification in the paper before you update your score, please mention it.\n\nThe authors have only until November 15th to reply back.\n\nI also encourage you to take a look at each others\u2019 reviews. There might be a remark in other reviews that changes your opinion.\n\nThank you,\nArea Chair"}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/Area_Chair1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bye8hREtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1357/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1357/Authors|ICLR.cc/2020/Conference/Paper1357/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157223, "tmdate": 1576860561328, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment"}}}, {"id": "BkeWh3hmsS", "original": null, "number": 2, "cdate": 1573272744814, "ddate": null, "tcdate": 1573272744814, "tmdate": 1573272744814, "tddate": null, "forum": "Bye8hREtvB", "replyto": "BJleU5H-qB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for your review. \n\n> 1) It is well-known that the latent activations of deep autoregressive models don\u2019t contain much semantically meaningful information.\n\nTo the best of our knowledge, we do not know of any existing work that shows this property in deep autoregressive models. We would appreciate if you could provide references to such existing work.\n\nWe would like to emphasize that our paper targets the problem of image manipulation with autoregressive models, and is not aiming to solve a representation learning problem. Therefore, we designed our experiments to show that Fisher scores are a better latent space than alternative latents in autoregressive models. Among possible latent spaces that could be extracted from autoregressive models, we found layer activations to be the strongest candidate. We believe such a choice is justified, as layer activations are also commonly used in many prior self-supervised learning methods [3] [4].\n\n> 2) It\u2019s obvious that Fisher scores contain more information than latent activations for deep autoregressive models and are better suited for manipulations\n\nWe agree that Fisher scores do contain more information than latent activations. However, we believe that it is not obvious that projected Fisher scores provides a latent space which entails more meaningful semantic manipulations for global attributes such as pose, hair color, and lighting. Experiments in [2] showed that smaller receptive fields attain competitive log-likelihood scores, suggesting that PixelCNNs model low-level statistics about the data. However, our experiments with using Fisher scores as an embedding space to interpolate show otherwise to common knowledge.\n\n> comparisons should be performed against other latent variable models\n\nOur paper aims to show that image manipulation is possible using autoregressive models, despite the lack of easily accessible latents such as those in VAEs or flow models. We believe that it is more meaningful to compare our method against existing and alternative methods that perform image manipulation using an autoregressive model, which motivates our decision as using layer activations for our baseline method.\n\n> 3) how is reconstruction error calculated\n\nThe decoder was trained to model discrete pixels values, so the reconstruction error is negative log-likelihood (nats per dim).\n\n> 4) for semantic manipulations, some quantitative evaluations will strengthen this part\n\nTo the best of our knowledge, we do not know of a method to effectively quantitatively evaluate the quality of semantic manipulations. We experimented with a few different evaluation metrics, such as using binary classifiers in a method similar to [1], however, none showed meaningful results as an evaluation metric. Training binary classifiers on CelebA attributes proved too easy, and provided no discernable difference between semantic manipulations using different embedding spaces even when there was a clear visual difference. We were also unable to use the same FID evaluating metric as interpolations, since semantic manipulations by design conditionally generate images out of distribution, whereas FID compares datasets of the same distribution.\n\n[1] Ravuri, Suman, and Oriol Vinyals. \"Classification Accuracy Score for Conditional Generative Models.\" arXiv preprint arXiv:1905.10887 (2019).\n[2] Salimans, Tim, et al. \"Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications.\" arXiv preprint arXiv:1701.05517 (2017).\n[3] Noroozi, Mehdi, and Paolo Favaro. \"Unsupervised learning of visual representations by solving jigsaw puzzles.\" European Conference on Computer Vision. Springer, Cham, 2016.\n[4] Gidaris, Spyros, Praveer Singh, and Nikos Komodakis. \"Unsupervised representation learning by predicting image rotations.\" arXiv preprint arXiv:1803.07728 (2018).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bye8hREtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1357/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1357/Authors|ICLR.cc/2020/Conference/Paper1357/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157223, "tmdate": 1576860561328, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment"}}}, {"id": "SJejdn2msH", "original": null, "number": 1, "cdate": 1573272690910, "ddate": null, "tcdate": 1573272690910, "tmdate": 1573272690910, "tddate": null, "forum": "Bye8hREtvB", "replyto": "rygwa-Oi5r", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "Thank you for your review. We would like to emphasize that the novelty of our work is showing the Fisher scores of PixelCNNs do indeed contain high-level semantic information about the data, which we believe is interesting given the common knowledge that PixelCNNs tend to model only low-level statistics of the data. Prior experiments such as in [2] showed that PixelCNNs with small receptive fields maintain log-likelihood performance close to PixelCNNs with large receptive fields, suggesting that PixelCNNs focus on modeling low level statistics about the data, rather than global semantically meaningful information.\n\nWe show that contrary to this common knowledge, PixelCNNs actually do contain global semantically meaningful information \u2014 although to access this information one must be careful to extract it in the correct way.  Our experiments show that naively interpolating using PixelCNN layer activations is not the correct way, as it results in non-meaningful interpolations. Surprisingly, however, we show that interpolating in Fisher score space does result in semantically meaningful interpolations. We believe that this demonstrates that PixelCNNs do capture high-level information about the data, contrary to the common knowledge that they only capture low-level statistics.\n\n> The paper uses the activation of the last layers of the PixelCNN as a baseline, which I consider to be a very weak baseline\n\nOur paper focuses on the question: is it possible to perform image interpolation using autoregressive models? Our experiments were designed to show that project Fisher scores provide better and more meaningful image manipulations than any other alternative latent spaces inherent to an autoregressive model, such as layer activations and noise space. In particular, the goal of our work is not to develop a new representation learning method; it is to develop an image interpolation method using autoregressive models. We believe that this is an interesting avenue of research because autoregressive models are not clearly suited for image interpolation, unlike VAEs and flows which have a clearly usable latent space.\n\n> For the evaluation, the paper only considers the FID score on the interpolated images and reconstructions. There are much better ways to compare the quality of unsupervised representations \u2026\n\nWe designed our evaluation metric with the intention to quantitatively show that interpolations using Fisher scores are better than those of using alternative embedding spaces of an autoregressive model. Empirically, using FID on interpolated datasets showed a strong correlation between FID scores and interpolation quality. \n\nOur paper does not focus on solving unsupervised learning using Fisher scores. Rather, it focuses on a novel method using Fisher scores to perform image manipulation using autoregressive models. We believe that a metric designed to evaluate interpolations is a more direct quantitative measurement of image manipulation quality, compared to standard representation learning evaluation methods.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bye8hREtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1357/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1357/Authors|ICLR.cc/2020/Conference/Paper1357/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157223, "tmdate": 1576860561328, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Authors", "ICLR.cc/2020/Conference/Paper1357/Reviewers", "ICLR.cc/2020/Conference/Paper1357/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Comment"}}}, {"id": "H1gJnKcl9B", "original": null, "number": 1, "cdate": 1572018598936, "ddate": null, "tcdate": 1572018598936, "tmdate": 1572972479443, "tddate": null, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper focuses on the problem of interpolating between data points using neural autoregressive models. The core idea is that it is possible to use (a smaller-dimensional projection of) the Fisher score of the density function defined by the autoregressive model to represent data points in embedding space, and a neural decoder for mapping them back to input space. Experiments on both MNIST and Celeb suggest that this is a sensible method, and leads to smoother interpolations rather than just relying on the embeddings resulting from the network activations.\n\nMinor: the FID acronym on pg. 2 was not introduced beforehand.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575878381301, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Reviewers"], "noninvitees": [], "tcdate": 1570237738554, "tmdate": 1575878381315, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review"}}}, {"id": "rygwa-Oi5r", "original": null, "number": 3, "cdate": 1572729278990, "ddate": null, "tcdate": 1572729278990, "tmdate": 1572972479353, "tddate": null, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "invitation": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This work proposes to learn a latent space for the PixelCNN by first computing the Fisher score of the PixelCNN model and then projecting it onto a lower-dimensional space using a sparse random matrix.\n\nMy first concern about this work is its novelty. Defining a feature space using the Fisher kernel of a generative model is a very well-known idea, and there is a large body of work around that. As the paper points out, the problem with the Fisher score for the recent deep generative model architectures is that Fisher score operates in the parameter space and the deep models have a very large number of parameters. The paper proposes to get around this problem by projecting the Fisher score onto a lower-dimensional space using random matrices. But I am not convinced that this random projection\u00a0can learn useful representations, which brings me to my second concern about the\u00a0evaluation metric. The paper uses the activation of the last layers of the PixelCNN as a baseline, which I consider to be a very weak baseline. Each activation at spatial position (i,j) only depends on the previous pixels and I believe they are not in general good high-level representations. For the evaluation, the paper only considers the FID score on the interpolated images and reconstructions. There are much better ways to compare the quality of unsupervised representations such as their performance on classifying images with a linear classifier as done in [1]. The paper would improve by comparing the quality of its latent representations with the recent unsupervised/self-supervised learning methods such as [1,2].\n\n[1] Data-Efficient Image Recognition with Contrastive Predictive Coding\n[2] Learning deep representations by mutual information estimation and maximization"}, "signatures": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1357/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Natural Image Manipulation for Autoregressive Models Using Fisher Scores", "authors": ["Wilson Yan", "Jonathan Ho", "Pieter Abbeel"], "authorids": ["wilson1.yan@berkeley.edu", "jonathanho@berkeley.edu", "pabbeel@cs.berkeley.edu"], "keywords": ["fisher score", "generative models", "image interpolation"], "TL;DR": "We develop a novel method to perform image interpolation and semantic manipulation using autoregressive models through fisher scores", "abstract": "Deep autoregressive models are one of the most powerful models that exist today which achieve state-of-the-art bits per dim. However, they lie at a strict disadvantage when it comes to controlled sample generation compared to latent variable models. Latent variable models such as VAEs and normalizing flows allow meaningful semantic manipulations in latent space, which autoregressive models do not have. In this paper, we propose using Fisher scores as a method to extract embeddings from an autoregressive model to use for interpolation and show that our method provides more meaningful sample manipulation compared to alternate embeddings such as network activations.", "pdf": "/pdf/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "paperhash": "yan|natural_image_manipulation_for_autoregressive_models_using_fisher_scores", "original_pdf": "/attachment/b628a7e74672a349f7beebed75ca8a33165bb386.pdf", "_bibtex": "@misc{\nyan2020natural,\ntitle={Natural Image Manipulation for Autoregressive Models Using Fisher Scores},\nauthor={Wilson Yan and Jonathan Ho and Pieter Abbeel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bye8hREtvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bye8hREtvB", "replyto": "Bye8hREtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1357/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575878381301, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1357/Reviewers"], "noninvitees": [], "tcdate": 1570237738554, "tmdate": 1575878381315, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1357/-/Official_Review"}}}], "count": 9}