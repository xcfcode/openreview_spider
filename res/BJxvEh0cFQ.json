{"notes": [{"id": "BJxvEh0cFQ", "original": "ByxHgT35KQ", "number": 1458, "cdate": 1538087982834, "ddate": null, "tcdate": 1538087982834, "tmdate": 1550892962676, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1ll1oYQl4", "original": null, "number": 1, "cdate": 1544948439524, "ddate": null, "tcdate": 1544948439524, "tmdate": 1545354490204, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Meta_Review", "content": {"metareview": "Reviewers largely agree that the proposed method for finetuning the deep neural networks is interesting and empirical results clearly show the benefits over finetuning only the last layer. I recommend acceptance. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Simple and effective parameter efficient method for finetuning"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1458/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352831634, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352831634}}}, {"id": "S1eTI1PuAX", "original": null, "number": 6, "cdate": 1543167829300, "ddate": null, "tcdate": 1543167829300, "tmdate": 1543167829300, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "SJeD6ZMT6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "content": {"title": "Response to Authors", "comment": "Thanks to the authors for their reply. I am satisfied with the current state of the paper and tend to keep my score."}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618651, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1458/Authors|ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618651}}}, {"id": "BJgEyp8gAQ", "original": null, "number": 5, "cdate": 1542642907799, "ddate": null, "tcdate": 1542642907799, "tmdate": 1542642953221, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "B1lPdZz6a7", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "content": {"title": "Thanks for the response", "comment": "Several changes have been made to my comments, thanks for pointing out the mistakes. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618651, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1458/Authors|ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618651}}}, {"id": "SJgssRVq3X", "original": null, "number": 2, "cdate": 1541193379353, "ddate": null, "tcdate": 1541193379353, "tmdate": 1542642917664, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "content": {"title": "Inspiring thought, though lack of sufficient proofs", "review": "This paper explored the means of tuning the neural network models using less parameters. The authors evaluated the case where only the batch normalisation related parameters are fine tuned, along with the last layer, would generate competitive classification results, while using very few parameters comparing with fine tuning the whole network model. However, several questions are raised concerning the experiment design and analysis:\n1. Only MobilenetV2 and InceptionV3 are evaluated as classification model, while other mainstream models such as ResNet, DenseNet are not included. Would it be very different regarding the conclusion of this paper?\n2. It seems that the only effective manner is by fine tuning the parameters of both batch normalisation related and lasts layer, while fine tuning last layer seems to be having the main impact on the final result. In Table 4, authors do not even provide the results fine tuning last layer only.\n3. The organisation of the paper and the order of illustration is a bit confusing. e.g. later sections are frequently referred in the earlier sections. Personally I would prefer a plain sequence than keep turning pages for confirmation.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "cdate": 1542234225301, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335951094, "tmdate": 1552335951094, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJeD6ZMT6Q", "original": null, "number": 4, "cdate": 1542427071202, "ddate": null, "tcdate": 1542427071202, "tmdate": 1542427071202, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "S1e7BbGqj7", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "We thank AnonReviewer1 for the review. Below are our responses inline. \n\n>> * explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).\n\nThe hyper-parameters are the same as those in the standard setup for MobilenetV2 or InceptionV3. We have added a line in the experiments section mentioning this.\n\n>> * fix Figure 3, it's impossible to read in the paper-printed version\n\nThe four subfigures are now split into two rows and are now hopefully easily readable. \n\n>> * explain how the average number of parameters per model in computed in Tables 4 and 5. E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account. The same holds for 0 in the second column, etc.\n\nThank you for pointing this out. We had mistakenly only counted the non-shared parameters in the models, and forgot to include the last layer parameters in the second column. This has now been corrected to simply the total number of parameters trained. \n\n>> * add a proper discussion for domain adaptation part. The simple \"The results are shown in Table 5\" is not enough. \n\nDone. \n\n>> * consider leaving the discussion of cost-efficient model cascades out. The presented details are too condensed and do not add value to the paper.\n\nMakes sense. We moved these results to the appendix to be included in the full version.\n\n>> * explain how different resolutions are managed by the same model in the domain adaptation experiments.\n\nWe added a line in the paper stating the images are brought to the right resolution using bilinear interpolation before passing as input to each model. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618651, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1458/Authors|ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618651}}}, {"id": "B1lPdZz6a7", "original": null, "number": 3, "cdate": 1542426991146, "ddate": null, "tcdate": 1542426991146, "tmdate": 1542426991146, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "SJgssRVq3X", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "content": {"title": "Response to AnonReviewer2", "comment": "We thank AnonReviewer2 for the review. Below is our detailed response.\n\n>> 1. Only MobilenetV2 and InceptionV3 are evaluated as classification model, while the residual connection based models such as ResNet, DenseNet are not included. Would it be very different regarding the conclusion of this paper?\n\nWe experimented extensively with multiple tasks (classification, detection, multi-task learning) and datasets instead of trying more models for the same task, as we intended to test the effectiveness of our method in various situations. Further, MobileNetV2 has residual connections, which encouraged us to believe that the results on other residual connection based models would be similar. \n\nWe ran experiments with ResNet and got similar results. For instance, transfer learning accuracy from ImageNet to Cars goes up from 61.4% (last layer fine-tuning) to 73% (S/B patch + last layer fine-tuning). From ImageNet to Aircraft, accuracy goes up from 51.8% (last layer) to 62.5% (S/B patch + last layer). In the interest of space, we did not think it added much to the experimental section of the paper.\n\n>> 2. It seems that the only effective manner is by fine tuning the parameters of both batch normalisation related and lasts layer, while fine tuning last layer seems to be having the main impact on the final result. In Table 4, authors do not even provide the results fine tuning last layer only.\n\nFine-tuning the last layer is not always required. For instance, in domain adaptation (Sec 5.4), the model patch consists of only the batch normalization parameters, and the resulting accuracies match or exceed those of individually trained models. \n\nFrom Figure 3 and Table 4, we see that fine-tuning scales, biases (S/B) and depthwise (DW) along with last layer causes an average 50% relative improvement in accuracy over fine-tuning only the last layer while being only a small (4%) increase in terms of number of parameters over the last layer.\n\nWhen performing multi-task or transfer learning across different tasks (e.g. ImageNet \u2192 Places365), it becomes necessary to have different last layers as the output spaces are different. In Table 4, the second column corresponds to the case where only the last layer is separate for each task. We apologize if this was not clear - we have now updated Table 4 headers to explicitly reflect this fact. \n \n>> 3. The organisation of the paper and the order of illustration is a bit confusing.\n\nWe will be happy to modify the paper if the reviewer elaborates on this point.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618651, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1458/Authors|ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618651}}}, {"id": "H1lFC1M6p7", "original": null, "number": 2, "cdate": 1542426577396, "ddate": null, "tcdate": 1542426577396, "tmdate": 1542426577396, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "BygmSOC2hm", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "We thank AnonReviewer3 for the review. Below are our responses to specific comments. \n\n>> 1. The memory benefit is obvious, it would be interesting to know the training speed compared to fine-tuning methods (both the last layer and the entire network)?\n\nGenerally, we did not see a large variation in training speed on the datasets that we tried. All fine-tuning approaches needed 50-200K steps depending on the learning rate and the training method. While different approaches definitely differ in the number of steps necessary for convergence, we find these changes to be comparable to changes in other hyper-parameters such as learning rate, and generally not providing a clear signal worth articulating in the paper. \n\n>> 2. It seems that DW patch has limited effects compared to S/B patch. It would be nice to have some analysis of this aspect.\n\nYes, DW patch seems to be less powerful than S/B patch. Generally, DW patch resulted in about 5-10% percentage points lower accuracy than the S/B patch while having comparable number of parameters. However, it does add a lot of value when used in conjunction with S/B patch. For instance, from the top two figures in Figure 3, we see that fine-tuning the combination of DW and S/B patches (4% of the network parameters) closes the accuracy gap between S/B patch (1% of the network parameters) and fine-tuning the last layer (37% of the network parameters). \n\nIf the reviewer thinks that adding the performance of DW only patch would be a useful addition to Figure 3, we are happy to do that. We had excluded it in the interest of not crowding the plots."}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618651, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJxvEh0cFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1458/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1458/Authors|ICLR.cc/2019/Conference/Paper1458/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers", "ICLR.cc/2019/Conference/Paper1458/Authors", "ICLR.cc/2019/Conference/Paper1458/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618651}}}, {"id": "BygmSOC2hm", "original": null, "number": 3, "cdate": 1541363770943, "ddate": null, "tcdate": 1541363770943, "tmdate": 1541533117262, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "content": {"title": "Interesting results on transfer learning", "review": "The authors proposed an interesting method for parameter-efficient transfer learning and multi-task learning. The authors show that in transfer learning fine-tuning the last layer plus BN layers significantly improve the performance of only fine-tuning the last layer. The results are surprisingly good and the authors also did analysis on the relationship between embedding space and biases. \n\n1. The memory benefit is obvious, it would be interesting to know the training speed compared to fine-tuning methods (both the last layer and the entire network)?\n2. It seems that DW patch has limited effects compared to S/B patch. It would be nice to have some analysis of this aspect.\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "cdate": 1542234225301, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335951094, "tmdate": 1552335951094, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1e7BbGqj7", "original": null, "number": 1, "cdate": 1540133178746, "ddate": null, "tcdate": 1540133178746, "tmdate": 1541533116801, "tddate": null, "forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "content": {"title": "Interesting idea and fair evaluation. Accept with minor changes.", "review": "Summary: the paper introduces a new way of fine-tuning neural networks. Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers. The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.\n\nQuality: the introduced way of fine-tuning is interesting alternative to the typical last layer re-training. I like that the authors present an intuition behind their approach and justify it by an illustrative example. The experiments are fair, assuming the authors explain the choice of hyper-parameters during the revision.\n\nClarity: in general the paper is well-written. The discussion of multi-task and domain adaptation parts can be improved though.\n\nOriginality: the contributions are novel to my best knowledge.\n\nSignificance: high, I believe the paper may facilitate a further developments in the area.\n\nI ask the authors to address the following during the rebuttal stage:\n* explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).\n* fix Figure 3, it's impossible to read in the paper-printed version\n* explain how the average number of parameters per model in computed in Tables 4 and 5. E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account. The same holds for 0 in the second column, etc.\n* add a proper discussion for domain adaptation part. The simple \"The results are shown in Table 5\" is not enough. \n* consider leaving the discussion of cost-efficient model cascades out. The presented details are too condensed and do not add value to the paper.\n* explain how different resolutions are managed by the same model in the domain adaptation experiments.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1458/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning", "abstract": "We introduce a novel method that enables parameter-efficient transfer and multi-task learning with deep neural networks. The basic approach is to learn a model patch - a small set of parameters - that will specialize to each task, instead of fine-tuning the last layer or the entire network. For instance, we show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, we show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly. Our approach allows both simultaneous (multi-task) as well as sequential transfer learning. In several multi-task learning problems, despite using much fewer parameters than traditional logits-only fine-tuning, we match single-task performance. \n", "keywords": ["deep learning", "mobile", "transfer learning", "multi-task learning", "computer vision", "small models", "imagenet", "inception", "batch normalization"], "authorids": ["pramodkm@uchicago.edu", "mark.sandler@gmail.com", "azhmogin@google.com", "howarda@google.com"], "authors": ["Pramod Kaushik Mudrakarta", "Mark Sandler", "Andrey Zhmoginov", "Andrew Howard"], "pdf": "/pdf/9eaa0161656b9baebf26e14f030b153f69d764e0.pdf", "paperhash": "mudrakarta|k_for_the_price_of_1_parameterefficient_multitask_and_transfer_learning", "TL;DR": "A novel and practically effective method to adapt pretrained neural networks to new tasks by retraining a minimal (e.g., less than 2%) number of parameters", "_bibtex": "@inproceedings{\nmudrakarta2018k,\ntitle={K For The Price Of 1: Parameter Efficient Multi-task And Transfer Learning},\nauthor={Pramod Kaushik Mudrakarta and Mark Sandler and Andrey Zhmoginov and Andrew Howard},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJxvEh0cFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1458/Official_Review", "cdate": 1542234225301, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJxvEh0cFQ", "replyto": "BJxvEh0cFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1458/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335951094, "tmdate": 1552335951094, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1458/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 10}