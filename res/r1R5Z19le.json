{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1491121759597, "tcdate": 1478254998257, "number": 158, "id": "r1R5Z19le", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "r1R5Z19le", "signatures": ["~Elad_Hoffer1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": ["rJoZ1i3_l"], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396391253, "tcdate": 1486396391253, "number": 1, "id": "B1JehM8dg", "invitation": "ICLR.cc/2017/conference/-/paper158/acceptance", "forum": "r1R5Z19le", "replyto": "r1R5Z19le", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper studies semi-supervised learning by combining ideas from metric embedding and entropy. The model attempts to embed samples with visible labels into corresponding clusters, while embedding samples without labels close to some of the cluster centroids. Strong numerical results are reported on small-scale semi-supervised image tasks. \n \n The reviewers acknowledged the effectiveness of the method and the strong numerical results, but expressed concerns about the lack of originality with respect to previous works. \n \n The AC found the work pleasantly well presented and strikingly simple, yet with excellent numerical performance. These two qualities make this work actually refreshing relative to the ever-increasing complexity of current deep learning architectures. In particular, this seems to be the *proper* way to perform semi-supervised learning. \n However, the model appears extremely similar to [Grandvalet & Bengio, '04], not just in the entropy-minimization regularization for unlabeled examples, but also for the cross-entropy minimization of labeled examples and the semi-supervised objective. The only difference I perceive is that [G & B '04] present a generic recognition model p( z | x), whereas the present submission uses a classification layer of the form \n (1) p(z | x ) = softmax( -|| Phi(x) - Phi(y_k) ||^2 ), \n where the y_k are randomly chosen examples of class respectively k. p(z | x) is thus random relative to the choice of 'anchors' y_k. \n Thus, the present model is rather a particular case, unless I misunderstood. In that case, the main question is to understand how much the excellent numerical performance relies on this particular choice of classification layer. The numerical section should consider a baseline where (1) is replaced by a 'standard' classification softmax of the form p(z | x ) = softmax( < v_k, Phi(x) > ), where v_k are class-specific parameters. \n \n For these reasons,we recommend inviting this submission to the workshop track, and we encourage the authors to address the previous remark.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396393423, "id": "ICLR.cc/2017/conference/-/paper158/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "r1R5Z19le", "replyto": "r1R5Z19le", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396393423}}}, {"tddate": null, "tmdate": 1484042591932, "tcdate": 1484042591932, "number": 4, "id": "BkOPbNzIe", "invitation": "ICLR.cc/2017/conference/-/paper158/public/comment", "forum": "r1R5Z19le", "replyto": "S1ZMS80Qx", "signatures": ["~Elad_Hoffer1"], "readers": ["everyone"], "writers": ["~Elad_Hoffer1"], "content": {"title": "comment", "comment": "Thank you for the review, we appreciate your remarks and incorporated them into latest revision.\nAs you point out, the objective introduced in this work corresponds to a sum of distance ratio loss (Hoffer 2015) and entropy minimization (Grandvalet 2004). While these are not new, this is the first attempt to our knowledge, of combining these ideas for semi-supervised metric learning. We will add an additional information regarding the differences from these earlier works.\nSzegedy 2015 uses targets that are \u201csoftened\u201d by weighted average between the true-target, and a random sample from a noise distribution u(k) (uniform in the paper). As these are sampled separately for each iteration, this corresponds to random label noise. We will add an additional explanation in our paper for this fact.\nThe choices for \\lambda_{1,2} and k-NN parameter were made using a validation set. We did not found any substantial difference between the values we explored, so they were usually left as the default value.\nWe will add an additional figure depicting the labels at the start of training as you suggested. We will also try to shed some light on the interaction between the losses used."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287707212, "id": "ICLR.cc/2017/conference/-/paper158/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1R5Z19le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper158/reviewers", "ICLR.cc/2017/conference/paper158/areachairs"], "cdate": 1485287707212}}}, {"tddate": null, "tmdate": 1484042557984, "tcdate": 1484042557984, "number": 3, "id": "B1LB-VzLg", "invitation": "ICLR.cc/2017/conference/-/paper158/public/comment", "forum": "r1R5Z19le", "replyto": "ByfUT5b4x", "signatures": ["~Elad_Hoffer1"], "readers": ["everyone"], "writers": ["~Elad_Hoffer1"], "content": {"title": "comment", "comment": "Thank you for the review, we appreciate your remarks and incorporated them into latest revision.\nAs you point out, this work is based on the method of Hoffer and Ailon (2015) of metric learning using embedded distance ratios. However, this work is the first, as far as we know, to leverage this method to learn in a semi-supervised regime. This is done by using an additional entropy minimization objective over the distribution of embedded distance ratios. \nAn additional discussion will be added to the paper to try and address when this method will break down."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287707212, "id": "ICLR.cc/2017/conference/-/paper158/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1R5Z19le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper158/reviewers", "ICLR.cc/2017/conference/paper158/areachairs"], "cdate": 1485287707212}}}, {"tddate": null, "tmdate": 1484042516435, "tcdate": 1484042516435, "number": 2, "id": "rynM-Vz8x", "invitation": "ICLR.cc/2017/conference/-/paper158/public/comment", "forum": "r1R5Z19le", "replyto": "rkAXNP7Ex", "signatures": ["~Elad_Hoffer1"], "readers": ["everyone"], "writers": ["~Elad_Hoffer1"], "content": {"title": "comment", "comment": "Thank you for the review, we appreciate your remarks and incorporated them into latest revision.\nSpecifically, we wish to address your concerns for novelty of this work. Comparing with the works of Hadsell and Weston, this work uses a novel objective which is composed of a distance ratio measure (unlike the contrastive, hinge based loss used before), and an entropy minimization on the distance measure to labeled samples. Although distance ratio loss (Hoffer 2015) and entropy minimization (Grandvalet 2004) are not new, this is the first attempt to our knowledge, of combining these ideas for semi-supervised metric learning. Furthermore, we would argue that the interaction between these criterions is a form of balancing (which can be weighted), that corresponds with your observation for the need of a balancing constraint.\nWe would also like to point that the neural network models themselves are very simple and the baseline achieved by training them with the standard cross-entropy has significantly lower accuracy. Therefore, we are certain that the high performance achieved is due to the proposed objective, and not the network architecture."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287707212, "id": "ICLR.cc/2017/conference/-/paper158/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1R5Z19le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper158/reviewers", "ICLR.cc/2017/conference/paper158/areachairs"], "cdate": 1485287707212}}}, {"tddate": null, "tmdate": 1482023974279, "tcdate": 1482023974279, "number": 3, "id": "rkAXNP7Ex", "invitation": "ICLR.cc/2017/conference/-/paper158/official/review", "forum": "r1R5Z19le", "replyto": "r1R5Z19le", "signatures": ["ICLR.cc/2017/conference/paper158/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper158/AnonReviewer3"], "content": {"title": "Not clearly enough related to previous work.", "rating": "4: Ok but not good enough - rejection", "review": "The authors propose a semi-supervised technique for neural networks which includes two objectives: (1) the neural net embeddings of two samples with identical labels is constrained to be closer than the embeddings of samples with different labels (2) the embedding of an unlabeled example is constrained to be close to the embeddings of the closest labeled sample (and far away from the other ones).\n\nWhile the authors list a number of previous works, they do not relate them very well with their approach, and actual differences appear unclear. In particular, the approach seems rather incremental with respect to (Hadsell et al. 2006), the way the neighbors are chosen being the main difference; in that respect, (Weston et al, 2008 or 2012) (which could be viewed as an application of DrLim from Hadsell et al, applied to semi-supervised learning) is even closer to the approach proposed here.\n\nThere is also no balancing constraint in the proposed approach, which was known to be crucial in all these models from the 2000s.\n\nConcerning the experimental results, reported performance are very good; given the approach is very close to previous work, it is hard to know if good performance come from better neural net architectures or something else. This should be clarified.\n\nIn summary, the novelty is not clearly defined in this paper; differences with existing literature should be highlighted. Experimental results are very good, but it is hard to know where comes the difference in performance with previous (very related) work.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512680782, "id": "ICLR.cc/2017/conference/-/paper158/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper158/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper158/AnonReviewer1", "ICLR.cc/2017/conference/paper158/AnonReviewer2", "ICLR.cc/2017/conference/paper158/AnonReviewer3"], "reply": {"forum": "r1R5Z19le", "replyto": "r1R5Z19le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512680782}}}, {"tddate": null, "tmdate": 1481692425434, "tcdate": 1481692425428, "number": 1, "id": "S1ZMS80Qx", "invitation": "ICLR.cc/2017/conference/-/paper158/official/review", "forum": "r1R5Z19le", "replyto": "r1R5Z19le", "signatures": ["ICLR.cc/2017/conference/paper158/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper158/AnonReviewer1"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "This work presents an embedding approach for semi-supervised learning with neural nets, in the presence of little labeled data. The intuition is to learn a metric embedding that forms \u201cclusters\u201d with the following desiderata: two labeled examples from the class should have a smaller distance in this embedding compared to any example from another class & a given unlabeled example embedding will be closer to all of the embeddings of *some* label (i.e. that a given unlabeled example will be \u201cmatched\u201d to one cluster). The paper formulates these intuitions as two differentiable losses and does gradient descent on their sum.\n\nIt\u2019s unclear to me how different is this work from the sum of Hoffer & Ailon (2015) (which is eq. 3) and Grandvalet & Bengio (2004) (seems to be related to eq. 4). Would be nice if the authors not only cited the previous work but summarized the actual differences.\nIn Section 5.1, the authors say that Szegedy et al. (2015) use random noise in the targets -- is that actually true? I think only soft targets are used (which are not noisy).\n\nDoes the choice of \\lambda_{1,2} make a difference?\n\nHow is k for k-NN actually chosen? Is there a validation set?\n\nFigure 1 would benefit from showing where the labeled examples were at the beginning of training (relative to each other / rest of the data).\n\nThe submission seems overall OK, but somewhat light on actual data-driven or theoretical insights. I would\u2019ve liked experiments showing the influence of data set sizes at the very least, and ablation experiments that showed the influence of each of the corresponding losses.\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512680782, "id": "ICLR.cc/2017/conference/-/paper158/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper158/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper158/AnonReviewer1", "ICLR.cc/2017/conference/paper158/AnonReviewer2", "ICLR.cc/2017/conference/paper158/AnonReviewer3"], "reply": {"forum": "r1R5Z19le", "replyto": "r1R5Z19le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512680782}}}, {"tddate": null, "tmdate": 1481458752386, "tcdate": 1481458752378, "number": 1, "id": "Sk_SV6cml", "invitation": "ICLR.cc/2017/conference/-/paper158/public/comment", "forum": "r1R5Z19le", "replyto": "BJzbomkQg", "signatures": ["~Elad_Hoffer1"], "readers": ["everyone"], "writers": ["~Elad_Hoffer1"], "content": {"title": "Answer", "comment": "Thank you for you question.\nThe proposed objective can be affected by class imbalanced data set, which we believe can be mitigated by proportional weighting of the loss function. Further investigations are needed to quantify the affect of such phenomena."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287707212, "id": "ICLR.cc/2017/conference/-/paper158/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1R5Z19le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper158/reviewers", "ICLR.cc/2017/conference/paper158/areachairs"], "cdate": 1485287707212}}}, {"tddate": null, "tmdate": 1480698635607, "tcdate": 1480698618171, "number": 1, "id": "BJzbomkQg", "invitation": "ICLR.cc/2017/conference/-/paper158/pre-review/question", "forum": "r1R5Z19le", "replyto": "r1R5Z19le", "signatures": ["ICLR.cc/2017/conference/paper158/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper158/AnonReviewer2"], "content": {"title": "class imbalance", "question": "Can the authors comment on whether the proposed objective is affected by class imbalanced data sets?\ni.e. many more samples for some classes than others. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Semi-supervised deep learning by metric embedding", "abstract": "Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.", "pdf": "/pdf/7eac89ab912b7990b401913de9106ef5e6b257ee.pdf", "paperhash": "hoffer|semisupervised_deep_learning_by_metric_embedding", "keywords": ["Deep learning", "Semi-Supervised Learning"], "conflicts": ["technion.ac.il", "intel.com"], "authors": ["Elad Hoffer", "Nir Ailon"], "authorids": ["ehoffer@tx.technion.ac.il", "nailon@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959433219, "id": "ICLR.cc/2017/conference/-/paper158/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper158/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper158/AnonReviewer2"], "reply": {"forum": "r1R5Z19le", "replyto": "r1R5Z19le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper158/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959433219}}}], "count": 9}