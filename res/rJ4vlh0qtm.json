{"notes": [{"id": "rJ4vlh0qtm", "original": "S1g_FofFOX", "number": 1087, "cdate": 1538087919491, "ddate": null, "tcdate": 1538087919491, "tmdate": 1545355443586, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Skekr57teV", "original": null, "number": 1, "cdate": 1545316919031, "ddate": null, "tcdate": 1545316919031, "tmdate": 1545354473905, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "invitation": "ICLR.cc/2019/Conference/-/Paper1087/Meta_Review", "content": {"metareview": "The reviewers raised a number of major concerns including the incremental novelty of the proposed and a poor readability of the presented materials (lack of sufficient explanations and discussions). The authors decided to withdraw the paper.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper1087/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1087/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1087/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352971398, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1087/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1087/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1087/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352971398}}}, {"id": "Skl9IBL9A7", "original": null, "number": 3, "cdate": 1543296337780, "ddate": null, "tcdate": 1543296337780, "tmdate": 1543296378170, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "invitation": "ICLR.cc/2019/Conference/-/Paper1087/Official_Comment", "content": {"title": "A Revised Version", "comment": "In the revised paper, we have updated a complete appendix which is missing in the original submission. Thanks."}, "signatures": ["ICLR.cc/2019/Conference/Paper1087/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1087/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1087/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1087/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611801, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJ4vlh0qtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1087/Authors", "ICLR.cc/2019/Conference/Paper1087/Reviewers", "ICLR.cc/2019/Conference/Paper1087/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1087/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1087/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1087/Authors|ICLR.cc/2019/Conference/Paper1087/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1087/Reviewers", "ICLR.cc/2019/Conference/Paper1087/Authors", "ICLR.cc/2019/Conference/Paper1087/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611801}}}, {"id": "SJgGnWw92m", "original": null, "number": 3, "cdate": 1541202346397, "ddate": null, "tcdate": 1541202346397, "tmdate": 1541533434208, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "invitation": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "content": {"title": "not clear about the originality", "review": "This paper proposes a spontaneous and self-organizing communication learning scheme in multi-agent RL setup. The problem is interesting. I mainly have one concern regarding its originality.\n\nFrom a technical perspective, it's not clear to me that there's much novelty in this approach.  I guess it might be the case the focus of the paper is to propose a framework or scheme. However, almost all the ingredients/components are standard.\n\nRegarding clarity, it's not clear to me:\n* how the structure from Figure 2 can be reproduced. \n* how statistically significant the evaluation results are. ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1087/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "cdate": 1542234309284, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1087/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335869800, "tmdate": 1552335869800, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1087/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJgUO5sOn7", "original": null, "number": 1, "cdate": 1541089901958, "ddate": null, "tcdate": 1541089901958, "tmdate": 1541533433986, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "invitation": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "content": {"title": "Paper can be improved by adding more ablation studies around the architecture and doing a more through empirical evaluation.", "review": "Summary: \nThis paper expands on the work on 'emergent communication' with 2 innovations: \n- The architecture has a separate 'message channel' that processes the incoming and outgoing messages mostly independently of the hidden state of the agent. There are also dedicated architecture elements for the interaction between the hidden state and the message stream. \n- The outgoing message is gated with a 'speak' action: only when the agent takes the speak-action at time step t is a message sent out at timestep t+1. \n\nComments for improvement: \n-The paper proposes a rather complicated architecture, with many moving part. In the paper's current form it is extremely hard to see which part of this architecture contribute to the success of the method. A set of ablation studies on the different components would indeed be very helpful. \n-Using the word 'thought' to describe the hidden state of the agent is rather distracting.\n-Equation (1): This just seems to be the policy gradient term for a factorised action space across 'environment action' and 'communication action'. The only obvious difference is that the policy here is shown to condition on the state representation s_t, rather than on the input. Is that intended?\n-The paper suffers from a lot of undefined notation, e.g. the s_t above. Please clarify.\n-In Figure 2b) the MCU is shown to produce the action a_t as an output. That seems like a mistake. \n-Figure 4): The results seem to be extremely unstable, which is a well known issue for independent learning. Recent work (MADDPG, COMA) has shown that centralised critics can drastically avoid these instabilities and improve final performance. Did you compare against using a centralised critic, V(central state), rather the V(observation)? Also, using a single seed on this kind of unstable learning process renders the results highly non-conclusive. \n-In Figure (5), what are the red-arrows? Do these correspond to the actual actions taken by the agents or are they simply annotations? It would be good to see how far the communication range is by comparison. Also, why is there a blob of 'communicating' agents far from the enemy? \n-Are different methods in the large scale battle task trained in self-play and then pitched against other methods in a round-robin tournament after training has finished or are they trained against each other? \n-In Figure 6 (a), why are average rewards changing over the course of training? I would expect this to be a zero-sum setting in self-play. \n-I couldn't find any supplementary material referenced in the text for the details. Instead the paper seems to have another copy of the paper itself attached in the pdf. This makes it hard to evaluate the paper given that few details around training are provided in the main text. \n\nOverall I am concerned that the learning method used in the paper (independent baseline) is known to be unstable and to produce poor results in the multi-agent setting (see COMA and MADDPG). This raises the concern that the communication channel is mostly useful for overcoming the issues introduced from having a decentralised critic.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1087/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "cdate": 1542234309284, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1087/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335869800, "tmdate": 1552335869800, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1087/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkxIWUbt2Q", "original": null, "number": 2, "cdate": 1541113342389, "ddate": null, "tcdate": 1541113342389, "tmdate": 1541533433737, "tddate": null, "forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "invitation": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "content": {"title": "Review", "review": "The paper presents a study on multi-agent communication. The main innovation from previous work is the introduction of an explicit Speak binary action that controls whether or not an agent will emit a message. The proposed model is test on two tasks, multi-camera surveillance and battle tasks with a large number of population.\n\nOverall, this paper is clear (although model details are missing, the authors point at the Appendix, but the Appendix is missing) and the authors compare to a number of baselines. I appreciate the use of multi-agent communication in cases where the number of agents very large,  as this is a very good stress test for current algorithms and can potentially help identifying novel challenges. \n\nMy main concern is that in a collaborative setting I don't see why we should expect that occluding information is better than revealing information? Isn't always revealing everything the best strategy? When only 3 cameras, I really cannot think of why a model would get better performance by choosing to not reveal information. Figure 4b somewhat confirms that as there seems to be a lot of variance on the Ssoc. Have you checked how stable are your results across runs? I could believe that occluding information can be beneficial if the number of agents is very big and there is redundancy. But in the limit, not revealing information should only facilitate training --  and indeed this seems to be happening in 6a as Ssoc is learning faster but meanfield is catching up. Could there be an ablation experiment in which everything stays the same in the model but the agents always activate the Speak action? This would answer the question of how crucial this main Speak feature is for Ssoc.\n\nCan you elaborate on this? Moreover, since the Appendix appears to be missing, can you comment on stable results were across runs?\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1087/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SSoC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration", "abstract": "Multi-agent collaboration is required by numerous real-world problems. Although distributed setting is usually adopted by practical systems, local range communication and information aggregation still matter in fulfilling complex tasks. For multi-agent reinforcement learning, many previous studies have been dedicated to design an effective communication architecture. However, existing models usually suffer from an ossified communication structure, e.g., most of them predefine a particular communication mode by specifying a fixed time frequency and spatial scope for agents to communicate regardless of necessity. Such design is incapable of dealing with multi-agent scenarios that are capricious and complicated, especially when only partial information is available. Motivated by this, we argue that the solution is to build a spontaneous and self-organizing communication (SSoC) learning scheme. By treating the communication behaviour as an explicit action, SSoC learns to organize communication in an effective and efficient way. Particularly, it enables each agent to spontaneously decide when and who to send messages based on its observed states. In this way, a dynamic inter-agent communication channel is established in an online and self-organizing manner. The agents also learn how to adaptively aggregate the received messages and its own hidden states to execute actions. Various experiments have been conducted to demonstrate that SSoC really learns intelligent message passing among agents located far apart. With such agile communications, we observe that effective collaboration tactics emerge which have not been mastered by the compared baselines.", "keywords": ["reinforcement learning", "multi-agent learning", "multi-agent communication", "deep learning"], "authorids": ["kong@pku.edu.cn", "lijingg@pku.edu.cn", "jimxinbo@gmail.com", "yizhou.wang@pku.edu.cn"], "authors": ["Xiangyu Kong", "Jing Li", "Bo Xin", "Yizhou Wang"], "TL;DR": "This paper proposes a spontaneous and self-organizing communication (SSoC) learning scheme for multi-agent RL tasks.", "pdf": "/pdf/1d30cd0a472052ed717904f5d4e01c108e5520b2.pdf", "paperhash": "kong|ssoc_learning_spontaneous_and_selforganizing_communication_for_multiagent_collaboration", "_bibtex": "@misc{\nkong2019ssoc,\ntitle={{SS}oC: Learning Spontaneous and Self-Organizing Communication for Multi-Agent Collaboration},\nauthor={Xiangyu Kong and Jing Li and Bo Xin and Yizhou Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=rJ4vlh0qtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1087/Official_Review", "cdate": 1542234309284, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJ4vlh0qtm", "replyto": "rJ4vlh0qtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1087/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335869800, "tmdate": 1552335869800, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1087/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 6}