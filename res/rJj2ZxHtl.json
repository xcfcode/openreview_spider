{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028641577, "tcdate": 1490028641577, "number": 1, "id": "Sy5wdtaig", "invitation": "ICLR.cc/2017/workshop/-/paper161/acceptance", "forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028642088, "id": "ICLR.cc/2017/workshop/-/paper161/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028642088}}}, {"tddate": null, "tmdate": 1489713703914, "tcdate": 1489713703914, "number": 4, "id": "rJeNq3_jl", "invitation": "ICLR.cc/2017/workshop/-/paper161/public/comment", "forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "signatures": ["~Philip_Bachman1"], "readers": ["everyone"], "writers": ["~Philip_Bachman1"], "content": {"title": "Result Update", "comment": "We've updated our submission with better results on Omniglot. For the 20-way setting with 50 total label queries, we first train the model to query 20 labels, and then fine-tune the model for 50 queries. Both phases of training optimize a reward which measures improvement in prediction accuracy. While fine-tuning, we add an auxiliary reward which encourages a class-balanced selection policy."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368627924, "tcdate": 1487368627924, "id": "ICLR.cc/2017/workshop/-/paper161/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "reply": {"forum": "rJj2ZxHtl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368627924}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489713312712, "tcdate": 1487368627112, "number": 161, "id": "rJj2ZxHtl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "rJj2ZxHtl", "signatures": ["~Philip_Bachman1"], "readers": ["everyone"], "content": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489548535288, "tcdate": 1489548535288, "number": 3, "id": "r1yZr4Lix", "invitation": "ICLR.cc/2017/workshop/-/paper161/public/comment", "forum": "rJj2ZxHtl", "replyto": "BJDET5Esx", "signatures": ["~Philip_Bachman1"], "readers": ["everyone"], "writers": ["~Philip_Bachman1"], "content": {"title": "review response", "comment": "Thanks for the helpful suggestions. We've added some extra active learning baselines in the MovieLens setting (see updated Fig. 2(c)). We add a Gaussian Process baseline, which selects the next movie to label in proportion to the variance of the predictive posterior distribution over its rating, and an Entropy Sampling baseline, which trains a classifier on the ratings and selects movies in proportion to the prediction entropy. The base classifier for Entropy Sampling was our end-to-end model, with the selection module swapped for the ES heuristic. These baselines implement the standard \"uncertainty sampling\" heuristic for two different prediction models.\n\nNote that the movie embeddings used by our model and all baselines were pretrained using a standard matrix factorization approach, so our baselines do in fact \"learn the representations offline using standard supervised learning and apply an existing active learning algorithm at test time\". We forgot to mention this point in earlier revisions, but it's included now.\n\nIt's true that our MovieLens task is not totally realistic. However, we found that this form of proxy task is common in the active learning and metalearning literature. Any approach to dealing with missing data will imply its own particular assumptions, and we've opted for the simplest path. Note that biases from our restriction to movies with known ratings will affect both our model and the baselines.\n\nYour intuition about the biLSTM is correct. Reducing constraints imposed by our modeling assumptions, to extend our model to more realistic settings, would make an ideal topic for future work."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368627924, "tcdate": 1487368627924, "id": "ICLR.cc/2017/workshop/-/paper161/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "reply": {"forum": "rJj2ZxHtl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368627924}}}, {"tddate": null, "tmdate": 1489444143422, "tcdate": 1489444143422, "number": 2, "id": "BJDET5Esx", "invitation": "ICLR.cc/2017/workshop/-/paper161/official/review", "forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "signatures": ["ICLR.cc/2017/workshop/paper161/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper161/AnonReviewer2"], "content": {"title": "review", "rating": "6: Marginally above acceptance threshold", "review": "The paper presents an architecture to learn an active learning procedure that can be applied to different tasks of the same domain. An example practical usage is preference elicitation for recommendation, in which one wants to learn the series of questions to ask to users to efficiently collect ratings for recommendation. The algorithm is based on the idea that a \"question\" is a rating/label of an item in a pre-specified support set. The support set depends on the task at hand. The overall algorithm is trained using policy gradient, and some experiments on Omniglot and MovieLens show the algorithm performs better than a few baselines.\n\nThe idea makes sense and the problem is interesting since there is no clear solution to the \"cold-start\" problem in the literature. The work is still fairly preliminary (for instance, a simple baseline would be to learn the representations offline using standard supervised learning and apply an existing active learning algorithm at test time), but it may be sufficient for acceptance to the workshop.\n\nremarks:\n- It seems that the MovieLens experiments do not correspond to a realistic scenario and I am not sure of the conclusion of the experiments. The support set in these experiments contains only movies that were rated by the user (without the ratings). It may seem to make sense in lab experiments because we cannot ask the user to rate additional movies. In practice however,  knowing what kind of movies the user rates is already informative of the user interests, even without the ratings (see e.g., Marlin et al. \"Collaborative Prediction and Ranking with Non-Random Missing Data\": people tend to rate items they like). Thus, the model in the experiments has access to more information that what would be available in practice. A more realistic evaluation would be to take the entire set of movies as support set, but to ignore the query if it is not a movie that the user rated. \n\n- Related question: what is the bi-LSTM useful for in the encoder of the support set? I suppose this is used to encode individual items in the context of the whole support set. But once again, in the MovieLens/cold-start recommendation setting, I am not sure that it can really be used in practice.\n\n- In Fig. 2 (c), it seems that much of the improvement compared to the baselines comes at the first query. Do the authors have an idea of the rule found by the model to make the first selection? ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489444144132, "id": "ICLR.cc/2017/workshop/-/paper161/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1", "ICLR.cc/2017/workshop/paper161/AnonReviewer2"], "reply": {"forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489444144132}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489370189471, "tcdate": 1489204536258, "number": 2, "id": "SJgHHxZoe", "invitation": "ICLR.cc/2017/workshop/-/paper161/public/comment", "forum": "rJj2ZxHtl", "replyto": "SkIyJsesx", "signatures": ["~Philip_Bachman1"], "readers": ["everyone"], "writers": ["~Philip_Bachman1"], "content": {"title": "a couple more updates", "comment": "Thanks for taking the time to read through our revisions and provide more feedback. Your understanding of our task/test setup for the MovieLens experiments is correct. In response to your comments regarding \"cold start\", we've updated our terminology to refer to the \"bootstrapping\" problem for recommendation systems (see, e.g. [1]). During internal discussions, we've used \"cold start\" to refer generally to both zero-shot and (very) few-shot settings (some prior work uses this sense [2]). The \"bootstrapping\" terminology is a more precise fit for our current work, and should help avoid confusion.\n\nIn regards to state-of-the-art results for Omniglot, we're unaware of existing published results for training on all available characters in a class. It's unclear whether you're most interested in results for discrimination among all character classes, or specifically for the 20-way k-shot setting (with k set to the max permitted by the data). The \"all-way\" discrimination problem should be quite challenging, but that's speculation on our part. More concretely, we're running tests in the 20-way and 40-way settings, using 5-shot and 10-shot learning. Here, the 20-way problem starts hitting diminishing returns. At similar points in training, performance differs only slightly between the 5 and 10-shot setting, despite doubling the labeled support set.\n\nResults for a class-balanced MN are as follows:\n- 20-way, 5-shot MN  : 98.4\n- 20-way, 10-shot MN : 98.6\n- 40-way, 5-shot MN  : 96.7\n- 40-way, 10-shot MN : 97.2\nFor comparison, our model reaches 96.2 in the 2.5-shot setting (i.e. 50 label queries). We'll train our model for >50 label queries, and include these results for comparison (in a future update, as tests will take a while to run).\n\nNote that (i) our modified MN slightly outperforms the original results from Vinyals et al. (e.g. 94.3 vs 93.8 in the 20-way, 1-shot setting), and (ii) the recent MetaNetwork model in [3] beats the above results in the 20-way, 1-shot setting (at 97.0). Perhaps adapting our approach to work with the MetaNetwork architecture could improve our results.\n\nIn future work, we plan to scale our method to larger support sets, more classes, and more label queries. We also plan to further investigate the potential of imitation learning from classic active learning algorithms (for a sort of \"algorithm distillation\"), and to investigate a broader set of real-world application scenarios. The algorithm distillation perspective is particularly interesting to us, as it represents an extension of the notion of \"learning algorithms by example\" to settings in which existing hand-coded algorithms are often suboptimal, and non-trivial to design.\n\n[1] http://dl.acm.org/citation.cfm?id=1871734\n[2] http://dl.acm.org/citation.cfm?id=2433451\n[3] http://arxiv.org/abs/1703.00837"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368627924, "tcdate": 1487368627924, "id": "ICLR.cc/2017/workshop/-/paper161/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "reply": {"forum": "rJj2ZxHtl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368627924}}}, {"tddate": null, "tmdate": 1489182429732, "tcdate": 1489182429732, "number": 1, "id": "SkIyJsesx", "invitation": "ICLR.cc/2017/workshop/-/paper161/official/comment", "forum": "rJj2ZxHtl", "replyto": "H1_kgO1se", "signatures": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1"], "content": {"title": "improving", "comment": "Thanks for quickly improving the document and answering my concerns.\nThe document is now more clearly explaining the algorithm. It is much\nimproved indeed.\nRegarding the \"cold start\" problem, can you confirm what I think I now\nunderstood of the setting: for each user, you have access to potentially\n50 ratings, but your algorithm selects one of them to ask for a label,\nand with it makes 10 predictions; subsequently it selects a second rating,\nand with both revisit its 10 predictions, etc, and that's what we observe\nin fig 2c. Results are good, but I'm not sure this is the real definition\nof a \"cold start\" since you do require the user to rate (even 1 movie) before\nyou make any recommendation... I see it as a good result of \"low shot\"\nbut not really \"cold start\", no? Also, what are the actual state-of-the-art\non Omniglot if you had access to the full data? I suppose much better, but\nit might be good as a reference point (to be precise: how many \"requests\"\nare needed to reach the full performance?)\nI'm improving my score accordingly (but it can still be improved!)\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368627930, "tcdate": 1487368627930, "id": "ICLR.cc/2017/workshop/-/paper161/official/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "reply": {"forum": "rJj2ZxHtl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/workshop/paper161/reviewers", "ICLR.cc/2017/workshop/paper161/areachairs"], "cdate": 1487368627930}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489182341371, "tcdate": 1488991944022, "number": 1, "id": "SJeCU269l", "invitation": "ICLR.cc/2017/workshop/-/paper161/official/review", "forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "signatures": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1"], "content": {"title": "not enough details?", "rating": "6: Marginally above acceptance threshold", "review": "The topic of this paper is to present a novel active learning mechanism\nbased on reinforcement learning and one-shot learning, where active learning\nis seen as a sequential decision process of selecting one example at a time\nto be labeled and update the model accordingly to better select the next\nexample.\n\nI did not quite understand the motivation example of the cold start problem\nin recommendation tasks: it's only \"cold\" for the first movie, not afterward,\nso how does it differ from normal recommendation approaches?\n\nMore importantly, I did not quite understand the precise proposed model:\nthe figure helped but was not enough, and the text itself said \"a detailed\ndescription... is beyond the scope of this extended abstract\". So the only\nthing I got was the loss function and a very rough idea of the overall process.\nHow does it differ from other active learning approaches for instance?\n\nFinally, experiments look good but are not compared to any other active\nlearning approaches (apart from random selection which is rather naive).\n\nI understand this is a workshop submission and it's only 3 pages but if\nI don't understand the main idea and the results, it's hard for me to give\na good score.\n\n*improving score after revision.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489444144132, "id": "ICLR.cc/2017/workshop/-/paper161/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/AnonReviewer1", "ICLR.cc/2017/workshop/paper161/AnonReviewer2"], "reply": {"forum": "rJj2ZxHtl", "replyto": "rJj2ZxHtl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper161/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489444144132}}}, {"tddate": null, "tmdate": 1489104864449, "tcdate": 1489104864449, "number": 1, "id": "H1_kgO1se", "invitation": "ICLR.cc/2017/workshop/-/paper161/public/comment", "forum": "rJj2ZxHtl", "replyto": "SJeCU269l", "signatures": ["~Philip_Bachman1"], "readers": ["everyone"], "writers": ["~Philip_Bachman1"], "content": {"title": "response to review", "comment": "Thanks for the feedback. We've uploaded a re-written draft that hopefully clarifies our motivations and the structure of our model. We agree that these were unclear in our initial submission. We'd appreciate if you read through our changes and provide additional feedback.\n\nMost notably, we supplement Figure 1 with an algorithmic description of our model and we more clearly distinguish our model from existing active learning methods. Briefly, in contrast to existing methods, our model learns its data representation, strategy for selecting items to label, and prediction function jointly, end-to-end. Prior methods largely rely on hand-crafted selection strategies, and scaling them to high-dimensional data remains a significant problem [1] that has previously been addressed with kernel or graph-based approaches rather than end-to-end learning [2, 3].\n\nWith respect to baselines, in the MovieLens setting we compare to a Popular-Entropy policy that has been shown to work well in the cold-start recommendation literature, as well as a Min-Max-Cosine policy of our own design. While the Min-Max-Cosine policy performs well on Omniglot (we provide additional Omniglot results in a full write-up of this work), it performs poorly on MovieLens. This suggests there may be some value in learning task-adapted active learning models end-to-end.\n\n[1] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. \"Deep Bayesian Active Learning with Image Data,\" arXiv, 2017.\n[2] Alex Holub, Pietro Perona, and Michael C Burl. \"Entropy based active learning for object recognition,\" In Computer Vision and Pattern Recognition Workshops, 2008.\n[3] Ajay J Joshi, Fatih Porikli, and Nikolaos Papanikolopoulos. \"Multi-class active learning for image classification,\" In Computer Vision and Pattern Recognition, 2009."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algorithms for Active Learning", "abstract": "We present a model that learns active learning algorithms via metalearning. For each metatask, our model jointly learns: a data representation, an item selection heuristic, and a one-shot classifier. Our model uses the item selection heuristic to construct a labeled support set for the one-shot classifier. Using metatasks based on the Omniglot and MovieLens datasets, we show that our model performs well in synthetic and practical settings.", "pdf": "/pdf/57f0453cda94b18532e9b3350670c8da0cdec576.pdf", "TL;DR": "We present a model and experiments for meta active learning.", "paperhash": "bachman|learning_algorithms_for_active_learning", "keywords": ["Deep learning", "Supervised Learning"], "conflicts": ["maluuba.com", "microsoft.com"], "authors": ["Philip Bachman", "Alessandro Sordoni", "Adam Trischler"], "authorids": ["phil.bachman@maluuba.com", "alessandro.sordoni@maluuba.com", "adam.trischler@maluuba.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368627924, "tcdate": 1487368627924, "id": "ICLR.cc/2017/workshop/-/paper161/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper161/reviewers"], "reply": {"forum": "rJj2ZxHtl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368627924}}}], "count": 9}