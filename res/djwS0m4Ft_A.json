{"notes": [{"id": "djwS0m4Ft_A", "original": "S-wTeuDKil", "number": 1422, "cdate": 1601308158449, "ddate": null, "tcdate": 1601308158449, "tmdate": 1611607627203, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "mnvz-cLz8n", "original": null, "number": 1, "cdate": 1610040377053, "ddate": null, "tcdate": 1610040377053, "tmdate": 1610473969453, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper proposes the use of topological similarity between conditional submanifolds for a given latent dimension as a metric for measuring disentanglement in generative models. To estimate the topological similarity between conditional submanifolds, the authors build upon an earlier work of Relative Living Times (RLT). \n\nR5 and R4 had concerns on the paper, particularly about the lack of enough novelty in the actual technique (R5) and about the lack of convincing experiments (R4). One of the concerns raised by R4 was around the discrepancies between MIG and FactorVAE.\u00a0However as noted by other reviewers (R2 and R5), these discrepancies between different popular metrics are well acknowledged in the literature and authors have responded to this point. R2 and R5 also appreciate that avoiding the rotation issue faced by most of these disentanglement metrics is one of the strengths of the proposed metric.\n\nWhile I tend to agree with R5 that the actual technique is inspired from the earlier work on \"Geometry Score\", I also think the application to measuring disentanglement in generative models is a novel contribution in itself, especially because current metrics have issues as pointed out by other reviewers -- the paper provides a fresh conditional sub-manifold perspective on disentanglement and a theoretically sound metric for measuring disentanglement. \n\nConsidering this novel perspective and a resulting theoretically sound metric for measuring disentanglement that addresses some of the issues with current metrics, I recommend accepting the paper. \n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040377040, "tmdate": 1610473969436, "id": "ICLR.cc/2021/Conference/Paper1422/-/Decision"}}}, {"id": "B2TxuNdoqbq", "original": null, "number": 3, "cdate": 1603905486483, "ddate": null, "tcdate": 1603905486483, "tmdate": 1606747104630, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review", "content": {"title": "Official Blind Review #2", "review": "This paper proposes a new metric to quantify disentanglement by leveraging ideas from manifold topology, more precisely the homology of conditional submanifolds. It has a strong theoretical grounding (clearly better than existing metrics) and results appear to be promising.\n\nHowever it is at times quite hard to follow, and I am not entirely confident that I fully understood how the Wasserstein RLTs were estimated in practice. I\u2019d still recommend publication, given the novelty and importance of a theoretical sound metric for disentanglement.\n\nComments/questions:\n1. The Introduction, Background and Manifold interpretation sections do a good job of introducing the subject, covering the literature and providing enough background about differential geometry, but I think a clear algorithmic demonstration of steps (d) and (e) of Figure 2 is lacking. \n      1. How exactly do you estimate the Wassertein RLT and compute the matrix M?\n      2. Writing the exact equations used, e.g. in the Appendix, would be helpful. Overall I found the main text to rely on explanations a bit more than would be necessary, where some math would be clearer (having the code will be most helpful however)\n      3. The actual disentanglement metrics $\\mu$ and $\\mu_{sup}$ might deserve a \\begin{equation} for clarity.\n      4. You never explicitly say if \u201chigh $\\mu$ => high disentanglement\u201d, which I think is how one should interpret Table 1 given the main text?\n      \n2. Providing a bit more explanations about how to interpret the RLT histograms would be valuable. I imagine that if the histograms vary as a function of their conditioning, this indicates entanglement?\n      \n3. Figure 7 was interesting, but the specific mention of a mismatch in how the classifier method (i.e. Disentanglement (Kim & Mnih) I assume?) ranks $\\beta$-TCVA and FactorVAE differently was hard to follow (i.e. these do not appear that close in your $\\mu_{sup}$ figure?)\n      \n4. Do the topological similarity matrices in Figure 5 provide interesting information about which factors are grouped together?\n      1. Could you add labels on the axes and discuss what each cluster represents in a few selected models/datasets?\n      \n5. How does the method relate to what was done in GEOMANCER [1]? They also leverage differential geometry and holonomy (but as a learning signal for representation, not as a metric obviously), so discussing it might be valuable?\n\n\n[1] https://arxiv.org/abs/2006.12982", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538119019, "tmdate": 1606915766032, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1422/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review"}}}, {"id": "E94fJgYrPZi", "original": null, "number": 28, "cdate": 1606279267471, "ddate": null, "tcdate": 1606279267471, "tmdate": 1606279267471, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "RbsZbVDXYX5", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response to update: conciseness and algorithmic details", "comment": "Thank you sincerely for your thoroughness in reviewing our revision and for supporting the theoretical basis of our work \u2014 we believe your suggestions have strengthened this paper and agree that the application of W. RLTs to measuring disentanglement is a key contribution. To that end we have modified the main text to better convey to the reader how to understand and apply our metrics. After making the paper a bit more concise by removing some repeated details, we have also moved a key algorithm for computing our metric to the main body (due to space constraints we were unable to shift all the algorithms). In the Experiments section we have added procedural information on taking a dataset and generative model of interest and computing our metrics using the appropriate algorithms, as well as relevant experimental parameters. We believe that these changes give the reader a more complete view of our application of TDA to disentanglement."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "RbsZbVDXYX5", "original": null, "number": 5, "cdate": 1604672158108, "ddate": null, "tcdate": 1604672158108, "tmdate": 1606250005349, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review", "content": {"title": "An exciting demonstration of topology-based assessments of generative models", "review": "# Synopsis of the paper\n\nThis paper presents a new model for assessing to what extent a deep\ngenerative model is disentangled. In contrast to existing methods, this\npaper proposes an approach founded on topological considerations: by\nassessing the topological dissimilarity of submanifolds of a given model,\nwhich are conditioned on an individual factor. The overarching idea is\nthat a fully-disentangled model should exhibit high topological\ndissimilarity for *different* factors, while exhibiting low topological\ndissimilarity for the *same* factors (but with different values for said\nfactors).\n\nThese topological dissimilarity assessments are achieved by employing\npersistent homology, a method from topological data analysis that\ngeneralises ordinary simplicial homology (i.e. 'counting\nhigh-dimensional holes') to a multi-scale setting (in which point clouds\nare being assessed). Previous work for GAN comparison, viz. the\n'geometry score' is extended by a new internal metric, the Wasserstein\ndistance.\n\nA set of experiments demonstrates the utility of the proposed approach,\nvalidating previous knowledge.\n\n# Summary of the review\n\nThis paper is tackling a highly relevant topic (disentanglement\nanalysis) and provides a novel, fresh perspective that is mathematically\nwell justified. The paper is chock full of excellent ideas that make me\nexcited about their potential; I am sure that this will be shine a light\non the potential of topology-driven methods.\n\nHowever, while the paper is well written for the most part, I cannot\nfully endorse it for publication yet because of two reasons:\n\n1. The paper is missing crucial details about its comparison method.\n   While I know the existing work to piece everything together, I am\n   not sure the method as such is reproducible at the moment.\n\n   I am agreeing with most of the claims in the paper, but I would be\n   hard-pressed to implement exactly the same method in the same\n   fashion, because not all the details are there.\n\n2. While most of the paper flows very well, in an almost conversational\n   style that I very much appreciate, there are also several places at\n   which concepts are not explained correctly or with sufficient\n   precision. There are also some issues with the terminology that make\n   it harder to fully understand what is going on.\n\nIf these two points were to be rectified in a revision of the paper,\nit would definitely strengthen the message of this paper!\n\nPlease see below for detailed comments.\n\n# Detailed comments\n\n- The introduction is really 'on point' and makes an excellent case for\n  requiring more foundational approaches\n\n- The way 'topology' is introduced in the introduction is very\n  imprecise; I find the discussion of 'high-density' and 'low-density'\n  to be problematic here. Algebraic topology, which is where persistent\n  homology originated from, has no notion of density; all considerations\n  of 'holes' are based on purely algebraic arguments. While it is true\n  that you can incorporate density information into persistent homology,\n  this discussion is slightly misleading.\n\n  I would point out rather that holes are typically considered to be the\n  boundaries of these low-density regions (if the 'density argument' is\n  left in there).\n\n- Some of the terms are overloaded and used multiple times: 'latent\n  dimension' is used equivalently to 'latent factor', it seems. I would\n  strongly suggest to use a unified terminology.\n\n- The term 'homeomorphic dimensions' is vague. I also have to point out\n  that the method used in this paper is only *invariant* under\n  homeomorphism! More precisely, two topological objects can have the\n  same homology (or persistent homology, or barcode, etc.) even though\n  they are **not** homeomorphic. This is a crucial detail that is not\n  handled correctly in the paper at present; for example, Figure\n  5 claims that 'homeomorphic groups' are shown, but the approach cannot\n  detect this. If anything, the case should be made for depicting that\n  these groups are 'likely' homeomorphic. Alternatively, one could write\n  that the proposed approach assesses the *topological similarity* of\n  models.\n\n- Often, the term 'topology' is also used as an equivocation.\n  Unfortunately, the term is overloaded in mathematics as well: a space\n  can *have* a topology (i.e. systems of open sets etc.), but I have the\n  impression that the paper often means to say 'shape' or 'topological\n  features' (connected components, cycles, etc.) rather than 'topology'.\n\n- The explanation of a manifold could be improved; why not mention the\n  definition in terms of 'locally looks like some $\\mathbb{R}^d$'? The\n  discussion of 'open discs' might leave some readers baffled.\n\n- I disagree with the sentence 'Under the manifold hypothesis, the latent\n  space of a deep generative model has an extremely dense underlying\n  manifold with few, if any, holes, [...]'. Holes characterise the shape\n  of a manifold; the manifold hypothesis only posits the hypothesis that\n  data originate from a manifold. It does not say anything about the\n  *shape* of the manifold itself, and I do not agree with the notion\n  that having no holes is somehow 'better'.\n\n  A generative model that 'learns' that all samples can be arranged\n  along a cycle in some latent space can be very appropriate depending\n  on the data set.\n\n  (Moreover, Figure 2 in some sense tells the opposite story of this\n  sentence.)\n\n- The definition/introduction of (persistent homology) at the end of\n  Section 2 could be improved: the Vietoris--Rips complex goes back to\n  a 1927 paper by L. Vietoris (https://link.springer.com/article/10.1007/BF01447877);\n  an excellent introduction to modern topological concepts is provided\n  in the book 'Computational Topology: An Introduction' by Edelsbrunner\n  and Harer.\n\n  I also disagree with homology 'approximating the topology'. Homology\n  is *one* specific invariant in algebraic topology. In this sense, it\n  does not approximate anything but describes a data set in terms of\n  its topological features.\n\n- The term 'symplectic vertex' is not correct here, as far as\n  I understand. Everything is discussed in terms of simplicial\n  complexes; I do not see the connection to symplectic topology here. \n\n- The explanation of the Vietoris--Rips complex could be improved.\n  I feel that the explanation in terms of creating edges based on the\n  proximity criterion will leave most readers baffled. I would suggest\n  adding a brief explanation/illustration about this, maybe using Figure\n  2d.\n\n- What is meant by having a manifold 'assume topology $\\tau$'? Does this\n  refer to the manifold expressing a certain a set of barcodes?\n\n- In Figure 3, I would rather write '[...] the submanifolds conditions on\n  a specific rotation [...]'. Upon first reading the figure,\n  I misunderstood its central point, namely that *if* the rotation is\n  fixed, so that only the scale varies, the resulting submanifold will\n  not have any holes, as the variation in scale provides a simple 1D\n  structure.\n\n- I would not say that submanifolds have different 'topologies' than\n  their super-manifold; rather they might/will have different homology\n  maybe or 'shape'?\n\n- While I fully agree with the thrust of the method, I would need more\n  details on p. 4. How is the partitioning of the manifold achieved in\n  practice? How are the factors chosen? How are their respective values\n  chosen? Is it possible to provide more examples here?\n\n- When discussing conditional submanifold topology, consider mentioning\n  how these manifolds are being obtained in practice, maybe by providing\n  more examples.\n\n- I do not understand the main thrust of the 'Topological asymmetry'\n  section. Is the main argument that manifolds conditioned on the same\n  factor should have the same shape and, moreover, that manifolds coming\n  from the same factor should be more similar to one another than\n  manifolds coming from different factors?\n\n- What does it mean that factors are 'not homeomorphic' in Figure 4? Is\n  the ground-truth topology known?\n\n- The statement '...that best separates similar and dissimilar\n  topologies...' should again be rephrased and made more precise, for\n  example by adding '...topological features, as measured using\n  persistent homology...'.\n\n- In the 'Metric' section, I would caution strongly against this term.\n  The RLT/Wasserstein calculations might result in a metric in the\n  mathematical sense (for sure, the Wasserstein distance constitutes\n  a metric on the space of barcodes, as the paper mentions), but I am\n  not sure whether the *score* calculated in this section constitutes\n  a metric. If anything, this would have to be proven.\n\n- The 'Metric' section is also hard to read because of differences in\n  terminology. Why is $\\xi$ used to represent an index, whereas other\n  Greek letters are used for functions? What is $\\delta$? Is it the\n  proposed measure of disentanglement?\n\n- After the 'Metric' section, I am missing a concluding section, that\n  summarises how the method works in practice. The following questions\n  need to be answered:\n\n  1. How are topological features computed (i.e., which point cloud is\n     being used and which filtration)?\n\n  2. How is the Vietoris--Rips complex computed in practice? How is its\n     scale parameter $\\epsilon$ chosen?\n\n  3. What is the dimensionality used to compute topological features,\n     i.e. are high-dimensional features being used at all?\n\n\n- '...to those of the reals.': what does this mean?\n\n- It seems that $\\tau$ is not used consistently; is $\\rho$ meant in\n  Figure 6?\n\nAll in all, this paper makes me very excited about the potential of\ntopology-based methods, and I envision that, with some changes, this\nwill be a strong publication in the future!\n\n# Style & clarity\n\nThe paper is well-written; here are some additional suggestions for\nfurther improving its clarity: \n\n- 'generated dSprites' --> 'generated from the dSprites data set'?\n\n- 'by composition' --> 'by the composition'\n\n- The term 'group' is unfortunately somewhat overloaded as well; is\n  'factor' more appropriate in some places? Or is the paper actually\n  talking about manifold groups?\n\n- I would strongly suggest to check whether 'persistent homology' might\n  not be ore appropriate in many places instead of 'homology'. The\n  latter should be reserved to the setting of *one* simplicial complex,\n  but the main argument of the paper is that one has to adopt\n  a multi-scale description of the data set. \n\n# Update after initial revision\n\nI have re-read the revised version multiple times now, and I thank the authors for the amount of work they put into their revision. I am raising my score for the next discussion round. That being said, I want to point out why I cannot fully endorse this paper yet. First, from the point of topological data analysis, the central algorithm is a comparatively small extension of the Geometry Score paper. I agree that this is a superb idea, yet the main contribution for me lies in the application of that technique to disentanglement\u2014and for this to be fully understandable, some more work is needed. For example, putting the central algorithmic details into the appendix will make the adoption of the method that much harder. \n\nMoreover, while I appreciate the overall story and description of the method, I do not think that readers will understand how this disentanglement is actually _achieved_ by means of the proposed TDA approach. I would therefore prefer to see a more 'technical' or 'algorithmic' description of the contributions in the main paper, in particular since I think that the ideas of conditional submanifold topology require more attention.\n\nMy expertise is more the topology and less so the application of disentanglement; nevertheless, this paper strikes me as highly ambitious with a lot of potential, yet somewhat unfinished in its present form. I do believe that it has the potential to be extremely impactful with some additional modifications (concerning conciseness, but also experimental details).\n\nI fully realise that this is not yet the desired outcome for the authors; I shall endeavour to discuss this further with my fellow reviewers to see that we can reach a consensus!", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538119019, "tmdate": 1606915766032, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1422/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review"}}}, {"id": "kX6lU2VI_Ix", "original": null, "number": 2, "cdate": 1603854693394, "ddate": null, "tcdate": 1603854693394, "tmdate": 1606238014882, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review", "content": {"title": "Disentanglement metric measuring intrinsic properties of a generative model with respect to its factors of variation. ", "review": "The paper presents a disentanglement metric to measure the intrinsic properties of a generative model with respect to the factor of variation in the dataset. Toward this, the paper first assumes disentangled factors reside in different manifolds. These different manifolds are the sub-manifolds of some manifold M for a given disentangled generative model. The paper considers the fact that in an entangled model the sub-manifolds are not homeomorphic and thus similarity across submanifolds can be measured to evaluate a model\u2019s disentanglement. As such, disentanglement is related to the topological similarity.  For measuring topological similarity, the paper then introduces Wasserstein Relative Living Times. The proposed metric is used to evaluate standard disentanglement methods and datasets demonstrating the importance. \n\nPros:\n- The paper is well written and the proposed metric is well articulated.\n- The manifold interpretation of disentanglement (section 3) is clear and could be considered a stand-alone contribution to the disentanglement community. \n- The experiments covered depth in terms of dataset selection and the number of models considered for the evaluation of the metric. \n\nFew questions/suggestions:\n- Can the authors briefly describe why W. Distance defines a valid metric on barcode space and others don\u2019t, or point out to relevant literature in section 3.1?\n- In Li et. al., 2019, MIG-sup was proposed to remedy the weakness of the MIG metric. For the unsupervised portion, since MIG was considered a comparision, can authors also compare their method with MIG-sup? Or at least discuss it along with MIG? \n\nLi, Z., Murkute, J. V., Gyawali, P. K., & Wang, L. (2019, September). PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS. In International Conference on Learning Representations.\n\n(Update): The score has been updated after the rebuttal phase.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538119019, "tmdate": 1606915766032, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1422/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review"}}}, {"id": "jdtiw2R3DH", "original": null, "number": 13, "cdate": 1606027480832, "ddate": null, "tcdate": 1606027480832, "tmdate": 1606027480832, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "whctm6u0fRr", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Thanks and happy to answer more questions", "comment": "Thank you so much. We are more than happy to answer all additional questions. Please let us know if it would be easier for you to see a version with changes highlighted; we can upload that instead for now. In the meantime, hope you find the revised portions satisfactory. Thanks again for the fortifying comments."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "B1bXuCUdAj", "original": null, "number": 12, "cdate": 1606000205491, "ddate": null, "tcdate": 1606000205491, "tmdate": 1606000205491, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "qswCk7X5H6R", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Thanks for the update.", "comment": "Thanks for your response and the extended experiments on disentanglement metrics. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "qswCk7X5H6R", "original": null, "number": 6, "cdate": 1605485739363, "ddate": null, "tcdate": 1605485739363, "tmdate": 1605757159010, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "kX6lU2VI_Ix", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for your enthusiastic response on the clarity of the manifold interpretation of disentanglement, depth of experiments, and clear writing. \n\nRegarding W. distance defining a valid metric on barcode space, thanks for pointing that out. We added the appropriate citation to Carlsson (2019) and moved the citation closer to the phrase in another area, both occurring in Section 3.1. Intuitively, W. distance can be seen as defining an edit distance in terms of a penalty function in barcode space, and thus satisfies the triangle inequality. A precise definition can be found in Section 5.1 of \u201cPersistent Homology and Applied Homotopy Theory\u201d (Carlsson, 2019).\n\nRegarding the Li et al., 2019 paper, we have cited it in the main text of our background and related work sections (and an additional mention in the appendix), as it is very pertinent. Following ICLR guidelines that allow small contained studies during the revision period, we have run such a study for MIG-sup VAE, \u03b2-VAE, and \u03b2-TCVAE. We found that for these models, MIG and MIG-sup are highly correlated (r2=0.95) and plot a box-plot over several run in Appendix G. Based on that paper (Li et al., 2019), MIG-sup and MIG correspond, respectively, to the disentanglement concepts of consistency (when one dimension exclusively encodes multiple factors) and restrictiveness (when one factor is exclusively split into multiple dimensions) in Shu et al. 2019, to which we had connected in Appendix A. We included this note about MIG-sup in that section (Update: We performed several runs for a more complete analysis of MIG-sup).\n\nThank you again for your kind response and hope these points help elucidate your questions."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "whctm6u0fRr", "original": null, "number": 8, "cdate": 1605540678470, "ddate": null, "tcdate": 1605540678470, "tmdate": 1605540678470, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "Vor6ii1dV91", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Thanks for the updates", "comment": "Thanks for the detailed response and the care with which you addressed my concerns, I really appreciate it! I will read the updated version in detail and respond with any additional questions I might have."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "ZBNKqIVwWLQ", "original": null, "number": 7, "cdate": 1605485794086, "ddate": null, "tcdate": 1605485794086, "tmdate": 1605485794086, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "iK3mpIDampL", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for helpful comments and notes on the novelty and experimental breadth of the work.\n\nWe provided a deeper analysis on the scores of the models at the end of our Experiments section, just before the conclusion. Specifically, we've stated that different datasets and requirements for evaluating disentanglement may favor an unsupervised variant over a supervised variant, and vice versa. Without known factors or without factors of interest, the unsupervised variant is clearly the more favorable or in some cases the only option. One benefit of using the unsupervised variant even if the factors are known is when multiple combinations of factors are valid to disentangle the data. \n\nFor example, one can imagine disentangling color into RGB \\{red, green, blue\\}, HSL \\{hue, saturation, lightness\\}, or HSV \\{hue, saturation, value\\}. The unsupervised evaluation metric would be satisfied with a model that disentangles into any of these. A supervised evaluation metric, for which the known factors are RGB, however, would not. RGB is a human (supervised) prior that dictates not only whether but how the factors disentangle. In effect, this leads to differences in rankings across the two variants. Nevertheless, in the case of a disentanglement dataset, such as dSprites, where the factors were created first and the  data was created from those factors, we would expect that the known factors are reasonable ones, if not the best ones according to human judgment, to disentangle. That is, while there may be alternatives, this is a good, and quite possibly the most intuitive, human prior. \n\nHowever, datasets in the wild, which CelebA veers closer to, differs in this respect. We do not know the complete set of factors of variation for CelebA's human faces, and the attributes provided in the metadata are a subset at best. In this case, if one wishes to measure disentanglement generally, we suggest using unsupervised approaches to assess the disentanglement of a learned model. If one wishes to measure the disentanglement of specific factors, e.g. sunglasses and hair color, then the supervised variant would be more appropriate. Nevertheless, different variants suit different needs, and across datasets and variants, we may expect different models to emerge as superior in their ability to disentangle.\n\n\nRegarding the \u201cdead\u201d units, as discussed in Eastwood & Williams 2018, these are clustered under our method based on topological similarity, and therefore not penalized in our evaluation metric as we use the trace on the clusters in the computation (and not, for example, their mean). Arguably, however, the resulting representation would be more compact (\"better\" in some sense, though not necessarily disentangled), if there are no or fewer dead units. \n\n\nAgreed on the future work direction and a good extension, as the StyleGAN line of work has similarly done so with their PPL evaluation metric, incorporating it into the training of StyleGAN2, a subsequent iteration of their work. \n\nThanks again for your helpful comments. We hope these points help elucidate your questions.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "NBji3fWPO1t", "original": null, "number": 5, "cdate": 1605485715151, "ddate": null, "tcdate": 1605485715151, "tmdate": 1605485715151, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "B2TxuNdoqbq", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for your helpful comments and suggestions that have helped with clarifying the procedural steps and the figures. This is important to making our work easier to digest in visuals and algorithms separate from the main text, and we appreciate these suggestions.\n\nFor clarifying the precise steps of computing W. RLTs and the matrix M, we add the central algorithms to Appendix I and refer to them in the main text. Specifically, we break down the full procedure into three simpler algorithms: W. RLT procedure on the generated data manifold, W. RLT procedure on the real data manifold, and evaluation metric \u03bc calculation. We have linked to the codebase in our abstract.\n\nWe have also included additional explanations in the figure captions to help with their clarity. Specifically, we have revised these 3 requested items: (a) RLT diagrams can be interpreted as vectorizations of the persistent homology of, in this case, a conditional submanifold, providing information about the homology groups (k-dimensional holes and their relative lifetime as proximity, or the radius of the ball around each point, varies) as estimated by persistent homology. We add this clarification in the text and captions. (b) we clarify that Figure 7 is on the dSprites dataset and provide further discussion of observed differences at the end of the experiments section. The mismatch that we believe you refer to focuses on the results in Table 1, less so on Figure 7, so we switch their ordering to help with reading that section). (c) We note that the largest clusters in dSprites are consistently orientation, which is consistent with the real disentangling factors, as they have the most values, and shape which has the least values generally corresponds to the smallest cluster. However, since Figure 5 shows the unsupervised variant and these models do not perfectly disentangle, one cannot assign a corresponding factor without a valid correspondence being evaluated.\n\nRegarding the related work on Geomancer, we note that holonomy and homology are separate concepts, yet certainly related. While homology is a topological invariant of the manifold, holonomy used in the Geomancer paper hinges on differential geometry methods and could be an interesting subject for future work, given the well known connections, such as the Gauss-Bonnet theorem,  between differential geometric quantities such as curvature and homological invariants. We include this in our extended background section, as it is a relevant piece of work at this intersection to reference and to bolster.\n\nFinally, stylistically, we add \\begin{equation} to the evaluation metric equations. We also explicitly highlight that a higher \u03bc entails greater disentanglement in the Table 1 caption and in the main text. \n\nThank you again for your comments that helped clarify aspects of the paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "zdUj5qjAPRG", "original": null, "number": 4, "cdate": 1605485679691, "ddate": null, "tcdate": 1605485679691, "tmdate": 1605485679691, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "M-J_zgIWtg", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for your comments and note on a general simple evaluation metric \u2014 this is exactly our aim to contribute this to the literature.\n\nRegarding your question on Fig. 3 of the entangled situation: an entangled model would qualitatively embed the hearts in a spiral around the conical shell; this spiral would correspond to hearts that both change in size and in rotation. For this to be clear to future readers, we have included a visual example in that figure. \n\nThe hyperparameters were the same across datasets, not tuned separately, and specifically default from their respective papers (Appendix G). Such discrepancies can be seen across datasets (one architecture is often not globally best), which was our motivation to ensure that experiments were not conducted on a single dataset, but multiple, spanning toy disentanglement datasets like dSprites and more \"in-the-wild\" datasets like CelebA. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "Vor6ii1dV91", "original": null, "number": 3, "cdate": 1605294730051, "ddate": null, "tcdate": 1605294730051, "tmdate": 1605294730051, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "YL99kCdBjg4", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response continued: revisions for clarifying procedures and tightening language ", "comment": "2/2 (Continued from previous comment)\n\n* Improving the definition of a manifold to not only discuss \"open discs\" more formally, but also that it \"locally looks like some R^k\"\n* Clarifying discussion of the manifold hypothesis, because the current wording seems confusing, suggesting having no holes (a certain shape) is better, which is not the intention of the sentence.\n* Rewording our explanation of proximity and persistent homology as: Proximity is defined using a dissimilarity measure between points. It is used to build a simplicial complex in which a collection of points spans a simplex if all points have proximity measure less than some threshold. Varying the threshold gives persistent homology. \n* Referring to Figure 2(d) when explaining the witness complex to improve this explanation. Rewording simplicial complexes \"approximating the topology\" to \"approximating the homology\" and removing the reference to a 'symplectic vertex'\n* Removing \"assumes topology \u03c4\" and clarifying that the model's learned manifold approximates the topology of the true data manifold (and superlevel sets of density of the true data manifold) through the learning process. \n* Figure 3 has been updated to highlight the conditioning, and Figure 4 has been updated to clarify that it shows conditional submanifolds which were clustered together in one row and those which were not clustered together in the next row, and Figure 6 has been updated to correspond to our evaluation metric.\n* The phrase \u201cthat best separates similar and dissimilar topologies\u201d has been made more precise, based on your suggestion.\n* Rewording \"metric\" to \"dissimilarity measure\" or \"evaluation metric\", avoiding ambiguity with the meaning of \"metric\" in the mathematical sense of distance or in the broader use of metric in evaluation. \n* Replacing Greek letter \u03be for Roman letter c when referring to number of biclusters, for consistency of Greek and Roman lettering\n* Clarifying that submanifolds may have different homology (not \"topology\") than their supermanifolds\n* Referring to \"persistent homology\" instead of \"homology\" where more appropriate. We mean persistent homology throughout the paper.\n* Clarifying \"reals\" to mean real data, not R^n\n* Incorporated each of your suggestions regarding style and clarity, including rewording \"groups\" as \"clusters\" where appropriate, as we are measuring topological similarity, not making claims on homeomorphic groups, thereby avoiding possible ambiguity with \"homology groups\" here. \n\nThanks, again, for your detailed review in making our work much clearer and from there, impactful in moving work at this intersection forward."}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "YL99kCdBjg4", "original": null, "number": 2, "cdate": 1605294650889, "ddate": null, "tcdate": 1605294650889, "tmdate": 1605294650889, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "RbsZbVDXYX5", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment", "content": {"title": "Author response: revisions for clarifying procedures and tightening language", "comment": "Thank you for your thoughtful and detailed response. We really appreciate the constructive comments therein, as well as the positive praise on the \"novel, fresh perspective that is mathematically well justified\". Incorporating your suggestions has bolstered our work, and we hope the revisions can improve the assessment of our work.\n\nWe've prepared a response, and modified the manuscript, to each of your points. In particular, (1) we provide greater detail and more concrete examples to improve the paper's reproducibility, including certain details from prior work, which we make sure to include in either the main text or Appendix, and (2) we tighten the language on topology and resolved vocabulary ambiguities, particularly for a reader of topology expecting more mathematical rigor.\n\nWhen addressing mathematical rigor and discussing topology in this context, we acknowledge that we walk a fine line between perfect mathematical rigor on the one hand and concreteness for a more general audience on the other. We hope that we have found the right level for the machine learning community.\n\nWe have included these revisions in the updated manuscript.\n\nRegarding (1), we provide the following details on the approach in section 3, the Metric section 3.2, and Appendix G. We also confirm that your interpretation is correct of the Topological asymmetry section in section 3.\n\n*RLT procedure*\nThe method for computing the relative living times (RLTs) originates from the Geometry Score paper (Khrulkov et al. 2018) and we include the requested details on their method in the Appendix. Specifically, they use the Gudhi library and compute persistence intervals in a dimension by constructing witness complexes. The witness complex is computed for all filtration values at once to compute a persistence diagram, which summarizes the homology for all \u03f5. Topological features are usually not computationally tractable in high dimensions, so we do not use high-dimensional features there \u2014 specifically, we are only using k=1 dimension, per the Geometry Score implementation.\n\n*Conditional submanifold in practice*\nThe factors of a generating dataset such as dSprites, and their values, are provided with the dataset. Features in the dSprites dataset include shape, orientation, x-position, and y-position. An example image (a data point) is a heart rotated 90 degrees in the top right corner. The values of each feature (factor) are provided in this generating dataset and, in this case, discretized. In generating a submanifold, we would hold a factor, such as orientation, constant, while varying the others (sampling different values for the others) to create a subsample that we then use in the RLT procedure. In a non-toy dataset, such as CelebA, where the factors and their values are not known to high accuracy, we can only estimate a possible subset. In this case, we follow prior precedent and use the binary attributes provided in the dataset, such as wearing sunglasses or black hair color. This type of selection of factors and values are common in disentanglement literature; we do not introduce a novel protocol with the factor selection here. \n\nFor a generated manifold, we do not know the factors corresponding to the latent dimensions upfront. As a result, we hold latent dimensions constant and randomly sample values from the latent prior (spherical normal) within a dimension to hold constant while varying the values of others through random sampling. Each set of latent dimension values correspond to a point in the data manifold, which we use the corresponding generative model to generate. These points on the generative model's data manifold are then embedded using an ImageNet-pretrained VGG16 network as a feature extractor (these details are currently in Appendix G). These embeddings produce point clouds from which the persistence barcodes are computed and vectorized using the RLT procedure. \n\nWe clarify these in the text and an added algorithm diagram in the Appendix.\n\nRegarding (2), we unify terminology for the following suggestions and updated the manuscript to reflect this by:\n* Clarifying the use of topology throughout the paper and defining it more precisely. Specifically, we include in the Introduction: We achieve this by using topology, the mathematical discipline which differentiates between shapes based on gross features such as holes, loops, etc., alongside density analysis of samples. The combination of these two ideas are the basis for functional persistence, which is one of the areas of application of persistent homology. \n* Using \"latent dimensions\" throughout for consistency, removing the phrase \u201clatent factor.\u201d \n* Moreover, \u201chomeomorphic dimensions\u201d is replaced with references to \u201chomeomorphic submanifolds conditioned on a factor\u201d and \u201clikely homeomorphic\u201d is used where appropriate.\n\n1/2 (Continued in next comment)"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "djwS0m4Ft_A", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1422/Authors|ICLR.cc/2021/Conference/Paper1422/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923859890, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Comment"}}}, {"id": "iK3mpIDampL", "original": null, "number": 1, "cdate": 1603824929889, "ddate": null, "tcdate": 1603824929889, "tmdate": 1605024449406, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review", "content": {"title": "Novel application of topological similarity to disentangling metrics, but needs more experimental validation", "review": "Summary: Introduces unsupervised disentangling metric that measures homeomorphic similarity between submanifolds conditioned on a given factor, and homeomorphic dissimilarity on submanifolds conditioned on different factors. The paper also includes a supervised variant which can directly assess topological similarity of submanifolds with label-spaces. The paper also introduces a novel variation of RLTs that  employs wasserstein distance instead of euclidean distance. \n\nStrengths:\n* Novel application of topological similarity to unsupervised evaluation of disentangling.\n* Unsupervised and supervised metrics are both in the same units, and can be directly compared.\n* Experimental comparison, using the proposed metric, of many standard disentangling models on challenging datasets.\n\nWeaknesses:\n* The comparison of the proposed metric to mutual information gap and the metric from Kim and Mnih 2018 shown in Figure 7 is not convincing. Not only does the ranking change, but the distributions of scores look wildly different between models (e.g., \\mu has low variance for VAE in both supervised and unsupervised cases, but both MIG and Kim & Minh show relatively high variance for VAE). It is possible that discrepancy is a good thing, and that the proposed model is capturing disentangling even better than the baseline metrics. However, there is not enough experimental validation to know whether this is the case. The paper would be stronger if it had more experimental validation, including a replication of the reported scores from the MIG (Chen et al., 2018) and (Kim and Minh 2018) paper, and deeper analysis explaining the relative differences in scores for models. Without this component, it is difficult to know whether the model comparison results (Table 1) are meaningful.\n* It would be nice to include a discussion of how the proposed metric accounts for \u201cdead\u201d units (e.g., Eastwood & Williams 2018)? These might result in topologically similar submanifolds (since the conditional distributions would be nearly identical) and a worse score for the metric, even though the representation is arguably well-disentangled.\n\nClarity:\n* Typo: Page 6, Line 5: \u201cFigure 9\u201d should be \u201cFigure 4\u201d\n\nOther notes:\n* It would be very interesting to see an experiment where the unsupervised metric is used to choose hyper-parameters of a model which is then evaluated in a supervised way, to demonstrate that the unsupervised metric is a valid substitute for a supervised metric.", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538119019, "tmdate": 1606915766032, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1422/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review"}}}, {"id": "M-J_zgIWtg", "original": null, "number": 4, "cdate": 1604087480764, "ddate": null, "tcdate": 1604087480764, "tmdate": 1605024449249, "tddate": null, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "invitation": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review", "content": {"title": "Interesting looking paper", "review": "Summary\n\nThe paper proposes a novel metric for evaluating disentanglement by taking a manifold-topological perspective on the representations learnt. The key insight is that for a disentangled representation, when we fix a certain factor of variation at different values the topology of the conditional sub-manifolds should be similar. Using this insight the paper proposes a metric for disentangling which does not require annotations of the factors of variation and is more general than previous such tests.\n\nStrengths\n+ Having an approach that is general and easy to compute across datasets and models makes a lot of sense\n\nWeaknesses\n\nIt would be nice to further clarify the intuitions for how disentangling relates to the manifold structures using more examples in the paper for people who are not familiar with the manifold topology literature. For example, in Fig. 3 it would be nice to show qualitatively what an entangled model would do for the rotation scale disentangling situation.\n\nIt seems somewhat surprising that \\beta-VAE_{B} does so much worse than \\beta-VAE on CelebA, were the hyperparameters tuned separately for the CelebA dataset?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper1422/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1422/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating the Disentanglement of Deep Generative Models through Manifold Topology", "authorids": ["~Sharon_Zhou1", "~Eric_Zelikman1", "fredlu@stanford.edu", "~Andrew_Y._Ng1", "~Gunnar_E._Carlsson1", "~Stefano_Ermon1"], "authors": ["Sharon Zhou", "Eric Zelikman", "Fred Lu", "Andrew Y. Ng", "Gunnar E. Carlsson", "Stefano Ermon"], "keywords": ["generative models", "evaluation", "disentanglement"], "abstract": "Learning disentangled representations is regarded as a fundamental task for improving the generalization, robustness, and interpretability of generative models. However, measuring disentanglement has been challenging and inconsistent, often dependent on an ad-hoc external model or specific to a certain dataset. To address this, we present a method for quantifying disentanglement that only uses the generative model, by measuring the topological similarity of conditional submanifolds in the learned representation. This method showcases both unsupervised and supervised variants. To illustrate the effectiveness and applicability of our method, we empirically evaluate several state-of-the-art models across multiple datasets. We find that our method ranks models similarly to existing methods. We make our code publicly available at https://github.com/stanfordmlgroup/disentanglement.", "one-sentence_summary": "Evaluate disentanglement of generative models by measuring manifold topology using persistent homology", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhou|evaluating_the_disentanglement_of_deep_generative_models_through_manifold_topology", "supplementary_material": "/attachment/04ad0b91fb3123b7165418232542083c04cbee13.zip", "pdf": "/pdf/1a87763ff698ed701fa9648dad3eeb0fee6bb67b.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nzhou2021evaluating,\ntitle={Evaluating the Disentanglement of Deep Generative Models through Manifold Topology},\nauthor={Sharon Zhou and Eric Zelikman and Fred Lu and Andrew Y. Ng and Gunnar E. Carlsson and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=djwS0m4Ft_A}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "djwS0m4Ft_A", "replyto": "djwS0m4Ft_A", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1422/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538119019, "tmdate": 1606915766032, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1422/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1422/-/Official_Review"}}}], "count": 17}