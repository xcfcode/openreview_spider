{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1394073180000, "tcdate": 1394073180000, "number": 5, "id": "lyepyotVxkKoF", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "BBxkB2w0I_OjZ", "replyto": "BBxkB2w0I_OjZ", "signatures": ["Ian Goodfellow"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We ran some more experiments to determine the effect of increasing the number of parameters in shallow models. Specifically, we used a model with 3 hidden layers: two convolutional layers followed by a fully connected layer. If we increase the size of the fully connected layer it rapidly starts to overfit. If we increase the size of the convolutional layers, the accuracy increases, but with diminishing marginal utility. We have launched a second round of experiments with even larger convolutional layers. We are hoping to find the point at which they start to overfit so that we can include this result in the final version of the paper. So far we have not been able to match the accuracy of our 11-layer model with this approach."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392802200000, "tcdate": 1392802200000, "number": 4, "id": "cHoRcxbFCpcMx", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "BBxkB2w0I_OjZ", "replyto": "BBxkB2w0I_OjZ", "signatures": ["Ian Goodfellow"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "In order to avoid the ArXiv approval delay, we have posted a revised copy of our paper directly here:\r\nhttps://drive.google.com/file/d/0B64011x02sIkd3RwSDRpTXlKSzQ/edit?usp=sharing\r\n\r\n'Anonymous 88a9', 'Anonymous ac02' and 'Anonymous dee9' have raised concerns\r\nabout the clarity of the description of the architecture and inference process.\r\nWe have updated the paper to add Appendix A, a worked example showing exactly\r\nhow the inference process works step by step. We hope this resolves the ambiguities\r\nin the main text.\r\n\r\n'Anonymous ac02' suggests to use larger shallow networks to have another\r\ndatapoint on the importance of a deep network. This is a great idea and we\r\nhave started experiments with models of varying sizes using 3 hidden layers to see\r\ntheir improvements based on the number of parameters alone. We will post another\r\nupdate when these experiments are complete but didn't manage to finish them during\r\nthe recommended rebuttal period.\r\n\r\n'Anonymous dee9' suggested that we were doing heavy post-processing of the image\r\nbecause we were doing tight crops around the street number. We have five responses\r\nto this criticism:\r\n1) We mistakenly omitted some details about the limitations of our preprocessing\r\nof the larger internal dataset. These details make it clear that the preprocessing\r\nis not especially useful. Specifically, the centroid is not well-known, the scale\r\nis not known at all, and the crop size we use for that dataset is 128x128 compared\r\nto the 54x54 we used on the public SVHN. Our results on this dataset therefore\r\nindicate that the network is able to localize the house number itself as well as localizing the digits\r\nwithin the number. They also demonstrate the network is able to handle wide variations\r\nin the scale of the house number.\r\n2) It is not computationally practical to run a convolutional network on a\r\ncompletely uncropped Street View panorama, so some degree of preprocessing is\r\ninevitable.\r\n3) On the public SVHN, all pre-existing methods make use of more ground truth\r\nlocalization information than our method does. All previous authors who have\r\npublished on this dataset use the version that is tightly cropped per-digit.\r\nWe use the much looser crop that identifies only the region in which the multi-digit\r\nnumber occurs, but we still improve upon the state of the art for single digit\r\nrecognition. This demonstrates that the system is able to localize individual\r\ndigits on this dataset.\r\n4) Other systems for transcription represent the concept of the sequence external\r\nto the neural net, i.e. the sequence parsing is handled by post-processing techniques\r\nsuch as HMM inference, non-maxima suppression, etc. Only our approach trains a neural\r\nnet with an internal concept of a sequence.\r\n5) Our system uses *no post-processing at all* but only pre-processing, while other\r\nsystems use both pre-processing and post-processing.\r\n\r\n\r\n\r\n'Anonymous dee9' suggests that we should have given the accuracy number with and\r\nwithout dropout for our internal dataset to prove that 'we did not need to train\r\nwith dropout'. We agree that this claim is overreaching, we changed the paper to\r\nsay that we were not seeing large overfitting and decided to not use dropout primarily\r\nin order to speed up the training, which is time-consuming for the larger models."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391897280000, "tcdate": 1391897280000, "number": 3, "id": "p9jY1AuSYy9M-", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "BBxkB2w0I_OjZ", "replyto": "BBxkB2w0I_OjZ", "signatures": ["anonymous reviewer dee9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "review": "The authors propose an integrated approach to sequence recognition in the case of limited number of characters (house numbers with 5 characters at most). Avoiding separating localization, segmentation and recognition is novel in this context. This is the right approach and results are good but the model is not well explained (see below).\r\n\r\nPros:\r\n- integrated sequence recognition rather than traditional localization/segmentation/recognition step.\r\n- new record on single digit\r\n- accuracy high enough for real world deployment (although the ability to pay human operators for remaining errors in the 98% regime means that real world deployment is possible even at very low accuracy, depending how much money the company is willing to spend).\r\n\r\nCons:\r\n- 'and has special code for handling much of the mechanics such as proposing candidate object regions' and 'we take a similar approach, but with less post-processing': this is misleading and debatable that there is less post-processing because the authors methods relies on a pre-detection step that gives relatively tight bounding boxes around the number, as indicated here: 'Beyond cropping the image close to the street number'. One could argue that there is as much post-processing in the other cited work once the detection is performed.\r\n- what happens at the top of the network is not clear at all to me. Are they using an HMM or not? Does the 64x64 input image yield a grid of probabilities? then what is the size of that grid? Or is the network directly predicting N outputs, and based on the value of L, uses only the first L values out of N?\r\n- 'a softmax classifier that is attached to intermediate features': digit softmax are located on the intermediate hidden layers? which ones?\r\n- 'On this task, due to the larger amount of training data, we did not need to train with dropout': it would have been nice to see the numbers with and without dropout instead of just relying on this claim."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391827860000, "tcdate": 1391827860000, "number": 2, "id": "6bml6ARnFNWcA", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "BBxkB2w0I_OjZ", "replyto": "BBxkB2w0I_OjZ", "signatures": ["anonymous reviewer ac02"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "review": "The paper presents an application of deep neural networks to the problem of reading multi-digit housenumbers from StreetView images.  The basic architecture is essentially standard (maxout units, ReLu units, convolution, and several dense layers), but is unusually deep (11 layers).  The output of the detector is a softmax predictor for the length of a sequence, as well as softmax predictors for each digit in the sequence.  This simple output encoding is sufficient to achieve a high recall at very high precision that is competitive with human labelers.  The authors conclude that this particular OCR application may regarded as solved at this stage.\r\n\r\nThere is relatively little new in terms of algorithms here, but the results are excellent.  \r\n\r\nThe paper is clearly written, though the prose could be tightened up a bit.  If room can be made, I think a deeper analysis of the method\u2019s success would be useful.  For example, is it possible that the \u201cdeeper\u201d networks are fitting the training set better as a result of more model parameters?  Or is the depth truly the deciding factor?\r\n\r\nMost surprising to me is the fact that there is no explicit need to model the label structure beyond the obvious:  a detector for sequence length and softmax outputs for digit classes, with a small tweak to choose the most likely length of the sequence during test time.  This follows along with recent work on detection systems that suggests sophisticated regressors are able to do something similar for object classes, so I think this otherwise simple component is a useful datapoint for that conversation.\r\n\r\nPros:\r\n\r\nSimple off-the-shelf application with excellent performance;  perhaps high enough to count this task as \u201csolved\u201d.\r\n\r\nA useful reference point for work on predicting structured outputs like character sequences.\r\n\r\nCons:\r\n\r\nEssentially boiler-plate neural network.  A bit more detailed analysis of the result would be useful."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391811000000, "tcdate": 1391811000000, "number": 1, "id": "YBcwB2mgG9d1f", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "BBxkB2w0I_OjZ", "replyto": "BBxkB2w0I_OjZ", "signatures": ["anonymous reviewer 88a9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "review": "This submission describes an approach for digit and sequence recognition that results in improved performance on the StreetView house number dataset using a simple structured output to recognize the entire sequence as an ordered set of detections and a very deep convolutional network (11 layers).  The approach is end-to-end, without requiring multiple networks or a composite of techniques. \r\n\r\nThe approach has very high accuracy and is attractive in its simplicity, although the authors make clear that it could not be extended to, for instance, general text recognition in images.  The relevance for ICLR is high, although the paper has some significant omissions that keep it from being a very strong candidate for acceptance.\r\n\r\nFirst, the method is not clear, in particular the interface between the varia softmax digit classifiers and the output of the convnet. It is unclear whether there is any representation of locality in this interface beyond the assignment of different classifiers for each position.  In the introduction, it is stated that the subtasks of localization, segmentation, and recognition are solved in an integrated way, but section 3 introduces the dataset, which has localized inputs- numbers which fill at least \u2153 of the image. This needs to be clarified.\r\n\r\nSecond, to further the contribution of the paper, additional experiments or analysis could have been performed to understand the features, the architecture, the loss function, or other aspects of the approach. With these missing, the submission is somewhat thin and the contribution lessened.\r\n\r\nSmaller issues: the variables used in the plate model in Fig. 1 need to be defined in the caption and supporting text as well as later when the method is explained, and DistBelief should not be used in the abstract and intro without citation or footnote."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387854900000, "tcdate": 1387854900000, "number": 39, "id": "BBxkB2w0I_OjZ", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "BBxkB2w0I_OjZ", "signatures": ["julianibarz@google.com"], "readers": ["everyone"], "content": {"title": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", "decision": "submitted, no decision", "abstract": "Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localization, segmentation, and recognition steps. In this paper we propose a unified approach that integrates these three steps via the use of a deep convolutional neural-network that operates directly off of the image pixels. This model is configured with 11 hidden layers all with feedforward connections. We employ the DistBelief implementation of deep neural networks to scale our computations over this network. We have evaluated this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluated this approach on an even more challenging dataset generated from Street View imagery containing several 10s of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators and has to date helped us extract close to 100 million street numbers from Street View imagery worldwide.", "pdf": "https://arxiv.org/abs/1312.6082", "paperhash": "ibarz|multidigit_number_recognition_from_street_view_imagery_using_deep_convolutional_neural_networks", "keywords": [], "conflicts": [], "authors": ["Julian Ibarz", "Ian Goodfellow", "Sacha Arnoud", "Vinay Shet", "Yaroslav Bulatov"], "authorids": ["julianibarz@google.com", "goodfellow.ian@gmail.com", "sacha@google.com", "vinayshet@google.com", "yaroslavvb@gmail.com"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 6}