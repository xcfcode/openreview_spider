{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363043100000, "tcdate": 1363043100000, "number": 1, "id": "J5RZOWF9WLSi0", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "OznsOsb6sDFeV", "replyto": "llHR9RITMyCTz", "signatures": ["Christian Osendorfer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Deare954,\r\nthank you for your detailed feedback.\r\n\r\nWe don't argue that the chosen task should replace existing \r\nbenchmarks. Instead, we think that it supplements these, because \r\nit covers aspects of unsupervised feature learning that have been \r\nignored so far. Note that by avoiding any subsequent supervision \r\nwe not only think of supervised fine tuning of the learnt architecture \r\nbut rather no supervised learning on the representations at all \r\n(e.g. like it is still done in [R2]). This is hopefully clearer in \r\nversion 3 of the paper, we removed words like 'refinement' \r\nand 'fine tuning'.\r\n\r\nThank you for pointing out missing references [R1, R2, R3]. We \r\nadded [R2, R4, R5] to the paper in order to avoid the impression \r\nwe are not aware of these approaches (we think that R4 fits better \r\nthan R1 and R5 better than R3). We were, but did not mention \r\nthese approaches because they are (i) relying on a supervised signal \r\nand/or (ii) are concerned with high-level correspondences (we consider\r\nfaces as high-level entities). Current work investigates some of these \r\nmethods, because utilizing the available pairing information should \r\nbe beneficial with respect to a good overall performance. We are not \r\narguing that discriminative methods work worse on this dataset. \r\nHowever, in this paper we are not striving to achieve state-of-the-art \r\nresults: We investigate a new benchmark for unsupervised learning and \r\ntest how good existing unsupervised methods do. We tried to make the \r\nanalysis part in version 3 of the paper more clearer.\r\n\r\nWe don't think that our claims are incorrect: We manage to perform \r\ncomparable to SIFT when the size of the representation is free. It is \r\nnot clear if for standard distance computations a bigger representations \r\n(in particular a sparse one) is actually an advantage. We also manage \r\nto perform better than several well known compact descriptors when we \r\nbinarize the learnt representations.\r\n\r\nWe also don't think that the evaluation is insufficient. The time to \r\nextract the features will be clearly dominated by the SIFT keypoint \r\ndetector, because computing a new representation given a patch is a \r\nsequence of matrix operations. Training times are added to the new\r\nversion of the paper. ROC curves will be in a larger technical \r\nreport that describes in more detail the performance of a bigger \r\nnumber of feature learning algorithms (both supervised and unsupervised)\r\non this dataset.\r\n\r\nThank you for pointing out a missing experiment, training on general \r\nnatural image patches (not extracted around keypoints) and then \r\nevaluating on the dataset. We are trying to incorporate results for \r\nthis experiment in the final version of the paper. It should also be \r\nvery interesting to experiment with the idea of unsupervised\r\nalignment [R2], especially as every patch implicitly has already \r\nsome general alignment information from its keypoint.\r\n\r\nIn Table 1b, SIFT is not normalized and used as a 128 byte descriptor \r\n(in Table 1a a 128 double descriptor (with normalized entries) is used).\r\n\r\nA new version (arxiv version 3) of the paper is uploaded on March 11.\r\n\r\n[R1] H. Mobahi, R. Collobert, J. Weston. Deep Learning from Temporal Coherence in Video.\r\n[R2] Gary Huang, Marwan Mattar, Honglak Lee, Erik Learned-Miller. Learning to Align from Scratch.\r\n[R3] Memisevic, R. Gradient-based learning of higher-order image features.\r\n[R4] S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification.\r\n[R5] J. Susskind, R. Memisevic, G. Hinton, and M. Pollefeys. Modeling the joint density of two images under a variety of transformations."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363042920000, "tcdate": 1363042920000, "number": 1, "id": "HH0nm6IT6SHZc", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "OznsOsb6sDFeV", "replyto": "3wmH3H7ucKwu0", "signatures": ["Christian Osendorfer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Dear 3338,\r\nThank you for your feedback. In order to give a comprehensive\r\nanswer, we quote sentences from your feedback and try to respond\r\nappropriately.\r\n\r\n>>> It is not clear what the purpose of the paper is.\r\nWe suggest that the way unsupervised feature learning\r\nmethods are evaluated should be extended: A more direct evalution\r\nof the learnt representations without subsequent supervised algorithms,\r\nand not tied to the task of high-level object classification.\r\n\r\n>>> The ground truth correspondences of the dataset were found by \r\n>>> clustering the image patches to find correspondences.\r\nThis is not how the description of [R1] with respect to the\r\nGround Truth Data (section II in [R1]) reads.\r\n\r\n>>> In this paper, simple clustering methods were not \r\n>>> compared to such as kmeans ...\r\nWe added a K-Means experiment to the new version of the paper.\r\nWe run K-Means (with a soft threshold function) [R2] on the dataset,\r\nit performs worse than spGRBM. (This is mentioned in the new version\r\n3 of the paper).\r\n\r\n>>> Additionally, training in a supervised way makes much more sense\r\n>>> for finding correspondences.\r\nThis is not the question that we are asking. We deliberately \r\navoid any supervised training because we want to investigate\r\npurely unsupervised methods. We are not trying to achieve any \r\nstate-of-the-art results.\r\n\r\n>>> It is not clear from the paper alone what is considered at match \r\n>>> between descriptors\r\nWe have added some text that describes how a false positive\r\nrate for a fixed true positive rate is computed.\r\n\r\n>>> The preprocessing of the image patches seems different for each \r\n>>> method. This could lead to wildly different scales of the input \r\n>>> pixels and thus the corresponding representations of the various \r\n>>> methods.\r\nCould you elaborate why this is something to consider \r\nin our setting?\r\n\r\n>>> In section 3.3 it is mentioned that it is surprising that L1 \r\n>>> normalization works better because sparsity hurts classification \r\n>>> typically.\r\nWe don't say that 'sparsity hurts classification typically'. We say\r\nthe exact opposite (that sparse representations are beneficial\r\nfor classification) and give a reference to [R3], a paper that you\r\nalso reference. We say that it is surprising that a sparse representation\r\n('sparse' as produced by spGRBM, not by a normalization scheme) \r\nperforms better in a  distance calculation, because the general \r\nunderstanding is (to our  knowledge) that sparse representations \r\nsuffer  more from the curse of dimensionality when considering \r\ndistances.\r\n\r\n>>> However, the sparsity in the paper is directly before the distance \r\n>>> calculation, and not before being fed as input to a classifier which \r\n>>> is a different setup and would thus be expected to behave differently \r\n>>> with sparsity. This is the typical setup in which sparsity is found to \r\n>>> hurt classification performance because information is being thrown \r\n>>> away before the classifier is used.\r\nWe don't understand what is meant here. Wasn't the gist of [R3] that\r\na sparse encoding is key for good classification results? However, we\r\nthink that the main point that we wanted to convey in the referred part\r\nof the paper was poorly presented. We tried\r\nto make the presentation of the analysis part better in the new version\r\n(arxiv version 3) of the paper.\r\n\r\n>>> ...does not appear to apply to a wide audience as other papers have \r\n>>> done a comparison of unsupervised methods in the past'\r\nThose comparisions are, as explained in the paper, done always in combination\r\nwith a subsequent supervised classification algorithm on a high-level\r\nobject classification task. We want to avoid exactly this setting. We think\r\nthat the paper is relevant for researchers working on\r\nunsupervised (feature) learning methods and for researchers working in \r\nComputer Vision.\r\n\r\nA new version (arxiv version 3) of the paper is uploaded on March 11.\r\n\r\n[R1] M. Brown, G. Hua, and S. Winder. Discriminative learning of local image descriptors.\r\n[R2] A. Coates, H. Lee, and A. Ng. An analysis of single-layer networks in unsupervised feature learning.\r\n[R3] A. Coates and A. Ng. The importance of encoding versus training with sparse coding and vector quantization."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363042680000, "tcdate": 1363042680000, "number": 1, "id": "rH1Wu2q8W0ujI", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "OznsOsb6sDFeV", "replyto": "Hu7OueWCO4ur9", "signatures": ["Christian Osendorfer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Dear f716,\r\nthank you for your feedback. We evaluated more models\r\nthan shown in Table 1, but they perform not as good as\r\nspGRBM so we decided to leave those out (from the Table) in order to\r\navoid clutter. The models are mentioned in section 3.5\r\nof the paper (the arxiv version 2 of the paper).\r\n\r\nWe are currently running experiments with deep convolutional\r\nnetworks to determine how much improvement supervision \r\nsignals can achieve.\r\n\r\nWe uploaded a new version (on March 11) that changes some\r\nbits of the presentation. We also evaluated K-Means on the\r\ndataset (it is mentioned under 'Other models', because its\r\nperformance is below the one frome spGRBM)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362057120000, "tcdate": 1362057120000, "number": 2, "id": "llHR9RITMyCTz", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "OznsOsb6sDFeV", "replyto": "OznsOsb6sDFeV", "signatures": ["anonymous reviewer e954"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning for low-level Local Image Descriptors", "review": "This paper proposes to evaluate feature learning algorithms by using a low-level vision task, namely  image patch matching. The authors compare three feature learning algorithms, GRBM. spGRBM and mcRBM against engineered features like SIFT and others.\r\nThe empirical results unfortunately show that the learned features are not very competitive for this task. \r\n\r\nOverall, the paper does not propose any new algorithm and does not improve performance on any task.\r\nIt does raise an interesting question though which is how to assess feature learning algorithms. This is a core problem in the field and its solution could help a) assessing which feature learning methods are better and b) designing algorithms that produce better features (because we would have better loss functions to train them). Unfortunately, this work is too preliminary to advance our understanding towards the solution of this problem (see below for more detailed comments). \r\nOverall quality is fairly poor: there are missing references, there are incorrect claims, the empirical validation is insufficient. \r\n\r\nPros\r\n-- The motivation is very good. We need to improve the way we compare feature learning methods.\r\n-- The filters visualization is nice.\r\n\r\nCons\r\n-- It is debatable whether the chosen task is any better for assessing the quality of feature learning methods. The paper almost suggested a better solution in the introduction: we should compare across several tasks (from low level vision like matching to high level vision like object classification). If a representation is better across several tasks, then it must capture many relevant properties of the input.\r\nIn other words, it is always possible to tweak a learning algorithm to give good results on one dataset, but it is much more interesting to see it working well across several different tasks after training on generic natural images, for instance. \r\n-- The choice of the feature learning methods is questionable, why are only generative models considered here? The authors do mention that other methods were tried and worked worse, however it is hard to believe that more discriminative approaches work worse on the chosen task. In particular, knowing the matching task it seems that a method that trains using a ranking loss (learning nearby features for similar patches and far away features for distant inputs) should work better. See:\r\nH. Mobahi, R. Collobert, J. Weston. Deep Learning from Temporal Coherence in Video. ICML 2009.\r\n-- The overall results are pretty disappointing. Feature learning methods do not outperform the best engineered features. They do not outperform even if the comparison is unfair: for instance the authors use 128 dimensional SIFT but much larger dimensionality for the learned features. Besides, the authors do not take into account time, neither the training time nor the time to extract these features. This would also be considered in the evaluation.\r\n\r\nMore detailed comments:\r\n-- Missing references.\r\nIt is not true that feature learning methods have never been assessed quantitatively without supervised fine tuning. On a low level vision task, I would refer to:\r\nLearning to Align from Scratch\r\nGary Huang, Marwan Mattar, Honglak Lee, Erik Learned-Miller.\r\nIn Advances in Neural Information Processing Systems (NIPS) 25, 2012.\r\nAnother missing reference is \r\n2011 Memisevic, R.\r\nGradient-based learning of higher-order image features. \r\nInternational Conference on Computer Vision (ICCV 2011).\r\nand other similar papers where Memisevic trains features that relate pairs of image patches.\r\n--ROC curves should be reported at least in appendix, if not in the main text.\r\n-- I do not understand why SIFT results on tab 1 a) differs from those in tab. 1 b)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361968260000, "tcdate": 1361968260000, "number": 3, "id": "3wmH3H7ucKwu0", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "OznsOsb6sDFeV", "replyto": "OznsOsb6sDFeV", "signatures": ["anonymous reviewer 3338"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning for low-level Local Image Descriptors", "review": "This paper is a survey of unsupervised learning techniques applied to the unsupervised task of descriptor matching. Various methods such as Gaussian RBMs, sparse RBMs, and mcRBMs were applied to image patches and the resulting feature vectors were used in a matching task. These methods were compared to standard hand-crafted descriptors such as SIFT, SURF, etc.\r\n\r\nPros\r\nProvides a survey of descriptors for matching pairs of image patches.\r\n\r\nCons\r\nIt is not clear what the purpose of the paper is. The paper compares several learning algorithms on the task of what essentially seems like clustering image patches to find their correspondences. The ground truth correspondences of the dataset were found by clustering the image patches to find correspondences... In this paper, simple clustering methods were not compared to such as kmeans or sparse coding which are less complicated models than RBMs and are meant for finding correspondences. Additionally, training in a supervised way makes much more sense for finding correspondences.\r\n\r\nIt is not clear from the paper alone what is considered at match between descriptors? Is it the distance being below a threshold, the pair of descriptors being closer than any other pair of descriptors, etc.?\r\n\r\nThe preprocessing of the image patches seems different for each method. This could lead to wildly different scales of the input pixels and thus the corresponding representations of the various methods.\r\n\r\nIn section 3.3 it is mentioned that it is surprising that L1 normalization works better because sparsity hurts classification typically. However, the sparsity in the paper is directly before the distance calculation, and not before being fed as input to a classifier which is a different setup and would thus be expected to behave differently with sparsity. This is the typical setup in which sparsity is found to hurt classification performance because information is being thrown away before the classifier is used.\r\n\r\nNovelty and Quality:\r\nThis paper is not novel in that it is survey of prior work applied to matching descriptors. It is well written but does not appear to apply to a wide audience as other papers have done a comparison of unsupervised methods in the past, for example:\r\n- A. Coates, H. Lee, and A. Ng. An analysis of single-layer networks in unsupervised feature learning. In Proc. AISTATS, 2011.\r\n- A. Coates and A. Ng. The importance of encoding versus training with sparse coding and vector quanti- zation. In Proc. ICML, 2011."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361947080000, "tcdate": 1361947080000, "number": 1, "id": "Hu7OueWCO4ur9", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "OznsOsb6sDFeV", "replyto": "OznsOsb6sDFeV", "signatures": ["anonymous reviewer f716"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning for low-level Local Image Descriptors", "review": "his paper proposes a dataset to benchmark the correspodence problem\r\nin computer vision. The dataset consists of image patches that have\r\ngroundtruth matching pairs (using separate algorithms). Extensive\r\nexperiments show that RBMs perform well compared to hand-crafted\r\nfeatures.\r\n\r\nI like the idea of using itermediate evaluation metrics to measure the\r\nprogress of unsupervised feature learning and deep learning. That\r\nsaid, comparing the methods on noisy groundtruth (results of other\r\nalgorithms) may have some bias.\r\n\r\nThe experiments could be made stronger if algorithms such as\r\nAutoencoders or Kmeans (Coates et al, 2011, An Analysis of\r\nSingle-Layer Networks in Unsupervised Feature Learning) are\r\nconsidered.\r\n\r\nIf we can consider the groundtruth as clean, will supervised learning\r\na deep (convolutional) network using the groundtruth produce better\r\nresults?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358720100000, "tcdate": 1358720100000, "number": 17, "id": "OznsOsb6sDFeV", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "OznsOsb6sDFeV", "signatures": ["osendorf@gmail.com"], "readers": ["everyone"], "content": {"title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Unsupervised feature learning has shown impressive results for a wide range of input modalities, in particular for object classification tasks in computer vision. Using a large amount of unlabeled data, unsupervised feature learning methods are utilized to construct high-level representations that are discriminative enough for subsequently trained supervised classification algorithms. However, it has never been quantitatively investigated yet how well unsupervised learning methods can find low-level representations for image patches without any supervised refinement. In this paper we examine the performance of pure unsupervised methods on a low-level correspondence task, a problem that is central to many Computer Vision applications. We find that a special type of Restricted Boltzmann Machines performs comparably to hand-crafted descriptors. Additionally, a simple binarization scheme produces compact representations that perform better than several state-of-the-art descriptors.", "pdf": "https://arxiv.org/abs/1301.2840", "paperhash": "osendorfer|unsupervised_feature_learning_for_lowlevel_local_image_descriptors", "keywords": [], "conflicts": [], "authors": ["Christian Osendorfer", "Justin Bayer", "Patrick van der Smagt"], "authorids": ["osendorf@gmail.com", "bayer.justin@googlemail.com", "smagt@tum.de"]}, "writers": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 7}