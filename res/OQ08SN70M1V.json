{"notes": [{"id": "OQ08SN70M1V", "original": "jkKRjyPmcVG", "number": 260, "cdate": 1601308037360, "ddate": null, "tcdate": 1601308037360, "tmdate": 1611607658392, "tddate": null, "forum": "OQ08SN70M1V", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "id_QDXuaKXt", "original": null, "number": 1, "cdate": 1610040423493, "ddate": null, "tcdate": 1610040423493, "tmdate": 1610474022517, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper introduces a pair of related regularization-oriented techniques for fine-tuning pretrained transformer models for NLP tasks, and shows that both are more efficient and more effective than prior work in thorough experiments on a wide range of tasks. The techniques are motivated by the idea of 'representational collapse', which is defined as drops in the ability of a linear model trained on an input representation to solve tasks _other than_ the one being trained on.\n\nPros:\n- The new method is demonstrated to be broadly efficient and effective on a wide range of tasks.\n\nCons:\n- It's not clear why 'representational collapse' warrants a new term, or whether it's desirable in general.\n- The motivations for some of the precise technical decisions behind the new methods are unclear."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040423479, "tmdate": 1610474022500, "id": "ICLR.cc/2021/Conference/Paper260/-/Decision"}}}, {"id": "w4Eapvo_FtX", "original": null, "number": 2, "cdate": 1603885872256, "ddate": null, "tcdate": 1603885872256, "tmdate": 1606295964251, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Review", "content": {"title": "Addressing an important problem but hard to read and understand", "review": "This paper proposes a method for fine-tuning to address the issue of representation collapse. The authors claim that their proposed approach is more robust to hyper-parameters of the fine-tuning process and more computationally efficient compared to its counter parts, e.g., SMART. The proposed method is called Robust Representations through Regularized Finetuning (and an extension called Robust Representations through Regularized and Reparameterized Finetuning)  the main idea, as I understand, is to minimize the amount of change in representations of the model at each training step during the fine-tuning.\n\nIn order to show that the representational collapse problem exist when using standard fine-tuning techniques, and that their method, indeed, resolves this problem, they design a series of probing experiments where the apply fine-tuning on a set of datasets/tasks in a sequential order using the best checkpoint from the prior iteration.  They measure the performance of the iteratively fine-tuned model on the source task at each step and show that with their method, the performances drops much less with sequential probing in contrast to the standard fine-tuning approach. Furthermore, they apply this iterative fine-tuning in cycles, revising the sequence of tasks in each cycle, and they find that in most cases, they get much bigger improvements in the performance of the model on the target tasks in each cycle (again compared to standard fine-tuning).\n\nI find the problem addressed in the paper is super important and proposed solution very intuitive. I think the paper can be written in a way more clear way with a bit bigger audience in mind. In addition, in order to better show the merits of the proposed approach, if applicable maybe it would be more fair if the approach is compared with more simpler solutions to pose constraints on the amount of change in the representations, e.g., to simply  mix the data from source and target or add a distance term to the fine-tuning loss, or existing approaches like elastic weight consolidation that are used in continual learning setups (where the constraint is on the parameters of the model rather than the representations).\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146956, "tmdate": 1606915779087, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper260/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Review"}}}, {"id": "zIX4YOqf8Gh", "original": null, "number": 8, "cdate": 1606178780232, "ddate": null, "tcdate": 1606178780232, "tmdate": 1606178780232, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "VLWGO07RIQR", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Re: AnonReviewer4", "comment": "Thank you for your clarification! We have updated the paper (Section~2) to explain and connect trust-region methods more explicitly with our formulation of RXF. Thank you once again for your review!"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "VLWGO07RIQR", "original": null, "number": 7, "cdate": 1605958193782, "ddate": null, "tcdate": 1605958193782, "tmdate": 1605958193782, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "SXUhp2iM4lD", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Thank you for your response", "comment": "Thank you very much for your response.\n\nI just wanted to clarify that what I meant by \"(writing the paper with a bit bigger audience in mind\" I didn't mean to try it on other domains, I think it is perfectly fine for this work to focus on the language tasks in the experiments. My point was more about the language of the paper. I consider my self as someone who is very interested in your work and would definitely want to use it or refer to it in my future work, but I wasn't familiar with things like the trust region theory, and you use this term quite often in the paper. It would have helped me a lot for example, if you simply explained what trust region theory is and why it is relevant in this context early in the paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper260/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "Tams3J3Lla", "original": null, "number": 6, "cdate": 1605570526492, "ddate": null, "tcdate": 1605570526492, "tmdate": 1605570526492, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "RfTjRDXIx7w", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Re: AnonReviewer1", "comment": "Thank you for your detailed review of our paper! We appreciate and would like to address each of your comments individually.\n\n**The proposed methods (R3F and R4F) are a simple and incremental revision of the existing method (SMART), and there are no fundamental grounds or intuitions from which the proposed formulation is derived and justified (except for its empirical superiority).**\nWe believe the simplicity of RXF is a benefit that manifests itself in faster compute times. Furthermore, this will allow for broader adoption for RXF than more complex/computationally expensive methods like SMART. We'd also like to reiterate another novelty of the paper: experimentation and exploration into the proposed representation collapse phenomena. \n\n**There is no details or explanations about how the proposed methods are directly related to trust region theory (and what exactly trust region theory is).**\n\nIn sections 2 and 2.1, we make a connection between the SMART objective and natural gradients, which is a subfield of trust region based methods. In particular, eq 1 formally shows the relation between constrained optimization and trust region. We apologize for the confusion and will update the section to make the connection more explicit.\n\n\n**InfoXLM**\nDuring the paper's writing, InfoXLM was not made public; thus, we could not experiment with it.\n\n**Why should fine-tuned representations be also generalizable in cases where we only consider the end performance of a specific target task?**\nMaintaining generalizable representations even for end tasks can be seen as a form of regularization. It's trivial for models to exploit dataset-specific features to achieve excellent training performance, yet empirically we show that maintaining generalizable representations improves the generalization gap. The exact mechanism as to why this is the case is still unknown. It requires formal definitions of generalizable representations, which to our knowledge, is still an active field of research. \n\n**It would be much better if the definition of 'representational collapse' can be well-defined in a mathematical and measurable manner, instead of just relying on empirically showing its existence with probing (though it is also desirable).**\n\nWe agree that a mathematical definition of representational collapse would be of great benefit, however, in order to define representational collapse, we need to define generalizable representations. This is an active area of work, hence we defer to probing experiments to measure generalization.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "SXUhp2iM4lD", "original": null, "number": 5, "cdate": 1605567773802, "ddate": null, "tcdate": 1605567773802, "tmdate": 1605567773802, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "w4Eapvo_FtX", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Re: AnonReviewer4", "comment": "Thank you for taking the time to review our paper! We\u2019re glad you found this paper to be addressing an important problem and our solution to be intuitive! We agree this paper could have been written to focus on a broader audience (i.e., fine tuning for domains other than language). Still, we wanted to explicitly focus on language fine-tuning due to various factors, including compute budget. We leave the analysis of RXF to other modalities than language as future work.\n\nFor our comparisons, we wanted to compare to other various optimization techniques (FreeLB, SMART, SGD++). We agree that a more in-depth analysis would require looking at multiple approaches utilizing methods such as data-augmentations, but we believe the baselines we chose are mostly fair. \n\nPlease let us know if you have any points which could make the paper clearer, we would appreciate any feedback on making this paper more accessible!\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "F7N6AKwhTnx", "original": null, "number": 4, "cdate": 1605567425035, "ddate": null, "tcdate": 1605567425035, "tmdate": 1605567425035, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "0mgWqbL9-OE", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Re: AnonReviewer3", "comment": "Thank you for taking the time to review our paper! We would like to address each of your concerns individually below:\n\n**The overall design of R4F is simple, as leveraging the Spectral Normalization to make the function 1-Lipschitz is not new** \nWe view R4F as an extension to R3F to further bound representational collapse. We agree that the mathematics is not novel; however, we believe the application of R3F and spectral normalization in the context of finetuning and the application to representation collapse to be the novelty of R4F.\n\n**Some notions and symbols are missing, such as x~ in equation 2.**\nThank you for your feedback; we will update our latest manuscript to fix mathematical and notational errors.\n\n**The analysis of the relationship to SMART and FreeLB is also a bit vague**\nWe apologize for the confusion, At the beginning of section 2, we state the SMART objective (equation 2) and contrast it to our proposed R3F/R4F objectives (equation 3 and 4), and in section 2.1, we introduce the computation cost of other state of the art finetuning approaches. We will update our manuscript to define FreeLB explicitly and better connect sections 2 and 2.1.\n\n**What is the major difference between catastrophic forgetting and representational collapse?**\nCatastrophic forgetting has been historically associated with continuous learning, recent work (Mosbach et al. 2020 https://arxiv.org/abs/2006.04884) showed that catastrophic forgetting concerning the original MLM objective is not essential for end task training, and instead the issue lies in optimization. We introduce the phenomenon of representational collapse, which is for generalizing end task representations rather than the pre-training representations. We will update the paper to make the distinction between catastrophic forgetting and representational collapse more clear.\n\n**What will happen if fine-tuned with different kinds of noise z? or with different sigma?**\n\nWe note there are many flavors of R3F that can occur with various noise distributions or perturbation strategies. We believe a larger, more general framework exists which connects trust region methods and consistency learning in general. We leave this area of exploration for future work and instead focus on a small but essential subset of trust region via R3F that shows significant improvements on several finetuning tasks across the language modality.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "q6Lq_X9H9dK", "original": null, "number": 3, "cdate": 1605566907841, "ddate": null, "tcdate": 1605566907841, "tmdate": 1605566907841, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "DIKqZkFzVpe", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment", "content": {"title": "Re: AnonReviewer2", "comment": "Thank you for your detailed review of our paper. We're glad you found our paper well written and appreciated our extensive experiments! We'd like to address your concerns.\n- We didn't include SMART in the generalization experiments mostly due to the computational cost and time constraints and the fact that SMART performed comparably to Standard++ in the early stages of the generalization experiments. We will state that SMART performance was similar to Standard++ explicitly in the paper. \n- We spent quite a bit of time figuring out what settings R3F outperformed and R4F and vice versa. We couldn't find a definitive pattern or prior, which allows us to recommend one algorithm versus the other. We'll also state this explicitly in the paper.\n- The reason for the mean/median discrepancy between Table 3/Table 2 is due to prior work. We created Table 2 from scratch and therefore decided to select the median due to it being a more robust measure. On the other hand, for Table 3, XLM-R and InfoXLM reported averages of 5 runs; therefore, to have an equivalent comparison, we also reported averages.\n- We introduced representational collapse to describe the lack of ability to generalize specifically post fine-tuning pre-trained representations. Specifically, we argue that pre-trained representations degrade during the fine-tuning stage. Similarly, catastrophic forgetting argues for degradations of generalizable representations in the continuous learning setting. We believe this term's introduction is justified due to the explorations of generalizable representations within this novel setting.\n-We believe our paper's novelty is two-fold, the proposal of RXF as a general method for fine-tuning pre-trained language representations and the exploration into this new phenomenon of representational collapse. The contribution of removing gradient ascent steps for random noise was explicitly made for decreasing SMART's computational complexity. Furthermore, the R4F extension with 1-Lip classification heads was for directly constraining the change in representations. We'll improve this section in the paper to layout our motivations more clearly. The second novelty is the exploration surrounding representational collapse.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "OQ08SN70M1V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper260/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper260/Authors|ICLR.cc/2021/Conference/Paper260/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872925, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Comment"}}}, {"id": "RfTjRDXIx7w", "original": null, "number": 1, "cdate": 1603714590201, "ddate": null, "tcdate": 1603714590201, "tmdate": 1605024728628, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Review", "content": {"title": "Review", "review": "\n#### Summary\n\n- This paper presents a simple but effective method rooted in trust region theory for fine-tuning pre-trained models without 'representational collapse'. Compared to previous methods (such as SMART by Jiang et al. (2019)), the newly proposed methods (R3F and R4F) are computationally simple while achieving more strong performance on several NLP tasks including GLUE, XNLI and summarization. The authors also introduce the concept of 'representational collapse', which means the degradation of generalizable representations of pre-trained models during the fine-tuning stage. Moreover, they empirically demonstrated that SMART and their proposed methods are effective in relieving representational collapse, compared to typical fine-tuning based on normal gradient descent (i.e., one without constraints).\n\n#### Pros (Reasons to Accept)\n\n- The paper is clearly written.\n- The introduction of simple but effective & efficient methods for fine-tuning pre-trained models.\n- Extensive experiments. It's good to see experiments on XNLI and summarization tasks in addition to one on GLUE.\n- Strong emprical results, achieving SOTA on several tasks.\n\n#### Cons (Reasons to Reject)\n\n- The proposed methods (R3F and R4F) are a simple and incremental revision of the exitsing method (SMART), and there are no fundamental grounds or intuitions from which the proposed formulation is derived and justified (except for its empirical superiority).\n- There is no details or explanations about how the proposed methods are directly related to trust region theory (and what exactly trust region theory is).\n\n#### Comments\n\n- I'm just wondering whether the proposed methods can also bring improvement to InfoXLM (in addition to XLM-R) in the XNLI experiment. If possible, showing this would make your claim much stronger.\n- Why should **fine-tuned** representations be also **generalizable** in cases where we only consider the end performance of a specific target task (and the proposed methods do not bring significant improvement on the target task performance)? I understand that the proposed methods are desirable in the case of XNLI where zero-shot cross-lingual transfer explicitly requires fine-tuned representations to be still general enough to be properly transferred to other languages. Is there any other plausible story where generalizability is very important when fine-tuning for **only** a designated task?\n- It would be much better if the definition of 'representational collapse' can be well-defined in a mathematical and measurable manner, instead of just relying on empirically showing its existence with probing (though it is also desirable).\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146956, "tmdate": 1606915779087, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper260/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Review"}}}, {"id": "0mgWqbL9-OE", "original": null, "number": 3, "cdate": 1603893506311, "ddate": null, "tcdate": 1603893506311, "tmdate": 1605024728501, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Review", "content": {"title": "A well-written paper with interesting ideas. ", "review": "This paper presents a lightweight fine-tuning strategy motivated by the trust-region theory, which achieved SOTA results on GLUE and  XNLI using no novel pertaining approaches. The paper also introduces a new analysis by defining a notion of representational collapse and provides a new methodology for measuring it during fine-tuning, which is interesting.\n\nIn my opinion, the defining and analysis of representational collapse is the major contribution of this paper. This paper  is well-written and strongly motivated with solid experimental results. \n\nStrength: \n\n+ A novel view of representation learning, a.k.a. representational collapse with comprehensive evaluations and detailed analysis. It may motivate other works of robust representation learning, and it is well suited for ICLR.\n+ A novel fine-tuning method which does not require extra backward computations and empirically works as well as or better than SMART\n+ SOTA evaluation results on both NLU and NLG datasets\n\nWeakness:\n\n- The overall design of R4F is simple, as leveraging the Spectral Normalization to make the function 1-Lipschitz is not new,\n- Some notions and symbols are missing, such as x~ in equation 2. And the analysis of the relationship to SMART and FreeLB is also a bit vague. I recommend the authors to carefully revise this part.\n \nQuestions:\n\nwhat is the major difference between catastrophic forgetting and representational collapse?\n\nWha will happen if fine-tuned with different kinds of noise z? or with different sigma?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146956, "tmdate": 1606915779087, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper260/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Review"}}}, {"id": "DIKqZkFzVpe", "original": null, "number": 4, "cdate": 1603901301402, "ddate": null, "tcdate": 1603901301402, "tmdate": 1605024728438, "tddate": null, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "invitation": "ICLR.cc/2021/Conference/Paper260/-/Official_Review", "content": {"title": "A simple and effective method for preserving generalizability of a model when fine-tuning.", "review": "Summary\n\nThe paper proposes a method for finetuning pre-trained models that ensures the generalization ability of the representation is maintained. The key innovation is that the computationally expensive ascent step in the mirror descent method of SMART can be replaced by simply injecting noise. The results support the hypothesis that this works well for keeping the generalization-ability of the model. The authors also define the degradation of the generalizability of the representation during finetuning as \u201crepresentational collapse\u201d. \n\nStrengths\n- The proposed approach is based on the change of the model in the output space g.f which seems like a very sensible way to constrain the model. The proposed approach therefore shares the advantage that the \u201cchange\u201d being minimised has some meaningful interpretation. This is in contrast to many continual learning approaches which operate purely in weight space. \n\n- Constraining the output function g to be 1-Lipschitz is also sensible and well explained in the paper as it ensures the Bregmann-divergance-based smoothness constraint applied on the output will also constrain the representation, f.\n\n- The experiments are quite strong. The method has been evaluated on a large range of NLP tasks using various transformers as the base model. All experiments include multiple runs and the average/median statistics have been reported.\n\n- The approach is much faster than the closest existing method, SMART and achieves comparable accuracy in most cases.\n\n- Overall the paper is very well written and easy to understand. The proposed novelty compared to the closest existing approach is clearly highlighted and validated by the experiments.\n\nConcerns\n- The generalization experiments in Figure 4 only compares the proposed method to standard fine-tuning with best practices (i.e. Standard++), why has a more sophisticated methods like SMART not been included in this figure? Also, the authors state that \u201cR3F/R4F consistently outperforms the adversarial fine-tuning method SMART\u201d, but from Figure 3 it seems that the converse is also true - in at least 2/6 of the tasks, SMART outperforms all the variants of the proposed method and is on par in two others.\n\n- There is quite a range of performance between the variants R3F and R4F, but there aren\u2019t any guidelines or suggestions on why this is the case or which one should be used in a particular situation. \n\n- The results in Table 3 and Table 2 show fractional improvements over the existing methods, however not variance is reported for these numbers. Another issue is that Table 2 uses median whereas Table 3 uses average. Is there a reason for this discrepancy?\n\n- The need for a new term \u201crepresentational collapse\u201d is not really justified in the paper. Most authors just use the term generalization. What exactly is the difference between \u201crepresentational collapse\u201d and just saying the models lacks the ability to generalize?\n\n- Perhaps the most significant weakness of the paper is that the novelty seems a bit limited. The difference compared to SMART is not really justified in a theoretical or principled manner. For example, what are the implications for using noise samples in Eqn. 4? Is it simply a heuristic to encourage smoothness? It would be good if the authors could explain this in more detail in the paper. At the moment it just appears as if ad-hoc modifications have been made to the cost function.\n\nMinor comments\n- There are some very minor typos throughout the paper that can be fixed. Eg. \u201ceven great degree\u201d\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper260/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper260/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Better Fine-Tuning by Reducing Representational Collapse", "authorids": ["~Armen_Aghajanyan1", "akshats@fb.com", "anchit@fb.com", "~Naman_Goyal1", "~Luke_Zettlemoyer1", "sonalgupta@fb.com"], "authors": ["Armen Aghajanyan", "Akshat Shrivastava", "Anchit Gupta", "Naman Goyal", "Luke Zettlemoyer", "Sonal Gupta"], "keywords": ["finetuning", "nlp", "representational learning", "glue"], "abstract": "Although widely adopted, existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings, motivating recent work on trust region methods. In this paper, we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution), thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally, by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN, Gigaword, Reddit TIFU, and the GLUE benchmark), while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.", "one-sentence_summary": "We present a lightweight augmentation to standard fine-tuning which outperforms previous methods across the board (i.e. SOTA on 3 summarization tasks, XNLI, RoBERTa on GLUE) while being computationally cheaper than other fine-tuning approaches.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "aghajanyan|better_finetuning_by_reducing_representational_collapse", "pdf": "/pdf/1468fd4aa86df7a9b9d588cbc2232f39a6fe0340.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\naghajanyan2021better,\ntitle={Better Fine-Tuning by Reducing Representational Collapse},\nauthor={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=OQ08SN70M1V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "OQ08SN70M1V", "replyto": "OQ08SN70M1V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper260/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146956, "tmdate": 1606915779087, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper260/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper260/-/Official_Review"}}}], "count": 12}