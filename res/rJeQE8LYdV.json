{"notes": [{"id": "rJeQE8LYdV", "original": "HygEAehtDN", "number": 18, "cdate": 1553716779189, "ddate": null, "tcdate": 1553716779189, "tmdate": 1562083039393, "tddate": null, "forum": "rJeQE8LYdV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "Storyboarding of Recipes: Grounded Contextual Generation", "authors": ["Khyathi Raghavi Chandu", "Eric Nyberg", "Alan Black"], "authorids": ["kchandu@cs.cmu.edu", "ehn@cs.cmu.edu", "awb@cs.cmu.edu"], "keywords": ["Multimodal", "Generation", "Structure", "Scaffold", "Multitask"], "TL;DR": "The paper presents two techniques to incorporate high level structure in generating procedural text from a sequence of images.", "abstract": "Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). These models show an improvement in empirical as well as human evaluation. Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes, and 72.5% preferred our model in terms of coherence and structure. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.\n", "pdf": "/pdf/4bb044572b09a51af070983728f81bdc90dc46b5.pdf", "paperhash": "chandu|storyboarding_of_recipes_grounded_contextual_generation"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "B1xFykfE54", "original": null, "number": 2, "cdate": 1555468000615, "ddate": null, "tcdate": 1555468000615, "tmdate": 1556906119527, "tddate": null, "forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Official_Review", "content": {"title": "Interesting task and dataset. Good contribution.", "review": "\nThis paper studies the problem of generating textual descriptions from sequences of images (i.e., a storyboard), by introducing a new dataset and two generation models. The dataset is in the cooking domain, contains about 16k recipes from the how-to blogs, each containing about 7-13 steps on average. The generated descriptions are evaluated with both automatic metrics (Bleu, Meteor, and Rouge-L), and human judgments.\n\nThe contribution of this paper is solid, given that the authors will release the datasets. I think this is a very interesting task and will inspire the development of more structure-aware generation models. My main complaint is that the descriptions of the two proposed models (SSiD and SSIL) is relatively vague. \n\nOther questions/ comments:\nIn Section 4.2, the sequence of phases/states are denoted with sequences of length 4 (e.g. r = <p1, p2, p3, p4>. This is slightly confusing, since there can be many more phases/states, as shown in Table 2.\n\nIn the first paragraph of 4.2, the authors mentioned another source of supervision with unimodal textual recipes. How many unimodal recipes are used? Would it be possible to provide more details about them?\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Storyboarding of Recipes: Grounded Contextual Generation", "authors": ["Khyathi Raghavi Chandu", "Eric Nyberg", "Alan Black"], "authorids": ["kchandu@cs.cmu.edu", "ehn@cs.cmu.edu", "awb@cs.cmu.edu"], "keywords": ["Multimodal", "Generation", "Structure", "Scaffold", "Multitask"], "TL;DR": "The paper presents two techniques to incorporate high level structure in generating procedural text from a sequence of images.", "abstract": "Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). These models show an improvement in empirical as well as human evaluation. Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes, and 72.5% preferred our model in terms of coherence and structure. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.\n", "pdf": "/pdf/4bb044572b09a51af070983728f81bdc90dc46b5.pdf", "paperhash": "chandu|storyboarding_of_recipes_grounded_contextual_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Official_Review", "cdate": 1554234178032, "reply": {"forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234178032, "tmdate": 1556906086954, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "ByxxcqfnKE", "original": null, "number": 1, "cdate": 1554946695539, "ddate": null, "tcdate": 1554946695539, "tmdate": 1556906119304, "tddate": null, "forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Official_Review", "content": {"title": "Useful new dataset and interesting model, but model not described in enough detail", "review": "This paper provides:\n(1) A new dataset of step-by-step recipes, where each recipe has both an image and a corresponding how-to text. The proposed task is to map from the images to the text.\n(2) A description of a model that adds structure to the visual story telling baseline (global-local attention cascading network). They add structure in two ways: (a) SSiD: They cluster sentence representations of recipe sentences into clusters that are called \"phases\" - thus a recipe can be represented as a sequence of \"phases\".  Then they learn a weighted FSA which gives the probabilities of transitioning from one phase to another (I think). This is somehow incorporated into the decoder, but I'm not sure how. (b) SSiL: They introduce a loss which says that the structure (i.e. phase sequence) of the images and the generated text must be the same. They show that (a) and (b) improve over the baseline on BLEU, METEOR, ROUGE-L, and human evaluation.\n\nPros:\n- The dataset seems really useful for researchers working on structured multimodal image-to-text generation.\n- The overall idea of the SSiD and SSiL models seems like a good idea, and it shows convincing performance improvements.\n- There are some really nice visualizations of the phases provided on the dataset website: https://storyboarding.github.io/story-boarding/40topics.html\n\nCons:\n- The SSiD model is not described in nearly enough detail for the reader to understand it properly. See more detailed notes below.\n- Reproducibility: Unless I missed something, the authors do not mention whether they will release the code (and the generated output) for their SSiD and SSiL models. Especially given that the models are not explained in enough detail, this severely limits the reproducibility and usefulness of the work. I doubt that any researcher would be able to reproduce the models given only the information in the paper.\n\nComments about detail of SSiD model:\n- There are no equations in section 4.2, thus there is no precise description of the many steps required to build and train the model. \n- Though I could mostly understand the first two paragraphs of section 4.2 (though I would not be able to reproduce the results due to the many missing details), I was not able to understand the overall idea of the FSM. For example, what are the states of the FSM? Are the states the phases? \n- The FSM is motivated as \"softer\" but I don't understand how or why it is softer or why softness is a good thing.\n- Could you give a brief explanation of \"ergodic\" when you use it - this would help reader comprehension.\n- \"These state transition probabilities are concatenated in the decoder.\" - can you give more detail what you mean here, with an equation?\n- Part of the problem is that the baseline model (Glocal) is only very superficially described. Though the reader can of course read the Glocal paper for the details, it would be more accessible if you gave a more detailed description, as the Glocal model is not necessarily well-known or standard. More importantly, this paper should introduce notation in section 4.1 so that section 4.2 can refer to it - to make precise how exactly SSiD works.\n- In Algorithm 1, I don't know what many of the lines mean. e.g. \"Apply FSM to dataset\", \"For each state find entropy and reverse sort\". Perhaps this is because I didn't understand earlier parts. \n\nNote: You should reference \"Simulating Action Dynamics with Neural Process Networks\" https://arxiv.org/abs/1711.05313\n\nIn conclusion, this dataset looks very useful, the model sounds interesting and seems high-performing, but the model is so insufficiently described that it will frustrate researchers who wish to build on these results. Once the SSiD model is described properly (and the code released), this will be a great paper.", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Storyboarding of Recipes: Grounded Contextual Generation", "authors": ["Khyathi Raghavi Chandu", "Eric Nyberg", "Alan Black"], "authorids": ["kchandu@cs.cmu.edu", "ehn@cs.cmu.edu", "awb@cs.cmu.edu"], "keywords": ["Multimodal", "Generation", "Structure", "Scaffold", "Multitask"], "TL;DR": "The paper presents two techniques to incorporate high level structure in generating procedural text from a sequence of images.", "abstract": "Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). These models show an improvement in empirical as well as human evaluation. Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes, and 72.5% preferred our model in terms of coherence and structure. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.\n", "pdf": "/pdf/4bb044572b09a51af070983728f81bdc90dc46b5.pdf", "paperhash": "chandu|storyboarding_of_recipes_grounded_contextual_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Official_Review", "cdate": 1554234178032, "reply": {"forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234178032, "tmdate": 1556906086954, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper18/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "HJg0R7dw9N", "original": null, "number": 1, "cdate": 1555690453990, "ddate": null, "tcdate": 1555690453990, "tmdate": 1556906119044, "tddate": null, "forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "The paper proposes and interesting task/dataset, but the description of the model could be improved. It would be great to take this account for the camera-ready."}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Storyboarding of Recipes: Grounded Contextual Generation", "authors": ["Khyathi Raghavi Chandu", "Eric Nyberg", "Alan Black"], "authorids": ["kchandu@cs.cmu.edu", "ehn@cs.cmu.edu", "awb@cs.cmu.edu"], "keywords": ["Multimodal", "Generation", "Structure", "Scaffold", "Multitask"], "TL;DR": "The paper presents two techniques to incorporate high level structure in generating procedural text from a sequence of images.", "abstract": "Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). These models show an improvement in empirical as well as human evaluation. Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes, and 72.5% preferred our model in terms of coherence and structure. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.\n", "pdf": "/pdf/4bb044572b09a51af070983728f81bdc90dc46b5.pdf", "paperhash": "chandu|storyboarding_of_recipes_grounded_contextual_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper18/Decision", "cdate": 1554814608310, "reply": {"forum": "rJeQE8LYdV", "replyto": "rJeQE8LYdV", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814608310, "tmdate": 1556906097455, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}