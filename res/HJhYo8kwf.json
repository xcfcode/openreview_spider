{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124460351, "tcdate": 1518459780458, "number": 194, "cdate": 1518459780458, "id": "HJhYo8kwf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HJhYo8kwf", "signatures": ["~Romain_Laroche1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "About the attractor phenomenon in decomposed reinforcement learning", "abstract": "We consider tackling a single-agent RL problem by decomposing it to $n$ learners. These learners are generally trained \\textit{egocentrically}: they are greedy with respect to their own local focus. In this extended abstract, we show theoretically and empirically that this leads to the presence of attractors: states attracting and detaining the agent, against what the global objective function would advise.", "paperhash": "laroche|about_the_attractor_phenomenon_in_decomposed_reinforcement_learning", "keywords": ["Reinforcement Learning", "hierarchical reinforcement learning"], "_bibtex": "@misc{\n  laroche2018about,\n  title={About the attractor phenomenon in decomposed reinforcement learning},\n  author={Romain Laroche and Mehdi Fatemi and Joshua Romoff and Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=HJhYo8kwf}\n}", "authorids": ["romain.laroche@gmail.com", "mehdi.fatemi@microsoft.com", "joshua.romoff@mail.mcgill.ca", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche", "Mehdi Fatemi", "Joshua Romoff", "Harm van Seijen"], "TL;DR": "We show that a local greedy optimisation for a decomposed RL problem creates an attractor phenomenon compromising the task completion.", "pdf": "/pdf/3ac0d5980088045e39618b877076814bb6090a6a.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582705163, "tcdate": 1520696533569, "number": 1, "cdate": 1520696533569, "id": "HkRAhO-Kz", "invitation": "ICLR.cc/2018/Workshop/-/Paper194/Official_Review", "forum": "HJhYo8kwf", "replyto": "HJhYo8kwf", "signatures": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer3"], "content": {"title": "slightly sloppy take on a problem of growing interest", "rating": "4: Ok but not good enough - rejection", "review": "I've been noticing more and more people talking about these sorts of problems---merging the advice of multiple policies. There was a lot of work along these lines back in the olden days and, I believe, people abandoned these approaches because there wasn't a well reasoned way to combine results and know whether the combination would perform well.\n\nIt's worth revisiting these issues, but I'd really like to see some sort of discussion about what might be different this time around. This paper (probably in part due to its brevity!) doesn't really provide sufficient context to convey why it's worth considering such approaches again. It also gets kind of sloppy at the end, with incomplete sentences and missing words here and there. I don't think the paper is ready yet.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "About the attractor phenomenon in decomposed reinforcement learning", "abstract": "We consider tackling a single-agent RL problem by decomposing it to $n$ learners. These learners are generally trained \\textit{egocentrically}: they are greedy with respect to their own local focus. In this extended abstract, we show theoretically and empirically that this leads to the presence of attractors: states attracting and detaining the agent, against what the global objective function would advise.", "paperhash": "laroche|about_the_attractor_phenomenon_in_decomposed_reinforcement_learning", "keywords": ["Reinforcement Learning", "hierarchical reinforcement learning"], "_bibtex": "@misc{\n  laroche2018about,\n  title={About the attractor phenomenon in decomposed reinforcement learning},\n  author={Romain Laroche and Mehdi Fatemi and Joshua Romoff and Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=HJhYo8kwf}\n}", "authorids": ["romain.laroche@gmail.com", "mehdi.fatemi@microsoft.com", "joshua.romoff@mail.mcgill.ca", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche", "Mehdi Fatemi", "Joshua Romoff", "Harm van Seijen"], "TL;DR": "We show that a local greedy optimisation for a decomposed RL problem creates an attractor phenomenon compromising the task completion.", "pdf": "/pdf/3ac0d5980088045e39618b877076814bb6090a6a.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582704976, "id": "ICLR.cc/2018/Workshop/-/Paper194/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper194/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper194/AnonReviewer4"], "reply": {"forum": "HJhYo8kwf", "replyto": "HJhYo8kwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper194/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper194/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582704976}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582580497, "tcdate": 1521384085993, "number": 2, "cdate": 1521384085993, "id": "Ska5qx2Fz", "invitation": "ICLR.cc/2018/Workshop/-/Paper194/Official_Review", "forum": "HJhYo8kwf", "replyto": "HJhYo8kwf", "signatures": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer4"], "content": {"title": "Unsurprising paper with no take home message", "rating": "5: Marginally below acceptance threshold", "review": "This paper shows that for a high enough discount factor, policies that follow a linear combination of egocentric policies have an attractor which could be quite suboptimal. The examples used in the paper are simple and the result is not surprising. The authors also lack motivation of using such a simple linear combination policy, making the paper borderline towards rejection. \nIn summary, this paper states a problem which is obvious (greedy/sub-optimal policies can pull you towards opposite directions), without a clear path forward.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "About the attractor phenomenon in decomposed reinforcement learning", "abstract": "We consider tackling a single-agent RL problem by decomposing it to $n$ learners. These learners are generally trained \\textit{egocentrically}: they are greedy with respect to their own local focus. In this extended abstract, we show theoretically and empirically that this leads to the presence of attractors: states attracting and detaining the agent, against what the global objective function would advise.", "paperhash": "laroche|about_the_attractor_phenomenon_in_decomposed_reinforcement_learning", "keywords": ["Reinforcement Learning", "hierarchical reinforcement learning"], "_bibtex": "@misc{\n  laroche2018about,\n  title={About the attractor phenomenon in decomposed reinforcement learning},\n  author={Romain Laroche and Mehdi Fatemi and Joshua Romoff and Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=HJhYo8kwf}\n}", "authorids": ["romain.laroche@gmail.com", "mehdi.fatemi@microsoft.com", "joshua.romoff@mail.mcgill.ca", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche", "Mehdi Fatemi", "Joshua Romoff", "Harm van Seijen"], "TL;DR": "We show that a local greedy optimisation for a decomposed RL problem creates an attractor phenomenon compromising the task completion.", "pdf": "/pdf/3ac0d5980088045e39618b877076814bb6090a6a.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582704976, "id": "ICLR.cc/2018/Workshop/-/Paper194/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper194/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper194/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper194/AnonReviewer4"], "reply": {"forum": "HJhYo8kwf", "replyto": "HJhYo8kwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper194/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper194/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582704976}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573602266, "tcdate": 1521573602266, "number": 248, "cdate": 1521573601927, "id": "Hk9ky11cz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HJhYo8kwf", "replyto": "HJhYo8kwf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "About the attractor phenomenon in decomposed reinforcement learning", "abstract": "We consider tackling a single-agent RL problem by decomposing it to $n$ learners. These learners are generally trained \\textit{egocentrically}: they are greedy with respect to their own local focus. In this extended abstract, we show theoretically and empirically that this leads to the presence of attractors: states attracting and detaining the agent, against what the global objective function would advise.", "paperhash": "laroche|about_the_attractor_phenomenon_in_decomposed_reinforcement_learning", "keywords": ["Reinforcement Learning", "hierarchical reinforcement learning"], "_bibtex": "@misc{\n  laroche2018about,\n  title={About the attractor phenomenon in decomposed reinforcement learning},\n  author={Romain Laroche and Mehdi Fatemi and Joshua Romoff and Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=HJhYo8kwf}\n}", "authorids": ["romain.laroche@gmail.com", "mehdi.fatemi@microsoft.com", "joshua.romoff@mail.mcgill.ca", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche", "Mehdi Fatemi", "Joshua Romoff", "Harm van Seijen"], "TL;DR": "We show that a local greedy optimisation for a decomposed RL problem creates an attractor phenomenon compromising the task completion.", "pdf": "/pdf/3ac0d5980088045e39618b877076814bb6090a6a.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}