{"notes": [{"id": "S1lhbnRqF7", "original": "rJxsM4TqKX", "number": 1207, "cdate": 1538087939566, "ddate": null, "tcdate": 1538087939566, "tmdate": 1552601063760, "tddate": null, "forum": "S1lhbnRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1l4mLAge4", "original": null, "number": 1, "cdate": 1544771099883, "ddate": null, "tcdate": 1544771099883, "tmdate": 1545354521541, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Meta_Review", "content": {"metareview": "This paper investigates a new approach to machine reading for procedural text, where the task of reading comprehension is formulated as dynamic construction of a procedural knowledge graph. The proposed model constructs a recurrent knowledge graph (as a bipartite graph between entities and location nodes) and tracks the entity states for two domains: scientific processes and recipes.\n\nPros:\nThe idea of formulating reading comprehension as dynamic construction of a knowledge graph is novel and interesting. The proposed model is tested on two different domains: scientific processes (ProPara) and cooking recipes.\n\nCons:\nThe initial submission didn't have the experimental results on the full recipe dataset and also had several clarity issues, all of which have been resolved through the rebuttal. \n\nVerdict:\nAccept. An interesting task & models with solid empirical results.\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "An interesting task & models with solid empirical results."}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1207/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352924533, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352924533}}}, {"id": "rkxUMYW6hX", "original": null, "number": 2, "cdate": 1541376269679, "ddate": null, "tcdate": 1541376269679, "tmdate": 1543737561547, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "content": {"title": "Meaningful contribution, but hard to read", "review": "The paper proposes a recurrent knowledge graph (bipartite graph between entities and location nodes) construction & updating mechanism for entity state tracking datasets such as (two) ProPara tasks and Recipes. The model goes through the following three steps: 1) it reads a sentence at each time step t and identifies the location of each entity via machine reading comprehension model such as DrQA (entities are predefined). 2) Co-reference module adjusts relationship scores (soft adjacency matrix) among nodes, including possibly new nodes introduced by the MRC model. 3) to propagate the relational information across all the nodes, the model performs L layers of LSTM for each entity that attend on other nodes via attention (where the weights come from the adjacency matrix). The model repeats the three steps for each sentence. The model is trained by directly supervising for the correct span by the MRC model at each time step, which is possible because the data provides strong supervision for each sentence (not just the answer at the end).\n The model achieves the state of the art in the two tasks of ProPara and Recipes dataset.\n\nStrengths: The paper provides an elegant solution for tracking relationship between entities as time (sentence) progresses. I also agree with the authors that this line of work (dynamic KG construction and modification) is an important area of research. While the model shares a similar spirit to EntNet, I think the model has enough distinctions / contributions, especially given that it outperforms EntNet by a large margin. The model also obtains non-trivial improvement over previous SOTA models.\n\nWeaknesses: Paper could have been written better. I had hard time understanding it. The notations are overall confusing and not explained well. Also there are a few unclear parts which I discuss in questions below.\n\nQuestions: \n1. Are e_{i,t} and lambda_{i,t} vectors? Scalars? Abstract node notations? It is not clear in the model section. Also, it took me a long time to figure out that \u2018i\u2019 is used to index each entity (it is mentioned later).\n2. The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context. What happens if there are multiple mentions in the text? Which one does it look at?\n3. For the LSTM in the graph update, why does it have only one input? Shouldn\u2019t it have two inputs, one for previous hidden state and the other for input?\n4. Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k. This is great, but could you also report the number when the full dataset is used?\n5. What does it mean that in training time the model \u201cupdates\u201d the location node representation with the encoding of correct span. Do you mean you use the encoding instead?\n6. For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score? Is it the threshold that maximizes F1?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "cdate": 1542234281052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335896214, "tmdate": 1552335896214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1e-ClGZkV", "original": null, "number": 9, "cdate": 1543737544945, "ddate": null, "tcdate": 1543737544945, "tmdate": 1543737544945, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "H1e6Tr4X0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Thanks for clarification", "comment": "Thank you for the clarification. Now the paper seems to be more clear than before. As my major concern was readability and it is now enhanced, I am raising my score to 7. Great work."}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "H1e6Tr4X0Q", "original": null, "number": 3, "cdate": 1542829509012, "ddate": null, "tcdate": 1542829509012, "tmdate": 1542836936821, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "rkxUMYW6hX", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Response to Reviewer 1 comments", "comment": "Thank you for the useful feedback. We\u2019ve updated our paper to take it into account -- we\u2019ve updated the model description and the notation in Section 4 to clarify our method. Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions. We also made several updates that address your specific questions.\n\n1. Are e_{i,t} and lambda_{i,t} vectors? Scalars? Abstract node notations? It is not clear in the model section. Also, it took me a long time to figure out that \u2018i\u2019 is used to index each entity (it is mentioned later).\n\nThe entity and location embeddings  e_{i,t} and lambda_{i,t} are d-dimensional vectors, although we also overload the symbols to refer to abstract nodes in the model\u2019s knowledge graphs. In the updated manuscript we state both these facts explicitly and state much earlier that \u2018i\u2019 is the index for entities.\n\n2. The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context. What happens if there are multiple mentions in the text? Which one does it look at?\n\nWhen there are multiple mentions of entity i, the initial representation v_i is formed by summing the representations of each mention. We have updated the paper to clarify this (Sec 4.1).\n\n3. For the LSTM in the graph update, why does it have only one input? Shouldn\u2019t it have two inputs, one for previous hidden state and the other for input?\n\nGood point! We\u2019ve improved the notation used to describe the model in Section 4. The update equation now shows clearly that the LSTM takes in the concatenation of two node inputs (entity and location embeddings) along with the previous hidden state.\n\n4. Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k. This is great, but could you also report the number when the full dataset is used?\n\nWe\u2019ve completed an experiment on the full Recipes dataset and updated the paper to describe the result (this experiment did not finish in time for the initial submission). The model\u2019s F1 score improves from 51.64 on the partial data to 54.27 on the full data, surpassing the previous state of the art by a more significant margin.\n\n5. What does it mean that in training time the model \u201cupdates\u201d the location node representation with the encoding of the correct span. Do you mean you use the encoding instead?\n\nWe meant that we perform teacher-forcing to train the model. During training, we extract the context encodings for the groundtruth span and use these in downstream operations  to obtain the node representations. At test time, we use the MRC module\u2019s predicted span rather than the groundtruth.\n\n6. For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score? Is it the threshold that maximizes F1?\n\nFor ProPara task 2, our model was optimized for micro averaged F1 on the development set. Tandon et al. (2018) were kind enough to provide us with their evaluation script.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "r1e8lyS7RQ", "original": null, "number": 5, "cdate": 1542831853553, "ddate": null, "tcdate": 1542831853553, "tmdate": 1542832091341, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "H1gOvMYT37", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Response to Reviewer 3 comments", "comment": "Thanks for the insightful comments. We\u2019ve tried to improve our paper based on your feedback. Most significantly, we\u2019ve performed additional ablation studies to confirm that our modeling choices improve performance, and we provide further empirical insight on what the coreference operations do. We\u2019ve also updated the model description and the notation in Section 4 to clarify modeling mechanisms and choices. Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions. Below we address your concerns point-by-point.\n\nThe proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says. This is especially the case in a few places involving coreference:\n1. The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.\n2. The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.\nWhile these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.\n======\nBased on your comments, we\u2019ve performed additional ablations to measure the impact of the co-reference mechanisms. We find that removing any of them leads to a decrease in performance (Rows 2, 3, 4 of Table 5).\n\nTo provide more than just this quantitative insight, we\u2019ll expand here on how KG-MRC handles coreference to better motivate the modeling choices:\nThe construction of graph G_t from G_{t-1} uses co-reference disambiguation of nodes to prevent node duplication and to enforce temporal dependencies. We perform coreference disambiguation between location nodes of G_t and G_{t-1} via Eq. 1 (call this inter-graph coreference) and between the location nodes in the same graph Gt (call this intra-graph coreference) via Eq. 2. The inter-graph coreference yields new, intermediate representations for the nodes in G_t. These are further updated via the intra-graph coreference step.\n\nInter-graph Co-ref: One way to think about this is that we construct a new graph G_t at every time step. Now the graph G_{t-1} might contain some location nodes which are predicted again at time step \u2018t\u2019 (e.g., in Figure 2, leaf node already existed in G_{t-1}). Instead of replacing an old node with an entirely new node at \u2018t\u2019, we take a recurrent approach and do a gated update that preserves some information stored in the node in previous time steps while adding new information unique to time step \u2018t\u2019. \n\nIntra-graph Co-ref: Inter-graph co-ref isn\u2019t enough since the MRC module makes its span predictions independently. This means that, at time step t, the model could predict the same span/location for multiple entities and add all these duplicates to the graph. Moreover, a single location might have the same surface form but be from different parts of the paragraph (e.g. \u201cleaf\u201d in the 1st and the 5th sentence of the para in figure 2). The operations in Eq. 2 resolve this by performing self-attention (i.e., the predicted locations of all entities are compared to each other).\n====="}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "r1gfdkBXAm", "original": null, "number": 6, "cdate": 1542831977520, "ddate": null, "tcdate": 1542831977520, "tmdate": 1542832012209, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "r1e8lyS7RQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Response to Reviewer 3 comments (contd.)", "comment": "Response continued from above.\n\nWhy does the graph update require coreference pooling again?  Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?\n=====\nWe agree that the coreference pooling in the graph update seems repetitive at first glance. We have further clarified the explanation given in the text and included another ablation experiment  (row 4 of Table 5) to confirm its usefulness.  This step does indeed repeat Eq. 2. In a nutshell, this is necessary because, after the recurrent and residual graph updates (Eqs 3.1 - 3.3) that propagate information across edges, we may end up with different representations for location nodes corresponding to the same location. We don\u2019t want these representations to diverge from each other because of information propagation.\n\nTo give you more detail: \nThe graph update step ensures information propagation between entities and location representations. Specifically if the current location of entity \u201ce_t\u201d is predicted as \u201c\\lambda_t\u201d, the graph update steps ensures that both the entity and location representation gets the same update (via eq 3.2 and 3.3). This would have been sufficient if every entity had a unique location. But, multiple entities can actually exist in the same location. Let\u2019s consider this small graph below\n\t\nWater - -> leaf\nCO_2 --> leaf\n\nHere both water and CO_2 exist in the same location, leaf.  But let\u2019s say that the MRC model picked the \u201cleaf\u201d span from sentence 1 (of the text in Fig 2) for \u201cWater\u201d and from sentence 4 for CO_2. In reality, they refer to the same location entity \u201cleaf\u201d. Now, due to eq. 3.3, the two embeddings of leaf will get two different residual updates (one would be corresponding to Water and other would be because of CO_2). Because of the different updates, the two representations of the same entity might diverge. To remedy this, we re-use the coreference matrix \u201cU\u201d we create in eq. (2), which should already have a high attention score corresponding to the two leaf locations. Thus we perform a similar operation to the intra-graph update.\n====\nAnother modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?\n====\nThe \u201cprefixes\u201d that our model reads at each time step comprise all sentences up to and including the current sentence s_t. The motivation for this modeling choice was empirical. In our preliminary experiments we evaluated alternative strategies, such as (a) only considering the current sentence s_t, and (b) considering the entire paragraph at every time step. We found that operating on prefixes performed best. This is in line with the findings of Dalvi et al., 2018, where the Pro-Global model (which uses prefixes) performs better than the Pro-Local model (which operates on single sentences)."}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "S1xtKI4mAX", "original": null, "number": 4, "cdate": 1542829696857, "ddate": null, "tcdate": 1542829696857, "tmdate": 1542829696857, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "Sklcn-_c3m", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Response to Reviewer 2 comments", "comment": "We\u2019re glad that you found the paper interesting and well-written. To address your comments and questions:\n\n1. the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN. Also, NPN can probably be modified to output spans of a sentence. I will be curious to know how it performs.\n\nThe NPN model requires a pre-defined lexicon of action types (i.e., verbs), such as cut, bake, boil, etc. For the recipes dataset, the action types and their causal effects were manually collected and defined. Since the ProPara dataset does not have these annotations, we would have to manually identify action types to apply NPN to it.\nAlso, NPN treats the state change as a classification problem (of about 260 classes that are also manually defined). In contrast, KG-MRC finds the state-describing span in the text directly, which we believe is a more generic approach.\n\n2. A more detailed illustration of the system / network is needed. Would have made it much easier to understand the paper. \n\nWe agree that more detail would help readers to understand the model better. We\u2019ve made some hopefully significant updates to Section 4 (model description and notation) to improve clarity, and we hope you\u2019ll take the time to read the new manuscript. Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each symbol represents along with its dimensions.\n\n3. What are the results when using the whole training set of Recipes ?\n\nWe\u2019ve completed an experiment on the full Recipes dataset and updated the paper to describe the result (this experiment did not finish in time for the initial submission). The model\u2019s F1 score improves from 51.64 on the partial data to 54.27 on the full data, surpassing the previous state of the art by a more significant margin.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "HkeB75RZRQ", "original": null, "number": 2, "cdate": 1542740508686, "ddate": null, "tcdate": 1542740508686, "tmdate": 1542740508686, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "content": {"title": "Summary of updates", "comment": "Based on the insightful feedback from our reviewers, we\u2019ve updated our paper and believe it is substantially improved. Below we summarize the general changes, and in responses to individual reviewers, we respond directly to their comments/questions.\n\nFull Recipes experiment (Section 5.2):\nWe completed an experiment on the full Recipes dataset and updated the paper with the result. This experiment did not finish in time for the initial submission, so we only had results from a model trained on partial data. The model\u2019s F1 score improved from 51.64 on the partial data to 54.27 on the full data, surpassing the previous state of the art (51.27) by a more significant margin.\n\nAdditional ablations (Table 5):\nTo demonstrate more clearly the impact of several modelling choices, we\u2019ve completed additional ablation experiments. Specifically, these measure the performance contributions of the model\u2019s coreference operations and show that they are important.\n\nUpdate to results on commonsense constraints (Table 6):\nAfter submission, we discovered a string-matching bug in the script that calculates commonsense constraint violations. Correcting this bug changes our results slightly, although the general takeaway is the same. KG-MRC still does not violate any commonsense constraints of Types 1 and 2 (as defined in ProStruct (Tandon et al., 2018)), but we find that both our model and ProStruct violate a small number of Type 3 constraints -- KG-MRC notably makes proportionally fewer violations than ProStruct (4.1% vs 6.3%). We also report violation numbers for several ablated variants of our model and find that they consistently perform worse than the full model. These results are all summarized in Table 6 of the updated manuscript.\n\nImproved Section 4\nWe received feedback that additional details and notational changes in the model description would help readers to understand the model better. We, therefore, made some hopefully significant updates to Section 4 to improve clarity. Two important additions are a high-level summary of the model, which we give at the beginning of Section 4, and a table (Table 2) that lists what each variable represents along with its dimensions.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616945, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1lhbnRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1207/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1207/Authors|ICLR.cc/2019/Conference/Paper1207/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers", "ICLR.cc/2019/Conference/Paper1207/Authors", "ICLR.cc/2019/Conference/Paper1207/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616945}}}, {"id": "H1gOvMYT37", "original": null, "number": 3, "cdate": 1541407328397, "ddate": null, "tcdate": 1541407328397, "tmdate": 1541533332819, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "content": {"title": "Good ideas and results, could use some work with explanation", "review": "* Summary\nThis paper addresses machine reading tasks involving tracking the states of entities over text. To this end, it proposes constructing a knowledge graph using recurrent updates over the sentences of the text, and using the graph representation to condition a reading comprehension module. The paper reports positive evaluations on three different tasks.\n\n* Review\n\nThis is an interesting paper. The key technical component in the proposed approach is the idea that keeping track of entity states requires (soft) coreference between newly read entities and locations and the ones existing in the knowledge graph constructed so far.\n\nThe proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says. This is especially the case in a few places involving coreference:\n1. The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.\n2. The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.\n\nWhile these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.\n\nWhy does the graph update require coreference pooling again?  Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?\n\nAnother modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?\n\nThat the model implicitly learns constraints from data is interesting!\n   \nBottomline: The paper presents interesting ideas and good results, but would be better if the modeling choices were better explored/motivated.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "cdate": 1542234281052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335896214, "tmdate": 1552335896214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Sklcn-_c3m", "original": null, "number": 1, "cdate": 1541206450265, "ddate": null, "tcdate": 1541206450265, "tmdate": 1541533332319, "tddate": null, "forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "content": {"title": "Contributions are novel and convinced about significance", "review": "The paper addresses a challenging problem of predicting the states of entities over the description of a process. The paper is very well written, and easily understandable. The authors propose a graph structure for entity states, which is updated at each step using the outputs of a machine comprehension system. The approach is novel and well motivated. I will suggest a few improvements: \n\n1. the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN. Also, NPN can probably be modified to output spans of a sentence. I will be curious to know how it performs.\n\n2. A more detailed illustration of the system / network is needed. Would have made it much easier to understand the paper. \n\n3. What are the results when using the whole training set of Recipes ?\n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1207/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension", "abstract": "We propose a neural machine-reading model that constructs dynamic knowledge graphs from procedural text. It builds these graphs recurrently for each step of the described procedure, and uses them to track the evolving states of participant entities. We harness and extend a recently proposed machine reading comprehension(MRC) model to query for entity states, since these states are generally communicated in spans of text and MRC models perform well in extracting entity-centric spans.   The  explicit,  structured,  and  evolving  knowledge  graph  representations that our model constructs can be used in downstream question answering tasks to improve machine comprehension of text, as we demonstrate empirically.  On two comprehension tasks from the recently proposed  ProPara dataset,  our model achieves state-of-the-art results. We further show that our model is competitive on the Recipes dataset, suggesting it may be generally applicable.", "keywords": ["recurrent graph networks", "dynamic knowledge base construction", "entity state tracking", "machine reading comprehension"], "authorids": ["rajarshi@cs.umass.edu", "tsmunkhd@microsoft.com", "eric.yuan@microsoft.com", "adam.trischler@microsoft.com", "mccallum@cs.umass.edu"], "authors": ["Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum"], "pdf": "/pdf/eb7c59849622510f3f8942b47bcbc95113ff0ba8.pdf", "paperhash": "das|building_dynamic_knowledge_graphs_from_text_using_machine_reading_comprehension", "_bibtex": "@inproceedings{\ndas2018building,\ntitle={Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension},\nauthor={Rajarshi Das and Tsendsuren Munkhdalai and Xingdi Yuan and Adam Trischler and Andrew McCallum},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1lhbnRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1207/Official_Review", "cdate": 1542234281052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1lhbnRqF7", "replyto": "S1lhbnRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1207/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335896214, "tmdate": 1552335896214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1207/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 11}