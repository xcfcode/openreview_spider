{"notes": [{"id": "HyGySsAct7", "original": "S1xgEdnLKX", "number": 52, "cdate": 1538087735091, "ddate": null, "tcdate": 1538087735091, "tmdate": 1545355380425, "tddate": null, "forum": "HyGySsAct7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ryeQvoYbx4", "original": null, "number": 1, "cdate": 1544817499192, "ddate": null, "tcdate": 1544817499192, "tmdate": 1545354529024, "tddate": null, "forum": "HyGySsAct7", "replyto": "HyGySsAct7", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Meta_Review", "content": {"metareview": "The authors propose an algorithm for generating adversarial examples for ASR systems treating them as black boxes. \n\nStrengths\n- One of the early works to demonstrate black box attacks on ASR system that recognize phrases instead of isolated words.\n\nWeaknesses\n- The approach assumes that the logits are available, which may not be realistic for most ASR systems when they are used in practice -- typically only the final transcription is available.\n- Although the technique is applied to continuous speech, algorithmic improvements over prior work of Alzanot et al. is minimal.\n- Evaluation is weak. For example, cross correlation cannot completely capture the adversarial nature of a generated audio sample. \n- The authors use a genetic algorithm for generating new set of examples which are pruned and mutated. It\u2019s not clear what guarantees exist that the algorithm will eventually succeed. \n\nThe reviewers agree that the presented work puts forth an interesting research direction. But given the deficiencies of the current submission as pointed out by the reviewers, the recommendation is to reject the paper.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Limited novelty compared to previous works"}, "signatures": ["ICLR.cc/2019/Conference/Paper52/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper52/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353354336, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyGySsAct7", "replyto": "HyGySsAct7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper52/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper52/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper52/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353354336}}}, {"id": "B1eLktzOnm", "original": null, "number": 1, "cdate": 1541052638221, "ddate": null, "tcdate": 1541052638221, "tmdate": 1543289011653, "tddate": null, "forum": "HyGySsAct7", "replyto": "HyGySsAct7", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "content": {"title": "The paper is not well-positioned against the existing literature on black-box attack. Its empirical evaluation is somewhat sloppy.", "review": "PAPER SUMMARY:\n\nThis paper introduces a biologically motivated black-box attack algorithm. \nThe target model in this case is DNN applied to the ASR context (automatic speech recognition system). \n\nNOVELTY & SIGNIFICANCE:\n\nThe proposed approach extends the previous genetic approach of (Alzantot et al., 2018) to attack a more complicated ASR system (that handles phrases and sentences). The new contribution here is an add-on momentum mutation component on top of the existing genetic programming architecture of (Alzantot et al., 2018) as illustrated in Figure 3.\n\nThis however appears very incremental seeing that integrating the mutation component into existing system is straight-forward and that mutation is not even a new concept -- it has always been a vital component in genetic programming paradigm.\n\nIt is also unclear how this mutation component improves over the existing work (more on this in the sections below).\n\nAnother issue is this work seems to ignore the recent literature on adversarial black-box attacks to DNN model. To list a few:\n\nChen, P.-Y.; Zhang, H.; Sharma, Y.; Yi, J.; and Hsieh, C.-J. 2017b.\nZOO: Zeroth-order optimization-based  black-box attacks to deepneural networks without training substitute models. \nIn Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (15-26) ACM\n\nCheng,  M.;  Le,  T.;  Chen,  P.-Y.;  Yi,  J.;  Zhang,  H.;  and  Hsieh,C.-J.2018.\nQuery-efficient hard-label black-box attack:  An optimization-based approach. arXiv preprint arXiv:1807.04457\n\nWhile these works have not been used to attacking ASR system, they should be directly applicable to such system since after all, they are black-box attacks. I think the proposed method needs to be compared with these works.\n\nTECHNICAL SOUNDNESS:\n\nI find it surprising that even though the proposed method is claimed to be a black-box attack but in the end, it actually exploits the fact that the target model uses CTC decoder. This pertains specifically to the target model's internal architecture and a black-box attack is not supposed to know this.\n\nCLARITY:\n\nThe paper is clearly written.\n\nEMPIRICAL RESULTS:\n\nI do not understand this statement:\n\n\"That 35% of random attacks were successful in this respect highlights the fact that black box\nadversarial attacks are definitely possible and highly effective at the same time\"\n\nWhy is 35% successful attack rate a positive result? The result tends to suggest that this is an attack with low success rate. \n\nThe 2nd paragraph in 3.2 seems to give a vague explanation: \"the vast majority of failure cases are only a few edit distances away from the target. \n\nThis suggests that running the algorithm for a few more iterations could produce a higher success rate, although at the cost of correlation similarity\".\n\nGiven the above statement, I do not see why the authors didn't actually \"run the algorithm for a few more iterations\" to verify it ...\n\nI am also curious why is the success rate of the proposed method is significantly lower than that of the existing system -- I assume \"single word black box\" is the work of (Alzantot et al., 2018).\n\nI find the empirical evaluation somewhat sloppy: why are the tested method not compared on the same benchmark? How do we interpret the results then?\n\nREVIEW SUMMARY:\n\nThe paper misses the recent literature on black-box attack. The authors need to compare with those to demonstrate the efficiency of their proposed work. I also find the contribution of this paper too incremental & its empirical evaluation appears somewhat sloppy and not convincing (see my specific comments above). ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper52/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "cdate": 1542234548778, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyGySsAct7", "replyto": "HyGySsAct7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335638314, "tmdate": 1552335638314, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryxlDFpLp7", "original": null, "number": 3, "cdate": 1542015319990, "ddate": null, "tcdate": 1542015319990, "tmdate": 1542015364745, "tddate": null, "forum": "HyGySsAct7", "replyto": "r1g3c6VgpX", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "content": {"title": "Author response to reviewer 3", "comment": "Dear reviewer,\n\nThank you for your detailed comments on our paper.\n\n== Response to: \"ask how success rate varies as a function of the initial phrase and target phrase\"\n\nThank you for this insight; we agree this would be useful to see how the attack performs for phrases likely in the general English language.\n\n== Response to: \"the authors should do user studies\"\n\nWe agree that user studies would most effectively verify the efficacy of the attack; however, this would incur significant costs for the authors. In lieu of a human study, the Carlini & Wagner attack measured attack via cross-correlation, and so we use the measure for similarity.\n\n== Response to: \"Table 1 is not useful since either the datasets are different or information is not given on the specific white box attacks.\"\n\nIn Table 1, we attempt to provide a standardized comparison of the previous techniques; naturally, there will be gaps since both are different attack types and attack different models. Since our method is the first to extend black-box attacks to ASR systems, there are no direct previous baselines to compare with. For example, datasets are different since DeepSpeech can accept any input, whereas the classification model can only accept 1-word phrases from the predefined set of classes.\n\n== Response to: \"Does increasing the iterations lead to a higher success rate as claimed at end of page 7?\"\n\nYes it does; we will change the wording to make it less ambiguous and make sure to add a couple extra figures in the final version as verification."}, "signatures": ["ICLR.cc/2019/Conference/Paper52/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621974, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyGySsAct7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper52/Authors|ICLR.cc/2019/Conference/Paper52/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621974}}}, {"id": "ryeSGI6L67", "original": null, "number": 2, "cdate": 1542014476544, "ddate": null, "tcdate": 1542014476544, "tmdate": 1542014476544, "tddate": null, "forum": "HyGySsAct7", "replyto": "B1eLktzOnm", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "content": {"title": "Author response to reviewer 2", "comment": "Dear reviewer,\n\nThank you for your detailed comments on our paper and finding it well written. \n\n== Response to: \"Another issue is this work seems to ignore the recent literature on adversarial black-box attacks to DNN model\"\n\nThank you for providing relevant literature. The first method provided, ZOO [1], is in fact closely related to finite gradient estimation, introduced in [2], which is the method our attack uses in phase 2. As for the second method provided, the paper introduces an attack for hard-label black box settings, where even output logits are not known, and where optimization is much more difficult [3]. In our setting, we assumed output logits are known, and so hard-label methods are not needed, as using output logits make optimization much easier. \n\n== Response to: \"the proposed method is claimed to be a black-box attack but in the end, it actually exploits the fact that the target model uses CTC decoder\"\n\nIn the black-box setting, all that is required is access to the output logits of the model (as specified in Section 1.3). Any loss function that uses the output logits and target phrase could be applied to our method; we chose CTC loss as it is a well-known loss function suited for this task. Thus, the fact that both the training of the victim model and our attack use CTC loss is mostly coincidence.\n\n== Response to: \"The result tends to suggest that this is an attack with low success rate\"; \"why is the attack success rate of the targeted attack success rate of the proposed method is significantly lower than that of the existing system\"\n\nAs stated in Section 1.2, the difficulty of this task comes in attempting to apply black-box optimization to a deeply-layered, highly nonlinear decoder model that has the ability to decode phrases of arbitrary length. We would like to clarify that there has not been an existing black box system for targeting the DeepSpeech model; the black box method in [4] attacks a lightweight classification model, where the model uses a softmax loss to classify between 50 words. The DeepSpeech model is much more complex, namely in that it can decode phrases of arbitrary length, and each output state (50 states per second) of the recurrent structure has a softmax layer, whereas in the classification model there was only one softmax.\n\n== Response to: \"why are the tested method not compared on the same benchmark\"\n\nIn Table 1, we attempt to provide a standardized comparison of the previous techniques; naturally, there will be gaps since both are different attack types and attack different models. Our method is the first to extend black-box attacks to ASR systems; thus, we are aiming to be a baseline on this task, and there are no direct previous baselines to compare with. For example, datasets are different since DeepSpeech can accept any input, whereas the classification model can only accept 1-word phrases.\n\nReferences: \n\nChen, P.-Y.; Zhang, H.; Sharma, Y.; Yi, J.; and Hsieh, C.-J. 2017b.\nZOO: Zeroth-order optimization-based  black-box attacks to deepneural networks without training substitute models. \nIn Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (15-26) ACM\n\nA. Nitin Bhagoji, W. He, B. Li, and D. Song. Exploring the Space of Black-box Attacks on Deep\nNeural Networks. ArXiv e-prints, December 2017.\n\nCheng,  M.;  Le,  T.;  Chen,  P.-Y.;  Yi,  J.;  Zhang,  H.;  and  Hsieh,C.-J.2018.\nQuery-efficient hard-label black-box attack:  An optimization-based approach. arXiv preprint arXiv:1807.04457\n\nM. Alzantot, B. Balaji, and M. Srivastava. Did you hear that? Adversarial Examples Against\nAutomatic Speech Recognition. ArXiv e-prints, January 2018.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper52/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621974, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyGySsAct7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper52/Authors|ICLR.cc/2019/Conference/Paper52/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621974}}}, {"id": "Sklu5t3IaQ", "original": null, "number": 1, "cdate": 1542011280187, "ddate": null, "tcdate": 1542011280187, "tmdate": 1542011280187, "tddate": null, "forum": "HyGySsAct7", "replyto": "SkxXsTqT3m", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "content": {"title": "Author response to reviewer 1", "comment": "Dear reviewer,\n\nThank you for your detailed comments on our paper and finding it of interest. \n\nThe suggestions of various black-box algorithms to use are appreciated, and could promise to generate higher quality adversarial examples. Such extensions would definitely be welcome in future work, as in this paper we attempt to establish a baseline that future methods can compare to."}, "signatures": ["ICLR.cc/2019/Conference/Paper52/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621974, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyGySsAct7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper52/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper52/Authors|ICLR.cc/2019/Conference/Paper52/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers", "ICLR.cc/2019/Conference/Paper52/Authors", "ICLR.cc/2019/Conference/Paper52/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621974}}}, {"id": "r1g3c6VgpX", "original": null, "number": 3, "cdate": 1541586324157, "ddate": null, "tcdate": 1541586324157, "tmdate": 1541586324157, "tddate": null, "forum": "HyGySsAct7", "replyto": "HyGySsAct7", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "content": {"title": "Evaluation is weak", "review": "This paper proposes a black-box attack on multi-word ASR systems.  Most work on black-box attacks have focused on tasks in vision. This work adds to the literature on attac\nks on speech systems. The key novelties are the handling of a loss function over multiple decodings as well as the use of novel genetic algorithms to generate the adversari\nal examples.\n\nA weakness of this paper is that they do not compare to the closely related Alzantot et al. work. While the latter is focused on single word settings and is thus solving an\n easier problem, what would happen if the Alzantot et al. method was applied to each\n\n\nWhile the idea is interesting but incremental, the evaluation of the approach is weak.\n\n1. Insted of choosing random pairs of words as target phrases, it would be interesting to pick phrases that are likely to occur in English and to ask how success rate varie\ns as a function of the initial phrase and target phrase.\n\n2. To confirm that the resulting adversarial examples are similar to audio samples in the original dataset, the authors should do user studies. This is a key component in e\nvaluating the efficacy of such attacks. The cross correlation is useful but does not get at perceptual similarity.\n\n3. Table 1 is not useful since either the datasets are different or information is not given on the specific white box attacks.\n\n4. Does increasing the iterations lead to a higher success rate as claimed at end of page 7?\n\n\nAbstract:\n1. This sentence is misleading : \"Current work..are known\" given the Alzantot et al. work focuses on black-box attacks.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper52/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "cdate": 1542234548778, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyGySsAct7", "replyto": "HyGySsAct7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335638314, "tmdate": 1552335638314, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkxXsTqT3m", "original": null, "number": 2, "cdate": 1541414299315, "ddate": null, "tcdate": 1541414299315, "tmdate": 1541534327522, "tddate": null, "forum": "HyGySsAct7", "replyto": "HyGySsAct7", "invitation": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "content": {"title": "Targeted adversarial examples for black box audio systems", "review": "In \"Targeted adversarial examples for black box audio systems\" the authors look at an adversarial problem in neural nets for audio processing. There is quite a lot of recent interest in adversarial problems in machine learning. That work is mostly on the image side, and so this work is very topical. The problem is to modify an audio signal without changing how it sounds to the human ear, so that it is interpreted as the attacker wishes by the neural network. In the black box approach, the weights of the neural network are not known by the attacker. The attacker however must be able to present modified audio and learn the network's interpretation as often as the attacker wants. This work is very exciting and topical, and of interest to the ICLR community.\n\nThe authors demonstrate a proof of concept using the recent DeepSpeech model, and they connect very well with recent literature on adversarial networks.\n\nThe particular algorithm the authors propose is based on genetic algorithms. I thought that this was a weak part of the paper, because genetic algorithms are quite ad hoc and have few theoretical guarantees when compared to SMC, MCMC, nested sampling or herding, which all do basically the same thing as genetic algorithms. This can lead to loose ends, such as the \"momentum mutation\" introduced by the authors in 2.2, wherein probability of mutation increases as the population fails to adapt. It is true that momentum mutation would avoid local maxima, but it would also take the solution away from global maxima through a sort of \"sampling noise\" (the global maxima is a point at which the population also \"fails to adapt\", as there's no more adaptation to be done). It's unclear if this is a problem, but things like annealed importance sampling also deal with the same problem (or effective sample size of SMC), and they have theory to back them up.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper52/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Targeted Adversarial Examples for Black Box Audio Systems", "abstract": "The application of deep recurrent networks to audio transcription has led to impressive gains in automatic speech recognition (ASR) systems. Many have demonstrated that small adversarial perturbations can fool deep neural networks into incorrectly predicting a specified target with high confidence. Current work on fooling ASR systems have focused on white-box attacks, in which the model architecture and parameters are known. In this paper, we adopt a black-box approach to adversarial generation, combining the approaches of both genetic algorithms and gradient estimation to solve the task. We achieve a 89.25% targeted attack similarity after 3000 generations while maintaining 94.6% audio file similarity.", "paperhash": "taori|targeted_adversarial_examples_for_black_box_audio_systems", "keywords": ["adversarial attack", "adversarial examples", "audio processing", "speech to text", "deep learning", "adversarial audio", "black box", "machine learning"], "authorids": ["rohantaori@berkeley.edu", "amogkamsetty@berkeley.edu", "brentonlongchu@berkeley.edu", "nikitavemuri@berkeley.edu"], "authors": ["Rohan Taori", "Amog Kamsetty", "Brenton Chu", "Nikita Vemuri"], "TL;DR": "We present a novel black-box targeted attack on speech to text systems that supports arbitrarily long adversarial transcriptions and achieves state of the art performance.", "pdf": "/pdf/1d511d4e96a5890caa42c60884c55bfda8ae1cd5.pdf", "_bibtex": "@misc{\ntaori2019targeted,\ntitle={Targeted Adversarial Examples for Black Box Audio Systems},\nauthor={Rohan Taori and Amog Kamsetty and Brenton Chu and Nikita Vemuri},\nyear={2019},\nurl={https://openreview.net/forum?id=HyGySsAct7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper52/Official_Review", "cdate": 1542234548778, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyGySsAct7", "replyto": "HyGySsAct7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper52/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335638314, "tmdate": 1552335638314, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper52/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}