{"notes": [{"id": "SylUiREKvB", "original": "SylgeMFODH", "number": 1319, "cdate": 1569439389537, "ddate": null, "tcdate": 1569439389537, "tmdate": 1577168236743, "tddate": null, "forum": "SylUiREKvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "-QFzvWn3Q2", "original": null, "number": 1, "cdate": 1576798720377, "ddate": null, "tcdate": 1576798720377, "tmdate": 1576800916199, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes a neural network architecture that uses a hypernetwork (RNN or feedforward) to generate weights for a network (variational RNN), that models sequential data. An empirical comparison of a large number of configurations on synthetic and real world data show the promise of this method.\n\nThe authors have been very responsive during the discussion period, and generated many new results to address some reviewer concerns. Apart from one reviewer, the others did not engage in further discussion in response to the authors updating their paper.\n\nThe paper provides a tweak to the hypernetwork idea for modeling sequential data. There are many strong submissions at ICLR this year on RNNs, and the submission in its current state unfortunately does not pass the threshold.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703749, "tmdate": 1576800251188, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Decision"}}}, {"id": "rylIcVsaYH", "original": null, "number": 1, "cdate": 1571824781590, "ddate": null, "tcdate": 1571824781590, "tmdate": 1573897288533, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "This paper proposes the variational hyper RNN (VHRNN), which extends the previous variational RNN (VRNN) by learning the parameters of RNN using a hyper RNN. VRHNN is tested and compared with VRNN on synthetic and real datasets. The authors report superior performance parameter efficiency over VRNN.\n\nThe performance of VHRNN is promising and certainly better than the previous VRNN for some applications. However, the VHRNN is constructed by a straight-forward combination of existing techniques and hence the technical contribution of this paper is marginal.\n\nAlthough Section 4 is entitled as systematic generalization analysis of VHRNN, the reported results are only for the specific structures of VHRNN and VRNN. Isn\u2019t it useless to present results for the VRNN with a latent dimension of 4, at least as a sanity check? \n\nFig. 2 and the texts referring to it discuss the KL divergence between the prior and the variational posterior. While the FIBO is mainly used as the objective in this paper, is the ELBO enough if the authors care the simultaneous low reconstruction error and low KL divergence?\n\nIt is unclear and explained little if the comparison using parameter count is fair for VHRNN and VRNN since they have different structures.\n\nIt would be nicer to discuss for which kind of time-series VRNN is enough.\n\nMinor comments:\nThe caption of Figure 1 is too close to the main texts.\nEq. (4) is overlapping with texts.\nCan the equations at the bottom of p.3 be explained with an illustration?\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575548327962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Reviewers"], "noninvitees": [], "tcdate": 1570237739115, "tmdate": 1575548327978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review"}}}, {"id": "Hkxn7dMhsr", "original": null, "number": 12, "cdate": 1573820452401, "ddate": null, "tcdate": 1573820452401, "tmdate": 1573854225818, "tddate": null, "forum": "SylUiREKvB", "replyto": "HkxATlPrsr", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Response to AnonReviewer1 Update", "comment": "We thank the reviewer for making suggestion on the use of specific wording to avoid confusion. In the updated version of the paper, we used the term \u201cregime identification\u201d to refer to the model\u2019s ability to uncover the underlying patterns of data generation.\n\nWe ran experiments with VHRNN models on JSB Chorale, Stock and the synthetic dataset after replacing the recurrent network with an MLP for $\\theta$ to generate the weights of $g$ and keeping the other components of VHRNN unchanged. We name this variant of VHRNN model VHRNN-MLP and the original VHRNN model VHRNN-RNN. We present the experiment results and comparisons with VHRNN-RNN models with the same latent dimension in a separate responses named \"VHRNN-MLP vs VHRNN-RNN Parameter Performance Comparison \" due to space constraint. We also present systematic generalization study results of VHRNN-MLP in various scenarios of the synthetic dataset in the response named \"VHRNN-MLP vs VHRNN-RNN Systematic Generalization Study Comparison\". The experiment results are also incorporated into Section I of the appendix in the updated version of our paper.\n\nAs we can see, given the same latent dimension, VHRNN-MLP models can have slightly better performance than VHRNN-RNN with more parameters in some cases, VHRNN-MLP performs worse than VHRNN-RNN in more settings. However, the performance of VHRNN-MLP also degrades faster than VHRNN-RNN on the JSB Chorale dataset as the latent dimension increases. Systematic generalization study on the synthetic dataset also shows that VHRNN-MLP has worse performance than VHRNN-RNN no matter in Test setting or in the systematically varied settings.\n\nWe ran experiments using our implementation of HyperLSTM proposed in the original HyperNetworks[1] on JSB Choral and Stock datasets. Compared with VHRNN, HyperLSTM does not have latent variables. It does not have an encoder or decoder either. Our implementation of HyperLSTM is similar to the recurrence model of VHRNN, defined in Equation 1, using LSTM cell. The output distribution is binary for JSB Chorale dataset and a mixture of Gaussian with 5 components for Stock dataset. Experiment results and comparisons against VHRNN are presented in a separate response named \u201cVHRNN and HyperLSTM Comparison\u201d. Since HyperLSTM does not have a latent variable, we compare VHRNN and HyperLSTM in terms of the number of hidden units and the total number of parameters. The number of hidden units in VHRNN and HyperLSTM models is twice the dimension of hidden state as both model contains two RNNs, one primary network and one hyper network. For HyperLSTM models, we report the exact log likelihood and for VHRNN models, we report the FIVO value which is a lower bound of log likelihood. As we can see, the performance of VHRNN completely dominates HyperLSTM no matter what number of hidden units we pick. Actually, the performance of HyperLSTM is even worse than VRNN which indicates the importance of latent variable in modelling complex time-series data. More implementation details and experiment results on HyperLSTM models can be found in Section H of the appendix in the updated version of the paper.\n\nWe will add experiment results of VHRNN-MLP and HyperLSTM models on more datasets and comprehensive comparisons with VHRNN-RNN in future versions. We hope our response answers the reviewer\u2019s questions and satisfies the reviewer\u2019s requests.\n\n[1]Ha, David, Andrew Dai, and Quoc V. Le. \"Hypernetworks.\" arXiv preprint arXiv:1609.09106 (2016)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "SJgwukGhiB", "original": null, "number": 8, "cdate": 1573818222584, "ddate": null, "tcdate": 1573818222584, "tmdate": 1573854063952, "tddate": null, "forum": "SylUiREKvB", "replyto": "Skl0TyPSjH", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Response to AnonReviewer4 Update", "comment": "We thank the reviewer for making suggestion of a related work and recognizing our work\u2019s difference from that one and unique contribution. The latest related work has been added to the Background and Related Work section with a brief discussion on the similarity and difference between their work and ours. We further improved the Model Formulation section by clarifying the definition of all the notations. We showed one implementation of VHRNN\u2019s recurrence model $g$ using LSTM cell in Section 3 in the original submission. We visualize the architecture of this implementation in Section A of the appendix in the updated version of our paper. We hope the diagram could further illustrate this implementation of VHRNN. The readability of the paper is improved after the update with more space between equation, caption and text. We will continue improving the paper\u2019s presentation in future versions. \n\nAs AnnoReviewer1 suggested, we also ran experiments where the hypernetwork for $\\theta$ is replaced by a feed-forward network without temporal structure. The results are presented in the response to AnnoReviewer1. We find that VHRNN models with a feed-forward network for $\\theta$ overall performs slightly worse than VHRNNs with recurrent network for $\\theta$ given the same latent dimension and similar number of parameters. However, in systematic generalization study using the synthetic dataset, we find VHRNN models with a feed-forward network for $\\theta$ uniformly shows worse performance than the VHRNN models with a recurrent network structure in all scenarios. These experiment results further justifies the use of a recurrent network for $\\theta$.\n\nWe hope our response answers the reviewer\u2019s questions and satisfies the reviewer\u2019s requests."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "BJx5jWQ2jS", "original": null, "number": 13, "cdate": 1573822882077, "ddate": null, "tcdate": 1573822882077, "tmdate": 1573853392360, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Summary of Changes to the Paper", "comment": "We thank all the reviewers for their thoughtful comments. Upon the suggestion from the reviewers, we made the following major changes to the content of our paper:\n\n1. We further clarified the definition of notations in Section 3 Model Formulation.\n\n2.  We replaced the term \u201csystem identification\u201d with \u201cregime identification\u201d that refers to the model\u2019s ability to uncover the underlying dynamics of data generation.\n\n3. We added the systematic generalization study results of VRNN models with latent dimension of 4 to Tab. 1\n\n4. We added a diagram of VHRNN\u2019s recurrence model using LSTM cell to better illustrate the implementation of VHRNN in Section A of the appendix.\n\n5. We made performance vs number of hidden units comparisons between VHRNN and VRNN models and added the plots showing the comparison results in Section F of Appendix.\n\n6. We provided more implementation details about the encoder, decoder and prior networks of VHRNN as well as the observation and latent variable encoding networks in the appendix.\n\n7. We compared our VHRNN against HyperLSTM on two real-world datasets and added the comparison results to Section H of the sppendix.\n\n8. We compared our proposed VHRNN model with an variant of VHRNN that has no recurrence structure in the hyper networks. The comparison results and analysis are presented in Section I of the appendix.\n\nWe hope our responses and updated paper satisfactorily addressed the reviewers\u2019 questions and concerns."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "S1gtkwM2ir", "original": null, "number": 11, "cdate": 1573820128967, "ddate": null, "tcdate": 1573820128967, "tmdate": 1573820128967, "tddate": null, "forum": "SylUiREKvB", "replyto": "HkxATlPrsr", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "VHRNN and HyperLSTM Comparison", "comment": "VHRNN vs HyperLSTM Comparison with Same Number of Hidden Units\n+--------------+-------------------+-------------------+--------------+\n| Datasets  | Hidden Units| VHRNN FIVO | HLSTM LL|\n+--------------+-------------------+-------------------+--------------+\n|                   | 24                   | -6.80               | -9.15         |\n+                  +-------------------+-------------------+--------------+\n|                   | 28                   | -6.76                | -8.91        |\n+                  +-------------------+-------------------+--------------+\n|                   | 32                   | -6.81               | -8.87         |\n+                  +-------------------+-------------------+--------------+\n| JSB            | 48                   | -6.86                | -8.94         |\n+                  +-------------------+-------------------+--------------+\n|                  | 64                    | -6.82               | -8.85         |\n+                  +-------------------+-------------------+--------------+\n|                  | 80                    | -6.87               | -8.77         |\n+                  +-------------------+-------------------+--------------+\n|                  | 84                    | -6.90               | -8.77         |\n+--------------+-------------------+-------------------+--------------+\n|                  | 24                    | 9.33                | 8.61           |\n+                  +-------------------+-------------------+--------------+\n|                  | 28                    | 9.34                | 8.44           |\n+ Stock       +-------------------+-------------------+--------------+\n|                  | 32                    | 9.27                | 8.44           |\n+                  +-------------------+-------------------+--------------+\n|                  | 36                    | 9.31                | 8.47           |\n+--------------+-------------------+-------------------+--------------+\n\n                  VHRNN vs HyperLSTM Comparison with Similar Number of Parameters\n+--------------+--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n| Datasets | HLSTM Param.| HLSTM Hidden| VHRNN Param. | VHRNN Hidden | VHRNN FIVO | HLSTM LL|\n+--------------+--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n|                  | 29k                    | 48                       | 27k                     | 24                         | -6.80                | -8.94      |\n+                  +--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n| JSB           | 82k                    | 84                        | 88k                     | 64                        | -6.81                | -8.77      |\n+                  +--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n|                  | 124k                  | 104                     | 125k                   | 88                         | -6.87               | -8.85      |\n+--------------+--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n|                  | 15k                    | 36                       | 16k                      | 24                         | 9.33                | 8.47       |\n+ Stock       +--------------------+----------------------+----------------------+-----------------------+-------------------+------------+\n|                  | 26k                    | 48                       | 23k                      | 32                         | 9.27                | 8.51       |\n+--------------+--------------------+----------------------+----------------------+-----------------------+-------------------+------------+"}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "B1eYrNz2sS", "original": null, "number": 10, "cdate": 1573819457004, "ddate": null, "tcdate": 1573819457004, "tmdate": 1573819477911, "tddate": null, "forum": "SylUiREKvB", "replyto": "HkxATlPrsr", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "VHRNN-MLP vs VHRNN-RNN Systematic Generalization Study Comparison", "comment": "            VHRNN-MLP vs VHRNN-RNN Systematic Generalization Study Comparison\n+------------------+----------+------------+-------+-----------------+-------------+----------+------------+------------------+---------+\n| Model           | Z Dim. | Param. | Test  | NOISELESS | SWITCH | RAND  | LONG    | ZERO-SHOT | ADD   |\n+------------------+----------+------------+-------+-----------------+-------------+----------+------------+------------------+---------+\n| VHRNN-MLP| 4          | 1676      | -5.13 | -2.73            | -5.22      | -4.12    | -604937 | -2.94             | -3.84  |\n+------------------+----------+------------+-------+-----------------+-------------+----------+------------+------------------+---------+\n| VHRNN-RNN| 4         | 1568      | -4.68 | -2.08            | -4.27       | -3.91    | -3005     | -2.57             | -2.62  |\n+------------------+----------+------------+-------+-----------------+-------------+----------+------------+------------------+---------+\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "BklLq7Mnsr", "original": null, "number": 9, "cdate": 1573819278495, "ddate": null, "tcdate": 1573819278495, "tmdate": 1573819278495, "tddate": null, "forum": "SylUiREKvB", "replyto": "HkxATlPrsr", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "VHRNN-MLP vs VHRNN-RNN Parameter Performance Comparison", "comment": "                VHRNN-MLP vs VHRNN-RNN Parameter Performance Comparison\n+-------------+----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n| Datasets| Z Dim. | VHRNN-MLP Param. | VHRNN-RNN Param.| VHRNN-MLP FIVO | VHRNN-RNN FIVO |\n+-------------+----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 12        | 28k                               | 27k                               | -6.83                        | -6.80                         |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 14        | 32k                               | 31k                               | -6.73                        | -6.76                         |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 16        | 37k                               | 35k                               | -6.76                        | -6.81                         |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n| JSB          | 24        | 62k                               | 58k                               | -6.83                        | -6.86                          |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 32        | 94k                               | 88k                               | -7.13                        | -6.82                         |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 40        | 135k                             | 125k                            | -7.08                         | -6.87                         |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 42        | 146k                             | 135k                            | -7.02                         | -6.90                         |\n+-------------+----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 12        | 16k                               | 16k                              | 9.47                          | 9.33                           |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 14        | 19k                               | 18k                              | 9.21                          | 9.34                           |\n+ Stock      +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 16        | 24k                               | 23k                              | 9.31                          | 9.27                           |\n+                 +----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n|                 | 18         | 29k                              | 28k                              | 9.19                          | 9.31                           |\n+-------------+----------+-----------------------------+-----------------------------+--------------------------+---------------------------+\n| Syn-Test | 4          | 1676                            | 1568                             | -5.13                        | -4.68                          |\n+-------------+----------+-----------------------------+-----------------------------+--------------------------+---------------------------+"}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "SylsiWDSoS", "original": null, "number": 5, "cdate": 1573380515078, "ddate": null, "tcdate": 1573380515078, "tmdate": 1573380515078, "tddate": null, "forum": "SylUiREKvB", "replyto": "rylIcVsaYH", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "We would like to thank the reviewer for providing thoughtful comments and suggestions on improving the presentation of the paper. The suggested improvements of the paper\u2019s presentation will be addressed in the next updated version of the paper. \n\nThe reviewer acknowledged that VHRNN models show better performance than the VRNN models by combining the VHRNN with hyper networks. However, the motivation of our work is to better handle complex variabilities within and across sequences in time-series data by dynamically changing the model\u2019s weights based on observations. Hypernetwork is a commonly adopted class of networks with dynamically generated weights. We connect dynamic weight generation with hypernetwork with variational Bayes method for sequence modeling to fulfill this task. We trained our model with the FIVO objective because it is based on the well-studied particle filtering algorithm with good properties like tighter bound and smaller variance. The design choices not only result in a better performance of VHRNN models than VRNN but also enables VHRNNs to perform change detection at inference time and generalize to unseen dynamics. In contrast, VRNN models without dynamically generated weights failed on these tasks. The well-motivated composition of existing modules that results in better performance is a scientific contribution. \n\nQuestion:\nWhile the FIBO is mainly used as the objective in this paper, is the ELBO enough if the authors care the simultaneous low reconstruction error and low KL divergence?\nAnswer:\nWe use FIVO instead of ELBO for training and evaluating our models due to the advantages of FIVO over ELBO and fair comparison with previous works. The objective of our model is to maximize a variational lower bound of the data log-likelihood. FIVO is a tighter variational lower bound than ELBO with a smaller variance based on a well-studied particle filtering algorithm. Previous work [1] using VRNN trained and evaluated by FIVO demonstrates the state-of-the-art results for modeling time-series with latent variable models on various settings.\n\nQuestion: It is unclear and explained little if the comparison using parameter count is fair for VHRNN and VRNN since they have different structures.\nAnswer: \nWe acknowledge that it is difficult to define and compare the complexities of VHRNN and VRNN models because of the structural difference between them. However, the number of parameters is a widely adopted surrogate of model complexity of deep neural network and often used in the study of models\u2019 parameter-performance efficiency[2]. We also show an additional plot of FIVO vs the number of hidden units in the current updated version in the appendix. We can see that VHRNN also dominates the performance of VRNN with a similar or fewer number of hidden units in most of the settings. Furthermore, the fact that VHRNN almost always outperforms VRNN for all parameter or hidden unit sizes precisely shows the superiority of the new architecture. \n\nQuestion: It would be nicer to discuss for which kind of time-series VRNN is enough.\nAnswer: \nThe experimental results on HT sensor dataset show that the VRNN model achieves comparable performance as VHRNN with a similar number of parameters. In contrast, VHRNN consistently outperforms VRNN on JSB Chorale dataset. It\u2019s worth noting that in comparison with JSB Chorale dataset, HT Sensor has simpler data generation dynamics (there are only three types of stimulus applied to the sensors, white noise, alcohol, and banana) and the dataset size of HT sensor is much larger than JSB Chorale. So we believe VRNN models given enough capacity might perform as well as VHRNN on time series data with relatively simple data generation pattern and enough training data.However, for datasets with more complex patterns, VHRNN would be a more suitable model.\n\nWe will update the response with the experimental results of VRNN with a latent dimension of 4 on the synthetic dataset as soon as possible and add a figure to illustrate equations in Section 3 in the upcoming version of our paper. Please reconsider the rating if we have satisfactorily answered the reviewer's questions. We are happy to answer any further questions the reviewer might have.\n\n[1] Maddison, Chris J., et al. \"Filtering variational objectives.\" Advances in Neural Information Processing Systems. 2017.\n[2] Huang, Gao, et al. \"Densely connected convolutional networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "HkxATlPrsr", "original": null, "number": 4, "cdate": 1573380294189, "ddate": null, "tcdate": 1573380294189, "tmdate": 1573380317301, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylW2nrRtS", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "We would like to thank the reviewer for providing thoughtful comments. The reviewer recognized that our proposed models consistently outperform the state-of-the-art VRNN models with fewer parameters on both synthetic and real-world data. However, the motivation of our work is to better handle complex variabilities within and across sequences in time-series data by dynamically changing the model\u2019s weights based on observations. Hypernetwork is the class of models of natural choice to handle dynamic weight generation. Our work introduces the idea of dynamic weight generation into the study of sequence modeling with variational Bayesian methods to achieve the goal. Our proposed models are trained with the state-of-the-art FIVO objective based on the well-studied particle filtering algorithm. Dynamic weight generation not only results in the better performance of VHRNN models then VRNN but enables VHRNNs to perform change detection at inference time and generalize to unseen dynamics. In contrast, VRNN models without dynamically generated weights failed on these tasks. The use of existing modules in our work is well motivated and it results in the advantage and superior performance of our model over VRNN.\n\nWe will modify the wording  of ``System Identification\u2019\u2019 in the next updated version of our paper and update this response with more experiment results as soon as possible. We are also willing to answer any further questions the reviewer might have."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "Skl0TyPSjH", "original": null, "number": 3, "cdate": 1573380038089, "ddate": null, "tcdate": 1573380038089, "tmdate": 1573380038089, "tddate": null, "forum": "SylUiREKvB", "replyto": "Bkl7IVhBqS", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment", "content": {"title": "Response to AnonReviewer4", "comment": "We would like to thank the reviewer for recognizing the contributions of our work and making suggestions on the presentation of the paper. We completely agree that adding a figure showing the architecture of hyper LSTM and better clarifying the definition of notations would be helpful to the readers. They will be incorporated into the next updated version of our paper soon. We will also improve the presentation, cite existing related works and add more experiment details in the next version. We are willing to answer any further questions the reviewer might have.\n\nQuestion: Why the hyper-network for \\phi is feedforward but the one for \\theta is RNN?\nAnswer: \nAs the generation of both samples and network weights is determined by the latent variable and hidden states, we assume that they encode information about the current underlying dynamics or patterns of data generation. Therefore, we can use the latest latent variable and hidden state with a feed-forward network to determine the weights of the decoder $\\phi$ that generates the observation for one step. Meanwhile, we would like to explicitly keeping track of the history of data generation dynamics for the hyper network. We believe it could better help the hyper network to produce weights that can adapt to the change between the old dynamic and the new one. Moreover, the design of hyper networks that uses an RNN to generate the weights of another RNN has been well studied in the original HyperNetworks and demonstrates promising performance on many tasks. Thus, we use another RNN as the hyper network to generate the weights $\\theta$ of the primary RNN. It takes the latent variable and the previous hidden state from the primary RNN as input.\n\nQuestion: How many LSTM units are in the model in each experiments? Are they similar in both VHRNN and VRNN?\nAnswer: \nThe hidden state dimension of each LSTM network in the paper is the same as the latent variable dimension except for the ablation study section. However, it\u2019s worth noting that VHRNN contains two LSTM networks, the primary network and the hyper network.  They have the same number of hidden units unless otherwise mentioned. Therefore, the number of hidden units in a VHRNN model is twice the number of latent dimension. We used one-layer LSTM for both VHRNN and VRNN models. In the current updated version of our paper, we also show plots of FIVO vs number of hidden units for VRNN and VHRNN models in Section E of the appendix. We can see that VHRNN also dominates the performance of VRNN with a similar or fewer number of hidden units in most of the settings.\n\nQuestion: What is the structure of encoder/decoder layers? How many units in each layer? Are they the same for VHRNN and VRNN?\nAnswer: \nWe follow similar principles as the original Variational RNN paper when designing the encoder and decoder. The architecture of the encoder defined in Equation 5 is the same for VHRNN and VRNN. For synthetic datasets, we used a fully connected network with two hidden layers; each has the same number of units as the latent variable dimension. For other real-world datasets, we use a fully connected network with one hidden layer with the same number of units as the latent dimension.\nFor VHRNN models, we use fully connected hyper networks with two hidden layers for synthetic data and fully-connected hyper networks with one hidden layer for other datasets as the decoder networks. The number of units in each hidden layer is also the same as the latent variable. For VRNN models, we use plain feed-forward networks for decoder. The number of hidden layers and units in the hidden layer are determined in the same way as VHRNN models.\nWe will add the experiment details for different settings in the next version of our paper.\n\nQuestion: There are four sets of weights in the primary model: weights of RNN, dec, enc, prior. How are these weights generated by the two hyper-networks \\theta and w?\nAnswer:  \nThe weights of the RNN and encoder are dynamically generated while the weights of the encoder and prior networks are fixed. $\\omega$ denotes the weight of the decoder. For each layer of the decoder, we generate the bias and a scaling vector that scales each row of the weight matrix using a two-layer MLP (hyper network). $\\theta$ denotes the weight of the RNN part of our model. At each time step, we generate the bias vectors and row-scaling vectors for all weight matrices of the primary RNN by directly mapping from the hidden state of the hyper RNN via linear transformations.\n\nQuestion: How is the number of parameters in the experiment calculated. Do they refer to the number of parameters in the hypernetworks only?\nAnswer: \nThe number of parameters reflects the total number of trainable parameters of the model, including the RNN, prior network, the encoder which proposes the variational posterior distribution and the decoder. For VHRNN, the parameter counts of the RNN and the decoder include both the primary network and the hyper network."}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylUiREKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1319/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1319/Authors|ICLR.cc/2020/Conference/Paper1319/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157825, "tmdate": 1576860552544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Authors", "ICLR.cc/2020/Conference/Paper1319/Reviewers", "ICLR.cc/2020/Conference/Paper1319/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Comment"}}}, {"id": "SylW2nrRtS", "original": null, "number": 2, "cdate": 1571867816635, "ddate": null, "tcdate": 1571867816635, "tmdate": 1572972484286, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a variational hyper recurrent neural network which is a combination of the variational RNN and the hypernetwork. The hypernetwork is an RNN whose output modifies the parameters of the variational RNN dynamically at runtime. Overall, this seems like an extension of the idea of using a hypernetwork with the VRNN (rather than the RNN as done in Ha. et. al). The model is trained via the FIVO objective. The model and learning algorithm are compared to the variational RNN and tested on a variety of synthetic settings where the VHRNN outperforms the VRNN in held-out likelihood. The performance gains are investigated on synthetic datasets where the paper notes that the VHRNN is often quicker to adapt variations that happen within seqences (for example, the paper considers a dataset where multiple patterns are stitched together into a sequence and study the changes in the KL divergence and reconstruction at switch points). On four real-world sequential datasets, the paper finds that the model outperforms the VRNN across many configurations and with a fewer number of parameters.\n\nSummary: I don't think the model presented here is very novel, in that it is a combination of existing ideas; however, the paper does a good job of studying the model in a variety of different configurations on both synthetic and real-world data. The model does appear to consistently outperform the Variational RNN of Chung et. al.\n\nQuestions and comments:\n(a) I do not think the word \"System Identification\" should be used on page 5 to describe the results of Figure 2. Doing so would overload existing notation in the time series literature where the word refers to the identification of parameters under a pre-specified physical system.\n(b) How well does the Recurrent Hyper network (with no latent variable) do on the tasks considered here? I understand that it may be a less expressive model in general, but it is not clear to me why it would not be a competitive baseline on some of the smaller datasets considered here -- was this baseline tried?\n(c) Did you experiment with non-temporal architectures for the hypernetwork? Since z_t and h_t-1 (which are conditioned on) contain information about the history of the sequence, one might argue that conditioning on them might suffice to predict the modifications to the parameters of the theta and g.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575548327962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Reviewers"], "noninvitees": [], "tcdate": 1570237739115, "tmdate": 1575548327978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review"}}}, {"id": "Bkl7IVhBqS", "original": null, "number": 3, "cdate": 1572353098527, "ddate": null, "tcdate": 1572353098527, "tmdate": 1572972484241, "tddate": null, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "invitation": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "In this paper the authors propose an architecture based on variational autoencoders and hyper-networks. The basic idea is that the weights of the underlying RNN/autoencoder are not fixed, but are coming from another RNN/feed-forward network which captures the underlying dynamics and adjusts the weights accordingly. The experimental results show the benefit of the model compared to a similar method without hypernets.\n \nIn terms of novelty, the combination of auto-encoder RNNs and hyper-networks is not entirely novel and it has previously been developed (https://www.biorxiv.org/content/10.1101/658252v1). However, while I think these previous works should be discussed in the paper (they are not currently), the two architectures are sufficiently different and the current work is novel enough in my opinion. On the other hand, in terms of presentation, I think the paper can be improved. The architecture is not entirely clear from the text. I think a graph showing the architecture of the model would be very helpful here. The notations also seem loosely defined (what is the dimensionality of x_t, z_t, etc.) and sometimes undefined (e.g., x_t in equation 1 is not defined).  \n \nIn terms of model architecture, it wasn\u2019t clear for me why the hyper-network for \\phi is feedforward but the one for \\theta is RNN?\n \nThe experiments seem promising, but I have the following questions before being able to assess the results:\n \n- How many LSTM units are in the model in each experiment? Are they similar in both VHRNN and VRNN?\n \n- What is the structure of encoder/decoder layers? How many units in each layer? Are they the same for VHRNN and VRNN?\n \n-There are four sets of weights in the primary model: weights of RNN, dec, enc, prior. How are these weights generated by the two hyper-networks \\theta and w?\n \n- How is the number of parameters in the experiment calculated. Do they refer to the number of parameters in the hypernetworks only?\n \n \nMinor:\nI suspect the spaces between the equations and captions are also manually changed which has made the paper physically dense and a bit unreadable (see equation 4 for example). Similarly, the space between the caption of Figure 1 and the text after seems too small.\n \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1319/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Hyper RNN for Sequence Modeling", "authors": ["Ruizhi Deng", "Yanshuai Cao", "Bo Chang", "Leonid Sigal", "Greg Mori", "Marcus Brubaker"], "authorids": ["ruizhid@sfu.ca", "yanshuaicao@gmail.com", "bchang@stat.ubc.ca", "lsigal@cs.ubc.ca", "mori@cs.sfu.ca", "marcus.brubaker@borealisai.com"], "keywords": ["variational autoencoder", "hypernetwork", "recurrent neural network", "time series"], "TL;DR": "We propose a novel probabilistic sequence model that excels at capturing high variability in time series data using hypernetworks.", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "pdf": "/pdf/93f90e0957e0c16587617a33a124a46db9f2a256.pdf", "paperhash": "deng|variational_hyper_rnn_for_sequence_modeling", "original_pdf": "/attachment/221a22d1286cda27aa63d2f56a021a0904e99777.pdf", "_bibtex": "@misc{\ndeng2020variational,\ntitle={Variational Hyper {\\{}RNN{\\}} for Sequence Modeling},\nauthor={Ruizhi Deng and Yanshuai Cao and Bo Chang and Leonid Sigal and Greg Mori and Marcus Brubaker},\nyear={2020},\nurl={https://openreview.net/forum?id=SylUiREKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylUiREKvB", "replyto": "SylUiREKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1319/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575548327962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1319/Reviewers"], "noninvitees": [], "tcdate": 1570237739115, "tmdate": 1575548327978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1319/-/Official_Review"}}}], "count": 14}