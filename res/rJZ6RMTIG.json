{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521582983587, "tcdate": 1519732355405, "number": 1, "cdate": 1519732355405, "id": "BJsKIazuz", "invitation": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "signatures": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer3"], "content": {"title": "Incremental impact, experiments are unclear", "rating": "3: Clear rejection", "review": "The paper suggests to use log geomentric mean as debugging tool when training DNNs. However I have several major concerns on it:\n1. The idea of using geomentric mean of the weights is quite straightforward and doubtfully can serve a topic for the research paper.\n2. The exeriments description is very unclear. It is obvious how the geomentric mean can by used for debugging. The authors claim that the geometric mean should vary within narrow interval otherwise something is wrong. However no experiemntal evidence is provided.\n3. The range of log geometric range seems strange. It contains zero in all three cases hence the geometric mean for the weights is abuot one which is weird.\n\nI think the impact of the paper is quite low and the experimental description is insufficient.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Empirical Study of Weights in Deep Convolutional Neural Networks and Its Application to Training Convergence", "abstract": "This paper presents an empirical study of weights in deep neural networks and propose a quantitative metric, Logarithmical Geometric Mean of absolute weight parameter (LoGM), to evaluate the impact of weight on training convergence. We develop an automatic tool to measure LoGM and conduct extensive experiments on ImageNet with three well-known deep convolutional neural networks (CNNs). We discover two empirical observations from the experiments on same model: 1) LoGM variance is small between weight snapshots per iteration; and 2) each CNN model has a reasonable divergence region. Preliminary results show our methodology is effective with convergence problem exposure time reduction from weeks to minutes. Three known convergence issues are confirmed and one new problem is detected at early stage of feature development. To the best of our knowledge, our work is first attempt to understand the impact of weight on convergence. We believe that our methodology is general and applicable on all deep learning frameworks. The code and training snapshots will be made publicly available.", "pdf": "/pdf/0a3596b2321897bbd5d65e8d14017523542690fe.pdf", "TL;DR": "A quantitative approach to detecting convergence problem within minimal iterations for CNN training", "paperhash": "shen|an_empirical_study_of_weights_in_deep_convolutional_neural_networks_and_its_application_to_training_convergence", "keywords": ["Deep Neural Networks", "Quantitative Metric", "Convergence", "Divergence Region"], "authors": ["Haihao Shen", "Jiong Gong", "Jianhui Li", "Xiaoli Liu", "Xinan Lin"], "authorids": ["haihao.shen@intel.com", "jiong.gong@intel.com", "jianhui.li@intel.com", "xiaoli.liu@intel.com", "xinan.lin@intel.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582983391, "id": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper62/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer1"], "reply": {"forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582983391}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582868825, "tcdate": 1520553903621, "number": 2, "cdate": 1520553903621, "id": "S1_3y8JFz", "invitation": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "signatures": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer2"], "content": {"title": "The paper is quite confusing.", "rating": "4: Ok but not good enough - rejection", "review": "I like the idea to study the weights in deep neural networks. But the intuition of this paper is very unclear. I think the author could remove section 2.1 to put more experimental results. The observations are not clear. For example,observation 1 claims that \"LoGM variance is small between snapshots per iteration\", which is hard to understand. And the author should define the quantity of \"small\" by showing the normal range of LoGM in the whole training process. Observation 2 needs to properly define the \"divergence region\". In addition, conclusions drawn by having three networks trained on a single dataset seems unconvincing.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Empirical Study of Weights in Deep Convolutional Neural Networks and Its Application to Training Convergence", "abstract": "This paper presents an empirical study of weights in deep neural networks and propose a quantitative metric, Logarithmical Geometric Mean of absolute weight parameter (LoGM), to evaluate the impact of weight on training convergence. We develop an automatic tool to measure LoGM and conduct extensive experiments on ImageNet with three well-known deep convolutional neural networks (CNNs). We discover two empirical observations from the experiments on same model: 1) LoGM variance is small between weight snapshots per iteration; and 2) each CNN model has a reasonable divergence region. Preliminary results show our methodology is effective with convergence problem exposure time reduction from weeks to minutes. Three known convergence issues are confirmed and one new problem is detected at early stage of feature development. To the best of our knowledge, our work is first attempt to understand the impact of weight on convergence. We believe that our methodology is general and applicable on all deep learning frameworks. The code and training snapshots will be made publicly available.", "pdf": "/pdf/0a3596b2321897bbd5d65e8d14017523542690fe.pdf", "TL;DR": "A quantitative approach to detecting convergence problem within minimal iterations for CNN training", "paperhash": "shen|an_empirical_study_of_weights_in_deep_convolutional_neural_networks_and_its_application_to_training_convergence", "keywords": ["Deep Neural Networks", "Quantitative Metric", "Convergence", "Divergence Region"], "authors": ["Haihao Shen", "Jiong Gong", "Jianhui Li", "Xiaoli Liu", "Xinan Lin"], "authorids": ["haihao.shen@intel.com", "jiong.gong@intel.com", "jianhui.li@intel.com", "xiaoli.liu@intel.com", "xinan.lin@intel.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582983391, "id": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper62/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer1"], "reply": {"forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582983391}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582771340, "tcdate": 1520637294016, "number": 3, "cdate": 1520637294016, "id": "S18Or9lFG", "invitation": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "signatures": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer1"], "content": {"title": "Quantitative metric to detect convergence problems in CNN training", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes a metric called LoGM to evaluate the evolution of the CNN weight during the training. The authors claim that LoGM can be used to detect convergence problems in the CNN training.\n\nThe paper is confusing and hard to understand.  There are different aspects that are unclear. For example:\n\n- Authors state that \"the problems in the convergence of CNN training can be due to obtining 'not a number' in the evaluation of the loss function, or due to the fact of non obtaining state-of-the-art accuracy\". I think this is an unfounded simplification. For example, the problem could be also the batch size, among others.\n\n- LoGM is defined as the average log of the CNN weigths. What is the intuitive idea behind this measure? Algorithm 1 is unnecessary.\n\n- Figure 1 is not properly discussed. In my opinion these results (and also the results of Table 1) do not show the potential of the metric.\n\n- In section 3.2. states \"We apply the divrgence region in real applications with 3 issues confirmed and 1 new detected\". I do not know what this means in the context of the paper.\n\n- Authors mention often the concept \"reasonable divergence region\", but the term is not properly defined or discussed.\n\nI think this paper is not clear. The work pretends to make an observation but, from my viewpoint, it is not solid enough to be published.\n \n\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Empirical Study of Weights in Deep Convolutional Neural Networks and Its Application to Training Convergence", "abstract": "This paper presents an empirical study of weights in deep neural networks and propose a quantitative metric, Logarithmical Geometric Mean of absolute weight parameter (LoGM), to evaluate the impact of weight on training convergence. We develop an automatic tool to measure LoGM and conduct extensive experiments on ImageNet with three well-known deep convolutional neural networks (CNNs). We discover two empirical observations from the experiments on same model: 1) LoGM variance is small between weight snapshots per iteration; and 2) each CNN model has a reasonable divergence region. Preliminary results show our methodology is effective with convergence problem exposure time reduction from weeks to minutes. Three known convergence issues are confirmed and one new problem is detected at early stage of feature development. To the best of our knowledge, our work is first attempt to understand the impact of weight on convergence. We believe that our methodology is general and applicable on all deep learning frameworks. The code and training snapshots will be made publicly available.", "pdf": "/pdf/0a3596b2321897bbd5d65e8d14017523542690fe.pdf", "TL;DR": "A quantitative approach to detecting convergence problem within minimal iterations for CNN training", "paperhash": "shen|an_empirical_study_of_weights_in_deep_convolutional_neural_networks_and_its_application_to_training_convergence", "keywords": ["Deep Neural Networks", "Quantitative Metric", "Convergence", "Divergence Region"], "authors": ["Haihao Shen", "Jiong Gong", "Jianhui Li", "Xiaoli Liu", "Xinan Lin"], "authorids": ["haihao.shen@intel.com", "jiong.gong@intel.com", "jianhui.li@intel.com", "xiaoli.liu@intel.com", "xinan.lin@intel.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582983391, "id": "ICLR.cc/2018/Workshop/-/Paper62/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper62/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper62/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper62/AnonReviewer1"], "reply": {"forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper62/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582983391}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573601047, "tcdate": 1521573601047, "number": 243, "cdate": 1521573600710, "id": "rktk11k9z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rJZ6RMTIG", "replyto": "rJZ6RMTIG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Empirical Study of Weights in Deep Convolutional Neural Networks and Its Application to Training Convergence", "abstract": "This paper presents an empirical study of weights in deep neural networks and propose a quantitative metric, Logarithmical Geometric Mean of absolute weight parameter (LoGM), to evaluate the impact of weight on training convergence. We develop an automatic tool to measure LoGM and conduct extensive experiments on ImageNet with three well-known deep convolutional neural networks (CNNs). We discover two empirical observations from the experiments on same model: 1) LoGM variance is small between weight snapshots per iteration; and 2) each CNN model has a reasonable divergence region. Preliminary results show our methodology is effective with convergence problem exposure time reduction from weeks to minutes. Three known convergence issues are confirmed and one new problem is detected at early stage of feature development. To the best of our knowledge, our work is first attempt to understand the impact of weight on convergence. We believe that our methodology is general and applicable on all deep learning frameworks. The code and training snapshots will be made publicly available.", "pdf": "/pdf/0a3596b2321897bbd5d65e8d14017523542690fe.pdf", "TL;DR": "A quantitative approach to detecting convergence problem within minimal iterations for CNN training", "paperhash": "shen|an_empirical_study_of_weights_in_deep_convolutional_neural_networks_and_its_application_to_training_convergence", "keywords": ["Deep Neural Networks", "Quantitative Metric", "Convergence", "Divergence Region"], "authors": ["Haihao Shen", "Jiong Gong", "Jianhui Li", "Xiaoli Liu", "Xinan Lin"], "authorids": ["haihao.shen@intel.com", "jiong.gong@intel.com", "jianhui.li@intel.com", "xiaoli.liu@intel.com", "xinan.lin@intel.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518313145265, "tcdate": 1518313145265, "number": 62, "cdate": 1518313145265, "id": "rJZ6RMTIG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rJZ6RMTIG", "signatures": ["~Haihao_Shen1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "An Empirical Study of Weights in Deep Convolutional Neural Networks and Its Application to Training Convergence", "abstract": "This paper presents an empirical study of weights in deep neural networks and propose a quantitative metric, Logarithmical Geometric Mean of absolute weight parameter (LoGM), to evaluate the impact of weight on training convergence. We develop an automatic tool to measure LoGM and conduct extensive experiments on ImageNet with three well-known deep convolutional neural networks (CNNs). We discover two empirical observations from the experiments on same model: 1) LoGM variance is small between weight snapshots per iteration; and 2) each CNN model has a reasonable divergence region. Preliminary results show our methodology is effective with convergence problem exposure time reduction from weeks to minutes. Three known convergence issues are confirmed and one new problem is detected at early stage of feature development. To the best of our knowledge, our work is first attempt to understand the impact of weight on convergence. We believe that our methodology is general and applicable on all deep learning frameworks. The code and training snapshots will be made publicly available.", "pdf": "/pdf/0a3596b2321897bbd5d65e8d14017523542690fe.pdf", "TL;DR": "A quantitative approach to detecting convergence problem within minimal iterations for CNN training", "paperhash": "shen|an_empirical_study_of_weights_in_deep_convolutional_neural_networks_and_its_application_to_training_convergence", "keywords": ["Deep Neural Networks", "Quantitative Metric", "Convergence", "Divergence Region"], "authors": ["Haihao Shen", "Jiong Gong", "Jianhui Li", "Xiaoli Liu", "Xinan Lin"], "authorids": ["haihao.shen@intel.com", "jiong.gong@intel.com", "jianhui.li@intel.com", "xiaoli.liu@intel.com", "xinan.lin@intel.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 5}