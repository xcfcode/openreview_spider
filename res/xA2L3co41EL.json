{"notes": [{"id": "xA2L3co41EL", "original": "tAEoDwFYMTr", "number": 33, "cdate": 1615310255078, "ddate": null, "tcdate": 1615310255078, "tmdate": 1615313024774, "tddate": null, "forum": "xA2L3co41EL", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/SSL-RL/-/Blind_Submission", "content": {"title": "Critic-Guided Learning to Segment Rewarding Objects in First-Person Views", "authorids": ["ICLR.cc/2021/Workshop/SSL-RL/Paper33/Authors"], "authors": ["Anonymous"], "keywords": ["self-supervision", "Reinforcement Learning", "auxiliary targets", "generalization", "U-Net"], "TL;DR": "We train a U-Net model to generate masks over reward-related objects in images. Our approach allows training the U-Net model without explicit label information, but only using feedback from a critic model trained using a DRL technique.", "abstract": "We train a U-Net model to generate masks over reward-related objects in images. Our approach allows to train the U-Net model without explicit label information, but only using feedback from a critic model which learned to estimate the expected-reward value of an image observation. The masking is learned in contrastive fashion with image pairs using an adversarial scheme for employing the critic score gradient with respect to the mask operation: The pair consists of two images, where the first has a high and the second a low critic value. Training with such pairs enables the U-Net model to produce masks that decrease the critic value in the first image and increase the critic value in the second image when transferring pixels in the masked segment from the first to the second image. The training of the U-Net model is based on an imitation database from the NeurIPS 2020 MineRL Competition Track, where our agent took the ?-place winning entry. Video demonstration: www.rebrand.ly/Rewarding-Objects-mp4", "pdf": "/pdf/52491e0fd7f090d763a027c034e60b551db8085a.pdf", "paperhash": "anonymous|criticguided_learning_to_segment_rewarding_objects_in_firstperson_views", "_bibtex": "@inproceedings{\nanonymous2021criticguided,\ntitle={Critic-Guided Learning to Segment Rewarding Objects in First-Person Views},\nauthor={Anonymous},\nbooktitle={Submitted to Self-Supervision for Reinforcement Learning Workshop - ICLR 2021},\nyear={2021},\nurl={https://openreview.net/forum?id=xA2L3co41EL},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/SSL-RL"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/SSL-RL"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/SSL-RL"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/SSL-RL"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/SSL-RL"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/SSL-RL"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615310247528, "tmdate": 1615313016556, "id": "ICLR.cc/2021/Workshop/SSL-RL/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}