{"notes": [{"id": "rkxDoJBYPB", "original": "SkeGjCAdDr", "number": 1918, "cdate": 1569439647025, "ddate": null, "tcdate": 1569439647025, "tmdate": 1583912042302, "tddate": null, "forum": "rkxDoJBYPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "FdwJq_Jl-P", "original": null, "number": 1, "cdate": 1576798735891, "ddate": null, "tcdate": 1576798735891, "tmdate": 1576800900478, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The submission presents an approach that leverages machine learning to optimize the placement and scheduling of computation graphs (such as TensorFlow graphs) by a compiler. The work is interesting and well-executed. All reviewers recommend accepting the paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708531, "tmdate": 1576800256979, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Decision"}}}, {"id": "HJxVQ5MnjH", "original": null, "number": 4, "cdate": 1573820955874, "ddate": null, "tcdate": 1573820955874, "tmdate": 1573820955874, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "S1xv-cfhsH", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment", "content": {"title": "Continuation", "comment": "> - Could the authors clarify why the two methods mentioned in \u201cLearning to directly predict a solution\u201d has quadratic complexity w.r.t. # of nodes and whereas REGEL is linear?\n\nLet n be the number of nodes in the input graph for which placement and scheduling decisions need to be predicted. Predicting the decisions with an autoregressive model will need O(n) steps, where each step involves performing inference on the graph neural network. Since a single inference pass on the GNN has at least O(n) cost, the total prediction cost scales as O(n^2). We also experimented with a non-autoregressive approach for predicting the decisions that has O(n) total cost, but the results were significantly worse. REGAL performs a single inference pass on the GNN, so it has O(n) cost.\n\n> - Confusion on Figure 4(b): Could some more critical statistics about the graphs in the training/test dataset be reported? e.g. what\u2019s the average depth of the training graphs? When there are 32 MP layers a node\u2019s feature will be passed across its 32-hop neighborhood, which seems surprising as it is common to observe GNN starts degenerating with increased depth \u2026\n\nWe added Figure 6 in the appendix to show the distribution of the diameters of graphs in our dataset.\n\nWe do observe a plateau of GNN performance with increased depth (as reported in Figure 4(b)), but no significant drop with large depth.  In principle, even when the number of layers is larger than the graph diameter, the GNN can still use the additional layers to do more computation, which can be helpful for making predictions.  [Selsam et al. (2019)] (https://arxiv.org/abs/1802.03685 ) shows an extreme example of this where 1000 message passing layers were used in GNNs to make predictions on graphs with much less number of nodes, and improved performance was reported with increased number of message passing layers even up to 1000.  Training GNNs with large depth may be more challenging than training shallower GNNs, but various techniques can be applied to make this easier, e.g. adding GRU / LSTM-style gating or residual connections. Overall we did not experience the degeneration at 32 message passing layers that the reviewer suspected."}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxDoJBYPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1918/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1918/Authors|ICLR.cc/2020/Conference/Paper1918/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148988, "tmdate": 1576860530167, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment"}}}, {"id": "S1xv-cfhsH", "original": null, "number": 3, "cdate": 1573820927396, "ddate": null, "tcdate": 1573820927396, "tmdate": 1573820927396, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "SJlyOpyNcH", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment", "content": {"title": "Response to \"Official Blind Review #3\"", "comment": "> The paper is well-written and I enjoyed reading the paper.\n\nThanks for your comments!\n\n> Some more descriptions about the BRKGA algorithm ...\n\nSee changes to Section 3.2.\n\n> - I am very confused by one of the claims that \u201c the first work on learning a policy for jointly optimizing placement and scheduling\u201d. \u2026\n\nGood point. Our claim was not clearly stated, and we have changed the discussion in the introduction. The works we cite that learn a policy for device placement relied on TensorFlow\u2019s dynamic scheduler to make the scheduling decisions. In that setting, we do not claim that one should jointly optimize placement and scheduling, and it\u2019s not obvious how to do so.\n\nOn the other hand, we have approached the problem from the perspective of static scheduling, which applies in a number of recently developed compilers for deep learning computation graphs. In the static setting, jointly deciding the assignment from the operations to devices and the schedule of operations within a device is a classical problem and hence a natural one to solve; see Kwok and Ahmad (1999) and Sinnen (2007), both cited in our paper. Deciding on placement and scheduling separately makes the task harder. The poor performance of the GP+DFS baseline is an example of this; the graph partitioner ignores scheduling when making placement decisions. A similar motivation for joint optimization can also be found for the problem of CPU instruction scheduling and register allocation, see e.g., Motwani et al. (1995) https://pdfs.semanticscholar.org/1b7d/20b856fd420f93525e70a876853f08560e38.pdf.\n\nWe have indeed performed ablation tests on the value of learning in the placement and scheduling spaces; see appendix section A.12. These results suggest that the majority of gains from REGAL are in fact thanks to learning better sampling distributions in the scheduling part of the action space.\n\n> - The model is trained with standard REINFORCE -- how many training time and resources are needed to train a REGEL model for a task? How\u2019re the training dynamics looking like (variance, convergence, etc?)? \n\nSee figure 7 in section A.3 for the training set reward curves for runtime and peak memory minimization tasks. The graph neural network policy is trained using 10 cores of a CPU machine (no GPUs were used), with multi-threading used by BRKGA for evaluating chromosomes and by TensorFlow. A training run takes approximately 2-3 days to be completed.\n\n> - In terms of the generalization ability of REGEL, the paper has clearly shown that REGEL is able to generalize to differently shaped graphs, with acceptable cost, but I am wondering for the same dataflow graph, how REGEL generalizes to different input data configurations (size, modality, etc.)? \u2026\n\nWe have not tested REGAL in this setting, opting to focus on the harder task of generalizing across graphs with different topologies. It would indeed be interesting to see if the performance gains are greater when the dataset is restricted to variations on a single topology.\n\nTo partially address this question, we performed an additional analysis on our results. We\u2019ve added figure 12 in the appendix to show a breakdown of the reward by unique graph topology on the TF runtime test set (note that as per section A.1.2 we created 99 additional copies of each graph and randomly modified the tensor sizes). We see that for many graphs, the effect of REGAL (most often, the improvement from REGAL) is consistent within the family. This suggests that REGAL is identifying patterns that are specific to an architecture.\n\n> - It seems the method and assumptions about graphs or training data are pretty coupled with TensorFlow and graph-mode execution, how could the method be generalized to other ML frameworks (e.g. frameworks with eager execution)\n\nThe methods and its assumptions are indeed tied to static scheduling; however, it\u2019s not accurate to say that they are coupled to TensorFlow; they apply to any optimizing static compiler for neural network computation graphs. Such compilers include Glow, MLIR, TVM, and XLA. XLA, for example, can be used from TensorFlow, PyTorch, Jax, and Flux/Julia.\n\nFor a pure eager-mode setting, our methods do not apply and would need to be substantially redesigned. The work of Mao et al. (2019) may be interesting in this regard, in that they apply learning to an on-line scheduling problem where both a schedule and mapping onto hardware must be decided as new jobs arrive to a data processing cluster. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxDoJBYPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1918/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1918/Authors|ICLR.cc/2020/Conference/Paper1918/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148988, "tmdate": 1576860530167, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment"}}}, {"id": "r1ezDrz2iS", "original": null, "number": 2, "cdate": 1573819737880, "ddate": null, "tcdate": 1573819737880, "tmdate": 1573819737880, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "SJlqiP0S5H", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment", "content": {"title": "Response to \"Official Blind Review #2\"", "comment": "Thank you for the review and the interesting questions!\n\n> 1. The detailed explanations of o_a(G) and o_s(G) should be included.\n\no_a(G) and o_s(G) are defined as the objective value of the best solution for graph G found by BRKGA using, respective, 1) the mutant sampling distributions predicted by the GNN, and 2) uniform distributions (i.e., as is done in standard BRKGA).\n\nMultiple reviewers have requested additional details on how BRKGA works, so we have added a self-contained description of the meta-heuristic algorithm to Section 3.2.\n\n> 2. How were the attribute vectors  x_v and x_e defined in your experiments?\n\nThe specific node features x_v and edge features x_e have are described in section A.2 of the appendix. We have expanded on this description.\n\n> 3. The baseline (GP+DFS) may not be strong enough, since it is designed to reduce the communication cost. With the information of the input size and time complexity of ops, a better greedy algorithm can be designed. Moreover, the performance of Local Search and BRKGA 5K are similar, and REGAL is just slightly better than BRKGA 5K. Hence, the improvement over the best efficient greedy algorithm seems small.\n\nWe have acknowledged in Section 5.3 that GP+DFS is a weak baseline. We compare with it because a similar GP approach is used by XLA for model parallelism and by Mirhoseini et al. (ICML \u201817) as a baseline.\n\nIf we understand your suggestion about a greedy algorithm, this would be one that sequentially decides which task to run next and on which device. One issue with this approach is that it could get stuck with no feasible moves to make due to the memory constraints. It would nevertheless be possible to try this (see, e.g., https://arxiv.org/abs/1711.01912 which we recently discovered), although we expect that Tuned BRKGA would provide higher-quality solutions.\n\nAlso, the hyperparameters for local search were tuned using grid search the same way as Tuned BRKGA, so it should be compared to Tuned BRKGA rather than BRKGA 5K. The gap in percent improvement between local search and Tuned BRKGA is larger than the gap between local search and BRKGA for the TF Runtime and Synthetic Runtime test sets (Table 1).\n\nIn our opinion, the improvements are not small, they have to be judged with respect to how difficult it is to obtain these improvements - see room for improvement (Table 1; \u201cGap from best known\u201d), effort required to gain the same improvement for BRKGA (Fig 3) and absolute improvements (Fig 2).\n\n> Overall, the studied topic is interesting, and this paper is also intriguing.\n\nThanks!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxDoJBYPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1918/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1918/Authors|ICLR.cc/2020/Conference/Paper1918/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148988, "tmdate": 1576860530167, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment"}}}, {"id": "rkezBNn5oH", "original": null, "number": 1, "cdate": 1573729338184, "ddate": null, "tcdate": 1573729338184, "tmdate": 1573729559324, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "ryxXud915S", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment", "content": {"title": "Response to \"Official Blind Review #1\"", "comment": "Thank you for the review and the interesting questions!\n\n> Then the authors use a heuristic BRKGA to learn a policy ..., that actually works on unseen graphs. \n> ...it is not immediately clear to the reader the effect of BRKGA on the mapping of the graph to the resource network and why it works so well, \u2026\n\nTo clarify, BRKGA is a genetic algorithm we use to solve the joint placement and scheduling problem. BRKGA guides its search based on the solutions seen so far, like a classical optimization algorithm. We introduce learning by training a Graph Neural Network (GNN) that defines a mapping from computation graphs to mutant sampling distributions for BRKGA. The combination of GNNs and BRKGA is REGAL.\n\nWe expanded the description of BRKGA in Section 3.2 to help clarify its role. It is challenging to explain why it works so well. In addition to the references cited in the paper, we recommend the tutorial given by Resende at CLAIO/SBPO 2012 (http://mauricio.resende.info/talks/2012-09-CLAIO2012-brkga-tutorial-both-days.pdf ). BRKGA is a relative of the cross-entropy method (https://doi.org/10.1007/s10479-005-5724-z ) that has been successfully applied in combinatorial optimization and machine learning.\n\nNote also that to apply BRKGA to a specific problem, one must design a mapping from [0, 1]^n to the space of solutions. An exploration of design choices here could yield insights but is outside the scope of this work.\n\n> - Can you explain why the beta distribution choices ... have a negative impact on the makespan in certain cases? ... \n\nWe don\u2019t have detailed insights for why the learned policy performs worse than BRKGA for certain cases. However, it is easy to formulate an example where this can occur\u2014consider a mutant sampling distribution that has unit probability mass at a single poor solution. In such a case, REGAL (i.e., BRKGA with this bad sampling distribution) will never sample good solutions, but plain BRKGA may find better solutions by using the uniform random distribution.\n\n> - To what extent are the simulations realistic? ...\n\nWe have validated our performance model in an end-to-end production setting that is more restricted than the setting in the paper. When the number of devices (i.e., d) equals 1, the performance model reliably identifies schedules with low peak memory usage. The runtime part of the simulation, only non-trivial when d > 1, has not yet been validated with experiments on hardware. We expect that it will be necessary to model the asynchronous aspect of transfers in order to accurately predict runtimes on real hardware. \n\nRather than claiming that the performance model is realistic, we have claimed that it provides a challenging (i.e., NP-hard) setting in which to study how to learn an optimizer. Maintaining the simpler performance model also allows us to compare with baselines like constraint programming (CP), which help us validate the methodology. While CP would be hard to extend to more complex performance models, REGAL can be applied just as well.\n\n> - Have you tried Scotch? \u2026\n\nWe have not tried Scotch; however, our GP+DFS baseline is analogous to Scotch, to the best of our knowledge. We set up the graph partitioning (GP) problem as follows: Each node in the graph is a TensorFlow operation, and edges represent direct data dependencies, with weights proportional to the sizes of the tensors. We aim to find a partitioning of the nodes into d (= 2) disjoint subsets such that the weight of edges that cross the subsets is minimized. We believe that this matches the graph partitioning setup, e.g., reported in Mirhoseini et al. (ICML \u201817).\n\nIn place of Scotch, we use an implementation of the classical Kernighan\u2013Lin algorithm modified to support weighted edges. We chose this proprietary implementation over Scotch because it\u2019s already in use in an optimizing compiler for device-placement decisions.\n\n> - Can you obtain insights with respect how you could cluster the TensorFlow computation graphs? \n\nWe have not yet tried to obtain insights about how the policy\u2019s behavior can be used to cluster computation graphs. One possibility is to learn a fixed dimensional graph-level embedding as part of the policy network, and then to cluster the embedding vectors for the training set graphs. Another possibility, as mentioned in Section 6, is to use a Mixture of Experts architecture for the policy, and once trained, analyze which graphs are selected by which experts to understand how the policy clusters graphs. Both of these are interesting directions for future work.\n\n> - Can you improve the discussion on BRKGA? \u2026 \n\nSee changes to Section 3.2.\n\n> - ... can you comment on any insights concerning the structure of the partition and schedule? \n\nWe have added a new section (A.13), where we provide some insights into the structure of the joint placement and scheduling policy at the node-level. While we see some patterns in Figure 10, the overall learned policy remains non-trivial."}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxDoJBYPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1918/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1918/Authors|ICLR.cc/2020/Conference/Paper1918/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148988, "tmdate": 1576860530167, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Authors", "ICLR.cc/2020/Conference/Paper1918/Reviewers", "ICLR.cc/2020/Conference/Paper1918/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Comment"}}}, {"id": "ryxXud915S", "original": null, "number": 1, "cdate": 1571952747385, "ddate": null, "tcdate": 1571952747385, "tmdate": 1572972406773, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this work the authors propose a deep RL approach to minimize the makespan and the peak memory usage of a computation graph as produced by MXNet/PyTorch/TensorFlow.  This is an increasingly important problem as distributed deep learning is necessary in many cases. The authors aim to minimize the execution time and/or the peak memory usage. For this purpose they generate a training dataset out of a real-world dataset of various TensorFlow computation graphs using simulation software. The proposed RL approach consists of two steps. First  a GNN is used to derive representations for computation graphs. Then the authors use a heuristic BRKGA to learn a policy for the placement of computation graphs, that actually works on unseen graphs. Overall this paper is well-written, deals with an important practical problem. While it is not immediately clear to the reader the effect of BRKGA on the mapping of the graph to the resource network and why it works so well, the results are convincing (but still there is space for improvement).  That is why I rate it as a \"weak accept\". \n\n- Can you explain why the beta distribution choices at each node may have a negative impact on the makespan in certain cases? Have you looked into them? \n- To what extent are the simulations realistic? Can you please comment more on this aspect? \n- Have you tried Scotch? https://www.labri.fr/perso/pelegrin/scotch/. Since the software aims to achieve a different objective, it serves as a baseline. \n- Can you obtain insights with respect how you could cluster the TensorFlow computation graphs? \n- Can you improve the discussion on BRKGA? Since it is a vital component of the proposed framework, it would be informative to read few more self-contained details on how it works in section 2.\n- Once you obtain a mapping, can you comment on any insights concerning the structure of the partition and schedule? "}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575245646865, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Reviewers"], "noninvitees": [], "tcdate": 1570237730405, "tmdate": 1575245647062, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review"}}}, {"id": "SJlyOpyNcH", "original": null, "number": 2, "cdate": 1572236647356, "ddate": null, "tcdate": 1572236647356, "tmdate": 1572972406730, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary\n\nThis paper proposes an ML-based method to optimize TensorFlow Graph execution. Specifically, it combines graph neural networks (GNNs) and BRKGA (a genetic algorithm) to search over the joint space of TF node-device placement and scheduling. The core claims on the advantages of this method are that (1) it co-searches placement and scheduling space, (2) the trained model can generalize to different graphs and inference cost is very  small. The experimental results show that REGEL can outperform a few baseline methods on this problem.\n\nWriting\n- The paper is well-written and I enjoyed reading the paper.\n- Some more descriptions about the BRKGA algorithm could be added in.\n\n\nMethod and Results\n\nSome confusion if the authors could answer:\n- I am very confused by one of the claims that \u201c the first work on learning a policy for jointly optimizing placement and scheduling\u201d. I don\u2019t see much evidence in the result section about showing the co-searching the joint space yield advantages? I am fairly familiar with the line of work on only optimizing device placement, but it would be good to see some ablation studies showing search over the joint space is advantageous. \n\n- The model is trained with standard REINFORCE -- how many training time and resources are needed to train a REGEL model for a task? How\u2019re the training dynamics looking like (variance, convergence, etc?)? \n\n- In terms of the generalization ability of REGEL, the paper has clearly shown that REGEL is able to generalize to differently shaped graphs, with acceptable cost, but I am wondering for the same dataflow graph, how REGEL generalizes to different input data configurations (size, modality, etc.)? E.g. if the batch size of the input data is changed, the execution time of each kernel and their memory usage (in general, the system treatment) would change; Can a trained REGEL model on a data config A generalize to B? How would this affect the performance of REGEL?\n\n- It seems the method and assumptions about graphs or training data are pretty coupled with TensorFlow and graph-mode execution, how could the method be generalized to other ML frameworks (e.g. frameworks with eager execution)\n\n- Could the authors clarify why the two methods mentioned in \u201cLearning to directly predict a solution\u201d has quadratic complexity w.r.t. # of nodes and whereas REGEL is linear? \n\n- Confusion on Figure 4(b): Could some more critical statistics about the graphs in the training/test dataset be reported? e.g. what\u2019s the average depth of the training graphs? When there are 32 MP layers a node\u2019s feature will be passed across its 32-hop neighborhood, which seems surprising as it is common to observe GNN starts degenerating with increased depth (because all node features become similar during message passing)\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575245646865, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Reviewers"], "noninvitees": [], "tcdate": 1570237730405, "tmdate": 1575245647062, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review"}}}, {"id": "SJlqiP0S5H", "original": null, "number": 3, "cdate": 1572362145557, "ddate": null, "tcdate": 1572362145557, "tmdate": 1572972406687, "tddate": null, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "invitation": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper, the authors proposed a framework to generating a task scheduling for a compiler to reduce the execution cost of neural networks. A computation graph is first fed into a GNN to produce a beta distribution, which is then fed into the BRKGA algorithm to yield the encoded solutions. The motivation is interesting, and the proposed method is technically reasonable. The details are also included in the appendix. To improve the quality, the following concerns may be considered:\n\n1. The detailed explanations of o_a(G) and o_s(G) should be included.\n\n2. How were the attribute vectors  x_v and x_e defined in your experiments?\n\n3. The baseline (GP+DFS) may not be strong enough, since it is designed to reduce the communication cost. With the information of the input size and time complexity of ops, a better greedy algorithm can be designed. Moreover, the performance of Local Search and BRKGA 5K are similar, and REGAL is just slightly better than BRKGA 5K. Hence, the improvement over the best efficient greedy algorithm seems small.\n\nOverall, the studied topic is interesting, and this paper is also intriguing.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1918/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["adipal@google.com", "fgimeno@google.com", "vinair@google.com", "yujiali@google.com", "mlubin@google.com", "pushmeet@google.com", "vinyals@google.com"], "title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": ["Aditya Paliwal", "Felix Gimeno", "Vinod Nair", "Yujia Li", "Miles Lubin", "Pushmeet Kohli", "Oriol Vinyals"], "pdf": "/pdf/c0aa0effb0efd296d031e0ece93c6cd7e0f5fcc1.pdf", "TL;DR": "We use deep RL to learn a policy that directs the search of a genetic algorithm to better optimize the execution cost of computation graphs, and show improved results on real-world TensorFlow graphs.", "abstract": "We present a deep reinforcement learning approach to minimizing the execution cost of neural network computation graphs in an optimizing compiler. Unlike earlier learning-based works that require training the optimizer on the same graph to be optimized, we propose a learning approach that trains an optimizer offline and then generalizes to previously unseen graphs without further training. This allows our approach to produce high-quality execution decisions on real-world TensorFlow graphs in seconds instead of hours. We consider two optimization tasks for computation graphs: minimizing running time and peak memory usage. In comparison to an extensive set of baselines, our approach achieves significant improvements over classical and other learning-based methods on these two tasks. ", "keywords": ["reinforcement learning", "learning to optimize", "combinatorial optimization", "computation graphs", "model parallelism", "learning for systems"], "paperhash": "paliwal|reinforced_genetic_algorithm_learning_for_optimizing_computation_graphs", "_bibtex": "@inproceedings{\nPaliwal2020Reinforced,\ntitle={Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs},\nauthor={Aditya Paliwal and Felix Gimeno and Vinod Nair and Yujia Li and Miles Lubin and Pushmeet Kohli and Oriol Vinyals},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxDoJBYPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e3b9eecc4df4d1ab7d1248d3e8d454609e85e01f.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxDoJBYPB", "replyto": "rkxDoJBYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1918/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575245646865, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1918/Reviewers"], "noninvitees": [], "tcdate": 1570237730405, "tmdate": 1575245647062, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1918/-/Official_Review"}}}], "count": 9}