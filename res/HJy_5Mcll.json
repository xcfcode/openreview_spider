{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396415477, "tcdate": 1486396415477, "number": 1, "id": "rJvZ3zL_l", "invitation": "ICLR.cc/2017/conference/-/paper178/acceptance", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "Three knowledgable reviewers recommend rejection and there was no rebuttal. The AC agrees with the reviewers."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396415965, "id": "ICLR.cc/2017/conference/-/paper178/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396415965}}}, {"tddate": null, "tmdate": 1483727142979, "tcdate": 1483727142979, "number": 4, "id": "S1kEbwTrx", "invitation": "ICLR.cc/2017/conference/-/paper178/official/review", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer1"], "content": {"title": "Interesting work, lack of depth", "rating": "4: Ok but not good enough - rejection", "review": "\nPaper summary: this work presents ENet, a new convnet architecture for semantic labeling which obtains comparable performance to the previously existing SegNet while being ~10x faster and using ~10x less memory. \n\n\nReview summary: Albeit the results seem interesting, the paper lacks detailed experimental results, and is of limited interest for the ICLR audience.\n\n\nPros:\n* 10x faster\n* 10x smaller\n* Design rationale described in detail\n\n\nCons:\n* The quality of the reference baseline is low. For instance, cityscapes results are 58.3 IoU while state of the art is ~80 IoU. Thus the results are of limited interest.\n* The results that support the design rationale are not provided. It is important to provide the experimental evidence to support each claim.\n\n\nQuality: the work is interesting but feels incomplete. If your model is 10x faster and smaller, why not try build a model 10x longer to obtain improved results ? The paper focuses only on  nimbleness at the cost of quality (using a weak baseline). This limits the interest for the ICLR audience.\n\n\nClarity: the overall text is somewhat clear, but the model description (section 3) could be more clear. \n\n\nOriginality: the work is a compendium of \u201cpractitioners wisdom\u201d applied to a specific task. It has thus limited originality.\n\n\nSignificance: I find the work that establishes a new \u201cbest practices all in one\u201d quite interesting, but however these must shine in all aspects. Being fast at the cost of quality, will limit the impact of this work.\n\n\nMinor comments:\n* Overall the text is proper english but the sentences constructions is often unsound, specific examples below. \n* To improve the chances of acceptance, I invite the authors to also explore bigger models and show that the same \u201ccollected wisdom\u201d can be used both to reach high speed and high quality (with the proper trade-off curve being shown). Aiming for only one end of the quality versus speed curve limits too much the paper.\n* Section 1: \u201cmobile or battery powered \u2026 require rates > 10 fps\u201c. 10 fps with which energy budget ? Should not this be  > 10 fps && < X Watt.\n* \u201cRules and ideas\u201d -> rules seem too strong of a word, \u201cguidelines\u201d ?\n* \u201cIs of utmost importance\u201d -> \u201cis of importance\u201d (important is already important)\n* \u201cPresents a trainable network \u2026 therefore we compare to \u2026 the large majority of inference the same way\u201d; the sentence makes no sense to me, I do not see the logical link between before and after \u201ctherefore\u201d\n* Scen-parsing -> scene-parsing\n* It is arguable if encoder and decoder can be called \u201cseparate\u201d\n* \u201cUnlike in Noh\u201d why is that relevant ? Make explicit or remove\n* \u201cReal-time\u201d is vague, you mean X fps @ Y W ?\n* Other existing architectures -> Other architectures\n* Section 3, does not the BN layer include a bias term ? Can you get good results without any bias term ?\n* Table 1: why is the initial layer a downsampling one, since the results has half the size of the input ?\n* Section 4, non linear operations. What do you mean by \u201csettle to recurring pattern\u201d ?\n* Section 4, dimensionality changes. \u201cComputationally expensive\u201d, relative to what ?\n* Section 4, dimensionality changes. \u201cThis technique ... speeds-up ten times\u201d, but does not provide the same results. Without an experimental validation changing an apple for an orange does not make the orange better than the apple.\n* Section 4, dimensionality changes. \u201cFound one problem\u201d, problem would imply something conceptually wrong. This is more an \u201cissue\u201d or an \u201cmiss-match\u201d when using ResNet for semantic labelling.\n* Section 4, factorizing filters. I am unsure of why you call nx1 filter asymmetric. A filter could be 1xn yet be symmetric (e.g. -2 -1 0 1 2). Why not simply call them rectangular filters ?\n* Section 4, factorizing filters. Why would this change increase the variety ? I would have expected the opposite.\n* Section 4, regularization. Define \u201cmuch better\u201d.\n* Section 5.1; \u201c640x360 is adequate for practical applications\u201d; for _some_ applications.\n* Section 5.2, \u201cvery quickly\u201d is vague and depends on the reader expectations, please be quantitative.\n* Section 5.2, Haver -> have\n* Section 5.2, in this work -> In this work\n* Section 5.2, unclear what you use the class weighting for. Is this for class balancing ?\n* Section 5.2, Cityscapes was -> Cityscapes is\n* Section 5.2, weighted by the average -> is each instance weighted relative the average object size.\n* Section 5.2, fastest model in the Cityscapes -> fastest model in the public Cityscapes", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483727143651, "id": "ICLR.cc/2017/conference/-/paper178/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer3", "ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer4", "ICLR.cc/2017/conference/paper178/AnonReviewer1"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483727143651}}}, {"tddate": null, "tmdate": 1483227380759, "tcdate": 1483227380759, "number": 3, "id": "rJaxbprSe", "invitation": "ICLR.cc/2017/conference/-/paper178/official/review", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer4"], "content": {"title": "Fast and compressed semantic segmentation. Lack of novelty. Experiments are not convincing enough. ", "rating": "4: Ok but not good enough - rejection", "review": "This paper aims at designing a real-time semantic segmentation network. The proposed approach has an encoder-decoder architecture with many pre-existing techniques to improvement the performance and speed. \n\nMy concern is that the most of design choices are pretty ad-hoc and there is a lack of ablation study to validate each choice. \n\nMoreover, most of the components are not new to the community (indexed pooling, dilated convolution, PReLu, steerable convolution, spatial dropout). The so-called 'early down-sampling' or 'decoder size' are also just very straightforward trade-off between speed and performance through reducing the size/depth of the layers. \n\nThe performance and inference comparison is only conducted against a rather weak baseline, SegNet, which also makes the paper less convincing. On the public benchmark the proposed model does not achieve comparable results against state-of-the-art. As some other reviewer raised, there are some stronger model that has similar efficiency compared with SegNet.\n\nThe speed-up improvement is good yet reasonable given all the components used. However, we also did see a big sacrifice in performance on some benchmarks, which makes all these tricks less promising. \n\nThe only fact I found impressive is that the model size is 0.7MB, which is of good practical use and helpful to dump on mobile devices. However, there is NO analysis over how is the trade-off between the model size and the performance, and what design would result how much reduction in model size. I did not find the memory consumption report for the inference stage, which are perhaps even more crucial for embedded systems. \n\nPerhaps this paper does have a practical value for practical segmentation network design on embedding systems. But I do not believe the paper brings insightful ideas that are worthy to be discussed in ICLR, either from the perspective of model compression or semantic segmentation. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483727143651, "id": "ICLR.cc/2017/conference/-/paper178/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer3", "ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer4", "ICLR.cc/2017/conference/paper178/AnonReviewer1"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483727143651}}}, {"tddate": null, "tmdate": 1482004738976, "tcdate": 1482004647502, "number": 2, "id": "ByyhOMQVx", "invitation": "ICLR.cc/2017/conference/-/paper178/official/review", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer2"], "content": {"title": "fast system, but needs more thorough account", "rating": "5: Marginally below acceptance threshold", "review": "This paper describes a fast image semantic segmentation network.  Many different techniques are combined to create a system much faster than the baseline SegNet approach, with accuracy comparable or somewhat worse in most of three datasets evaluated.\n\nThe choices and techniques used to achieve these speed optimizations are enumerated and described along with intuitions behind them.  However, this section lacks measurements and experimental results showing the effects of these choices.  To me, that would have been a key component to the paper.  As it stands now, we only get to see final evaluation numbers, which appear to describe a speed/accuracy tradeoff with little insight into the pieces sum to get there.\n\nIn addition, I feel there could be a more thorough comparison with different existing systems.  Only SegNet is shown in comparison tables, even though many current systems are outlined in the related work.  Additional datasets such as Pascal or COCO may be interesting here as well, perhaps with a larger version of the ENet model.\n\nThe system looks to be fast, with decent accuracy on the majority of benchmarks described.  However, as a practical implementation paper, I feel it needs to more thoroughly demonstrate the effects of each component, as well as possibly some of the sizing/tuning, in order to provide a more robust picture.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483727143651, "id": "ICLR.cc/2017/conference/-/paper178/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer3", "ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer4", "ICLR.cc/2017/conference/paper178/AnonReviewer1"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483727143651}}}, {"tddate": null, "tmdate": 1481908573001, "tcdate": 1481904115391, "number": 1, "id": "HJoxx5ZEg", "invitation": "ICLR.cc/2017/conference/-/paper178/official/review", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer3"], "content": {"title": "This may be of interest to practitioners - but I do not think that there is a clear academic value to this paper.", "rating": "3: Clear rejection", "review": "The paper introduces a lightweight network for semantic segmentation that combines several acceleration ideas.\nAs indicated in my preliminary question, the authors do not make the case about why any of the techniques they propose is beyond what we know already: factorizing filters into alternating 1-D convolutions, using low-rank kernels, or any of the newer inception network architectures.\n\nI have had a hard time figuring out what is the take-home message of this paper. All of these ideas are known, and have proven their worth for detection. If a paper is going to be accepted for applying them to semantic segmentation, then in the next conference another paper should be accepted for applying them to normal estimation, another to saliency estimation and so on. \n\nAs the authors mention in their preliminary review:\n\"I agree that most improvements from classification architectures are straightforward to apply to object segmentation, and that's exactly what we've done - our network is based on current state of the art models. Instead of repeating most of the discussion on factorizing filters, etc., that has been discussed in a lot of papers already, we have decided that it's much more valuable to describe in depth the choices that are related to segmentation only - these are the most important contributions of our paper.\"\n\nI do not see however any in-depth discussion of certain choices - e.g. an analysis of how certain choices influence performance or speed. Instead all one gets are some statements \"these gave a significant accuracy boost\" \"this helped a lot\", \"that did not help\", \"this turned out to work much better than that\" . This is not informative - and is more like an informal chat rather than an in-depth discussion. \n\nIf novelty is not that important, and it is only performance or speed that matter, I am still not convinced.\nThe authors only compare to [1,2] (SegNet) in terms of both accuracy and speed. I cannot see the reason why they do so, and they do not really justify it. According to the authors' evaluation, [1] requires ~1 sec. per frame,  while Deeplab v2, without the DenseCRF, runs at 5-8fps. \n(https://arxiv.org/abs/1606.00915)\nOn Cityscapes, SegNet/ENet are at 57/56 accuracy, while  without the DenseCRF, Deeplab V1 (@8fps) yields a mAP of ~65%; Deeplab V2 is at 70%. \nSo accuracy-wise this paper is 14% below a strong baseline in terms of mAP - and speed-wise only twice as fast as DeepLab, which was never optimized for speed. \nFor reference the current state-of-the-art on CityScales is at ~81% (https://www.cityscapes-dataset.com/benchmarks/).\nSo accuracy-wise the present work is practically irrelevant, and speed-wise the authors choose a very weak baseline (~1fps).\n\nThere is no systematic comparison with other acceleration techniques, and no ablation study of the impact of different choices (factorization, pooling, low/high resolution features, etc) on speed and/or efficiency.\n\nAs such, I do not see what is the take-home message of this paper and how we could use it elsewhere. This could be useful for practitioners, e.g. as a technical report (but still the main thing one would care about are the relative improvements); but I cannot see what a researcher would use from this paper as a take-home message.   ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483727143651, "id": "ICLR.cc/2017/conference/-/paper178/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer3", "ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer4", "ICLR.cc/2017/conference/paper178/AnonReviewer1"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483727143651}}}, {"tddate": null, "tmdate": 1481517433117, "tcdate": 1481517433108, "number": 9, "id": "ry-KKjiQx", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "ryEfdPPme", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "sorry I don't mean it when I say 'low quality' ...", "comment": "\n\nActually I think it is really a good project consisted of high-quality codes and useful insights. thx for sharing it with the community."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1481305092695, "tcdate": 1481305092688, "number": 8, "id": "B1aW2wO7x", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "r1zd6CwQg", "signatures": ["~Adam_Paszke1"], "readers": ["everyone"], "writers": ["~Adam_Paszke1"], "content": {"title": "Yes, we have a repository on GitHub", "comment": "Yes, you can find the code at https://github.com/e-lab/ENet-training"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1481268586506, "tcdate": 1481268586498, "number": 7, "id": "r1zd6CwQg", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "ByhgFGJMl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "code available", "comment": "Is there publicly available code for ENet?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1481238539607, "tcdate": 1481238539601, "number": 6, "id": "ryEfdPPme", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "SJA7CSl7e", "signatures": ["~Adam_Paszke1"], "readers": ["everyone"], "writers": ["~Adam_Paszke1"], "content": {"title": "Could you please elaborate on why do you find it of low technical quality?", "comment": "Great to hear that you've used our code!\n\nYes, we haven't developed many improvements lately, as we've been doing internships, and returned to our previous research only now. Could you please elaborate on why do you find it of low technical quality?\n\nI wouldn't say there's a single dominant choice, the final effect is rather a sum of them all. For the analysis of the most important factors that affect the network's efficiency, I'd suggest to read the references that discuss classification architectures. Also, as I've said below, I'll update the paper with a more detailed breakdown of the effects of our contributions. I can also recommend using the NVIDIA Visual Profiler for finding the bottlenecks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1481238083478, "tcdate": 1481238083470, "number": 5, "id": "BkoB8PwQg", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "HyNmYY1Qe", "signatures": ["~Adam_Paszke1"], "readers": ["everyone"], "writers": ["~Adam_Paszke1"], "content": {"title": "Our aim was to improve the efficiency of segmentation architectures, not CNNs in general", "comment": "Actually, we have provided references for a few other works that discussed modern, state of the art, classification architectures and the design choices that affected their performance. You can find complexity analysis both in [1] and [2]  and that were the most important works we used.\n\nI think XNOR-Net is a completely orthogonal improvement - it discusses a way of training networks with binary weights, as bitwise operations tend to be cheaper than floating-point ops on most hardware. You apply the same technique to ENet and it might benefit from it in the same way. However, I'm not aware of any framework that supports the binary network with specialized CUDA kernels, so right now it might even end up running slower than with regular convolutions, that have larger capabilities.\n\nAs for discussion of the other references:\n* \"Accelerating Very Deep Convolutional Networks for Classification and Detection\" and \"Speeding up Convolutional Neural Networks with Low Rank Expansions\" - I haven't seen these paper before, and while they seem interesting, you can find that a sequence of asymmetric convolutions is also a low-rank approximation of a larger convolution. Another benefit is that it's very straightforward to add it to the model (there's no need for solving additional optimization tasks). I have seen asymmetric convolutions in quite many places, while I haven't heard of any uses of these techniques.\n\n* Convolutional Neural Networks at Constrained Time Cost - The architectures discussed in this paper are pretty old, and not at all similar to most modern designs. For example in [2] it has been proposed to decompose most filters larger than 3x3 into a sequence of smaller convolutions, while this paper still proposes using 7x7 convolutions in the initial stages of the network, that still operates on large feature planes (7*7/(3*3*3) = nearly 2x larger complexity).\n\nI agree that most improvements from classification architectures are straightforward to apply to object segmentation, and that's exactly what we've done - our network is based on current state of the art models. Instead of repeating most of the discussion on factorizing filters, etc., that has been discussed in a lot of papers already, we have decided that it's much more valuable to describe in depth the choices that are related to segmentation only - these are the most important contributions of our paper.\n\nI agree that our work would benefit from a more detailed breakdown of contributions of individual choices. As I said in a comment below, I'll update the paper soon.\n\nThank you for your input! I hope this resolves the issues.\n\n[1] Deep residual learning for image recognition\n[2] Re-thinking the inception architecture for computer vision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1481235523068, "tcdate": 1481235523064, "number": 4, "id": "S1jB3UPXg", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "SkUQH_1Xx", "signatures": ["~Adam_Paszke1"], "readers": ["everyone"], "writers": ["~Adam_Paszke1"], "content": {"title": "That's a very good point", "comment": "Actually that's a very good point. Once I get back from NIPS, I'll go over the experiment log and update the paper with detailed information on the effects of each design choice. Thank you for bringing this up, I think it really can add a lot."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1480773158370, "tcdate": 1480773158359, "number": 3, "id": "SJA7CSl7e", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "good project yet still of low technical quality ...", "comment": "I have tried the open source implementation for different tasks these several months. It's fast, reasonably accurate and useful for prototyping.\n\nHowever I see no technical quality improvements against its NIPS submission version.\n\nI am really wondering which design choice is the most dominant one. \n\nWondering what I should do if I want to design a network as efficient as this one."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1480722716176, "tcdate": 1480722716172, "number": 2, "id": "HyNmYY1Qe", "invitation": "ICLR.cc/2017/conference/-/paper178/pre-review/question", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer3"], "content": {"title": "Comparisons with other works on accelerating neural nets", "question": "I understand that the authors prefer to design their network from scratch, rather than accelerate it post-hoc. \nBut I could not find any reference or comparisons to other works on accelerations of neural networks for computer vision. Most such works are indeed used for detection - but in my understanding the acceleration techniques would directly transfer.\n\nOne of the latest references is (real-time detection on mobile phones):\nXNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks, Mohammad Rastegari, AI2; Vicente Ordonez, Allen Institute for AI; Joe Redmon; Ali Farhadi, University of Washington\n\nwhile slightly older ones are:\n. arXiv:1505.06798\n    Accelerating Very Deep Convolutional Networks for Classification and Detection\n    Xiangyu Zhang, Jianhua Zou, Kaiming He, Jian Sun \n\n arXiv:1412.1710 \n    Convolutional Neural Networks at Constrained Time Cost\n    Kaiming He, Jian Sun \n\narXiv:1405.3866 \n    Speeding up Convolutional Neural Networks with Low Rank Expansions\n    Max Jaderberg, Andrea Vedaldi, Andrew Zisserman \n\nas well as many others, cited in the references above. \nSince the two problems (semantic segmentation/object detection) are not that different, I think it would make sense to measure the added value of the proposed contribution with respect to the works above. \n\nCan the authors comment on this?\n\nAnd can the authors comment on the impact of their individual choices, rather than provide only the results of their final architecture?\nIt is currently hard to assess the contribution of the different components. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959422013, "id": "ICLR.cc/2017/conference/-/paper178/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer3"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959422013}}}, {"tddate": null, "tmdate": 1480717598077, "tcdate": 1480717598073, "number": 1, "id": "SkUQH_1Xx", "invitation": "ICLR.cc/2017/conference/-/paper178/pre-review/question", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["ICLR.cc/2017/conference/paper178/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper178/AnonReviewer2"], "content": {"title": "Computation savings of each design choice?", "question": "The total computational cost vs the comparison SegNet system is reported at the end.  But I'm curious what is the incremental savings of each of the design items in sec 4.  Is it possible to provide the benefit of each of the sec 4 items, in terms of using vs not using each choice, perhaps in the 512x512 image scenario?  It also would be nice to report any loss/gain in accuracy for these as well, but I'm more interested in the computational savings since accuracy seems roughly similar in the end.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959422013, "id": "ICLR.cc/2017/conference/-/paper178/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper178/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper178/AnonReviewer2", "ICLR.cc/2017/conference/paper178/AnonReviewer3"], "reply": {"forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "writers": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959422013}}}, {"tddate": null, "tmdate": 1479645427966, "tcdate": 1479645427962, "number": 2, "id": "ByhgFGJMl", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "rk3rdQwbl", "signatures": ["~Adam_Paszke1"], "readers": ["everyone"], "writers": ["~Adam_Paszke1"], "content": {"title": "iOS APIs are not enough. Pascal was left for future work.", "comment": "I agree it would be great to benchmark ENet on iOS or Android. I looked into the functions provided by Apple, and the problem is that they seem to support only more classical pooling-only architectures. We would have to write our own unpooling kernels/shaders, so writing an optimised version would require a non-trivial amount of learning and work. I can\u2019t even find kernels for gradient computation, so there\u2019s no easy way to reproduce transposed convolution either.\n\nWe did some initial experiments on Pascal VOC, but we decided to first reach accuracy comparable to SegNet on Cityscapes, SUN and CamVid. Pascal is quite different, and we\u2019ll probably investigate this in a future work.\n\nThank you for your suggestions!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "tmdate": 1479125060359, "tcdate": 1479125060355, "number": 1, "id": "rk3rdQwbl", "invitation": "ICLR.cc/2017/conference/-/paper178/public/comment", "forum": "HJy_5Mcll", "replyto": "HJy_5Mcll", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Comparison on VOC? ", "comment": "Interesting work and especially relevant going forward with the plethora of mobile devices. It would be especially interesting to see the time comparisons\non a mobile device using any of the currently available mobile frameworks. For example iOS has CNN support using Metal. Here is sample code [bit.ly/2fQQcrX]\nthat specifically runs VGG on an iPhone (not in fully convolutional format) but which you could probably modify easily to match your architecture.\nAlso, have you tried training the same architecture on the Pascal VOC segmentation challenge? SegNet has a mean IU of 59.9 according to the VOC benchmark [bit.ly/2g9Mpa3]. What does ENet achieve? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287698130, "id": "ICLR.cc/2017/conference/-/paper178/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJy_5Mcll", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper178/reviewers", "ICLR.cc/2017/conference/paper178/areachairs"], "cdate": 1485287698130}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478289069016, "tcdate": 1478269542859, "number": 178, "id": "HJy_5Mcll", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HJy_5Mcll", "signatures": ["~Abhishek_Chaurasia1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation", "abstract": "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n", "pdf": "/pdf/19025e9f9e55430fa57f3730bcf86cc5ad1c73b8.pdf", "paperhash": "paszke|enet_a_deep_neural_network_architecture_for_realtime_semantic_segmentation", "keywords": ["Deep learning"], "conflicts": ["mimuw.edu.pl", "purdue.edu", "hanyang.ac.kr", "iitg.ac.in"], "authors": ["Adam Paszke", "Abhishek Chaurasia", "Sangpil Kim", "Eugenio Culurciello"], "authorids": ["a.paszke@students.mimuw.edu.pl", "aabhish@purdue.edu", "sangpilkim@purdue.edu", "euge@purdue.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 17}