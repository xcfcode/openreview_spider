{"notes": [{"id": "rJgP7hR5YQ", "original": "ryeBGLT5FX", "number": 1365, "cdate": 1538087966632, "ddate": null, "tcdate": 1538087966632, "tmdate": 1545355389385, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1lyl8RegN", "original": null, "number": 1, "cdate": 1544771046924, "ddate": null, "tcdate": 1544771046924, "tmdate": 1545354521465, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Meta_Review", "content": {"metareview": "This paper investigates composition and decomposition for adversarially training generative models that work on composed data. Components that are sampled from component generators are then fed into a composition function to generate composed samples, aiming to improve modularity, extensibility, and interpretability of GANs. The paper is written very clearly and is easy to follow.\nExperiments considered application to both images (MNIST) and text (yelp reviews).\nThe original version of the paper lacks any qualitative analysis, even though experiments were described. Authors revised the paper to include some experimental results, however, they are still not sufficient. State-of-the-art baselines, from previous work suggested by the reviewers should be included for comparison.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Paper falls short of experimental results, especially comparison to state-of-the-art baselines"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1365/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352865041, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352865041}}}, {"id": "BkxNHkNq0m", "original": null, "number": 4, "cdate": 1543286587746, "ddate": null, "tcdate": 1543286587746, "tmdate": 1543286612348, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "r1e7Mx3A2m", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "content": {"title": "Thanks for your comments.", "comment": "Dear sir,\n\nOur generators' architectures followed DCGAN. \nA thing to clarify in MNIST-BB experiment is our composition/decomposition network are Unet and they are not generators. For the details about the networks' architectures, please see apendix.\nIn terms of your question, Unet composition network shows it can learn rotate, shift and scale(not very large scale) in our experiments. We observed that pooling (in our case is stride=2) is especially important for learning large shifting of foregrounds. We also observed that a fully-conolutional network (encoder-decoder) can achieve similar performance. We actually tried spatial transformer (ST) in our composition network but we failed. The reason is this network needs to learn large shifting that is too far for the gradient to propate for ST. On the other hand, ST-GAN uses a progessive algorithm to update transformation with also support the idea that it is hard to do large warping at one step. Compositionnal GAN uses RAFN network to first change the viewpoint of an object then does spatial transforming that might suggest only ST is not enough. It is not clear whether ST is sufficient to learn all affine transformation under GANs setting."}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621607006, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJgP7hR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1365/Authors|ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621607006}}}, {"id": "HkgZIX79Am", "original": null, "number": 3, "cdate": 1543283528875, "ddate": null, "tcdate": 1543283528875, "tmdate": 1543283528875, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "SyxhevqD3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "content": {"title": "Thank you reveiwer 2. Please see our reply. ", "comment": "We thank the reviewer for their detailed and thoughtful review. We have made some improvements to our paper based on these suggestions - adding quantitative evaluations, adding comparisons to relevant related work and clarifying our notation  - please see inline for our detailed responses:\n\n>>> Hard to tell whether this approach works since the metrics for evaluation are not specified\u2026 ...\n>>> 1.    I believe the weakest part of this paper is the evaluation section.  ... ...\n(<<<) We agree with the reviewer that while our qualitative results provide some intuition about which tasks are feasible and which are not, providing qualitative metrics across the entire dataset is important. We supplemented our original qualitative results with quantitative metrics - specifically, we evaluated the foreground generator learned from composed examples using FID score and compared this to our base GAN model trained on the actual foreground dataset (as a theoretical upper bound on performance for the compositional model). We show that as expected, we do not do quite as well when we have to learn to decompose and model the foreground simultaneously, but are within range of the FID scores reported in literature on MNIST and Fashion-MNIST.\n>>> 2.    Aside from evaluation, there are some other details missing from the presentation. ... ...Choices of models are often not explained. ...\n(<<<)We apologize for the missing details, these details were omitted due to space constraints but we have included the relevant details on the full architecture used, including type of regularization, values of alpha etc., in a new section of the appendix.\n>>>   It is not explained in detail how the Yelp-reviews dataset is altered to achieve coherence. ... ....\n(<<<) The general architecture of the composition network is described at a high level in section 3.2. In brief, it is a seq-to-seq model that takes the concatenation of the two sentence and outputs a sentence pair that is made more coherent by this network. In addition, we have included additional details on architecture and hyperparameters used in a new section of the appendix.\n>>> 3.    The theoretical section is an interesting contribution, ... ...\n(<<<) We apologize for the disconnected presentation of our theoretical results. The theoretical results were meant to formalize the intuition from the experimental examples that task 1 and 3 are \u201cfeasible\u201d in some sense and to provide sufficient conditions on the composition operation such that tasks 1 and 3 are identifiable. We have edited the text to make this connection clearer.\n>>> 4.    My understanding is that both datasets used are created by the authors by making alterations to MNIST and Yelp-reviews dataset, .... ....\n(<<<) Our primary goal was to suggest a set of composition / decomposition subtasks (c.f. tasks 1 through 4 in our submission), as well as deriving some basic theoretical results about the identifiability of these tasks (e.g., conditions where one can learn component models from composed data etc). The experimental results were intended more as illustrative examples of when such models were learnable (or not) which motivated our synthetic datasets where the \u201cground truth\u201d composition operation is known to us. We agree with the reviewer that it would be interesting to apply our model to more complex datasets and we look forward to exploring that further (along with various extensions of the model that this would require) in future work.\n>>> 5.    In section 2.3, in the coherent sentence experimental setting,... ...\nMinor issues: \n>>> 6.    From the related work section, it is not clear how your approach is different from Azadi et al. (2018). Please include more details.\n(<<<) Complicated but special case of our framework, hence comparison would not be suitable. We cited them\nWe have added a comparison table1 which explains how our work relates to various other contributions in this area including Azadi et al. \n>>> 7.    In section 2.4, you mention using Wasserstein GANs, ... ...\n(<<<) We apologize that due to space constraints we were not able to explain the Wasserstein GAN in sufficient detail. We have provided additional details of our architectures in the appendix. \n>>> 8.    I believe there are some errors in which tasks reference which figures in section 3.3. Should Task 2 refers to Figure 6, and Task 3 to Figure 7?\n(<<<) Yes, that is correct, we apologize for the confusion and have corrected the references.\n>>> 9.    What exactly is range(.) in section 4? If this refers to the interval of values that a variable can take, the saying \u201cis a matrix of size |range(Z)| \u00d7 |range(Y )|\u201d doesn\u2019t exactly make sense. Please define formally. \n(<<<) \u201crange(.)\u201d refers to the set of values that Z and Y can take on \u201c| range (X) |\u201d thus denoting the cardinality of the range of X (the number of values X can take on).\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621607006, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJgP7hR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1365/Authors|ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621607006}}}, {"id": "rkxRCJXqRm", "original": null, "number": 2, "cdate": 1543282645640, "ddate": null, "tcdate": 1543282645640, "tmdate": 1543282645640, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "SJlqBB3FnQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "content": {"title": "Thank you reveiwer 3. Please see our reply.", "comment": ">>> - There have been works on this before in the GAN literature, they have not been even cited, let alone being compared to in the experiments. Seminal examples include Donahue et al., ICLR 2018 \"Semantically decomposing the latent spaces of generative adversarial networks\", and (a bit less starkly in terms of the alignment with the goals of this paper): Huang et al., 2017 \"Stacked generative adversarial networks\". \n- In general, comparisons to state-of-the-art (or to other) algorithms are missing.\n\nWe thank the reviewer for pointing us to some of the related work in this field. We\u2019ve added a new comparison table that compares our method to other related methods, and in particular, show that to the best of our knowledge we are the first to tackle the general problem of learning a part generator and composition / decomposition directly from composed data. Regarding comparisons specifically to Donahue et al. and Huang et al. please see the section below on \u201cfactorized\u201d representations.\n\n>>> - Is the assumptions of pre-trained components viable with image, and not text, data? Please elaborate\n\n\nWe apologize for the confusion caused by our presentation of the text example. The assumption of pre-trained components is indeed still viable with text. In our example, the equivalent pre-trained component would be a generative model for sentences from the review corpus - in our experiments, this is done by training a generator on the first/second sentence of reviews in the corpus.\n\n>>> - The related work section is missing out on dozens of  works, those on disentanglement or interpretability; what is the point then of making a related work section in the first place if only one single example of an algorithm in each broad topic is mentioned? If so, I would suggest mentioning this single example prior to the discussing the topic without a related work section, or (apparently the better option) to do a related work section with a rigorous coverage. Examples of some related works on disentanglement and interpretability: \nHiggins et al., ICLR 2017 \"beta-VAE\" - Kim & Mnih, ICML 2018 \"Disentangling by factorising\" - Adel et al., ICML 2018 \"Discovering interpretable representations for both deep generative and discriminative models\" - Chen et al., NIPS 2017 \"InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets\", etc.\n\n\nAgain, we thank the reviewer for pointing us to work that is related from the interpretability, disentanglement side of things. As the reviewer correctly points out, there is much recent work in the area of learning disentangled representations of data. However, this work is not directly relevant to our work (as we explain below). We included some examples (including Kim & Mnih etc.) from the disentanglement literature, mostly as a means of explaining to the reader how our work differs from the general approaches in learning disentangled representations and not as a comprehensive review of work in the broad field.\n\nAs mentioned in our related work section, the work in disentangled representations is complementary to our work but differs in that 1) we specifically attempt to learn standalone component generators and 2) our composition operations occurs \u201cindependently\u201d of sampling the components (we also cite this as a reason why the decomposition learned by our models are unlikely to yield good \u201cdisentangled\u201d representations). This is important since our goal is to be able to learn marginal, component generators that can then be reused (e.g., to inductively learn more components as illustrated in our chain learning example).\n\nIt is unclear to us, for example, how we could sample individual components from a factorized latent representation (nor should that be the goal when optimizing for interpretability). We see our work as a parallel but complementary approach, focusing on exploring how we can build complex models incrementally with atomic generators.\n\nWe also thank the reviewer for their feedback on our related work section, we\u2019ve fleshed out comparisons to relevant related work in the form of a new table 1 which summarizes our contribution relative to some of the most similar existing work.\n\n>>> - The advantages promised in Section 1 are a little bit too presumptuous. Too many idealistic assumptions are need in order for these advantages to hold. For instance, extensibility has been mentioned as an advantage in Section 1 and in the abstract, and that has not been capitalised on, or confirmed in the experiments, or from this point onwards. \n\nWe agree with the reviewer that the advantages in section 1 are more aspirational and should be reworded to reflect that. We do note that we have added a cross-dataset chain-learning example which we hope does suggest that these advantages could be realizable using this compositional framework.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621607006, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJgP7hR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1365/Authors|ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621607006}}}, {"id": "B1eoKJXq0m", "original": null, "number": 1, "cdate": 1543282563087, "ddate": null, "tcdate": 1543282563087, "tmdate": 1543282563087, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "Sklg9J-a37", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "content": {"title": "Thank you reveiwer 1. Please see our reply.", "comment": "We thank the reviewer for their detailed and thoughtful review. We have made some improvements to our paper based on these suggestions - adding quantitative evaluations and expanding our comparison to related work - please see inline for our detailed responses:\n\nReply to 1:\n\nFirst, we\u2019d like to clarify that the primary intent of our work was to suggest a set of composition / decomposition subtasks (c.f. tasks 1 through 4 in our submission), as well as deriving some basic theoretical results about the identifiability of these tasks (e.g., conditions where one can learn component models from composed data etc). The experimental results were intended more as illustrative examples of when such models were learnable (or not) which explained our lack of quantitative evaluations.\n\nHowever, we agree with the reviewer that providing a qualitative evaluation across the entire dataset is useful. We supplemented our original qualitative results with quantitative metrics - specifically, we evaluated the foreground generator learned from composed examples using a standard FID score and compared this to our base GAN model trained on the actual foreground dataset (as a theoretical upper bound on performance for the compositional model). We show that, as expected, we do not do quite as well when we have to learn to decompose and model the foreground simultaneously, but are within range of the FID scores reported in literature on MNIST. We further evaluated FID scores on Fashion-MNIST in the same manner as an additional validation.\n\nReply to 2:\n\nWe apologise for the lack of clarity in our presentation of the various sub-tasks. Part of the contribution of our work is to enumerate various composition/decomposition tasks and to demonstrate the feasibility of a subset of these tasks. However, we agree with the reviewer that this may result in confusion for the reader. We\u2019ve edited the introduction to make it clearer that our main focus is to demonstrate that \u201cchain learning\u201d is possible since it provides a simple proof-of-concept for modular extensions of GANs. \n\nReply to 3:\n\nWe agree that having a pre-specified number of components is a limitation of this framework. We are definitely interested in exploring extensions of such models beyond a fixed, pre-specified number of components. However, we believe that even this constrained version of compositionality has not been extensively explored - especially in terms of our theoretical understanding of when such compositional training is possible.\n\nRegarding our compositional operation being too simple, we agree that our composition transformations are not sufficient to capture \u201creal-world\u201d composition. Our goal was to show a proof-of-concept on a challenging but still feasible set of composition operations (e.g., in our chain learning example, the composition consists of scaling, rotation and masking).\nLastly, we agree that most of the tasks assume knowledge of a component generator. This was the main motivation behind our work (how to re-use GANs in a modular fashion), we believe that the chain learning example shows a possible approach for how one can iteratively build up a collection of component generators and hence handle compositional data of increasing complexity.\n\nReply to 4:\n\nWe thank the reviewer for the pointer to LR-GANs, that is certainly very interesting and relevant related work. However, there are some key differences between our work and the work on LR-GANs. Firstly, we learn a marginal component model for the foreground that is able to generate foreground samples (instead of generating foreground conditioned on background) this is important for us to be able to reuse component generators as demonstrated in our chain learning examples (we have included a cross-domain chain learning example in the appendix to further illustrate this). Secondly, the LR-GAN is restricted to modelling affine compositions and do not learn a corresponding decomposition operation. The authors also demonstrate that both having a good foreground mask and restricting composition to affine transformations is required for good performance of their model in their ablative analysis. We appreciate the insights provided by the authors of LR-GAN, and while these priors are useful when modeling images specifically and may be useful in our contexts as well, we are more focused on identifying where compositional learning is identifiable more generally without \n\nIn summary, there are two main differences in the model formulation directly.  First, in our framework the foreground generator and background generator are independent, while LR-GAN\u2019s foreground generator is dependent on background generator. This independence is required for part generators learnt to be reusable. Second, in our framework there is a decomposition operation and a cycle consistency regularization in the model. We showed that this regularization is beneficial to learning a good part generators.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621607006, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJgP7hR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1365/Authors|ICLR.cc/2019/Conference/Paper1365/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621607006}}}, {"id": "Sklg9J-a37", "original": null, "number": 3, "cdate": 1541373832386, "ddate": null, "tcdate": 1541373832386, "tmdate": 1541533195023, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "content": {"title": "interesting paper, but missed quantitative analysis and comparisons.", "review": "[Overview]\n\nIn this paper, the authors studied the problem of composition and decomposition of GANs. Motivated by the observations that images are naturally composed of multiple layouts, the authors proposed a new framework to study the compositional image generation and its decomposition by defining several tasks. On those various tasks, the authors demonstrate the possibility of the proposed model to composing image components and decompose the images afterwards. These results are interesting and insightful to some extent.\n\n[Strengthes]\n\n1. The authors proposed a framework for compose images from components and decompose the images into components. Based on this new framework, the authors tried different settings, by fixing the learning of one or more modules in the model. The experiments on various tasks are appreciated.\n\n2. In the experiments, the authors tried both image and text to demonstrate the concepts in this paper. Moreover, some qualitative results are presented.\n\n[Weaknesses]\n\n1. The authors performed multiple experiments regarding various tasks defined in this paper.However, I can hardly find any quantitative evaluation for the results. It is not clear to me that how the quality of the composed images and the decomposed components from images are. I would suggest the authors derive some metric to measure quality quantitatively, provide some statistics on the whole datasets.\n\n2. In this paper, the authors proposed multiple tasks in terms of which parts are fixed and known in the training process. However, dominated by so many different tasks, the core idea is losses in the paper. From the paper, I cannot get the core idea the authors want to deliver. I would suggest the authors focus on one certain task and perform more qualitative and quantitative analysis and comparisons, as also mentioned above.\n\n3. The proposed model has several tricky parts. First, the number of components are pre-determined. However, in realistic cases, the number of components are unknown, and thus how many component generators should be used is ill-posed. Second, the composing operation is simple and tricky. Such a simple composing operation make it hard to adapt to some more complicated data, such as cifar10 or so. Thirdly, almost all tasks need some components known. Even for the Task 4, c is known, and the model performs poorly for generating the disentangled components.\n\n4. The authors missed one very relevant paper:\n\nLR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation. Yang et al.\n\nIn the above paper, the authors proposed an end-to-end model for generating images with background and foreground compositionally. It can be applied to a number of realistic datasets. Regardless of the decomposition part in this paper, the proposed method in the above paper seems to be clearly superior to the composition part in this paper considering this paper fails on Task 4. The authors should give credit to the above paper (even the synthesized MNIST dataset looks similar ) and pay some efforts to explain the advantages in comparison it.\n\n[Summary]\n\nThis paper proposed a new framework to study the compositionally of images during generation and decomposition. Through several experiments on various tasks, the authors presented some interesting results and provided some insights on the potentials and difficulties in this direction. However, as pointed above, I think this paper lacks enough experimental analysis and comparison. Its core idea hard to capture. Also, it missed a comparison to some related work.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "cdate": 1542234245457, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335931117, "tmdate": 1552335931117, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJlqBB3FnQ", "original": null, "number": 2, "cdate": 1541158209694, "ddate": null, "tcdate": 1541158209694, "tmdate": 1541533194774, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "content": {"title": "So isolated from the similar works on GANs", "review": "- There have been works on this before in the GAN literature, they have not been even cited, let alone being compared to in the experiments. Seminal examples include Donahue et al., ICLR 2018 \"Semantically decomposing the latent spaces of generative adversarial networks\", and (a bit less starkly in terms of the alignment with the goals of this paper): Huang et al., 2017 \"Stacked generative adversarial networks\". \n\n- In general, comparisons to state-of-the-art (or to other) algorithms are missing.\n\n- Is the assumptions of pre-trained components viable with image, and not text, data? Please elaborate\n\n- The related work section is missing out on dozens of  works, those on disentanglement or interpretability; what is the point then of making a related work section in the first place if only one single example of an algorithm in each broad topic is mentioned? If so, I would suggest mentioning this single example prior to the discussing the topic without a related work section, or (apparently the better option) to do a related work section with a rigorous coverage. Examples of some related works on disentanglement and interpretability: \nHiggins et al., ICLR 2017 \"beta-VAE\" - Kim & Mnih, ICML 2018 \"Disentangling by factorising\" - Adel et al., ICML 2018 \"Discovering interpretable representations for both deep generative and discriminative models\" - Chen et al., NIPS 2017 \"InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets\", etc.\n\n- The advantages promised in Section 1 are a little bit too presumptuous. Too many idealistic assumptions are need in order for these advantages to hold. For instance, extensibility has been mentioned as an advantage in Section 1 and in the abstract, and that has not been capitalised on, or confirmed in the experiments, or from this point onwards. \n\n- It will be interesting to see what happens with rather real-world cases like occlusion, etc\n\n- Writing has room for improvements, in terms of both the flow and also grammar, etc. There are a few typos. ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "cdate": 1542234245457, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335931117, "tmdate": 1552335931117, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SyxhevqD3Q", "original": null, "number": 1, "cdate": 1541019380459, "ddate": null, "tcdate": 1541019380459, "tmdate": 1541533194567, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "content": {"title": "Interesting new problem formulation, not carefully presented and evaluated.", "review": "The paper proposes a framework for training generative models that work on composed data. The models are trained in an adversarial fashion. The authors apply it to decompose foreground/background parts on MNIST images, and to perform sentence composition/decomposition.\n\nHigh level comments:\n* Clarity: In terms of language and writing style, the paper is written very clearly and easy to follow. In terms of presentation, there are some details that are omitted which would have made understanding easier and the work more reproducible.\n* Quality: The idea that is introduced seems intuitive and reasonable, but the experiments does not have enough details to prove that this method works (i.e. no quantitative results presented).  Moreover, the presentation of the method is not very well done (missing details), especially since the authors used the upper limit of 10 pages.\n* Originality: I am not familiar with the literature of generative models to judge this precisely, but according to the related work section it sounds like an original idea that is worth sharing.\n* Significance: I believe the idea of modeling data composition explicitly sounds intuitive and interesting, and it is worth sharing. However, the experimental section does not have enough evidence that it is actually possible to learn this, so it is not clear whether the contribution is significant.\n\nPros:\n-\tinteresting new problem formulation \n-\tsimple and clear language\n-\tthe theoretical analysis in the last section could be interesting more generally in the context of GANs\n-\tthe framework is applied on 2 different modalities: images and text.\n\nCons:\n-\thard to tell whether this approach works since the metrics for evaluation are not specified and there are no quantitative results in the experimental section (only 1 qualitative example per task)\n-\tthe work is not reproducible due to the lack of details (see more explanations below)\n-\tthe theoretical analysis is a standalone piece of the paper, without any discussion about the implications, or making connections to the previous sections.\n\nDetailed comments:\n1.\tI believe the weakest part of this paper is the evaluation section. The authors run their framework on 4 tasks of increasing difficulty. While the MNIST examples make for a nice and intuitive qualitative analysis, the are no quantitative results at all. The only result that is reported for each task is one qualitative picture. The authors make statements such as \u201cThe decomposition network learns to decompose the digits and backgrounds correctly\u201d , \u201cGiven one component, decomposition function and the other component can be learned.\u201d but there is not mention for how these conclusion are made (no metrics, no numbers). Indeed, it is difficult in general to quantify the results of generative models, but most other GAN papers introduce some sort metric that can be used to aggregate the evaluation on an entire dataset. If the authors manually inspected the results, they should at least report how many images they inspected and how many looked correct. \n2.\tAside from evaluation, there are some other details missing from the presentation. The individual details may not be major, but because all of these are missing together, it really affects the overall quality of the paper. For example:\n    \uf0a7\t the authors state: \u201cTo train discriminator(s), a regularization is applied. For brevity, we do not show the regularization term (see Petzka et al. (2017)) used in our experiments.\u201d. For reproducibility purposes, I believe it is important to at least mention the type of regularization, at least in the appendix. \n    \uf0a7\tThere is a parameter alpha used to balance the losses. What values was used in the experiments?\n    \uf0a7\tChoices of models are often not explained. Why did you choose that form for c(o1, o2) in section 3.3? Why DCGAN for component generators, and U-net for decomposition?\n    \uf0a7\tIt is not explained in detail how the Yelp-reviews dataset is altered to achieve coherence. The authors mention that \u201cAs we sample a pair independently, the input sentences are not generally coherent but the coherence can be achieved with a small number of changes.\u201d. However, the specific algorithm by which these changes are made is not specified, and thus it can\u2019t be reproduced.\n3.\tThe theoretical section is an interesting contribution, but the paper just states a list of theorems without making any connections to the applications used before, or a broader discussion about how these fit in the context of GANs more generally.\n4.\tMy understanding is that both datasets used are created by the authors by making alterations to MNIST and Yelp-reviews dataset, thus making them to some extent synthetic datasets suited to fit this problem formulation. I would have like to see how this composition/decomposition works on existing datasets with no alterations. Does it still work? \n5.\tIn section 2.3, in the coherent sentence experimental setting, I don\u2019t fully understand the design of the task. Figure 2 shows an example where composition and decomposition are not symmetric (i.e. composing then decomposing does not go back to the input sentences), although one of your losses is supposed to ensure exactly this cyclic consistency. Why not choose another problem that doesn\u2019t directly violate your assumptions?\n\nMinor issues: \n6.\tFrom the related work section, it is not clear how your approach is different from Azadi et al. (2018). Please include more details.\n7.\tIn section 2.4, you mention using Wasserstein GANs, with no further details about this model (not even a one line description). Without reading their paper, the readers of your paper could not easily follow through this section. The losses further introduced are also not explained intuitively (e.g. what do the two expectation terms in l_g_i represent?).\n8.\tI believe there are some errors in which tasks reference which figures in section 3.3. Should Task 2 refers to Figure 6, and Task 3 to Figure 7?\n9.\tWhat exactly is range(.) in section 4? If this refers to the interval of values that a variable can take, the saying \u201cis a matrix of size |range(Z)| \u00d7 |range(Y )|\u201d doesn\u2019t exactly make sense. Please define formally. \n\nFinal remarks and advice: \nOverall, I believe the paper introduces some interesting ideas. There is definitely value in the problem definition and theoretical analysis. However, I believe the paper needs more work on presentation and evaluation, especially since the authors opted for 10 pages and according to ICLR guidelines \u201cReviewers will be instructed to apply a higher standard to papers in excess of 8 pages.\u201d. Hopefully the above comments will help the authors improve this work!", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1365/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Official_Review", "cdate": 1542234245457, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1365/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335931117, "tmdate": 1552335931117, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1365/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1e7Mx3A2m", "original": null, "number": 1, "cdate": 1541484554919, "ddate": null, "tcdate": 1541484554919, "tmdate": 1541484554919, "tddate": null, "forum": "rJgP7hR5YQ", "replyto": "rJgP7hR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1365/Public_Comment", "content": {"comment": "Dear Authors,\n \nCould you please provide more details on your generators\u2019 architectures? I am particularly interested in your MNIST-BB experiment (Figure 4) and the fact of rotating and shifting digits according to the given background. I think a Resnet or a Unet generator is not able to rotate, shift, and scale objects by an adversarial loss function. This is why a spatial transformer was used in the ST-GAN [1] and Compositional GAN [2] papers. It would be great if you could clarify this.\n\n[1]: Lin, et al. \"ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing.\"\u00a0\n[2]: Azadi, et al. \"Compositional GAN: Learning Conditional Image Composition.\"\u00a0", "title": "Not clear how to spatially transform objects"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1365/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COMPOSITION AND DECOMPOSITION OF GANS", "abstract": "In this work, we propose a composition/decomposition framework for adversarially training generative models on composed data - data where each sample can be thought of as being constructed from a fixed number of components. In our framework, samples are generated by sampling components from component generators and feeding these components to a composition function which combines them into a \u201ccomposed sample\u201d. This compositional training approach improves the modularity, extensibility and interpretability of Generative Adversarial Networks (GANs) - providing a principled way to incrementally construct complex models out of simpler component models, and allowing for explicit \u201cdivision of responsibility\u201d between these components. Using this framework, we define a family of learning tasks and evaluate their feasibility on two datasets in two different data modalities (image and text). Lastly, we derive sufficient conditions such that these compositional generative models are identifiable. Our work provides a principled approach to building on pretrained generative models or for exploiting the compositional nature of data distributions to train extensible and interpretable models.\n", "keywords": [], "authorids": ["ycharn@cs.unc.edu", "chen.zhenghao@gmail.com", "vjojic@gmail.com"], "authors": ["Yeu-Chern Harn", "Zhenghao Chen", "Vladimir Jojic"], "TL;DR": "GANs can be composed to build more complex models and decomposed to obtain building blocks", "pdf": "/pdf/65ca1a26823ef5457e32d1b9dc5d90283e1a4f1f.pdf", "paperhash": "harn|composition_and_decomposition_of_gans", "_bibtex": "@misc{\nharn2019composition,\ntitle={{COMPOSITION} {AND} {DECOMPOSITION} {OF} {GANS}},\nauthor={Yeu-Chern Harn and Zhenghao Chen and Vladimir Jojic},\nyear={2019},\nurl={https://openreview.net/forum?id=rJgP7hR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1365/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311614662, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rJgP7hR5YQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1365/Authors", "ICLR.cc/2019/Conference/Paper1365/Reviewers", "ICLR.cc/2019/Conference/Paper1365/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311614662}}}], "count": 10}