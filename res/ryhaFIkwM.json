{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124454806, "tcdate": 1518459332388, "number": 188, "cdate": 1518459332388, "id": "ryhaFIkwM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ryhaFIkwM", "signatures": ["~Masahiro_Suzuki1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Semi-Supervised Multimodal Learning with Deep Generative Models", "abstract": "In recent years, deep neural networks are used mainly as discriminators of multimodal learning. We should have large amounts of labeled data for training them, but obtaining such data is difficult because it requires much labor to label inputs. Therefore, semi-supervised learning, which improves the discriminator performance using unlabeled data, is important. Among semi-supervised learning, methods based on deep generative models such as variational autoencoders (VAEs) are known to be trained end-to-end with high accuracy. In this paper, we propose a novel model of semi-supervised multimodal learning based on multimodal VAEs: SS-HMVAE. Furthermore, to cope with unimodal inputs in test data, we propose an extended model based on existing studies of complementation of  missing values, which we call SS-HMVAE-kl. From experimentation, we confirm that the proposed model has higher performance than either conventional unimodal or multimodal semi-supervised learning.", "paperhash": "suzuki|semisupervised_multimodal_learning_with_deep_generative_models", "_bibtex": "@misc{\n  suzuki2018semi-supervised,\n  title={Semi-Supervised Multimodal Learning with Deep Generative Models},\n  author={Masahiro Suzuki and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ryhaFIkwM}\n}", "authorids": ["masa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "authors": ["Masahiro Suzuki", "Yutaka Matsuo"], "keywords": [], "pdf": "/pdf/d539971722db4109bd34c93a3093ea419dc4796e.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582986978, "tcdate": 1519620226277, "number": 1, "cdate": 1519620226277, "id": "HJcYeG-Of", "invitation": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "signatures": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer2"], "content": {"title": "Very dense, bit difficult to read, experimental results seem ok", "rating": "6: Marginally above acceptance threshold", "review": "The idea is to have a VAE for multimodal data . for semi-supervised learning.\nA generative model is defined, starting by defining a distribution of the labels to condition the generative process of the two modalities. \n\nThe description of SS-HMVAE-kl is so concise that it becomes unclear to me.\n\nThere are a couple of sentences (second to last paragraph on P2) that need updating.\nThe experimental results appear to be good, but I have difficulties understanding what is actually been done. \n\nI believe the current version to be good enough for workshop acceptance.\nI would recommend the authors to update the wording in the manuscript. ", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-Supervised Multimodal Learning with Deep Generative Models", "abstract": "In recent years, deep neural networks are used mainly as discriminators of multimodal learning. We should have large amounts of labeled data for training them, but obtaining such data is difficult because it requires much labor to label inputs. Therefore, semi-supervised learning, which improves the discriminator performance using unlabeled data, is important. Among semi-supervised learning, methods based on deep generative models such as variational autoencoders (VAEs) are known to be trained end-to-end with high accuracy. In this paper, we propose a novel model of semi-supervised multimodal learning based on multimodal VAEs: SS-HMVAE. Furthermore, to cope with unimodal inputs in test data, we propose an extended model based on existing studies of complementation of  missing values, which we call SS-HMVAE-kl. From experimentation, we confirm that the proposed model has higher performance than either conventional unimodal or multimodal semi-supervised learning.", "paperhash": "suzuki|semisupervised_multimodal_learning_with_deep_generative_models", "_bibtex": "@misc{\n  suzuki2018semi-supervised,\n  title={Semi-Supervised Multimodal Learning with Deep Generative Models},\n  author={Masahiro Suzuki and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ryhaFIkwM}\n}", "authorids": ["masa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "authors": ["Masahiro Suzuki", "Yutaka Matsuo"], "keywords": [], "pdf": "/pdf/d539971722db4109bd34c93a3093ea419dc4796e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986771, "id": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper188/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer1"], "reply": {"forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986771}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582719390, "tcdate": 1520683452922, "number": 2, "cdate": 1520683452922, "id": "BySTtrbFz", "invitation": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "signatures": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer3"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposed SS-HMVAE and SS-HMVAE-kl for semi-supervised multimodal learning. Specifically, the models proposed in this paper are quite similar to M2 of Diederik P Kingma 2014 with the difference in that multimodal data are considered. Hence I think the novelty is incremental. Moreover, it seems the decomposition of q_{\\phi}(a,z|x,w,y) under equation 1 is incorrect, since y is missed. As for the experimental results, the improvement over other baselines is not significant. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-Supervised Multimodal Learning with Deep Generative Models", "abstract": "In recent years, deep neural networks are used mainly as discriminators of multimodal learning. We should have large amounts of labeled data for training them, but obtaining such data is difficult because it requires much labor to label inputs. Therefore, semi-supervised learning, which improves the discriminator performance using unlabeled data, is important. Among semi-supervised learning, methods based on deep generative models such as variational autoencoders (VAEs) are known to be trained end-to-end with high accuracy. In this paper, we propose a novel model of semi-supervised multimodal learning based on multimodal VAEs: SS-HMVAE. Furthermore, to cope with unimodal inputs in test data, we propose an extended model based on existing studies of complementation of  missing values, which we call SS-HMVAE-kl. From experimentation, we confirm that the proposed model has higher performance than either conventional unimodal or multimodal semi-supervised learning.", "paperhash": "suzuki|semisupervised_multimodal_learning_with_deep_generative_models", "_bibtex": "@misc{\n  suzuki2018semi-supervised,\n  title={Semi-Supervised Multimodal Learning with Deep Generative Models},\n  author={Masahiro Suzuki and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ryhaFIkwM}\n}", "authorids": ["masa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "authors": ["Masahiro Suzuki", "Yutaka Matsuo"], "keywords": [], "pdf": "/pdf/d539971722db4109bd34c93a3093ea419dc4796e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986771, "id": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper188/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer1"], "reply": {"forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986771}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582609386, "tcdate": 1520897162927, "number": 3, "cdate": 1520897162927, "id": "BkQ9nYNKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "signatures": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer1"], "content": {"title": "not exciting enough for an iclr workshop paper", "rating": "5: Marginally below acceptance threshold", "review": "Summary:\nThis paper proposes a VAE model for semi-supervised multimodal learning--that is semi-supervised learning when the covariates have different domains of definition. The model is extended to deal with the problem of missing covariate at test time.\n\nQuality:\nThe maths is correct.\n\nClarity:\nThe paper can benefit from a lot of editing but the overall goal and idea are clear.\n\nOriginality and Significance:\nIt is marginal. See Suzuki et al 2016", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-Supervised Multimodal Learning with Deep Generative Models", "abstract": "In recent years, deep neural networks are used mainly as discriminators of multimodal learning. We should have large amounts of labeled data for training them, but obtaining such data is difficult because it requires much labor to label inputs. Therefore, semi-supervised learning, which improves the discriminator performance using unlabeled data, is important. Among semi-supervised learning, methods based on deep generative models such as variational autoencoders (VAEs) are known to be trained end-to-end with high accuracy. In this paper, we propose a novel model of semi-supervised multimodal learning based on multimodal VAEs: SS-HMVAE. Furthermore, to cope with unimodal inputs in test data, we propose an extended model based on existing studies of complementation of  missing values, which we call SS-HMVAE-kl. From experimentation, we confirm that the proposed model has higher performance than either conventional unimodal or multimodal semi-supervised learning.", "paperhash": "suzuki|semisupervised_multimodal_learning_with_deep_generative_models", "_bibtex": "@misc{\n  suzuki2018semi-supervised,\n  title={Semi-Supervised Multimodal Learning with Deep Generative Models},\n  author={Masahiro Suzuki and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ryhaFIkwM}\n}", "authorids": ["masa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "authors": ["Masahiro Suzuki", "Yutaka Matsuo"], "keywords": [], "pdf": "/pdf/d539971722db4109bd34c93a3093ea419dc4796e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986771, "id": "ICLR.cc/2018/Workshop/-/Paper188/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper188/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper188/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper188/AnonReviewer1"], "reply": {"forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper188/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986771}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573585841, "tcdate": 1521573585841, "number": 183, "cdate": 1521573585496, "id": "Sk9ACRCKG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ryhaFIkwM", "replyto": "ryhaFIkwM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-Supervised Multimodal Learning with Deep Generative Models", "abstract": "In recent years, deep neural networks are used mainly as discriminators of multimodal learning. We should have large amounts of labeled data for training them, but obtaining such data is difficult because it requires much labor to label inputs. Therefore, semi-supervised learning, which improves the discriminator performance using unlabeled data, is important. Among semi-supervised learning, methods based on deep generative models such as variational autoencoders (VAEs) are known to be trained end-to-end with high accuracy. In this paper, we propose a novel model of semi-supervised multimodal learning based on multimodal VAEs: SS-HMVAE. Furthermore, to cope with unimodal inputs in test data, we propose an extended model based on existing studies of complementation of  missing values, which we call SS-HMVAE-kl. From experimentation, we confirm that the proposed model has higher performance than either conventional unimodal or multimodal semi-supervised learning.", "paperhash": "suzuki|semisupervised_multimodal_learning_with_deep_generative_models", "_bibtex": "@misc{\n  suzuki2018semi-supervised,\n  title={Semi-Supervised Multimodal Learning with Deep Generative Models},\n  author={Masahiro Suzuki and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ryhaFIkwM}\n}", "authorids": ["masa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "authors": ["Masahiro Suzuki", "Yutaka Matsuo"], "keywords": [], "pdf": "/pdf/d539971722db4109bd34c93a3093ea419dc4796e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}