{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457856096308, "tcdate": 1457856096308, "id": "YW9joWo7zsLknpQqIKZ1", "invitation": "ICLR.cc/2016/workshop/-/paper/161/comment", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "L7VjEWkOpTRNGwArs4jX", "signatures": ["~Edward_Choi1"], "readers": ["everyone"], "writers": ["~Edward_Choi1"], "content": {"title": "Authors' response to the comments", "comment": "Thank you for your comments and suggestion.\n1) This is a good suggestion. We did not see improvement when using a larger context window for training visit representation, and some changes along this line could alleviate this issue. \n2) We used age, gender and ethnicity for the demographic information, as mentioned in the extended version. Defining the demographic information as an input to f_V is a correct statement. We will revise this part in the final version.\n3) X-axis of figure 2 was an oversight at the last moment. The correct labels are \u201cSize of the code representation\u201d, \u201cNumber of training epochs\u201d, \u201cSize of the visit representation\u201d, \u201cSize of the context window for training visit representation\u201d. We will correct this in the final version.\n4) The interpretation part is included in the extended version, but due to lack of space we could not put it in 3 pages."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455830787733, "ddate": null, "super": null, "final": null, "tcdate": 1455830787733, "id": "ICLR.cc/2016/workshop/-/paper/161/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/161/reviewer"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457765441718, "tcdate": 1457765441718, "id": "71Bozj5zOiAE8VvKUQRy", "invitation": "ICLR.cc/2016/workshop/-/paper/161/comment", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": ["~Edward_Choi1"], "readers": ["everyone"], "writers": ["~Edward_Choi1"], "content": {"title": "General response to the reviewers' comments", "comment": "We\u2019d like to thank the reviewers for the insightful comments. \nSome of the comments could be addressed by the extended version in ArXiv as we mentioned in the paper: http://arxiv.org/abs/1602.05568 \nDue to lack of space, we had to make compromises with details.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455830787733, "ddate": null, "super": null, "final": null, "tcdate": 1455830787733, "id": "ICLR.cc/2016/workshop/-/paper/161/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/161/reviewer"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457765128918, "tcdate": 1457765128918, "id": "71BozgLgnuAE8VvKUQRG", "invitation": "ICLR.cc/2016/workshop/-/paper/161/comment", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "GvV10KXRBi1WDOmRiMk4", "signatures": ["~Edward_Choi1"], "readers": ["everyone"], "writers": ["~Edward_Choi1"], "content": {"title": "Authors' response to the comments", "comment": "Thank you for your comments and suggestion.\n1) v_t, the visit representation at time t is trained to predict the codes from neighboring visits V_{t-w}, V_{t-w+1}, \u2026, V_{t+w}. The codes of V_t themselves are used to generate the visit representation v_t. The application where we use v_t to predict the codes in V_{t+1} is for evaluation purposes. We do not learn visit representations only for that prediction task. In the extended version, we conduct another prediction task for additional evaluation. \n2) We used age, gender and ethnicity as mentioned in the extended version. \n3) Stationarity [not to be confused with stationary random processes] is a keen observation. Patients rarely go through drastic changes in a short time window. That was the basis of our assumption that neighboring visits should be predictive of each other. Skip-gram seems to learn slowly compared to GloVe because it can only use local co-occurrence information. Med2Vec alleviates this problem by leveraging neighboring visits."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455830787733, "ddate": null, "super": null, "final": null, "tcdate": 1455830787733, "id": "ICLR.cc/2016/workshop/-/paper/161/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/161/reviewer"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457647087684, "tcdate": 1457647087684, "id": "GvV10KXRBi1WDOmRiMk4", "invitation": "ICLR.cc/2016/workshop/-/paper/161/review/12", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": ["ICLR.cc/2016/workshop/paper/161/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/161/reviewer/12"], "content": {"title": "Good application paper about a bag-of-words model with temporal dynamics", "rating": "7: Good paper, accept", "review": "This paper presents a simple two-layer neural network for modeling bag-of-word representations with temporal dynamics, applicable to sequences of related documents. The end-to-end learning algorithm consists in optimising the sum of two losses, the cross-entropy for co-occurrences of words in one document, and the cross-entropy for predicting words in a document appearing at a different time.\n\nInstead of words, the authors use medical codes (with a vocabulary of about 29k codes) in consecutive patient records, and demonstrate the applicability of their model to predicting medical codes records, using a set of 3.3M visits for 550k patients, and demonstrate that their model outperforms non-temporal models such as stacked-autoencoders, skip-grams or Glove vectors (as well as a plain sum of one-hot representations). When predicting the codes of the next visit, they achieve a recall of about 0.76 to 0.77 at 30 codes.\n\nThe paper is well written but some areas remain unclear.\n\n1) Why does loss function (1) and figure 1 suggest that codes from visit V_t are used interchangeably to predict codes from visists V_{t-w}, V_{t-w+1}, ..., V_{t-1}, V_{t+1}, ..., V_{t+w}? The application is to predict V_{t+1} from V_t.\n\n2) What are the demographic data used by the authors (vector d_t)?\n\n3) If I am not mistaken, the fact the one-hot vectors perform as well as the other methods seems to suggest that there is a strong stationarity in the consecutive visits, on which the authors should elaborate. Similarly, the performance of skip-grams is surprisingly bad compared to the other methods.\n\n\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580093614, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580093614, "id": "ICLR.cc/2016/workshop/-/paper/161/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "mO9mQWp8Rij1gPZ3Ul5q", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/161/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457647026687, "tcdate": 1457647026687, "id": "L7VjEWkOpTRNGwArs4jX", "invitation": "ICLR.cc/2016/workshop/-/paper/161/review/10", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": ["ICLR.cc/2016/workshop/paper/161/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/161/reviewer/10"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "This paper presents an interesting application of embedding learning algorithms to the Healthcare domain. It introduces a model that can jointly learn embeddings of two healthcare concepts: medical codes and patient visits. The set of all medical codes is analogous to words or the vocabulary of a language, and a patient visit is defined as a subset of all medical codes, i.e. a bag-of-words.\n\nThe paper is clear and well written. While the model used in this paper is not original, it is a good start for learning representations in the healthcare domain.\n\nMajor issues:\n1- I find the model used for learning visit representations a bit problematic. The prediction given a specific visit representation v_t is provided with several (in fact 2*w) different (bag-of-word) targets simultaneously, each for a different neighbouring visit. I believe this would cause some kind of \"unlearning\", where the model is asked to predict different things for the same input. \nA better model could be to use a different softmax for each neighbouring visit target, or aggregate those targets (e.g. average or AND) and ask the model to provide one single prediction per input.\n\n2- There is some important information missing. For example, I cannot find a definition of the demographic information d_t. In fact, using this information should be defined as input to the function f_V.\n\n3- Figure 2 has 4 different sub-plots, all with the same x-axis but with different ranges. It is not clear what the authors are trying to show here, and why not combining all of them in one plot.\n\n4- Claims about better interpretability of the representations are not supported by experimental result.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580022907, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580022907, "id": "ICLR.cc/2016/workshop/-/paper/161/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "mO9mQWp8Rij1gPZ3Ul5q", "replyto": "mO9mQWp8Rij1gPZ3Ul5q", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/161/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455728937917, "tcdate": 1455728937917, "id": "mO9mQWp8Rij1gPZ3Ul5q", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "mO9mQWp8Rij1gPZ3Ul5q", "signatures": ["~Edward_Choi1"], "readers": ["everyone"], "writers": ["~Edward_Choi1"], "content": {"CMT_id": "", "title": "Multi-layer Representation Learning for Medical Concepts", "abstract": "Learning efficient representations for concepts has been proven to be an important basis for many applications such as machine translation or document classification. \nProper representations of medical concepts such as diagnosis, medication, procedure codes and visits will have broad applications in healthcare analytics.  \nHowever, in Electronic Health Records (EHR) the visit sequences of patients include multiple concepts (diagnosis, procedure, and medication codes) per visit. \nThis structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within each visit. \nIn this work, we propose Med2Vec, which not only learns distributed representations for both medical codes and visits from a large EHR dataset with over 3 million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts.\nIn the experiments, Med2Vec displays significant improvement in key medical applications compared to popular baselines such as Skip-gram, GloVe and stacked autoencoder, while providing clinically meaningful interpretation.", "pdf": "/pdf/mO9mQWp8Rij1gPZ3Ul5q.pdf", "paperhash": "choi|multilayer_representation_learning_for_medical_concepts", "conflicts": ["gatech.edu", "usc.edu"], "authors": ["Edward Choi", "Mohammad Taha Bahadori", "Jimeng Sun", "Elizabeth Searles", "Catherine Coffey"], "authorids": ["mp2893@gatech.edu", "bahadori@gatech.edu", "jsun@cc.gatech.edu", "Elizabeth.Searles@choa.org", "Catherine.Coffey@choa.org"]}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 6}