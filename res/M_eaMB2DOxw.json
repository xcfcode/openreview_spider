{"notes": [{"id": "M_eaMB2DOxw", "original": "A-tMqVz10vB", "number": 1952, "cdate": 1601308215090, "ddate": null, "tcdate": 1601308215090, "tmdate": 1614985636508, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "LaWkb7nlPM", "original": null, "number": 1, "cdate": 1610040524876, "ddate": null, "tcdate": 1610040524876, "tmdate": 1610474133962, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper received reviews from experts in representation of invariant functions. They all have expressed concerns regarding the novelty of the technical contributions, and the lack of appropriate comparisons to existing results. This applies in particular to representation of symmetric functions using neural networks which was largely covered by previous works, as acknowledged by the authors. The authors are encouraged to consider the valuable inputs by the reviewers and revise accordingly. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040524864, "tmdate": 1610474133946, "id": "ICLR.cc/2021/Conference/Paper1952/-/Decision"}}}, {"id": "fsaeNYjzv2B", "original": null, "number": 4, "cdate": 1604193799045, "ddate": null, "tcdate": 1604193799045, "tmdate": 1606788957861, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review", "content": {"title": "About representing symmetric and asymmetric functions via neural networks.  Not clear the representations are helpful or informative.  Writing too informal and rushed for me to tell", "review": "This paper is about representing functions $\\psi : (\\mathbb{R}^d)^n \\rightarrow \\mathbb{R}$ that are symmetric or asymmetric with respect to the permutation group $S_n$.  The aim is to consider neural networks giving only functions that symmetric or asymmetric, and to establish universality results.  The motivation comes from applications such quantum physics or computer vision with permutation symmetries. \n\nHonestly, I am very unconvinced by this paper.  In particular, the representation for symmetric functions is essentially due to Newton ($d=1$) and to Weyl ($d > 1$).  On the other hand, the representation for asymmetric functions -- dressed up in elaborate notation and the language of Slater determinants -- seems to just be the statement that an asymmetric function is divisible by the Vandermonde determinant (when $d=1$).  Maybe there are interesting results in this paper, but the writing is so informal and apparently rushed, I simply could not tell.  Itemized comments follow.\n\n\nPage 1, Footnote 4, terminology: I would suggest just sticking to one of \u201ccovariant\u201d or \u201cequivariant\u201d throughout the paper\n\nPage 1, Definition 1, notation: Although I understand the authors are using Matlab notation when they write \u201c$\\{1 : n \\}$ is short for $\\{1, \\ldots, n\\}$\u201d, it would be more standard to abbreviate $[n] := \\{1, \\ldots, n\\}$.\n\nPage 2, usage of $d$, notation: Please define the meaning of $d$ before referring to this notation.\n\nPage 3: \u201cFunctions on sets of fixed size n are equivalent to symmetric functions in n variables.\u201d  Isn\u2019t it symmetric functions in n variables restricted to the domain where no two variables take the same value?\n\nPage 4: \u201cInstead of averaging, the minimum or maximum or median or many other compositions would\nalso work, but the average has the advantage that smooth \u001f lead to smooth \u001e and  , and more\ngeneral, preserves many desirable properties such as (Lipschitz/absolute/...) continuity, (k-times)\ndifferentiability, analyticity, etc.\u201d  Could the authors expand on what they mean by minimum, maximum, median or other compositions to (anti)symmetrize functions?  Never heard of that.  Also, it should be remarked that the averaging operator is an orthogonal linear projection onto the subspace of (anti)symmetric functions known as the Reynolds operator in classical group invariant theory; in particular, averaging has the property that it is the identity applied to the functions that are already (anti)symmetric.\n\nPage 4, Footnote 6: \u201cwhich induces uniform convergence on compacta\u201d. I had to google \u201ccompacta\u201d to find out it is the plural of compact subset or compact metric space. Suffice to say this word is not widely used.\n\nPage 4:  Do you mean $\\mathcal{G}_{func} := \\{g: \\mathbb{R}^m \\rightarrow \\mathbb{R}\\}$?  Also could you say more about how the basis templates $\\eta_b$ are coming in?\n\nPage 5: It is stated that computing with elementary symmetric polynomials \u201cis numerically more stable\u201d than with power sums.  Why?  Also why do \u201cwe need at least $m \\geq n$ functional bases for a continuous representation\u201d?\n\nPage 5: \u201c Every continuous AS function can be approximated/represented by a finite/infinite linear combination of such [Slater] determinants:\u201d Why?\n\nPage 6, Theorem 3, theorem statement: Thus you have reduced the representation of an antisymmetric function in $n$ variables to that of $n$ symmetric functions in $n-1$ variables, at the expense of an $n \\times n$ determinant.  It is not clear how computationally useful this could be, since symmetric functions in $n-1$ variables are nontrivial computationally to represent already, e.g., Theorem 2\u2019s approach would involve $n-1$ power sums.  \n\nPage 6, Theorem 3, proof: The actual representation of $\\psi({\\bf{x}})$ that is constructed in the proof is almost certainly not useful, namely that it is the determinant of the matrix whose rows look like the following:\n\n$$\n\\begin{pmatrix}\n\\psi({\\bf{x}}) / \\Delta({\\bf{x}})  & x_1 & x_1^2 & \\ldots & x_1^{n-1} \n\\end{pmatrix}\n$$\n$$\n\\begin{pmatrix}\n\\psi({\\bf{x}}) / \\Delta({\\bf{x}})  & x_2 & x_2^2 & \\ldots & x_2^{n-1} \n\\end{pmatrix}\n$$\n\netc. (Sorry, can't get multi-rowed matrices to render properly in OpenReview...)\n\nCrucial question: why is this a good way of expressing antisymmetric functions, in theory or practice?  The content here is that any asymmetric function is divisible by the Vandermonde determinant.  If the larger $d$ representation results depend on this, I don't know how much they tell me...\n\nPage 7: \u201cFor $d > 1$, the Fermion nodes $\\{{\\bf X} :  \\psi({\\bf X}) = 0\\}$ form essentially arbitrary $\\psi$-dependent unions of (non-linear) manifolds partitioning $\\mathbb{R}^{dn}$ into an arbitrary even number of cells of essentially arbitrary topology [Mit07].\u201d  This language is too intuitive for me.  What does this sentence mean??\n\nPage 7, Theorem 5, proof discussion:  \u201cWhether this generalizes to $n > 2$  and $d > 1$  is an open problem.\u201d  This is confusing.  Does the theorem have a restriction on $n$ and $d$?\n\nPage 7\u20138, \u201cEquivariant Neural Network\u201d subsection: work of Risi Kondor and coauthors needs to be cited here.\n\nPage 8, Theorem 6: It would help the reader to include in the body of the paper a more precise statement or diagram showing the construction of the approximating EMLP.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107151, "tmdate": 1606915807084, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1952/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review"}}}, {"id": "JCu-sW8HPym", "original": null, "number": 1, "cdate": 1603713972941, "ddate": null, "tcdate": 1603713972941, "tmdate": 1606742918133, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review", "content": {"title": "Interesting topic but missed significant previous works", "review": "Post discussion:\nI read the author's response and other reviews. I will stick to my rating and encourage the author to resubmit a revised version focusing on the antisymmetric case. \n\n\n\n\n\nSummary:\n\nThe paper studies the approximation power and shows universality results for two recent neural network models that represent symmetric and antisymmetric functions. The main contributions of the paper are claimed to be (1) Universality of Fermi-Net (antisymmetric model) with a single Generalized Slater determinant (2) Universality of symmetric MLPs. In both cases, the authors emphasize the fact that the theorems deal with (i) vector inputs rather than scalar inputs, and that (ii) the approximation results are based on smooth polynomials rather than discontinuous functions as done in previous works. \n\nWhile the problem the paper targets is interesting and important, the paper missed several important previous works and does not do a good job explaining their novelty with respect to the previous work that was cited. See below.\n\nContribution 1: I am not an expert on antisymmetric function approximation and didn\u2019t know Ferminet, but contribution 1 seems novel to me, although the authors should make a better job explaining the difference between their results and the original FermiNet paper. It is not entirely clear what was done before and what is new\n\nContribution 2 and points (i),(ii) were discussed before in several papers. First \u201cProvably Powerful Graph Networks\u201d (NeurIPS 2019) used the power sum multi symmetric polynomials for representing set functions in the same way they are used in this paper.  Second, \u201cOn universal equivariant set networks\u201d (ICLR 2020) proves a universal approximation theorem for equivariant set functions based on these polynomials. Given these two works, I am not sure the current paper has any additional contribution.\n\nStrong points:\n\nUnderstanding the approximation power of invariant/equivariant neural networks is an important goal.\nThe results on antisymmetric functions are nice\n\nWeak points:\n\nThe work is not properly positioned with respect to previous work and pretty much misses all the work done on the approximation of invariant functions since DeepSets. Except for the discussion above, the following should be cited/discussed:\n\n-- \u201cJanossy Pooling: Learning Deep Permutation-Invariant Functions for Variable-Size Inputs\u201d ICLR 2019, which discusses permutation sampling strategies. \n\n-- \u201cUniversal approximations of invariant maps by neural networks\u201d 2018 that discusses symmetrization and approximation of symmetric functions (and function invariant to many other compact groups). \n\n-- \u201cPointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\u201d CVPR 2017, which also show universal approximation for symmetric functions.\n\n-- \u201cOn the Universality of Invariant Networks\u201d, \"Universal Equivariant Multilayer Perceptrons\" ICML 2019/2020 might also be relevant.\n\nRecommendation:\n\nThe paper studies an important problem but missed significant previous work. I believe that the results on antisymmetric function approximation are novel and suggest rewriting the paper focused on these results, with a clear discussion on the contribution with respect to previous works. It might also be good to spend more time on Ferminet while doing so since this model is less known to the machine learning community. In its current form, The paper is not ready for publication.\n\nMinor comments:\n\nThe authors added a long version (22 pages) as an appendix. Not sure if this is OK. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107151, "tmdate": 1606915807084, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1952/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review"}}}, {"id": "o2fT2bngqCV", "original": null, "number": 3, "cdate": 1603861472292, "ddate": null, "tcdate": 1603861472292, "tmdate": 1606686705392, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review", "content": {"title": "A good contribution to the understanding of representing symmetric and anti-symmetric functions", "review": "Update:\nI have read the authors' responses and other comments.  I still think that the theoretical results on anti-symmetric functions of this submission are novel, which is, however, not well-delivered. A lot of space is wasted to discuss symmetric functions, for which the contributions of this paper are not clear.  I suggest substantially rewriting this paper by only focusing on the anti-symmetric functions. \n\n===============================================================\nSummary:\n\nThis paper studies the representation of symmetric and anti-symmetric functions as well as the parameterization with neural networks.  This issue is very important for applying deep learning to solve problems from computational quantum physics as well as point clouds.  \n\nPros:\n\nThis paper is well-organized, in particular the connection to the previous work.  The representations of symmetric and anti-symmetric functions are very important but less-studied problems. As I understand it, this paper makes some interesting contributions to this topic.  Theorem 3 & 5 are very especially interesting, which basically shows that one Slater determinant is enough to approximate any anti-symmetric functions. \n\nCons:\n\nWhile the theorems in this paper look pretty, it is not clear if they have computational advantages over the other ansatzes.  After all, no approximation rates and numerical results are provided. For example, computing Vandermonde determinants is much efficient than computing Slater determinants.  But as suggested in this paper, the approximation with Slater determinants is more efficient than the one with Vandermonde determinants. Combined them together, it is not clear which one will be more practical. Could you comment more on this point?\n\n\nOther comments:\nThe authors do not put the proofs in the appendix.  Instead, they provide an extended version of the paper in the supplemental material which includes the proofs.  This makes the reading of the proof more challenging since readers have to dig out the proofs from the long paper. So basically, there are two versions of this paper. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107151, "tmdate": 1606915807084, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1952/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review"}}}, {"id": "IqcrkI02Hyj", "original": null, "number": 4, "cdate": 1605870846694, "ddate": null, "tcdate": 1605870846694, "tmdate": 1606225331479, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "1-B5jF2nkMB", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment", "content": {"title": "Computation, Polynomial Approximation, Review, Straightforward", "comment": "Thank you for your review. The numbering below refers to the review\u2019s numbering\n\n1) I think there is a misunderstanding here. If I use a standard MLP (or any architecture not respecting permutation symmetry), the only known way to convert this to a guaranteed and exactly (anti)symmetric function in a differentiable and universal way is by summing _all_ n! permutations as per Eq.(1). You write, \u201cSure this is true, but the symmetries make a huge difference here.\u201d Which symmetries are you referring to? If \u03c7 is a general MLP with randomly initialized weights it contains no symmetries.  You may have in mind initializing or setting the weights to somehow make the MLP symmetric. Well, this is precisely the approach taken by [ZKR+18] and pursued here and proven to be universal in Theorem 6.\nRegarding low-degree polynomials: Of course you can approximate (anti)symmetric functions by general polynomials, but these approximations will in general not be _exactly_ (anti)symmetric, and exact (anti)symmetry is crucial in quantum physics applications. If we are content with approximate anti-symmetry, we could indeed just use a general MLPs, which we already know to be universal. But this may require an exponentially larger training size, as compared to using MLPs (EMLP/FermiNet) that are intrinsically (anti)symmetric. All this is explained in Section 3 of the paper.\n\n2) The \u201cbroadest review\u201d was intended to refer only to the extended version, but I realize that I failed to edit this out for the submission (which is not a review). Virtually everything introduced or discussed in the first 5 pages is either to motivate why simpler approaches fail -or- are required background or notation to formulate and understand the theorems and proofs, and rather compactly so. The extended version indeed contains a broad review, since apparently even the \u201coverlong\u201d background discussion in the main paper fails to confer why we need this complicated approach via Slater determinants, equivariant MLPs, and symmetric polynomials.\n\n3) If Theorem 6 is straightforward, I am curious to hear whether universality holds for a 1-hidden layer EMLP, and if not, why 2 layers are needed while 1-hidden-layer MLPs are universal. If theorems Theorem 3 and 5 are straightforward, I am curious to hear whether the loss of differentiability in Theorem 3 is an artifact of the proof, or an intrinsic problem of the GSD, or, why the answers to these questions are not obvious. In hindsight and with sufficient knowledge, most proofs are \u201cstraightforward in some sense\u201d. The main results are the stated theorems and discussed before and after the theorem and are not swept under the rug. The immense importance and practical success of the FermiNet is mentioned in Section 2 and demonstrated in [PSMF20]. I presume the reviewer would like me to add a paragraph about the importance of quantum physics simulations in general and [PSMF20] in particular."}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "M_eaMB2DOxw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1952/Authors|ICLR.cc/2021/Conference/Paper1952/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853908, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment"}}}, {"id": "n6_-YLByLsI", "original": null, "number": 2, "cdate": 1605869797030, "ddate": null, "tcdate": 1605869797030, "tmdate": 1606224891940, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "fsaeNYjzv2B", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment", "content": {"title": "Clarification of Reviewers Questions", "comment": "Thank you for your detailed review. The numbering below refers to the review\u2019s paragraphs. \n\n2) Newton and Weyl form the core of the proof, but the equivariance proof of EMLP is non-trivial and anything but a straightforward consequence of them. The discussion is naturally and deliberately informal but due to space restrictions dense at places, but the theorems themselves and the proofs in most parts are formal and complete, or if not, clarifications before or after the theorems are provided. The paper is neither rushed nor too informal. Regarding where the interesting results are, they are primarily concentrated in the theorems, and arguably in Table 1 in the supplementary and the discussion of open problems.\n\n3) Except on page 1 where I discuss the various symmetry concepts more broadly, I only use \u2018equivariant\u2019 and do not mention \u2018covariant\u2019 anymore.\n\n4) {1:n} is not taken from Matlab but may have the same origin. I find the contraction {1,\u2026,n} \u2192 {1...n} \u2192 {1\u22een} \u2192 {1:n} more \u201cautological\u201d than the more fashionable [n] notation.\n\n5) Define d=1 before usage: OK\n\n6) In the NN literature \u2018set\u2019 is usually misused as / short-for \u2018multi-set\u2019, but that indeed should either be avoided or noted.\n\n7) Replace the average (1/n!)\u2211\u2026 over permutations in (1) by min{\u2026}, max{\u2026}, or median{\u2026}, e.g. \u03d5(x) := min{\u03c7(S_\u03c0(x)) : \u03c0\u2208S_n}, but maybe I misunderstand your question. I can mention that this is an orthogonal linear projection, called Reynolds operator. That the average (and min/max/median{\u03c7(S_\u03c0(x)) : \u03c0\u2208S_n}) leave (anti)symmetric functions \u03c7 unchanged is directly implied by what I write (formally) in the line after (1) \u201c(proof: use \u03c7 := \u03c6 or \u03c7 := \u03c8)\u201d.\n\n8) While stand-alone \u201ccompacta\u201d is rarely used in math, the expression \u201cuniform convergence on compacta\u201d is a reasonably well-known notion of convergence (7000+ Google hits) corresponding to the compact-open topology.\n\n9) Yes, G_func is the set of all functions. I am not sure what to say beyond that the basis templates \u03b7 are one way to generate (multi)symmetric bases, which is particularly relevant for equivariant NN, since they \u201cmatch\u201d the local structure.\n\n10) Afair, a representation based on elementary symmetric polynomials is less likely to require large positive and negative terms subtly canceling each other compared to using power sums as basis. The need for m\u2265n is explained in the provided reference [WFE+19], essentially because there are no continuous injections from \u211d^n to \u211d^m if m<n.\n\n11) That every continuous AS function can be approximated/represented by a finite/infinite linear combination of such [Slater] determinants is a folk result in physics. In non-physics linear-algebra terms, roughly speaking, it generalizes the well-know fact that any m\u00d7m matrix can be represented as a sum of m rank-1 matrices. For AS you need rank-2 matrices, then you generalize this to tensors of order n, and then from vectors to functions. In physics jargon, this is called the Full Configuration Interaction, which can solve any n-particle Schr\u00f6dinger equation exactly.\n\n12) Reducing the problem of representing AS functions to the problem of representing symmetric/equivariant functions is as of today the _only_ feasible way of representing AS functions (for n>10 and d>1), and since the symmetric/equivariant functions can be efficiently approximated by EMLPs (the whole point of the other half of the paper) this reduction _is_ useful. There are no analogous \u201crestricted\u201d MLPs representing AS functions directly without the detour via determinants. There is a reason why virtually all quantum physicists use this approach, and [PSMF20] and many other papers demonstrate how/that this works in practice.\n\n13) To prove universality, one only needs to show the existence of _some_ representation. In all likelihood the approximation found by training a NN is different from the construction used in any universality proof. The construction in Thm.3 for AS(d=1) is actually not too bad, since smooth \u03c8 are represented by smooth (and non-singular) \u03c7, though the loss of differentiability is disconcerting. It makes more sense to criticize the creative but unreasonable construction in the proof of Thm.5 for d>1. But as stated, in both cases it is an open problem whether this is a rectifiable artifact of the proof, or an intrinsic problem of the GSD approach itself.\n\n14) The provided reference to slides [Mit07] contain beautiful illustrations and explanations, which are way beyond the scope of this paper.\n\n15) Theorems 3 and 5 hold for any n. The last \u00a7 of Section 5 provides a superior construction for n=2, but whether this n=2 \u201cresult\u201d generalizes to n>2 is an open problem.\n\n16) OK\n\n17) Indeed, a diagram would help provided I can come up with one which is more than just showing a generic 3-Layer EMLP labeled with \u03b7, \u03c1, \u03c6. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "M_eaMB2DOxw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1952/Authors|ICLR.cc/2021/Conference/Paper1952/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853908, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment"}}}, {"id": "jF4Wf4MosV0", "original": null, "number": 5, "cdate": 1605871441621, "ddate": null, "tcdate": 1605871441621, "tmdate": 1605871480301, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "JCu-sW8HPym", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment", "content": {"title": "Difference to FermiNet Paper and Missing References", "comment": "Thank you for your review. The numbering below refers to the review\u2019s numbering: \n\nC1) [PSMF20] introduces the FermiNet and experimentally evaluates it. They observe that increasing the number of GSDs increases empirical performance. There is no theoretical analysis in this paper. A natural and important question arises whether fewer GSDs even if compensated by larger NNs perform worse due to an inherent minimal approximation error, so a large number of GSDs is unavoidable, or for other reasons, e.g. failure of the learning algorithm, which if overcome could reduce the number of expensive GSD evaluations. The theoretically clean version of this question is whether a FermiNet with a bounded number of GSDs (or even just 1 GSD) is universal, or whether increasing accuracy requires increasing the number of GSDs. Since the latter is true for (a) classical Slater determinant representations and (b) experimentally for GSDs, the discovery that 1 GSD suffices in theory was unexpected (at least for d>1).\n\nC2) Thank you very much for the provided references. They are all sufficiently relevant to include in the background section, but the one true embarrassing omission is \u201cOn universal equivariant set networks\u201d (ICLR 2020). This (great) paper indeed proves universality of EMLPs with essentially the same approach, though my polynomial construction is a little simpler. It is a bit surprising that it didn\u2019t come up during my literature search. Given this prior work, the EMLP part of my submission becomes more-or-less redundant, leaving the anti-symmetric part (and the IMO nice survey of approaches in the supplementary), which, I admit, in itself doesn\u2019t seem to warrant acceptance at ICLR unless someone could solve the loss-of-differentiability problem. The only consolation is that the statement by some of the other reviewers that (the proof of) Theorem 6 is trivial / straightforward / not worth publishing is at odds with the fact that the above work, which essentially is \u201cjust\u201d this proof, has been accepted at ICLR.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "M_eaMB2DOxw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1952/Authors|ICLR.cc/2021/Conference/Paper1952/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853908, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment"}}}, {"id": "FxxB0hENYAO", "original": null, "number": 3, "cdate": 1605870114491, "ddate": null, "tcdate": 1605870114491, "tmdate": 1605870114491, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "o2fT2bngqCV", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment", "content": {"title": "Computational Advantages over other Ansatzes", "comment": "Thank you for your review.\nRegarding your question about computational advantages: I am not sure which \u201cother ansatzes\u201d you are referring to. For d>1, and n>10 (say), the Slater determinant, which can be computed in time O(n^3), is the _only_ known computationally feasible approach for representing AS functions. \nFor d=1 (only), AS functions can also be represented using the Vandermonde determinant, which can be computed in time O(n^2). Both are much faster than naive (anti)symmetrization, which takes time O(n!). Maybe you are referring to a sorting representation, which can be computed in time O(n), but this is not differentiable, or sampling which is not exact, both are problematic in quantum physics applications, so has any other approach that has been suggested so far. Sec.3 and Table 1 of the extended version reviews the difficulties alternative representation approaches face. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "M_eaMB2DOxw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1952/Authors|ICLR.cc/2021/Conference/Paper1952/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853908, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Comment"}}}, {"id": "1-B5jF2nkMB", "original": null, "number": 2, "cdate": 1603817476834, "ddate": null, "tcdate": 1603817476834, "tmdate": 1605024321117, "tddate": null, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "invitation": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review", "content": {"title": "review for antisymmetric", "review": "In this paper the authors study the representability of symmetric or antisymmetric functions using neural networks. In particular, we say f: R^n -> R is symmetric/ antisymmetric if f(x)= f(pi(x)) for all pi in S_n or is of the form f(x)= sign(pi) *f(pi(x)) where sign(pi) is the sign of the permutation. Such functions with such symmetries are ubiquitous\u00a0in quantum physics since if one looks at the wave function of a\u00a0 system of identical bosons, then they are symmetric and if you look at fermions they are antisymmetric. In this paper they authors try to understand if there exists succinct\u00a0architectures that can learn/represent functions with such a symmetry property.\u00a0 In this direction the author makes a few observations For every \"nice\" antisymmetric function f, there exists a symmetric function Phi and a matrix associated to Phi such that determinant of Phi can be used to represent f.\u00a0 Then the authors show that the standard Ferminet (the first demonstration of deep learning) can be used to represent determinants of slater determinant and hence an arbitrary continous antisymmetric function.\n\nOverall, this paper is interesting to read but I wouldn't recommend it for acceptance for the following reasons:\n\n1) There are many points which seem like \"overselling\". The author claims that a polynomial f: R^n -> R has n! many terms and that is too many to approximate and so on. Sure this is true, but the symmetries make a huge difference here. Additionally, there is a rich theory of approximation theory saying we can approximate symmetric functions by low-degree polynomials, so why not just allow the NN to compute this low-degree polynomial which in turn approximates f?\u00a0\n\n2) It seems to me that this paper is more of a review, than something novel. Even the author at many places claims that this paper is a thorough review, so its not clear if it clears the bar for ICLR.\n\n3) The main results of this paper are straightforward in some sense. In fact the author doesn't even talk of the main results for the first 5 pages and the main results are simply swept under the rag, and it's not clear to me what is the novelty of the results in that case.\u00a0The quantum motivation also seems very weak, i prefer a much more solid motivation for why such functions are useful (given the author mentions practicality).\n\nGiven these reservations I wouldn't accept it for recommendation.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1952/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1952/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Representing (Anti)Symmetric Functions", "authorids": ["~Marcus_Hutter1"], "authors": ["Marcus Hutter"], "keywords": ["Neural network", "approximation", "universality", "Slater determinant", "Vandermonde matrix", "equivariance", "symmetry", "anti-symmetry", "symmetric polynomials", "polarized basis", "multilayer perceptron", "continuity", "smoothness"], "abstract": "Permutation-invariant, -equivariant, and -covariant functions and anti-symmetric functions are important in quantum physics, computer vision, and other disciplines. Applications often require most or all of the following properties: (a) a large class of such functions can be approximated, e.g. all continuous function (b) only the (anti)symmetric functions can be represented (c) a fast algorithm for computing the approximation (d) the representation itself is continuous or differentiable (e) the architecture is suitable for learning the function from data (Anti)symmetric neural networks have recently been developed and applied with great success. A few theoretical approximation results have been proven, but many questions are still open, especially for particles in more than one dimension and the anti-symmetric case, which this work focuses on. More concretely, we derive natural polynomial approximations in the symmetric case, and approximations based on a single generalized Slater determinant in the anti-symmetric case. Unlike some previous super-exponential and discontinuous approximations, these seem a more promising basis for future tighter bounds.", "one-sentence_summary": "We prove universality of the symmetric/equivariant 2-hidden-layer Perceptron and of the FermiNet with a single generalized Slater determinant, both based on polynomials and for particles of arbitrary dimension.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hutter|on_representing_antisymmetric_functions", "supplementary_material": "/attachment/b7ec381a0b44a3d00d9115225f0f2cae5c103984.zip", "pdf": "/pdf/ceb82fadd82d17e8d0b7c92bdc97cacfc2ace6d8.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=FX1-zRfnSu", "_bibtex": "@misc{\nhutter2021on,\ntitle={On Representing (Anti)Symmetric Functions},\nauthor={Marcus Hutter},\nyear={2021},\nurl={https://openreview.net/forum?id=M_eaMB2DOxw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "M_eaMB2DOxw", "replyto": "M_eaMB2DOxw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1952/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538107151, "tmdate": 1606915807084, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1952/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1952/-/Official_Review"}}}], "count": 10}