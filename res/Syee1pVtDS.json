{"notes": [{"id": "Syee1pVtDS", "original": "H1eDMWNrPH", "number": 289, "cdate": 1569438936271, "ddate": null, "tcdate": 1569438936271, "tmdate": 1577168224262, "tddate": null, "forum": "Syee1pVtDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "4IIz4JjqHT", "original": null, "number": 1, "cdate": 1576798692355, "ddate": null, "tcdate": 1576798692355, "tmdate": 1576800942985, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes  a decentralized algorithm with regret for distributed online convex optimization problems. The reviewers worry about the assumptions and the theoretical settings, they also find that the experimental evaluation  is insufficient.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795723632, "tmdate": 1576800275142, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper289/-/Decision"}}}, {"id": "Skek9hvCKH", "original": null, "number": 2, "cdate": 1571875975103, "ddate": null, "tcdate": 1571875975103, "tmdate": 1574880817190, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "The authors study distributed online convex optimization where the distributed system consists of various computing units connected by a time varying graph. The authors prove optimal regret bounds for a proposed decentralized algorithm and experimentally evaluate the performance of their algorithms on distributed online regularized linear regression problems.\n\nThe paper seems well written and well researched and places itself well in context of current literature. The authors also improve the state of the art in the field. The main weakness of the paper is the limited experimental evaluation and applicability of the assumptions and the theoretical setting that underpins this work.\n\n[Edit: After going through the other reviews, I have downgraded my score. The revised version of the paper the authors uploaded is 23 pages long with the main paper body being 10 pages. The CFP instructs reviewers to apply a higher standard to judge such long papers. I  am not convinced that the paper is solving an important problem that merits such a long paper.]", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947068939, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper289/Reviewers"], "noninvitees": [], "tcdate": 1570237754294, "tmdate": 1574947068950, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Review"}}}, {"id": "ryx0Hfpvor", "original": null, "number": 5, "cdate": 1573536325609, "ddate": null, "tcdate": 1573536325609, "tmdate": 1573536325609, "tddate": null, "forum": "Syee1pVtDS", "replyto": "BkxpNs8MiS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment", "content": {"title": "I have read the rebuttal", "comment": "Thanks for your response. I believe the additional empirical studies make the paper more convincing."}, "signatures": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer2"], "readers": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syee1pVtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper289/Authors|ICLR.cc/2020/Conference/Paper289/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173608, "tmdate": 1576860557523, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment"}}}, {"id": "HygP8E7msS", "original": null, "number": 4, "cdate": 1573233743332, "ddate": null, "tcdate": 1573233743332, "tmdate": 1573233743332, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment", "content": {"title": "Revision uploaded", "comment": "We thank all the reviewers for their invaluable and constructive feedback. We have replied to each reviewer's concerns separately, and uploaded a revised version of our paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper289/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syee1pVtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper289/Authors|ICLR.cc/2020/Conference/Paper289/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173608, "tmdate": 1576860557523, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment"}}}, {"id": "HJgoRcIfor", "original": null, "number": 2, "cdate": 1573182163293, "ddate": null, "tcdate": 1573182163293, "tmdate": 1573232103807, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Skek9hvCKH", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment", "content": {"title": "Response to Official Blind Review #3", "comment": "We thank the Reviewer for the positive comments. \n\nAbout our assumptions. Assumption 4 is quite standard in the literature on distributed online or offline optimization, and easy to achieve in a distributed manner in real-world networks. For example, when bidirectional communication between nodes is allowed, we can enforce symmetry on the node interaction matrix, which immediately makes it doubly stochastic. There are also other methods to construct doubly stochastic matrices for a network, see, e.g., [F. Garin and L. Schenato. A survey on distributed estimation and control applications using linear consensus algorithms, 2011] and [Bahman Gharesifard and Jorge Cortes. When does a digraph admit a doubly stochastic adjacency matrix?, 2010].\n\nAbout real-world experiments. We have followed the Reviewer\u2019s suggestion and implemented our algorithms over the distributed online regularized linear regression problem with two real datasets selected from the LIBSVM repository ( https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ ). The details of the datasets are summarized as follows:\n----------------------------------------------------------------\nDataset  |    # of features    |    # of instances\n----------------------------------------------------------------\nmg          |             6               |       1385  \n----------------------------------------------------------------\nbodyfat  |            14              |        252  \n----------------------------------------------------------------\n\nWe use the same network as that used in Section 4 of the paper. The plots are provided in the following screenshots (mg dataset with \\rho = 0, please see https://pasteboard.co/IFy9B7U.png ; mg dataset with \\rho = 1, please see https://pasteboard.co/IFyajAf.png ; bodyfat dataset with \\rho = 0, please see, https://pasteboard.co/IFyaIPX.png ; bodyfat dataset with \\rho = 1, please see https://pasteboard.co/IFyb9TY.png ). These numerical experiments on real-world datasets show the convergence of the proposed algorithms and are consistent with the results established in Theorems 1-4 of our paper. \n\nFurthermore, to demonstrate the efficiency of our algorithm, we have compared our algorithm with a standard distributed online optimization algorithm called D-OCG (Distributed Online Conditional Gradient) on these two real datasets. The detailed results are provided in the screenshots (mg dataset with \\rho = 1, please see https://pasteboard.co/IFBMgLM.png ; bodyfat dataset with \\rho = 1, please see https://pasteboard.co/IFBMHDE.png ) . "}, "signatures": ["ICLR.cc/2020/Conference/Paper289/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syee1pVtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper289/Authors|ICLR.cc/2020/Conference/Paper289/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173608, "tmdate": 1576860557523, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment"}}}, {"id": "BkxpNs8MiS", "original": null, "number": 3, "cdate": 1573182260885, "ddate": null, "tcdate": 1573182260885, "tmdate": 1573199228020, "tddate": null, "forum": "Syee1pVtDS", "replyto": "SJxEdyinFr", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment", "content": {"title": "Response to Official Blind Review #2", "comment": "We thank the Reviewer for the positive comments and the suggestions.\n\n1. It is prefer to append some experiments on real-world applications.\n\nWe have followed your suggestion and appended some experiments on real-world datasets, which are selected from the LIBSVM repository ( https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ ). More specifically, we investigated the performance of our algorithm on the mg dataset that has 6 features and 1385 instances, and on the bodyfat dataset that has 14 features and 252 instances. The plots are provided in the following screenshots (mg dataset with \\rho = 0, please see https://pasteboard.co/IFy9B7U.png ; mg dataset with \\rho = 1, please see https://pasteboard.co/IFyajAf.png ; bodyfat dataset with \\rho = 0, please see, https://pasteboard.co/IFyaIPX.png ; bodyfat dataset with \\rho = 1, please see https://pasteboard.co/IFyb9TY.png ). We have used the same network as that used in Section 4 of the paper.\n\nThese numerical experiments on real-world datasets show the convergence of the proposed algorithms and are consistent with the results established in Theorems 2 and 4 of our paper. \n\n2. Although the regret bound of DOCO is better, the projection step is expensive. Can you compare the running time of DOCO with projection-free algorithms?\n\nObserve that the projection step in our algorithms is really inexpensive, as it consists in projecting onto a ball. Specifically, to avoid projections is to allow the algorithm to violate the constraints by projecting onto a simplified set (a ball) which covers the original constraint set. In every round, each node projects its decision onto a Euclidean ball, which can be easily solved analytically, but at the price of constraint violations. \n\nWe thank the Reviewer for pointing out the projection-free algorithms to us, which is indeed quite relevant. In fact, we cited a most related paper and made comparisons with it in the manuscript. We have made some comparisons with the projection-free algorithm (i.e., D-OCG in Wenpeng Zhang, et al., ICML, 2017) using two real-world datasets selected from the LIBSVM repository (https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/ ). The details of the datasets are summarized as follow:\n----------------------------------------------------------------\nDataset  |    # of features    |    # of instances\n----------------------------------------------------------------\nmg          |             6               |       1385  \n----------------------------------------------------------------\nbodyfat  |            14              |        252  \n----------------------------------------------------------------\n\nWe use the same network as that used in Section 4 of the paper. The detailed results are provided in the following screenshots (mg dataset with \\rho = 1, please see https://pasteboard.co/IFBMgLM.png ; bodyfat dataset with \\rho = 1, please see https://pasteboard.co/IFBMHDE.png ). \n\nFrom these plots one can confirm that: (i) Our DOCO algorithm achieves better performance than D-OCG under the same information feedback (of course, D-OCG exhibits no constraint violations); and (ii) For both algorithms, the performance is degraded from full information to bandit feedback."}, "signatures": ["ICLR.cc/2020/Conference/Paper289/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syee1pVtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper289/Authors|ICLR.cc/2020/Conference/Paper289/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173608, "tmdate": 1576860557523, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment"}}}, {"id": "r1g3i58GoH", "original": null, "number": 1, "cdate": 1573182115548, "ddate": null, "tcdate": 1573182115548, "tmdate": 1573198367864, "tddate": null, "forum": "Syee1pVtDS", "replyto": "ByeydF1zqr", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment", "content": {"title": "Response to Official Blind Review #1", "comment": "We thank the Reviewer for these insightful comments. We would like to emphasize that Assumption 4 is quite standard in the literature on distributed online or offline optimization, and easy to achieve in a distributed manner in real-world networks. For example, when bidirectional communication between nodes is allowed, we can enforce symmetry on the node interaction matrix, which immediately makes it doubly stochastic. There are also other methods to construct doubly stochastic matrices for a network, see, e.g., [F. Garin and L. Schenato. A survey on distributed estimation and control applications using linear consensus algorithms, 2011] and [Bahman Gharesifard and Jorge Cortes. When does a digraph admit a doubly stochastic adjacency matrix?, 2010]."}, "signatures": ["ICLR.cc/2020/Conference/Paper289/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syee1pVtDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper289/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper289/Authors|ICLR.cc/2020/Conference/Paper289/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504173608, "tmdate": 1576860557523, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper289/Authors", "ICLR.cc/2020/Conference/Paper289/Reviewers", "ICLR.cc/2020/Conference/Paper289/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Comment"}}}, {"id": "SJxEdyinFr", "original": null, "number": 1, "cdate": 1571757932232, "ddate": null, "tcdate": 1571757932232, "tmdate": 1572972614413, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper considers distributed online convex optimization with long-term constraints, which extends Yuan & Lamperski (2018)\u2019s work to decentralized case with time-varying directed network. The authors propose DOCO frameworks (full-information and one-point bandit feedback) based on augmented Lagrangian functions. They also provide the corresponding regret bounds for both strongly and non-strongly convex cases. The experiments on synthetic data validate the effectiveness of proposed algorithms.\n\nThe problem setting of this paper is interesting and the theoretical contribution is nice, but the empirical studies could be improved:\n\n1. It is prefer to append some experiments on real-world applications.\n\n2. Although the regret bound of DOCO is better, the projection step is expensive. Can you compare the running time of DOCO with projection-free algorithms?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947068939, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper289/Reviewers"], "noninvitees": [], "tcdate": 1570237754294, "tmdate": 1574947068950, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Review"}}}, {"id": "ByeydF1zqr", "original": null, "number": 3, "cdate": 1572104551315, "ddate": null, "tcdate": 1572104551315, "tmdate": 1572972614303, "tddate": null, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "invitation": "ICLR.cc/2020/Conference/Paper289/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: \nThe paper considers a distributed variant of online convex optimization problem over multiple players, where, at each trial t, convex loss_l_t.i is revealed to player i and but evaluated by sum of loss functions sum_i=1^n l_t,i. The players can communicate with their neighborhood and share their decisions. Under the problems setting and some assumption on the neighborhood graph structure, the authors prove regret bounds for convex/strongly-convex losses and full-info/bandit settings. Specifically, the paper allows the algorithm to violate domain constraints but the sum of violation has to be sublinear in the number of trials. They also show the violation bounds simultaneously. \n\n\nComments:\nThe key assumption is Assumption 4, that the players share a doubly-stochastic matrix which is used to mix neighbors\u2019 decisions. This assumption allows to mix all players\u2019 decisions in a long run and the derived regret bounds make sense. The theoretical results are non-trivial. \n\nAs a summary, I feel the results are beyond standard previous work and has certain values. Note that I have not evaluated correctness of the results, but the results are likely under Assumption 4. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper289/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "We consider distributed online convex optimization problems, where the distributed system consists of various computing units connected through a time-varying communication graph. In each time step, each computing unit selects a constrained vector, experiences a loss equal to an arbitrary convex function evaluated at this vector, and may communicate to its neighbors in the graph. The objective is to minimize the system-wide loss accumulated over time. We propose a decentralized algorithm with regret and cumulative constraint violation in ${\\cal O}(T^{\\max\\{c,1-c\\} })$ and ${\\cal O}(T^{1-c/2})$, respectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the loss functions are strongly convex, we establish improved regret and constraint violation upper bounds in ${\\cal O}(\\log(T))$ and ${\\cal O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by state-of-the-art algorithms and fundamental limits in the corresponding centralized online optimization problem (for both convex and strongly convex loss functions).  In the case of bandit feedback, the proposed algorithms achieve a regret and constraint violation in ${\\cal O}(T^{\\max\\{c,1-c/3 \\} })$ and ${\\cal O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically illustrate the performance of our algorithms for the particular case of distributed online regularized linear regression problems.", "title": "Distributed Online Optimization with Long-Term Constraints", "keywords": [], "authors": ["Deming Yuan", "Alexandre Proutiere", "Guodong Shi"], "authorids": ["dmyuan1012@gmail.com", "alepro@kth.se", "guodong.shi@anu.edu.au"], "pdf": "/pdf/f1466ecffdf06f9bea9930a57b0392183d5382ee.pdf", "paperhash": "yuan|distributed_online_optimization_with_longterm_constraints", "original_pdf": "/attachment/a54a40bcf4edb92964b8b57cdbd92763fa55c4ef.pdf", "_bibtex": "@misc{\nyuan2020distributed,\ntitle={Distributed Online Optimization with Long-Term Constraints},\nauthor={Deming Yuan and Alexandre Proutiere and Guodong Shi},\nyear={2020},\nurl={https://openreview.net/forum?id=Syee1pVtDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syee1pVtDS", "replyto": "Syee1pVtDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper289/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947068939, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper289/Reviewers"], "noninvitees": [], "tcdate": 1570237754294, "tmdate": 1574947068950, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper289/-/Official_Review"}}}], "count": 10}