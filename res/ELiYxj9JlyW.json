{"notes": [{"id": "ELiYxj9JlyW", "original": "2vgHP53HaQx", "number": 1208, "cdate": 1601308135396, "ddate": null, "tcdate": 1601308135396, "tmdate": 1614985663914, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "32cGIB247r", "original": null, "number": 1, "cdate": 1610040497418, "ddate": null, "tcdate": 1610040497418, "tmdate": 1610474103857, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The authors propose a process to leverage the memorization effect of deep learning models to filter out examples at the boundary (hard) that the models are confident on, and argue that identifying those hard confident examples help improve the accuracy when learning under noisy data. The process essentially alternates between confident example selection and classifier updating, where the two parts are expected to help each other to form a positive cycle. Experiments demonstrate superior results over other self-purifying approaches.\n\nThe reviewers have a very diverse opinion about the paper. On the positive side, everyone agrees that the superior experimental results to be very impressive. The authors have addressed some concerns well, such as the running time. One reviewer pointed out that the current study has not been combined with semi-supervised learning yet, but during the discussion, most agreed that it is not a crucial negative point of the current paper. On the actual negative points, there are issues that were not cleared even after the rebuttal, such as whether re-initialization in the process helps escape local optimal, and the key difference between the \"small-loss trick\" and \"memory-momentum trick.\" While the authors argued the novelty with respect to SELF, more illustrations and experiments are needed to highlight the novelty aspect.\n\nGiven the diverse opinions, the AC read the paper in detail, and assessed the reviewer's opinions and the authors rebuttal. Overall a serious concern is the leap of faith that the proposed process is indeed (a) \"leveraging the memorization effect\" to (b) \"extract hard confident examples\" to (c) \"improve accuracy in noisy learning\". For (a), it is mentioned that deep learning models \"learns simple patterns on majority of data\" first, where the majority in this work is argued is the clean ones. But there is no validation of this claim in the experiments. For instance, there is no figure/discussion that shows how much \"clean data\" has been correctly captured/memorized by the earlier deep learning models. For (b), the terminology of \"hard but confident\" is ill-defined. If examples being hard means them to be around the boundary, one can argue that they could never be \"confident\" as one measure of the confidence is the margin. The authors may want to mean \"hard but clean\", but then more illustrations are needed to analyze whether the extracted examples are really the clean ones, or if there are noisy ones being \"confident\" from the proposed process as well. For (c), it is then unclear whether the improved performance is caused by noise removal (as the authors hope to argue), or by just zooming in to the boundary (regardless of whether the extracted examples are clean or noisy). The authors are encouraged to not just look at the superior performance on accuracy, but analyze more on what actually happened behind the scenes to understand the proposed process better.\n\nSome more comments from the AC that could help the authors (1) Are the examples kept by the proposed approach similar to the ones kept by SELF? Why or why not? Are there empirical studies on this? (2) For the competitors' approaches, what would their Figure 4 look like? In particular, for approaches that use \"small-loss trick\", what would Figure 4 look like? How would Figure 4 be different for the proposed process (i.e extracting hard \"confident\" examples) and others (like extracting just hard examples without considering confidence, or just confident examples without considering hardness)? (3) Are there studies that deliberately initialize the process with noisy data, to see how sensitive the process is before the \"positive cycle\" begins?\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040497405, "tmdate": 1610474103842, "id": "ICLR.cc/2021/Conference/Paper1208/-/Decision"}}}, {"id": "nFczKfgmm9", "original": null, "number": 3, "cdate": 1603896674729, "ddate": null, "tcdate": 1603896674729, "tmdate": 1606814452653, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review", "content": {"title": "Simple idea, but many questions about novelty, presentation, and methodology", "review": "This paper proposes momentum of memorization as a way to distinguish hard examples needed for efficient learning from noisy examples which decrease classification accuracy. The method finds confident, hard examples and updates them dynamically during model training. This is done by iteratively selecting examples with labels that agree with model predictions and then training on only the confident data. Results show improved accuracy on standard image classification datasets with both synthetic and real world label noise.\n\n\nNovelty\n- In addition to the methods cited in \"Relation to existing work,\" the authors should cite and discuss self-training methods which have become quite popular over the past decade [1]\n- The paper also describes Algorithm 1 as adding an outer loop to the recent SELF algorithm [2], which considerably limits its novelty.\n\nCorrectness/Experiments:\n- Results show consistent improvement over baselines\n- A more thorough evaluation would include ablation on the parameters $N_{outer}$ and $N_{inner}$, as well as the modified early stopping \"trick\"\n- Figure 4 shows qualitative t-SNE visualizations of identified confident examples. qualitatively, these look well separated. However, t-SNE is known to preserve local structure better than global structure, making it a poor way to visualize how close confident examples are to decision boundaries. It's also impossible to tell whether any of the dots (in particular blue and red) are incorrectly labeled wrt ground truth class labels (i.e. \"noisy\" vs \"hard\")\n- Many claims are made without theoretical or empirical justification. For example, showing how training/validation accuracy varied with $N_{outer}$ and $N_{inner}$ would support the claim that Me-Momentum is leveraging the memorization effect.\n\nClarity\n- Example figures and problem formulation are quite nice\n- I believe this naming may cause confusion with the momentum update widely used in optimization. Additionally, I am not sure how this paper fits the notion of momentum more than any number of other training procedures. For example, increasing the learning rate at each epoch would fit the colloquial/physics meaning of \"traveling through hypothesis space\" just as well as this approach which uses repeated fine tuning.\n- Algorithm 1 and Section 2 would benefit from additional notation in addition to the pseudocode and text explanation\n- Unclear what the reader should take away from Figure 4 and 10-13 (see above)\n- typos: \"an surrogate\" should be \"a surrogate\", and \"clothing1M\" should be \"Clothing1M\"\n\nPro\n- Nice illustrations and problem description\n- Results perform well against baselines\n\nCons\n- Limited novelty compared to SELF and self-training methods more generally\n- Concerns about methodology and clarity, especially wrt visualizations\n- Empirical methodology/analysis should be improved\n\nQuestions:\n- How does the running time compare to normal neural network training, and to other baseline methods?\n- Do Tables 1-3 show a similar improvement to Table 4 when switching to clean validation set?\n- How sensitive is Me-Momentum to hyperparameters $N_{outer}$ and $N_{inner}$?\n- Is the recall of confident examples wrt accurately labeled data as high as the precision? Will identifying additional confident samples lead to even higher accuracy?\n\n\n[1] Huang and Harper. Self-Training PCFG Grammars with Latent Annotations\nAcross Languages, EMNLP 2009 https://www.aclweb.org/anthology/D09-1087.pdf\n\n[2] Nguyen et al. SELF: learning to filter noisy labels with self-ensembling, ICLR 2020. https://arxiv.org/abs/1910.01842\n\nEDIT: The author response addressed some of my concerns. In particular, it confirms that the experimental results are impressive compared to many baselines. However, I would appreciate the distinction between easy and hard confident examples much more if the authors went beyond illustrative figures and defined this concept more precisely. Without a precise definition, it's difficult to verify the paper's claims about why the method performs well. Based on t-SNE visualizations, the author response offers an alternate definition of \"far away from the cluster centroids.\" The submission would be much stronger if it developed this idea further and analyzed it quantitatively.\n\nNext, the authors suggest that methods cannot distinguish hard confident examples from mislabeled examples using the \"small loss trick\" alone, and that their \"momentum trick\" is necessary. However, they do not present a principled argument or strong evidence to support the claim. In fact, some recent methods do show a separation between these types of training data using measurable quantities, see Figure 1 of [3] and Figures 1-2 of [4].\n\nFinally, the authors claim that reinitialization helps escape bad local optima. However, I do not see how low standard deviation supports this claim.\n\n[3] Pleiss et al. Identifying Mislabeled Data using the Area Under the Margin Ranking, Neurips 2020. https://arxiv.org/abs/2001.10528\n\n[4] Swayamdipta et al. Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics, EMNLP 2020. https://arxiv.org/abs/2009.10795]", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124092, "tmdate": 1606915799436, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1208/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review"}}}, {"id": "3IZOw9sGzRv", "original": null, "number": 3, "cdate": 1605587340849, "ddate": null, "tcdate": 1605587340849, "tmdate": 1605590763116, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "svTd45rxxj1", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment", "content": {"title": "To AnonReviewer1", "comment": "Q1: About the noisy validation set.  \nA1: Our work follows the widely used practice in the literature of learning from noisy labels, i.e., using a noisy validation set for early stopping [r2][r3][r4][r5]. It is empirically reported to work well. Note that the correct labels are dominating in each noisy class and that label noise is random, the accuracy on the noisy validation set, and the accuracy on the clean test data set are positively correlated. The noisy validation set therefore can be employed. We agree with the reviewer that a more in-depth theoretical analysis of this aspect is worth further learning. However, we respectively cannot agree with the reviewer that using a noisy validation set is not acceptable.\n\n[r2] Zhilu Zhang and Mert Sabuncu. Generalized cross-entropy loss for training deep neural networks with noisy labels. NeurIPS, 2018.  \n[r3] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. CVPR, 2017.  \n[r4] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama. Are anchor points really indispensable in label-noise learning? NeurIPS, 2019.  \n[r5] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. NeurIPS 2020.  \n\nQ2: Why hard confident example can be extracted.  \nA2: Note that hard confident examples are entangled with incorrectly labeled data. If we just use the traditional memorization-based trick, e.g., the small-loss trick, we cannot distinguish the hard confident examples and the incorrectly labeled data. However, with the \u201cMomentum of memorization\u201d, we can do so. Specifically, by using the traditional memorization-based trick, we could extract easy confident examples and learn classifiers based on them. The hard confident examples is more connected to the easy confident examples than the incorrectly labeled examples because the former two share some common features. By using the classifiers learned by easy confident examples, we can distinguish the hard confident examples from the incorrectly labeled data and thus extract hard confident examples. This philosophy is called the memorization of the momentum. We will make this clear in the paper.\n\nQ3:  Stuck in the local optimum  \nA3: Thanks for the nice concern. By simply implementing the intuition, it is likely that we will stick in the bad local optimum because we have the memorization of noisy labels and the inferiority of sample-selection bias. However, this could be effectively addressed by reinitializing the classifier at the beginning of each outer loop. Specifically, with the noisy dataset, especially without a clean validation set, the classifier may be affected by label noise and sticks into a bad local optimum due to the memorization of neural networks. Reinitializing neural networks provide an opportunity to relearn the knowledge in a lower noisy dataset compared with the last outer loop. This helps the classifier escape the bad local optimum. Evidence is that the standard deviations of classification accuracy in three artificial datasets are relatively low compared with other baselines.\n\nQ4: Higher noise rate  \nA4: Note that we only make use of confident examples and discard the non-confident examples. If the noise rate is too high, e.g., noise rate 80%, the number of extracted examples may become too small, which means there are not enough examples for good training. This could be addressed by making use of the non-confident examples by using the semi-supervised learning method, e.g., DivideMix [r1]. However, our aim is to verify the effectiveness of the method to extract high-quality confident examples, not to boost the classification performance. \n\nWe think even with the currently used noise rates, the empirical results of the proposed method are convincing, showing that we indeed extracted high-quality (and hard) confident examples. Here are results that comparing with baselines on Symmetric 50%\n\nDataset\u2003\u2003\u2003\u2003\u2003\u2003\u2003JointOptim \u2003\u2003DMI\u2003\u2003 \u2003 \u2003T-revision\u2003\u2003Me-Momentum  \nCIFAR10 Sym-50\u2003\u2003\u200385.00\u00b10.17  \u2003\u200378.28\u00b10.48 \u2003  83.49\u00b10.42\u2003\u200386.40\u00b10.34   \nCIFAR100 Sym-50 \u2003\u2003 50.22\u00b10.41  \u2003\u200344.25\u00b11.14 \u2003  49.28\u00b10.43\u2003\u200358.06\u00b10.59  \n\nNote that we compared the proposed method with SELF on Symmetric 60% in appendix C (backbone consistently with SELF). Specifically,\n\nDataset\u2003\u2003\u2003\u2003\u2003\u2003\u2003SELF\u2003\u2003\u2003\u2003\u2003Me-Momentum  \nCIFAR10 Sym-60\u2003\u2003\u200375.47%\u2003\u2003\u2003\u200387.88%  \nCIFAR100 Sym-60 \u2003\u2003 50.60%\u2003\u2003\u2003\u200359.51%  \n \nThe results show that Me-Momentum largely outperforms SELF. Note that the backbone and loss function (cross-entropy loss function) are the same. The outperformance clearly shows that Me-Momentum can better extract high-quality confident examples significantly.\n\n[r1] Li, Junnan, Richard Socher, and Steven CH Hoi. \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning.\" In ICLR. 2019."}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ELiYxj9JlyW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1208/Authors|ICLR.cc/2021/Conference/Paper1208/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862383, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment"}}}, {"id": "f9Jc8LK8Ba", "original": null, "number": 4, "cdate": 1605588187303, "ddate": null, "tcdate": 1605588187303, "tmdate": 1605590748277, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "PGZl9qGdqhH", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment", "content": {"title": "To  AnonReviewer2", "comment": "Thanks for the positive support!\n\nQ1: Visualization analyses and hyperparameter sensitivity  \nA1: As pointed out by reviewer 3 that t-SNE is known to preserve local structure better than global structure, making it a poor way to visualize how close confident examples are to decision boundaries. However, the visualization at least shows that we could extract confident examples that are far away from the cluster centroids. Those could be interpreted as hard confident examples as well. The current figures clearly show that we gradually extract confident examples on the boundaries of the clusters. The label precision in Figure 3 shows that the vast majority of the extracted confident examples are of correct labels. The high classification accuracy also verifies that the extracted confident examples are of high quality.\n\nFigure 6 shows that the proposed method is not sensitive to the hyperparameter tao, which is proposed for robust early stopping. We may not need to set specific values for N_outer and N_inner as we can stop the algorithm when there no improvement in the next inner or outer loop by looking at the validation set. However, this may be time-consuming. We set N_outer and N_inner to be specific values to save time.\n\nFrom Figure 3, we can see how the number of confident examples, confident label precision, and the test accuracy varies by increasing the number of the round of inner and outer loops in a limited range. We can see that the curves are quite smooth, which shows that the proposed method is not very sensitive to the hyperparameters.\n\n\nQ2: Adding more baselines  \nA2: Our aim is to verify the effectiveness of the method to extract high-quality confident examples, not to boost the classification performance. The not-so-confident examples could be exploited, e.g., by the semi-supervised learning methods, to further improve the performance as did in DivideMix [r1].\n\n[r1] Li, Junnan, Richard Socher, and Steven CH Hoi. \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning.\" In ICLR. 2019.\n\n\nQ3: Why noisy validation set  \nQ3: Our work follows the widely used practice in the literature of learning from noisy labels, i.e., using a noisy validation set for early stopping [r2][r3][r4][r5]. It is empirically reported to work well. Note that the correct labels are dominating in each noisy class and that label noise is random, the accuracy on the noisy validation set, and the accuracy on the clean test data set are positively correlated. The noisy validation set therefore can be employed. A more in-depth theoretical analysis of this aspect is worth further learning. \n\n[r2] Zhilu Zhang and Mert Sabuncu. Generalized cross-entropy loss for training deep neural networks with noisy labels. NeurIPS, 2018.  \n[r3] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. CVPR, 2017.  \n[r4] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama. Are anchor points really indispensable in label-noise learning? NeurIPS, 2019.  \n[r5] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. NeurIPS 2020.  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ELiYxj9JlyW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1208/Authors|ICLR.cc/2021/Conference/Paper1208/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862383, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment"}}}, {"id": "k-t-BwRNrcW", "original": null, "number": 5, "cdate": 1605588996263, "ddate": null, "tcdate": 1605588996263, "tmdate": 1605590700442, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "nFczKfgmm9", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment", "content": {"title": "To AnonReviewer3 (2)", "comment": "Regarding the clarity.  \nQ5: Regarding the term \u201cMomentum\u201d  \nA5: We agree with the reviewer that the term \u201cMomentum\u201d may cause confusion for readers. The examples raised by the reviewer about \u201cMomentum\u201d are also more from the optimization perspective. We will make it clear that the \u201cMomentum\u201d in this paper refers to the \u201cMomentum of memorization\u201d.  Note that the hard confident examples are entangled with incorrectly labeled data. If we just use the traditional memorization-based trick, e.g., the small-loss trick, we cannot distinguish the hard confident examples and the incorrectly labeled data. However, with the \u201cMomentum of memorization\u201d, we can do so. Specifically, by using the traditional memorization-based trick, we could extract easy confident examples and learn classifiers based on them. The hard confident examples are more connected to the easy confident examples compared with the incorrectly labeled examples. By using the classifiers learned by easy confident examples, we can distinguish the hard confident examples from the incorrectly labeled data and thus extract hard confident examples. This philosophy is called the memorization of the momentum. We will make this clear in the paper.\n\n\nQ6: Regarding t-SNE  \nA6: We agree with the reviewer that t-SNE is known to preserve local structure better than global structure, making it a poor way to visualize how close confident examples are to decision boundaries. However, the visualization at least shows that we could extract confident examples that are far away from the cluster centroids. Those could be interpreted as hard confident examples as well.\n\nIf we further divide the confident examples with correct and correct labels. The figures may look very complicated. The current figures clearly show that we gradually extract confident examples on the boundaries of the clusters. The label precision in Figure 3 shows that the vast majority of the extracted confident examples are of correct labels. The high classification accuracy also verifies that the extracted confident examples are of high quality.\n\nRegarding the novelty.  \nQ7: the self-training method.  \nA7: Thanks for pointing out the related work. Note that the baselines we compared do not include the state-of-the-art methods which make use of the non-confident examples by using a semi-supervised learning method, e.g., DivideMix [r1]. Our aim is to verify the effectiveness of the method to extract high-quality confident examples, not to boost the classification performance. The self-training method is a powerful semi-supervised learning method. We will discuss it in the related work but will not include it as a baseline. We note that combining the proposed method with self-training is an interesting future work.\n\n[r1] Li, Junnan, Richard Socher, and Steven CH Hoi. \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning.\" In ICLR. 2019.\n\nQ8: Similarity to SELF.  \nA8: The two methods are quite different because (1) we have different aims and (2) the methodologies are different. \n\nEspecially, SELF is focusing on removing non-confident labels while we are focusing on how to extract high-quality confident examples. As SELF will make use of non-confident examples by using semi-supervised methods, they do not care very much about the hard confident examples. However, identifying the hard confident examples is the bottleneck for our proposed method as we only make use of the confident examples. \n\nBecause of the different aims, the methods designed are quite different. Although we use a similar method to identify confident examples, Me-momentum is specifically designed for extracting hard confident examples. A specific early stopping method and re-initialization have been designed for the outer loop to avoid the memorization of noisy labels and the inferiority of sample-selection bias, which is very essential for extracting hard confident examples. (Hard confident examples are usually entangled with incorrectly labeled examples and could be extracted only when the memorization of noisy labels and the inferiority of sample-selection bias have been addressed well.) \n\nTo further show the difference, we empirically compare Me-Momentum with SELF under the same setting. More details can be found in Appendix C.\n\nDataset\u2003\u2003\u2003\u2003\u2003\u2003\u2003SELF\u2003\u2003\u2003\u2003\u2003Me-Momentum  \nCIFAR10 Sym-40\u2003\u2003\u200387.35%\u2003\u2003\u2003\u200392.31%  \nCIFAR10 Sym-60\u2003\u2003\u200375.47%\u2003\u2003\u2003\u200387.88%  \nCIFAR100 Sym-40 \u2003\u2003 61.40%\u2003\u2003\u2003\u200368.25%  \nCIFAR100 Sym-60 \u2003\u2003 50.60%\u2003\u2003\u2003\u200359.51%  \n\nThe results show that Me-Momentum largely outperforms SELF. Note that the backbone and loss function (cross-entropy loss function) are the same. The outperformance clearly shows that Me-Momentum can better extract high-quality confident examples significantly.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ELiYxj9JlyW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1208/Authors|ICLR.cc/2021/Conference/Paper1208/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862383, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment"}}}, {"id": "BYOmUQYBu7M", "original": null, "number": 6, "cdate": 1605589709493, "ddate": null, "tcdate": 1605589709493, "tmdate": 1605590681540, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "nFczKfgmm9", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment", "content": {"title": "To AnonReviewer3 (1)", "comment": "Thanks for the careful reading and nice comments!\n\nQ1: Running time comparison.  \nA1: The number of the inner loop varies because the inner loop stops by exploiting a noisy validation set.\nNote that we discard non-confident examples and only use confident examples to train the model. The training time in each round would be much less than the normal training. We compare the training time with representative baselines on CIFAR10 with ResNet18 as follows:\n\nMethods\u2003\u2003\u2003\u2003\u2003\u2003 \u2003Training time  \nCE \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u200368 mins  \nJointOptim \u2003\u2003\u2003\u2003\u2003\u2003 88 mins  \nCo-teaching\u2003\u2003\u2003\u2003\u2003\u200391 mins  \nT-revision\u2003\u2003\u2003\u2003\u2003\u2003\u2003232 mins  \nMe-Momentum\u2003\u2003\u2003\u2003 169.40\u00b118.80 mins (symmetric 50%)  \n\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 \u2003\u2003  160.0\u00b121.01 mins (instance 40%)\n\nNote that CE stands for the normal neural network training by employing the cross-entropy loss function. The total number of epochs for CE is set to 200. Since the number of the inner loop varies in the proposed method, we have reported the average training time of five runs and the standard deviation. Note that Me-momentum has a smaller training time on the instance-40% noise than that on the symmetric-50% noise. This may be caused by that the former setting is more difficult than the latter one and less confident examples are extracted.\n\nThe conclusion is that the training time of the proposed method is shorter than T-revision but longer than Co-teaching, JointOptim, and CE.\n\n\nQ2: Do Tables 1-3 show a similar improvement to Table 4 when switching to clean validation set?\nQ2: Yes, they are. A clean validation set will help to select a better\u00ac model compared with the noisy validation set. The final performance will become better. The details are as follows (Each trial is repeated five times):\n\nDataset\u2003\u2003\u2003\u2003 \u2003\u2003with noisy validation set\u2003\u2003\u2003with clean validation set  \nCIFAR10 Sym-20\t\u2003\u200391.44\u00b10.33\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 91.60\u00b10.31  \nCIFAR10 Sym-40\t\u2003\u200388.39\u00b10.34\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 89.14\u00b10.51  \t\t\t\nCIFAR10 Sym-50\t\u2003\u200386.40\u00b10.34\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 86.88\u00b10.70  \nCIFAR10 Inst-20 \t\u2003\u2003 90.86\u00b10.21\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 91.34\u00b10.24  \nCIFAR10 Inst-40 \u2003 \u200386.66\u00b10.91\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 87.80\u00b10.84  \n\nQ3: How sensitive is Me-Momentum to hyperparameters N_outer and N_inner?  \nA3: Thanks for the nice concern. We may not need to set specific values for N_outer and N_inner as we can stop the algorithm when there no improvement in the next inner or outer loop by looking at the validation set. However, this may be time-consuming. We set N_outer and N_inner to be specific values to save time.\n\nFrom Figure 3, we can see how the number of confident examples, confident label precision, and the test accuracy varies by increasing the number of the round of inner and outer loops in a limited range. We can see that the curves are quite smooth, which shows that the proposed method is not very sensitive to the hyperparameters.\n\nQ4: Is the recall of confident examples wrt accurately labeled data as high as the precision? Will identifying additional confident samples lead to even higher accuracy?  \nA4: Thanks for the nice comment. We have listed the label precision and recall for the accurately labeled as follows:\n\nDataset\u2003\u2003\u2003\u2003 \u2003\u2003 Label precision\u2003\u2003Recall  \nCIFAR10 Sym-40 \u2003\u2003 96.43\u00b10.48\u2003\u2003\u2003\u2003 95.76\u00b10.24  \nCIFAR10 Inst-40 \u2003 \u2003 94.48\u00b11.84\u2003\u2003\u2003\u2003 94.22\u00b10.46  \nCIFAR100 Sym-40\u2003\u200398.09\u00b10.10\u2003\u2003\u2003\u2003 82.15\u00b10.68  \nCIFAR100 Inst-40 \u2003\u200391.01\u00b14.06\u2003\u2003\u2003 \u200378.24\u00b13.56  \n\nWe can see that for the dataset CIFAR10, the recall is as high as the precision, which justifies that we have extracted high-quality confident examples and why we have a good classification performance. However, the recall is relatively low compared with the precision on CIFAR100 where each class has a relatively small number, making it difficult to learn.\n\nIntuitively, with additional high-quality confident examples, the classification accuracy could be further improved. The proposed method aims to extract high-quality confident examples by justifying the proposed idea, i.e., momentum of memorization, without making use of the non-confident examples or a clean validation set. The accuracy could be improved by making use of the non-confident examples or a clean validation set, which will be studied in the future. Note that we will explain why we use the term \u201cMomentum\u201d later, which will provide the intuition why hard confident examples will be extracted and justify the novelty of the proposed method.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ELiYxj9JlyW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1208/Authors|ICLR.cc/2021/Conference/Paper1208/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862383, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment"}}}, {"id": "D6L3EuwJGBU", "original": null, "number": 2, "cdate": 1605581809662, "ddate": null, "tcdate": 1605581809662, "tmdate": 1605590638816, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "XLb9bkVW5V0", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment", "content": {"title": "To AnonReviewer4", "comment": "Thanks very much for the positive support! \n\nWe address the concerns in cons one by one in the following.\n\nQ1: Running time comparison.  \nA1: The number of the inner loop varies because the inner loop stops by exploiting a noisy validation set.\nNote that we discard non-confident examples and only use confident examples to train the model. The training time in each round would be much less than the normal training. We compare the training time with representative baselines on CIFAR10 with ResNet18 as follows:\n\nMethods \u2003\u2003\u2003\u2003Training time  \nCE\u2003\u2003\u2003\u2003\u2003\u2003\u2003 68 mins  \nJointOptim \u2003\u2003\u2003 88 mins  \nCo-teaching\u2003\u2003\u200391 mins  \nT-revision\u2003\u2003\u2003\u2003232 mins  \nMe-Momentum \u2003169.40 $\\pm 18.80$ mins (symmetric 50%)  \n \u2003\u2003\u2003\u2003 \u2003\u2003\u2003\u2003 160.0 $\\pm 21.01$ mins (instance 40%)  \n\n\n\nNote that CE stands for the normal neural network training by employing the cross-entropy loss function. The total number of epochs for CE is set to 200. Since the number of the inner loop varies in the proposed method, we have reported the average training time of five runs and the standard deviation. Note that Me-momentum has a smaller training time on the instance-40% noise than that on the symmetric-50% noise. This may be caused by that the former setting is more difficult than the latter one and less confident examples are extracted.\n\nThe conclusion is that the training time of the proposed method is shorter than T-revision but longer than Co-teaching, JointOptim, and CE.\n\nQ2: Regarding the not-so-confident examples.  \nA2: Note that we have discarded the not-so-confident examples in each round. Our aim is to verify the effectiveness of the method to extract high-quality confident examples, not to boost the classification performance. The not-so-confident examples could be exploited, e.g., by the semi-supervised learning methods, to further improve the performance as did in DivideMix [r1].\n\n[r1] Li, Junnan, Richard Socher, and Steven CH Hoi. \"DivideMix: Learning with Noisy Labels as Semi-supervised Learning.\" In ICLR. 2019.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ELiYxj9JlyW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1208/Authors|ICLR.cc/2021/Conference/Paper1208/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862383, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Comment"}}}, {"id": "svTd45rxxj1", "original": null, "number": 1, "cdate": 1603466262988, "ddate": null, "tcdate": 1603466262988, "tmdate": 1605024502462, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review", "content": {"title": "Potentially interesting work, but technical contribution is limited, and the method is not theoretically solid.", "review": "*quality*\nThe organization of this paper is barely satisfactory. The technique proposed to extract hard confident examples in this paper is not convincing, even though the experimental results seem promising.\n\n*clarity*\nIt is not difficult to understand the proposed method, however, the Figures in this paper are somewhat confusing to readers.\n\n*originality*\nIn this paper, the authors focus on extracting hard confident examples from the noisy training data for learning with noisy labels. There is no method to extract hard confident examples before, the idea is novel. However, the technical contribution is limited.\n\n*significance*\nThe idea of extracting hard confident examples is good, however, I do not think this paper solves this issue properly. How to extract hard confident examples correctly still remains a challenging problem.\n\n*pros and cons*\nPros:\n(1). Authors provide sufficient experiments which evaluate the methods on multiple datasets.\n(2). The proposed method achieves better performance than state-of-the-art methods. \n\nCons:\n(1). As for the question \u201cHow to validate the learned classifiers in Steps 3 and 5 without a clean validation set?\u201d, the authors claim that the noisy validation set could be used as a surrogate to validate the classifiers if no clean validation set is available. I do not think it is reasonable here.\n(2). The confident examples can be extracted based on the memorization effect, it seems reasonable. But why hard confident examples can be extracted? The authors explained as previously extracted confident examples will help identify hard confident examples, it is so empirical and maybe another explanation is needed here. Moreover, in the corresponding paragraph, there might be some error with \u201cFigure 6\u201d (should be \u201cFigure 2\u201d?).\n(3). The intuition \u201cbetter confident examples will result in a better classifier and a better classifier will identify better confident examples\u201d have been mentioned many times, I wonder will the method proposed in this paper stuck in the local optimum when the two loops in Algorithm 1 execute.\n(4). The proposed method performs better than the state-of-the-art with 20% and 40% noisy labels. It would be better if the experiments with lager noise rate (e.g., >=50%) are also conducted.\n(5). Some minor issues, for example, \u201cextract\u201d should be \u201cextracted\u201d in the step 2 of Algorithm 1; \u201c$\\times$\u201d and \u201c*\u201d are abused in Section 3; and the resolution of some Figures in this paper is not satisfactory.\n\nGenerally, I feel that the method proposed in this paper is somehow too empirical, and more theoretical study is needed.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124092, "tmdate": 1606915799436, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1208/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review"}}}, {"id": "PGZl9qGdqhH", "original": null, "number": 2, "cdate": 1603720874419, "ddate": null, "tcdate": 1603720874419, "tmdate": 1605024502397, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review", "content": {"title": "Review 2 for \"ME-MOMENTUM: EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA\"", "review": "This paper propose a novel and effective method called Me-Momentum to cope with noisy labels. The algorithm borrows the idea of momentum from physics and tries to identify hard examples. The authors alternately update the hard examples and improve the classifier to achieve the robustness to noisy labels. Experiments and comparisons with recent state-of-art methods are provided to verify the effectiveness of Me-Momentum. \n\nPros:\n\n1. Different from the existing methods, which aim to identify simple clean examples, this paper analyzes the importance of hard examples and provide a way to identify them. The method is interesting and effective. It gives a new perspective and makes clear contributions for learning with noisy labels. \n\n2. The design of inner loop and outer loop is interesting and insightful, and is proved to be very effective. \n\n3. The experimental results are promising. The proposed method achieves great performance (75.18%) on Clothing1M. In addition, compared with SOTA SELF,  Me-Momentum outperforms it by a large margin. The authors also provide an ablation study to analyze the sensitivity of the hyperparameter $tau$. Thus, the significance of the proposed method with respect to experimental results may be high in the community. \n\n4. The paper is well written. The description of the technical details is very clear. It is easy to reproduce this method.\n\nSpecific comments and questions:\n\n1. Insufficient analysis of visualization results and analysis of hyperparameter sensitivity. The authors should add them to improve this paper. In addition, the baselines are reimplemented with default parameters? I hope the author can emphasize or add some descriptions of the implementation details of the comparison methods. \n\n2. Adding more baselines will be better. Some recent methods achieve great classification performance for learning with noisy labels, such as [1]. The authors can compare the proposed method with them to make the results more convincing. \n\n3. The proposed method uses a noisy validation set to choose classifiers, and then identify confident examples with robust classifier. The authors should explain why a noisy validation dataset can be used to choose classifiers which perform well on clean datasets. This choice may not be accurate?\n\n4. There are some grammatical errors and typos. The author should proofread this paper. For example, \u201cThe results are presented in Figure XX\u201d, the authors miss the figure number. Please check it carefully. \n\n[1] NLNL: Negative Learning for Noisy Labels, Youngdong Kim et al, ICCV2019. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124092, "tmdate": 1606915799436, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1208/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review"}}}, {"id": "XLb9bkVW5V0", "original": null, "number": 4, "cdate": 1603947936155, "ddate": null, "tcdate": 1603947936155, "tmdate": 1605024502268, "tddate": null, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "invitation": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review", "content": {"title": "Interesting Work", "review": "The authors introduce an interesting approach to handling hard \"confident\" samples in learning with label noises. At the heart of the proposed approach is an interactive method that jointly refines the classifier and the samples. The confident samples are initialized by utilizing the memorization effect of deep networks. Then, a classifier is learned from such samples. \n\nDuring the learning process, hard confident data are selected progressively by looking at the classification results, which further better select confident samples. \n\nExperimental results show that the proposed method achieves state of the art.\n\nPros:\n1. The task studied here could be of interest to a large number of readers in the community.\n2. The overall idea is quite interesting and intuitively makes sense. I like the fact that the core idea of the proposed approach finds its root in physics. \n3. The results are very promising, in spite of the simple nature.\n4. The manuscript is overall well-written and easy to follow. \n\nCons:\n1. The iterative nature is good and bad. It seems to me that sometimes it requires many rounds in the inner loop, as shown in Fig. 3, for example, the number is up to 20 to 30. Please show some numbers in terms of running time and compare them with the baselines. \n2. I might be missing something here but, what about the not-so-confident samples? Any scheme to take care of them?\n\nMinor issues\n1. The fonts in Fig. 3 should be enlarged.\n2. It would be better if the author could elaborate more on its connection with the momentum in physics.\n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1208/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1208/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ME-MOMENTUM:  EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA", "authorids": ["~Yingbin_Bai1", "~Tongliang_Liu1"], "authors": ["Yingbin Bai", "Tongliang Liu"], "keywords": ["label noise", "hard confident examples"], "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shaping accurate classifiers.   Extracting confident examples has been widely studied in the community of learning with noisy labels.  However, it remains elusive how to extract hard confident examples from the noisy training data.  In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns,  i.e.,  which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier.  Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples.  We call the approach the \u201cMomentum of Memorization\u201d (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "one-sentence_summary": "In this work, we try to address the label noise problem by extracting hard confident examples.", "pdf": "/pdf/4f93e2f30d8a0027c7bc4d4b456838e4e9c3c6fa.pdf", "supplementary_material": "/attachment/6040a1439db683bdb7c84d38337c5f77ce9fc3ee.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bai|memomentum_extracting_hard_confident_examples_from_noisily_labeled_data", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=aaCAAZ5PsI", "_bibtex": "@misc{\nbai2021memomentum,\ntitle={{\\{}ME{\\}}-{\\{}MOMENTUM{\\}}:  {\\{}EXTRACTING{\\}} {\\{}HARD{\\}} {\\{}CONFIDENT{\\}} {\\{}EXAMPLES{\\}} {\\{}FROM{\\}} {\\{}NOISILY{\\}} {\\{}LABELED{\\}} {\\{}DATA{\\}}},\nauthor={Yingbin Bai and Tongliang Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=ELiYxj9JlyW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ELiYxj9JlyW", "replyto": "ELiYxj9JlyW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1208/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538124092, "tmdate": 1606915799436, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1208/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1208/-/Official_Review"}}}], "count": 11}