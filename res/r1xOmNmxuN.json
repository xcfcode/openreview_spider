{"notes": [{"id": "r1xOmNmxuN", "original": "ByxxpKBKP4", "number": 24, "cdate": 1553114143902, "ddate": null, "tcdate": 1553114143902, "tmdate": 1562082104999, "tddate": null, "forum": "r1xOmNmxuN", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Learning Graph Neural Networks with Noisy Labels", "authors": ["Hoang NT", "Jun Jin Choong", "Tsuyoshi Murata"], "authorids": ["hoangnt@net.c.titech.ac.jp", "junjin.choong@net.c.titech.ac.jp", "murata@c.titech.ac.jp"], "keywords": ["weakly supervised learning", "noisy label data", "graph neural network", "loss correction"], "TL;DR": "We apply loss correction to graph neural networks to train a more robust to noise model.", "abstract": "We study the robustness to symmetric label noise of GNNs training procedures. By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task. Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting. ", "pdf": "/pdf/a061049461e56b8d0df63a8b17264ca6d81be0a6.pdf", "paperhash": "nt|learning_graph_neural_networks_with_noisy_labels"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "SJgt2CGwYV", "original": null, "number": 1, "cdate": 1554620081080, "ddate": null, "tcdate": 1554620081080, "tmdate": 1555512017993, "tddate": null, "forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Official_Review", "content": {"title": "Interesting work but need clear writing", "review": "Summary: This paper introduces the loss correction for Graph Neural Networks (GNN) to deal with symmetric graph label noise. The paper shows interesting works on GNN, but the writing could be clearer to deliver the proposed idea.\n\nNotes:\n- The paper shows an interesting work on graph datasets. It has the potential for diverse graph-related tasks.\n- The paper focuses on a graph classification task. It would be better to show performances on a node classification task.\n- One area which is not clear is the justification of the worst performance of the conservative estimation model. What about the original models? GIN and GraphSAGE also use cross-entropy loss, but they show much better performances than D-CNN-C, A, and E in some datasets. (What is the 'original model'? GIN?)\n- The writing could be clearer to deliver the proposed idea. Explanations for notations are missing in some parts. Also, the paper needs clearer definitions of each model.\n\nThe paper introduces an interesting denoising approach on GNN, and the proposed model shows good performances on datasets. There are some unclear areas in the paper, which should be addressed before final submission.", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Graph Neural Networks with Noisy Labels", "authors": ["Hoang NT", "Jun Jin Choong", "Tsuyoshi Murata"], "authorids": ["hoangnt@net.c.titech.ac.jp", "junjin.choong@net.c.titech.ac.jp", "murata@c.titech.ac.jp"], "keywords": ["weakly supervised learning", "noisy label data", "graph neural network", "loss correction"], "TL;DR": "We apply loss correction to graph neural networks to train a more robust to noise model.", "abstract": "We study the robustness to symmetric label noise of GNNs training procedures. By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task. Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting. ", "pdf": "/pdf/a061049461e56b8d0df63a8b17264ca6d81be0a6.pdf", "paperhash": "nt|learning_graph_neural_networks_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Official_Review", "cdate": 1553713418246, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418246, "tmdate": 1555511815996, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper24/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BygKOjQKYE", "original": null, "number": 2, "cdate": 1554754417140, "ddate": null, "tcdate": 1554754417140, "tmdate": 1555511881868, "tddate": null, "forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Official_Review", "content": {"title": "Paper which tackles an interesting problem, but still needs to be improved.", "review": "This work proposes the use of a noise correction loss in the context of graph neural networks to deal with noisy labels. The GNN is implemented following the message passing approach proposed by Xu (2019). The authors compare 3 different noise estimators (namely the conservative, anchors and exact approaches) in the task of graph classification using 9 datasets.\n\nThe paper tackles an interesting and relevant problem to the community. The contribution of the proposed loss in real settings is not clear since only experiments with synthetic noise were performed. More importantly, in its current form the paper is not easy to follow and there are missing details and omissions that should be corrected:\n\n- Until we read the \u201cEmpirical results\u201d section, it is not clear what are the differences between the conservative, anchor and exact methods. The description given in the \u201cEmpirical results\u201d section should be part of the \u201cMethod\u201d section.\n\n- For the conservative approach, it is not clear what is the loss function used to train the first model which estimates C.\n\n- In Sec 2.1, what is \"m\" in 2^m ? Is this the number of possible labels?\n\n- What is C^a in Table 2?\n\n- Table 3 indicates \u201cWe calculate the mean and std of accuracy score on test data for 10 runs each configuration\u201d. However, there is only one value reported in the table which I assume corresponds to the mean value.\n\n- Figure 2 indicates \u201cX-axis presents the test accuracies\u201d. As far as I understand, test accuracies are indicated in the Y-axis.\n", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Graph Neural Networks with Noisy Labels", "authors": ["Hoang NT", "Jun Jin Choong", "Tsuyoshi Murata"], "authorids": ["hoangnt@net.c.titech.ac.jp", "junjin.choong@net.c.titech.ac.jp", "murata@c.titech.ac.jp"], "keywords": ["weakly supervised learning", "noisy label data", "graph neural network", "loss correction"], "TL;DR": "We apply loss correction to graph neural networks to train a more robust to noise model.", "abstract": "We study the robustness to symmetric label noise of GNNs training procedures. By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task. Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting. ", "pdf": "/pdf/a061049461e56b8d0df63a8b17264ca6d81be0a6.pdf", "paperhash": "nt|learning_graph_neural_networks_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Official_Review", "cdate": 1553713418246, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper24/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418246, "tmdate": 1555511815996, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper24/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "ByxERKnMcV", "original": null, "number": 1, "cdate": 1555380683763, "ddate": null, "tcdate": 1555380683763, "tmdate": 1555510980245, "tddate": null, "forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Graph Neural Networks with Noisy Labels", "authors": ["Hoang NT", "Jun Jin Choong", "Tsuyoshi Murata"], "authorids": ["hoangnt@net.c.titech.ac.jp", "junjin.choong@net.c.titech.ac.jp", "murata@c.titech.ac.jp"], "keywords": ["weakly supervised learning", "noisy label data", "graph neural network", "loss correction"], "TL;DR": "We apply loss correction to graph neural networks to train a more robust to noise model.", "abstract": "We study the robustness to symmetric label noise of GNNs training procedures. By combining the nonlinear neural message-passing models (e.g. Graph Isomorphism Networks, GraphSAGE, etc.) with loss correction methods, we present a noise-tolerant approach for the graph classification task. Our experiments show that test accuracy can be improved under the artificial symmetric noisy setting. ", "pdf": "/pdf/a061049461e56b8d0df63a8b17264ca6d81be0a6.pdf", "paperhash": "nt|learning_graph_neural_networks_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper24/Decision", "cdate": 1554736067196, "reply": {"forum": "r1xOmNmxuN", "replyto": "r1xOmNmxuN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736067196, "tmdate": 1555510971481, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}