{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396493747, "tcdate": 1486396493747, "number": 1, "id": "HyUL3fI_e", "invitation": "ICLR.cc/2017/conference/-/paper304/acceptance", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "All three reviewers point to significant deficiencies. No response or engagement from the authors (for the reviews). I see no basis for supporting this paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396494218, "id": "ICLR.cc/2017/conference/-/paper304/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396494218}}}, {"tddate": null, "tmdate": 1485195482722, "tcdate": 1481948531056, "number": 2, "id": "HJjO64fEe", "invitation": "ICLR.cc/2017/conference/-/paper304/official/review", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/conference/paper304/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper304/AnonReviewer2"], "content": {"title": "Final review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a regularization technique for k-shot learning based on orthogonal grouping of units in a neural network. The units within a group are forced to be maximally similar, at the same time the units from different groups are encouraged to be orthogonal. While I like the motivation of the approach, the empirical analysis provided in the paper doesn\u2019t look particularly convincing.\n\nMy main concerns are the following:\n\n1. The method is sensitive to the values of alpha and beta and a poor choice of those hyperparameters can lead to a quite drastic drop in performance comparing the minor gains one gets when alpha and beta are set properly.\n\n2. It seems strange that the best performance is obtained when the group's size ratio is 0.5. From the figures in the paper, it follows that usually, one has more \u201corthogonal\u201d groups in a filter bank. I have an impression that the empirical evidence doesn\u2019t align well with the motivation of the proposed approach.\n\n3. The paper contains a significant amount of typos and incorrectly formatted references. There are also several places in the manuscript that I found hard to understand due to unusual phrasing.\n\nI would like to thank the authors for answering/addressing my pre-review questions. I would be grateful if the authors could provide more clarifications of the following:\n\n1. Question 2: I\u2019m not sure if modifying \\theta_{map} alone would result in any learning at all. Do I understand correctly that \\theta_{map} is only used to define groups? If so, then I don\u2019t see how the proposed method can be used in the purely unsupervised regime.\n\n2. Question 3: I was not referring to the fixed clustering based on the filter of the pre-trained network. One can perform that clustering at every step of the k-shot learning process. I\u2019m not sure I understand why the authors visualize grouping of _filters_ while in the actual algorithm they group _activations_. \n\nOverall, the paper is quite interesting but needs a stronger empirical justification of the approach as well as a better presentation of the material.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512629732, "id": "ICLR.cc/2017/conference/-/paper304/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper304/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper304/AnonReviewer1", "ICLR.cc/2017/conference/paper304/AnonReviewer2", "ICLR.cc/2017/conference/paper304/AnonReviewer3"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512629732}}}, {"tddate": null, "tmdate": 1482344195798, "tcdate": 1482344195798, "number": 3, "id": "rJnZPrOEe", "invitation": "ICLR.cc/2017/conference/-/paper304/official/review", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/conference/paper304/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper304/AnonReviewer3"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a k-shot learning framework that can be used on existing pre-trained networks by grouping filters that produce similar activations. The grouped filters are learned together to address overfitting when only few training samples are available. \n\nThe idea of the paper is interesting there are some encouraging results, but the current version doesn't seem ready for publication:\n\nPerformance:\nThe method should be compared with other state-of-the-art k-shot learning methods (e.g., Matching Networks by Vinyals et al., 2016). It's not clear how this method compares against them.\n\nMissing explanation:\nExperimental setting for k-shot learning should be more detailed.\n\nMeasure:\nAccuracy difference does not look like a good idea for comparing the baseline method and the proposed one. Just raw accuracies would be fine. \n\nMany grammatical errors and inappropriate formatting of citations, such as:\nM. et al. (2011)\nImageNet (Alex et al. (2012))\nJudy et al. (2013): this reference appears three times in the reference section.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512629732, "id": "ICLR.cc/2017/conference/-/paper304/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper304/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper304/AnonReviewer1", "ICLR.cc/2017/conference/paper304/AnonReviewer2", "ICLR.cc/2017/conference/paper304/AnonReviewer3"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512629732}}}, {"tddate": null, "tmdate": 1481842091189, "tcdate": 1481842091184, "number": 1, "id": "rJ7nT9gEe", "invitation": "ICLR.cc/2017/conference/-/paper304/official/review", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/conference/paper304/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper304/AnonReviewer1"], "content": {"title": "Dimensionality Reduction Approach.", "rating": "4: Ok but not good enough - rejection", "review": "The authors of this work propose a learnable approach to reducing the dimensionality of learned filters in deep neural networks. This is an interesting approach, but the presented work looks a bit raw.\n\n1. There are many typos in this manuscript. \n2. The experimental results are rather weak and don't show much improvement in accuracy. Instead the authors could position this work as a compression mechanism and would have to compare to low rank approximation of filters for DNNs. Yet this is not done. \n3. Aside from compression, OMG can be viewed as a form of regularization to reduce the unnecessary capacity of the network to improve generalization. Again, this is not addressed in enough detail.\n4. If the authors care to compare their approach to other 1-shot learning methods, then they would have to evaluate their approach with siamese and triplet learning networks. This isn't done.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512629732, "id": "ICLR.cc/2017/conference/-/paper304/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper304/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper304/AnonReviewer1", "ICLR.cc/2017/conference/paper304/AnonReviewer2", "ICLR.cc/2017/conference/paper304/AnonReviewer3"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512629732}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481658734747, "tcdate": 1478285453355, "number": 304, "id": "S1HcOI5le", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "S1HcOI5le", "signatures": ["~haoqi_fan1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481007822396, "tcdate": 1480924829495, "number": 1, "id": "SkrjC9Mmg", "invitation": "ICLR.cc/2017/conference/-/paper304/public/comment", "forum": "S1HcOI5le", "replyto": "rJ4Jwq17x", "signatures": ["~haoqi_fan1"], "readers": ["everyone"], "writers": ["~haoqi_fan1"], "content": {"title": "Thank you so much for your great questions", "comment": "Hi, Thank you so much for taking time reviewing this paper, and thank you for proposing such insightful questions.\n\n1. Thank you for your kind advice. We have revised the paper with the evaluation protocol and details to reflect your concern.\n\n2. Thank you for proposing this insightful question. That is exactly one important point we want to show in this paper.\nFor any neural network with OGM, there are two set of parameters \u03b8_w (parameters of the network) and \u03b8_{map} (parameter of the mapping). As we mentioned in p. 5, 3.1.2 that OMG can be used as an unsupervised method. If the loss is only cast on \u03b8_{map}, then the weights from the original network would not be changed, but only be grouped. Then the features are not degenerate since \u03b8_w is unchanged.\n\n3. This is a very important question and thank you very much for asking that!\nThe high-level answer would be: we want the grouping of OMG can reflect the distribution of given data rather than the distribution of the pre-trained network. And the grouping is more statically meaningful on activation rather than filters since the number of activation (the patches being forwarded) is much larger than the number of filters.\n\n\nIn order to clear the potential misunderstandings, we want to mention that OMG can work with most of the standard layers as the convolutional layer, fully connected layer, and etc. The reason we only visualize the grouping results on convolutional layers is that the convolutional kernel is easy to observe by readers.\n\n\nWe also love to highlight the key differences between our model and a \"clustering\" model. The clustering is not an end-to-end approach, and it can not manipulate the parameters of the neural network. But OMG can help the model learn a more discriminative feature. More specifically, learning the \u03b8_{map} can regard as clustering, but a more important component of OGM is trying to optimize the \u03b8_w with the given  \u03b8_{map}.\n\nThank you so much again for sharing your insightful thought on this paper. And we have revised this paper to reflect your concerns. More specifically, the experiemental section is change with more details and stronger argument.\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287629836, "id": "ICLR.cc/2017/conference/-/paper304/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HcOI5le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper304/reviewers", "ICLR.cc/2017/conference/paper304/areachairs"], "cdate": 1485287629836}}}, {"tddate": null, "tmdate": 1481007814349, "tcdate": 1480927445961, "number": 2, "id": "H1RR_sM7g", "invitation": "ICLR.cc/2017/conference/-/paper304/public/comment", "forum": "S1HcOI5le", "replyto": "SyPXH5fXx", "signatures": ["~haoqi_fan1"], "readers": ["everyone"], "writers": ["~haoqi_fan1"], "content": {"title": "Thank you so much for your great questions.", "comment": "Hi, thank you so much for your great questions.\nIt is my great pleasure to reply your concerns.\n\n\n1) Yes, indeed the Algorithm 1 is not describing the complete optimization of OMG. As we mentioned at the very end of page 5, the Algorithm 1 is proposed to optimize argmin_{\u03b8_{map}} L. So Algorithm 1 is exactly as you mentioned, is only used for group assignments. Another part of parameters - argmin_{\u03b8_w} L, is optimized by standard SGD as we mentioned in 3.1.3. The entire optimization is done by repeating the SGD and the Algorithm 1.\nI want to say thank you for bringing this very important concern! And I have revised the paper to make sure the description in the paper will not be misguiding.\n\n\n2) Thank you so much for bring this important issue! I have revised the paper to introduce and cite these baseline methods we compared with.\nIf you allowed me to have a quick description here:\nLate Fusions is a simple approach to independently train a source and target classifier and combine the scores of the two to create a final scoring function.\nCPM is a model designed for learning a compact dictionary of image patches representing meaningful components of an object. \n\n\n3) Thank you so much for bring this detailed question! I have revised the paper to reflect the k values in the paper. For Table 1. the k value is 1/2 of the neural unit size. And for Table 3. we used the grid search for each of the 20 random train/ test splits, so each time k values are different. However a quick answer of this question would be, the k value are also around 1/2 of the neural unit size.\n\n\nI\u2019d love to say thank you again for bringing these meaningful questions and concerns. I have revised the paper to reflect your great concerns.  More specifically, the experiemental section is change with more details and stronger argument."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287629836, "id": "ICLR.cc/2017/conference/-/paper304/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HcOI5le", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper304/reviewers", "ICLR.cc/2017/conference/paper304/areachairs"], "cdate": 1485287629836}}}, {"tddate": null, "tmdate": 1480922398836, "tcdate": 1480922398832, "number": 2, "id": "SyPXH5fXx", "invitation": "ICLR.cc/2017/conference/-/paper304/pre-review/question", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/conference/paper304/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper304/AnonReviewer3"], "content": {"title": "quesitons", "question": "Algorithm 1 is not complete as this is not an optimization algorithm but group assignments. Can you specify the full optimization algorithm?\n\nWhat are exactly are \u201cLate Fusions\u201d and CPM in table 2?\n\nWhat are the k values for table 1 and 3?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959349893, "id": "ICLR.cc/2017/conference/-/paper304/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper304/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper304/AnonReviewer2", "ICLR.cc/2017/conference/paper304/AnonReviewer3"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959349893}}}, {"tddate": null, "tmdate": 1480726235646, "tcdate": 1480726235641, "number": 1, "id": "rJ4Jwq17x", "invitation": "ICLR.cc/2017/conference/-/paper304/pre-review/question", "forum": "S1HcOI5le", "replyto": "S1HcOI5le", "signatures": ["ICLR.cc/2017/conference/paper304/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper304/AnonReviewer2"], "content": {"title": "Questions", "question": "1. p. 9, 5.3.1, Could the authors elaborate on the evaluation protocol and models in the comparison (e.g. how is baseline CNN trained)\n\n2. p. 5, 3.1.2, The authors mention that OMG can be used as an unsupervised method. Wouldn't that result in degenerate features (features that are not useful but still minimize para-loss)\n\n3. The algorithm uses activations to cluster the filters. Why is not that possible to use the appearance of filters themselves?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "OMG: Orthogonal Method of Grouping With Application of K-Shot Learning", "abstract": "Training a classifier with only a few examples remains a significant barrier when using neural networks with large number of parameters. Though various specialized network architectures have been proposed for these k-shot learning tasks to avoid overfitting, a question remains: is there a generalizable framework for the k-shot learning problem that can leverage existing deep models as well as avoid model overfitting? In this paper, we proposed a generalizable k-shot learning framework that can be used on any pre-trained network, by grouping network parameters to produce a low-dimensional representation of the parameter space. The grouping of the parameters is based on an orthogonal decomposition of the parameter space. To avoid overfitting, groups of parameters will be updated together during the k-shot training process. Furthermore, this framework can be integrated with any existing popular deep neural networks such as VGG, GoogleNet, ResNet, without any changes in the original network structure or any sacrifices in performance. We evaluate our framework on a wide range of intra/inter-dataset k-shot learning tasks and show state-of-the-art performance.", "pdf": "/pdf/369a5da0a0a4abeec41c3541591979aa7cdff827.pdf", "paperhash": "fan|omg_orthogonal_method_of_grouping_with_application_of_kshot_learning", "keywords": [], "conflicts": ["u.northwestern.edu", "baidu.com", "gmail.com", "northwestern.edu", "google.com", "eecs.berkeley.edu", "cs.cmu.edu", "cmu.edu", "andrew.cmu.edu"], "authors": ["Haoqi Fan", "Yu Zhang", "Kris M. Kitani"], "authorids": ["haoqif@andrew.cmu.edu", "kkitani@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959349893, "id": "ICLR.cc/2017/conference/-/paper304/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper304/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper304/AnonReviewer2", "ICLR.cc/2017/conference/paper304/AnonReviewer3"], "reply": {"forum": "S1HcOI5le", "replyto": "S1HcOI5le", "writers": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper304/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959349893}}}], "count": 9}