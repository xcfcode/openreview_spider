{"notes": [{"id": "SkexNpNFwS", "original": "ryeAB2-PvH", "number": 473, "cdate": 1569439016065, "ddate": null, "tcdate": 1569439016065, "tmdate": 1577168240630, "tddate": null, "forum": "SkexNpNFwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "BZdKH35SH_", "original": null, "number": 1, "cdate": 1576798697514, "ddate": null, "tcdate": 1576798697514, "tmdate": 1576800938243, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes applying potential flow generators in conjunction with L2 optimal transport regularity to favor solutions that \"move\" input points as little as possible to output points drawn from the target distribution.  The resulting pipeline can be effective in dealing with, among other things, image-to-image translation tasks with unpaired data.  Overall, one of the appeals of this methodology is that it can be integrated within a number of existing generative modeling paradigms (e.g., GANs, etc.).\n\nAfter the rebuttal and discussion period, two reviewers maintained weak reject scores while one favored strong acceptance.  With these borderline/mixed scores, this paper was discussed at the meta-review level and the final decision was to side with the majority, noting that a revision which fully addresses reviewer comments could likely be successful at a future venue.  As one important lingering issue, R1 pointed out that the optimality conditions of the proposed approach are only enforced on sampled trajectories, not actually on the entire space.  The rebuttal concedes this point, but suggests that the method still seems to work.  But as an improvement, the suggestion is made that randomly perturbed trajectories could help to mitigate this issue.  However, no experiments were conducted using this modification, which could be helpful in building confidence in the reliability of the overall methodology.\n\nAdditionally, from my perspective the empirical validation could also be improved to help solidify the contribution in a revision.  For example, the image-to-image translation experiments with CelebA were based on a linear (PCA) embedding and feedforward networks.  It would have been nice to have seen a more sophisticated setup for this purpose (as discussed in Section 5), especially for a non-theoretical paper with an ostensibly practically-relevant algorithmic proposal.  And consistent with reviewer comments, the paper definitely needs another pass to clean up a number of small grammatical mistakes.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716251, "tmdate": 1576800266347, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper473/-/Decision"}}}, {"id": "SJedfWUaYS", "original": null, "number": 3, "cdate": 1571803407889, "ddate": null, "tcdate": 1571803407889, "tmdate": 1573908438015, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "######## Updated Review ############\n\nThe author(s) have presented a sincere rebuttal, which I really appreciate. Although I still don't quite agree with all the points made by the author(s), I have changed my mind to be more or less borderline about this submission, given that the author(s) have gone through great length to clarify and improve their manuscript. \n\n\n#################################\n\nThis paper proposed a generative modeling framework called potential flow generator. Instead of deriving new matching criteria between distributions, the authors considered redefining the generative process via simulating a continuous flow that is constrained by the optimality conditions on the flow potential field derived based on L2 optimal transport. This is certainly an interesting direction to explore, however, while the points made are valid, they are not well justified. My major criticism is that too much compromise needs to be made in order to construct such a flow generator. In practical terms, it's computationally costly and sacrifices too much of the network's flexibility. My overall evaluation for this work is a straightforward/brute-force application of well-known (but less practical) results, without proposing any remedies to the real challenges that underlie. My detailed comments are listed below:\n\n1. It is assumed that the input distribution should have the same ambient dimensionality as the target distribution, and the continuity constraints mean that the deforming to the target can take an excruciatingly slow pace, the main obstacle faced by all flow-based constructions. This point is partly evidenced by the experiment section where none of the input distributions is far from the target. It's questionable whether this framework can efficiently perform \"generative modeling\", in which a simple noise distribution is pushed to a more sophisticated target distribution. \n\n2. Relations to the Neural ODE literature is not sufficiently discussed, which I believe is closest to this work. A major drawback of Neural ODE is slow computations. \n\n3. While the author(s) have criticized an intuitive construction of L2 transport penalty in Eqn (13), their objective Eqn (17) suffers a similar issue. \n\n4. The experiments are weak and not convincing. First, ss mentioned in earlier comments, 2D toy transport and image translation are fairly easy tasks. Second, only qualitative results are reported, and there is no baseline model to compare with. Third, without ablation study, We can hardly verify the fact the gains are actually coming from the flow part, as vanilla GANs can also perform a similar task. \n\nMinors: Additionally, language issues can be spotted here and there. The author(s) should more carefully proofread this manuscript. And I find it confusing that Fig 3 (a) and (b) uses different examples for WGAN and CNF. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576069311995, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper473/Reviewers"], "noninvitees": [], "tcdate": 1570237751617, "tmdate": 1576069312008, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Review"}}}, {"id": "S1eWiDDcjB", "original": null, "number": 10, "cdate": 1573709721469, "ddate": null, "tcdate": 1573709721469, "tmdate": 1573710077452, "tddate": null, "forum": "SkexNpNFwS", "replyto": "HJetYewqsr", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Part 3", "comment": "Reply to the detailed comments: \n\n1, Input distribution should have the same ambient dimensionality as the target distribution.\n\nIf they are not in the same dimension, we cannot define L2 optimal transport. And we think such requirement for the embedding space is reasonable for translation tasks.\n\nThe reviewer commented that \u201cthe main obstacle faced by all flow-based constructions\u201d is that the deforming is slow. Note that in our paper, by approximating the potential $\\phi$ instead of the transport scheme, we are actually looking for the generator with the shortest squared transport distance, so that the problem of slow deforming could be alleviated. In this sense, our paper is helping the development of the flow-based constructions.  \n\nPS: We want to comment on the reviewer\u2019s opinion that in generative model, \u201ca simple noise distribution is pushed to a more sophisticated target distribution\u201d. This is how the generative models were proposed years ago, but now we are far beyond that. The input distribution can be more than noise, for example, in translation tasks. We discussed this issue in the first page of the paper.\n\n2,  The reviewer commented that the relations to the Neural ODE literature is not sufficiently discussed. A major drawback of Neural ODE is slow computations. \n\nWe made an update to section 3.3.2 to discuss the relations to Neural ODE. \n\nYes, Neural ODE is slow if we refine the time discretization too much. But we still like this paper since it enlightened the future development of interpretable deep learning methods. We think our paper is an example of the exploration in this direction.\n\n3, The reviewer commented that while the author(s) have criticized an intuitive construction of L2 transport penalty in Eqn (13), their objective Eqn (17) suffers a similar issue.\n\nWe don\u2019t agree that the object Eqn 17 suffers a similar issue.\n\nFor the intuitive construction, the L2 transport penalty and original distribution loss (GAN loss or normalizing flow loss) are conflicted, since the L2 transport penalty achieves minimum if and only if the generator is an identity map, while the original loss achieves minimum if and only if the generator transports the input distribution to the target one. As a consequence, we always need to sacrifice both for a trade off. \n\nMeanwhile there is no conflict between PDE loss and original loss, since we can achieve minimum for both loss when we find the optimal transport from input to target distribution (the maximum likelihood training for normalizing flow models in equation 17 is equivalent to minimizing KL(target||output)), and this is exactly what we are looking for!  \n\nWe made a detailed quantitative comparison in 4.1.1 to justify our claim.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "SkguVwv9iH", "original": null, "number": 9, "cdate": 1573709615751, "ddate": null, "tcdate": 1573709615751, "tmdate": 1573709888945, "tddate": null, "forum": "SkexNpNFwS", "replyto": "HJetYewqsr", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Part 4", "comment": "4, The reviewer commented that the experiments are weak and not convincing. \n\nWe updated section 4 of the paper.\n\nIt\u2019s easy to transport one distribution to another. However, as we mentioned above, provided with unpaired data, it\u2019s not trivial to find the \u201ccorrect\u201d point-to-point map (e.g. we don\u2019t want to map from Alice\u2019s face to Bob\u2019s face). \n\nWe are surprised that the reviewer thinks \u201cvanilla GANs can also perform a similar task\u201d. Of course it cannot find the \u201ccorrect\u201d map. It will map from Alice\u2019s no smiling face to Bob\u2019s smiling face. We showed that in our revised paper (Figure 5).\n\nWe need additional regularity on the generator to find the \u201ccorrect\u201d map. Actually CycleGAN is also exploring this direction: the two generators are encouraged to be the inverse of each other by the consistency loss. However, we want to point out that the consistency loss in CycleGAN cannot provide sufficient regularity: we can still construct a pair of generators to be inverse of each other, where the first generator maps from Alice\u2019s face to Bob\u2019s face, and the second generator maps from Bob\u2019s face to Alice\u2019s face. This actually happened in our experiments, as shown in our revised paper (Figures 2 and 5).\n\nWe think the difference between Vanilla GAN, CycleGAN, and our method, is already clear via a qualitative comparison. Commonly used quantitative criteria for GANs, like Inception Score and Fr\u00e9chet Inception Distance, cannot be applied to our task, since they can only evaluate the generated distribution, but cannot evaluate the point-to-point map. And we don\u2019t have ground truth target images (e.g., we have images of no smiling Alice and smiling Bob, but we don\u2019t have images of smiling Alice).\n\nOverall, we don\u2019t agree with the reviewer that such translation problems with unpaired data are so simple that \u201cvanilla GANs can also perform a similar task\u201d. We made some updates on section 4.1 and 4.2, basically to compare between vanilla GAN, CycleGAN, and GANs with the potential flow generator. We hope that these updates can make our paper more convincing.\n\n5. As for Figure 3, we want to point out that if we use maximum likelihood training, for any normalizing flow model, no matter discrete or continuous, the input distribution should have positive density everywhere, otherwise the log density is going to be trouble. Therefore, the third problem for WGAN, where the input distribution is a uniform distribution on a square, cannot be solved by the normalizing flow model using maximum likelihood training. Also, the 2D Gaussian to Gaussian problem is pretty interesting and standard, so we tested CNF on this problem, and found that the performance is similar to GANs. The other two problems are the same. \n\n\n\nAt last we want to talk about our remedies to the real challenges. We view the interpretability of the generative models for translation tasks with unpaired data as a significant challenge. Instead of stacking tricks based on intuition, we want to formulate the problem and solve it in a mathematically interpretable way. We believe that our paper is exploring the right path.\n\nWe apologize again for not making our points clear in the first draft. We have improved our paper based on the helpful comments. We hope our revised paper is more convincing. If there are any other questions, please let us know.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "r1x3TDDcjS", "original": null, "number": 11, "cdate": 1573709763617, "ddate": null, "tcdate": 1573709763617, "tmdate": 1573709763617, "tddate": null, "forum": "SkexNpNFwS", "replyto": "HJetYewqsr", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Part 2", "comment": "2, Another major criticism is about the network\u2019s flexibility. \n\nBefore responding to this comment, we would like to discuss the meaning of it:  what does  flexibility mean? To map from one distribution to another one, there could be too many (even infinite) point-to-point map schemes, as is depicted in Figure 1. Actually, we have two different \u201cflexibilities\u201d. \n\nType-1: flexibility of distribution-to-distribution map, i.e. the generator family (the set consisting of generators with different network parameters) is sufficiently rich to approximately transport the input distribution to the target one. \nType-2: flexibility of point-to-point map, i.e. the generator family is sufficiently rich to approximate a specific map from points to points. \n\nOf course type-1 flexibility is good for us, but type-2 flexibility may not be: in translation tasks with unpaired data, taking the celebA task as an example, the type-2 flexibility is actually harmful, in that if the generator is too flexible in this sense, and thus we may map Alice\u2019s face to Bob\u2019s face! \n\nActually, this is exactly why we need to give additional \u201cregularization\u201d to the generator: we want to reduce the type-2 flexibility, without hurting the type-1 flexibility.\nCleary PFG will reduce the type-2 flexibility, in that we are looking for the L2 optimal transport maps, ruling out/discouraging the non-optimal ones.\nAs for the second part, we claim that the potential flow generator did not hurt the type-1 flexibility. We would like to show this both from theory and experiments.\n\nTheory: For any input and target distribution absolutely continuous w.r.t. Lebesgue measure (i.e. the distributions have density functions), the paper of Brenier has showed the existence of the time dependent potential $\\phi$. In our paper we use a neural network to approximate such potential function $\\phi$ directly. We cannot see any loss in the type-1 flexibility here. \n\nExperiments: we don\u2019t agree with the reviewer\u2019s comment that \u201cnone of the input distributions is far from the target\u201d. In Figure 3 the input and output distributions are totally different. Cases like Gaussian to muti-modal Gaussian, Gaussian to arcs, are very standard and widely used as test problems. Also, while the input digits and output digits \u201clook similar\u201d,  we don\u2019t think that the distribution of digits 0-4 and distribution of digits 5-9 are similar. Our experiments in the paper already showed that our generator could handle a wide spectrum of problems.\n\nOverall, we conclude that our method reduced the generator flexibility, but only for type-2 flexibility. This is not a bug, it's a feature!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "HJetYewqsr", "original": null, "number": 1, "cdate": 1573707905444, "ddate": null, "tcdate": 1573707905444, "tmdate": 1573709541517, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SJedfWUaYS", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Thanks to the reviewer for the helpful comments that helped us improve our manuscript! (Part 1)", "comment": "We would like to thank the reviewer for the helpful comments that helped us improve our manuscript.\n\nBefore going into a detailed discussion,  here we want to clarify our goal again. We are not just trying to transport from input distribution to target distribution, this is already well studied in various generative models. Note that to map from one distribution to another one, there could be too many (even infinite) point-to-point map schemes. Our goal is to regularize the generators in various generative models, so that we are trying to find the optimal map, which minimizes the squared transport distance. Such regularization could be applied to translation tasks where only UNPAIRED data are available, e.g. we have images of no smiling Alice and smiling Bob, but we don\u2019t have images of smiling Alice.\n\nReply to the major criticisms: \n\n1, One major criticism is about the compromise on computational cost. \n\nWe made a computational cost comparison between (a) vanilla WGAN-GP, (b) CycleGAN using WGAN-GP for loss functions, and (c) WGAN-GP with the potential flow generator (our method in the paper), on the celebA translation problem. To make a fair comparison, for each generator and discriminator, we use a feedforward neural network with the same size of hidden layers (5x256) (so that the total number of parameters used in Vanilla WGAN-GP and our method are similar whereas it is double in CycleGAN), and we use the same batch size and learning rate. We test all cases on the same single NVIDIA GeForce RTX 2080Ti GPU.\n\nWe found that for each iteration, vanilla WGAN-GP is the fastest, CycleGAN is about 1.5x in time,  and continuous PFG is about 2.3x in time. As for the number of iterations required for convergence, we found that our method and CycleGAN converge after 1e5 iterations. For the Vanilla GAN we observed that the output images keep changing even after 1.9e5 iterations, so we just cut off at 2e5 iteration. We made a detailed comparison in our revised paper (Figure 5), where we show that the Vanilla GAN and  CycleGANs can generate smiling faces, but from the \u201cwrong\u201d people.\n\nWe should point out that in the celebA problem we used n=10 as the number of timesteps in flow (it\u2019s coarse, but worked well in this problem); this is somewhat like a ResNet with about 10 blocks.  The computational cost would definitely increase if we refine the time discretization in the potential flow generator. \n\nOverall, we didn\u2019t see unacceptable compromise on computational cost in our practice. We think it\u2019s totally reasonable to pay some more computational cost for a correct solution, using our method. Of course we don\u2019t want a quick but wrong answer.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "B1ev54PqsH", "original": null, "number": 6, "cdate": 1573708943090, "ddate": null, "tcdate": 1573708943090, "tmdate": 1573709438660, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SkxDSfz8FB", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Thanks to the reviewer for the helpful comments that helped us improve our manuscript!  (Part 1)", "comment": "We would like to thank the reviewer for the helpful comments that helped us improve our manuscript!\n\n1, The reviewer commented that the class of potential functions over which the optimization is performed is not the whole class of functions, leading to approximations;\n\nUsing a neural network to approximate the potential $\\phi$ will lead to errors. However, the motivation and purpose of this paper is trying to regularize the deep generative model, instead of computing the exact L2 optimal transport. We have updated the paper, especially section 3.1 and conclusion, to further clarify this point.\n \n2, The reviewer commented that the optimality conditions are only enforced on sampled trajectories, not on the entire space.\n\nThis is an excellent point, and gave us the opportunity to rethink our algorithm.\n\nYes, the residual points should cover the whole spatial-temporal domain in principle. Theoretically, only penalizing the squared residual of the PDE on ``trajectories'' could lead to failure in approximating the L2 optimal transport map. However, in our numerical experiments, this \u201cflawed\u201d sampling strategy still works. As an improvement, in each training iteration we can perturb the trajectory points with Gaussian noise in space and uniform noise in time as residual points, so that they are sampled from the whole spatial-temporal domain in principle.\n\nWe didn\u2019t notice this problem in the first draft, since we thought if the solution of this HJ equation (Equation 7) exists for a certain initial condition, once it is satisfied in $supp(\\rho_t)$ (in the spatial-temporal domain), then $\\phi$ in $supp(\\rho_t)$ should be the correct solution. However, we just realized that it\u2019s possible that the solution doesn\u2019t exist in the whole domain, even when the equation is satisfied in $supp(\\rho_t)$.\n\nThanks so much for pointing this out. We updated Section 3.3.1 to clarify this point. \n\n3, About the comparisons.\n\nWe have updated section 4.1.2, 4.1.3 and 4.2.2, adding the comparisons with Seguys et al.18 and CycleGAN. Thanks again for the helpful suggestions!\n\n4, There are some unclear elements in the paper.\n\n4.1The final, total, optimization problem is never clearly expressed. I believe a general algorithm presentation could help in understanding the general picture of the method. \nSince we are trying to design a regularized generator for a wide range of generative models, it\u2019s difficult to give an algorithm presentation, since it depends on what kind of generative model we are using. For example, in WGAN-GP there are discriminators, but in normalizing flow model we don\u2019t use any discriminators, etc. \nIn short, our generator is a plug-and-play module in generative models: we only need to replace the original generator with ours, with a PDE loss augmented to the original generator loss (if using continuous potential flow generator). We updated the last section in the paper.\n\n4.2 Notably, for instance, It is still not clear if the generator G is disconnected from the potential definition (following Eq. 10 I assume not) How are the trajectories sampled.\nSorry that we didn\u2019t make ourselves clear in the first draft. \nNo, the generator is always connected from the potential definition. In short, we are using a neural network to represent the potential (see details in the reply 4.4 below). And then we have an ODE, where the velocity is the gradient of potential. Then by the time integral, we get a \u201ctrajectory\u201d from samples of input distribution to corresponding output samples.\n\n4.3 Is the discriminator trained on the same sampled trajectories or different ones.\nThe discriminator is trained on the outputs of generators, i.e. the terminal points of sampled trajectories. We didn\u2019t change the training of the discriminator in different generative models. Usually the training of discriminator is the key of different versions of GANs; keeping it untouched could help our method to be applied to more GAN models more easily.\n\n4.4 In the potential generator, it seems that the time is considered the same way as the feature space. Can you comment on this point ?\nIn the continuous potential flow generator, we use a neural network to represent $\\phi(x,t)$, therefore the input is the concatenation of feature (spatial coordinate in Euclidean space) and time. In the discrete potential flow generator, we use a neural network to represent $\\phi(x, 0)$, so the input is just the spatial coordinate. In this case $\\phi(x, t)$ with t>0 should be estimated via equation 8, which is a discretization of Equation 7.\n\n4.5 Is it possible to evaluate the flow of different time stamps that the ones used for training.\nWe are not sure if we understand the question. We can evaluate the flow by sampling the \u201ctrajectories\u2019\u2019.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "HJe9PIw5jH", "original": null, "number": 8, "cdate": 1573709410190, "ddate": null, "tcdate": 1573709410190, "tmdate": 1573709410190, "tddate": null, "forum": "SkexNpNFwS", "replyto": "B1ev54PqsH", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Part 2", "comment": "1, About theoretical novelty\n\nYes, the mathematical formulation of optimal transport in section 3.1 is well known, but we think to integrate it in a wide range of deep generative model, and to apply it in translation tasks are new.\n\n2, Error estimation\n\nIt\u2019s unrealistic to solve the Monge's problem and find the exact L2 optimal transport map, due to the limited families of neural network functions as well as the errors arise from training the neural networks (this might be the Holy Grail of neural networks, and is far beyond this paper). Instead, our goal is to regularize the generators in a wide range of generative models, so that the generator maps could approximate the L2 optimal transport map at least in low dimensional problems, and are endowed with the characteristics of \u201cproximity\u201d so that we can apply to engineering problems. We updated section 3.1 to further clarify this point.\n\nMinor comments:\n\nWe thought that in Brenier\u2019s paper in 1991, the domain is supposed to be bounded, while Gangbo and Mccann generalized to $R^d$. But you are right, Brenier should take the credit for the uniqueness of Monge problem for the squared Euclidean cost. We have updated the citation in section 2.\n\n\nWe thank the reviewer again for the helpful comments!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "H1ltkXv9jB", "original": null, "number": 5, "cdate": 1573708513436, "ddate": null, "tcdate": 1573708513436, "tmdate": 1573709159259, "tddate": null, "forum": "SkexNpNFwS", "replyto": "S1gXPSXhYB", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment", "content": {"title": "Thanks to the reviewer for the helpful suggestions that helped us improve our manuscript!", "comment": "We would like to thank the reviewer for the helpful suggestions that helped us improve our manuscript!\n\n1, The design of networks\nWe updated Appendix C to provide the detailed designs of the networks and other hyperparameters.\nSpecifically, in potential flow generator models, all the neural networks (including the networks representing $\\phi$ and discriminator networks) are feedforward neural networks of 5 hidden layers, each of width 256 in image translation tasks, or width 128 otherwise. The input layer dimension is D in discrete potential flow generator and D+1 in continuous potential flow generator, where D is the spatial dimension, and the output layer dimension is 1 in both. The activation function is tanh so that the represented potential function is smooth.\n\n2, We cited the two papers at the end of the revised paper. Another referee commented that the training of Neural ODE is slow, but the training of our method could be accelerated by applying methods related to optimal transport, e.g. the Wasserstein natural gradient method. We leave these possible improvements to future work.\n\nThanks again for the helpful suggestions!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkexNpNFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper473/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper473/Authors|ICLR.cc/2020/Conference/Paper473/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170967, "tmdate": 1576860550933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper473/Authors", "ICLR.cc/2020/Conference/Paper473/Reviewers", "ICLR.cc/2020/Conference/Paper473/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Comment"}}}, {"id": "SkxDSfz8FB", "original": null, "number": 1, "cdate": 1571328575444, "ddate": null, "tcdate": 1571328575444, "tmdate": 1572972591041, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper proposes a \u2018potential flow generator\u2019 that can be seen as a regularizer for traditional GAN losses. It is based on the idea that samples flowing from one distribution to another should follow a minimum travel cost path. This regularization is expressed as an optimal transport problem with a squared Euclidean cost. Authors rely on the dynamic formulation of OT proposed by Benamou and Brenier, 2000. They propose to learn a time-dependent potential field which gradient defines the velocity fields used to drive samples from a source distribution toward a target one. Experiments on a simple 1D case (where the optimal transport map is known), and on images with an MNIST / CelebA qualitative example.\nThe use of this dynamic formulation is well known in the OT community. See as a good examples:\nTrigila, G., & Tabak, E. G. (2016). Data\u2010driven optimal transport. Communications on Pure and Applied Mathematics, 69(4), 613-648.\nand more generally Chapter 7 of the \u2018Computational Optimal Transport\u2019 book by Peyr\u00e9 and Cuturi.\n\nThe novelty arises from the use of neural networks to represent the potentials. However, the claim that the obtained map is the optimal transport map seems wrong to me, because:\nThe class of potential functions over which the optimization is performed is not the whole class of functions, leading to approximations;\nThe optimality conditions (a.k.a continuity or preservation of mass equations) are only enforced on sampled trajectories, not on the entire space. \nWhile this claim should definitely be lowered, it is nonetheless still acceptable provided that the proposed model is performing good. On this part, the paper strength could be improved provided that comparisons with existing methods computing a Monge map could be given. Notably, a comparison with the approach from Seguy et al. 2018 is missing. On a same level, a qualitative comparison with cycleGAN  in Figure 4 is missing. \nThere are some unclear elements in the paper. The final, total, optimization problem is never clearly expressed. I believe a general algorithm presentation could help in understanding the general picture of the method. Notably, for instance, It is still not clear if the generator G is disconnected from the potential definition (following Eq. 10 I assume not). How are the trajectories sampled ? Is the discriminator trained on the same sampled trajectories or different ones ?  In the potential generator, it seems that the time is considered the same way as the feature space. Can you comment on this point ? Is it possible to evaluate the flow of different time stamps that the ones used for training ? \n\nAs a summary,\nPros:\nAn interesting way to represent time-dependent potentials with a network for regularizing generative models\nCons:\nNot much theoretical novelties in the paper, nor a good analysis on the source of errors of the model (e.g. impact of discretization on the problem)\nThere are some unclear aspects in the paper (see comments)\nThe potential benefits of the approach over the state-of-the-art should be more clearly discussed. \n\n\nMinor comment:\n P3. Uniqueness of Monge problem for the squared Euclidean cost should be attributed to Brenier 91 and his polar factorization theorem. McCann generalized it to Riemannian manifold.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576069311995, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper473/Reviewers"], "noninvitees": [], "tcdate": 1570237751617, "tmdate": 1576069312008, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Review"}}}, {"id": "S1gXPSXhYB", "original": null, "number": 2, "cdate": 1571726682830, "ddate": null, "tcdate": 1571726682830, "tmdate": 1572972591007, "tddate": null, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "invitation": "ICLR.cc/2020/Conference/Paper473/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This is a great paper using optimal transport theory for generative and implicit models. Instead of using general vector fields, the authors apply the potential vector fields in optimal transport theory to design neural networks. The mathematics is correct with convincing examples. This brings an important mathematical connection between fluid dynamics and GANs or implicit models. \n\nI suggest the acceptance of this paper after addressing the following minor questions. \n\n1. Would the authors provide slightly more details about the design of networks? \n\n2. In the literature, the author may need to cite \n\n\"A. Lin, W. Li, S. Osher, G. Montufar, Wasserstein proximal of GANs, 2018.\"\n\"W. Li, G. Montufar, Natural gradient via optimal transport, 2018\"\n\nThe Wasserstein natural gradient method there may improve the computational speed of the proposed models. \n\nIn all, this is an exciting paper with many potentials in future neural network designs. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper473/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liu_yang@brown.edu", "george_karniadakis@brown.edu"], "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for Generative Models", "authors": ["Liu Yang", "George Em Karniadakis"], "pdf": "/pdf/25a7b5dbd2a8a4633471178ae89dbb79f3011c07.pdf", "TL;DR": "We propose a special generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models.", "abstract": "We propose a potential flow generator with $L_2$ optimal transport regularity, which can be easily integrated into a wide range of generative models including different versions of GANs and flow-based models. With up to a slight augmentation of the original generator loss functions, our generator is not only a transport map from the input distribution to the target one, but also the one with minimum $L_2$ transport cost. We show the correctness and robustness of the potential flow generator in several 2D problems, and illustrate the concept of ``proximity'' due to the $L_2$ optimal transport regularity. Subsequently, we demonstrate the effectiveness of the potential flow generator in image translation tasks with unpaired training data from the MNIST dataset and the CelebA dataset. ", "code": "https://drive.google.com/drive/folders/1I04bvuQqiorxhq4pVedgrmPZKnA6N4-D?usp=sharing", "keywords": ["generative models", "optimal transport", "GANs", "flow-based models"], "paperhash": "yang|potential_flow_generator_with_l_2_optimal_transport_regularity_for_generative_models", "original_pdf": "/attachment/b01fd8b9a8c722d75ba157b213ad6abb569c83e8.pdf", "_bibtex": "@misc{\nyang2020potential,\ntitle={Potential Flow Generator with {\\$}L{\\_}2{\\$} Optimal Transport Regularity for Generative Models},\nauthor={Liu Yang and George Em Karniadakis},\nyear={2020},\nurl={https://openreview.net/forum?id=SkexNpNFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkexNpNFwS", "replyto": "SkexNpNFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper473/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576069311995, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper473/Reviewers"], "noninvitees": [], "tcdate": 1570237751617, "tmdate": 1576069312008, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper473/-/Official_Review"}}}], "count": 12}