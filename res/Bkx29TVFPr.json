{"notes": [{"id": "Bkx29TVFPr", "original": "rygpLmCDvB", "number": 721, "cdate": 1569439123697, "ddate": null, "tcdate": 1569439123697, "tmdate": 1577168291667, "tddate": null, "forum": "Bkx29TVFPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ndn2zhMfK7", "original": null, "number": 1, "cdate": 1576798704205, "ddate": null, "tcdate": 1576798704205, "tmdate": 1576800931857, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes an implicit function approach to learning the modes of multimodal regression. The basic idea is interesting, and is clearly related to density estimation, which the paper does not discuss. \n\nBased on the reviews and the fact that the authors did not submit a helpful rebuttal, I recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728716, "tmdate": 1576800281174, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper721/-/Decision"}}}, {"id": "B1lVl4iioB", "original": null, "number": 3, "cdate": 1573790699802, "ddate": null, "tcdate": 1573790699802, "tmdate": 1573790699802, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "Sye133lTKS", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment", "content": {"title": "Thanks for the positive feedback.", "comment": "Thanks for reading our paper carefully.  We will take into account all of your suggestions/questions/comments in the next version. We apologize that we do not have sufficient time to respond to all of your questions. \n\nWhen doing prediction: yes, we conducted experiments with/without the partial derivative term. The partial derivative term is critical to ensure implicit function theorem applies around the query point. Empirically, doing prediction without that term can work on some dataset, but can also find many wrong points on some other datasets. Hence, incorporating that term is more robust across datasets. \n\nThe error distribution is assumed to be Gaussian. \"look like Gaussian\" may be subjective. (a) is using a training set without adding noise so it can be thought of as Gaussian with mean zero and take the limit of variance to zero. Our figure shows that the errors highly concentrate around zero. Note that we use the whole training set for computing the distribution. It should be a good approximation. \n\nFig 5. For implicit model, we indeed get the representation by feeding into both x and y and y is found by grid search. Implicit model takes both x and y as input. Hence we expect the neural network representation should be finer as the target space information can be utilized. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper721/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkx29TVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper721/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper721/Authors|ICLR.cc/2020/Conference/Paper721/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167224, "tmdate": 1576860530597, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment"}}}, {"id": "rylHeo5oiH", "original": null, "number": 2, "cdate": 1573788396947, "ddate": null, "tcdate": 1573788396947, "tmdate": 1573788396947, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "HJlJbLHVtB", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment", "content": {"title": "Thank you for reading our paper. ", "comment": "Thank you for reading our paper. We believe our empirical results should be considered as persuasive in modal regression literature as far as we know. "}, "signatures": ["ICLR.cc/2020/Conference/Paper721/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkx29TVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper721/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper721/Authors|ICLR.cc/2020/Conference/Paper721/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167224, "tmdate": 1576860530597, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment"}}}, {"id": "Hkec0q9osH", "original": null, "number": 1, "cdate": 1573788370209, "ddate": null, "tcdate": 1573788370209, "tmdate": 1573788370209, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "HklWwuchKB", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment", "content": {"title": "Thank you for reading our paper. ", "comment": "Thank you for taking time to read our paper. We believe our empirical results should be considered as persuasive in modal regression literature as far as we know. "}, "signatures": ["ICLR.cc/2020/Conference/Paper721/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkx29TVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper721/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper721/Authors|ICLR.cc/2020/Conference/Paper721/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167224, "tmdate": 1576860530597, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper721/Authors", "ICLR.cc/2020/Conference/Paper721/Reviewers", "ICLR.cc/2020/Conference/Paper721/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Comment"}}}, {"id": "HJlJbLHVtB", "original": null, "number": 1, "cdate": 1571210742851, "ddate": null, "tcdate": 1571210742851, "tmdate": 1572972560653, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper proposes an implicit function approach to learning the modes of multimodal regression. The basic idea is interesting, and is clearly related to density estimation, which the paper should have discussed. On the other hand the tackled problem is a weaker variant of the learning multimodal output distributions in regression. What is the benefit of tackling this simpler problem, when in reality we are interested in the output distributions? In Bayesian literature (BNNs, deep GPs, Bayesian regression) multimodal outputs are routinely produced, but the paper ignores these methods. The paper should compare to these, and demonstrate the benefit of just learning the modes instead of learning the full output distributions (perhaps the mode learning gives more accurate mode assignment?).\n\nThe paper should be more rigorous on what is the problem setting. Right now its unclear if g(.) is multimodal, if \\eta is multimodal, or if both are. This is an important distinction since it deals with whether the underlying system is modal or if the noise modal, and connects with aleatoric/epistemic characterisations. The earlier works could have been presented in more clear manner, currently the paper gives an impression that learning joint function over (x,y) is novel which it surely isn't. It was a bit hard to follow the earlier works, they should be more clearly categorised.\n\nThe artificial datasets raise more questions than they answer. Both of them are simple univariate cases, where one would expect even simple approaches work very well. But there are suddenly 40000 datapoints for the first case (why not eg 50?), optimisation seems to take hundreds of thousands of iterations, and the results are still quite bad all around (fig3). I suspect that there are coding issues, and overall the univariate examples are not very informative in general. The \"high-dimensional\" case is not really high-dimensional, and a real one should have been proposed instead. There are also no real competing methods in any experiments, except for very simple regression methods or baselines from the 90's (MDN). With no comparisons to competing methods the experiments are close to worthless. The two real dataset experiments are not enough, and even there the improvement seems to be modest with only trivial baselines included. I also don't understand why the bike classification problem is chosen for regression.\n\nThe paper proposes to combine the implicit function idea with output mode estimation, however the problem definition is vague, competing Bayesian methods and density estimation methods are ignored, the experiments are insufficient with little state-of-the-art comparisons, few datasets and clear problems in the learning. The results show only small improvements, which are not explicated sufficiently. The specific problem tackled is of minor importance for the wider ICLR community."}, "signatures": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575279520034, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper721/Reviewers"], "noninvitees": [], "tcdate": 1570237748055, "tmdate": 1575279520046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Review"}}}, {"id": "HklWwuchKB", "original": null, "number": 2, "cdate": 1571756120837, "ddate": null, "tcdate": 1571756120837, "tmdate": 1572972560619, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a parametric modal regression algorithm for multi-modal distributions. In such settings, learning the conditional mode is more desirable than the conditional mean, the latter being the focus of standard regression approaches. The objective in model regression is to find the conditional mode. \n\nExisting non-parametric approaches to learning the conditional mode are difficult to scale. On the other hand, existing parametric approaches for modal regression aim to learn the full conditional distribution, which is a much harder problem. The present work proposes a parametric approach to estimate the conditional mode using the Implicit Function Theorem. The key idea is to learn a (parametric and implicit) function f(x,y) whose minima(s) 'y' corresponds to the conditional modes. However, the paper does not explain clearly how the above idea is put to practice as an algorithm in Section 3. It will be great if Section 3 can be re-written with more detailed explanations in paragraphs following the \"Implicit Function Theorem\" definition and more examples. \n\nThe experiments mainly are performed artificial datasets to assess the algorithm when the underlying multi-model distributions are known. Empirical results are also discussed on a couple of real-world datasets where the proposed algorithm obtains the best results. "}, "signatures": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575279520034, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper721/Reviewers"], "noninvitees": [], "tcdate": 1570237748055, "tmdate": 1575279520046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Review"}}}, {"id": "Sye133lTKS", "original": null, "number": 3, "cdate": 1571781799435, "ddate": null, "tcdate": 1571781799435, "tmdate": 1572972560574, "tddate": null, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "invitation": "ICLR.cc/2020/Conference/Paper721/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper considers the regression problem in scenarios in which the conditional distribution of the response variable y given the input x is multimodal. For artificially constructed datasets, in which the the conditional modes are known, performance is assessed by the RMS distance to the mode closest to each prediction.  For real-world datasets, performance is in terms of RMSE and MAE.\n\nThe authors propose to learn a function f(x,y) that takes both an input x and a proposed output y and produces a value of 0 when the output y is correct for the input (i.e a conditional mode of p(y|x)), and hopefully a nonzero output when y is incorrect.  To predict on a point x, one searches for a y that makes f(x,y)=0.  For this to work, we will need f(x,y)\u22600 for incorrect y. To achieve this, the authors take inspiration from the implicit function theorem and additionally seek an f with \u2202f/\u2202y=-1 at the modes for each x.  For implementation, they seeks an f that minimizes the objective f\u00b2(x\u1d62,y\u1d62) + ( \u2202f(x\u1d62,y\u1d62)/\u2202y - 1 )\u00b2 over the training data.  To predict y for a given x, they find argmin_y f\u00b2(x,y) + ( \u2202f(x,y)/\u2202y - 1 )\u00b2 by grid search over the range of y, which they assume to be known. \n\nI think this is a very interesting and novel approach to regression.  It seems to work well in artificial examples and competitively on some real world examples.  \n\nMy main concern is that, although the objective function is fairly intuitive, it is not  clear to me what the properties are of the population minimizer (i.e. in the infinite data case).  Equation (1) defines modes as local maxima of the density, and for evaluation purposes on the artificial data, we look at deviation from the closest conditional mode.  With infinite data, do we expect the f to converge to something that's 0 at all the conditional modes, or just at the ones with the largest density?  What do we even want to happen?  Can we use this approach to predict all the modes for each x?  While I consider all of these interesting questions, after some consideration, I don't think that missing answers to these questions should delay publication.  \n\nI recommend accepting this paper, assuming reasonable responses can be provided to the questions and issues below.  It's a novel and promising approach to an interesting problem in regression.  It leaves some open questions for further theoretical analysis, but that seems ok to me.\n\nSpecific questions:\n- In section 3, second sentence, I think you want to write either the minimum of f^2 or a zero of f?\n- Page 3, not sure what is meant by \"should be described by the same mapping g_j(x).\"\n- In the implicit function theorem, it ends with a capital F, but I think you want f.\n- When you say \"this condition is only local and may not encourage a minimal set of conditional modes\" -- I guess you mean a minimum set of zeros? Or predicted conditional modes?\n- In Equation 5, you write a full l_2 norm for what I believe is just a scalar -- how about parenthesis instead?\n- When you make your y prediction using the argmin... it seems like you could also minimize without the partial derivative term, as in your original explanation of f.  Did you compare the performance with and without the partial derivative term?\n- In comparing to the MDN network, it's interesting that MDN needs more mixture components than the true distribution, but that doesn't really seem like a point of criticism.  Neural networks themselves seem to work better with far more parameters than we think they should need.  To be fair, I'd suggest hyperparameter searching over a broader range of mixture components for MDNs, maybe up to 10.  \n- In your section \"verify the learned error distribution\", you say that \"it is obvious that the error function indeed looks like a Gaussian distribution and the one trained without noise 4(a) shows an extremely small variance.\"  Two comments: 1) It's definitely not obvious that 4(a) has a Gaussian distribution. 2) Why would you expect 2a to be Gaussian?  The variance should be entirely due to the randomness in the selection of training data, which has nothing to do with Gaussians in the 0 noise case, as far as I can tell.\n- In Figure 5, are the error bands the standard error of the mean, or the standard deviation across trials, or something else?\n- I don't at all understand the setup of the 'Examining the neural network representation'.  I understand what the embedding of x is for the L2 model but what does that mean for the Implicit model, in which an x cannot be embedded without a y? \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper721/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pan6@ualberta.ca", "whitem@ualberta.ca", "farahmand@vectorinstitute.ai"], "title": "An implicit function learning approach for parametric modal regression", "authors": ["Yangchen Pan", "Martha White", "Amir-massoud Farahmand"], "pdf": "/pdf/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "TL;DR": "We introduce a simple and novel modal regression algorithm which is easy to scale to large problems. ", "abstract": "For multi-valued functions---such as when the conditional distribution on targets given the inputs is multi-modal---standard regression approaches are not always desirable because they provide the conditional mean. Modal regression approaches aim to instead find the conditional mode, but are restricted to nonparametric approaches. Such approaches can be difficult to scale, and make it difficult to benefit from parametric function approximation, like neural networks, which can learn complex relationships between inputs and targets. In this work, we propose a parametric modal regression algorithm, by using the implicit function theorem to develop an objective for learning a joint parameterized function over inputs and targets. We empirically demonstrate on several synthetic problems that our method (i) can learn multi-valued functions and produce the conditional modes, (ii) scales well to high-dimensional inputs and (iii) is even more effective for certain unimodal problems, particularly for high frequency data where the joint function over inputs and targets can better capture the complex relationship between them. We conclude by showing that our method provides small improvements on two regression datasets that have asymmetric distributions over the targets. ", "keywords": ["regression", "modal regression", "implicit function theorem", "multivalue function"], "paperhash": "pan|an_implicit_function_learning_approach_for_parametric_modal_regression", "original_pdf": "/attachment/9f564c062bbaafd9996290ddc42e916deb322bce.pdf", "_bibtex": "@misc{\npan2020an,\ntitle={An implicit function learning approach for parametric modal regression},\nauthor={Yangchen Pan and Martha White and Amir-massoud Farahmand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkx29TVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkx29TVFPr", "replyto": "Bkx29TVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper721/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575279520034, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper721/Reviewers"], "noninvitees": [], "tcdate": 1570237748055, "tmdate": 1575279520046, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper721/-/Official_Review"}}}], "count": 8}