{"notes": [{"id": "rylVYjqHdN", "original": "Skx9f8_H_N", "number": 56, "cdate": 1553472379603, "ddate": null, "tcdate": 1553472379603, "tmdate": 1562082113313, "tddate": null, "forum": "rylVYjqHdN", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "A Pseudo-Label Method for Coarse-to-Fine Multi-Label Learning with Limited Supervision", "authors": ["Cheng-Yu Hsieh", "Miao Xu", "Gang Niu", "Hsuan-Tien Lin", "Masashi Sugiyama"], "authorids": ["r05922048@ntu.edu.tw", "miao.xu@riken.jp", "gang.niu@riken.jp", "htlin@csie.ntu.edu.tw", "sugi@k.u-tokyo.ac.jp"], "keywords": ["Multi-Label Learning", "Weakly-Supervised Learning", "Pseudo-Labels", "Meta-Learning"], "TL;DR": "We propose a special weakly-supervised multi-label learning problem along with a newly tailored algorithm that learns the underlying classifier by learning to assign pseudo-labels.", "abstract": "The goal of multi-label learning (MLL) is to associate a given instance with its relevant labels from a set of concepts. Previous works of MLL mainly focused on the setting where the concept set is assumed to be fixed, while many real-world applications require introducing new concepts into the set to meet new demands. One common need is to refine the original coarse concepts and split them into finer-grained ones, where the refinement process typically begins with limited labeled data for the finer-grained concepts. To address the need, we propose a special weakly supervised MLL problem that not only focuses on the situation of limited fine-grained supervision but also leverages the hierarchical relationship between the coarse concepts and the fine-grained ones. The problem can be reduced to a multi-label version of negative-unlabeled learning problem using the hierarchical relationship. We tackle the reduced problem with a meta-learning approach that learns to assign pseudo-labels to the unlabeled entries. Experimental results demonstrate that our proposed method is able to assign accurate pseudo-labels, and in turn achieves superior classification performance when compared with other existing methods.", "pdf": "/pdf/4fa57ef71ac362a2169d6cdeb2a6dcd6839d85b0.pdf", "paperhash": "hsieh|a_pseudolabel_method_for_coarsetofine_multilabel_learning_with_limited_supervision"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "SkeUhEJVtV", "original": null, "number": 1, "cdate": 1554408621534, "ddate": null, "tcdate": 1554408621534, "tmdate": 1555512027658, "tddate": null, "forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Official_Review", "content": {"title": "Review: A Pseudo-Label Method for Coarse-to-Fine Multi-Label Learning with Limited Supervision", "review": "The authors propose and implement a new meta-learning approach for multi-label classification where the labels are structured in a two-level hierarchy (i.e. if an example has a label y, it has the label y* where y* is any ancestor of y in the hierarchy).\n\nThe text in Figure 2 is very difficult to see since the font size is so small.\n\nI found the use of \"relevance\" describe a label of y=1 to be a little confusing. Why not use \"membership\", e.g. y=1 if the given instance belongs to the particular class?\n\nThe font in Table 1 is also a little small.\n\nIn equation 2, if (i,j) \\notin \\Omega, then what does [Y^psuedo]_i,j = {0, 1} mean? [Y^psuedo]_i,j isn't set-valued, is it?\n\nIn equation 7, the outermost parenthesis should be made larger to more appropriately fit its content. In addition, the sign function typically returns a value in {-1, 0, 1}, but your labels are in {0, 1}.\n\nHow did you obtain the feature vector from the examples in MS COCO? What is the classifier you used?\n\nFigure 4 is a bit difficult to read due to the dual y-axes. Perhaps splitting it into two figures would make it easier to understand?\n\nSome grammatical errors detract from the reader's ability to quickly understand the content. For example, there are a number of nouns with missing determiners (\"the\", \"a\", etc). Some verbs do not agree with the grammatical number of the subject noun. A few minor spelling errors: \"decent\" vs \"descent\", \"performances\" vs \"performance\", \"recover loss\" vs \"recovery loss\".\n", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Pseudo-Label Method for Coarse-to-Fine Multi-Label Learning with Limited Supervision", "authors": ["Cheng-Yu Hsieh", "Miao Xu", "Gang Niu", "Hsuan-Tien Lin", "Masashi Sugiyama"], "authorids": ["r05922048@ntu.edu.tw", "miao.xu@riken.jp", "gang.niu@riken.jp", "htlin@csie.ntu.edu.tw", "sugi@k.u-tokyo.ac.jp"], "keywords": ["Multi-Label Learning", "Weakly-Supervised Learning", "Pseudo-Labels", "Meta-Learning"], "TL;DR": "We propose a special weakly-supervised multi-label learning problem along with a newly tailored algorithm that learns the underlying classifier by learning to assign pseudo-labels.", "abstract": "The goal of multi-label learning (MLL) is to associate a given instance with its relevant labels from a set of concepts. Previous works of MLL mainly focused on the setting where the concept set is assumed to be fixed, while many real-world applications require introducing new concepts into the set to meet new demands. One common need is to refine the original coarse concepts and split them into finer-grained ones, where the refinement process typically begins with limited labeled data for the finer-grained concepts. To address the need, we propose a special weakly supervised MLL problem that not only focuses on the situation of limited fine-grained supervision but also leverages the hierarchical relationship between the coarse concepts and the fine-grained ones. The problem can be reduced to a multi-label version of negative-unlabeled learning problem using the hierarchical relationship. We tackle the reduced problem with a meta-learning approach that learns to assign pseudo-labels to the unlabeled entries. Experimental results demonstrate that our proposed method is able to assign accurate pseudo-labels, and in turn achieves superior classification performance when compared with other existing methods.", "pdf": "/pdf/4fa57ef71ac362a2169d6cdeb2a6dcd6839d85b0.pdf", "paperhash": "hsieh|a_pseudolabel_method_for_coarsetofine_multilabel_learning_with_limited_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Official_Review", "cdate": 1553713412221, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713412221, "tmdate": 1555511822384, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper56/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Sylgq-GuKV", "original": null, "number": 2, "cdate": 1554682247781, "ddate": null, "tcdate": 1554682247781, "tmdate": 1555511886725, "tddate": null, "forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Official_Review", "content": {"title": "This paper investigated an interesting setting, where the coarse labels are abundant and fine-grained labels are scarce. ", "review": "\nThe paper proposed to minimize the discrepancy between inferred fine-grained labels and given coarse labels, by assigning each training example a fine-grained pseudo label, which agrees with the direction of gradient descent. The experiment shows improvement over existing methods.\n\nHowever, the paper didn't cover the details of the model, which makes their claim less convincing. E.g. does it use hierarchical classification or totally ignore the hierarchical structure in prediction? Is the loss of true labels and pseudo labels weighted?\n\nAlso, I think the method of assigning pseudo labels is not quite stable. How about picking the most confident examples in each round, just like self training? It's interesting to see comparison of these methods.\n\nAnyway, as the method and setting are quite novel, I'd recommend acceptance of this paper.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Pseudo-Label Method for Coarse-to-Fine Multi-Label Learning with Limited Supervision", "authors": ["Cheng-Yu Hsieh", "Miao Xu", "Gang Niu", "Hsuan-Tien Lin", "Masashi Sugiyama"], "authorids": ["r05922048@ntu.edu.tw", "miao.xu@riken.jp", "gang.niu@riken.jp", "htlin@csie.ntu.edu.tw", "sugi@k.u-tokyo.ac.jp"], "keywords": ["Multi-Label Learning", "Weakly-Supervised Learning", "Pseudo-Labels", "Meta-Learning"], "TL;DR": "We propose a special weakly-supervised multi-label learning problem along with a newly tailored algorithm that learns the underlying classifier by learning to assign pseudo-labels.", "abstract": "The goal of multi-label learning (MLL) is to associate a given instance with its relevant labels from a set of concepts. Previous works of MLL mainly focused on the setting where the concept set is assumed to be fixed, while many real-world applications require introducing new concepts into the set to meet new demands. One common need is to refine the original coarse concepts and split them into finer-grained ones, where the refinement process typically begins with limited labeled data for the finer-grained concepts. To address the need, we propose a special weakly supervised MLL problem that not only focuses on the situation of limited fine-grained supervision but also leverages the hierarchical relationship between the coarse concepts and the fine-grained ones. The problem can be reduced to a multi-label version of negative-unlabeled learning problem using the hierarchical relationship. We tackle the reduced problem with a meta-learning approach that learns to assign pseudo-labels to the unlabeled entries. Experimental results demonstrate that our proposed method is able to assign accurate pseudo-labels, and in turn achieves superior classification performance when compared with other existing methods.", "pdf": "/pdf/4fa57ef71ac362a2169d6cdeb2a6dcd6839d85b0.pdf", "paperhash": "hsieh|a_pseudolabel_method_for_coarsetofine_multilabel_learning_with_limited_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Official_Review", "cdate": 1553713412221, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper56/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713412221, "tmdate": 1555511822384, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper56/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Hye_n0hG9V", "original": null, "number": 1, "cdate": 1555381935820, "ddate": null, "tcdate": 1555381935820, "tmdate": 1555510976167, "tddate": null, "forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "The paper has some relatively minor issue but an overall interesting concept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Pseudo-Label Method for Coarse-to-Fine Multi-Label Learning with Limited Supervision", "authors": ["Cheng-Yu Hsieh", "Miao Xu", "Gang Niu", "Hsuan-Tien Lin", "Masashi Sugiyama"], "authorids": ["r05922048@ntu.edu.tw", "miao.xu@riken.jp", "gang.niu@riken.jp", "htlin@csie.ntu.edu.tw", "sugi@k.u-tokyo.ac.jp"], "keywords": ["Multi-Label Learning", "Weakly-Supervised Learning", "Pseudo-Labels", "Meta-Learning"], "TL;DR": "We propose a special weakly-supervised multi-label learning problem along with a newly tailored algorithm that learns the underlying classifier by learning to assign pseudo-labels.", "abstract": "The goal of multi-label learning (MLL) is to associate a given instance with its relevant labels from a set of concepts. Previous works of MLL mainly focused on the setting where the concept set is assumed to be fixed, while many real-world applications require introducing new concepts into the set to meet new demands. One common need is to refine the original coarse concepts and split them into finer-grained ones, where the refinement process typically begins with limited labeled data for the finer-grained concepts. To address the need, we propose a special weakly supervised MLL problem that not only focuses on the situation of limited fine-grained supervision but also leverages the hierarchical relationship between the coarse concepts and the fine-grained ones. The problem can be reduced to a multi-label version of negative-unlabeled learning problem using the hierarchical relationship. We tackle the reduced problem with a meta-learning approach that learns to assign pseudo-labels to the unlabeled entries. Experimental results demonstrate that our proposed method is able to assign accurate pseudo-labels, and in turn achieves superior classification performance when compared with other existing methods.", "pdf": "/pdf/4fa57ef71ac362a2169d6cdeb2a6dcd6839d85b0.pdf", "paperhash": "hsieh|a_pseudolabel_method_for_coarsetofine_multilabel_learning_with_limited_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper56/Decision", "cdate": 1554736073701, "reply": {"forum": "rylVYjqHdN", "replyto": "rylVYjqHdN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736073701, "tmdate": 1555510965161, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}