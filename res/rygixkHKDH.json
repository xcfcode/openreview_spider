{"notes": [{"id": "rygixkHKDH", "original": "H1xKeIs_vS", "number": 1519, "cdate": 1569439475149, "ddate": null, "tcdate": 1569439475149, "tmdate": 1583912031395, "tddate": null, "forum": "rygixkHKDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "B_JqXFdQ8H", "original": null, "number": 1, "cdate": 1576798725397, "ddate": null, "tcdate": 1576798725397, "tmdate": 1576800911099, "tddate": null, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Decision", "content": {"decision": "Accept (Talk)", "comment": "This paper investigates the use non-convex optimization for two dictionary learning problems, i.e., over-complete dictionary learning and convolutional dictionary learning. The paper provides theoretical results, associated with empirical experiments, about the fact that, that when formulating the problem as an l4 optimization, gives rise to a landscape with strict saddle points and as such, they can be escaped with negative curvature. As a result, descent methods can be used for learning with provable guarantees. All reviews found the work extremely interesting, highlighting the importance of the results that constitute \"a solid improvement over the prior understandings on over-complete DL\" and \"extends our understanding of provable methods for dictionary learning\". This is an interesting submission on non-convex optimization, and as such of interest to the ML community of ICLR . I'm recommending this work for acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795719238, "tmdate": 1576800269853, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Decision"}}}, {"id": "BygCupVAYH", "original": null, "number": 2, "cdate": 1571863926231, "ddate": null, "tcdate": 1571863926231, "tmdate": 1574307560975, "tddate": null, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper studies the dictionary learning problem for two popular settings involving sparsely used over-complete dictionaries and convolutional dictionaries.\n\nFor the over-complete dictionary setting, given the measurements of the form $Y = A X$, where $A$ and $X$ denote the over-complete dictionary and the sparse coefficients, respectively, the paper explores an $\\ell^4$-norm maximization approach to recover the dictionary $A$. This corresponds to maximizing $\\|q^TY\\|^4_4$ over $q \\in \\mathbb{S}^{n-1}$. Interestingly, the paper shows that when $A$ is unit norm tight frame and incoherent the optimization landscape of the aforementioned non-convex objective has strict saddle points that can be escaped by along negative curvature. Furthermore, all local minimizers are globally optimal which are close to one of the columns of $A$. This shows that any descent method that can escape the saddle points will (approximately) recover one of the columns of $A$. \n\nFor convolution dictionaries, the paper shows that when the underlying filters are incoherent a suitably modified $\\ell^4$-norms based objective has only strict saddles over a sub-level set. Furthermore, all local optimizers within this sub-level set are close to one of the convolution filters. \n\nThe reviewer believes that this paper presents many interesting and novel results that extend our understanding of provable methods for dictionary learning. As claimed in the paper, this the first global characterization for the non-convex optimization landscape for over-complete dictionary learning. Besides, the paper provides the first provable guarantees for convolution dictionary learning. Overall, the paper is very well written and the key ideas used in the paper are nicely explained in the main body of the paper. The experimental results in the paper also corroborate the theoretical findings of the paper.\n\nMinor comments:\n\n1. In page 2, \"....can be simply summarized by the following slogan.\" ---> \"....can be simply summarized by the following statement.\"?\n\n2.  In page 7, replace \"cook up\" with \"propose\"?\n\n------------------------------\nAfter rebuttal\n\nThank you for the response. Releasing the code for reproducibility purposes is certainly a great idea.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576116228629, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Reviewers"], "noninvitees": [], "tcdate": 1570237736194, "tmdate": 1576116228641, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review"}}}, {"id": "H1eJ2sF2or", "original": null, "number": 5, "cdate": 1573850022868, "ddate": null, "tcdate": 1573850022868, "tmdate": 1573850022868, "tddate": null, "forum": "rygixkHKDH", "replyto": "ryxV5ne2jB", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment", "content": {"title": "Reply to Reviewer #3", "comment": "We thank the reviewer for the appreciations of our efforts in the revision."}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rygixkHKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1519/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1519/Authors|ICLR.cc/2020/Conference/Paper1519/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154812, "tmdate": 1576860543657, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment"}}}, {"id": "ryxV5ne2jB", "original": null, "number": 4, "cdate": 1573813387565, "ddate": null, "tcdate": 1573813387565, "tmdate": 1573813387565, "tddate": null, "forum": "rygixkHKDH", "replyto": "S1xicX0uiS", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment", "content": {"title": "Reply to Authors", "comment": "The authors' addressed my remarks and I changed my recommendation from weak accept to accept."}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rygixkHKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1519/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1519/Authors|ICLR.cc/2020/Conference/Paper1519/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154812, "tmdate": 1576860543657, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment"}}}, {"id": "ByeYfqGlcH", "original": null, "number": 3, "cdate": 1571985936544, "ddate": null, "tcdate": 1571985936544, "tmdate": 1573813194772, "tddate": null, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "The authors consider two problems: Overcomplete dictionary learning (ODL)\nand convolution dictionary learning (CDL).\nDictionary learning learns a matrix factorization of the data\nY = A X\nwhere A is the dictionary and X is the (known to be sparse) code.\nY consists of n rows (sample size) and p columns (dimension).\nIn the overcomplete version A is n x m where m > n, i.e. the number of learned\nfeatures is larger than the sample size.\nThe CDL problem is a special case of the ODL problem where the dictionary\nmatrix is known to consist of convolution filters instead of being unstructured.\n\nThe authors show that under a given set of assumptions local nonconvex\noptimization can be used to find globally relevant solutions.\nThe basic assumptions are:\n(i) unit norm tight frame\n(ii) mu-incoherence\n\t(relates the angles of the columns of a, e.g.\\ if columns are orthogonal,\n\tthey are incoherent / have small mu)\n(ii) stochastic model of the code X that says entries are Gaussian and sparse\n\taccording to a Bernoulli random variable\nThe authors present the idea of maximizing the l^4 norm of A^T q in order to\nfind q as rows of A.\nApparently l^4 norm maximization leads to \"spikiness\" which is exactly\ndesirable under mu-incoherence.\n\nThe authors show (assuming p \\to \\infty) that the optimization nonconvex\nlandscape (constrained to the sphere) does not contain any stationary points\nwithout negative curvature.\nA saddle avoiding optimizer therefore converges to local minimizers from\nrandom initialization.\n\nThe authors also show that the analysis extends to CDL via a preconditioned\ninitializer.\nFinally, they go on to briefly show some experiments that further validate\nthe theory presented in the paper.\n\nOverall, the authors present a rigorous technical analysis using powerful\nmathematical tools for nonconvex optimization (which is relevant to many\nmachine learning problems).\n\nI am recommending to accept based on the high quality of the work.\nBut I am not confident as to the accessibility of the paper to the wide\naudience of ICLR as it is rather technical.\nPerhaps, the complete contribution would be better suited as a journal article.\n\nNotes:\nIt would have been useful to give some more intuition about what \"spikiness\"\nof A^T q is, why spikiness exists under mu-incoherence and why l^4 norm\nmaximization improves spikiness.\n\nI am not sure that the inclusion of the CDL problem is beneficial for a\nconverence paper and would rather have more space allocated to the intuition on\nwhy the method works for ODL.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576116228629, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Reviewers"], "noninvitees": [], "tcdate": 1570237736194, "tmdate": 1576116228641, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review"}}}, {"id": "S1xicX0uiS", "original": null, "number": 1, "cdate": 1573606290813, "ddate": null, "tcdate": 1573606290813, "tmdate": 1573676947738, "tddate": null, "forum": "rygixkHKDH", "replyto": "ByeYfqGlcH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment", "content": {"title": "Reply to Reviewer #3", "comment": "We thank the reviewer for the comprehensive summary of our results and invaluable suggestions. We have double checked our paper and revised accordingly.\n\nOn Page 4 of the revised draft, we have introduced a notion of the spikiness and used simulations in Figure 2 to provide a better explanation of why maximizing $\\ell^4$ promotes spikiness (we are not aware of any formal definition of spikiness in the literature). Intuitively, we characterize the spikiness of a vector by the ratio between the largest and the second largest entries in magnitude. In Figure 2, we added simulations to demonstrate that the $\\ell^4$-norm tends to be larger when the spikiness of the vector increases. If $\\mathbf q$ is close to one of the columns of $\\mathbf A$ (e.g., $\\mathbf q = \\mathbf a_1$), around Equation (2.5) we explained why the vector $\\mathbf A^\\top \\mathbf q$ should be spiky, given the small incoherence $\\mu$ of $\\mathbf A$ (i.e., $\\mu \\ll 1$). In theory, we rigorously proved that $\\mathbf q = \\mathbf a_1$ is close to one of the global optimizers due to the spikiness of $\\mathbf \\zeta =\\mathbf A^\\top \\mathbf q$.\n\nWe agree with the reviewer that the inclusion of CDL might overexpose the readers. Indeed, the authors had several discussions over this before the submission. That being said, we had included CDL because we believe the inclusion of CDL is very beneficial to the audience in the ICLR community. The CDL problem can be reviewed as a more structured ODL problem such that it can be analyzed in a similar fashion with a few new ingredients (e.g., initialization, preconditioning, new concentration ideas). Building on the intuition and theory for ODL, it could make our introduction of CDL more accessible to the audience and save us the effort for another repetitive work. Moreover, the CDL can be reviewed as a very simple one-layer convolutional neural network (CNN) (Papyan et al., 2017a; 2018). The theory developed here has the potential to serve as a building block for developing more interpretable deep CNN, which closely relates to the core interest of the ICLR community. If the reviewer thinks it would be beneficial to address this issue, we will release a much-extended version of this work on arxiv in the future and provide a link in the final version of this paper. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rygixkHKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1519/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1519/Authors|ICLR.cc/2020/Conference/Paper1519/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154812, "tmdate": 1576860543657, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment"}}}, {"id": "rJxa2N0djH", "original": null, "number": 2, "cdate": 1573606580555, "ddate": null, "tcdate": 1573606580555, "tmdate": 1573612078989, "tddate": null, "forum": "rygixkHKDH", "replyto": "BygCupVAYH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment", "content": {"title": "Reply to Reviewer #1", "comment": "We thank the reviewer for the appreciation of our work. In the revision, we have carefully corrected all the minor issues raised by the reviewers. In addition, we have carefully revised the main draft, correcting other typos and inaccurate statements. We plan to release the code in the very near future as well for reproducible purposes."}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rygixkHKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1519/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1519/Authors|ICLR.cc/2020/Conference/Paper1519/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154812, "tmdate": 1576860543657, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment"}}}, {"id": "SkeexDRusH", "original": null, "number": 3, "cdate": 1573607143542, "ddate": null, "tcdate": 1573607143542, "tmdate": 1573611734702, "tddate": null, "forum": "rygixkHKDH", "replyto": "rJe375X3KB", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment", "content": {"title": "Reply to Reviewer #2", "comment": "We thank the reviewer for the accurate interpretations of our results and appreciation of our work. In the revision, to make our paper more accessible to the readers, we have carefully revised the main draft, correcting typos and inaccurate statements.\n\nWe agree with the reviewer that the absolute constant for the overcompleteness of ODL is disturbing, and we also believe this benign geometry should hold for a larger overcompleteness than we proved here. The major bottleneck of showing this is due to our very loose analysis for negative curvature in Region $\\mathcal R_{\\mathrm N}$. The authors have tried many ways to improve this bound, but have not yet managed to succeed so far. \n\nOne idea might be to consider i.i.d. Gaussian dictionary instead of the deterministic incoherent dictionary, and use probabilistic analysis instead of the worst-case deterministic analysis. However, our preliminary analysis suggests that elementary concentration tools for Gaussian empirical processes are not sufficient to achieve this goal. More advanced probabilistic tools might be needed here.\n\nAnother idea that might be promising is to leverage more advanced tools such as the sum of squares (SoS) techniques. Previous results (e.g., Barak et al., 2015; Ma et al., 2016; Schramm & Steurer, 2017) used SoS as a computational tool for solving this type of problems, while the computational complexity is often quasi-polynomial and hence cannot handle problems of large-scale. In contrast, our idea here is to use SoS to verify the geometric structure of the optimizing landscape instead of computation, to have a uniform control of the negative curvature in $\\mathcal R_{\\mathrm N}$. If we succeeded, this might lead to a tighter bound on the overcompleteness. Moreover, this can also serve as a more general method for verifying the benign optimization landscapes of other nonconvex problems. We will include a discussion section for elaborating these ideas in the future if the reviewer thinks it would be beneficial for the audience.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rygixkHKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1519/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1519/Authors|ICLR.cc/2020/Conference/Paper1519/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504154812, "tmdate": 1576860543657, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Authors", "ICLR.cc/2020/Conference/Paper1519/Reviewers", "ICLR.cc/2020/Conference/Paper1519/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Comment"}}}, {"id": "rJe375X3KB", "original": null, "number": 1, "cdate": 1571727908326, "ddate": null, "tcdate": 1571727908326, "tmdate": 1572972458057, "tddate": null, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "invitation": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "[Summary]\nThis paper studies the problem of non-convex optimization for Dictionary Learning (DL) in the situation when the underlying dictionary is over-complete (more basis vectors m than the dimension n). The paper proves that the L4 maximization formulation has a nice global landscape and can be efficiently minimized by (Riemannian) gradient descent, when the over-complete ratio m/n is less than an absolute constant. A similar result is proved for convolutional dictionary learning.\n\n[Pros]\nThe theoretical results in this paper provides a solid improvement over the prior understandings on overcomplete DL, a setting that is practically important yet theoretically more challenging than standard orthogonal/complete DL. \n\nSpecifically, the prior work of (Ge & Ma 2017) shows only a nice local optimization landscape when m > n^{1+\\eps} and hypothesizes that the global landscape is bad in the same setting (there exists bad local minima out of a certain sub-level set). In comparison, this work proves that at least for m/n <= 3 (roughly), the landscape is globally benign (has the strict saddle property), therefore providing a new understanding that the benign landscape is still preserved from \u201cthe other side\u201d where m/n grows mildly above 1. The analysis contains novel technicalities and can be of general interest for understanding the landscape of non-convex problems.\n\nThe paper also provides experimental evidence that gradient descent converges globally up until m = O(n^2), a broader regime than suggested by the theory (m <= 3n). (Though when m >= n^{1+\\eps}, the reason of global convergence from random init may be far from the present theory, in that there can be potentially exponentially many bad local min yet gradient descent won\u2019t get trapped.)\n\n[Cons]\nIt is still a bit disturbing to see that m/n needs to be bounded by a fixed absolute constant, rather than *any* constant, for the theory to work. From the proofs it seems like this constant (3) may have the potential to be improved, but it is not quite easy to completely get rid of it? \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1519/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qingqu1006@gmail.com", "ysz@berkeley.edu", "xli@ee.cuhk.edu.hk", "yqz.zhang@gmail.com", "zzhu29@jhu.edu"], "title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": ["Qing Qu", "Yuexiang Zhai", "Xiao Li", "Yuqian Zhang", "Zhihui Zhu"], "pdf": "/pdf/319b5a598511c90365a7055bb855148c63303f98.pdf", "abstract": "Learning overcomplete representations finds many applications in machine learning and data analytics. In the past decade, despite the empirical success of heuristic methods, theoretical understandings and explanations of these algorithms are still far from satisfactory. In this work, we provide new theoretical insights for several important representation learning problems: learning (i) sparsely used overcomplete dictionaries and (ii) convolutional dictionaries. We formulate these problems as $\\ell^4$-norm optimization problems over the sphere and study the geometric properties of their nonconvex optimization landscapes. For both problems, we show the nonconvex objective has benign (global) geometric structures, which enable the development of efficient optimization methods finding the target solutions. Finally, our theoretical results are justified by numerical simulations.\n", "keywords": ["dictionary learning", "sparse representations", "nonconvex optimization"], "paperhash": "qu|geometric_analysis_of_nonconvex_optimization_landscapes_for_overcomplete_learning", "_bibtex": "@inproceedings{\nQu2020Geometric,\ntitle={Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning},\nauthor={Qing Qu and Yuexiang Zhai and Xiao Li and Yuqian Zhang and Zhihui Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rygixkHKDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2e08043b4b80a539d7da1fa8d8a86c3ed534c301.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygixkHKDH", "replyto": "rygixkHKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1519/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576116228629, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1519/Reviewers"], "noninvitees": [], "tcdate": 1570237736194, "tmdate": 1576116228641, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1519/-/Official_Review"}}}], "count": 10}