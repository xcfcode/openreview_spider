{"notes": [{"id": "73WfweNDpiW", "original": null, "number": 32, "cdate": 1599483778385, "ddate": null, "tcdate": 1599483778385, "tmdate": 1599483778385, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Reading Head Start Review: Teach And Improve Your Child\u2019s Reading Skills", "comment": "Reading Head Start program is a learning program aimed at teaching and improving the reading skills of your child. The teaching techniques involved in this program are scientifically proven and she has full confidence in the ability of the program that she offers a 100%, 365-day money-back guarantee.Reading Head Start Review says that it tries to make the content as fun and educational as possible because the intent is not only to help your child read but also to get them interested in books.\nVisit website https://www.deyproject.org/reading-head-start-review/"}, "signatures": ["~Deyproject_blog1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Deyproject_blog1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "ycsM6CRF4r", "original": null, "number": 31, "cdate": 1598697356640, "ddate": null, "tcdate": 1598697356640, "tmdate": 1598697356640, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Man Greens Review- Does This Powder Help To Boost Man\u2019s Testosterone Level?", "comment": "According to Man Greens Review, Man greens powder is clinically proved supplement that is a mixture of Superfoods and ingredients best known for potency and it is clinically tested as effective. The ingredients present in Man Greens supplement were used 6000 years ago by ancient Ayurveda, and are used in the current world that will help in boosting a man\u2019s testosterone level without provoking other hormonal balance. Visit website https://systemagility.com/man-greens-review/\n\n"}, "signatures": ["~liam_alexander1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~liam_alexander1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "C2lrvUsXLpR", "original": null, "number": 30, "cdate": 1598532462915, "ddate": null, "tcdate": 1598532462915, "tmdate": 1598532507679, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Meticore Review \u2013 Is It A Genuine Weight Loss Supplement?", "comment": "According to Meticore Review, Meticore is a weight loss supplement and is famous for its uniqueness. The main reason behind this is, Meticore offers you six best plants and nutrients that are perfect for weight loss. One of the fuels for weight loss is low core temperature. When the body maintains a low core temperature, it is straightforward to supercharge metabolism. This secret can be applied, and it gives the best results both in men and women. Visit website https://rubinstein-taybi.org/meticore-review/\n"}, "signatures": ["~Eugene_Blaze1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Eugene_Blaze1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "LkFsTmAwpRZm", "original": null, "number": 29, "cdate": 1598111469790, "ddate": null, "tcdate": 1598111469790, "tmdate": 1598111469790, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Does NutraVesta Proven Plus Immune Boost Formula Work?", "comment": "Only a stronger immune system can help keep you fit, keeping you from getting sick again and again. If you think your immunity needs a boost, Nutravesta Proven plus is a very affordable formula that will work on your immune system, making it potent enough to fight disease and save you from paying medical bills. costly every month. With this product at your fingertips, you can happily enjoy foods that otherwise seemed to make you sick! See more https://www.phdsc.org/NutraVesta-Proven-Plus-Review"}, "signatures": ["~Henna_John1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Henna_John1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "Sylh3Mo6EB", "original": null, "number": 15, "cdate": 1566581427532, "ddate": null, "tcdate": 1566581427532, "tmdate": 1566581427532, "tddate": null, "forum": "HJWLfGWRb", "replyto": "Skxfz3UaNS", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "Original implementation", "comment": "Thank you for the implementation and enlightening the challenges. We are looking into it. \n\nWe open sourced our code on January here: \nhttps://github.com/google-research/google-research/commits/master/capsule_em \nwhich provides the checkpoints  for 1.3% test error too. "}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "Skxfz3UaNS", "original": null, "number": 25, "cdate": 1566563337521, "ddate": null, "tcdate": 1566563337521, "tmdate": 1566563337521, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Open Source Implementation", "comment": "Here is our implementation where we get a closer to the accuracy reported in the paper. We get 95.4% on smallNORB, whereas the paper reports an accuracy of 97.8% (configuration: A=64, B=8, C=D=16).\n\nhttps://github.com/IBM/matrix-capsules-with-em-routing"}, "signatures": ["~Ashley_Gritzman1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Ashley_Gritzman1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "r1lQjCAChm", "original": null, "number": 24, "cdate": 1541496474649, "ddate": null, "tcdate": 1541496474649, "tmdate": 1541496474649, "tddate": null, "forum": "HJWLfGWRb", "replyto": "rJgxonoNnm", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Could you elaborate in the initialization of the poses of the primary capsules", "comment": "My apologies if I ask too many details but please understand that I only have one GPU at my disposal through my work (i.e. one run costs 8 days), and can only spend spare time (i.e. weekends/evenings) on this. So every parameter I have to figure out experimentally will cost me an incredible amount of scarce time. \n\nInitialization of the poses of the primary capsules still does not seem trivial to me, because stabilizing input/output variance is arguably not the best approach:\n\nFor the chains of 4x4 matrices formed by em routing to not have exploding/vanishing output/gradients it seems like the determinant and eigenvectors matter more than the variance, i.e. not inflating or deflating poses. This would also explain your I + .03 * noise approach. Therefore I expect you might have used a different weight initialization for the primary caps poses than xavier. If you could be a bit more specific on how you determined those weights as well I would appreciate it a lot. I can assume the activations of the primary capsules will be just fine using xavier initialization right?\n\nFinally if you could share any of the standard deviations you used in your initial approach, I would appreciate it very much as well.\n"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "HyeWtbEunQ", "original": null, "number": 23, "cdate": 1541058937141, "ddate": null, "tcdate": 1541058937141, "tmdate": 1541058937141, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Where to apply regularization?", "comment": "Where do you apply the regularization that you mentioned?\n- initial 5x5 convolution (ReLU Conv1)\n- 1x1 linear transformation (PrimaryCaps)\n- pose parameter convolution weights (ConvCaps1, ConvCaps2, ClassCaps)\n- beta_v and beta_a"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "Hyg2bBrLnm", "original": null, "number": 14, "cdate": 1540932867779, "ddate": null, "tcdate": 1540932867779, "tmdate": 1540932867779, "tddate": null, "forum": "HJWLfGWRb", "replyto": "S1eo2P1I3Q", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "BP through EM", "comment": "The gradient flows through EM algorithm. We do not use stop gradient. A routing of 3 is like a 3 layer network where the weights of layers are shared."}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "S1eo2P1I3Q", "original": null, "number": 22, "cdate": 1540908978533, "ddate": null, "tcdate": 1540908978533, "tmdate": 1540908978533, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Backpropagation through EM", "comment": "Did you use tf.stop_gradient so that the gradient does not flow through each iteration of the EM routing, only the last step? Or did you allow the gradient to flow through all iterations of EM routing? "}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "SkeivUy83m", "original": null, "number": 21, "cdate": 1540908643212, "ddate": null, "tcdate": 1540908643212, "tmdate": 1540908643212, "tddate": null, "forum": "HJWLfGWRb", "replyto": "rJeQnSsE3X", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Where to apply regularization?", "comment": "Thanks, that's really helpful.\n\nWhere do you apply the regularization that you mentioned?\n- initial 5x5 convolution (ReLU Conv1)\n- 1x1 linear transformation (PrimaryCaps)\n- pose parameter convolution weights (ConvCaps1, ConvCaps2, ClassCaps)\n- beta_v and beta_a"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "rJgxonoNnm", "original": null, "number": 13, "cdate": 1540828311647, "ddate": null, "tcdate": 1540828311647, "tmdate": 1540828488770, "tddate": null, "forum": "HJWLfGWRb", "replyto": "rkgHuO67hQ", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "Optimizer & initializer", "comment": "We use Adam optimizer with default Tensorflow parameters.\n\nWe did not have any special ordering of training batches and we random shuffle. In terms of TF batch:\ncapacity=2000 + 3 * batch_size,\n# Ensures a minimum amount of shuffling of examples.\nmin_after_dequeue=2000.\n\nPlease not that for smallnorb viewpoint generalization test to make sure that the model only sees a fraction of certain directions and the generalization test is strict, we calibrated the semantic of azimuth '0' for every class so that the object at azimuth '0' roughly heads to the right. Therefore, in training the model never sees an object which heads to the left (from any class) while in test it is tested on objects which head to the left as well.\n\nThe gradient indeed is tricky. Almost all the math is done in log-scale to avoid numerical issues. We used truncated_normal_initializer and set the std so that at the start of training half of the capsules in each layer are active and half inactive (for the Primary Capsule layer where the activation is not computed through routing we use different std for activation convolution weights & for pose parameter convolution weights).\n\nRecently we are using a new initialization method: every 4x4 is initialized with I + noise of 0.03: (1 on the diag, random uniform noise in the range +/- 0.03 everywhere else). This new method is more scale able and easier to train. "}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "HJeJrLo4hQ", "original": null, "number": 12, "cdate": 1540826679085, "ddate": null, "tcdate": 1540826679085, "tmdate": 1540826679085, "tddate": null, "forum": "HJWLfGWRb", "replyto": "SkxQs3omhm", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "Hardware", "comment": "We used 8 sync gpus (batch of 64, 8 on each gpu) to train for ~ a day on small norb, ~10hr on MNIST and ~ 2 day on Cifar10."}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "rJeQnSsE3X", "original": null, "number": 11, "cdate": 1540826539227, "ddate": null, "tcdate": 1540826539227, "tmdate": 1540826539227, "tddate": null, "forum": "HJWLfGWRb", "replyto": "ryxTPFDe2X", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "regularizer & learning rate", "comment": "We use a weight decay loss with a small factor of .0000002 rather than the reconstruction loss.\nWe use an exponential decay with learning rate: 3e-3, decay_steps: 20000, decay rate: 0.96."}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "rkgHuO67hQ", "original": null, "number": 20, "cdate": 1540769900777, "ddate": null, "tcdate": 1540769900777, "tmdate": 1540769900777, "tddate": null, "forum": "HJWLfGWRb", "replyto": "BJg9lmDQnQ", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "The correct input count of xavier initialization?", "comment": "If you were to (or indeed did) use xavier initialization to prevent output and gradient issues with your sigmoid curves, did/would you use for the input count\n1.  4, perceiving each weight matrix as a small dense 4 neuron subnetwork (conveniently creating weight vectors of with a mean length close to 1) or \n2. the kernel size for the input\n3. the kernel size * 4 thus combining both perspectives\n\nWhat is/would be your output neuron count?\n\n"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "SkxQs3omhm", "original": null, "number": 19, "cdate": 1540762779377, "ddate": null, "tcdate": 1540762779377, "tmdate": 1540762779377, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Hardware/execution time", "comment": "What hardware did you use to train the network, and how long did it take until training was completed?"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "BJg9lmDQnQ", "original": null, "number": 18, "cdate": 1540743922287, "ddate": null, "tcdate": 1540743922287, "tmdate": 1540743922287, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "More parameters", "comment": "And to add to the question below;\n\n* What optimizer did you use (and what parameters)\n* How did you initialize your weights and did you take any measures to deal with gradient issues for your sigmoid curves?\n* Did you do any special ordering of your training batches?\n* Do you fill your batches in any special way?\n"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "ryxTPFDe2X", "original": null, "number": 17, "cdate": 1540548965267, "ddate": null, "tcdate": 1540548965267, "tmdate": 1540548965267, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Regularization and learning rate?", "comment": "Did you use any regularization in this paper? Perhaps a decoder network as in Sabour et al. (2017), or weight decay of some sort?\n\nAlso, what learning rate and schedule did you use?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "BkelcSxC47", "original": null, "number": 10, "cdate": 1533048200450, "ddate": null, "tcdate": 1533048200450, "tmdate": 1533048200450, "tddate": null, "forum": "HJWLfGWRb", "replyto": "Bkl9bvlpmm", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "Lambda and margin", "comment": "the formula we used for lambda is:\nlambda = final_lambda * (1 - tf.pow(0.95, tf.cast(i + 1, tf.float32)))\nwhere 'i' is the routing iteration (range is 0-2). Final_lambda is set to 0.01.\n\nThe margin that we set is: \nmargin = 0.2 + .79 * tf.sigmoid(tf.minimum(10.0, step / 50000.0 - 4))\nwhere step is the training step. We trained with batch size of 64.\n"}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "SkenLVlAEm", "original": null, "number": 9, "cdate": 1533047892333, "ddate": null, "tcdate": 1533047892333, "tmdate": 1533047892333, "tddate": null, "forum": "HJWLfGWRb", "replyto": "BJgX7Iy04m", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "content": {"title": "convolution capsule layer", "comment": "The first option is like having 1x1 convolution layers. The second option is what happens if you have kernel size larger than one. Since we have 3x3 convolution capsule layers (32 capsule types each) it means that 9x32 capsules receive the vote of a single capsule in layer bellow. Therefore these 9x32 capsules are competing for its vote (normalize the routing factors over the feedback of these 3x3x32 capsules).  "}, "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"id": "BJgX7Iy04m", "original": null, "number": 16, "cdate": 1533044251481, "ddate": null, "tcdate": 1533044251481, "tmdate": 1533047100355, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "Some clarification on the convolution topology?", "comment": "The paper states that capsules are connected through convolutions. However, these can be interpreted in two ways:\n\n1. An image (of features or color channels) is broken up into patches that are entirely isolated from each other. For each kernel for each position in the output an input capsule is assigned to an output capsule separate from assignments in other kernels. I.e. output capsules at different positions do not compete for input capsules.\n\n2. However, another interpretation is  the e-step takes every output capsule into account in whose kernel the input capsule appears. I.e. output capsules at different positions do compete for input capsules.\n\nWhich interpretation will reproduce your results?"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"id": "Bkl9bvlpmm", "original": null, "number": 15, "cdate": 1531934466179, "ddate": null, "tcdate": 1531934466179, "tmdate": 1531934501025, "tddate": null, "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "content": {"title": "How are the lambda and margin parameters changed during training?", "comment": "There are still a few gaps in the paper concerning the used lambda parameter during em routing and the margin parameter m for spread loss;\n\nLambda:\n\"the inverse temperature \u03bb increases at each iteration with a fixed schedule\"\nWhat is meant by an iteration? The context implies that you mean lambda is assigned an initial value every time em routing is executed, and that lambda is then increased each em routing iteration, but a different interpretation is that it increases for each training iteration, i.e. as a function of the number of examples fed to the network? \nWhat is the initial value, and how is the value changed during training, i.e. what is the \"fixed schedule\" the paper talks about? Does the parameter increase exponentially or linearly? \n\nMargin parameter m:\n\"By starting with a small margin of 0.2 and linearly increasing it during training to 0.9, we avoid dead capsules in the earlier layers.\"\n\nTo reproduce this linear increase it is necessary to know how over how many epochs this linear increase takes place. How many epochs of training did you have to do?\n"}, "signatures": ["~Guido_Sales_Calvano1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guido_Sales_Calvano1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1520437683693, "tcdate": 1509134920738, "number": 789, "cdate": 1518730165096, "id": "HJWLfGWRb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "HJWLfGWRb", "original": "BygUfzbAW", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "nonreaders": [], "details": {"replyCount": 46, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260094993, "tcdate": 1517249470649, "number": 236, "cdate": 1517249470629, "id": "Skv6Q1TBM", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "Authors present a new multi-layered capsule network architecture, implemented an EM routing procedure, and introduced \"Coordinate Addition\".  Capsule architectures are gaining interest because of their ability to achieve equivariance of parts, and employ a new form of pooling called \"routing\" (as opposed to max pooling) which groups parts that make similar predictions of the whole to which they belong, rather than relying on spatial co-locality. New state-of-art performances are being achieved on focused datasets, for which the authors have continued the trend.\n\nPros:\n- New significant improvement to state-of-art performance is obtained on smallNORB, both in comparison to CNN structure as well as the most recent previous implementation of capsule network.\n\nCons:\n- Some concern arose regarding the writing of the paper and the ability to understand the material, which authors have made an effort to address.\n\nGiven the general consensus of the reviewers that this work should be accepted, the general applicability of the technology to multiple domains, and the potential impact that improvements to capsule networks may have on an early field, area chair recommends this work be accepted as a poster presentation. ", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "tmdate": 1515695921422, "tcdate": 1511577822890, "number": 2, "cdate": 1511577822890, "id": "HyvJKULxM", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "ByAqs7VJf", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "Re: The objective function", "comment": "The objective function in details is:\n\\sum_c a'_c (-\\beta_a) + a'_c ln(a'_c) + (1-a'_c)ln(1-a'_c)+\\sum_h cost_{ch} + \\sum_i a_i *  r_{ic} * ln(r_{ic})\n\na'_c is the activation for capsule c in layer L+1 and a_i is the activation probability for capsule i in layer L. The rest of the notations follow paper. \n\nPlots showing the decay of objective function and the absolute difference between two routing iterations in the above objective function can be found at:\nhttps://imgur.com/a/eeD2X"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642511432, "tcdate": 1511794262643, "number": 1, "cdate": 1511794262643, "id": "Hykw8iKxG", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "A novel approach for capsule networks", "rating": "7: Good paper, accept", "review": "The paper proposes a novel architecture for capsule networks. Each capsule has a logistic unit representing the presence of an entity plus a 4x4 pose matrix representing the entity/viewer relationship. This new representation comes with a novel iterative routing scheme, based on the EM algorithm.\nEvaluated on the SmallNORB dataset, the approach proves to be more accurate than previous work (beating also the recently proposed \"routing-by-agreement\" approach for capsule networks by Sabour et al.). It also generalizes well to new, unseen viewpoints and proves to be more robust to adversarial examples than traditional CNNs.\n\nCapsule networks have recently gained attention from the community. The paper addresses important shortcomings exhibited by previous work (Sabour et al.), introducing a series of valuable technical novelties.\nThere are, however, some weaknesses. The proposed routing scheme is quite complex (involving an EM-based step at each layer); it's not fully clear how efficiently it can be performed / how scalable it is. Evaluation is performed on a small dataset for shape recognition; as noted in Sec. 6, the approach will need to be tested on larger, more challenging datasets. Clarity could be improved in some parts of the paper (e.g.: Sec. 1.1 may not be fully clear if the reader is not already familiar with (Sabour et al., 2017); the authors could give a better intuition about what is kept and what is discarded, and why, from that approach. Sec. 2: the sentence \"this is incorrect because the transformation matrix...\" could be elaborated more. V_{ih} in eq. 1 is defined only a few lines below; perhaps, defining the variables before the equations could improve clarity. Sec. 2.1 could be accompanied by mathematical formulation).\nAll in all, the paper brings an original contribution and will encourage further research / discussion on an important research question (how to effectively leverage knowledge about the part-whole relationships).\n\nOther notes:\n- There are a few typos (e.g. Sec. 1.2 \"(Jaderberg et al. (2015)\",  Sec. 2 \"the the transformation\", Sec. 4 \"cetral crop\" etc.).\n- The authors could discuss in more detail why the approach does not show significant improvement on NORB with respect to the state of the art.\n- The authors could provide more insights about why capsule gradients are smaller than CNN ones.\n- It would be interesting to discuss how the network could potentially be adapted, in the future, to: 1. be more efficient 2. take into account other changes produced by viewpoint changes (pixel intensities, as noted in Sec. 1).\n- In Sec, 4, the authors could provide more details about the network training.\n- In Procedure 1, for indexing tensors and matrices it might be better to use a comma to separate dimensions (e.g. V_{:,c,:} instead of V_{:c:}).", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642511349, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer1", "ICLR.cc/2018/Conference/Paper789/AnonReviewer3", "ICLR.cc/2018/Conference/Paper789/AnonReviewer2"], "reply": {"forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642511349}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642511397, "tcdate": 1511795879311, "number": 2, "cdate": 1511795879311, "id": "ry1nhoKgM", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Idea is interesting; need more empirical validation than smallNORB", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes a new kind of capsules for CNN. The capsule contains a 4x4 pose matrix motivated by 3D geometric transformations describing the relationship between the viewer and the object (parts). An EM-type of algorithm is used to compute the routing.\n\nThe authors use the smallNORB dataset as an example. Since the scenes are simulated from different viewer angles, the pose matrix quite fits the motivation. It would be more beneficial to know if this kind of capsules is limited to the motivation or is general. For example, the authors may consider reporting the results of the affNIST dataset where the digits undergo 2D affine transformations (in which case perhaps 3x3 pose matrices are enough?).\n\nMinor: The arguments in line 5 of the procedure RM Routing(a,V) do not match those in line 1 of the procedure E-Step.\n\nSection 2.1 (objective of EM) is unclear. The authors may want to explicitly write down the free energy function.\n\nThe section about robustness against adversarial attacks is interesting.\n\nOverall the idea appears to be useful but needs more empirical validation (affNIST, ImageNet, etc).\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642511349, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer1", "ICLR.cc/2018/Conference/Paper789/AnonReviewer3", "ICLR.cc/2018/Conference/Paper789/AnonReviewer2"], "reply": {"forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642511349}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642511364, "tcdate": 1512093897238, "number": 3, "cdate": 1512093897238, "id": "ByZRu4ClG", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "An extremely opaque paper with a potentially interesting idea and good results", "rating": "4: Ok but not good enough - rejection", "review": "The paper describes another instantiation of \"capsules\" which attempt to learn part-whole relationships and the geometric pose transformations between them.  Results are presented on the smallNORB test set obtaining impressive performance.\n\nAlthough I like very much this overall approach, this particular paper is so opaquely written that it is difficult to understand exactly what was done and how the network works.  It sounds like the main innovation here is using a 4x4 matrix for the pose parameters, and an iterative EM algorithm to find the correspondence between capsules (routing by agreement).  But what exactly the pose matrix represents, and how they get transformed from one layer to the next, is left almost entirely to the reader's imagination.  In addition, how EM factors in, what the probabilities P_ih represent, etc. is not clear.  I think the authors could do a much better job explaining this model, the rationale behind it, and how it works.\n\nPerhaps the most interesting and compelling result is Figure 2, which shows how ambiguity in object class assignment is resolved with each iteration.  This is very intriguing, but it would be great to understand what is going on and how this is happening.\n\nAlthough the results are impressive, if one can't understand how this was achieved it is hard to know what to make of it.\n\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642511349, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/AnonReviewer1", "ICLR.cc/2018/Conference/Paper789/AnonReviewer3", "ICLR.cc/2018/Conference/Paper789/AnonReviewer2"], "reply": {"forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642511349}}}, {"tddate": null, "ddate": null, "tmdate": 1515446631586, "tcdate": 1515446631586, "number": 8, "cdate": 1515446631586, "id": "HyguZD-Vf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "ByZRu4ClG", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "Improvements on the clarity of the paper", "comment": "Thank you for your comments. upon reflection we agree that the paper was confusing and we have taken several steps to reduce the opacity of our work to the reader. To that end we have done the following: \n- We have added section 2 which gives a general and intuitive explanation of the mechanism of capsule networks, paying close attention to how pose matrices get transformed from one layer to the next.\n- Having identified the EM objective as another source of confusion, we added an extended appendix in which we provide a gentle and approachable explanation for the free energy view of EM and how our routing algorithm builds upon it. \n- We have also added a paragraph to further explain figure 2 in the experiments section. \n- Finally we have made several changes to the language of the paper, focusing in particular on the notation.  \nWe believe that the comprehensibility of the paper has thus improved and appreciate your criticism. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1515446533929, "tcdate": 1515446533929, "number": 7, "cdate": 1515446533929, "id": "SJAWbD-4G", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "Hykw8iKxG", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "re: A novel approach for capsule networks", "comment": "Thank you for your detailed reading of the paper and suggestions!    \nAs per your comments on the EM routing, we agree that it was not presented as best it could have been, and have added an appendix to present a gentle and thorough introduction to the free energy view of EM and the objective function which our routing operation minimizes. In response to the question about efficiency, we would like to draw your attention to the total number of arithmetic operations required for the routing procedure - each iteration of routing represents fewer arithmetic operations than a single layer feed forward pass, but due to architectural optimization decisions in tensorflow, our current capsule implementation is not as fast as it could be. \n\nWe agree that larger scale testing would ideal, but due to the aforementioned efficiency limitations were not able to include it in this paper. \n\nIn regards to your other comments we have done the following: \n- To increase the clarity of the paper,  we have made several changes to the language used, and improved the mathematical notation.\n- We have added section 2 which provides an intuitive explanation of capsules and makes clear when the routing occurs. We feel that improves the readers' ability to engage with the rest of the presented content. We also defined the variables and notation used in the rest of the paper more explicitly.  \n- We have expanded on the sentence \"this is incorrect because the transformation matrix...\" you mentioned which is now in the appendix. \n- We have also made several changes to the nation and language throughout the paper to make it more comprehensible. \nthank you for your feedback, and hope that we have addressed your comments to your satisfaction. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1515442743011, "tcdate": 1515442743011, "number": 6, "cdate": 1515442743011, "id": "HJkSzIZEf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "ry1nhoKgM", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "affNIST generalization and EM objective ", "comment": "thank you for the feedback! To address your comments we have done the following: \n- To clarify the EM objective we have added an extended and thorough appendix which presents a gentle and intuitive explanation of the free energy view of EM, and explicit free energy function, and how our routing algorithm makes use of it.\n- We believe that the benefit of capsules is not limited to smallNORB and will generalize. As suggested, we replicated the affNIST generalization experiment reported in the previous Capsule paper (Sabour et al. 2017). We found that our EM capsule model (the exact architecture used for smallNORB and MNIST in the paper), when trained to 0.8% test error on expanded MNIST (40x40 pixel MNIST images, created by padding and shifting MNIST), achieved 6.9% test error on affNIST. We trained a baseline CNN (with AlexNet architecture, without pooling) to 0.8% test error and it was only able to achieve 14.1% test error on affNIST. Our capsule model was able to half the test error of a CNN when trained on MNIST and tested on affNIST.  Due to time and space constraints these results are not reported in the paper as it is now. \n- finally we address the minor issue raised in line 5 of the routing procedure. \nwe hope this has addressed your concerns, and thank you for your suggestions. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1514011921787, "tcdate": 1514011921787, "number": 13, "cdate": 1514011921787, "id": "rk5MadsMf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Hang_Yu2"], "readers": ["everyone"], "writers": ["~Hang_Yu2"], "content": {"title": "Matrix Capsule With EM Routing Reproduce Report", "comment": "Author: Hang Yu | Suofei Zhang\n\nEmail: hangyu5 at illinois.edu | zhangsuofei at njupt.edu.cn\n\n## Reproduce Method\n\n#### Hyperparameters\nsmallNORB dataset:\n* Samples per epoch: 46800\n* Sample dimensions: 96x96x1\n* Batch size: 50\n* Preprocessing:\n    * training:\n        1. add random brightness with max delta equals 32 / 255.\n        2. add random contrast with lower 0.5 and upper 1.5.\n        3. resize into HxW 48x48 with bilinear method.\n        4. crop into random HxW 32x32 piece.\n        5. apply batch norm to have zero mean and unit variance.\n        6. squash the image from 4 so that each entry has value from 0 to 1. This image is to be compared with the reconstructed image.\n    * testing:\n        1. resize into HxW 48x48 with bilinear method.\n        2. crop the center HxW 32x32 piece.\n        3. apply batch norm with moving mean and moving variance collected from training data set.\n\n#### Method\n\n1. The so called dynamic routing is in analog to the fully-connected layer in CNN. The so called ConvCaps structure extends dynamic routing into convolutional filter structure. The ConvCaps are implemented similarly as the dynamic routing for the whole feature map. The only difference is to tile the feature map into kernel-wise data and treat different kernels as batches. Then EM routing can be implemented within each batch in the same way as dynamic routing.\n\n2. Different initialization strategies are used for convolutional filters. Linear weights are initialized with Xavier method. Biases are initialized with truncated normal distribution. This configuration provide higher numerical stability of input to EM algorithm.\n\n3. The output of ConvCaps2 layer is processed by em routing with kernel size of 1*1. Then a global average pooling is deployed here to results final Class Capsules. Coordinate Addition is also injected during this stage.\n\n4. Equation 2 in E-step of Procedure 1 from original paper is replaced by products of probabilities directly. All the probabilities are normalized into [0, 10] for higher numerical stability in products. Due to the division in Equation 3, this operation will not impact the final result. Exponent and logarithm are also used here for the same purpose.\n\n5. A common l2 regularization of network parameters is considered in the loss function. Beside this, reconstruction loss and spread loss are implemented as the description in the original paper.\n\n6. Learning rate: starts from 1e-3, then decays exponentially in a rate of 0.8 for every 46800/50 steps, and ends in 1e-5 (applied for all trainings).\n\n7. We use Tensorflow 1.4 API and python programming language.\n\n## Reproduce Result\n\n#### Overview\n\nExperiments on is done by Suofei Zhang. His hardware is:\n\n* cpu\uff1aIntel(R) Xeon(R) CPU E5-2680 v4@ 2.40GHz\uff0c\n* gpu\uff1aTesla P40\n\n\n**On test accuracy**:\n\nsmallNORB dataset test accuracy (our result/proposed result):\n\n* CNN baseline (4.2M): 88.7%(best)/94.8%\n* Matrix Cap with EM routing (310K, 2 iteration): 91.8%(best)/98.6%\n\nThere are two comments to make:\n\n1. Even though the best of Matrix Cap is over by 3% to the best of CNN baseline, the test curve suggest Matrix Cap fluctuates between roughly 80% to 90% test dataset.\n2. We are curious to know the learning curve and test curve that can be generated by the author.\n\n**Training speed**:\n\n1. CNN baseline costs 6m to train 50 epochs on smallNORB dataset. Each batch costs about 0.006s.\n2. Matrix Cap costs 15h55m36s to train. Each batch costs about 1.2s.\n\n**Recon image**:\n\nWill come soon.\n\n**routing histogram**:\n\nWe have difficulty in understanding how the histogram is calculated.\n\n**AD attack**:\n\nWe haven't planned to run AD attack yet.\n\n### Notes\n\n> **Status:**\n> According to github commit history, this reproduce project had its init commit on Nov.19th. We started writing this report on Dec.19th. Mainly, it is cost by undedicated code review so that we have to fix bug and run it again, otherwise the project should be able to finish in a week.\n\n> **Current Results on smallNORB:**\n- Configuration: A=32, B=8, C=16, D=16, batch_size=50, iteration number of EM routing: 2, with Coordinate Addition, spread loss, batch normalization\n- Training loss. Variation of loss is suppressed by batch normalization. However, there still exists a gap between our best results and the reported results in the original paper.\n\n- Test accuracy(current best result is 91.8%)\n\n> **Current Results on MNIST:**\n- Configuration: A=32, B=8, C=16, D=16, batch_size=50, iteration number of EM routing: 2, with Coordinate Addition, spread loss, batch normalization, reconstruction loss.\n\n- Test accuracy(current best result is 99.3%, only 10% samples are used in test)\n\n##Reference\n\n[1] [MATRIX CAPSULES WITH EM ROUTING (paper)](https://openreview.net/pdf?id=HJWLfGWRb)\n\n[2] [Matrix-Capsules-EM-Tensorflow (our github repo: code and comments)](https://github.com/www0wwwjs1/Matrix-Capsules-EM-Tensorflow/)\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1512981201568, "tcdate": 1512981201568, "number": 12, "cdate": 1512981201568, "id": "rJFRG6oWG", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Arent_Warren_de_Jong1"], "readers": ["everyone"], "writers": ["~Arent_Warren_de_Jong1"], "content": {"title": "Spatial downsampling from ConvCaps2 (L_final-1) to Class Capsules (L_final)", "comment": "Thanks for all your research effort. It is great to read on this new paradigm and to see it actually working.\n\nOne part that is missing in my opinion, or I am very ignorantly glossing over it, is the downsampling from ConvCaps2 (L_final-1) to Class Capsules (L_final).\n\nAs mentioned, weights are shared among same entity capsules, so this would result in a one dimensional convolution (because K=1, stride=1), i.e. keeping the two spatial dimensions of the ConvCaps2 layer.\nWhereas the other layer transitions indeed keep their spatial information and result in multiple, same-entity capsules spread over the 2 input image dimensions, the final layer only has one capsule for each class for the entire image.\nIMHO this therefore requires a downsampling of the ConvCaps2 votes, a la maxpool, averagepool, or some extra dimension added to the EM routing algorithm."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1512750205963, "tcdate": 1512750205963, "number": 5, "cdate": 1512750205963, "id": "rJUY2VdbM", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "ryTPZJd-f", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "re: beta_v and beta_a", "comment": "beta_v and beta_a are per capsule type. Therefore, they are vectors for both convolutional capsules and final capsules. For example in terms of the notation in fig.1 beta_a and beta_v for convCaps1 are C dimensional vectors.\n\nThanks! We will revise the paper in regard to these points."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1512727687480, "tcdate": 1512726885060, "number": 11, "cdate": 1512726885060, "id": "ryTPZJd-f", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "beta_v and beta_a", "comment": "The dimensionality of the two trained beta parameters is not very clear to me from the paper. Are they shared across all capsules in the same layer (making them scalars) or does each capsule type have their own beta (meaning they are vectors).  I have had a look at the current implementation attempts of the model on GitHub and there the interpretations vary widely as well. Could you please clarify this point?\n\nMinor notes on the algorithm (Procedure 1):\n- \"V_ich  is an H dimensional vote...\": Did you mean V_ic?\n- M-Step line 5: Missing quantifier. Like mu and sigma, cost_h is computed for all h"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1512137867354, "tcdate": 1512137867354, "number": 10, "cdate": 1512137867354, "id": "SJQqV1JWz", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Spread loss is squared WW-Hinge-Loss", "comment": "The spread-loss in 3.1 is the square of the WW-hinge-loss for multi-class SVMs, a large-margin loss.\n\nSee:\n\nWeston, Jason; Watkins, Chris (1999). \"Support Vector Machines for Multi-Class Pattern Recognition\" (PDF). European Symposium on Artificial Neural Networks.\n\nand the following paper describes the relations of the different variants of this loss:\n\nhttp://jmlr.org/papers/v17/11-229.html\nIn the notation of that paper, it would be the combination of sum-over-others aggregation with relative margin concept and squared hinge loss.\n\nFor theoretical considerations, the log-probability should be used, in which case m  = 1 is fine and the last layer would not need to be normalized any more."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1511986743075, "tcdate": 1511986743075, "number": 9, "cdate": 1511986743075, "id": "HkAVUc3gz", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Kaitlin_Duck_Sherwood1"], "readers": ["everyone"], "writers": ["~Kaitlin_Duck_Sherwood1"], "content": {"title": "Typo", "comment": "The sentence fragment:\n   Spatial transformer networks (Jaderberg et al. (2015) seeks\nis missing a ), and the subject is plural and not singular.  So it should be:\n    Spatial transformer networks (Jaderberg et al. (2015)) seek"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1511969780085, "tcdate": 1511969780085, "number": 8, "cdate": 1511969780085, "id": "rJnxEL2xf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Micha_Pfeiffer1"], "readers": ["everyone"], "writers": ["~Micha_Pfeiffer1"], "content": {"title": "V_ih", "comment": "1) \"V_ih is the product of the the transformation matrix W_ic that is learned discriminatively\"\nThere is part of the sentense missing. Also, I believe this sentence describes \"V_i\" and not \"V_ih\". Suggestion:\n\" ... and V_ih is the value on dimension h of the vote V_i from capsule i to capsule c. V_i is obtained by taking the matrix product of the pose p_i of capsule i and the transformation Matrix W_ic. W_ic is learned discriminatively.\"\n\n2) From what I understand, the vote V_i is a matrix (since it's obtained by multiplying a 4x4 matrix with a 4x4 matrix), and v_ih is a scalar. I found \"V_ih is the value on dimension h of the vote ...\" to be missleading. Maybe it should be mentioned that V_i has to be reshaped into a vector first and then its h'th entry is V_ih?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1511578747698, "tcdate": 1511578747698, "number": 4, "cdate": 1511578747698, "id": "r17t2UIgf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "Hy9EvktkG", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "dimensionality of transformation matrix W_{ic} in ConvCaps", "comment": "W_{ic} is 4*4 if you flatten the capsule types and grid positions. Therefore i goes over changes in the range of (1, channels * height * width) in this formulation.\n\nHowever, We share the W_ic between different positions of two capsule types as in a convolutional layer with a kernel size k. Therefore, the total number of trainable parameters between two convolutional capsule layer types is 4*4*k*k and for the whole layer is 4*4*k*k*B*C. Where B is the number of different capsule types in layer bellow and C is the number of different capsule types in the next layer.\n\nPlease note that it is 4*4 rather than (4*4)*(4*4). "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1511578177414, "tcdate": 1511578177414, "number": 3, "cdate": 1511578177414, "id": "BkFS5LLxf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "ryM_Fi4JM", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "How to transform conv layer to the primary capsule layer?", "comment": "As Jianfei has explained, the primary capsule layer is a convolutional layer with 1x1 kernel. It transforms the A channels in the first layer to B*(4x4+1) channels. Then we split the B*(4x4+1) channels into B*(4x4) as the pose matrices for B capsules and B*1 as the activation logits of B capsules in primary layer. Then we apply sigmoid nonlinearity on the activation logits."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1510696754345, "tcdate": 1510696754345, "number": 7, "cdate": 1510696754345, "id": "Hy9EvktkG", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Gavin_Weiguang_Ding1"], "readers": ["everyone"], "writers": ["~Gavin_Weiguang_Ding1"], "content": {"title": "dimensionality of transformation matrix W_{ic} in ConvCaps", "comment": "In the convolutional capsule layers, what's the dimensionality of  transformation matrix W_{ic}?\nIs it still (4*4)->(4*4) which correspond to a 1*1 linear convolutional layer?\nor it is (4*4*k*k)->(4*4) which correspond to a k*k linear convolutional layer?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1510455985555, "tcdate": 1510455985555, "number": 6, "cdate": 1510455985555, "id": "Hkc2c4HyM", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "ryM_Fi4JM", "signatures": ["~Jianfei_Chen1"], "readers": ["everyone"], "writers": ["~Jianfei_Chen1"], "content": {"title": "How to transform conv layer to the primary capsule layer?", "comment": "Figure 1 explains that. I guess they use a A*B*(4*4+1) kernel to (linear) transform a 1 width * 1 height * 32 channels patch to 32 capsules, each shape is 4*4+1. Then they reshape the 4*4 part as a matrix and apply a sigmoid on the 1 part. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1510418849472, "tcdate": 1510418794078, "number": 5, "cdate": 1510418794078, "id": "ryM_Fi4JM", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "How to transform conv layer to the primary capsule layer?", "comment": "I still don't understand the transformation from convolution layer to primary capsule layer? Is it achieved by slicing 4x4*32 patches from the conv layer and then do a linear transformation for each 4x4 matrices?  what is the weight in \"The activations of the primary capsules are produced by applying the sigmoid function to weighted sums of the same set of lower layer ReLUs.\" is it the 4x4 variable? I found it confusing, can you elaborate how this works."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1510386582459, "tcdate": 1510386582459, "number": 4, "cdate": 1510386582459, "id": "ByAqs7VJf", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["~Jianfei_Chen1"], "readers": ["everyone"], "writers": ["~Jianfei_Chen1"], "content": {"title": "The objective function", "comment": "Can you write down what exactly is the objective function in Section 2.1?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1510092427847, "tcdate": 1509578507674, "number": 1, "cdate": 1509578507674, "id": "ByVzDRDRW", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "forum": "HJWLfGWRb", "replyto": "S1uPsnwR-", "signatures": ["ICLR.cc/2018/Conference/Paper789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper789/Authors"], "content": {"title": "state-of-the-art on \"small NORB\"", "comment": "They gain a lot by using the meta data at test time. Without using that information (which normally is not available at test time) they get 2.6%. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825727712, "id": "ICLR.cc/2018/Conference/-/Paper789/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper789/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper789/Authors|ICLR.cc/2018/Conference/Paper789/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper789/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper789/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper789/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825727712}}}, {"tddate": null, "ddate": null, "tmdate": 1509581767435, "tcdate": 1509581767435, "number": 2, "cdate": 1509581767435, "id": "rk1Am1uRW", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "ByVzDRDRW", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "state-of-the-art on \"small NORB\"", "comment": "The meta data is not used during test time only during training time."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}, {"tddate": null, "ddate": null, "tmdate": 1509571423975, "tcdate": 1509571423975, "number": 1, "cdate": 1509571423975, "id": "S1uPsnwR-", "invitation": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "forum": "HJWLfGWRb", "replyto": "HJWLfGWRb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "state-of-the-art on \"small NORB\"", "comment": "1.5% error rate has previously been reported on small NORB.\nhttps://www.researchgate.net/publication/265335724_Nonlinear_Supervised_Locality_Preserving_Projections_for_Visual_Pattern_Discrimination"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix capsules with EM routing", "abstract": "A capsule is a group of neurons whose outputs represent different properties of the same entity. Each layer in a capsule network contains many capsules. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 matrix which could learn to represent the relationship between that entity and the viewer (the pose). A capsule in one layer votes for the pose matrix of many different capsules in the layer above by multiplying its own pose matrix by trainable viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated for each image using the Expectation-Maximization algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The transformation matrices are trained discriminatively by backpropagating through the unrolled iterations of EM between each pair of adjacent capsule layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistance to white box adversarial attacks than our baseline convolutional neural network.", "pdf": "/pdf/8f973934873678bd6d0ed09097bcf11760c465f6.pdf", "TL;DR": "Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ", "paperhash": "hinton|matrix_capsules_with_em_routing", "_bibtex": "@inproceedings{\ne2018matrix,\ntitle={Matrix capsules with {EM} routing},\nauthor={Geoffrey E Hinton and Sara Sabour and Nicholas Frosst},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=HJWLfGWRb},\n}", "keywords": ["Computer Vision", "Deep Learning", "Dynamic routing"], "authors": ["Geoffrey E Hinton", "Sara Sabour", "Nicholas Frosst"], "authorids": ["geoffhinton@google.com", "sasabour@google.com", "frosst@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791678462, "id": "ICLR.cc/2018/Conference/-/Paper789/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "HJWLfGWRb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper789/Authors", "ICLR.cc/2018/Conference/Paper789/Reviewers", "ICLR.cc/2018/Conference/Paper789/Area_Chair"], "cdate": 1512791678462}}}], "count": 47}