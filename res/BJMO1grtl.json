{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028634503, "tcdate": 1490028634503, "number": 1, "id": "rkzvuFpjl", "invitation": "ICLR.cc/2017/workshop/-/paper152/acceptance", "forum": "BJMO1grtl", "replyto": "BJMO1grtl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Expectation Maximization", "abstract": "We introduce a novel framework for clustering that combines generalized EM\nwith neural networks and can be implemented as an end-to-end differentiable\nrecurrent neural network. It learns its statistical model directly from the data and\ncan represent complex non-linear dependencies between inputs. We apply our\nframework to a perceptual grouping task and empirically verify that it yields the\nintended behavior as a proof of concept.", "pdf": "/pdf/e74417b6997c818695bed4b9dacee324160d5a25.pdf", "TL;DR": "A framework for clustering that combines generalized EM with neural networks and can be implemented as an end-to-end differentiable recurrent neural network", "paperhash": "greff|neural_expectation_maximization", "keywords": ["Theory", "Deep learning", "Unsupervised Learning"], "conflicts": ["usi.ch", "idsia.ch", "supsi.ch", "cai.fi"], "authors": ["Klaus Greff", "Sjoerd van Steenkiste", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "sjoerd@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028635047, "id": "ICLR.cc/2017/workshop/-/paper152/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BJMO1grtl", "replyto": "BJMO1grtl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028635047}}}, {"tddate": null, "tmdate": 1489565211178, "tcdate": 1489565211178, "number": 1, "id": "SyQ7U_Uil", "invitation": "ICLR.cc/2017/workshop/-/paper152/public/comment", "forum": "BJMO1grtl", "replyto": "Hy4PvEkjg", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "writers": ["~Klaus_Greff1"], "content": {"title": "Added details", "comment": "Thank you for the feedback. We agree on your criticism and have now added a section in the appendix that describes the experimental setup in more detail. \nIn particular, we've used K=3 and 10 EM steps for all experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Expectation Maximization", "abstract": "We introduce a novel framework for clustering that combines generalized EM\nwith neural networks and can be implemented as an end-to-end differentiable\nrecurrent neural network. It learns its statistical model directly from the data and\ncan represent complex non-linear dependencies between inputs. We apply our\nframework to a perceptual grouping task and empirically verify that it yields the\nintended behavior as a proof of concept.", "pdf": "/pdf/e74417b6997c818695bed4b9dacee324160d5a25.pdf", "TL;DR": "A framework for clustering that combines generalized EM with neural networks and can be implemented as an end-to-end differentiable recurrent neural network", "paperhash": "greff|neural_expectation_maximization", "keywords": ["Theory", "Deep learning", "Unsupervised Learning"], "conflicts": ["usi.ch", "idsia.ch", "supsi.ch", "cai.fi"], "authors": ["Klaus Greff", "Sjoerd van Steenkiste", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "sjoerd@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487368042546, "tcdate": 1487368042546, "id": "ICLR.cc/2017/workshop/-/paper152/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper152/reviewers"], "reply": {"forum": "BJMO1grtl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487368042546}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489564809333, "tcdate": 1487368041705, "number": 152, "id": "BJMO1grtl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "BJMO1grtl", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "content": {"title": "Neural Expectation Maximization", "abstract": "We introduce a novel framework for clustering that combines generalized EM\nwith neural networks and can be implemented as an end-to-end differentiable\nrecurrent neural network. It learns its statistical model directly from the data and\ncan represent complex non-linear dependencies between inputs. We apply our\nframework to a perceptual grouping task and empirically verify that it yields the\nintended behavior as a proof of concept.", "pdf": "/pdf/e74417b6997c818695bed4b9dacee324160d5a25.pdf", "TL;DR": "A framework for clustering that combines generalized EM with neural networks and can be implemented as an end-to-end differentiable recurrent neural network", "paperhash": "greff|neural_expectation_maximization", "keywords": ["Theory", "Deep learning", "Unsupervised Learning"], "conflicts": ["usi.ch", "idsia.ch", "supsi.ch", "cai.fi"], "authors": ["Klaus Greff", "Sjoerd van Steenkiste", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "sjoerd@idsia.ch", "juergen@idsia.ch"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489181371397, "tcdate": 1489181371397, "number": 2, "id": "Sk7a55gil", "invitation": "ICLR.cc/2017/workshop/-/paper152/official/review", "forum": "BJMO1grtl", "replyto": "BJMO1grtl", "signatures": ["ICLR.cc/2017/workshop/paper152/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper152/AnonReviewer1"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "   The paper concerns the task of perceptual grouping (essentially clustering pixels in an image; pixels in the same cluster are meant to form meaningful perceptual constructs, hopefully relevant shapes; a kind of unsupervised segmentation task). The paper proposes a generative model for images in which a neural network function F encodes the dependencies between pixel. Each cluster has a different latent variable theta, such that a mixture of F(theta) with Gaussian noise makes up the final image. The important part in this generative model (relevant to the task) is to be able to infer to which clusters the pixels should be affected and that the clusters be meaningful. The model is trained with a loose approximation of EM  which takes the form of backdrop through time in a recurrent neural network.\n\n- An assessment of novelty, clarity, significance, and quality.\n   - the method seems novel\n   - the paper is not very clear and must be read many times to gather information about what the model is which is all over the place. Event then a lot remains unclear.\n   - negative results on real dataset suggest the method is not significant in its current form\n\n- A list of pros and cons (reasons to accept/reject).\n   pros:\n      - the method seems new\n      - implementation of a loose EM approximation with a RNN seems new and somewhat interesting\n   cons\n       - not clear but maybe this cannot be helped due to the 3 page limit.\n       - results seem encouraging on toy dataset (method seems to cluster pixels based on shape) but not on real dataset (pixels are clustered based on colour which is exactly what the authors did not want). This undermines the whole point of the method which is to capture dependency between pixels. This makes one doubt the applicability of the method to pixel grouping let alone applicability to anything else.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Expectation Maximization", "abstract": "We introduce a novel framework for clustering that combines generalized EM\nwith neural networks and can be implemented as an end-to-end differentiable\nrecurrent neural network. It learns its statistical model directly from the data and\ncan represent complex non-linear dependencies between inputs. We apply our\nframework to a perceptual grouping task and empirically verify that it yields the\nintended behavior as a proof of concept.", "pdf": "/pdf/e74417b6997c818695bed4b9dacee324160d5a25.pdf", "TL;DR": "A framework for clustering that combines generalized EM with neural networks and can be implemented as an end-to-end differentiable recurrent neural network", "paperhash": "greff|neural_expectation_maximization", "keywords": ["Theory", "Deep learning", "Unsupervised Learning"], "conflicts": ["usi.ch", "idsia.ch", "supsi.ch", "cai.fi"], "authors": ["Klaus Greff", "Sjoerd van Steenkiste", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "sjoerd@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489181372019, "id": "ICLR.cc/2017/workshop/-/paper152/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper152/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper152/AnonReviewer2", "ICLR.cc/2017/workshop/paper152/AnonReviewer1"], "reply": {"forum": "BJMO1grtl", "replyto": "BJMO1grtl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper152/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper152/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489181372019}}}, {"tddate": null, "tmdate": 1489090396211, "tcdate": 1489090396211, "number": 1, "id": "Hy4PvEkjg", "invitation": "ICLR.cc/2017/workshop/-/paper152/official/review", "forum": "BJMO1grtl", "replyto": "BJMO1grtl", "signatures": ["ICLR.cc/2017/workshop/paper152/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper152/AnonReviewer2"], "content": {"title": "Nice idea but details are missing.", "rating": "6: Marginally above acceptance threshold", "review": "The authors propose a clustering method based on a mixture distribution of components which are parameterized by neural networks. The system finds a clustering using generalized EM updates. The parameters are trained by propagating the likelihood gradient through these EM updates. The authors also propose a less principled but potentially more flexible version of the model in which the EM updates are replaced with more conventional recurrent neural network state updates. \n\nTo my knowledge, the proposed combination of models and trained inference method are new and an interesting approach to the grouping problem. The idea to backpropagate through inference updates is not new by itself and it would have been nice to see some references to earlier work in this area but obviously there was not much space available for that. \n\nI find it very unfortunate that there are not more details about the empirical work. It is not clear to me how many EM steps are used. While an extended abstract may not need to be detailed enough for an exact replication of the research, details like this are in my opinion necessary to at least get a rough idea about the complexity and practical value of the method. \n\nPros:\n- Nice new approach to the grouping problem.\n- Results seem to compare favorably to prior work.\n\nCons:\n- Lack of implementation details.\n- Limited evaluation and analysis of the methods.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Expectation Maximization", "abstract": "We introduce a novel framework for clustering that combines generalized EM\nwith neural networks and can be implemented as an end-to-end differentiable\nrecurrent neural network. It learns its statistical model directly from the data and\ncan represent complex non-linear dependencies between inputs. We apply our\nframework to a perceptual grouping task and empirically verify that it yields the\nintended behavior as a proof of concept.", "pdf": "/pdf/e74417b6997c818695bed4b9dacee324160d5a25.pdf", "TL;DR": "A framework for clustering that combines generalized EM with neural networks and can be implemented as an end-to-end differentiable recurrent neural network", "paperhash": "greff|neural_expectation_maximization", "keywords": ["Theory", "Deep learning", "Unsupervised Learning"], "conflicts": ["usi.ch", "idsia.ch", "supsi.ch", "cai.fi"], "authors": ["Klaus Greff", "Sjoerd van Steenkiste", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "sjoerd@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489181372019, "id": "ICLR.cc/2017/workshop/-/paper152/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper152/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper152/AnonReviewer2", "ICLR.cc/2017/workshop/paper152/AnonReviewer1"], "reply": {"forum": "BJMO1grtl", "replyto": "BJMO1grtl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper152/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper152/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489181372019}}}], "count": 5}