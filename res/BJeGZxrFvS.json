{"notes": [{"id": "BJeGZxrFvS", "original": "Hyx6w1gKPB", "number": 2127, "cdate": 1569439737867, "ddate": null, "tcdate": 1569439737867, "tmdate": 1577168264584, "tddate": null, "forum": "BJeGZxrFvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "NeSqmWx34", "original": null, "number": 1, "cdate": 1576798741273, "ddate": null, "tcdate": 1576798741273, "tmdate": 1576800894957, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Decision", "content": {"decision": "Reject", "comment": "This submission proposes a method to pass sanity checks on saliency methods for model explainability that were proposed in a prior work.\n\nPros:\n-The method is simple, intuitive and does indeed pass the proposed checks.\n\nCons:\n-The proposed method aims to pass the sanity checks, but is not well-evaluated on whether it provides good explanations. Passing these checks can be considered as necessary but not sufficient.\n-All reviewers agreed that the evaluation could be improved and most reviewers found the evaluation insufficient.\n\nGiven the shortcomings, AC agrees with the majority recommendation to reject.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795704755, "tmdate": 1576800252399, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Decision"}}}, {"id": "rJgOz7c2jH", "original": null, "number": 4, "cdate": 1573851919783, "ddate": null, "tcdate": 1573851919783, "tmdate": 1573851919783, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "BJg6iRPDYS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment", "content": {"title": "Response to Official Blind Reviewer 2", "comment": "We thank reviewer 2 for their thoughtful review. We agree that the question of how to optimally apply competition among labels remains open. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeGZxrFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2127/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2127/Authors|ICLR.cc/2020/Conference/Paper2127/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145932, "tmdate": 1576860541285, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment"}}}, {"id": "Bkgs3f93jr", "original": null, "number": 3, "cdate": 1573851827180, "ddate": null, "tcdate": 1573851827180, "tmdate": 1573851827180, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "S1enNy8TFr", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment", "content": {"title": "Response to Official Blind Reviewer 1", "comment": "We thank reviewer 1 for their thoughtful review. \n\nWe apologize for the typos, and are correcting them in the revised version. As for the sentence beginning Section 4, we attempted to show, in Figure 1, that that although nearly all the pixels in the actual digit \u20183\u2019 are highlighted in the saliency map with chosen label 3, some of these pixels appear more relevant for other classes, for example in the map for logit 7 the top and backbone of the 3 can clearly be seen.  This suggests that just because a pixel is present in the saliency map for logit \u20183\u2019, does not mean that is it primarily indicative of the label being \u20183\u2019, especially if it assigns a lower score to the label being \u20183\u2019 than to \u20187\u2019. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeGZxrFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2127/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2127/Authors|ICLR.cc/2020/Conference/Paper2127/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145932, "tmdate": 1576860541285, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment"}}}, {"id": "Hyg7GfcnjH", "original": null, "number": 2, "cdate": 1573851658993, "ddate": null, "tcdate": 1573851658993, "tmdate": 1573851658993, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "SJx3NyisqS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment", "content": {"title": "Response to Official Blind Reviewer 4", "comment": "We thank reviewer 4 for a  thoughtful review. \n\n4. In Figure 1, the data was normalized before feeding it to the neural network, so the background values are not all zero. We would also like to note that it is possible that any anomalous values in the input image may propagate spuriously to the logit, whether they be edges or some other image feature. \n6. Figure 1 shows the CGI map for chosen logit \u20183\u2019. \n7. In order to compare across logits, either completeness or approximate completeness (meaning there is a correlation between the sum of saliency scores for each logit and the logit value) must be satisfied. LRP, gradient * input for ReLU nets with no bias, DeepLift for ReLU nets with no bias, all satisfy completeness. Gradient *input seems to satisfy approximate completeness even for ReLU networks with bias. \n8. The authors do not mean to imply that such \u2018shared features\u2019 (those indicative for multiple classes) are irrelevant. However, our competition idea forces each pixel to  choose one label (the one giving it the maximal score). While at first glance this seems to discard potentially relevant pixels, the theory suggests reasons why it doesn\u2019t happen too often.\n9. This may be seen in Figure 1 in the rightmost column. \n10. Taking the gradient of the post-softmax probability with respect to the input does not satisfy completeness for the logit value for gradient * input, and we found it did not pass the sanity checks well. The referenced paper computes a different calculation, which is using the derivative of the post softmax probability with respect to the logit as the initial value for LRP. We did not test this method, as it is more specific to LRP and we were examining a more broad class of saliency methods. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeGZxrFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2127/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2127/Authors|ICLR.cc/2020/Conference/Paper2127/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145932, "tmdate": 1576860541285, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Authors", "ICLR.cc/2020/Conference/Paper2127/Reviewers", "ICLR.cc/2020/Conference/Paper2127/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Comment"}}}, {"id": "BJg6iRPDYS", "original": null, "number": 1, "cdate": 1571417765402, "ddate": null, "tcdate": 1571417765402, "tmdate": 1572972379654, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents a strategy for visualizing activation in networks that corresponds to features in the input layer. It addresses a problem posed for existing methods for characterizing saliency in activation subject to sanity checks which measure the degree to which the activation (saliency) map changes subject to different randomization tests.\nThe proposed solution involves a simple competition mechanism across saliency maps produced when different logits are considered such that small values are zeroed out in favor of larger values across the logits.\nOverall, I find this paper to be interesting and to address a problem worthy of further consideration. While the mechanism for competition is very simple, the resulting activation maps subject to randomization tests are reasonably convincing.\nIn the ideal case, I would have liked to see different strategies for eliciting competition explored to determine their relative merits. Nevertheless, I expect that such work will follow with this being an initial step in this direction."}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575543913529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Reviewers"], "noninvitees": [], "tcdate": 1570237727321, "tmdate": 1575543913543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review"}}}, {"id": "S1enNy8TFr", "original": null, "number": 2, "cdate": 1571802931609, "ddate": null, "tcdate": 1571802931609, "tmdate": 1572972379617, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "I Summary\nThe paper directly answers two sanity checks for saliency maps proposed by Adebayo et al (2018): 1. randomizing the weights of a model to prove that the input's resulting saliency map is different from a trained model' saliency map.  2. randomizing the inputs' labels to make the same proof. The authors propose a \"competitive version of saliency method\" which uses the saliency scores of every pixel for each labels and zero out: positive scored pixels that would not be maximal for the predicted class and negative scored pixels that are not minimal for the worst predicted label.\nOverall the method solves the aforementioned sanity checks, the authors claim it also generates more refined saliency maps.\n\nII Comments\n\n1. Content\nThe paper can be hard to read, due to multiple writing mistakes, abrupt phrasing, not well-articulated sentences. However, the idea is easy to understand and interesting but the contribution does not seem strong enough in its actual state. \nMy main concern is that the method seems to be designed only to answer the sanity checks: the resulting saliency maps can hardly be seen as more informative as other existing methods (eg figure 1). Quantitative measures (ROAR & KAR, Hooker et al. 2018) or surveys to show that the newly obtained saliency maps are more refined or help to best localize regions of interest would be a big bonus.\n\n2. Writing\nThe paper comports numerous typos, those do not impact the score of the review except if the sentence is not understandable. Please see the following points as support to improve the clarity of the paper.\n- Abstract last sentence: \"Some theoretical justification is provided\" -> \"Some\" is vague and makes your claim less credible -> \"theoretical justifications are given in the last paragraph to support our method...\"\n- Intro \n   paragraph 2 first sentence lack some words, l 2 product -> a product\n   \"See paper XX et al\" -> \"As in XX et al, we can see that\" or \"As stated in XX et al\", \"See\" is too familiar, formalizing the phrasing gives more credibility to your work\n- Related work\n  \"To give an example, does the map change a lot if we blank out or modify a portion of the image that humans find insignificant Kim et al. (2019)? \" This is not very well articulated, \"a lot\" is vague and a little familiar, \"significantly\" could be used here. Moreover, the citation is a little abrupt \"as we can see in XX\" would work better \nLittle typo on etc..\n\"fare best\" -> far better? The wording is still vague, it would help to add a quantitative measure\nthat's -> that is\n- Section 3\n\"This figure highlights\" -> which figure? (I think you just missed citing the fig here)\n- Section 4\nFirst sentence: Why is it a good idea? The claim is a little abrupt and could be detailed a little more\n\"destroy the saliency map\" -> destroy is a very strong word\n\"These random variables are complicated.\" -> This statement seems a little out of place and abrupt\n\"some constants\" -> \"constants\" (too vague otherwise as before)\n- Subsection 4.1\n\"randomly sampling a few such methods\" I believe there is a typo?\n\"See figure 3\" is abrupt as a sentence itself \"as you can see in figure 3 bla bla\"\nFigure 4 The image is small and hard to see on printed paper (same for the images in the appendix, they could be stacked over multiple lines instead of just one horizontal row)\nDefinition 2 punctuation at the end\n- Section 5\n\"The available code for these maps is slow, and computing even gradient for all 1000 ImageNet labels can be rather slow.\" What is the aim of this sentence?\n- subsection 5.3 \nlables -> labels\n\nIII Conclusion\nThe method itself is interesting, it would be interesting to see more qualitative results on the obtained saliency map itself: Does it produce more information? Is it more meaningful etc. Because as of now, it only seems to answer the two aforementioned sanity checks.  As for the writing, it is not always clear and can impede the understanding of the paper. I would be glad to change my review if those points are addressed.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575543913529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Reviewers"], "noninvitees": [], "tcdate": 1570237727321, "tmdate": 1575543913543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review"}}}, {"id": "SJx3NyisqS", "original": null, "number": 3, "cdate": 1572740915600, "ddate": null, "tcdate": 1572740915600, "tmdate": 1572972379572, "tddate": null, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "invitation": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\n\nThe paper proposes a simple technique to address the problem introduced by Adebayo et al. that several saliency approaches do not pass sanity checks. The proposed approach computes the saliency maps for all the classes and removes the pixels that play a role in predicting several classes. \n\nStrengths:\n\n1. Simple and intuitive approach. \n2. Well written and easy to read paper.\n3. The introduced approach makes Grad.Input pass the sanity checks introduced by Adebayo et al.\n\nWeaknesses:\n\n1. For any interpretability technique, passing the sanity check is a must, but just because a saliency technique passes the sanity checks, it doesn\u2019t mean that these maps explain the network\u2019s decision well. \n2. Lack of any quantitative evaluation (such as localization or pointing experiment) of their approach. \n3. Failure to show if the resultant maps are class-discriminative. Show performance on images with multiple classes. \n4. In fig 1,  In Grad . Input, I see positive values or negative values even when the original pixels are not active. This doesn\u2019t explain the presence of edges causing high values in the G.I map for such pixels, right?\n5. In figure 1, These maps only assign values to the pixels that need to be removed to make a certain classification decision. The regions that need to be active but are not present are not highlighted. \n6. In figure 1 the shown CGI Map is for which class?\n7. So, is the approach only applicable to such systems where the completeness is true? Can the authors provide a list of approach that satisfy completeness:\n8. Page 3 last paragraph: Consider the example in figure 1. Let's consider the maps for digit 3 and 5. For the top horizontal part of the digit, it plays a role in determining both 3 and 5. Assume that for one such pixel the value of h_5_i is greater thatn h_3_i (looking at the figure it is not unreasonable to expect that). Just because the g.input value of h_5_i is greater that h_3_i , are the authors saying that the top part is irrelevant?\n9. How does CGI look for the original 3 on standard model?\n10. Could the authors provide more intuition as the why the gradients of outputs from softmax layer doesn\u2019t give good results? The proposed approach from https://arxiv.org/pdf/1908.04351.pdf suggests that computing gradients from last layer improves the class discriminative behaviour.  \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2127/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks", "authors": ["Arushi Gupta", "Sanjeev Arora"], "authorids": ["arushig@princeton.edu", "arora@cs.princeton.edu"], "keywords": ["saliency", "attribution", "interpretability", "sanity checks"], "TL;DR": "We devise a mechanism called competition among pixels that allows (approximately) complete saliency methods to pass the sanity checks.", "abstract": " {\\em Saliency methods} attempt to explain a deep net's decision by assigning a {\\em score} to each feature/pixel in the input, often doing this credit-assignment via the gradient of the output with respect to input. \nRecently \\citet{adebayosan} questioned the validity of many of these methods since they do not pass simple {\\em sanity checks}, which test whether the scores shift/vanish when  layers of the trained net are randomized, or when the net is retrained using random labels for inputs. % for the inputs.   %Surprisingly, the tested methods did not pass these checks: the explanations were relatively unchanged. \n\nWe propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call {\\em competition for pixels}. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. Some theoretical justification is provided for it  and its performance is empirically demonstrated on several popular methods.", "pdf": "/pdf/4c48da32aed2c6bfe191304225d1b4c9724bfb9a.pdf", "paperhash": "gupta|a_simple_technique_to_enable_saliency_methods_to_pass_the_sanity_checks", "original_pdf": "/attachment/be435bc9e393ba4beb6b2a2d07537b08f437ae86.pdf", "_bibtex": "@misc{\ngupta2020a,\ntitle={A Simple Technique to Enable Saliency Methods to Pass the Sanity Checks},\nauthor={Arushi Gupta and Sanjeev Arora},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeGZxrFvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeGZxrFvS", "replyto": "BJeGZxrFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2127/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575543913529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2127/Reviewers"], "noninvitees": [], "tcdate": 1570237727321, "tmdate": 1575543913543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2127/-/Official_Review"}}}], "count": 8}