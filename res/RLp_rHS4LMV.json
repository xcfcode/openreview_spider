{"notes": [{"id": "RLp_rHS4LMV", "original": "djw4WDO3mA", "number": 14, "cdate": 1615595598748, "ddate": null, "tcdate": 1615595598748, "tmdate": 1615844207800, "tddate": null, "forum": "RLp_rHS4LMV", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission", "content": {"title": "Learning where to learn", "authorids": ["ICLR.cc/2021/Workshop/Learning_to_Learn/Paper14/Authors"], "authors": ["Anonymous"], "keywords": ["Deep Learning", "Meta-learning", "MAML", "Sparsity"], "abstract": "Finding neural network weights that generalize well from small datasets is difficult. A  promising approach is to  (meta-)learn a  weight initialization from  a collection of tasks,  such that a small number of weight changes results in low generalization error. We show that this form of meta-learning can be improved by letting the learning algorithm decide which weights to change, i.e., by learning where to learn. We find that patterned sparsity emerges from this process. Lower-level features tend to be frozen, while weights close to the output remain plastic. This selective sparsity enables running longer sequences of weight updates with-out overfitting, resulting in better generalization in the miniImageNet benchmark. Our findings shed light on an ongoing debate on whether meta-learning can discover adaptable features, and suggest that sparse learning can outperform simpler feature reuse schemes.", "pdf": "/pdf/ab6af0f01670dd61b30d217c0ec7528428b42a04.pdf", "proposed_reviewers": "", "paperhash": "anonymous|learning_where_to_learn", "_bibtex": "@inproceedings{\nanonymous2021learning,\ntitle={Learning where to learn},\nauthor={Anonymous},\nbooktitle={Submitted to Learning to Learn - Workshop at ICLR 2021},\nyear={2021},\nurl={https://openreview.net/forum?id=RLp_rHS4LMV},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "proposed_reviewers": {"value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615595596483, "tmdate": 1615844205826, "id": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}