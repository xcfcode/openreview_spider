{"notes": [{"id": "r1gelyrtwH", "original": "rJlcXboODr", "number": 1493, "cdate": 1569439464127, "ddate": null, "tcdate": 1569439464127, "tmdate": 1583912036887, "tddate": null, "forum": "r1gelyrtwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "CgcRRDdKTd", "original": null, "number": 1, "cdate": 1576798724671, "ddate": null, "tcdate": 1576798724671, "tmdate": 1576800911822, "tddate": null, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "All reviewers agree that this research is novel and well carried out, so this is a clear accept. Please ensure that the final version reflect the reviewer comments and the new information provided during the rebuttal", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726744, "tmdate": 1576800278936, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Decision"}}}, {"id": "S1x-cmNsiB", "original": null, "number": 4, "cdate": 1573761929229, "ddate": null, "tcdate": 1573761929229, "tmdate": 1573802305254, "tddate": null, "forum": "r1gelyrtwH", "replyto": "HJlGM8Fwsr", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment", "content": {"title": "\u201c1. Evaluation on More datasets\u201d", "comment": "We tested our proposed method and baselines on the NEMO sea surface temperature (SST) dataset (available at http://marine.copernicus.eu/services-portfolio/access-to-products/?option=com_csw&view=details&product_id=GLOBAL_ANALYSIS_FORECAST_PHY_001_024)\nWe first download the data in the area between 50N-65N and 75W-10W starting from 2016-01-01 to 2017-12-31, then we crop the [0, 550] - [100, 650] square from the area and sample 250 points from the square as our chosen dataset. We divide the data into 24 sequences, each lasting 30 days, and truncate the tail. All models use the first 5-day SST as input and predict the SST in the following 15 and 25 days. We use the data in 2016 for training all models and the left for testing.\n\nFor StandardOP, MeshOP and SDL, we test both options using linear regression and using RGN for the prediction part and report the best result. The results show that all methods incorporating spatial differences gain improvement on prediction and that our proposed learnable SDL outperforms all other baselines.\n\nMean absolute error (10^\u22122) for SST prediction\n+--------+-----------+----------+----------+-----------+------------------+-------------+-----------+\n| Step |    VAR   |  MLP    |   GRU  |   RGN   | StandardOP | MeshOP |   SDL    |\n|  15    | 15.123 | 15.058 | 15.101 | 15.172 |     14.756        |   14.607  | 14.382 |\n|  25    | 19.533 | 19.473 | 19.522 | 19.705 |     18.983        |   18.977  | 18.434 |\n+--------+-----------+----------+----------+-----------+------------------+-------------+-----------+\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gelyrtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1493/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1493/Authors|ICLR.cc/2020/Conference/Paper1493/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155199, "tmdate": 1576860547877, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment"}}}, {"id": "HJlGM8Fwsr", "original": null, "number": 3, "cdate": 1573520905893, "ddate": null, "tcdate": 1573520905893, "tmdate": 1573521890236, "tddate": null, "forum": "r1gelyrtwH", "replyto": "Bkgw7nNRKH", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment", "content": {"title": "Response #3", "comment": "Thank you for your comments and suggestions to improve the paper. Below are our responses to the main points of your comments: \n\n>> \u201c1. Evaluation on More datasets\u201d\nThanks for suggesting the evaluation on more datasets. The proposed method assumes that there are continuous phenomena governed by physics rules or equations and the phenomena are only observed at some locations (i.e., sparsely-observed dynamics). Under this assumption, we thought that climate data is ideal to evaluate our idea. \nCurrently, we are looking for more datasets to support our idea and we are investigating to apply on Sea Surface Temperature dataset.\n\n>> \u201c2. Uncover the relationship of gradients\u201d\nThis is a great suggestion and actually, discovering (or uncovering) hidden physics is one of the research topics related to physics with deep learning. In fact, while the main motivation of our work is different to these kinds of work, we believe that it is a great idea to extend our work to discovering latent rules since it makes data-driven models more interpretable.\n\n>> \"3. How sparse the data is?\"\nFor the synthetic experiment in Section 3.1, we sampled 200 points in 2D space (x,y)\u2208[-5.0, 5.0] x [-5.0, 5.0].\nFor the synthetic experiment in Section 3.2, we sampled 250 points in 2D space (x,y)\u2208[0, 2\u03c0] x [0, 2\u03c0].\nFor the temperature prediction experiment in Section 4, \n+---------------+----------------+---------------------+\n|                    |    Western  | Southeastern  |\n|   # Nodes  |        191       |         230            |\n+---------------+----------------+---------------------+\n\n>> \"3. Controlling the sparsity and evaluation the performance\"\nWe changed the number of nodes to control the sparsity of data. Our proposed model outperforms others under various settings of sparsity on the synthetic experiment in Section 3.2.\n\nMean absolute error (10^\u22122) for graph signal prediction\n+---------------+-----------+-----------+------------------+-------------+------------+\n|     Graph    |    VAR   |   MLP   | StandardOP | MeshOP |   Ours   |\n| 250 nodes | 0.1730 | 0.1627 |       0.1200     |    0.1287  |  0.1104  |\n| 150 nodes | 0.1868 | 0.1729 |       0.1495     |    0.1576  |  0.1482  |\n| 100 nodes | 0.1723 | 0.1589 |       0.1629     |    0.1696  |  0.1465  |\n+---------------+-----------+-----------+------------------+-------------+------------+\n\nFurthermore, we sampled 400 points and trained SDL as described in Section 3.1, and resampled fewer points (350,300,250,200) to evaluate if SDL generalizes less sparse setting. As the following table shows, MSE increases when fewer sample points are used. However, SDL is able to provide much more accurate gradients even if it is trained under a new graph with different properties. Thus, the results support that SDL is able to generalize the c setting.\n\nMean squared error (10^\u22122) for approximations of directional derivatives.\n+---------------+-------------------+---------------+-------------------+---------------+\n| Functions | FinGrad(350) | SDL(350)  | FinGrad(300) | SDL(300)  |\n| f2(x,y)       |    2.88\u00b10.11    |  1.03\u00b10.09 |    3.42\u00b10.14    | 1.14\u00b10.12 |\n+---------------+-------------------+---------------+-------------------+---------------+\n|                    | FinGrad(250)|  SDL(250)  | FinGrad(200) | SDL(200)  |\n|                    |   3.96\u00b10.17    |  1.40\u00b10.10 |     4.99\u00b10.31    | 1.76\u00b10.10 |\n+---------------+-------------------+---------------+-------------------+---------------+\n\n>> \u201c4. Can your method handle the noisy data/labels?\u201d\nIn this work, we assume that SDL is able to learn more effective approximations of derivatives, which are essential elements in physics dynamics, and some noisy factors can be handled by data-driven learning similar to many deep models. We choose graph neural networks for prediction in temperature and the learnable parameters handle the noisy factors and missing physics.\n\n>> \u201c5. Releasing the code and dataset\u201d\nWe will release the code and the dataset upon acceptance."}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gelyrtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1493/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1493/Authors|ICLR.cc/2020/Conference/Paper1493/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155199, "tmdate": 1576860547877, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment"}}}, {"id": "SJg0q7YDjH", "original": null, "number": 2, "cdate": 1573520277688, "ddate": null, "tcdate": 1573520277688, "tmdate": 1573520277688, "tddate": null, "forum": "r1gelyrtwH", "replyto": "S1gtmEPptS", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment", "content": {"title": "Response #2", "comment": "Thank you for your comments and suggestions to improve the paper. Below are our responses to the main points of your comments: \n\n>> \u201cJustification of why this particular parameterization is selected\u201d\nThanks for pointing out the motivation of the form, Eq1. As we mentioned in the draft, the main idea of SDL is to provide \u201cmodulated gradients and Laplacian\u201d which are more effective approximations of the derivatives than the approximation of finite derivatives. Since there are two variables (f_i and f_j) involved in the gradient and Laplacian, it is natural to introduce two learnable parameters. In fact, Eq 1 is a form of affine transform (excluding bias term). The reason why we didn\u2019t follow w1*f_j + w2*f_i, which is more generic, is to distinguish the role of each term. In other words, w^(1) is a scaling term and w^(2) is a differencing term. By doing that, we can enforce some constraints to the learnable parameters (e.g., make 0<w<1 or w is positive, etc.) separately for some purpose and it is easier to see how the constraints affect the derivatives.\n\n\nSeveral confusions or concerns about the synthetic experiments:\n>> \u201c1. Evaluation task and training task\u201d\nThe synthetic experiments (3.1 and 3.2) are under the supervised setting and therefore, the evaluation and training tasks are the same.\n\n>> \u201c1. What does the method generalize?\u201d\nIn terms of the generalization, the SDL generalizes the b setting, New graphs with a similar number of different sampled points. In other words, the method can learn parameters to compute the derivatives from discrete samples and the parameters are still valid for the different but same number of sample points. This generalization is verified by our synthetic experiments in Section 3.1.\n\nFurthermore, if the number of samples is enough, it also generalizes the c setting, New graph with different properties (e.g. more or less sparse). \nWe sampled 400 points and trained SDL as described in Section 3.1, and resampled fewer points (350,300,250,200) to evaluate if SDL generalizes less sparse setting. As the following table shows, MSE increases when fewer sample points are used. However, SDL is able to provide much more accurate gradients even if it is trained under a new graph with different properties. Thus, the results support that SDL is able to generalize the c setting.\n\nMean squared error (10^\u22122) for approximations of directional derivatives.\n+---------------+-------------------+---------------+-------------------+---------------+\n| Functions | FinGrad(350) | SDL(350)  | FinGrad(300) | SDL(300)  |\n| f2(x,y)       |    2.88\u00b10.11    |  1.03\u00b10.09 |    3.42\u00b10.14    | 1.14\u00b10.12 |\n+---------------+-------------------+---------------+-------------------+---------------+\n|                    | FinGrad(250)|  SDL(250)  | FinGrad(200) | SDL(200)  |\n|                    |   3.96\u00b10.17    |  1.40\u00b10.10 |     4.99\u00b10.31    | 1.76\u00b10.10 |\n+---------------+-------------------+---------------+-------------------+---------------+\n\nThe parameters consider the function values at each sampled point and spatial displacement between two points, thus if the dynamics/functions are changed, our parameters won\u2019t be applicable without training on the new dataset.\n\n>> \u201c2. Error bars on the synthetic experiment\u201d\nWe provide the standard deviation for the synthetic experiments in Section 3.1.\n\nTable 1: Mean squared error (10^\u22122) for approximations of directional derivatives.\n+---------------+--------------+---------------+--------------+---------------+--------------+\n| Functions |  FinGrad  |      MLP      |       GN      |   One-w    |      SDL      |\n|  f1(x,y)      | 6.42\u00b10.47 | 2.12\u00b10.32 | 1.05\u00b10.42 | 1.41\u00b10.44 | 0.97\u00b10.39 |\n|  f2(x,y)      | 5.90\u00b10.04 | 2.29\u00b10.77 | 2.17\u00b10.34 | 6.73\u00b11.17 | 1.26\u00b10.05 |\n+---------------+--------------+---------------+--------------+---------------+--------------+\n\nWe provide the standard deviation for the synthetic experiments in Section 3.2.\nWe generated 3 random meshes for the synthetic experiment in Section 3.2 and reported the mean absolute errors of all methods on the graph signal prediction task. Results show that our proposed method outperforms baselines significantly. \n\nTable 2: Mean absolute error (10^\u22122) for graph signal prediction\n+----------------+----------------+------------------+----------------+----------------+\n|       VAR       |      MLP       | StandardOP |   MeshOP   |      SDL       |\n| 16.84\u00b10.41 | 15.75\u00b10.53 |  11.90\u00b10.29  | 12.82\u00b10.06 | 10.87\u00b10.98 |\n+----------------+----------------+------------------+----------------+----------------+\n\n\nMinor comments:\n>> \u201cA related idea\u201d\nThis is a great suggestion. Actually, we are going to work for the applications of SDL and this point will be a possible future direction.\n\n>> \u201cthe type definition of f and F\u201d\nIn Section 2.1, we define f as node feature and F as edge feature. While we believe that the definition is correctly described, if you could point out the contradiction, we will make it clear."}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gelyrtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1493/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1493/Authors|ICLR.cc/2020/Conference/Paper1493/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155199, "tmdate": 1576860547877, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment"}}}, {"id": "H1lB2JFwiS", "original": null, "number": 1, "cdate": 1573519276520, "ddate": null, "tcdate": 1573519276520, "tmdate": 1573519276520, "tddate": null, "forum": "r1gelyrtwH", "replyto": "ByetFVF0tB", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment", "content": {"title": "Response #1", "comment": "Thank you for your comments and suggestions to improve the paper. Below are our responses to the main points of your comments: \n\nWeaknesses:\n>> \u201cA comparison to a graph learning model that is specifically designed for weather forecast\u201d\nIt would be a great comparison if there is a graph-based model specifically designed for a weather forecast. However, to the best of our knowledge, we haven\u2019t found the existing graph-based model particularly designed for climate modeling under the sparsely-observed setting. If you are aware of any references about a graph learning model for weather forecasting, please let us know them.\n\n>> \u201cAdding StandardOP or MeshOP might not help the prediction.\u201d\nIt is a good point that adding not-learnable operators (StandardOP or MeshOP) doesn\u2019t help to reduce the prediction error. The inconsistent behaviors of RGN(StandardOP) and RGN(MeshOP) in Table 3 support the idea that incorporating some incorrect or irrelevant features is little helpful and it can even be harmful. As Section 3.1 shows, the operators having no learnable parameters suffer substantial numerical error under the sparse setting and it causes the diminished prediction power when the operators are used. On the other hand, the consistent prediction power from PA-DGN is the evidence that the physics-inspired features from SDL are significantly helpful and provide a more effective inductive bias.\n\n>> \u201cWhat value for h was used?\u201d\nThanks for pointing out the confusion. Overall, there are two GNNs involved in PA-DGN; (1) GNNs in SDL and (2) GNNs in RGN. For both GNNs, we used h=2. \n\n>> \u201cNecessity of SDL since RGN by itself propagates the signals to neighbors\u201d\nThis is a very good point. Yes, RGN is actually able to do message-passing and it means that it is able to incorporate neighboring features. However, as the expressive power and learning efficiency of data-driven models are highly dependent on its architecture and features extracted from itself, it is still very critical to design proper architecture for efficient learning.\nThe purpose of using SDL is to provide physics-aware representations, which are data-driven spatial derivatives (gradients and Laplacian), instead of using observations directly. In other words, SDL provides a physics-aware inductive bias, which improves the prediction quality.\n\n\nAdditional comments:\n>> \u201cThe motivation of the second (\u2206f)i\u201d\nThe second (\u2206f)i in Section 2.2 is introduced to provide a different form of Laplacian in a triangulated mesh. It is well-known that the second Laplacian (geometric discretizations\nof the Laplacian) has more effective approximation qualities on the mesh. We will update the motivation of the second one in the draft.\n\n>> \u201cLack of explanation of what is train / test set\u201d\nFor the experiment in Section 3.1, we first defined a function on 2D space. Then, we sampled 200 points from the 2D coordinates and built a graph based on k-NN algorithm. As gradients are defined on each edge, we split the available edges as train/validation/test sets. We will update the draft to provide this information clearly.\n\n>> \u201cWhy the setup in Section 3.2 is only similar to PDE-Net?\u201d\nThere are 2 differences between the settings of Equation (8) in Long et al. 2018 and ours. (1) While the coefficients in Long et al. 2018 before the second-order spatial differentiation terms in the partial differential equation are constant, they are from a function of the coordinates of nodes in our setting. This setting increases the dynamics of the generated datasets and makes the prediction task more challenging; (2) In Long et al. 2018, the second-order spatial differentiation terms along x-axis and y-axis have different coefficients, while in ours setting they share the same coefficients. We make this modification to fit the equation on graph-structured data, because the Laplacian term on graphs of sampled nodes is defined as a scalar on nodes instead of having a specific direction.\n\n>> \u201cData split and the problem of learning different seasons\u201d\nThanks for pointing out the data splitting. Yes, we used the first 8 months for training and left months for validation and test. In fact, learning different seasons doesn't matter much since we focus on \"differences\" instead of absolute values. In other words, our model is focusing on how the \"differences\" of physical quantities interact and propagate spatially and temporally, and thus, if the governing physics rules are not significantly changed over the different seasons, it won\u2019t be affected. \nStill, some unique characteristics in the specific months in test/validation sets can\u2019t be seen during the training and they may not be properly handled. While we only have one-year observations, this problem can be handled by yearly splitting, i.e., train a model using a certain year and evaluate it on another year. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gelyrtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1493/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1493/Authors|ICLR.cc/2020/Conference/Paper1493/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155199, "tmdate": 1576860547877, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Authors", "ICLR.cc/2020/Conference/Paper1493/Reviewers", "ICLR.cc/2020/Conference/Paper1493/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Comment"}}}, {"id": "S1gtmEPptS", "original": null, "number": 1, "cdate": 1571808288829, "ddate": null, "tcdate": 1571808288829, "tmdate": 1572972461389, "tddate": null, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a method to reduce numerical error when predicting sequences governed by physical dynamics. The idea is that most physics simulators use finite difference differential operators, and the paper adds trainable parameters to them (the derivative and Laplacian operators). The added parameters are computed by a GNN. The paper concats the original graph feature and the output of the differential operators, and inputs them to a recurrent GNN to obtain the final prediction. \n\nI think the idea is interesting. Incorporating modulated derivative and Laplacian operators into physical simulators is novel and well justified. It could strengthen the argument is there is more justification of why this particular parameterization is selected. \n\nI think the experimental evaluation is somewhat adequate. There are a good selection of baselines including both manually designed iterators and GNNs. In particular, the weather prediction experiment show improved performance over several baselines. I am not familiar with this task or its state-of-the-art performance, but I am convinced that the proposed approach is superior compared to the claimed baselines (RGN, GRU). \n\nI have several confusions or concerns about the synthetic experiments\n\n1. In the synthetic experiments, is the evaluation task different from the training task? It is unclear from the description how well the learned parameters generalize. Does the method generalize to a. New functions/dynamics b. New graphs with similar properties (e.g. another graph draw from the same distribution) c. New graph with different properties (e.g. more or less sparse)? \n\n2. One short-coming of the synthetic experiment is the lack of error bars, or analysis of statistical significance. I think some of the improvements are not large enough to be statistically convincing without additional analysis. It seems necessary to experiment on multiple random problems (e.g. with random meshing, dynamics parameters). \n\nMinor comments:\n\nA related idea is \u201cLearning Neural PDE Solvers with Guarantees\u201d which modulates the finite difference iterative solver with deep networks, but the objective is solving PDEs with known dynamics instead of prediction with unknown dynamics. Conversely, the method the authors proposed seem also useful for speeding up PDE solvers. \n\nI think there is an error in the type definition of f and F in section 2.1. The two claimed types contradict each other.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576376760190, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Reviewers"], "noninvitees": [], "tcdate": 1570237736576, "tmdate": 1576376760201, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review"}}}, {"id": "Bkgw7nNRKH", "original": null, "number": 2, "cdate": 1571863583209, "ddate": null, "tcdate": 1571863583209, "tmdate": 1572972461343, "tddate": null, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose new architectures that simulate difference operators. According to my experience, this research is important since PDEs are the most commonly used form to represent known physical relationships in dynamical systems.  The proposed method has novelty in that it uses advanced machine learning architectures to estimate physically meaningful variables. The authors further investigate how to use the proposed spatial difference layer in two tasks. \nI would suggest improving this research on these aspects: \n1.\tThe proposed method should be evaluated on more datasets. The difference information is used in almost any real-world dynamical systems and thus it would be more convincing to show the effectiveness on diverse applications, e.g., object tracking, the variation of energy and mass across space and time.\n2.\tIt would be interesting to design a test scenario where governing PDEs are known. Is it possible for your method to uncover the relationship of gradients that govern the system?\n3.\tHow sparse the data is? It would be better to have an experiment where data is intentionally hidden to control the sparsity and then evaluate the performance.\n4.\tA side question: In real-world systems, the observations are not only governed by PDE, but also unknown noisy factors, missing physics, etc. Can your method handle the noisy data/labels?\n5.\tThe proposed method has some complex components. I would encourage releasing the code and the simulated dataset upon acceptance. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576376760190, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Reviewers"], "noninvitees": [], "tcdate": 1570237736576, "tmdate": 1576376760201, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review"}}}, {"id": "ByetFVF0tB", "original": null, "number": 3, "cdate": 1571882113171, "ddate": null, "tcdate": 1571882113171, "tmdate": 1572972461295, "tddate": null, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "invitation": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper considers the problem of predicting node and/or edge attributes in a physics-governed system, where we have access to measurement data on discrete sensor locations. In contrast to other methods, they explore the usefulness of a Spatial Difference Layer (SDL) that learns a representation of the gradients on the edges and the Laplacian on the nodes, where the parameters to create those operators are learnable weights. The SDL layer is concatenated with the original graph and fed into a recurrent graph network (RGN) to predict node and/or edge properties. \n\nStrengths:\n- This research is very relevant for physics inspired machine learning, since many physical systems are governed by underlying differential equations.\n- The authors show on synthetic data experiments that SDL is capable of representing the derivatives of a physical system.\n- Real world use case for temperature prediction is presented with encouraging results.\n\nWeaknesses:\n- While comparison to RGN represents a rather strong benchmark, it would be interesting to see a comparison to a graph learning model that is specifically designed for weather forecast.\n- Just adding the Spatial Difference Layer using numerical methods (method RGN(StardardOP) and RGN(MeshOP)) can diminish prediction power for a long time horizon. This result suggests that those gradients might not help the prediction.\n- The inclusion of an h-hop neighborhood is not quite clear. What value for h was used in the experiments? Is this really necessary, when RGN by itself propagates the signal to neighbors that are further away?\n\nAdditional comments:\n- 2.1 and 2.2: On first reading, it's a bit confusing why there are two different equations for (\u2206f)i. The motivation of the second equation should be made more explicit.\n- 3.1 lacks explanation of what is train / test set, which is given only in the appendix. This is critical information to understand the use cases of the model and should definitely be in the main body.\n- In 3.2 formatting of a(i), b(i) and c(i) is confusing. Why is the setup only similar to Long et al? It would be nice to point out the differences and explain why it wasn't exactly the same.\n- 4.1: Was the train/validation/test split done in contiguous segments? I.e. are the 8 months of training data January to August? How is the problem of learning different seasons handled?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1493/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": ["Sungyong Seo*", "Chuizheng Meng*", "Yan Liu"], "authorids": ["sungyons@usc.edu", "chuizhem@usc.edu", "yanliu.cs@usc.edu"], "keywords": ["physics-aware learning", "spatial difference operators", "sparsely-observed dynamics"], "TL;DR": "We propose physics-aware difference graph networks designed to effectively learn spatial differences to modeling sparsely-observed dynamics.", "abstract": "Sparsely available data points cause numerical error on finite differences which hinders us from modeling the dynamics of physical systems. The discretization error becomes even larger when the sparse data are irregularly distributed or defined on an unstructured grid, making it hard to build deep learning models to handle physics-governing observations on the unstructured grid. In this paper, we propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which exploits neighboring information to learn finite differences inspired by physics equations. PA-DGN leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. We demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.", "pdf": "/pdf/1e51db539dfe61a208b8a4b251f40a97f2eaa720.pdf", "paperhash": "seo|physicsaware_difference_graph_networks_for_sparselyobserved_dynamics", "code": "https://github.com/USC-Melady/ICLR2020-PADGN", "_bibtex": "@inproceedings{\nSeo*2020Physics-aware,\ntitle={Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics},\nauthor={Sungyong Seo* and Chuizheng Meng* and Yan Liu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gelyrtwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/2c26f85f401574696cf5b37cdc26acd1c289dc41.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gelyrtwH", "replyto": "r1gelyrtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576376760190, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1493/Reviewers"], "noninvitees": [], "tcdate": 1570237736576, "tmdate": 1576376760201, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1493/-/Official_Review"}}}], "count": 9}