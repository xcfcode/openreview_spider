{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396365019, "tcdate": 1486396365019, "number": 1, "id": "B1SRjML_g", "invitation": "ICLR.cc/2017/conference/-/paper115/acceptance", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "While the reviewers saw some value in your contribution, there were also serious issues, so the paper does not reach the acceptance threshold."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396365520, "id": "ICLR.cc/2017/conference/-/paper115/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396365520}}}, {"tddate": null, "tmdate": 1482459765256, "tcdate": 1482459765256, "number": 3, "id": "H16OqZ5Vl", "invitation": "ICLR.cc/2017/conference/-/paper115/official/review", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer3"], "content": {"title": "Not clear. The approach and methodology are not explained.", "rating": "3: Clear rejection", "review": "This paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks.\n\nRandom networks (deep networks with random Gaussian weights, hard tanh or ReLU activation) are studied according to several criterions: number of neutron transitions, activation patterns, dichotomies and trajectory length.\n\nThere doesn't seem to be a solid justification for why the newly introduced measures of expressivity really measure expressivity.\nFor instance the trajectory length seems a very discutable measure of expressivity. The only justification given for why it should be a good measure of expressivity is proportionality with other measures of expressivity in the specific case of random networks.\n\nThe paper is too obscure and too long. The work may have some interesting ideas but it does not seem to be properly replaced in context.\n\nSome findings seem trivial.\n\ndetailed comments\n\np2 \n\n\"Much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide\"\n\nI don\u2019t think so. In \"Deep Belief Networks are Compact Universal Approximators\" by Leroux et al., proof is given that deep but narrow feed-forward neural networks with sigmoidal units can represent any Boolean expression i.e. A neural network with 2n\u22121 + 1 layers of n units (with n the number of input neutron).\n\n\u201cComparing architectures in such a fashion limits the generality of the conclusions\u201d\n\nTo my knowledge much of the previous work has focused on mathematical proof, and has led to very general conclusions on the representative power of deep networks (one example being Leroux et al again).\n\nIt is much harder to generalise the approach you propose, based on random networks which are not used in practice.\n\n\u201c[we study] a family of networks arising in practice: the behaviour of networks after random initialisation\u201d\n\nThese networks arise in practice as an intermediate step that is not used to perform computations; this means that the representative power of such intermediate networks is a priori irrelevant. You would need to justify why it is not.\n\n\u201cresults on random networks provide natural baselines to compare trained networks with\u201d\n\nrandom networks are not \u201cnatural\u201d for the study of expressivity of deep networks. It is not clear how the representative power of random networks (what kind of random networks seems an important question here) is linked to the representative power of (i) of the whole class of networks or (ii) the class of networks after training. Those two classes of networks are the ones we would a priori care about and you would need to justify why the study of random networks helps in understanding either (i) or (ii).\n\np5\n\n\u201cAs FW is a random neural network [\u2026] it would suggest that points far enough away from each other would have independent signs, i.e. a direct proportionality between the length of z(n)(t) and the number of times it crosses the decision boundary.\u201d\n\nAs you say, it seems that proportionality of the two measures depends on the network being random. This seems to invalidate generalisation to other networks, i.e. if the networks are not random, one would assume that path lengths are not proportional.\n\np6\n\nthe expressivity w.r.t. remaining depth seems a trivial concerns, completely equivalent to the expressivity w.r.t. depth. This makes the remark in figure 5 that the number of achievable dichotomies only depends *only* on the number of layers above the layer swept seem trivial\n\np7\n\nin figure 6 a network width of 100 for MNIST seems much too small. Accordingly performance is very poor and it is difficult to generalise the results to relevant situations.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512693094, "id": "ICLR.cc/2017/conference/-/paper115/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper115/AnonReviewer2", "ICLR.cc/2017/conference/paper115/AnonReviewer1", "ICLR.cc/2017/conference/paper115/AnonReviewer3"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512693094}}}, {"tddate": null, "tmdate": 1482219821974, "tcdate": 1482219821974, "number": 9, "id": "rkINbPUEx", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "HyDtpy8Vx", "signatures": ["~Jascha_Sohl-Dickstein2"], "readers": ["everyone"], "writers": ["~Jascha_Sohl-Dickstein2"], "content": {"title": "Re: Generic Weights", "comment": "I think this is important, so I want to contribute an additional followup.\n\nIn our paper we use generic to mean that a property applies for \"typical\" or \"average case\" parameters. We then define \"average case\" for our specific results -- usually as an expectation over deep networks with weights drawn from a Gaussian.\n\nYou are defining generic to mean within an epsilon ball of hand chosen parameters. Under this definition of generic, I agree that your assesment of previous work is correct. However, this usage of generic is nearly the opposite of its colloquial usage. For instance, using this modified definition of generic: I have a very specific image, of an adorable puppy. If you slightly perturb the pixels in this image, it will still be of my puppy. Therefore, \"this image is of my puppy\" is a statement that holds for \"generic\" images. If you generate a new \"generic\" image, you can happily expect it to also have this property, and be of my puppy.\n\nWe are rather interested in the generic (now meaning \"typical\") behavior of neural networks, since we are interested in predicting properties of neural networks that can be expected to occur in practice after initialization and during training, rather than just in carefully constructed scenarios. Continuing with the image example, under this definition some generic properties of images would be their power-law falloff in fourier magnitude with frequency, and the existence of oriented edges.\n\nThank you again for taking the time to carefully review our work.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1482191680906, "tcdate": 1482191680906, "number": 8, "id": "HkFHQeIEe", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "HyDtpy8Vx", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Re: Generic Weights", "comment": "Apologies for the confusion-- of course perturbing after a particular choice of weights means that we have a set of measure > 0 (some epsilon ball say) for which this property holds.\n\nBut this still requires that one lands in that epsilon ball to get that number of linear regions, and it is unclear how many such epsilon balls there are (discounting the permutations of the existing construction) and how \"close\" they are to the typical starting point (after random initialization) of a neural network.\n\nOur use of the word \"generic\" was to indicate that we do away with having to think about such a specific construction, and show that even by drawing weights iid centered around 0, we *still* end up with exponential growth with depth."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1482190206714, "tcdate": 1482190206714, "number": 1, "id": "HyDtpy8Vx", "invitation": "ICLR.cc/2017/conference/-/paper115/official/comment", "forum": "B1TTpYKgx", "replyto": "BJlKsASVe", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "content": {"title": "Generic weights ", "comment": "Kindly note that a property holds for `generic weights' when this property still holds after perturbing a particular choice of the weights, which is precisely what you write. \nRoughly speaking this means that the property holds in a region of parameters which has a positive volume. \nThe actual size of this region will of course depend on how one measures the space, as does the expectation value. \nMeasuring the space of parameters with respect to a normal distribution is one possibility which also can be interpreted in terms of perturbations around the mean. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721858, "id": "ICLR.cc/2017/conference/-/paper115/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721858}}}, {"tddate": null, "tmdate": 1482185592209, "tcdate": 1482185592209, "number": 7, "id": "BJlKsASVe", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "rJRzy9B4l", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Response to AnonReviewer1", "comment": "Thank you for your careful reading, and specific feedback! We are working to improve the paper based on your suggestions. Some responses to specific points follow below:\n\n***\"In particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \"\n\nThis is untrue. In [Montufar et al, 2014], in Lemma 2 they put a lower bound on the *maximum* number of linear regions that can be achieved by adjusting weights. They also discuss in the text how weights can be perturbed, even for a network with an exponential number of linear regions, without changing the number of linear regions. Nowhere do they establish bounds on the expected number of linear regions for generic weights.\n\n\n***\"One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data.\"\n\nThank you for the connection. We actually discuss this in Appendix D.1, and will improve the reference to this discussion in the text. As you note, the literature on VC dimension typically takes a negative view of complexity, and treats it as a measure of how badly a class of functions could overfit to the training data. In this paper we take an opposite perspective, and instead treat complexity as a measure of how powerful and flexible a class of functions is, which is a view adopted from the combinatorial literature on the Sauer-Shelah lemma.\n\n\n***\"On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\"\n\nInterpreting the increase in trajectory length as the result of a composition a*a*a..*x is important, but only part of the whole picture. As we examine hard tanh, there is another  competing factor, which is whether neurons are saturated or not -- if neurons are saturated, then we cannot expect a perturbation to experience exponential growth and hence the trajectory itself will not grow.\n\nFrom the outset, it is unclear which of these will win out. But it turns out that even with saturation effects, the composition effects are enough to cause trajectory growth.\n\nThe reviewer is correct in that the increase of transitions is not due to this alone -- it also has to do with autocorrelation length, which also decreases exponentially (explored further in https://arxiv.org/abs/1606.05340). The only (mild) condition we need on the trajectory for this to be true is that the tangent vector must have a perpendicular component to the current point. (So for the proof to go through, it can't be a line from the origin.) \n\n\n***\"In Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see https://en.wikipedia.org/wiki/Big_O_notation). \n- It would be helpful to mention that the expectation is being taken with respect to the network weights and that these are normally distributed with variance \\sigma.\"\n\nThank you for these suggestions! We are making all of these changes (differentiable everywhere is not required.)\n\n\n***\"- Theorem 2. Here it would be good to be more specific about the kind of sign transitions. Is this about transitions at any units of the network, or about sign transitions at the scalar output of the entire network. \"\n\nThe theorem as stated is for the expected number of transition of the readout neuron in an n-layer network. The same relationship holds for any neuron in the network, as a function of that neuron's depth. We are clarifying this in the text.\n\n\n***\"- Theorem 3 is quite trivial. \"\nNote that Theorem 3 states that activation patterns of the *entire network* subdivide input space into convex polytopes! See Figure 3 for an illustration of this. We have found in conversation that our colleagues find it obvious that a single layer in a deep network subdivides the layer immediately below into convex polytopes, but are typically surprised to discover that the pattern of activity across all layers of the network subdivides input space into convex polytopes.\n\n\n***\"The bijection between transitions and activation patterns is not clear. \nTake a regular n-gon in the plane and a circle that crosses each edge twice. \nThis makes 2n transitions but only n+1 activation patterns.\"\n\nThis was stated and proved as only true for affine trajectories in the appendix but we will clarify this further in the text -- thank you for pointing it out!\n\n\n***\"- Theorem 4. \nWhere is the proof of this statement? \nHow does this relate to the simple fact that each activation pattern corresponds to the vector indicating the units that are `active'? \"\n\nThe proof of theorem 4 follows after the proof of theorem 6 in the appendix -- apologies that this was not more clearly marked before, but theorem 4 follows readily from the proof of theorem 3 and the statement of theorem 6.\n\nThis theorem gives an asymptotically tight bound on how many such unique vectors we can expect from a real neural network. The naive bound would be 2^(number of neurons) - so in our case, 2^(kn + m). But all of these combinations are not possible. E.g. if we trace a line in our input space and look at the on off pattern of the first hidden layer, each unit can only switch from on to off (or vice versa), *once*. So we get k different patterns, not 2^k.\n\n\nMINOR COMMENTS\n\"On page 19. Theorem 6. As far as I remember Stanley also provides an elementary proof of case with hyperplanes in general position. Many other works also provide elementary proofs using the same induction arguments in what is known as the sweep hyperplane method.\"\n\nStanley's proof method uses intersection posets to prove Zaslavsky's theorem a special case of which gives the bound in general position. At the time of writing, the authors were unable to find an elementary proof of this theorem.\n\n\nWe will make all the other changes you suggest in MINOR COMMENTS. Thank you again for your careful reading and actionable suggestions!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1482166038161, "tcdate": 1482166038161, "number": 2, "id": "rJRzy9B4l", "invitation": "ICLR.cc/2017/conference/-/paper115/official/review", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "content": {"title": "Review of ``ON THE EXPRESSIVE POWER OF DEEP NEURAL NETWORKS''", "rating": "6: Marginally above acceptance threshold", "review": "SUMMARY \nThis paper studies the expressive power of deep neural networks under various related measures of expressivity. \nIt discusses how these measures relate to the `trajectory length', which is shown to depend exponentially on the depth of the network, in expectation (at least experimentally, at an intuitive level, or theoretically under certain assumptions). \nThe paper also emphasises the importance of the weights in the earlier layers of the network, as these have a larger influence on the represented classes of functions, and demonstrates this in an experimental setting. \n\nPROS \nThe paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions, in particular elaborating on the relations between various points of view. \n\nCONS \nThe paper further advances and elaborates on interesting topics, but to my appraisal it does not contribute significantly new aspects to the discussion. \n\nCOMMENTS\n- The paper is a bit long (especially the appendix) and seems to have been written a bit in a rush. \nOverall the main points are presented clearly, but the results and conclusions could be clearer about the assumptions / experimental vs theoretical nature. \nThe connection to previous works could also be clearer. \n\n- On page 2 one finds the statement ``Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values -- a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.'' \n\nThis is partially true, but it neglects important parts of the discussion conducted in the cited papers. \nIn particular, the paper [Montufar, Pascanu, Cho, Bengio 2014] discusses not one hard coded function, but classes of functions with a given number of linear regions. \nThat paper shows that deep networks generically* produce functions with at least a given number of linear regions, while shallow networks never do. \n* Generically meaning that, after fixing the number of parameters, any function represented by the network, for parameter values form an open, positive -measure, neighbourhood, belongs to the class of functions which have at least a certain number of linear regions. \nIn particular, such statements can be directly interpreted in terms of networks with random weights. \n\n- One of the measures for expressivity discussed in the present paper is the number of Dichotomies. In statistical learning theory, this notion is used to define the VC-dimension. In that context, a high value is associated with a high statistical complexity, meaning that picking a good hypothesis requires more data. \n\n- On page 2 one finds the statement ``We discover and prove the underlying reason for this \u2013 all three measures are directly proportional to a fourth quantity, trajectory length.'' \nThe expected trajectory length increasing exponentially with depth can be interpreted as the increase (or decrease) in the scale by a composition of the form a*...*a x, which scales the inputs by a^d. Such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions. Here it seems that at least the assumptions on the considered types of trajectories also play an important role. \nThis is probably related to another observation from page 4: ``if the variance of the bias is comparatively too large... then we no longer see exponential growth.''\n\nOTHER SPECIFIC COMMENTS \nIn Theorem 1 \n- Here it would be good to be more specific about ``random neural network'', i.e., fixed connectivity structure with random weights, and also about the kind of one-dimensional trajectory, i.e., finite in length, closed, differentiable almost everywhere, etc. \n\n- The notation ``g \\geq O(f)'' used in the theorem reads literally as |g| \\geq \\leq k |f| for some k>0, for large enough arguments. It could also be read as g being not smaller than some function that is bounded above by f, which holds for instance whenever g\\geq 0. \nFor expressing asymptotic lower bounds one can use the notation \\Omega (see https://en.wikipedia.org/wiki/Big_O_notation). \n\n- It would be helpful to mention that the expectation is being taken with respect to the network weights and that these are normally distributed with variance \\sigma. \n\n- Theorem 2. Here it would be good to be more specific about the kind of sign transitions. Is this about transitions at any units of the network, or about sign transitions at the scalar output of the entire network. \n\n- Theorem 3 is quite trivial. \nThe bijection between transitions and activation patterns is not clear. \nTake a regular n-gon in the plane and a circle that crosses each edge twice. \nThis makes 2n transitions but only n+1 activation patterns. \n\n- Theorem 4. \nWhere is the proof of this statement? \nHow does this relate to the simple fact that each activation pattern corresponds to the vector indicating the units that are `active'? \n\n\nMINOR COMMENTS\n- The names of the theorems (e.g. ``Bound on ...'' in Theorem 1) could be separated more clearly from the statements, for instance using bold font, a dot, or parentheses. \n- On page 4, in Latex one can use \\gg for the `much larger' symbol. \n- On page 4, explain the notation \\delta z_\\orth.  \n- On page 4, explain that ``latent image'' refers to the image in the last layer. \n- Why are there no error bars in Figure 2?  \n- On page 5 explain that the hyperplane is in the last hidden layer. \n- On page 5, ``is transitioning for any input''. This is not clearly stated, since a transition takes place at a point in a trajectory of inputs, not for a single input. \n- The y-axis labels in Figure 1 (c) and (d) are too small. \n- Why are there no error bars in Figure 1 (a) and (b)? The caption could at least mention that shown are the averages over experiments. \n- In Figure 4 (b) the curves are occluded by the labels. \n- The numbering of results is confusing. In the Appendix some numbers are repeated with the main part and some are missing. \n- On page 19. Theorem 6. As far as I remember Stanley also provides an elementary proof of case with hyperplanes in general position. Many other works also provide elementary proofs using the same induction arguments in what is known as the sweep hyperplane method. \n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512693094, "id": "ICLR.cc/2017/conference/-/paper115/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper115/AnonReviewer2", "ICLR.cc/2017/conference/paper115/AnonReviewer1", "ICLR.cc/2017/conference/paper115/AnonReviewer3"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512693094}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1482083111925, "tcdate": 1478233540693, "number": 115, "id": "B1TTpYKgx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "B1TTpYKgx", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "content": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482083090253, "tcdate": 1482083090253, "number": 6, "id": "B1qzir4Eg", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "SkamR1QNe", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Updated version with easier to follow proofs of Theorems 2, 4", "comment": "In response to Reviewer2's helpful comments, we've submitted a revision with easier to read proofs of Theorems 2, 4.\n\nThank you very much for the constructive comments!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1481993795666, "tcdate": 1481993765430, "number": 5, "id": "SkamR1QNe", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Response to Reviewer2", "comment": "Thank you for the review! We will take the comments into account and endeavour to make the text even clearer.\n\nA quick comment about motivation: our goal in this work improve interpretability in deep neural networks through a better understanding of neural network expressivity. In particular, we look at different \"diagnostics\" (transitions/activation patterns/dichotomies) for measuring the expressiveness of different neural network architectures, and their practical consequences. The surprising fact that three natural measures of expressiveness are related by *direct* proportion (see below) to trajectory length suggests consequences on remaining depth (earlier parameters are more important to fit the final function) and a trade off between expressivity and stability during training due to initialization choices.  \n\nResponses inline to other specific comments below:\n\nTrajectory Length: We will add this as a definition before Theorem 1. We take a 1-d trajectory to be a 1-d curve in the high dimensional space, and we measure the length  -- https://en.wikipedia.org/wiki/Arc_length -- of its images in the latent spaces.\n\nComment: \"As a consequence of this study authors suggest\"\nResponse: In addition to the results suggesting that training earlier layers is important (as the network is especially sensitive to perturbations in the earlier layers) we also examine how different initializations cause the network to trade off between expressivity and stability (figures 8,9.) Further investigation into the \"optimal\" (least trajectory growth/shrinkage required) could result in faster convergence.\n\nComment: \"The relation to transition numbers is in term of the growth factor, and not as a quantity to quantity relationship\"\nResponse: The relation *is* a quantity to quantity relationship -- confusion might have been caused as due to the direct proportionality relationship, the growth rates are also naturally related. The *direct* proportionality between transitions and trajectory length intuited by the paragraph below Observation 1, and then demonstrated empirically by Figure 2. \n\nFigure 2 shows trajectory length and transitions for networks of different depths, widths and initialization (this might be made clearer by plotting each result as a separate point, and we are sorry if that line plot might be a source of confusion.) We find that the number of transitions are equal to the trajectory length (the quantity by quantity relationship) divided by a constant (approximately sigma_w/sqrt(k)).\n\nFigure 10 also shows a direct proportion between transitions and dichotomies, and so the take away conclusion is that measuring trajectory length growth for different architectures immediately indicates the approximate values of other expressivity measures on those architectures.\n\nComment: \"The geometry of the input set (of dimension m)  shows up only weakly in the activation patterns analysis.\"\nResponse: The activation pattern analysis is a general result, looking at any high dimensional input space (R^m, some m) and giving a novel result on how the hidden layers of the network *hierarchically* carve up the space into convex polytopes. The input dimension is an important part, as the upper bound on the number of regions is shown to be asymptotically tight by the construction in https://arxiv.org/abs/1402.1869 \n\nComment: \"What does theorem 1 tells us about the design and the architecture to use in neural networks as promised in the introduction is not clear\"\nResponse: Theorem 1 proves a growth rate for trajectory length, and as trajectory length is directly proportional to the other measures of expressivity, it suggests that a deeper network is more expressive (and therefore has inherent capacity to fit data better) than a shallow network. This method of analysis helps generalize the benefit of depth described in e.g. https://arxiv.org/abs/1512.03965, https://arxiv.org/abs/1402.1869, etc\n\n\nComment: \"The connection to transitions in Theorem 2 is rather weak\"\nResponse: Theorem 2 has a precise connection to the number of transitions one could expect in a network of a certain depth and width in the large weight initialization regime. The proof (in more detail below) shows that the bound given by Theorem 1 on trajectory length is *exact* (up to a constant) in the number of transitions for such a network.\n\nComment: Comments on proof of Theorem 2\nResponse: Thank you for the constructive comments! We will state notation beforehand to make this proof clearer. As noted, T is a random variable (for layer d+1) and t is a fixed value (of number of transitions in the previous layer.) The expectation is taken with respect to the weights right before the neurons in layer d (so W^(d)) as that determines the number of neuron transitions in layer d+1, and we get the expected number of transitions in layer d+1 given the number of transitions in layer d.\n\nThe recursion is indeed for d+1 > 1 (so d the first hidden layer onwards), and we will make that clearer. (This is what enables us to assume that the input is saturated, and has absolute value 1.) \n\nFor the input layer, where W \\in \\mathbb{R}^{k\\times m}, note that the initialization scale is slightly different -- as is standard in practice, the initialization is N(0, sigma_w^2/input_dim). In the second hidden layer on, the input dim is k, but in the first hidden layer, the input dim is = m, and so this difference is taken into account.\n\nComment: Proof of Theorem 4\nResponse: Thank you for the comment, we will make this clearer. Theorem 4 can be derived quickly after Theorem 6 is proved, and the connection is thus stated immediately after Theorem 6, but could be made clearer! In more detail:\nWe show (theorem 6) that k hyperplanes in R^m result in r(k,m) regions, which is <= O(k^m) (sum of binomial coefficients).\nSo, the first hidden layer of the deep neural network carves up input space into r(k,m) regions <= O(k^m).\nConsider the second hidden layer  -- this has a different hyperplane arrangement for *every* region created by the first hidden layer (which has at most r(k,m) regions). \nSo, in total, there are r(k,m)*r(k,m) (number of regions created by first layer*number of regions created by second layer in each region of first layer.). \nContinuing in this way, for a network with n hidden layers, there are at most r(k,m)*n <= O(k^mn) regions total, giving the result in Theorem 4.\nThanks again for the comments, and we will update the paper making this clearer!\n\nComment: Figures 8 and 9\nResponse: Thank you for the related link! Actually, it is not a straightforward contraction that happens, because plotting the weight norms during training shows that the weight norms don't change *too* much. We suspect the network is changing the exact point in parameter space to result in less of an expansion.\n\nOther trajectories besides circular were tried (and the theory holds for most trajectories) and similar results were observed. We can include more plots if this would help?\n\nBoth cases (same/different labels) were tried, with similar results.\n\nThanks again for the detailed comments, and we will incorporate them in the next version to address them!\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1481832604724, "tcdate": 1481823295880, "number": 1, "id": "Hk_SELg4x", "invitation": "ICLR.cc/2017/conference/-/paper115/official/review", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer2"], "content": {"title": "Interesting ideas on the trajectory lengths, the motivations and the conclusion of the study are not clear ", "rating": "5: Marginally below acceptance threshold", "review": "Summary of the paper:\n\nAuthors study in this paper quantities related to the expressivity of neural networks.The analysis is done for a random network. authors define the \u2018trajectory length\u2019 of a one dimensional trajectory as the length of the trajectory as the points (in a m- dimensional space) are embedded by layers of the network. They provide growth factors as function of hidden units k, and number of layers d.  the growth factor is exponential in the number of layers. Authors relates this trajectory length to authors quantities : \u2018transitions\u2019,\u2019activation patterns \u2019 and \u2018Dichotomies\u2019. \nAs a consequence of this study authors suggest that training only  earlier layers in the network  leads higher accuracy then just training later layers. Experiments are presented on MNIST and CIFAR10.\n\nClarity:\n\nThe  paper is a little hard to follow, since  the motivations are not clear in the introduction and the definitions across the paper are not clear. \n\nNovelty:\n\nStudying the trajectory length as function of transforming the data by a multilayer network is   new and interesting idea. The relation to transition numbers is in term of the growth factor, and not as a quantity to quantity relationship. Hence it is hard to understand what are the implications.\n\nSignificance:\n\nThe geometry of the input set (of dimension m)  shows up only weakly in the activation patterns analysis.  The trajectory study should tell us how the network organizes the input set. As observed in the experiments the network becomes contractive/selective as we train the network. It would be interesting to study those phenomenas using this trajectory length , as a measure for disentangling nuisance factors ( such as invariances etc.). In the supervised setting the network need not to be contractive every where , so it needs to be selective to the class label, a  theoretical study of the selectivity and contraction using the trajectory length would be more appealing.\n\nDetailed comments:\n\nTheorem 1:\n\n- As raised by reviewer one the definition of a one dimensional input trajectory is missing. \n- What does theorem 1 tells us about the design and the architecture to use in neural networks as promised in the introduction is not clear. The connection to transitions in Theorem 2 is rather weak. \n\nTheorem 2:\n\n- in the proof of theorem 2 it not clear what is meant by T and t. Notations are confusing, the expectation is taken with respect to which weight: is it W_{d+1} or (W_{d+1} and W_{d})? I understand you don't want to overload notation but maybe E_{d+1} can help keeping track. I don't see how the recursion is applied if T and t in it, have different definitions. seems T_{d+1} for you is a random variable and t_{d} is fixed. Are you fixing W_d and then looking at W_{d+1} as  random?\n\n- In the same proof:  the recursion  is for d>1  ? your analysis is for W \\in R^{k\\times k}, you don't not study the W \\in \\mathbb{R}^{k\\times m}. In this case you can not assume assume that |z^(0)|=1.\n\n- should d=1, be analyzed alone to know how it scales with m?\n\nTheorem 4 in main text:\n\n- Is the proof missing? or Theorem 4 in the main text is Theorem 6 in the appendix?\n\nFigures 8 and 9:\n\n- the trajectory length reduction in the training isn't that just the network becoming contractive to enable mapping the training points to the labels? See for instance  on contraction in deep networks https://arxiv.org/pdf/1601.04920.pdf\n\n- How much the plot depends on the shape of the trajectory? have you tried other then circular trajectory?\n\n- In these plots the 2 mnist points had same label ? or different label?  both cases should be studied, to see the tradeoff between contraction and selectivity to the class label.\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512693094, "id": "ICLR.cc/2017/conference/-/paper115/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper115/AnonReviewer2", "ICLR.cc/2017/conference/paper115/AnonReviewer1", "ICLR.cc/2017/conference/paper115/AnonReviewer3"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512693094}}}, {"tddate": null, "tmdate": 1481219068961, "tcdate": 1481219068954, "number": 4, "id": "H1BW2Mvmg", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "HkXrqHy7e", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Response to trajectory and random networks questions", "comment": "Thank you very much for your questions! We will endeavor to make these terms clearer in the paper.\n\nCircular trajectory: we pick points x_0, x_1 in the high dimensional space, and look at the curve x_0 cos(theta) + x_1 sin(theta) as theta varies between 0 and pi/2.\n\nNon-zero magnitude perpendicular to x(t): Yes, exactly (we will add this to the statement to make it clearer.) To perform the analysis used in the theorem, we focus on an independent component by looking at the perpendicular, so for this proof, we need some non-zero perpendicular component.\n\nRandom neural network: In theorem 1, the network architecture (depth, width) is fixed, and we draw the weights from the initialization distribution (so weights are random). Note that the statement of theorem 1 is in expectation, and the expectation is taken over the weights (i.e. taken over the initialization distribution for the weights.)\n\nThe one dimensional trajectory: we are looking at finite length trajectories (as we want to e.g. interpolate between different data points), but we don't require the trajectory to be differentiable. \n\nHope this is helpful!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1481197614683, "tcdate": 1481197614677, "number": 3, "id": "SkwEuT8Ql", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "H1Iu6D1Qx", "signatures": ["~Maithra_Raghu1"], "readers": ["everyone"], "writers": ["~Maithra_Raghu1"], "content": {"title": "Response to questions", "comment": "Thank you for your comments and questions.\n\nThe paper summary is correct (though our motivation was more to study expressivity via function complexity than the other way around), and we have three measures of functional complexity that we study for different architectures, before, during and after training.\n\nRegarding the choice of weight variances: we broadly had two different types of experiments:\n1) Experiments on the network after random initialization, which we used to verify that the theoretical results also held empirically.\n2) Experiments studying the network during and after training to study how the results for random networks apply during and after training\n\nAs the theory (Theorem 1) predicts behavior for all values of sigma, the first type of experiments (Figures 1, 2) were carried out for many different values of sigma. Other experiments in the first type (Figure 4, 5) were run for many different values of sigma, but for ease of display, one was chosen (e.g. sigma2 = 8) to be the plot in the paper. The results also hold for all sigma in the exponential regime. We would be happy to include more/different plots if this would be helpful! \n\nFor the second kind of experiments, again, many different values of sigma were tested, and one was chosen for display in the paper. For Figures 6,7 we wanted to demonstrate that remaining depth is an important consideration even for smaller sigma, and for figures 8, 9 , we chose sigma2 = 3 and sigma2 = 16 as representatives of the two different regimes for training. Other weight variances could also be chosen here.\n\nPage 2: Suppose there are two neural networks, f1 and f2. A common way to compare them is to pick a specific set of values for the weights of f1, and show that for those *specific* values, f2 doesn't have weight values that let it approximate f1 well. From this type of result however, it's hard to conclude that f1 is better than f2 just because *one* function of f1 (which is often artificially constructed) is not able to be approximated well by f2. This was part of the motivation to start with random initialization."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1480715629923, "tcdate": 1480715629917, "number": 2, "id": "H1Iu6D1Qx", "invitation": "ICLR.cc/2017/conference/-/paper115/pre-review/question", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer3"], "content": {"title": "sigma", "question": "your papers proposes a proxy for function complexity (which you call expressivity)\n\nYou then study how function complexity changes with the number of layers and with training.\n\nIn several of you experiments, you seem to change the weight variance a lot.\n - Why are the weight variances in your experiments much larger than what would usually be found at the beginning or the end of training a real, useful network ?\n - One experiments (Fig 2) test several variance values values, another uses sigma2 = 8, another sigma2=2, then you switch to sigma1, then sigma2=16 and finally sigma2=3. These values seem very arbitrary, what is their significance ?\n\n\nPage 2, what do you mean by \"Furthermore, architectures are often compared via \u2018hardcoded\u2019 weight values \u2013 a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another.\"\n\n\n\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959454513, "id": "ICLR.cc/2017/conference/-/paper115/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper115/AnonReviewer1", "ICLR.cc/2017/conference/paper115/AnonReviewer3"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959454513}}}, {"tddate": null, "tmdate": 1480706619341, "tcdate": 1480706619336, "number": 1, "id": "HkXrqHy7e", "invitation": "ICLR.cc/2017/conference/-/paper115/pre-review/question", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper115/AnonReviewer1"], "content": {"title": "notation, definitions", "question": "Kindly explain ``circular trajectory is chosen between two random vectors''. \nAlso ``non-zero magnitude perpendicular to x(t)''. Is this saying that the curve is not a ray from the origin?  \nIn Theorem 1, random neural network means a fixed network with random weights? \nThe one dimensional trajectory is meant finite in length, differentiable? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959454513, "id": "ICLR.cc/2017/conference/-/paper115/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper115/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper115/AnonReviewer1", "ICLR.cc/2017/conference/paper115/AnonReviewer3"], "reply": {"forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper115/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959454513}}}, {"tddate": null, "tmdate": 1479006430448, "tcdate": 1479006430443, "number": 2, "id": "HyLkYIHbg", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "S1d1pIRle", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "ICLR Paper Format", "comment": "Thanks for pointing out! Done now."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}, {"tddate": null, "tmdate": 1478554498600, "tcdate": 1478548703948, "number": 1, "id": "S1d1pIRle", "invitation": "ICLR.cc/2017/conference/-/paper115/public/comment", "forum": "B1TTpYKgx", "replyto": "B1TTpYKgx", "signatures": ["~Tara_N_Sainath1"], "readers": ["everyone"], "writers": ["~Tara_N_Sainath1"], "content": {"title": "ICLR Paper Format", "comment": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font type for your submission to be considered. Thank you!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Expressive Power of Deep Neural Networks", "abstract": "We study the expressive power of deep neural networks before and after\ntraining. Considering neural nets after random initialization, we show that\nthree natural measures of expressivity all display an exponential dependence\non the depth of the network. We prove, theoretically and experimentally,\nthat all of these measures are in fact related to a fourth quantity, trajectory\nlength. This quantity grows exponentially in the depth of the network, and\nis responsible for the depth sensitivity observed. These results translate\nto consequences for networks during and after training. They suggest that\nparameters earlier in a network have greater influence on its expressive power\n\u2013 in particular, given a layer, its influence on expressivity is determined by\nthe remaining depth of the network after that layer. This is verified with\nexperiments on MNIST and CIFAR-10. We also explore the effect of training\non the input-output map, and find that it trades off between the stability\nand expressivity of the input-output map.", "pdf": "/pdf/13029099cee636443454372dd3471bf701e74616.pdf", "TL;DR": "Derives and explains the exponential depth sensitivity of different expressivity measures for deep neural networks, and explores consequences during and after training. ", "paperhash": "raghu|on_the_expressive_power_of_deep_neural_networks", "keywords": ["Theory", "Deep learning"], "conflicts": ["cornell.edu", "google.com", "stanford.edu"], "authors": ["Maithra Raghu", "Ben Poole", "Jon Kleinberg", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["maithrar@gmail.com", "benmpoole@gmail.com", "kleinber@cs.cornell.edu", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721989, "id": "ICLR.cc/2017/conference/-/paper115/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1TTpYKgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper115/reviewers", "ICLR.cc/2017/conference/paper115/areachairs"], "cdate": 1485287721989}}}], "count": 17}