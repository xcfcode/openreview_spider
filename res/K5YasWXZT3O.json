{"notes": [{"id": "zEIrs-MkgJW", "original": null, "number": 1, "cdate": 1615339769633, "ddate": null, "tcdate": 1615339769633, "tmdate": 1615339806138, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Comment", "content": {"title": "Code link", "comment": "https://github.com/litian96/TERM"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"forum": "K5YasWXZT3O", "readers": {"values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs"}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}}, "multiReply": true, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["everyone"], "tcdate": 1610649464875, "tmdate": 1610649464875, "id": "ICLR.cc/2021/Conference/Paper647/-/Comment"}}}, {"id": "K5YasWXZT3O", "original": "hnz2qluCe-", "number": 647, "cdate": 1601308077044, "ddate": null, "tcdate": 1601308077044, "tmdate": 1615338002682, "tddate": null, "forum": "K5YasWXZT3O", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "M3lIg_-Imk", "original": null, "number": 1, "cdate": 1610040490309, "ddate": null, "tcdate": 1610040490309, "tmdate": 1610474096162, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "Dear Authors,\n\nThank you very much for your detailed feedback to the initial reviews and also for further answering additional questions raised by a reviewer. Your effort has been certainly contributed to clarifying some of the concerns raised by the reviewers and improving their understanding of this paper.\n\nOverall, all the reviewers found a merit in this paper and thus I suggest its acceptance. However, as Reviewer #2 suggested, investigating the convergence in the stochastic case is very important. More discussion on this would be a valuable addition to the paper, which the authors can incorporate in the final version."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040490295, "tmdate": 1610474096146, "id": "ICLR.cc/2021/Conference/Paper647/-/Decision"}}}, {"id": "PO-XJZYyXNX", "original": null, "number": 10, "cdate": 1606269004832, "ddate": null, "tcdate": 1606269004832, "tmdate": 1606269004832, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "So_YTxS-RTq", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to additional comments", "comment": "Thank you for your additional feedback. We hope our response has addressed the rest of the reviewer's comments in the last round, and we respond to additional comments below.\n\n**[convergence guarantees for stochastic TERM]** In this work, our aim was to rigorously understand the properties of the TERM objective and its solutions, and demonstrate TERM's generality for a wide range of ML applications. Based on the competitive empirical performance of TERM and the stochastic method we used in a subset of the experiments, as well as the direct comparisons between the stochastic and batch method (Figure 7), we agree that more formal convergence guarantees for the stochastic case would be an interesting direction of future work. In comparison to traditional ERM, these guarantees are slightly more complex due to the fact that the stochastic gradient estimator is biased, thus requiring additional machinery beyond what is typically needed for stochastic solvers for vanilla ERM. \n\n**[noisy outliers vs. noisy samples]** Thank you for this suggestion; we will use the word 'noisy samples' rather than 'outliers' to avoid confusion."}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "UDJeH2eg16", "original": null, "number": 2, "cdate": 1603928365090, "ddate": null, "tcdate": 1603928365090, "tmdate": 1606250957448, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Review", "content": {"title": "Interesting analysis with a broad range of applications", "review": "This work analyzes the LogSumExp aggregated loss (named tiled empirical risk minimization, or TERM, in the paper). It provides several general properties of the loss, such as its relation to min/avg/max-loss, and interpretations of different trade-offs. Empirically, it is shown that TERM can be applied to a diverse set of problems, including robust optimization, fairness and generalization.\n\nStrength:\n1. Provide theoretical analysis on the properties of TERM\n2. Various experiments to showcase the usefulness of TERM as objective\n\nWeakness:\n1. Unclear convergence of the optimization procedure\n2. Missing literature\n\nDetails:\n1. The LogSumExp has been extensively studied in geometric programming (Calafiore and El Ghaoui, 2014, Sec.9.7) and boosting (Mason et al., 2000; Shen and Li, 2010). The current manuscript does have some novel interpretations such as the trade-off between avg-min losses. However, I am not an expert in this field, thus not sure how much the new analysis will contribute to the community (or the analysis may exist somewhere). Additionally, LogSumExp is called \"tilted\" without explanation. Why not call it LogSumExp, which is well-known?\n\nRef:\n- Calafiore, G.C. and El Ghaoui, L., 2014. Optimization models. Cambridge university press.\n- Mason, L., Baxter, J., Bartlett, P.L. and Frean, M.R., 2000. Boosting algorithms as gradient descent. In Advances in neural information processing systems (pp. 512-518).\n- Shen, C. and Li, H., 2010. On the dual formulation of boosting algorithms. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(12), pp.2216-2231.\n\n2. Some of the technical details are missing.\n- What is the range of t in Fig.1?\n- The interpretation 2 is constrained to be t<0 for avg-min trade-off (and t>0 for avg-max, as shown empirically in Fig.9). This should be clear in the informal statement to avoid confusion. Also, the interpretation 3 is valid for t>0.\n- Algorithm 2 claims that t is temperature, but in fact, t is more like the inverse of temperature in common sense (consider softmax).\n\n3. Convergence of the optimization procedure is not convincing. Since Algo.2 is using a non-trivial averaging for the normalization term, the convergence of the stochastic version is unclear. It seems that the convergence discussion in Appendix H is only for the batch version.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138407, "tmdate": 1606915797547, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper647/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Review"}}}, {"id": "So_YTxS-RTq", "original": null, "number": 9, "cdate": 1606250931665, "ddate": null, "tcdate": 1606250931665, "tmdate": 1606250931665, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "Je01Pff3BFs", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Additional comments", "comment": "Thank you for the explanations. \n\nThe convergence of the stochastic version is crucial since it is more practical for large scale datasets. Traditional ERM-based algorithms can handle this, so it would be nice for TERM to have similar converging algorithms.\n\nOne more comment on the \"80% outlier\" issue from R4. I agree that the term \"outliers\" can be misleading as they are usually in minority and erroneous in certain ways. It might be less confusing if they are called \"noisy samples\" instead."}, "signatures": ["ICLR.cc/2021/Conference/Paper647/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "9jZhWL7_hNy", "original": null, "number": 5, "cdate": 1605648887006, "ddate": null, "tcdate": 1605648887006, "tmdate": 1605650850358, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "XV4Nntx_9Ac", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We thank the reviewer for the suggestions to improve the paper.\n\n**[Tuning t]** The goal of our analyses is precisely to highlight the effect of 't' on TERM, so that this tuning does not need to be magical; our paper provides numerous theoretical and empirical insights that explain the effect of positive/negative values of 't'. In terms of our experiments, as discussed in Section 5, we select t by performing simple grid search on a handful of values of t for positive t examples, and use t=-2 across all experiments involving negative t. Importantly, we note that all the methods we compare against (other than vanilla ERM, which performs considerably worse) have at least one hyperparameter that requires tuning. TERM (with just a single hyperparameter) scales similarly as ERM. Therefore, it is in fact more lightweight than most of the competitors we compare against (we discuss this throughout Section 5).\n\n**[Train/test splits for experiments]** We report standard error for the experiments in Table 1 and Table 3 based on multiple runs with different train/test splits, as these datasets don\u2019t come with a predefined train/test split. However, for CIFAR10 (Table 2 and Figure 3), which has a standard and widely-used train/test split, we use the standard train/test split for evaluation. Similarly, for the results in Figure 5, we use the exact train/test partition used by the baseline methods to directly compare to this prior work.\n\n**[Stochastic solvers]** While TERM does not maintain additivity of individual losses, the gradient is a weighted sum of the ERM gradient (see Section 2, Lemma 1), which still allows us to use stochastic methods to solve it (see Algorithms 2 & 4). Further, for a specific t, optimizing TERM is equivalent to optimizing $\\frac{1}{N} \\sum_i e^{t f(x_i; \\theta)}$ (removing the log part in the objective), which preserves additivity.\n \n**[Comparison with other works]** Thanks for this suggestion; we have added a citation to the robust gradient descent method (Holland and Ikeda, 2019) in our related work. We have also performed additional experiments to test robust gradient descent on our robust regression application. We take their open-source code on Github and use the suggested hyperparameters. The results are shown in the following table:\n\n| method    | 20% noise     | 40% noise  | 80% noise |\n|------------------|--------------|-------------|--------------|\n| Robust GD    | 1.62 (.04) | 2.39 (.04) | 4.18 (.07)|\n\nRobust GD does not achieve higher test accuracy than the baselines we compare with.\n\n**[Generalization of TERM]** We agree with the reviewer that generalization with respect to t would be an interesting direction of future work; we will mention this in the conclusion.\n\n**[Other technical details]** We clarify the reviewer\u2019s concerns regarding a few technical details here. \n\n(1) The assumption that there doesn\u2019t exist a $\\theta$ such that $\\nabla f(x_i; \\theta )$ are all zero is not restrictive in the convex setting, which is the focus of the theoretical study in this paper. For example, for the loss in our first toy example in Figure 1, the assumption excludes the case where all data points $x_i$ are the same. \n\n(2) L\u2019hopital\u2019s rule is applied at $t$ and $\\log \\left(\\frac{1}{N} \\sum_{i \\in [N]} e^{t f(x_i; \\theta)} \\right)$, respectively. We have added a sentence to clarify this. \n\n(3) We can exchange between the limit and the derivative because the gradient of the objective with respect to $\\breve{\\theta}(\\tau)$ is a weighted sum of the gradients with weights bounded by [0, 1]. Please see our revisions for a detailed derivation. Thanks for these suggestions to improve the clarity of our work.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "jscOrXZLOlA", "original": null, "number": 8, "cdate": 1605649753147, "ddate": null, "tcdate": 1605649753147, "tmdate": 1605649753147, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "qLJgnLurpD", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to Reviewer #4", "comment": "We appreciate the reviewer's detailed reviews for improving the draft.\n\n**[Convexity for t<0]** TERM becomes nonconvex for sufficiently negative t; we state this point in Appendix H (the \u2018Convergence with t\u2019 section). \n\n**[80% noise in robust regression and classification]**\n\nThe outliers we consider in the experiments are random noisy samples without any structure. In such cases, if 20% of the clean data have a clear structure and the remaining are random noise, it is possible that the model can still discover the underlying structure of the clean data. We were motivated to look at this application and the extreme noise regimes (> 50% noise ratio) based on prior work in classification, e.g., https://arxiv.org/pdf/1712.05055.pdf, https://arxiv.org/pdf/1805.07836.pdf, which we compared with in our submission. \n\nWe do agree with the reviewer that it is likely not possible to mitigate outliers if the 80% outliers were structured or adversarial. We are not even sure whether one could recover noise levels smaller than 50% in the presence of adversarial noise. We have added a discussion regarding this point in the main text in Section 5 (\u2018robust regression\u2019). \n\nTo further highlight the differing performance under structured vs. unstructured noise, we have also added some toy examples to Appendix I.2  (Figure 11, 12, 13). For unstructured random noise, we generate synthetic data, and run regression and classification tasks on them under noise ratio 0%,  20%, 40%, and 80%. These results show that TERM with t<0 is fairly robust under all noise levels (while the performance does drop at 80% noise, it can still learn useful information, and achieves much lower error than ERM). In contrast (and to the reviewer\u2019s point), we have also constructed cases based on structured noise in Figure 14 where TERM in fact fits to the noisy samples and ignores the \u2018clean\u2019 samples for large noise values (80%), as would be expected.\n\nRegarding your concern on the interpretability of the noise in CIFAR10, we have conducted experiments on synthetic data for robust classification for a binary case using logistic regression as the loss function (Figure 13, Appendix I.2). Similarly, we see that TERM (t=-2) is fairly robust. We have added discussions on this point in Section 5. We also compare with the generalized cross entropy baseline (GCE), which we also compared against on the CIFAR10 dataset. We note that in this toy example, GCE is as good as TERM with t=-2. On the real dataset CIFAR 10, TERM outperforms GCE (Table 2). \n\n**[Comparison with Scikit-learn]** We implemented the baselines ourselves (as opposed to using a library like scikit-learn) in order to remove implementation differences/randomness induced by the complicated abstractions provided by a third-party library, and to keep everything else (e.g., the optimizer, the data shuffling, etc) fixed except the objective for a fair comparison. Additionally, we compared with a number of recent, state-of-the-art methods, which we would expect to be superior to the default methods in scikit-learn. However, as per your suggestion, we have conducted experiments comparing to robust methods provided by sklearn on robust regression. The results are shown in the table below.\n\n\n|scikit-learn methods |20% noise | 40% noise |80% noise|\n|-----|-----|-----|-----|\n|LinearRegressor (L2) |2.96 (.18) |2.89 (.35) |4.09 (.61)|\n|HuberRegressor | 1.40 (.68) | 2.14 (.14) |3.72 (.55) |\n|RANSAC | 2.63 (.14)  | 2.87 (.33)  | 4.07 (.62)|\n\nAs we can see, the RANSAC method is worse than Huber loss in this case, and all methods perform considerably worse than TERM. Moreover, the Theil-Sen regressor in scikit-learn fails to finish running within a fairly long time (1000x of the L2 regressor). We suspect this is due to the fact that this algorithm does not scale well with the number of samples and the feature dimension.\n\n**[Feature corruption experiments]** We greatly appreciate the reviewer\u2019s careful evaluation, which included running our code in a different setting. We agree that TERM can also obtain good performance with feature noise, and we do have such experiments in the appendix (Table 5). We are happy to bring these or related feature corruption experiments from the appendix into the main text if the reviewer thinks that would add value to the paper.\n\n**[Formal convergence results]** We added a theorem (Theorem 13) on the convergence rates for batch TERM. Please see our response to all reviewers for details.\n\n**[Others]** We believe minimax is commonly used to refer to any objective minimizing the worst loss, as applicable to a multitude of problems (see e.g. https://en.wikipedia.org/wiki/Minimax); however, we are happy to switch to min-max to avoid any confusion.\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "Je01Pff3BFs", "original": null, "number": 7, "cdate": 1605649323254, "ddate": null, "tcdate": 1605649323254, "tmdate": 1605649375195, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "UDJeH2eg16", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to Reviewer #2 ", "comment": "We thank the reviewer for the helpful comments.\n\n**[Convergence of TERM]** We have added Theorem 13 on the convergence guarantees for batch TERM, and we empirically demonstrate the convergence of stochastic TERM. Please see our response to all reviewers for more details along these lines.\n\n**[LogSumExp v.s. Tilting]** \u2018LogSumExp\u2019 objectives consider exponential smoothing to approximate the max. While we cited related literature on smoothly approximating the maximum in our original submission, we now also explicitly mention the term \u2018LogSumExp\u2019 to make the connection clear, and have added the references you mentioned. The term \u201ctilted\u201d comes from the idea of \u201ctilting\u201d in the importance sampling literature. In contrast to LogSumExp, which conceptually focuses on positive t\u2019s, exponential tilting considers both positive and negative t\u2019s. We therefore view \u201ctilting\u201d as a more general notion, and believe it more aptly describes the objective we investigate (which encompasses both positive/negative t).\n\nThe existing analysis on LogSumExp is certainly relevant to TERM and we make these connections explicit in the appendix where we present our results (e.g., the strong convexity property is known). However, we note that the analyses on the properties of the TERM objective and its solutions are new (e.g., the tradeoffs between max-loss, and avg-loss or the variance reduction property), and the connections made with superquantile optimization are also entirely novel. \n\n**[Other details]** \n(1) The t's in Figure 1 are in the range [-10,10], which roughly matches the performance of t $\\in (-\\infty, +\\infty)$ for these toy problems.\n(2) In the text, we explicitly state that the avg/max loss tradeoff corresponds to positive t\u2019s and the avg/min loss tradeoff corresponds to negative t\u2019s. In the informal statement presented under the text, the non-increasing of max loss holds for all t\u2019s, and the non-decreasing of avg loss applies to only positive t\u2019s. We have revised this statement. Thanks for pointing this out.\n(3) We have changed the temperature t to temperature 1/t to match convention, as per your suggestion.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "8vjso2io2t", "original": null, "number": 6, "cdate": 1605649081625, "ddate": null, "tcdate": 1605649081625, "tmdate": 1605649168642, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "-nFZF8lNkM6", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "We thank the reviewer for the valuable feedbacks.\n\n**[Outlier definition]** The outliers we consider are noisy samples with large losses, not adversarial examples; this notion of \u2018outlier\u2019 is standard in other literature, e.g., this interpretation motivates the use of the median for robust machine learning. To avoid confusion, we have added discussions around random unstructured noise v.s. adversarial noise in Section 5. Please also see our response to Reviewer #4.\n\n**[Numerical issues for large t\u2019s]** We do not encounter numerical issues when using the batch solver. However, we agree that we could face such issues when using the stochastic variant. We developed the stochastic solver using a tilted average to estimate the gradients to mitigate this potential issue, and we empirically show that the stochastic method achieves good performance in practice for a number of applications (specifically, for our experiments on robust classification, low-quality annotators, class imbalance, and fair federated learning).\n\n**[Convergence of TERM]** We have added Theorem 13 on the convergence guarantees for batch TERM, and we empirically demonstrate the convergence of stochastic TERM. Please see our response to all reviewers for more details along these lines.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "95m1TKIkDUz", "original": null, "number": 4, "cdate": 1605647655961, "ddate": null, "tcdate": 1605647655961, "tmdate": 1605647655961, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment", "content": {"title": "Response to all reviewers", "comment": "We thank all reviewers for their valuable feedback. We first address shared concerns, and then respond to specific comments from each reviewer. We have updated the paper (with revisions highlighted in blue) and we refer to this updated version in our responses. \n\n**[Contributions]** In this work, we explore tilted empirical risk minimization (TERM) as a simple, unified framework to address various challenges with ERM. We analyze the properties and solutions of the TERM objective, and provide novel connections between TERM and superquantile methods. We develop efficient solvers for TERM and show via multiple real-world applications that TERM achieves competitive performance with state-of-the-art, problem-specific approaches. Our work aims to highlight the effectiveness and versatility of tilted objectives in machine learning.\n\n**[Convergence of TERM]** Our batch solver for TERM achieves the same convergence rates (differing by a constant linear with t) as standard gradient descent under the same assumptions. Our original submission included discussions on the convexity and smoothness of TERM in Appendix H. For completeness, we have also added Theorem 13 in Appendix H.1, which directly provides the convergence rates for the batch method. In terms of the stochastic solver, we have empirically demonstrated convergence by effectively applying it to various ML applications (specifically, our experiments on robust classification, low-quality annotators, class imbalance, and fair federated learning). We have also validated the convergence results on toy problems, where it is computationally feasible to run the batch method for comparison (Figure 7). Given the promising empirical performance, we agree with the reviewers that a theoretical analysis of the stochastic solver would be an interesting direction of future work; we highlight this in the conclusion.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "K5YasWXZT3O", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper647/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper647/Authors|ICLR.cc/2021/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Comment"}}}, {"id": "qLJgnLurpD", "original": null, "number": 1, "cdate": 1603785719061, "ddate": null, "tcdate": 1603785719061, "tmdate": 1605024639161, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Review", "content": {"title": "Review of \"Tilted Empirical Risk Minimization\"", "review": "\n\n  *  Summary of the paper.\n  The paper presents a modification of the empirical risk minimization (ERM) framework in order to obtain more robust or fairer results, using tilted objective. The paper exhibit several properties of the tilted empirical risk minimization (TERM) algorithm applied to classification and regression, TERM exhibits a trade-off between average loss and max loss for instance and this trade-off can be handled with a parameter t that control how robust one wants to be or how fair one wants to be. The claims are supported by a number of numerical illustrations that show the practical efficiency of the method for diverse tasks.\n \n  * Strong points: the article is entirely reproducible as the author furnishes a well documented code. The figures and experiments made in the article provide a good illustration of the algorithm and a few theoretical lemma come to help understand the algorithm better.\n   \n  * Weak points: Use of 80% outliers in Table 1 without further explications. I think there is too much material, you made a lot of different experiments and it would have been great to have less experiments but more explications. There is no theoretical risk bound that would give us the efficiency of TERM, for instance in a corrupted setting or with respect to a fairness loss.\n    \n  *  Recommendation.\n    I vote for accept. The algorithm seems efficient and easy to implement and it allows the user a broad choice of different extensions of the basic learning framework in particular to fairness and robustness in classification and regression.\n\n**Most of my review will be about the robustness part of the article because it is a subject I am familiar with.**\n\n  *  Questions:\n    * It is very weird that TERM works in Table 1 even when there are 80% outliers , as my understanding of outliers is that they must be in minority. I would say that if 80% of the points are outliers, maybe the 20% points are in fact the outliers and I don't see a practical application where the inliers would be in minority. It seems counterintuitive. Can you explain that ? This is even more counterintuitive in classification where the error is smaller when the corruption is 80% than when it is 40%. I am not sure what is the task and what it is that your algorithm do in the 80% noise context. All the definitions of noise/outliers that I know of suppose that the proportion of outliers is smaller than 50%. In fact I think the problem with 80% outliers is theoretically impossible except when doing list decoding (see for instance the article \"List-Decodable Robust Mean Estimation and Learning Mixtures of Spherical Gaussians\" by Diakonikolas, Kane and Stewart).\n    \n    * Why did you not compare your algorithms with scikit-learn algorithms or scikit-learn-contrib algorithms ? I am thinking about HuberRegressor, RANSAC, TheilSenRegressor. To go further you could also test algorithms from scikit-lego for fairness or scikit-learn-extra for robust classification. To compare to a second party and not only your algorithms vs your algorithms.\n    \n    * Why did you only corrupt the labels in a robust classification task ? At least in the regression experiment, you could have corrupted the features and it works well. This is a very interesting property of your algorithm, there are not a lot of robust regression and classification algorithms that are robust to outliers in the feature space ! Is it a misunderstanding on my part or do you algorithm really work when feature space is corrupted ? I tested your algorithm on drug experiment with outliers in feature space and it worked. Huber and L1 did not work in this context.\n    \n    * Is the TERM problem convex when t<0 ? As it is, there is no reason that your algorithm will always converge to a global minimum.\n\n  * Additional Feedback.\n    * The 80% noise in Table 1 really bugged me when I read your article, maybe you may want to explain more or to remove it as it can cause misunderstandings I think.\n    * When comparing robust methods, (Table 1), the authors did not compare their methods to the mainstream algorithms like RANSAC or Theil-Sen regression. It would have been interesting to do so.\n    * The classification task considered by the authors in Table 1 (CIFAR-10) is not easy to interpret. What is an outlier for a neural network ? For a linear classifier, an outlier is readily defined for a very non-linear classifier; this is not so easy because most neural networks will be so nonlinear that the introduction of outliers in the training dataset will not change the performances of the algorithm.\n    * It would have been interesting to compare TERM to other robust classification algorithms on an easier dataset in low dimension to exhibit the comparative performances similarly to what is done for regression.\n    * You talk of \"minimax\" in a way that is unusual. Most of the time, at least in theoretical ML, minimax algorithms refer to algorithms which attain the optimal rate of convergence (see Section 14.1 in \"A Probabilistic Theory of Pattern Recognition\" by Devroye, Gyorfi and Lugosi). I think this is not what you mean, what you used I call it minmax. I don't know if yours is a common use of the term and if this is the case, sorry for this comment and don't take it into account.\n    * Typo: Section 5.3 inn -> in.\n    * The fact that the objective is strongly convex when t>0 is fairly important (this proves the convergence), I think that you should include the whole proof and not an abridged version of it (see proof Lemma 3).\n    \n    \n    \n    \n\n\n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138407, "tmdate": 1606915797547, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper647/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Review"}}}, {"id": "XV4Nntx_9Ac", "original": null, "number": 4, "cdate": 1603955094839, "ddate": null, "tcdate": 1603955094839, "tmdate": 1605024639039, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Review", "content": {"title": "The paper explore relevant applications of exponential smoothing in several ML problems. It is well written and should be interesting for ML practioners.", "review": "The paper provide nice discussions of a simple modification of ERM paradigm. Mainly, it consists in applying an exponential smoothing to the loss function. The authors provide several interpretations and connexions with (robustness/fairness/quantile regression etc...) literature and show how the TERM can be adapted to such problem. The paper is well written, contains pedagogical illustrations and detailed properties of TERM.\n\n- The success of Term heavily rely on a *magical* tuning of the parameter $t$ depending on the application. Grid search was used in this paper which considerably increases the complexity of the algorithm without necessarily improving significantly the accuracy when compared to competitors.\n\n- The experiments does not report standard deviation in the train/test splitting. Averaging the test accuracy after several random splitting would be beneficial for clarity.\n\n- The classical ERM formulation is written as sum of functions, which allows several advanced stochastic optimization algorithm. Such structure is destroyed in the tilted formulation.\n\n- In Assumption 2, isn't it too restrictive to assume that $f(x_i, \\cdot)$ does not have critical point (which does not seems true for quadratic loss)? \n\n- To help the reader, the authors might recall on which quotient the L'hopital rule is applied (after verification of assumptions)\n\n- In equation (87), the limit and derivation are permuted without justification (uniform convergence might be needed). Same for Eq (90)\n\n- Should be interesting to compare with recent robust estimation such as median of means or robust gradient descent (Holland and Ikeda, 2019).\n\n- Should be also interesting to know how the generalization bound (and sample complexity) of TERM compare with the one of ERM wrt $t$.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138407, "tmdate": 1606915797547, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper647/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Review"}}}, {"id": "-nFZF8lNkM6", "original": null, "number": 3, "cdate": 1603940115059, "ddate": null, "tcdate": 1603940115059, "tmdate": 1605024638975, "tddate": null, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "invitation": "ICLR.cc/2021/Conference/Paper647/-/Official_Review", "content": {"title": "This paper provides a unified framework for solving a bunch of issues in ERM. ", "review": "This paper considers a unified framework named TERM for addressing a bunch of problems arising in the simple averaged empirical minimization. By leveraging the key hyper-parameter t in the TERM loss, it can recover the original average loss and approximate robust loss, min/max loss, and the superquantile loss, etc. The authors also propose gradient-based optimization algorithms for solving the TERM problem.  \n\nOne thing that I do not understand very well is the paragraph under Lemma 1. Why is it necessary that outliers can cause a large (positive t) or small (negative t)  losses? Note that outliers can be arbitrary, say adversarial. \n\nAlso, do you have numerical issues for large enough t?\n\nIs it possible to show certain convergence results of the algorithms for solving the TERM? Especially, the TERM has the nice property that it is always smooth (depending on the value of t). \n\nOverall, the TERM seems to be a good unification of different losses used in machine learning society for different purposes. The theoretical justifications also look reasonable and informative. In addition, the authors conduct a series of experiments to show the good performance of TERM for different tasks such as robustness to outliers, handling imbalance, and improving generalization, etc. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper647/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper647/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tilted Empirical Risk Minimization", "authorids": ["~Tian_Li1", "~Ahmad_Beirami1", "~Maziar_Sanjabi1", "~Virginia_Smith1"], "authors": ["Tian Li", "Ahmad Beirami", "Maziar Sanjabi", "Virginia Smith"], "keywords": ["exponential tilting", "models of learning and generalization", "label noise robustness", "fairness"], "abstract": "Empirical risk minimization (ERM) is typically designed to perform well on the average loss, which can result in estimators that are sensitive to outliers, generalize poorly, or treat subgroups unfairly. While many methods aim to address these problems individually, in this work, we explore them through a unified framework---tilted empirical risk minimization (TERM). In particular, we show that it is possible to flexibly tune the impact of individual losses through a straightforward extension to ERM using a hyperparameter called the tilt. We provide several interpretations of the resulting framework: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to a superquantile method. We develop batch and stochastic first-order optimization methods for solving TERM, and show that the problem can be efficiently solved relative to common alternatives. Finally, we demonstrate that TERM can be used for a multitude of applications, such as enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance. TERM is not only competitive with existing solutions tailored to these individual problems, but can also enable entirely new applications, such as simultaneously addressing outliers and promoting fairness.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|tilted_empirical_risk_minimization", "one-sentence_summary": "We show that tilted empirical risk minimization (TERM) can be used for enforcing fairness between subgroups, mitigating the effect of outliers, and handling class imbalance, all in a unified framework.", "pdf": "/pdf/4e65d21b2f7769fad229ff3007346abb249d69d1.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021tilted,\ntitle={Tilted Empirical Risk Minimization},\nauthor={Tian Li and Ahmad Beirami and Maziar Sanjabi and Virginia Smith},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YasWXZT3O}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "K5YasWXZT3O", "replyto": "K5YasWXZT3O", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper647/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138407, "tmdate": 1606915797547, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper647/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper647/-/Official_Review"}}}], "count": 14}