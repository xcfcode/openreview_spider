{"notes": [{"id": "SkEqro0ctQ", "original": "rkeJSn9KFm", "number": 113, "cdate": 1538087746319, "ddate": null, "tcdate": 1538087746319, "tmdate": 1547604597679, "tddate": null, "forum": "SkEqro0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SylGSIC7lE", "original": null, "number": 1, "cdate": 1544967737961, "ddate": null, "tcdate": 1544967737961, "tmdate": 1545354489668, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Meta_Review", "content": {"metareview": "The paper receives a unanimous accept over reviewers, though some concerns on novelty exist. So it is suggested to be a probable accept. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Unanimous accept. "}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper113/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353332567, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353332567}}}, {"id": "BJgqJWpijm", "original": null, "number": 1, "cdate": 1540243682145, "ddate": null, "tcdate": 1540243682145, "tmdate": 1543254179341, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "content": {"title": "Interesting idea. Potentially convincing experiments. Limited methodological novelty", "review": "This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. '18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. \n\nResults are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where \"humans\" were asked to pick more interpretable models. \n\nThe paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns:\n\n1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice.\n\n2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the \"agglomeratively grouped CD scores of individual features\" are the same as the \"CD scores for the groups/interactions of features\" in terms of their contribution to the final prediction.\n\n3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task).\n\n4). The paper talks several times about diagnosing why a model went wrong e.g. the \"negation\" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "cdate": 1542234534911, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335652216, "tmdate": 1552335652216, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJgRJN1chm", "original": null, "number": 2, "cdate": 1541170150334, "ddate": null, "tcdate": 1541170150334, "tmdate": 1543253785675, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "content": {"title": "Contextual decomposition for general DNNs", "review": "**Summary**\n\nIn this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs. They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction. \n\n**Strength**\n\n1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations.\n2. Experiments are elaborate and cover the breadth of the proposed method well.\n3. The paper is well presented and fairly easy to follow. \n\n\n**Weakness**\n\n1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/abs/1801.05453).\n2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "cdate": 1542234534911, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335652216, "tmdate": 1552335652216, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJeLz1ht0m", "original": null, "number": 11, "cdate": 1543253774384, "ddate": null, "tcdate": 1543253774384, "tmdate": 1543253774384, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "Byxr3jst0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Response to revision", "comment": "Thanks for updating the paper and addressing my concerns, mainly regarding the novelty. \nI will change my rating accordingly. "}, "signatures": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "Byxr3jst0Q", "original": null, "number": 10, "cdate": 1543252908696, "ddate": null, "tcdate": 1543252908696, "tmdate": 1543252908696, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SJgRJN1chm", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Response to review revisions", "comment": "Thanks for your response. We see that you have responded to our comments by adding the sentence \"They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction.\" onto the summary of our paper, and leaving the strengths, weaknesses and rating unchanged.\n\nIn light of your updated summary, we feel your main concern should also be revisited. Your stated concern is that \"This approach for RNNs is presented fairly well in the previous [CD] paper\". Our main contribution, hierarchical interpretations, was not presented in the CD paper, or in any other paper, and is independent of CD (it can be applied to any phrase/patch importance score). The bulk of recent work in this area has focused on (non-hierarchical) heat maps (we cite 13 recent papers in our related work that do this). Our experiments show that applying our hierarchical interpretation algorithm to CD, yields higher user trust, and more insight into a model's predictive accuracy, than CD alone, or any of our other baselines.\n\nTo be clear, our point is that moving from heat-maps, such as Table 1 in [1] (the CD paper),  Figure 5 in [2], or Figure 4 in [3] (our three baselines), to hierarchies, such as Figure 2 in our paper, is not incremental.\n\nWe responded to concern #2 above, and also modified paragraph 5 of section 3.1 and added a figure on page 27 of the supplement (Fig S5). Did this address your concern?\n\n[1] https://arxiv.org/pdf/1801.05453.pdf\n[2] https://arxiv.org/pdf/1612.08220.pdf\n[3] https://arxiv.org/pdf/1703.01365.pdf"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "S1gxYcrUCQ", "original": null, "number": 9, "cdate": 1543031415884, "ddate": null, "tcdate": 1543031415884, "tmdate": 1543031415884, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SylmiHLXAX", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Thanks for responding", "comment": "Thanks for your response, and acknowledging the paper updates.\n\nTo summarize, it appears our revisions have satisfied most of your concerns, with the only remaining one being the \"incremental contribution of the paper\".  Moreover, this concern is strong enough that you have not altered your rating despite your other concerns being addressed. We have two points we'd like to make in response.\n\nFirst, we feel that our main contribution (hierarchical interpretations) is, in fact, novel. No paper, including the CD paper, has considered this, with much recent effort being put into (non-hierarchical) heat maps (we cite 13 recent papers in our related work that do this). Our algorithm for hierarchical importance is also independent of CD, and could be applied for any suitable patch/phrase importance score. Our experiments show that applying our hierarchical interpretation algorithm (our main contribution) to CD, yields higher user trust, and more insight into a model's predictive accuracy, than CD alone, or any of our other baselines.\n\nTo echo our previous response, our point is that moving from heat-maps, such as Figure 5 in [1] or Figure 4 in [2] (two of our baselines), to hierarchies, such as Figure 2 in our paper, is not incremental. Rather, it is a simple algorithm that produces a novel form of interpretation (hierarchies) with validated empirical benefits.\n\n[1] https://arxiv.org/pdf/1612.08220.pdf\n[2] https://arxiv.org/pdf/1703.01365.pdf"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "SylmiHLXAX", "original": null, "number": 8, "cdate": 1542837658563, "ddate": null, "tcdate": 1542837658563, "tmdate": 1542837658563, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "Syxrlyfzpm", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "The revised version of the paper is improved.", "comment": "Thanks for updating the paper. The revised version is definitely improved. Also, thanks for clarifying some of my questions.\n\n\nRegarding your comment:\n>>>we feel that the simplicity of our method should be an argument for its acceptance, not against.\n\nI totally agree with that and am myself a big fan of simpler methods which show strong empirical performance!\n\nHowever, the issue here is a little different. It's not so much about simplicity but more about the incremental contribution of the paper relative to the CD paper by (Murdoch et. al. 18), which in my eyes is little.\n\nThat said, the judgement of novelty of a paper w.r.t. prior literature is very subjective, so I leave it to the Area Chair/Senior PC to make a final call on that. "}, "signatures": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "Syxrlyfzpm", "original": null, "number": 4, "cdate": 1541705452888, "ddate": null, "tcdate": 1541705452888, "tmdate": 1541705745765, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "BJgqJWpijm", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Thanks for your comments", "comment": "Thank you very much for the exceptionally detailed and thoughtful review. We address your concerns below\n\n1) We\u2019d like to emphasize that our main source of novelty lies in moving from the word/pixel-level heat maps (e.g. Figure 5 in [1]), which are the current SOTA for interpreting individual DNN predictions, to hierarchical interpretations, such as Figure 2 in our paper. In our human experiments, we compare our hierarchical interpretations against three non-hierarchical baselines, ultimately concluding that the hierarchy is in fact beneficial.\n\nGiven that the experimental gains across NLP and vision are meaningful, we feel that the simplicity of our method should be an argument for its acceptance, not against. In machine learning, there is often the temptation to propose complicated \u201chighly novel\u201d approaches, many of which are never adopted. In contrast, we explicitly tried to identify the simplest approach that could produce a meaningful improvement over the current SOTA. In interpretability, we feel simplicity is particularly important, as we must consider the human component in providing simple, easy to understand insights into the model. We have found that the more complicated the interpretation method, the harder it is to convince users to use, understand, and trust the method\u2019s output.\n\n2) As R2 also pointed out, section 3.2 was too heavy with mathematical details and lacking intuition. We have now added a paragraph to the beginning of section 3.2, which should hopefully make it clearer. \n\nTo answer your question, the agglomeration algorithm was run post-hoc - ACD does not modify the original prediction of the LSTM. \n\nThe agglomeration algorithm is simply an approach for constructing the hierarchy of phrases/pixels, but does not alter the CD scores produced for each node in the hierarchy. That is, the score for each node in the hierarchy is simply the CD score for that particular phrase/pixel-blob, which I believe is what you mean by \u201cCD scores for the groups/interactions of features\". By \"agglomeratively grouped CD scores of individual features\", I think you\u2019re referring to the sum of the CD scores for the sub-phrases/words contained within a phrase. This value isn\u2019t displayed in the hierarchy, as summing importance scores can\u2019t capture interactions, such as the negation between \u201cn\u2019t lift\u201d and \u201cthis heartfelt enterprise out of the familiar.\u201d that occurs in Figure 2.\n\n3) We agree that it could be interesting to see whether CNNs and LSTMs produce similar importance scores and/or hierarchies on the same dataset, and this is something we have thought about for future work (e.g. \u201cDo LSTMs and CNNs capture different kinds of interactions?\u201d). Unfortunately, in a conference paper we don\u2019t feel we have the space to do such an analysis in a defensible manner. Moreover, we feel the existing results are more important to justifying the main part of the paper - hierarchical interpretations.\n\n4) The problem of using interpretations to improve accuracy is quite interesting, and one that we have spent a lot of time thinking about it. The short answer is that it is not immediately clear how to do so, but we are optimistic that improved interpretations like ACD should prove useful in improving model\u2019s accuracy\n\nHowever, even if ACD never leads to increased prediction performance, we think it\u2019s important to stress that there are many uses for interpretations that have no effect on predictive performance. As we discuss in the first paragraph of our introduction, in scientific applications [2-4], it is the interpretations themselves which are the findings, and are ultimately reported in publications. In industry, interpretability is important in determining the fairness of a model [5], and satisfying regulatory concerns [6]. Finally, as we show in our human experiments, improved interpretations help users to better trust the predictions of their models, which is helpful even if it does not change the predictions themselves.\n\n[1] https://arxiv.org/pdf/1612.08220.pdf\n[2] https://arxiv.org/abs/1702.05747 \n[3]https://www.researchgate.net/publication/261538344_The_Emergence_of_Machine_Learning_Techniques_in_Criminology \n[4] http://msb.embopress.org/content/12/7/878 \n[5] https://arxiv.org/abs/1104.3913 \n[6] https://arxiv.org/abs/1606.08813 "}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "r1lzrabz6Q", "original": null, "number": 1, "cdate": 1541705017906, "ddate": null, "tcdate": 1541705017906, "tmdate": 1541705727501, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Modifications to paper in response to reviewers and commenters", "comment": "We thank the reviewers for their time and thoughtful comments. In response to their input, we have made the following changes to the manuscript: \n\n1. To address  reviewers 2 and 3\u2019s concerns about the motivation of our agglomeration procedure, we added a paragraph at the beginning of Section 3.2 to give more intuition on our agglomeration procedure, before delving into the precise, mathematical details.\n2. To address reviewer 1\u2019s questions about the motivation of generalizing CD to CNNs, we added the fifth in Section 3.1 to give more details.\n3. To address Shi Feng\u2019s questions about comparing with Godin et al.\u2019s concurrent work, and reviewer 1\u2019s comments about motivating our generalization of CD, we added Figure S5 on page 27 to illustrate rationale for equations in CD and compare against Godin et al.\n4. To address reviewer 2\u2019s concerns about uncertainty estimates for our usability study, we added statistical significance analysis for human experiments in the third and fifth paragraphs on page 8.\n5. Minor modifications for clarity in response to the reviewers (e.g. in the introduction, method section)\n\nWe should note that the pdfdiff is showing more changes than we actually made. This is because we had to move one of our larger figures to keep things in place, which appears to have triggered a change, e.g. the bottom half of page 8. In these cases, the actual text and layout of the paper has not been altered."}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "SygJ7JMzp7", "original": null, "number": 5, "cdate": 1541705495280, "ddate": null, "tcdate": 1541705495280, "tmdate": 1541705495280, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "S1xxnzLo2m", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Thanks for your interest in our work", "comment": "Thanks for your interest in our work, Shi! I think it is worth clarifying that in both our work and Godin et al., the extension of CD is a relatively secondary contribution to the \u201cmeat\u201d of the paper (for our work that is the hierarchical interpretation, for Godin et al. it is the analysis of character-level neural networks).\n\nInterestingly, our original extension of CD to CNNs was quite similar to Godin et. al. However, when we tried this on ImageNet we found that the results were both qualitatively bad, and often produced very large importance scores (indicating that something was \u201cblowing up\u201d). To fix this, there were two main changes we made (which is also where we differ from Godin et al.): (1) partitioning the bias in a conv/linear layer and (2) modifying the decomposition for the ReLu nonlinearity.\n\nWe have added a paragraph to 3.1 and a supplementary figure (Fig S5) on page 27 both to show the difference between our approach and Godin et al. and to better motivate our generalized CD. Hopefully this can shed some light into the differences in behaviour in a vision setting."}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "ryeseAZMaQ", "original": null, "number": 3, "cdate": 1541705203387, "ddate": null, "tcdate": 1541705203387, "tmdate": 1541705203387, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SJgRJN1chm", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Thanks for your comments", "comment": "Thanks for the helpful comments. We would like to address your concerns about the novelty of the work.\n\n\u201c1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper.\u201d\n\nAs you correctly noted, one of the two contributions of this paper is to generalize CD from LSTMs to generic DNNs. However, we would like to clarify that the most important contribution of this paper is not generalizing CD, but introducing the concept (and implementation) of hierarchical importance for interpreting neural network predictions. \n\nThe current state of the art for interpreting neural network predictions is word/pixel-level heat-maps, such as Figure 5 in [1]. Our main contribution is to introduce hierarchical interpretations, such as Figure 2 in our paper, and show that they improve over heat maps, the prior SOTA. In our human experiments, we compare our hierarchical interpretations (agglomerative CD, or ACD) against three non-hierarchical baselines, ultimately concluding that the hierarchy is in fact beneficial.\n\nWe hope that we have clarified that hierarchical interpretations are the main contribution of our paper, and that this addresses your concern around the novelty of this work. To address this, we have (slightly) modified our introduction and method sections. We tried to make this clear throughout the paper and would welcome suggestions on how to avoid similar misunderstandings for future readers.\n\n\u201c2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.\u201d\n\nThanks for pointing this out - we realize we omitted much of our justification in making the modifications for convolution and pooling layers. To address this, we have added some intuition in the fifth paragraph of section 3.1. Additionally, we have added a figure in page 27 of the supplement (Fig S5) showing the effect of our modifications to the update equations for convolution and ReLU layers.\n\n\n[1] https://arxiv.org/pdf/1612.08220.pdf\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "r1lU3TWMaQ", "original": null, "number": 2, "cdate": 1541705133571, "ddate": null, "tcdate": 1541705133571, "tmdate": 1541705133571, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "Hyx_i_0h3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "content": {"title": "Thanks for the feedback", "comment": "Thanks for the helpful comments and positive feedback. We\u2019re glad you agree that the hierarchical notion of importance is important and well validated. We address some of your concerns below.\n\n\u201cThe main methodological contribution (hierarchical CD) is well motivated but only provided in the form of an algorithm. Could have been more precisely described and optimality discussed.\u201d\n\nThis is great feedback, we agree that we were missing a bigger picture, non-mathematical description of the algorithm. We have added a paragraph at the beginning of Section 3.2 giving intuition for our method before jumping into the technical details.\n\n\u201cUncertainty estimates could have improved the significance of the usability study.\u201d \n\nWe agree, and have updated the paper to include statistical significance results. We\u2019ve provided the details below, but the summary is that most of the big jumps in our plots were significant, with the exception of ImageNet in plot A, where the results were only \u201csuggestive\u201d (p values ranged from 0.07 to 0.15). Overall, it seems like the benefits of ACD are in fact statistically meaningful.\n\nStatistical significance results summary:\n\nIdentifying an accurate model (one-sided two-proportion t-test)\nSentiment: gaps between ACD and IG, break-down are significant, ACD to CD is not\nMNIST: nothing is significant\nImageNet: gaps between ACD and others are suggestive, but not significant (p values range from 0.07 to 0.15)\n\nRanking trust in model (permutation test with mean rank test statistic)\nSentiment/ImageNet: ACD\u2019s mean rank is significantly higher than all other methods\nMNIST: ACD is significantly higher than break down, everything else is not."}, "signatures": ["ICLR.cc/2019/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621559, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkEqro0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper113/Authors|ICLR.cc/2019/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621559}}}, {"id": "Hyx_i_0h3Q", "original": null, "number": 3, "cdate": 1541363872060, "ddate": null, "tcdate": 1541363872060, "tmdate": 1541534271062, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "content": {"title": "Interesting hierarchical approach to explainability", "review": "This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study\n\nQuality, \nThe paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, \n\nClarity, \nThe main methodological contribution (hierarchical CD) is well motivated but only  provided in the form of an algorithm. Could have been more precisely described and optimality discussed. \n\nOriginality & significance\nThe work builds heavily on CD but has the hierarchical extension is original and significant. \nUncertainty estimates could have improved the significance of the usability study\n\npros and cons\n+ interesting problem\n+ well-motivated algorithmic extension of CD\n- uncertainty of usability experiment?\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper113/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Official_Review", "cdate": 1542234534911, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper113/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335652216, "tmdate": 1552335652216, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper113/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1xxnzLo2m", "original": null, "number": 1, "cdate": 1541264040295, "ddate": null, "tcdate": 1541264040295, "tmdate": 1541264060884, "tddate": null, "forum": "SkEqro0ctQ", "replyto": "SkEqro0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper113/Public_Comment", "content": {"comment": "Godin et al. just presented at EMNLP an extension of CD to CNNs: https://arxiv.org/abs/1808.09551\nIt should be noted that it was put on arxiv 2 months later than yours. But it would be interesting to compare the two, for example Godin et al. did not partition the bias.", "title": "Related (and likely concurrent) work"}, "signatures": ["~Shi_Feng1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper113/Reviewers/Unsubmitted"], "writers": ["~Shi_Feng1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Hierarchical interpretations for neural network predictions", "abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.", "keywords": ["interpretability", "natural language processing", "computer vision"], "authorids": ["chandan_singh@berkeley.edu", "jmurdoch@berkeley.edu", "binyu@berkeley.edu"], "authors": ["Chandan Singh", "W. James Murdoch", "Bin Yu"], "TL;DR": "We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.", "pdf": "/pdf/edd9240b121ad8ce494d42bb4ce31f44f4d8d045.pdf", "paperhash": "singh|hierarchical_interpretations_for_neural_network_predictions", "_bibtex": "@inproceedings{\nsingh2018hierarchical,\ntitle={Hierarchical interpretations for neural network predictions},\nauthor={Chandan Singh and W. James Murdoch and Bin Yu},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkEqro0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper113/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311915751, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkEqro0ctQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper113/Authors", "ICLR.cc/2019/Conference/Paper113/Reviewers", "ICLR.cc/2019/Conference/Paper113/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311915751}}}], "count": 15}