{"notes": [{"id": "MZIQZgjqOIX", "original": null, "number": 45, "cdate": 1592019225087, "ddate": null, "tcdate": 1592019225087, "tmdate": 1592019225087, "tddate": null, "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "content": {"title": "The resistance is expected", "comment": "The authors have decided to challenge the hard fixed notion in the deep learning community about the generalizability of a network, which is the most basic component of a deep neural network. The results they have produced have shaken my pre-existing beliefs and perceptions on the neural networks.\nIt would have been better if they had pointed to a specific example of where the model could classify with random label. I would like to research more about the implications of random label classification and memorization in models.\nEven though a huge model may be able to memorize the data / features, I feel it would not make sense to build a model with wasted capacity to learn random labels.\nThe discovery that the dropout generalization also doesn't help much is what grabbed my attention.\nOverall, it was a great paper challenging a lot of existing beliefs and notions taken for granted in the deep learning realm. I strongly hope it  encourages / challenges all researchers to come up with a better researach to defend the neural architectures."}, "signatures": ["~Srichakradhar_Reddy_Nagireddy1"], "readers": ["everyone"], "nonreaders": [""], "writers": ["~Srichakradhar_Reddy_Nagireddy1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "ddate": null, "tmdate": 1517291978278, "tcdate": 1517291978278, "number": 44, "cdate": 1517291978278, "id": "S1zRtYaBG", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Thomas_G_Dietterich1"], "readers": ["everyone"], "writers": ["~Thomas_G_Dietterich1"], "nonreaders": [""], "content": {"title": "A very disappointing paper", "comment": "I expected to like this paper, because I respect the authors, and many people have said good things about it. In addition, I enthusiastically support experimental work to improve our understanding of how deep nets work. I'm sorry to say I was very disappointed.\n\nI agree with Pirmin Lemberger that the results in this paper are completely unsurprising. I'm surprised that the authors were surprised. I'm shocked that at least one reviewer thought this was ground breaking.\n\nSuppose you replace every occurrence of \"neural net\" in this paper with \"decision tree\". Would you still be surprised? Of course trees would be able to memorize the data. Of course the trees would need to be deeper for random labels than for random pixels (because random pixels provide more information for memorizing the data; shuffling the original pixels is just another way of generating random pixels). Of course regularizing the depth of the trees would not make them generalize well. The only difference is that trees would perform very poorly on the original data too, because they lack the right representations to generalize well.\n\nRegularization only prevents overfitting. It does not ensure that there are good hypotheses in the hypothesis space. Your experiments with randomly parameterized convolutional layers show that they DO help ensure that there are good hypotheses in H. \n\nI note in Figure 1 that it takes 5000 steps to fit the original data, and more than 13000 steps to fit random labels. This directly contradicts your statement that training did not slow down substantially. Training time nearly tripled.\n\nIt has long been known that the most effective way to control hypothesis complexity in neural networks is early stopping. Back in the 90s, the standard procedure was to use the biggest hidden layer you could afford, and then do early stopping. (IIRC this appears in the \"Tricks of the trade\" book https://books.google.com/books?isbn=3540494308). \n\nIn your experiment, if we apply early stopping at 5000 steps, we will get a non-trivial Radamacher complexity for this data set. On random labels, the accuracy will be near zero. Did you really not notice this?\n\nI think it is interesting that you did not need to change your hyperparameters to get the network to fit random labels. That suggests that the hyperparameters might depend more on the architecture and not so much on the data. Have people seen this in other cases?"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1493737675936, "tcdate": 1493737675936, "number": 43, "id": "BkEAgmUyZ", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "SyPCk4gve", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "What is the kernel?", "comment": "All questions are related to Section 5.\n\n1.\nRegarding your comment \"linearly separable in the feature space associated with the kernel\":\n\nPlease forgive if this should be obvious from the paper but what is the kernel associated with the experiment that gives 1.2% error rate on the test set?  The paper specifically mentions \"on MNIST with no pre-processing\".  To me this sounds like you are using the raw pixels as features and that the training set is \"linearly separable\" without qualifying with \"in the feature space associated with the kernel.\"  What do I misunderstand here?\n\n2.\nIn section 5. you derive mathematically that for the separable case the linear model obtained with SGD optimization provides the solution with the minimum L2 norm of the weight vector.  Is this the right interpretation of the result?  If yes then why did you not do this experiment using SGD, which would easily fit into the memory of a much lower-spec computer?\n\n3.\nFrom another reply, you are training 10 separate linear models, one for each class.  Are you assigning the class labels during testing as:  class=argmax_i (model_i)?\n\n"}, "nonreaders": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "nonreaders": null, "tmdate": 1491462359101, "tcdate": 1491121557175, "number": 42, "id": "ByaqH4Cne", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Pirmin_Lemberger1"], "readers": ["everyone"], "writers": ["~Pirmin_Lemberger1"], "content": {"title": "An introduction to generalization and regularization in DL for non experts", "comment": "The paper looks very interesting and thought provoking to me. However, having an education as a theoretical physics I found it hard at times to follow through all the arguments in the present forum. To clarify my own thoughts about this fascinating topic and to share them with data scientists I work with I wrote a short pedagogical paper arxiv.org/abs/1704.01312 , trying to connect everyday practice of data scientist practice with some basic theoretical knowledge in statistical learning, especially Rademacher complexity. Perhaps this could be helpful to other people without advanced theoretical knowledge in statistical learning. The focus is on explicit mathematical de\ffinitions and on a discussion of relevant concepts."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1490651149406, "tcdate": 1490651149406, "number": 41, "id": "B1SGObwnl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "pending question", "comment": "Could the authors report on ImageNet the training accuracy using both AlexNet and Inception with random labels and data augmentation ? Does that work? and do hyper-parameters need to change?\n\nThis has been requested several times in the discussion, but it has never been addressed (only on CIFAR10). \nOnly this experiment may fully substantiate the general claims made by the authors.\n\nThank you."}, "nonreaders": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489690496052, "tcdate": 1489690390815, "number": 40, "id": "ryy7ywOsg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Matthias_Minderer1"], "readers": ["everyone"], "writers": ["~Matthias_Minderer1"], "content": {"title": "Thought-provoking, but claims of significance not sufficiently backed up", "comment": "The authors claim to have shown that \"the traditional approaches fail to explain why large neural networks generalize well in practice\". \n\nWhile the paper was generally thought-provoking to read and discuss, the paper did not make it clear to me what these \"traditional approaches\" are and why it is surprising that they fail to explain the performance of neural networks.\n\nThe authors express their surprise at various abilities of neural networks, but consistently fail to provide references or arguments beyond \"conventional wisdom\" that explain why I should be surprised. A few examples:\n\n\"To our surprise, several properties of the training process for multiple standard achitectures is largely unaffected by this transformation of the labels. This poses a conceptual challenge. Whatever justification we had for expecting a small generalization error to begin with must no longer apply to the case of random labels.\"\n\nWhat is the conceptual challenge? It is not obvious to me that it is impossible to reconcile small generalization error with with the ability to fit noise. A reference or reasoning for being surprised would help.\n\n\"Surprisingly, stochastic gradient descent with unchanged hyperparameter settings can optimize the weights to fit to random labels perfectly, even though the random labels completely destroy the relationship between images and labels.\"\n\nWhy is this surprising? We know that the network has more than enough parameters to memorize the random labels, so it is not obvious that this is surprising.\n\n\"As shown in the last three rows of Table 2 in the appendix, although it does not reach the perfect 100% top-1 accuracy, 95.20% accuracy is still very surprising for a million random labels from 1000 categories.\"\n\"Quite surprisingly, fitting the training labels exactly yields excellent performance for convex models.\"\n\"Surprisingly, adding regularization does not improve either model\u2019s performance!\"\n\nAgain, why are these findings surprising? Is there any quantitative reasoning behind any of them?\n\nPerhaps I lack the background in statistical learning theory that may be necessary develop the intuitions that lead the authors to find their results surprising. Consequently, I think the paper would benefit from more rigorous arguments for why the findings are surprising."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "nonreaders": null, "tmdate": 1488077222137, "tcdate": 1488076313979, "number": 38, "id": "B1zmA3Jcx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "r14XBwotl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "A possible explanation for generalization not fully considered in the paper?", "comment": "I think the main message of the paper is not to show \"that generalization is bad for a problem with random labels\", but rather it shows training accuracy can be as good for a problem with randomized labels. While it is interesting and thought-provoking, I also think it is not super surprising, or groundbreaking. I could be wrong, but it seems the authors did not fully debunk a explaining theory (If they do, please definitely comment and let me know!) that: implicit regularization by SGD plays important role in selection of generalizable models over their counterparts. Namely, with the same cost, models with smaller norm are easy to \"reach\" under SGD training, and that's why current SGD based training would produce generalizable models when they can also memorize."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1488077110476, "tcdate": 1488077110476, "number": 39, "id": "S1ANWTkce", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "HJIRwLuwe", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Can it be well learned with large norm initialization?", "comment": "If the nets cannot be well trained using initialization with norm similarly to ones under good convergence, then the argument (that SGD implicitly regularizes l2 norm) holds, as the norm increases during the training. So the real question is: can it be well learned with large norm initialization? It seems rarely the case in practice?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487959610880, "tcdate": 1478281198090, "number": 259, "id": "Sy8gdB9xx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Sy8gdB9xx", "signatures": ["~Chiyuan_Zhang1"], "readers": ["everyone"], "content": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 49, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1487805667671, "tcdate": 1487791388548, "number": 37, "id": "r14XBwotl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Xiang_Zhang1"], "readers": ["everyone"], "writers": ["~Xiang_Zhang1"], "content": {"title": "Not useful", "comment": "(I read this paper after knowing that it got accepted to ICLR 2017)\n\nI am quite happy that a paper that actually talks about model complexity can be accepted to ICLR 2017. But I want to express my personal opinion (unrelated to my lab, my advisor etc) that this paper is a bit over-rated. Calling this paper \"groundbreaking\" is a bit ridiculous in my honest opinion, and it is unfair to the theory community. I hold no bad ideas to the authors or the chairs, but only to the technical details in both experiments and theory of the paper.\n\nTL;DR: The paper shows that generalization is bad for a problem with random labels. That is of course true, but uninteresting.\n\nIn section 2.2 2nd paragraph, the claim that the empirical Radamacher complexity is 1 is a bit hand-waving. One detail that is worth noting (but this does not mean the paper is wrong) is that the conclusion assumes that all functions in the hypothesis set H is bounded by 1 in absolute values. This is only true if H is defined as the set of error functions, or if H is the set hypothesis functions but only for a binary classification problem. The experiments with random labels seem to be conducted with multi-class classification. It would be non-trivial to conclude that the complexity is 1 in this case when H is defined as the set of error functions for multi-class classification problem, albeit it seems the result would be true to me (sorry for my hand-waving here).\n\nHowever, Rademacher complexity can also be used to bound the loss (or energy in the energy-based models framework [1]), which is the objective that our algorithm truly optimizes. There are papers that use Rademacher complexity this way. Optimizing a multi-class classification problem will decrease the difference between the upper- and lower-bounds of the loss, therefore decreasing the loss Rademacher complexity, but in very distinct manners between correct label case and random label case. Therefore, the experiments on random labels may not describe anything about loss Rademacher complexity in correct labels.\n\nNote that the previous paragraph linked Rademacher complexity to the dynamics of optimization, not just the hypothesis set. This is because at any stage of optimization (such as at a step of SGD), the set of hypotheses that the algorithm can explore afterwards is limited relative the current hypothesis that the algorithm possesses. There is an evolving upper-bound that the algorithm can never jump out of, because it needs to \"minimize\". This evolving hypothesis set is called \"sublevel hypothesis set\" in [2], which is the reason why the actual Rademacher complexity is evolving with the optimization process, rather than staying static as assumed by this paper or a majority of theoretical papers from the community. Note that all this applies to either correct labels or random labels.\n\nThus far, I think practitioners in deep learning can safely ignore the possible implication from the article that your problem is not bounded in generalization -- that is not yet proven to be true, because the paper misses the piece of ingredient that can combine the dynamics of optimization with complexity measurement, and another ingredient that characterizes the difference between the random-label problem and the correct-label problem to make the result mean anything. These ingradients are discussed in previous research, therefore I think the title about \"rethinking generalization\" is a bit unfair to other people who have contributed to the theory literature.\n\nBelow is a bit \"hand-waving\" on the distinction between random-label problem and correct-label problem. There is one more theorem that I want to mention to motivate more discussions on the difference of optimization between correct labels and random labels. It is the Talagrand's contraction lemma ([3], also a perhaps easier-to-understand version in [2]). It can be used to bound Rademacher complexity R(F(G)) with L * R(G), in which F(G) are the set of composite functions h(g) with h in H and g in G, and L is the maximum possible Liptchitz constant of functions in H.\n\nNote that \"deep\" learning models are essentially function compositions. Talagrand's lemma therefore means that the quality of your deep learning model's generalization bound depends on whether the function compositions have a Liptchitz constant smaller than 1 (that is, \"contracting\"). The conjecture I hope somebody can take a further look at is that, with correct labels, at the final optimization stage you can easily get contracting function compositions, but not with random labels, because the former assumes certain smoothness in some semantic space where classification makes sense.\n\n[1] LeCun, Yann, et al. A tutorial on energy-based learning. Predicting structured data 1 (2006): 0.\n[2] Zhang X. PAC-learning for energy-based models (Master dissertation, Courant Institute of Mathematical Sciences, New York, 2013).\n[3] M. Ledoux and M. Talagrand. Probability in Banach Spaces: Isoperimetry and Processes. Springer, 1991."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396466195, "tcdate": 1486396466195, "number": 1, "id": "ry5E2M8Ox", "invitation": "ICLR.cc/2017/conference/-/paper259/acceptance", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The authors report the experimental findings of a fascinating inquiry on the ability of the deep neural networks to fit randomly labelled data. The investigation is sound, enlightening, and inspiring. The authors propose both a) a theoretical example showing that a simple shallow network with a number of parameters large enough wrt sample size yields perfect finite-sample expressivity; b) a systematic extensive experimental evaluation to support the findings and claims. The experimental evaluation is a model of thoroughness. \n \n This is definitely groundbreaking work, which will inspire many works in the coming years.", "decision": "Accept (Oral)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396466793, "id": "ICLR.cc/2017/conference/-/paper259/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396466793}}}, {"tddate": null, "tmdate": 1486354923922, "tcdate": 1486354821227, "number": 36, "id": "SkTtKOSOl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "By2V8jpDe", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "What was observed in the experiments in Section 5 was probably not due to 'SGD implictly regularizes'.", "comment": "Thank you for the references. David. I wasn't questioning 'SGD implicitly regularizes'. My point was, what was observed in the experiments in Section 5 was not due to 'SGD implictly regularizes', but simply because the initial point was set to zero which led to a kind of 'least norm solution/explicit regularization'. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485841971757, "tcdate": 1485841971757, "number": 35, "id": "By2V8jpDe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "HJIRwLuwe", "signatures": ["~David_Krueger1"], "readers": ["everyone"], "writers": ["~David_Krueger1"], "content": {"title": "SGD: implicit regularization via flat-minima", "comment": "From what I've heard, SGD implicitly regularizes by finding flatter minima, see, e.g.:\nhttp://cims.nyu.edu/~achoroma/NonFlash/Papers/Entropy-SGD.pdf\nhttps://papers.nips.cc/paper/899-simplifying-neural-nets-by-discovering-flat-minima.pdf \n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485497559490, "tcdate": 1485497559490, "number": 34, "id": "BkkJBPdvx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "SyxWiYHDe", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "Thanks", "comment": "Thanks for patiently explaining and for your contributions to the field. I really appreciate it."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485494221865, "tcdate": 1485494221865, "number": 33, "id": "HJIRwLuwe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "A few questions regarding section 5", "comment": "Very inspiring paper. But I got a few questions regarding section 5 and hope that you can help clarify\n\n(1) You showed that the solutions to the linear model solved by SGD lie in the span of the data points, given that the initial point is zero. But this is true not only for SGD, but also for many other first order methods, right? All the analyses related to SGD in this section would hold for many other first order methods as well. So this set of experiments can hardly support your point that SGD acts as implicit regularizer.\n\n(2) You claimed that SGD would often converge to the solution with minimum norm, but I think this happened here mostly because the initial point was set to zero. Any local minimization method would converge to a local minimum that is close to zero(minimum norm solution) if it starts from zero. I do agree SGD may implicitly regularize a model, but I reckon the effect of implicit regularization shown in this set of experiments was probably/mostly because of choosing zero as initial points.\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485365394993, "tcdate": 1485365394993, "number": 32, "id": "ByocgDLve", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "What is the point of section 5?", "comment": "I cannot see how section 5 relates to the rest of the paper.\n\nYou say: \"it is useful to appeal to the simple case of linear models to see if there are parallel insights that can help\nus better understand neural networks.\" but I do not see any relevant insights in this section.\n\nThe claim seems to be that SGD does some implicit regularization.\nIt has been demonstrated previously that SGD implicitly regularizes by finding \"flatter\" minima.\n\nYou seem to suggest that SGD might also regularize implicitly by finding a minimum l2-norm solution, but then your results suggest that this is not the case, because:\n1. l2-regularization only gives a small improvement\n2. wavelet pre-processing increases performance but increases l2-norm\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485364914254, "tcdate": 1485364754439, "number": 31, "id": "SyqzC8Lwg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Bkw66zgve", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Please clarify this section", "comment": "You should mention this in the text.  You do not say that you use a kernel, or that it is the RBF kernel.\n\nWithout specifying otherwise, X should mean the data in the pixel-space.  This is also confusing because when you use the RBF kernel, d = infinity.\n\nAlso, when you say: \"the l2-norm of the minimum norm solution with no preprocessing is approximately 220\" this is in the RBF-kernel feature space, correct?  How does one compute the (approximate) norm in this space?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485310712403, "tcdate": 1485310712403, "number": 30, "content": {"title": "Yes", "comment": "Yes."}, "id": "SyxWiYHDe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "r1tHZ8rwl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485302318791, "tcdate": 1485302318791, "number": 29, "id": "BJvE9DHPe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "HJDLxjbUg", "signatures": ["~Moritz_Hardt1"], "readers": ["everyone"], "writers": ["~Moritz_Hardt1"], "content": {"title": "Yes.", "comment": "We mean *test* error, not training error. Even Yann LeCun's page on MNIST results shows that kernel methods achieve test error roughly in this regime. So, this shouldn't strike you as too surprising. These days the entire kernel matrix fits in main memory on a large machine thus making optimization much easier than back when people reported results for MNIST using kernel methods."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485301811968, "tcdate": 1485301811968, "number": 28, "id": "H1h4dDBPe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "SJHm677Px", "signatures": ["~Moritz_Hardt1"], "readers": ["everyone"], "writers": ["~Moritz_Hardt1"], "content": {"title": "I'd say 'no' for two reasons", "comment": "1. Universality theorems don't say anything about optimization. For example, our paper gives a very simple finite sample universality theorem showing that for any labeling of the function there *exists* a shallow neural net that can fit that labeling. This theoretical result doesn't mean that we can efficiently find such a labeling using stochastic gradient descent. This is however what the experiments show.\n\n2. The fact that there exist neural networks that can fit any labeling of the data doesn't by itself imply that natural architectures used in practice can do so. But this is again something our experiments imply."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485295937288, "tcdate": 1485295937288, "number": 27, "id": "r1tHZ8rwl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "BkCpSj-wx", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "I (think I) get it now", "comment": "Let me try summarize your argument.\n\"As conventional practice with deep neural nets on datasets such as image recognition often involves nets with much more parameters than training samples, we performed many experiments fitting a neural net F to random samples X, where the the number #F of parameters of F are greater than the number of samples |X|. Our findings strongly suggest that in this setting, F can fit most random functions on X, and as such, conventional theories like VC dimension which relies on empirical risk minimization and large sample size cannot distinguish between the case of 1) F fits an image classification function on X, and achieves low generalization error, as occurs in practice, and the case of 2) F fits a random function on X, and achieves not much better generalization error than random guessing.\"\n\nWould you say this accurately captures the argument presented in the \"Rademacher complexity and VC-dimension\" section?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485155634347, "tcdate": 1485155613406, "number": 26, "id": "SJHm677Px", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Universality Theorem", "comment": "According to the universality theorem (UT), (shallow) neural networks can approximate any function. In paper, you showed neural networks can fit a randomly labeled dataset. Don't we expect this phenomenon based on UT? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485081499512, "tcdate": 1485080641810, "number": 25, "id": "r15rubMwe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Kernel Solution?", "comment": "Others have pointed out this in comments. But, I'm confused about the kernel solution.\n\nThe authors mentioned that using the kernel method, we can fit any labeling for MNIST. For actual labeling, they got 1.2% test error, and stated that \"this kernel solution has an appealing interpretation in terms of implicit regularization. Simple algebra reveals that it is equivalent to the minimum L2-norm solution of Xw = y.\"\n\nDoes it mean that the minimum L2-norm solution for MNIST yields 1.2% test error? As I understand, Xw = y is not to be solved in the kernel feature space."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485055430192, "tcdate": 1485055430192, "number": 24, "id": "BkCpSj-wx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "rk4VubZwl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "We are talking about the regime where, roughly, the vc dimension is larger than the number of training examples. You may think it as finite n and d but d >> n; or both n and d goes to infinite but d at a higher speed."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1485015083670, "tcdate": 1485015083670, "number": 23, "id": "rk4VubZwl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "H15Do_gve", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "comment", "comment": "We agree on that. So I'm assuming you disagree with my interpretation of your comment? Could you formulate your argument in the paper precisely? (For example, state clearly in your claim whether you are fixing the hypothesis space, whether n goes to infinity, what do you fix as a constant, etc)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484979061196, "tcdate": 1484979041995, "number": 22, "id": "H15Do_gve", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "ryYuM_evx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "response", "comment": "Yes, absolutely. If you *fix the hypothesis space* and *let n goes to infinity*, then learnability is guaranteed provided finite VC-dimension. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484976753055, "tcdate": 1484976753055, "number": 21, "id": "ryYuM_evx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "BJCY3Qewx", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "Still confused", "comment": "Correct me if I'm wrong. It seems to me that you are saying the following:\n\"Because our empirical experiments indicate that NNs with more than n parameters can learn any function on a fixed sample of size n (i.e. shatters the sample), the bound given by VC theory is uninformative because it predicts O(d/E) samples, where E < 1/n, whereas we used only n << d/E samples to learn the target function on the size n sample.\"\n\nIf this is indeed your argument, then it mistakes sample error for global error, which is what VC theory and PAC learning is concerned with. The bound given in my previous post is for learning a function making at most error E under arbitrary *global distribution*, not just on the sampled points. Your experiments show that NNs with more than n parameters indeed have VC dimension greater than n, but in order to learn the correct function with small error globally, you need many more samples, the number of which is given in my last post.\n\nIf this is not your argument, I apologize, and please elaborate what you mean."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484970237662, "tcdate": 1484970237662, "number": 20, "id": "B18bt8lvl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "S1eCK3JPl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "References", "comment": "Thanks for pointing this out. We have updated this missing reference in the paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484964853648, "tcdate": 1484964853648, "number": 18, "id": "SkAgEBgwl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "ryKka-rLx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "We updated the PDF and added an appendix E to include the results on fitting random labels with explicit regularizers (including data augmentation). \n\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484959695343, "tcdate": 1484959695343, "number": 17, "id": "SyPCk4gve", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "BJtBTu4Lg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "Yes, they are linearly separable in the feature space associated with the kernel. MNIST is an easy dataset and commonly used as demonstration or sanity check in the deep learning community."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484958854510, "tcdate": 1484958854510, "number": 16, "id": "BJCY3Qewx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "r1MQ1b7Ix", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "The bound mentioned here is n = O(d/E). If one solves for E = O(d/n), the conclusion is then clear."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484955070790, "tcdate": 1484955070790, "number": 15, "id": "Bkw66zgve", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "ryfdugePe", "signatures": ["~Oriol_Vinyals1"], "readers": ["everyone"], "writers": ["~Oriol_Vinyals1"], "content": {"title": "Kernels is the answer : )", "comment": "Sure: the model is linear in the \"lifted\" feature space f(x) where f is a basis of the RKHS defined by the RBF kernel. This is called \"kernelization\" -- there are some good books out there explaining these methods in detail. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484945513814, "tcdate": 1484945513814, "number": 14, "id": "ryfdugePe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Linear Models -- what is going on?", "comment": "I am totally confused by the section on linear models.\n\nFor MNIST, d << n, so it seems you *cannot* fit any labelling.\nBut as I understand, you claim to do so, and to achieve 1.2% test error with the result.\n\nCan you please clarify this?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484929590254, "tcdate": 1484929480179, "number": 13, "id": "S1eCK3JPl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Behnam_Neyshabur1"], "readers": ["everyone"], "writers": ["~Behnam_Neyshabur1"], "content": {"title": "Implicit Regularization", "comment": "This is an important discussion and very significant issue.  It's worth noting our ICLR 2015 paper that already raised this issue and argued, based on different experiments, that generalization is coming from the optimization dynamics rather then a capacity bound on the model class, including discussion of explicit and implicit regularization and an analogy to matrix factorization:\n\nhttps://arxiv.org/pdf/1412.6614v4.pdf\n\nBut even though the issue was raised and discussed before, the experiments in the submission are indeed an excellent illustration of how high the capacity of neural networks are, and drives home the point that generalization is coming from a completely different place."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484260985393, "tcdate": 1484229857383, "number": 12, "id": "ryKka-rLx", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "HJJR_fQUg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "loose ends", "comment": "Please allow me to insist : you didn't answer my concerns on the missing experiments on ImageNet with random labels.\n\n\n- You said : (comment on Dec 16th 2016)\n\"For fitting random labels, we only studied random cropping augmentation on cifar10 as reported in the paper. We think investigating other jitter augmentation is an interesting question that merits future study.\"\n\n- You said : (parent comment)\n\"However, we have been able to get zero training error on augmented versions of CIFAR-10 (including crops, rotations, and flips) using the Inception architecture.\".\n\n- The numbers for cifar10 are nowhere to be found in the paper, yet there is : (abstract of the paper)\n\"convolutional networks [...] easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization\"\n\n- Data augmentation is included in \"explicit regularization\" as the paper says : (Sec 1.1, paragraph \"The role of explicit regularization.\")\n\"We show that explicit forms of regularization, such as weight decay, dropout, and data augmentation, [...].\"\n\n\n**** Question 1) Regarding the experiments that you did on augmented versions of CIFAR-10, can you please give the details on the corresponding setup for reproducing your findings ?\n\nI would like to check, in particular, how the number of parameters compares to the total number of augmented samples (upper bounding the size of the augmented dataset, which you say should be not clear how to measure).\n\nYou said you obtained zero training error in that case.\nCan you please update Table 1 with the missing numbers ?\n\n\n**** Question 2) You say : (Section 2.1)\n\"We also tested random labels on the ImageNet dataset [...]\nThe network also manages to reach 90% top-1 accuracy even with explicit regularizers turned on.\"\n\nI would like your confirmation that I understood section 2.1 correctly: did you manage to get a similar result on ImageNet (low training error with data augmentation and random labels) ?\nHow much did you get ?\n\nCan you please update Table 2 with the missing numbers ?\n\n\n**** Question 3) You say : (Section 1.1)\n\"Our central finding can be summarized as: Deep neural networks easily fit random labels.\"\nThis paper studies a form of overfitting. Standard practice (since Krizhevsky 2012) consists in using data augmentation against overfitting. However I see that you chose to exclude data augmentation from some experiments.\n\nOr did you decide that data augmentation was irrelevant for some experiments ? If yes then why ? Can you discuss this in the paper clearly ?\n\nCan you please point out which of your results are still true when this explicit regularizer is activated in your setups ?\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484194165908, "tcdate": 1484193089425, "number": 11, "id": "BJtBTu4Lg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "HJJR_fQUg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Minimum L2 norm solution Xw=y", "comment": "I have two questions about the statement: \"the minimum L2 norm w which satisfies Xw=y does indeed achieve a test error of 1.2%.\"\n\n1- Do you imply that the training data of MNIST are linearly separable? i.e., there exists a \"w\", for which Xw=y, where X is training data and y the corresponding labels.\n2- If we can get test error of 1.2% by minimum L2 norm solution, why do we bother using more complex classifiers, such as neural networks?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484101830646, "tcdate": 1484101830646, "number": 10, "id": "HJJR_fQUg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response to comments and reviews", "comment": "We thank the reviewers for their careful reading of our paper and many helpful questions and suggestions.\n\nWith regards to Reviewer 1\u2019s first question, we believe that this is indeed the most important open question in machine learning.  We intend on pursuing exactly this question in future work.  \n\nBoth Reviewer 2 and a public commenter asked for some clarification for what we mean by random labels.  Specifically, we take the same set of classes as in the original problem.  For each example, we assign to it a random class label.  For example, for CIFAR 10, there are ten classes.  For each example, we choose a random integer between 1 and 10, and assign that example to be in the class indexed by our random integer.  This assignment remains consistent across epochs throughout training.\n\nReviewer 3 requested some clarification of our experiments with kernels.  Indeed, we used a one-versus all classification scheme.  For each class a target vector was constructed with a 1 if the example was in the class and a -1 if the example was not in the class.  Hence, there was a different weight vector for each class.\n\nOne public comment asked about our MNIST experiments.  We clarify that the minimum l2 norm w which satisfies Xw=y does indeed achieve a test error of 1.2%.\n\nWe would also like to respond an additional insightful public comment about data augmentation.   Understanding the benefits of data augmentation is important, but it is not cut and dry as to how to count the number of examples after augmentation.  Since each augmented example is highly correlated  with an existing training example, it is not clear how to measure the size of the augmented data set.  However, we have been able to get zero training error on augmented versions of CIFAR-10 (including crops, rotations, and flips) using the Inception architecture.   Regardless, we note that the conceptual problems raised by our experiments are not resolved whether or not data augmentation is taken into account.\n\nFinally, another excellent public comment raised the issue that non-parametric classifiers can memorize labels.  We fully agree.  That popular neural net architectures behave like non-parametric classifiers is what we are trying to argue in the paper and is somewhat surprising.  Note that it is easy to construct a neural net that cannot memorize---the simplest example being linear regression with a rank-deficient design matrix.  Moreover, the comment suggests that capacity of nonparametric classifiers can be controlled by regularization.  We show in our experiments that the amount of regularization used in practice is not sufficient to control the capacity of neural net models.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484095257918, "tcdate": 1484095257918, "number": 9, "id": "r1MQ1b7Ix", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "Question", "comment": "Congratulations on an excellent paper!\n\nI have a question that I hope one of the authors can humor me. I'm not sure I understand the claim made in the implications section. For example, the following appears in the paragraph *Rademacher complexity and VC-dimension*.\n\n> Deep neural networks with more than n parameters have VC-dimension greater than n, which leads to trivial uniform convergence bounds.\n\nIf we replace \"deep neural networks\" with, say, \"linear thresholds\", the premise of this statement still holds, but the clause following \"which\" is false, as standard VC arguments show that linear thresholds are PAC learnable. More precisely, the class of linear threshold functions on R^d has d+1 parameters and VC dimension d+1, and by (essentially) the Sauer-Shelah Lemma, the number of samples required to learn linear thresholds to within error E and with (1 - D) confidence is O(E^-1 log D^-1 + d E^-1 log E^-1), which is a nontrivial \"uniform convergence bound.\" (Kearns and Vazirani 1994)\n\nCould the authors clarify what is meant in the above statement and perhaps present their arguments more explicitly for the reader?\n\n[1] Kearns, Michael, and Umesh Vazirani. 1994. An Introduction to Computational Learning Theory.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484048474373, "tcdate": 1484048451025, "number": 8, "id": "HJjHdrzIl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "H1S_oDbNg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "where ?", "comment": "Hi,\n\nI can't find the section where you studied random cropping augmentation on cifar10 for fitting random labels.\nI don't see the numbers in Table 1. Can you add them ?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1484005454571, "tcdate": 1484005454571, "number": 7, "id": "HJDLxjbUg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Is test accuracy of the Kernel method really ~99%?", "comment": "Hi,\n\nIn paper, you derived a kernel solution XX^T a = y, and then mentioned that \"On MNIST with no preprocessing, we are able to achieve a test error of 1.2% by simply solving (3).\" Is it a typo that you achieved test error of ~1%? Isn't it the training error? \n\nYou then mentioned that \"Note that this kernel solution has an appealing interpretation in terms of implicit regularization. Simple algebra reveals that it is equivalent to the minimum L2-norm solution of Xw = y\". So, one may wonder how \"minimum L2-norm solution\" yields ~99% accuracy on test data?!\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1483971134596, "tcdate": 1483971134596, "number": 6, "id": "BkwBqzZ8e", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "A classic result of non-parametric methods?", "comment": "Dear authors,\n\nAny non-parametric classifier (with number of parameters = O(number of data)) can memorize random labels. For instance, one can reproduce the result in this submission with 1-nearest neighbour and random forest classifiers in less than 10 lines of Python. Do 1-nearest neighbour and random forest classifiers \"require rethinking generalization\"? It is unsurprising that the Rademacher complexity of non-parametric classifiers is constant, since their number of parameters grows with data, and their capacity is controlled via regularization.\n\n```\nfrom sklearn.ensemble import RandomForestClassifier as rf\nfrom sklearn.neighbors import KNeighborsClassifier as kn\nimport numpy as np\n\nnp.random.seed(0)\n\nn = 1000\nx = np.random.randn(n,224*224)  # random ImageNET-sized images\ny = np.random.randint(2,size=n) # random labels\n\nprint(rf(n_estimators=n).fit(x,y).score(x,y)) # training accuracy = 1.0\nprint(kn(n_neighbors=1).fit(x,y).score(x,y))    # training accuracy = 1.0\n```"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1482448373484, "tcdate": 1482448373484, "number": 5, "id": "Skag0RK4e", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Some questions about random labels", "comment": "-Could you please clarify how did you do the \"random labels\" modification to the input labels? are \"all\" labels from a given class mapped to the \"same\" random label? (more specifically, two examples have the same label before modification, will they have same random label after the modification) or a label is replaced with a random one regardless of its original label (i.e. two examples have same labels before modifications, will likely get two different random labels)? \n- Let's take cifar10 as an example. The original data set has 10 classes, after the \"random label\" modification how many classes are there? 10? >10? <10? \n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1482291950801, "tcdate": 1482291950801, "number": 3, "id": "HJwljOv4x", "invitation": "ICLR.cc/2017/conference/-/paper259/official/review", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["ICLR.cc/2017/conference/paper259/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper259/AnonReviewer3"], "content": {"title": "", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "This paper offers a very interesting empirical observation regarding the memorization capacity of current large deep convolutional networks. It shows they are able to perfectly memorize full training-set input-to-label mapping, even with random labels (i.e. when label has been rendered independent of input), using the same architecture and hyper-parameters as used for training with correct labels, except for a longer time to convergence. \nExtensive experiments support the main argument of the paper. \n\nReflexions and observations about finite-sample expressivity and implicit regularization with linear models fit logically within the main theme and are equally thought-provoking.\n\nWhile this work doesn\u2019t propose much explanations for the good generalization abilities of what it clearly established as overparameterized models,\nit does compel the reader to think about the generalization problem from a different angle than how it is traditionally understood.\n\nIn my view, raising good questions and pointing to apparent paradox is the initial spark that can lead to fundamental progress in understanding. So even without providing any clear answers, I think this work is a very valuable contribution to research in the field.\n\nDetailed question: in your solving of Eq. 3 for MNIST and CIFAR10, did you use integer y class targets, or a binary one-versus all approach yielding 10 discriminant functions (hence a different alpha vector for each class)?\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512645072, "id": "ICLR.cc/2017/conference/-/paper259/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper259/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper259/AnonReviewer1", "ICLR.cc/2017/conference/paper259/AnonReviewer2", "ICLR.cc/2017/conference/paper259/AnonReviewer3"], "reply": {"forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512645072}}}, {"tddate": null, "tmdate": 1482092980036, "tcdate": 1482092980036, "number": 2, "id": "B1nh-uNVl", "invitation": "ICLR.cc/2017/conference/-/paper259/official/review", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["ICLR.cc/2017/conference/paper259/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper259/AnonReviewer2"], "content": {"title": "", "rating": "9: Top 15% of accepted papers, strong accept", "review": "This paper presents a set of experiments where via clever use of randomization and noise addition authors demonstrate the enormous modeling (memorization) power of the deep neural networks with large enough capacity.  Yet these same models have very good generalization behavior even when all obvious explicit or implicit regularizers are removed.  These observations are used to argue that classical theory (VC dimension, Rademacher complexity, uniform stability) is not able to explain the generalization behavior of deep neural networks, necessitating novel theory.\n\nThis is a very interesting and thought provoking body of work and I am in complete accord with the observations and conclusions of the paper.  The classical generalization theory is indeed often at a loss with complex enough model families.  As the authors point out, once model families reach a point where they have capacity to memorize train sets, the classical theory does not yield useful results that could give insight into generalization behavior of these models, leaving one to empirical studies and observations.\n\nA minor clarification comment: On page 2, \u201c \u2026 true labels were replaced by random labels.\u201d  Please state that random labels came from the same set as the true labels, to clarify the experiment.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512645072, "id": "ICLR.cc/2017/conference/-/paper259/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper259/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper259/AnonReviewer1", "ICLR.cc/2017/conference/paper259/AnonReviewer2", "ICLR.cc/2017/conference/paper259/AnonReviewer3"], "reply": {"forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512645072}}}, {"tddate": null, "tmdate": 1481922083492, "tcdate": 1481922083492, "number": 4, "id": "SysXLR-Nl", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "H1S_oDbNg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "follow-up", "comment": "I think there is something deeper here and a result of major importance is missing, that could make the paper significantly stronger.\n\n---\n\nI am glad that you ran the ImageNet experiment with AlexNet because it raises the following issue :\n- I believe [Krizhevsky et al. 2012] sets the standard for \"practice\" in training neural networks and I hope we all agree on this. This paper uses data augmentation as part of the training scheme, which means that the number of data points evaluated by the neural network is 2048 * 1.2 million = over 2 billion.\n=> AlexNet has 60 million parameters. \n=> Data augmentation is used to exactly combat overfitting, which in some sense is what this paper seems to analyze.\n=> If my understanding is correct, in practice the number of data points far exceeds the number of parameters.\n=> This fact seems to contradict what is in the abstract : \"as soon as the number of parameters exceeds the number of data points *as it usually does in practice*\" (emphasis added) so I am afraid it might be a little misleading for readers, and I hope the authors can either point where I am wrong and/or clarify this issue in the paper.\n\n---\n\nThe abstract says that \"Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization [...]\"\n\nOne of the most spectacular results in this paper is that AlexNet can learn a random labeling of ImageNet. (This result was notably shown in a slide of a presentation from one of the authors of the paper, which made a bit of a splash.)\n\nHowever, I noticed in the appendix that in the Table 2, the experiment \"ImageNet 1000 classes with random labels\" was never run with data augmentation, which is the most popular explicit regularization scheme. This table looks incomplete to me.\n\nI am very eager to see the result of this experiment because I believe it would make the paper much stronger and substantiate the claims much better.\n\n---\n\nIt is my opinion that either the claims should be weakened or this result needs to be included. My hope is that the setup built by the authors should be ready to run this experiment and the paper can be amended accordingly by the acceptance deadline.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1481894765623, "tcdate": 1481894765623, "number": 3, "id": "H1S_oDbNg", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "rkxMxtu7x", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "response", "comment": "For fitting random labels, we only studied random cropping augmentation on cifar10 as reported in the paper. We think investigating other jitter augmentation is an interesting question that merits future study."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1481662157658, "tcdate": 1481662157651, "number": 1, "id": "rJUCC0pQg", "invitation": "ICLR.cc/2017/conference/-/paper259/official/review", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["ICLR.cc/2017/conference/paper259/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper259/AnonReviewer1"], "content": {"title": "Memorization, overfitting, generalization", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "the authors of this work shed light on the generalization properties of deep neural networks. Specifically, the consider various regularization methods (data augmentation, weight decay, and dropout). They also show that quality of the labels, namely label noise also significantly affects the generalization ability of the network.\n\nThere are a number of experimental results, most of which are intuitive. Here are some specific questions that were not addressed in the paper:\n1. Given two different DNN architectures with the same number of parameters, why do certain architectures generalize better than others? In other words, is it enough to consider only the size (# of parameters) of the network and the size of the input (number of samples and their dimensionality), to be able to reason about the generalization properties of a given network?\n\n2. Does it make sense to study the stability of predictions given added dropout during inference?\n\nFinally, provided a number of experiments and results, the authors do not draw a conclusion or offer a strong insight into what is going on with generalization in DNNs or how to proceed forward. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512645072, "id": "ICLR.cc/2017/conference/-/paper259/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper259/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper259/AnonReviewer1", "ICLR.cc/2017/conference/paper259/AnonReviewer2", "ICLR.cc/2017/conference/paper259/AnonReviewer3"], "reply": {"forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512645072}}}, {"tddate": null, "tmdate": 1481617050141, "tcdate": 1481617050135, "number": 2, "id": "HJGjCmpQe", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "r1nuL7-Qx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Response", "comment": "1) Yes, we monitored both the objective function (cross entropy) and the accuracy. The training objective in all cases converges to a near-zero quantity.  The cross entropy on the test set tracks the training error and then curves upward.  However, this increase in the test cross entropy is because the model becomes more confident about labels it has labeled incorrectly.  \n\n2) For simplicity, we assumed infinite precision in our construction.  In finite precision, one could repeat the construction O(log(n)) times to avoid collisions."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1481310216448, "tcdate": 1481310216441, "number": 1, "id": "rkxMxtu7x", "invitation": "ICLR.cc/2017/conference/-/paper259/public/comment", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Data augmentation + random labels", "comment": "Can you still fit random labels on the training set when using jittering data augmentation ?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287661515, "id": "ICLR.cc/2017/conference/-/paper259/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sy8gdB9xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper259/reviewers", "ICLR.cc/2017/conference/paper259/areachairs"], "cdate": 1485287661515}}}, {"tddate": null, "tmdate": 1480828531684, "tcdate": 1480828531678, "number": 1, "id": "r1nuL7-Qx", "invitation": "ICLR.cc/2017/conference/-/paper259/pre-review/question", "forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "signatures": ["ICLR.cc/2017/conference/paper259/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper259/AnonReviewer3"], "content": {"title": "What about the optimizaiton objective? And finite-limited-precision?", "question": "1) Your experiments consider classification error, but the loss being optimized is always a different surrogate loss (e.g. conditional log likelihood). Did you look at the effect on the actual training objective being optimized? Can you comment on that?\n\n2) Regarding the result on effective finite sample expressivity. This results relies on the ability to uniquely identify each of your n d-dimensional training data points, after projection, as a single unique real number. Isn\u2019t this feasible primarily because they are \u00ab\u00a0true\u00a0\u00bb real values. Would it not break at some point with finite-limited-precision values?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can\nexhibit a remarkably small difference between training and test performance.\nConventional wisdom attributes small generalization error either to properties\nof the model family, or to the regularization techniques used during training.\n\nThrough extensive systematic experiments, we show how these traditional\napproaches fail to explain why large neural networks generalize well in\npractice. Specifically, our experiments establish that state-of-the-art\nconvolutional networks for image classification trained with stochastic\ngradient methods easily fit a random labeling of the training data. This\nphenomenon is qualitatively unaffected by explicit regularization, and occurs\neven if we replace the true images by completely unstructured random noise. We\ncorroborate these experimental findings with a theoretical construction\nshowing that simple depth two neural networks already have perfect finite\nsample expressivity as soon as the number of parameters exceeds the\nnumber of data points as it usually does in practice.\n\nWe interpret our experimental findings by comparison with traditional models.", "pdf": "/pdf/a667dbd533e9f018c023e21d1e3efd86cd61c365.pdf", "TL;DR": "Through extensive systematic experiments, we show how the traditional approaches fail to explain why large neural networks generalize well in practice, and why understanding deep learning requires rethinking generalization.", "paperhash": "zhang|understanding_deep_learning_requires_rethinking_generalization", "keywords": ["Deep learning"], "conflicts": ["mit.edu", "zju.edu.cn", "google.com", "berkeley.edu"], "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Benjamin Recht", "Oriol Vinyals"], "authorids": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "brecht@berkeley.edu", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959374999, "id": "ICLR.cc/2017/conference/-/paper259/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper259/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper259/AnonReviewer3"], "reply": {"forum": "Sy8gdB9xx", "replyto": "Sy8gdB9xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper259/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959374999}}}], "count": 50}