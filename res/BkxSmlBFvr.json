{"notes": [{"id": "BkxSmlBFvr", "original": "r1xiM4ltPH", "number": 2209, "cdate": 1569439772923, "ddate": null, "tcdate": 1569439772923, "tmdate": 1583912048526, "tddate": null, "forum": "BkxSmlBFvr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 21, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "Xyls5Y1Vra", "original": null, "number": 1, "cdate": 1576798743275, "ddate": null, "tcdate": 1576798743275, "tmdate": 1576800892930, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The authors analyze knowledge graph embedding models for multi-relational link predictions. Three reviewers like the work and recommend acceptance. The paper further received several positive comments from the public. This is solid work and should be accepted.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714255, "tmdate": 1576800264065, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Decision"}}}, {"id": "SyeyqnfijH", "original": null, "number": 10, "cdate": 1573756038866, "ddate": null, "tcdate": 1573756038866, "tmdate": 1573756038866, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "S1x__2kciB", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"title": "Regarding comment 2", "comment": "We have added Fig. 9 to our paper along the lines discussed above. The figure suggests that decent (but often not very good) configurations can be found by simply training for less than 400 epochs."}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "S1x__2kciB", "original": null, "number": 8, "cdate": 1573678192238, "ddate": null, "tcdate": 1573678192238, "tmdate": 1573678516860, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "Syljyis0Kr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"title": "Thank you for your feedback and support", "comment": "We thank you for your feedback and appreciate your support. In what follows, we briefly comment on the points raised in your review.\n\n1. There are no such limitations in our experimental framework that we are aware of.\n\n2. Good point! Generally, it may indeed be possible to short-circuit hyperparameter search but that is beyond our current study. Our framework is extensible, however, so that there shouldn't be any principal limitations in adding other hyperparameter optimization methods (and we'd like to include more). What we can do for the present study is to include plots that show model performance (e.g., best validation MRR obtained over all hyperparameter configurations) as a function of the epochs each configuration has been trained. The new plots will give information about how fast models can find good configurations and compare different models along these lines. Would you consider this helpful?\n\n3. Our goal was to have a fair, balanced comparison, but not to find perfect hyperparameters. For example, the ComplEx result mentioned in the \"Limitations\" section uses a configuration which is indeed within our search space but was not found during our hyperparameter search. Of course, the more effort we spend on  hyperparameter search, the better models we may find.\n\n4. We consciously did not report performance on an \"collectively good configuration\". A key point that we are trying to make is that there is no such configuration: any configuration will be good for some models but bad for others. The same argument extends to small search grids.\n\n5. Thanks for bringing this to our attention. We use (1) and will include a formal definition of the metrics in the appendix.\n\n6. Thanks, added.\n\n7. Thanks, fixed.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "SygQK6kqoS", "original": null, "number": 9, "cdate": 1573678458927, "ddate": null, "tcdate": 1573678458927, "tmdate": 1573678458927, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "H1gAye5RtB", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"title": "Thank you for your feedback and support", "comment": "We thank you for your feedback and appreciate your support. In what follows, we briefly comment on the points raised in your review.\n\n1. \"For the comparison between the trained models and previously published results, the sample size might be sufficient to draw the conclusions. However, the intra-model comparison, e.g. in Figure 2, are now comparing subsets of the runs which only comprise approx. (200/6) runs.\"\n\nRESPONSE: We agree. The sample size for the intra-model comparisons is 30 (sometimes more); estimates such as the median MRR will be subject to variance. We chose to show the full distribution of the scores, however,\n  which gives a better picture than point estimates and exposes variance (e.g., bottom right of Fig 2.: high for first 2 bars, low for 3rd bar).\n\n2. \"The influence of random initialization is not accounted for.\"\n\nRESPONSE: Indeed, and it should be accounted for. We trained all models of Tab. 2 five times; the largest observed standard deviation for MRR was no more than 0.002, i.e., very low. This high stability is in line with prior studies; e.g., Sun et al. (2019). We will revise the paper and report mean and std. dev. of 5 training runs instead of the result of a single run.\n\n3. \"For some ablations, e.g. TransE + Reciprocal, no reduction is given.\"\n\nRESPONSE: We added the use of reciprocal relations to TransE and are rerunning the corresponding experiments. We indeed found improvements in TransE's performance due to the use of reciprocal relations and will update the paper accordingly. ConvE, on the other hand, cannot be used without reciprocal relations.\n\n4. \"Also for the other ablations, it is unclear how statistically significant the reduction is.\"\n\nRESPONSE: Especially the smaller effects may indeed not be significant. Note, however, that the \"winning configuration\" is consistently compared to a larger number of \"ablation configurations\". For example, 1/3 of the configurations use CE (winning configuration), but 2/3rd do not (ablation configurations).\n\n5. \"Please add the best published results for a specific model-dataset combination to table 2.\"\n\nRESPONSE: The performance of DistMult and ComplEx given in the \"Large\" section of Tab. 2 are---to the best of our knowledge---the best reported numbers for these two models. For TransE, we added a reference to the best reported number to the limitations section. For RESCAL and ConvE, our study reports the best numbers, again to the best of our knowledge.\n\n6. \"Do the plots in Figure 1 include the runs which were stopped after 50 epochs due to insufficient MRR?\"\n\nRESPONSE: Yes. We may include statistics about the number of such configurations in the appendix. Would you consider this helpful? Generally, this statistic may serve as an indication of how easy it is to find a decent hyperparameter configurations for each model and dataset.\n   \n7. \"Could you elaborate on the combination of KvsAll and CE?\"\n\nRESPONSE: In KvsAll, examples correspond to \"questions\" such as (i,k,?) and all its true answers. We compute the cross entropy between the model distribution and the empirical distribution over all answers. The model distribution is given by the softmax distribution over the model scores s(i,k,?). The empirical distribution is given by the labels for all entities (for j-th entity: 1 if (i,k,j) in training data, 0 otherwise) normalized to sum to one. I.e., the empirical distribution for $n$ true answers to (i,k,?) assigns probability $1/n$ to each of the true answers and zero to everything else. In 1VsAll, on the other hand, examples directly correspond to training triples, as in prior work. The model distribution again correspond to softmax scores, but the data distribution now has a single 1 (the entity present in the current training triple). This matches the notion used by Kadlec et al.\n\n8. \"The combination of subject and object triple scores has for instance been used in simple [2].\"\n\nRESPONSE: Thanks, we added the reference to the \"reciprocal relations\" section.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "S1g1xsJqoH", "original": null, "number": 7, "cdate": 1573677798643, "ddate": null, "tcdate": 1573677798643, "tmdate": 1573677798643, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "SkemmQtecS", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"title": "Thank you for your feedback and support", "comment": "We thank you for your feedback and appreciate your support. We added a short explanation on quasi-random search to the main paper. We also plan to provide more details in the framework documentation (which also supports other methods for hyperparameter optimization).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "H1gAye5RtB", "original": null, "number": 1, "cdate": 1571885030274, "ddate": null, "tcdate": 1571885030274, "tmdate": 1572972368877, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper presents an experimental study about some KGE methods. It argues that papers often propose changes in several different dimensions, such as model, loss, training, regularizer, etc., at once without providing a sufficient investigation about the individual components' contributions. The experimental study considers two datasets (FB15k-237 and WNRR) and five different models (RESCAL, TransE, DistMult, ComplEx, ConvE). The models were selected using a quasi-random hyperparameter search, followed by a short Bayesian optimization phase to fine-tune the parameters. The performance of the best models found during this hyperparameter search are compared to first published results for the same model, as well as to a small selection of recent papers. To analyse the influence of single hyperparameters, the best found configuration is compared to the best configuration which does not use this specific value for the given hyperparameter.\n\nOverall, the paper adresses an important problem, as papers about new KGE methods often lack a clear separation of the individual changes' contribution. The experimental results show that older, simpler can compete with recently proposed models when trained properly. The intra-model comparison lacks statistical rigorousity, yet hints a few directions to further explore.\n\nThe experiments are based on a quasi-random hyperparameter search. While it is necessary for efficient exploration of larger search spaces [1], and should be the standard methodology for hyperparameter search of a new method, the interpretability of the comparison of two runs suffers. For the comparison between the trained models and previously published results, the sample size might be sufficient to draw the conclusions. However, the intra-model comparison, e.g. in Figure 2, are now comparing subsets of the runs which only comprise approx. (200/6) runs. Furthermore, the influence of random initialization is not accounted for. Another place where this can be witnessed is Table 3. Here, for some ablations, e.g. TransE + Reciprocal, no reduction is given. If I understood it correctly, this is due to not having a configuration which uses TransE and reciprocal relations. Also for the other ablations, it is unclear how statistically significant the reduction is.\n\n\nFurther Comments:\n1. Please add the best published results for a specific model-dataset combination to table 2.\n2. Do the plots in Figure 1 include the runs which were stopped after 50 epochs due to insufficient MRR?\n3. Could you elaborate on the combination of KvsAll and CE?\n4. The combination of subject and object triple scores has for instance been used in SimplE [2].\n\n\n[1] Bergstra, James, and Yoshua Bengio. \"Random search for hyper-parameter optimization.\" Journal of Machine Learning Research 13.Feb (2012): 281-305.\n[2] Kazemi, Seyed Mehran, and David Poole. \"Simple embedding for link prediction in knowledge graphs.\" Advances in Neural Information Processing Systems. 2018.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575763298365, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Reviewers"], "noninvitees": [], "tcdate": 1570237726140, "tmdate": 1575763298390, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review"}}}, {"id": "Syljyis0Kr", "original": null, "number": 2, "cdate": 1571891939275, "ddate": null, "tcdate": 1571891939275, "tmdate": 1572972368828, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary\n========\nThe paper conducts a thorough analysis of existing models for constructing knowledge graph embeddings. It focuses on attempting to remove confounding aspects of model features and training regime, in order to better assess the merits of KGE models. The paper describes the reimplementation of five different KGE models, re-trained with a common training framework which conducts hyperparameter exploration. The results show surprising insights, e.g., demonstrating that a system from 2011, despite being the earliest of the KGE models analyzed, demonstrates competitive results over a more recent (2017) published model.\n\nOverall Comments\n===============\nThe paper, and the described software release specifically, represent a solid contribution to the area of knowledge graph embeddings. I agree with the basic premise of this paper\u2019s analysis: in order to accelerate research in a maturing field (like knowledge graphs), it is important to be able to properly compare with older systems, removing artifacts that are due to general improvements in training and optimization techniques, from modeling specific changes. The report of the strong results from the RESCAL system, along with others, drive the point through. Furthermore, the paper is well-written and easy to follow, and should become a good reference for future works on KGEs.\n\nDetailed comments\n===============\nBelow are some detailed comments about specific parts of the paper, in order of importance:\n\n1. The paper mentions disregarding \u201cmonolithic\u201d models in the current analysis, primarily due to the expensive training of these models. It may, however, be the case that the future state-of-the-art models will be larger and slower to train (and, perhaps, of the monolithic type). Are there any limitations to the proposed experimental framework that would prevent running monolithic/large models?\n\n2. Regarding the item above, if one were to look at the training curves for the exploration of the current 5 KGE models, is it possible that verify winning hyperparameter configurations earlier than the full training is complete. In my experience, it is often the case that with fewer than 1/10th steps of full training (well before convergence), it is possible to compare model configurations (relatively). For example, \u201cPopulation-base training\u201d (https://arxiv.org/abs/1711.09846, https://arxiv.org/abs/1902.01894) is one framework where fewer training steps are used to quickly learn good hyperparameter configurations. I\u2019m wondering whether the KGE hyperparameter exploration training curves display similar early trends. Could a shortened training procedure produce sufficient information for learning good parameters, and potentially deal with larger/slower models?  In addition: would adopting population-based training be applicable to the proposed framework?\n\n3. In Section 3.2, \u201cLimitations\u201d, there is a surprising comment that performance can be improved with further hyperparameter tuning. It is not clear how the authors found the configurations that produced the improved results. It would be helpful to clarify why the hyperparameter exploration proposed in the paper did not discover these improved configurations. Were the improved configurations outside of the range of considered values? Or would the exploration require more points to find the improved configuration?\n\n4. In Section 3.3 \u201cBest configurations (quasi-random search)\u201d, specifically Table 3, the paper presents an ablation of independent hyperparameters, over the best configuration for each of the 5 models. This is a very interesting section. One further suggestion, however, is whether the paper could include the performance of each of the models on the _average_ best configuration. Although the paper describes losses for switching individual parameters to their second best values, it is unlikely that the losses are cumulative. So, for example, if we can take the average/majority best value for each parameter (embedding size = 512, batch size = 1024, training type = 1vsall, loss = CE, etc.), and collect results for that configuration. I think it would be interesting to know the difference between a model trained on a \u201ccollectively known good\u201d set of parameters vs. a model and task specific tuned set of parameters.\n\n5. In Section 2, \u201cEvaluation\u201d, HITS@k is not formally defined. Unfortunately, I have encountered slight variants of this metrics (e.g: (1) given a SINGLE correct label, HITS@k is the average rate of the label being present in the top k scored results, or (2) given ALL possible correct labels, HITS@k is the percentage of correct labels present within the top k scored results, etc.). It would be nice to precisely describe HITS@k in this work.\n\n6. Caption for Table 2 does not contain a description for the \u201cRecent\u201d super-column.\n\n7. In Section 3.3 \u201cBest configuration (quasi-random search)\u201d Space missing at \u201c... Tables 6 and 7(in \u2026\u201d, between 7 and (.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575763298365, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Reviewers"], "noninvitees": [], "tcdate": 1570237726140, "tmdate": 1575763298390, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review"}}}, {"id": "SkemmQtecS", "original": null, "number": 3, "cdate": 1572012827279, "ddate": null, "tcdate": 1572012827279, "tmdate": 1572972368780, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Authors did an extensive experimental study over neural link prediction architectures that was never done before, in such a systematic way, by other works in this space. Their findings suggest that some hyperparameters, such as the loss being used, can provide substantial improvements to some models, and can be the reason of the significant improvements in neural link prediction accuracy the community observed in recent months.\n\nThis is a really interesting paper, and can really shine some light on what was going on in neural link prediction over recent years. It also provides a great overview of the field -- in terms of architectures, loss functions, regularizers, sampling strategies, data augmentation strategies etc. -- that is really needed right now in the field.\n\nOne concern I have is that the hyperparameter tuning strategy is not really described -- authors just say something along the lines of \"we use av.dev\", but for those unfamiliar with this specific hyperparameter optimiser this does not provide much information (e.g. what is a Sobol sequence? I had to look it up)."}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575763298365, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Reviewers"], "noninvitees": [], "tcdate": 1570237726140, "tmdate": 1575763298390, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Review"}}}, {"id": "r1xoUNL2YB", "original": null, "number": 7, "cdate": 1571738707106, "ddate": null, "tcdate": 1571738707106, "tmdate": 1571738707106, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkgToE_PtH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"title": "Cross entropy with KvsAll ", "comment": "Yes, the question has been answered. Thanks.\n(It is still puzzling though why  KvsAll & CE performs sometimes better than KvsAll & BCE, as they both are based on the local closed world assumption.)"}, "signatures": ["~Jae_Hee_Lee2"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Jae_Hee_Lee2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "BkgToE_PtH", "original": null, "number": 6, "cdate": 1571419301415, "ddate": null, "tcdate": 1571419301415, "tmdate": 1571419338440, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "H1edT58ztH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Hi Jae, thanks for the support. As for your question, we are not using the CE definition of Kadlec et al., but directly the notion of cross entropy. Consider training point (i,k,j) and task (i,k,?) for which we compute the cross entropy between the model distribution, i.e. the softmax distribution of the scores s(i,k,?), and the data, i.e. the empirical distribution. For 1vsAll, the empirical distribution assigns probability 1 at position j, i.e., the true label, the rest is zero. This matches the notion used by Kadlec et al. For KvsAll, the empirical distribution for n true answers to (i,k,?) assigns probability 1/n to each of the true answers, zero to everything else. Does this clarify?", "title": "Cross entropy with KvsAll"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "SJgHpTUPtr", "original": null, "number": 5, "cdate": 1571413436827, "ddate": null, "tcdate": 1571413436827, "tmdate": 1571413436827, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BklXjDgCur", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Hi Apoorv, thanks for bringing this to our attention!", "title": "Thanks"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "H1edT58ztH", "original": null, "number": 6, "cdate": 1571084991587, "ddate": null, "tcdate": 1571084991587, "tmdate": 1571136910100, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "Hi, first of all I want to say that I totally support this line of work. Researchers working on KGE (and also on other topics as well!) should deal the baselines fairly and pay as much attention to them as they do to their own models.\n\nOne thing that I found not so clear in the paper is how the cross entropy loss (CE) is combined with KvsAll. (Note that this combination is used for the most of the best performing models on WN18RR in Table 3 of the paper).\nIt is clear to me that, based on the loss definition in [Kadlec et al., 2017], CE can be combined with 1vsAll. But it is not straight forward how CE can be combined with KvsAll, as claimed in line 7-8, page 4: \"CE ...  has also been used in the multi-label setting (KvsAll)\". Please either add a reference to the claim or give a more detailed explanation.", "title": "Combining Cross Entropy with KvsAll"}, "signatures": ["~Jae_Hee_Lee2"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Jae_Hee_Lee2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "BklXjDgCur", "original": null, "number": 5, "cdate": 1570797466898, "ddate": null, "tcdate": 1570797466898, "tmdate": 1570797466898, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "Much needed analysis! \nI just want to add that in the Appendix of RotatE [1], they have done an ablation study on TransE where they have achieved 0.333 MRR for TransE on FB15k-237 dataset using adversarial negative sampling. I have been able to reproduce the same using the code they provided. I felt this might be relevant for your paper, since your paper reports the best of 0.303\n\nThanks\n\n[1] RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space https://arxiv.org/abs/1902.10197", "title": "Best reported results of TransE"}, "signatures": ["~Apoorv_Umang_Saxena1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Apoorv_Umang_Saxena1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "HygxCrNiOB", "original": null, "number": 4, "cdate": 1570616776180, "ddate": null, "tcdate": 1570616776180, "tmdate": 1570616776180, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "r1x8cXwS_B", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Hi Chen, thanks for the comments. We plan on extending our study to include more models and datasets. In addition, we will release our framework as open source, and since adding new models is straightforward, we hope this will help to keep a growing list of comparable results for KGE models.", "title": "More models and datasets in the future"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "r1x8cXwS_B", "original": null, "number": 4, "cdate": 1570235278127, "ddate": null, "tcdate": 1570235278127, "tmdate": 1570235278127, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "Hello,\n\nVery interesting and solid work. I would like to provide a different perspective for KGE that might be helpful. In paper [1], I give a group-theoretic treatment of KGE and connect different models as modeling relations in KG as elements in different groups. \n\nFrom this perspective, RESCAL is actually quite powerful since it corresponds to $GL(n, R)$. Other more recent methods correspond to other \"smaller\" groups. I would not be surprised that if optimization is done right, RESCAL can perform as well as other methods due to its very general form. \n\nTo me, the most interesting thing is to quantify the improvement of modeling non-communicative relations (son\u2019s wife is not wife\u2019s son) by going from the abelian group to the non-abelian group.  RotatE can essentially model any finite abelian group (proved in [1]), and for non-abelian group, I saw three recent work [2][3][4]. It would be interesting to see under your evaluation platform, how much gain can we get by modeling non-abelian groups.\n\n[1] Group Representation Theory for Knowledge Graph Embedding https://arxiv.org/abs/1909.05100\n[2] Quaternion Knowledge Graph Embedding https://arxiv.org/abs/1904.10281\n[3] Relation Embedding with Dihedral Group in Knowledge Graph https://arxiv.org/abs/1906.00687\n[4] A Group-Theoretic Framework for Knowledge Graph Embedding (ICLR this year) https://openreview.net/forum?id=r1e30AEKPr", "title": "Group perspective"}, "signatures": ["~Chen_Cai1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Chen_Cai1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "HkeWpqyWdr", "original": null, "number": 3, "cdate": 1569942200725, "ddate": null, "tcdate": 1569942200725, "tmdate": 1569942274949, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "rylDuHjyuH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Thanks Tim for clearing this up. Also thanks to both Tim and Bahare Fatemi for the hint regarding the  SimplE paper, we will use those references.\n", "title": "Thanks for the clarification!"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "HJxeXqyb_H", "original": null, "number": 1, "cdate": 1569942040414, "ddate": null, "tcdate": 1569942040414, "tmdate": 1569942263640, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "r1g5orsAPH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Thank you for the comments. We will try to include data and a discussion about the different regularization techniques in the appendix. Also, thanks for the pointers to [1,2] with respect to introducing reciprocal relations; we'll add the corresponding references.", "title": "Regularization techniques and reciprocal relations"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "BkgFtc1Z_H", "original": null, "number": 2, "cdate": 1569942145200, "ddate": null, "tcdate": 1569942145200, "tmdate": 1569942145200, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "Hkg-AmjJdH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment", "content": {"comment": "Thanks and absolutely! The paper will be accompanied with an open-source software framework (on GitHub, currently private), which implements the different training techniques, models, and hyperparameter search. We have briefly mentioned this in the \"Reproducibility\" section in the paper, but will say more on the project homepage once the paper is deanonymized. We may be able to provide a dump of the codebase upfront, but we are not sure if we can do so truly anonymously.", "title": "Our framework will be released as open source"}, "signatures": ["ICLR.cc/2020/Conference/Paper2209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2209/Authors|ICLR.cc/2020/Conference/Paper2209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144741, "tmdate": 1576860555508, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Official_Comment"}}}, {"id": "rylDuHjyuH", "original": null, "number": 3, "cdate": 1569858926589, "ddate": null, "tcdate": 1569858926589, "tmdate": 1569858926589, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "r1g5orsAPH", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "My original work (Dettmers et al., 2018) did not use reciprocal relations. However, when a bug was identified in my codebase [1], I made use of reciprocal relations to allow for the continued use of 1-K predictions. I updated my paper with new, corrected results, and I did not update my paper with the precise definitions of using reciprocal relations. As such, I would attribute the first defined use of reciprocal relations to Kazemi & Poole (2018) and Lacroix et. al (2018) as mentioned by Bahare Fatemi.\n\n[1] https://github.com/TimDettmers/ConvE/issues/18", "title": "Timeline of the use of reciprocal relations."}, "signatures": ["~Tim_Dettmers2"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Tim_Dettmers2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "Hkg-AmjJdH", "original": null, "number": 2, "cdate": 1569858504602, "ddate": null, "tcdate": 1569858504602, "tmdate": 1569858504602, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "In my personal research, I found that there was always high variability between different code-bases and approaches. This is mostly due to (1) a variety of methods (batch size, loss, normalization, regularization etc.), and (2) some bugs in the evaluation procedure. I was not able to replicate some publications, for example, Kadlec et al., 2017 which is frustrating since such results can derail progress in the field. This work aims at a fair comparison of different knowledge graph completion by doing careful hyperparameter searches. As such this work can serve as a solid foundation and reference for future research. This is a very important contribution since the normalization of results across models allows for more precise calibration of promising research directions which allow for faster progress in this field of research.\n\nHowever, this work would be much more impactful if it would be coupled to a software framework in which new models can be developed. It would be of critical important that such a framework would be peer-reviewed to ensure that the evaluation procedure and sampling techniques are performed correctly. I am happy to peer review code if the authors are willing to provide such code.\n\nWhile the work would be strengthened significantly with the addition of a peer-reviewed codebase. I highly recommend this work to be accepted. Even without a peer-reviewed codebase, this work allows researchers to validate their personal codebases against results in this work. \n\n[1] Knowledge Base Completion: Baselines Strike Back: https://arxiv.org/abs/1705.10744", "title": "An important contribution. Source code needed."}, "signatures": ["~Tim_Dettmers2"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Tim_Dettmers2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}, {"id": "r1g5orsAPH", "original": null, "number": 1, "cdate": 1569793441719, "ddate": null, "tcdate": 1569793441719, "tmdate": 1569793441719, "tddate": null, "forum": "BkxSmlBFvr", "replyto": "BkxSmlBFvr", "invitation": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment", "content": {"comment": "Interesting work and interesting results. I have two questions/comments: \n1- I was wondering if it is possible for the authors to include a figure representing the distribution of filtered MRR for different regularization techniques (or add some discussion on their relative performance)? \n2- The authors attribute the use of reciprocal relations to Dettmers et al. 2018. I believe Dettmers et al. 2018 identified the leakage of the previous datasets due to the existence of inverse relations; the use of reciprocal relations for learning better embeddings was proposed in [1] and [2]. Also regarding \u201cOn the downside, the use of reciprocal relations means that a model does not provide a single triple score s(i, k, j) anymore (generally, s_{sub}(i, k, j) \\neq s_{obj}(i, k, j); the discrepancy has not been studied yet).\u201d, it has been proposed in [1] to considering the final score (s(i, k, j)) to be the average of the two scores (s_{sub}(i, k, j) and s_{obj}(i, k, j)) and it has been shown that this results in better performance compared to considering the final score to be either one of the scores (see SimplE vs SimplE-ignr in Table 1). \n[1] https://papers.nips.cc/paper/7682-simple-embedding-for-link-prediction-in-knowledge-graphs \n[2] http://proceedings.mlr.press/v80/lacroix18a.html", "title": "Two Questions/Comments"}, "signatures": ["~Bahare_Fatemi1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Bahare_Fatemi1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["daniel@informatik.uni-mannheim.de", "broscheit@informatik.uni-mannheim.de", "rgemulla@uni-mannheim.de"], "title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": ["Daniel Ruffinelli", "Samuel Broscheit", "Rainer Gemulla"], "pdf": "/pdf/d8532341877a4ce6e4fee643e629af2957579771.pdf", "TL;DR": "We study the impact of training strategies on the performance of knowledge graph embeddings.", "abstract": "Knowledge graph embedding (KGE) models learn algebraic representations of the entities and relations in a knowledge graph. A vast number of KGE techniques for multi-relational link prediction have been proposed in the recent literature, often with state-of-the-art performance. These approaches differ along a number of dimensions, including different model architectures, different training strategies, and different approaches to hyperparameter optimization. In this paper, we take a step back and aim to summarize and quantify empirically the impact of each of these dimensions on model performance. We report on the results of an extensive experimental study with popular model architectures and training strategies across a wide range of hyperparameter settings. We found that when trained appropriately, the relative performance differences between various model architectures often shrinks and sometimes even reverses when compared to prior results. For example, RESCAL~\\citep{nickel2011three}, one of the first KGE models, showed strong performance when trained with state-of-the-art techniques; it was competitive to or outperformed more recent architectures. We also found that good (and often superior to prior studies) model configurations can be found by exploring relatively few random samples from a large hyperparameter space. Our results suggest that many of the more advanced architectures and techniques proposed in the literature should be revisited to reassess their individual benefits. To foster further reproducible research, we provide all our implementations and experimental results as part of the open source LibKGE framework.", "keywords": ["knowledge graph embeddings", "hyperparameter optimization"], "paperhash": "ruffinelli|you_can_teach_an_old_dog_new_tricks_on_training_knowledge_graph_embeddings", "code": "https://github.com/uma-pi1/kge", "_bibtex": "@inproceedings{\nRuffinelli2020You,\ntitle={You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings},\nauthor={Daniel Ruffinelli and Samuel Broscheit and Rainer Gemulla},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkxSmlBFvr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e06abd255af19418802e92d7cdab9d6e8f05be89.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkxSmlBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504183572, "tmdate": 1576860588656, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2209/Authors", "ICLR.cc/2020/Conference/Paper2209/Reviewers", "ICLR.cc/2020/Conference/Paper2209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2209/-/Public_Comment"}}}], "count": 22}