{"notes": [{"id": "B1xkPBTtlN", "original": null, "number": 4, "cdate": 1545356631074, "ddate": null, "tcdate": 1545356631074, "tmdate": 1545356631074, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "rJxm-HpaJ4", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "content": {"title": "Regarding R2", "comment": "Thanks for the assessment. Regarding R2, this review arrived two weeks late. Thanks again. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/Authors"], "readers": ["ICLR.cc/2019/Conference/Paper1476/Authors", "everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621027, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1g9N2A5FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1476/Authors|ICLR.cc/2019/Conference/Paper1476/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621027}}}, {"id": "S1g9N2A5FX", "original": "Skl1WVLFtQ", "number": 1476, "cdate": 1538087986140, "ddate": null, "tcdate": 1538087986140, "tmdate": 1545355414442, "tddate": null, "forum": "S1g9N2A5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJxm-HpaJ4", "original": null, "number": 1, "cdate": 1544570107257, "ddate": null, "tcdate": 1544570107257, "tmdate": 1545354500234, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Meta_Review", "content": {"metareview": "The presented method proposes to use saliency maps as a component for an additional metric of forgetting in continual learning, and as a tool as additional information to improve learning on new tasks. \n\nPros: \n+ R2 & R3: Clearly written and easy to follow. \n+ R3: New metric to compare saliency masks\n+ R3: Interesting idea to utilize previously learned saliency masks to augment learning new tasks. \n+ R1: Performance improvements observed.\n\nCons:\n- R1 & R2: Novelty is limited in the context of prior works in this field. Unanswered by authors.\n- R2: Concerns around method's ability to use salient but disconnected components. Unanswered by authors.\n- R2: Experiments needed on more realistic datasets, such as ImageNet. Unanswered by authors. \n- R3: Performance gains are small. \n- R1 & R2: Literature review is insufficient. \n\nReviewers are leaning reject, and R2's concerns have not been answered by the authors at all. Idea seems interesting, authors are encouraged to take into careful consideration the feedback from authors and continue their research.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Saliency maps utilized for continual learning, but concerns around novelty and performance improvements."}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1476/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352825016, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1476/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1476/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352825016}}}, {"id": "B1xXNM8qpX", "original": null, "number": 3, "cdate": 1542246954727, "ddate": null, "tcdate": 1542246954727, "tmdate": 1542246954727, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "content": {"title": "Interpretable Continual Learning", "review": "Authors propose an incremental continual learning framework which is based on saliency maps on the learned tasks(i.e., explanations) with the ultimate goal of learning new tasks, while avoiding catastrophic forgetting. To this end, authors employ an attention mechanism based on average saliency masks computed on the predictions of the earlier task. In addition, a new metric, Flexible Saliency Metric (FSM) is proposed to evaluate the generated saliency maps. Authors employ three public, well-known datasets to evaluate the performance of their proposed framework.\n\nThe paper is well written and easy to follow. The methodology is sound and the results demonstrate that the proposed framework outperforms very recent conditional learning approaches. Nevertheless I have some major concerns with the methodology, proposed evaluation metric and experiments. Please find below my comments.\n\n- Technical novelty is rather limited. Contribution is incremental with respect to previous works on CL, as they use the variational CL (VCL) framework of Nguyen at al, 2018 and the weight of evidence (WE), as used in Zintgraf et al., 2017, to compute the saliency maps. From these saliency maps, a mask is computed to focus the attention in subsequent tasks, by averaging the explanations. This, however, limits the applicability of the proposed framework to \u2018similar\u2019 images (as pointed out by the authors). Another limitation of this technique is that explanations on learned tasks should correspond, spatially, to meaningful/discriminative areas for new tasks. Otherwise, the use of explanations on this CL approach would not work.\n- According to the authors, one of the limitations of known metrics to evaluate CL approaches is that \u2018the area of the saliency regions should be all connected, wasting opportunity to identify salient but possibly non-connected areas, such as the two eyes of an animal\u2019. Nevertheless, I do not see how this can be alleviated in the proposed FSM. The first term of eq (8), i.e., log(d_sal) will be large in the case of, for example, the two eyes of an animal, favouring again for connected saliency regions. How d_sal is computed? Is it a dense matrix between all pair of points?  \n- Being the FSM one of the main contributions of this work, experiments to assess its usability are insufficient. Authors should correlate the values obtained across the different CL frameworks with FSM to the actual performance in terms of precision/accuracy. Results demonstrate that the proposed ICL approach achieves the lowest values, in terms of FSM, but any interpretation can be done if it is not correlated with well established evaluation metrics.\n- Furthermore, it would be interesting to see how this method performs in more complex datasets, such as ImageNet, where tasks within the continual learning process may differ a lot. \n- I also feel the literature on CL is scarce and it does not motivate the choices of the manuscript. Authors should include a more detailed literature on this problem. \n\nMinor comments\n\n- In page 3, which is the difference between benchmarks and medical data, as datasets? Public medical data are also benchmarks.\n- How the z value in eq (6) is found? An ablation study to see the impact on the final results would be interesting.\n- In page 5, when describing the limitations of current methods for saliency map evaluation (\u2018It remains tricky how to identify,\u2026.,etc),what does etc mean? Please be more concise on the limitations. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "cdate": 1542234221915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335954545, "tmdate": 1552335954545, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Bkggfq0VTm", "original": null, "number": 2, "cdate": 1541888520426, "ddate": null, "tcdate": 1541888520426, "tmdate": 1541888520426, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "ryg4Fgr9hX", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "We thank the reviewer for their time and welcome feedback, which we are incorporating into the revised version. \n\nR: - Theoretical contribution\nA:\n-- Just a clarification regarding the first contribution: WE from the current task is not used to generate a saliency map for the next task; it is instead used to instruct the learner of the next task about which input areas are more important than others via the attention mechanism. This becomes a part of the future learning procedure, not just a post hoc visualisation method as in the original WE . As such, the first contribution is not solely about generating new visualisations; it is more about using the learned saliency maps from the past to attend in future learners. We therefore believe that the potential of this first contribution as a conceptual framework via which a learner can understand, attend, and then enhance its attention for future tasks, is not small. \n-- Importantly, we are the first to combine interpretability with continual learning and show that interpretability can help continual learning. It is a significant step to bring these two communities together. \n-- It is worth noting that VCL has achieved very good results on most of these benchmarks, so it is very hard to outperform it with a large margin. Nevertheless, although the experimental increases might not seem dramatic, they are statistically significant (we have added the statistical significance results to the appendix in the revised version). \n\n\nR: - Related work\nA:\n-- Thank you. In addition to the locations specified by the reviewer, the first two paragraphs of Section 1 (especially the second paragraph) discuss several other related works. We have added more to the revised version. \n\n\nR: - https://arxiv.org/pdf/1805.09733.pdf \nA:\n-- Thank you. We have cited the paper in the revised version, and plan to take it into further consideration in future work. \n\nR: - Yellow color in plots\nA:\n-- We have changed the yellow colour in Figures 2, 3 and 4 to black. Yellow is now no longer used in any plots. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621027, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1g9N2A5FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1476/Authors|ICLR.cc/2019/Conference/Paper1476/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621027}}}, {"id": "HkeYvOCVTm", "original": null, "number": 1, "cdate": 1541888096896, "ddate": null, "tcdate": 1541888096896, "tmdate": 1541888096896, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "HJeXDu9h2X", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "We thank the reviewer for their time and welcome feedback, which we are incorporating into the revised version. \n\nR: - \"important features for the new task should be in similar locations ...\"\n- \"the locations for important features should be comparatively stable ...\"\nA: \n-- Continual learning typically assumes a degree of similarity among the tasks. If tasks are completely different from each other, then most continual learning frameworks will somehow struggle. For example, the standard Split MNIST benchmark is in line with this \u201clocations of important features\u201d assumption. Having said that, we acknowledge that more agility to, at least, discover that early on would be beneficial. More importantly, a normalization strategy on top of our attention map would help enhance its invariance properties, potentially leading to a more robust treatment of the locations of important features. In page 4 in the revised version (footnote 3), we have clarified this and notified its potential for future work. \n-- Thank you for the suggestion regarding the fixed attention map. We tried an experiment using the fixed attention map as a baseline, and as expected it performs significantly worse than ours. We have added that to the revised version (see p.6 and Appendix A). \n\n\nR: - FSM vs. Classification performance\nA:\n-- It is true that evaluating the FSM is not necessarily the same as the classification results, which is precisely the reason why we show both in our results. As specified in page 2, \u201cHere we propose a new measure ...\u201d - our point in this regard is to propose another (different) manner via which catastrophic forgetting can be estimated, which is not the same as the classification accuracy. The goal is that (as we know and agree they are two different measures that might agree or disagree in their judgments on catastrophic forgetting) both can be used to inspect the degree of catastrophic forgetting. We have further clarified that in Section 6.2 in the experiments by stressing that the obtained FSM results \u201calong with the classification results\u201d denote the significance of the whole framework in addressing catastrophic forgetting. \nIt is definitely a good idea to analyse the correlation between changes in classification accuracy and in FSM values, thank you. We will rigorously investigate this in future work. \n\n\nR: - Statistical significance\nA:\n-- Thank you. We have added the statistical significance results to the revised version. Since we were concerned that adding this information to the plots would make them harder to read,  statistical significance of the the average accuracy and FSM results obtained after completing the last two tasks from each dataset, i.e. the corresponding values of the last two tasks of all the plots in Figures 1, 2, 3 and 4, are now displayed in the tables in Appendix A. \nChecking cases where the learner incorrectly classifies the image in the second time step is sound and will be inspected in future work. \n\n\nR: - Clarity\nA:\n-- We have fixed the typos in the revised version, thank you: i) The first sentence of the third paragraph in Section 4 now reads: \u201cFor input images of ..., the averaged weight of evidence matrix  is referred to as $\\text{WE}_{\\bm{i}}(\\bm{x}) \\in \\RR^{\\bm{r} \\times \\bm{c}}$.\u201d  ii) In page 6: \u201cThe size of the surrounding square \u2026 is 16 $\\times$ 16 pixels. \n \n\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621027, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1g9N2A5FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1476/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1476/Authors|ICLR.cc/2019/Conference/Paper1476/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers", "ICLR.cc/2019/Conference/Paper1476/Authors", "ICLR.cc/2019/Conference/Paper1476/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621027}}}, {"id": "HJeXDu9h2X", "original": null, "number": 2, "cdate": 1541347419102, "ddate": null, "tcdate": 1541347419102, "tmdate": 1541533103987, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "content": {"title": "A paper with a relevant and interesting contribution that lacks clarity and motivation", "review": "Summary:\nIn this paper, the authors propose a framework for continual learning based on explanations for performed classifications of previously learned tasks. In this framework, an average saliency map is computed for all images in the test set of a previous task to identify image regions, which are important for that task. When learning the next task, this average saliency map is used in an attention mechanism to help learning the new task and to prevent catastrophic forgetting of previously learned tasks. Furthermore, the authors propose a new metric for the goodness of a saliency map by taking into account the number of pixels in the map, the average distance between pixels in the map, as well as the prediction probability given only the salient pixels.\nThe authors report that their approach achieves the best average classification accuracy for 3 out of 4 benchmark datasets compared to other state-of-the-art approaches.\n\nRelevance:\nThis work is relevant to researchers in the field of continual/life-long learning, since it proposes a framework, which should be possible to integrate into different approaches in this field.\n\n\nSignificance:\nThe proposed work is significant, since it explores a new direction of using learner generated, interpretable explanations of the currently learned task as help for learning new tasks. Furthermore, it proposes a new metric for the goodness of saliency maps.\n\n\nSoundness:\nIn general, the proposed approach of using the average saliency map as attention mask for learning appears to be reasonable. However, the following implicit assumptions/limitations of the approach should be made more clear:\n\t- important features for the new task should be in similar locations as important features of the old task (for example, one would expect that the proposed approach would negatively affect learning the new task if the important features of the old task were all located in the bottom of the image, while all important features for the new task are in the top)\n\t- the locations for important features should be comparatively stable (for example, one would expect the average saliency map to become fairly meaningless if important features, such as the face of a dog, can appear anywhere in the image. Therefore, an interesting baseline for the evaluation of the ICL approach would be a predefined, fixed attention map consisting of concentric circles with the image center as their center, to show that the proposed approach does more than just deemphasizing the corners of the image)\n\nFurthermore, the authors appear to imply that increased FSM values for an old task after training on a new task indicate catastrophic forgetting. While this is a reasonable assumption, it does not necessarily seem to be the case that a larger, more disconnected saliency map indicates worse classification performance. Comparatively small changes in FSM may not affect the classification performance at all, while larger changes may not necessarily lead to worse classifications either. For example, by increasing the amount or size of image regions to be considered, the classifier may accidentally become more robust on an old task. Therefore, it may be a good idea for the authors to analyze the correlation between FSM changes and accuracy changes.\n\nEvaluation:\nThe evaluation of the proposed approach on the four used datasets appears to be reasonable and well done. However, given that the achieved performance gains over the state-of-the-art are fairly small, it would be good to assess if the obtained improvements are statistically significant. \nFurthermore, it may be informative to show the saliency maps in Figure 5 not only for cases in which the learner classified the image correctly in both time steps, but also cases in which the learner classified the image correctly the first time and incorrectly the second time. Additionally, the previously mentioned evaluation steps, i.e., using a fixed attention map as baseline for the evaluation and evaluating the correlation between FSM and accuracy may be informative to illustrate the advantages of the proposed approach.\n\nClarity:\nThe paper is clearly written and easy to follow. One minor issue is that the first sentence of the third paragraph in Section 4 is not a full sentence and therefore difficult to understand.\nFurthermore, on page 6, it is stated that the surrounding square $\\hat{x}_i$ is 15 x 15 pixels, while the size of the square $x_i$ is 10 x 10. This appears strange, since it would mean that $x_i$ cannot be in the center of $\\hat{x}_i$. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "cdate": 1542234221915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335954545, "tmdate": 1552335954545, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryg4Fgr9hX", "original": null, "number": 1, "cdate": 1541193851738, "ddate": null, "tcdate": 1541193851738, "tmdate": 1541533103743, "tddate": null, "forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "content": {"title": "Reasonable approach with good results; incremental novelty ", "review": "This paper proposes an extension to the continual learning framework using existing variational continual learning (VCL) as the base method. In particular, it proposes to use the weight of evidence (WE) (from Zintgraf et al 2017) for each task. Firstly, this WE can be used to visualize the learned model (as used in Zintgraf et. al. 2017). The novelty of this paper is:\n1. to use this WE from the current task to generate a silence map (by smoothing the WE) for the next task.  This is interpreted the learned the learned attention region. Such an approach is named Interpretable COntinual Learning (ICL) \n2. The paper proposes a metric for the saliency map naming FSM which is an extension of existing metric SSR. The extension is to take pixel count to compute the area instead of using rectangular region area, as well as taking the distance between pixels into account. This metric can be used to evaluate the level of catastrophic forgetting.\n\nPro:\nIn general, the idea is very intuitive and make sense.  The paper also demonstrates superior performance with the proposed method on continual learning on all classic tasks comparing with VCL and EWC. \nThe presentation is very easy to follow. \nIt seems like a valid and flexible extension that can be used in other continual learning frameworks.\n\nCons:\nThe theoretical contribution is very limited. The work is rather incremental from current state-of-the-art methods. \nThere should be a better discussion of related work on the topic. The paper currently only mentions the most related work for the proposed method,  using the whole section 2 to describe VCL and use section 3 to describe FSM and half of section 5 to describe SSR. A general overview of related work in these directions are needed.  \n\nOther:\n1. The paper should also consider more recently proposed evaluation metrics such as discussed in https://arxiv.org/pdf/1805.09733.pdf \n2. The author should try to avoid using yellow color in plots. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1476/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpretable Continual Learning", "abstract": "We present a framework for interpretable continual learning (ICL). We show that explanations of previously performed tasks can be used to improve performance on future tasks. ICL generates a good explanation of a finished task, then uses this to focus attention on what is important when facing a new task. The ICL idea is general and may be applied to many continual learning approaches. Here we focus on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. We use saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in terms of its explanations, which are assessed qualitatively and quantitatively using the proposed metric.", "keywords": ["Interpretability", "Continual Learning"], "authorids": ["tah47@cam.ac.uk", "nvcuong92@gmail.com", "ret26@cam.ac.uk", "zoubin@eng.cam.ac.uk", "aw665@cam.ac.uk"], "authors": ["Tameem Adel", "Cuong V. Nguyen", "Richard E. Turner", "Zoubin Ghahramani", "Adrian Weller"], "TL;DR": "The paper develops an interpretable continual learning framework where explanations of the finished tasks are used to enhance the attention of the learner during the future tasks, and where an explanation metric is proposed too. ", "pdf": "/pdf/1741d6de7919108296c6d684c959767824c36348.pdf", "paperhash": "adel|interpretable_continual_learning", "_bibtex": "@misc{\nadel2019interpretable,\ntitle={Interpretable Continual Learning},\nauthor={Tameem Adel and Cuong V. Nguyen and Richard E. Turner and Zoubin Ghahramani and Adrian Weller},\nyear={2019},\nurl={https://openreview.net/forum?id=S1g9N2A5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1476/Official_Review", "cdate": 1542234221915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1g9N2A5FX", "replyto": "S1g9N2A5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1476/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335954545, "tmdate": 1552335954545, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1476/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}