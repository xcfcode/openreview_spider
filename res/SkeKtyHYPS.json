{"notes": [{"id": "SkeKtyHYPS", "original": "BylVCLAuwr", "number": 1849, "cdate": 1569439617110, "ddate": null, "tcdate": 1569439617110, "tmdate": 1577168273726, "tddate": null, "forum": "SkeKtyHYPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "NcnZ6gab-Y", "original": null, "number": 1, "cdate": 1576798734051, "ddate": null, "tcdate": 1576798734051, "tmdate": 1576800902338, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Decision", "content": {"decision": "Reject", "comment": "This paper studies the effect of various data augmentation methods on image classification tasks. The authors propose the structural similarity as a measure of the magnitude of the various types of data augmentation noise they consider and argue that it is outperforms PSNR as a measure of the intensity of the noise. The authors performed an empirical analysis showing that speckle noise leads to improved CNN models on two subsets of ImageNet. While there is merit in thoroughly analysing data augmentation schemes for training CNNs, the reviewers argued that the main claims of the work were not substantiated and the raised issues were not addressed in the rebuttal. I will hence recommend rejection of this paper.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726079, "tmdate": 1576800278129, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Decision"}}}, {"id": "ryxfxYLKYr", "original": null, "number": 1, "cdate": 1571543274464, "ddate": null, "tcdate": 1571543274464, "tmdate": 1572972415674, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper studies the effect of various data augmentation methods on image classification tasks. The Authors propose the Structural Similarity (SSIM) as a measure of the magnitude of the various types of data augmentation noise they consider. The Authors argue that SSIM is superior to PSNR as a measure of the intensity of the noise, across various noise types.\n\nThe idea of using SSIM as a unified measure for noise in the context data augmentation in images is novel AFAIK and is neat IMO, because as the authors point, SSIM provides a more perceptually-driven distance measure between images than RMS or PSNR. One of the results of the paper is that a SSIM value of 0.8 is a good rule of thumb for choosing the magnitude of the noise irrespectively to the type of noise. This is a useful and interesting result.\n\nNevertheless, at this stage I am inclined to reject the paper, because I feel that the main claim is not sufficiently substantiated. The argument that SSIM provides a more universal (less noise-type-dependent) measure of strength than, say, PSNR in the context of data augmentation is not substantiated in the experiments. While intuitively the claim makes sense to me, it is hard to draw this conclusion when SSIM is not compared to any other metric (RMS, PSNR) as measure of strength for data augmentation. \n\nWhy is a larger Kurtosis detrimental for measuring the strength of data argumentation? Is there any evidence that links low Kurtosis to a better measure data augmentation strength? This is another question that could be addressed if SSIM were compared to other data augmentation strength metrics.\n\nIMHO the paper could have been made much stronger if it had the analog of Figure 5 for other measures of the noise (e. g. PSNR, RMS). If the results showed that SSIM is superior to them, I would learn a useful and insightful lesson form the paper. In its current form, I feel that the Authors made the first step in a very interesting direction but did not go far enough to substantiate their claims."}, "signatures": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875146172, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1849/Reviewers"], "noninvitees": [], "tcdate": 1570237731416, "tmdate": 1575875146185, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review"}}}, {"id": "BylWZ0s6YH", "original": null, "number": 2, "cdate": 1571827192760, "ddate": null, "tcdate": 1571827192760, "tmdate": 1572972415639, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper studies the different types of noises that could be added to the training image dataset while training an CNN model for classification. They study 5 different types of noise functions: Gaussian, Speckle, Salt and Pepper, Poisson, Occlusion.\n \nPros:\n1. Rigorously studying how to augment training data for CNN is important. \n\n\nCons:\n1. The primary question is novelty . - what is the research contribution of this dataset? They are running experiments of 5 different known noise functions, on two image datasets, on a single deep learning models. There are no fundamental research questions or hypothesis. This is a mere running of few experiments - known methods and known approaches. \n\n2. Are the results generalizable? Answer is no! The results on shown on two subsamples of Imagenet datasets for only ResNet 18 model. Maybe for this combination speckle noise (and not Gaussian, as pointed out in the comments by the authors) is better. How can the assure that for a different dataset, model, task combination the same speckle noise would perform better ? \n\n3. Improvement suggestion: What I would ideally look in this topic, is a method to automatically study the properties of the training data images (study the distribution) and conditional on this distribution recommend the best noise type and noise intensity. Thus, the whole story of noise injection could be made dynamic for a dataset, model, task combination\n\n4. Writing of the paper could be improved: 1. The need for noise based augmentation of is well known (Section 1). 2. The different kinds of noise functions are mostly text book knowledge (Section 2). 3. The different image quality metrics written here - MSE, PSNR, SSIM are also text book knowledge (Section 3). Overall, the first 4 pages of the paper are redundant and could be compressed into 1 page. Would like to read more on the experiments, analysis, and maybe automation of noise selection techniques in different kinds of tasks - segmentation, text classification, seq2seq etc.\n\n5. Choose very naive noise (or augmentation) functions: In general, the approach of augmentation of training data has evolved so much in the literature, that adding noise is hardly in practice. \n1. \"The Effectiveness of Data Augmentation in Image Classification using Deep Learning\" - Style Transformation\n2. \"Improving Deep Learning using Generic Data Augmentation\" - Geometric and Affine Transformation\nThus, the study on data augmentation should be performed across all these different transformation functions on training data and using only noise function is naive and is incomplete."}, "signatures": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875146172, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1849/Reviewers"], "noninvitees": [], "tcdate": 1570237731416, "tmdate": 1575875146185, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review"}}}, {"id": "rJxOAIYJcr", "original": null, "number": 3, "cdate": 1571948240434, "ddate": null, "tcdate": 1571948240434, "tmdate": 1572972415597, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims at analyzing the effect of injecting noise to images as data augmentation in training CNN for the image classification task. Based on the SSIM metric (which is shown to be a better metric than PSNR), different noise level on a set of different kinds of noise are explored. Experimental results on two sub-datasets of ImageNet suggest that Speckle noise would lead to better CNN models.\n\nEven though the simulations appear seemingly convincing, and the conclusion is somewhat interesting to me: speckle noise is recommended which contradicts the general usage of Gaussian noise. The results is too specific to both the model chosen resnet18v2 and also in the chosen dataset. Besides, my bigger concern is that the contribution of this work is highly limited, since there are a bunch of data augmentation techniques: cropping, flipping, color space transformation, rotation, noise injection, etc. Given this broad selection of data augmentation, as far as I know, noise injection is not the most effective nor popular one.  In fact, random cropping is the mostly used one that established past a few benchmark CNN models in the imageNet classification task, e.g, ResNet, DenseNet, etc. As such, it would be more convincing if it can be shown that proper noise injection can boost the recognition performance on the ImageNet task. \n\nMinors:\nAbstract line 8, and also introduces -> and also introduce   "}, "signatures": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1849/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875146172, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1849/Reviewers"], "noninvitees": [], "tcdate": 1570237731416, "tmdate": 1575875146185, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Official_Review"}}}, {"id": "HJe6hPSv_r", "original": null, "number": 2, "cdate": 1570359221470, "ddate": null, "tcdate": 1570359221470, "tmdate": 1570365943698, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Official_Comment", "content": {"comment": "Dear reviewers and readers,\n\nAs edit option for our paper still appears to be disabled (any recommendations regarding to this issue is highly appreciated), we are publishing an important correction and a small additional study via comment option.\n\nThe correction is due to a typo in the fourth paragraph of the 5th section (Discussion), that starts with the words \"For the rest of the noise types...\": Our final recommendation for the type of noise to be injected among Gaussian, speckle and Poisson noise models is NOT Gaussian, but speckle. The reasoning can be visually seen especially in the Figure 8(b), where speckle noise provides considerably better robustness than Gaussian noise. Furthermore, in Figures 4 and 5 neural models trained with speckle noise performs better than their Gaussian counterparts on six occasions, while the contrary is true only for three occasions (one case is nearly equal). This can be explained by speckle noise being feature-selective, targeting the high-intensity regions more than the low-intensity ones and thus allowing the neural network to better generalize for minor features. Although these observations have been made before the completion of the study, we are sorry for the crucial typo that will also be corrected in the original paper as soon as he editing is enabled. If reviewers approve, it is also possible to add this short explanation.\n\nSmall additional study is made upon the recommendation of a colleague, regarding to a conclusion reached by Koziarski & Cyganek (2017) that \"noise as a form of regularization on top of other regularization techniques, namely weight decay and dropout, does not improve the classification accuracy\". In the mentioned study, the properties of the noise and other regularization techniques applied to reach this conclusion are not disclosed, therefore we have made a series of experiments to determine the robustness and accuracy of the dropout-regularized CNN models with and without the noise injection procedure as advised in our study.  Initial reasoning behind not using such techniques was to comply with the ResNetV2 architecture of He et al. (2016).\n\nWe have chosen an aggresive dropout level of 0.5, and applied one of the three noise models; namely speckle, s&p and occlusion noise, at 0.8 MSSIM (see Table 2 from the study). For both datasets, we run the experiments for four different cases (w/o and w/noise, w/o and w/dropout), and trained each model for five times. The resulting loss metrics for each epoch is aggregated by the minimum value among five trials. The test set is composed of noise-free images of original datasets and their slightly noisy (0.9 MSSIM) counterparts for each noise type, in order to test for the model robustness with accuracy at the same time. The plots for each dataset can be seen in the following anonymous link: https://imgur.com/a/REothM6\n\nThe results are conforming with our discussions in the study, therefore there is no need for any change in the main structure, and this additional work can be seen as a confirmation of our findings. Noise injection, when appropriately constructed, can also be a good regularization technique especially with relatively difficult datasets (observe that the effect of noise injection is much greater in Imagewoof dataset which is substantially more challenging than Imagenette). The code for this additional work can be reached via: https://gofile.io/?c=2nXLAV\n\nAs we understand the policy of ICLR regarding to the follow-up studies, these results will be added to the paper depending on the decision of the reviewers. \n\nReferences\n\nKaiming He,  Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling (eds.), Computer Vision\u2013 ECCV 2016, pp. 630\u2013645, Cham, 2016. Springer International Publishing.  ISBN 978-3-319-46493-0.\n\nMicha Koziarski and Boguslaw Cyganek. Image recognition with deep neural networks in presence of noise: dealing with and taking advantage of distortions. Integrated Computer-Aided Engineering, 24:1\u201313, 08 2017. doi: 10.3233/ICA-170551.", "title": "Correction of a crucial typo and a small additional study"}, "signatures": ["ICLR.cc/2020/Conference/Paper1849/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeKtyHYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference/Paper1849/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1849/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1849/Reviewers", "ICLR.cc/2020/Conference/Paper1849/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1849/Authors|ICLR.cc/2020/Conference/Paper1849/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150008, "tmdate": 1576860538090, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference/Paper1849/Reviewers", "ICLR.cc/2020/Conference/Paper1849/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Official_Comment"}}}, {"id": "rylesyBjPr", "original": null, "number": 1, "cdate": 1569570712130, "ddate": null, "tcdate": 1569570712130, "tmdate": 1569607667828, "tddate": null, "forum": "SkeKtyHYPS", "replyto": "SkeKtyHYPS", "invitation": "ICLR.cc/2020/Conference/Paper1849/-/Official_Comment", "content": {"comment": "Due to the doubts of anonymity with regards to Google Drive shares, the link in the submission is deactivated. Code can be accessed via this new anonymous link: https://gofile.io/?c=GeXNVQ\n\nSorry for the inconvenience.", "title": "Change of code address"}, "signatures": ["ICLR.cc/2020/Conference/Paper1849/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Data Augmentation in Training CNNs: Injecting Noise to Images", "authors": ["Murtaza Eren Akbiyik"], "authorids": ["erenakbiyik@gmail.com"], "keywords": ["deep learning", "data augmentation", "convolutional neural networks", "noise", "image processing", "SSIM"], "TL;DR": "Ideal methodology to inject noise to input data during CNN training", "abstract": "Noise injection is a fundamental tool for data augmentation, and yet there is no widely accepted procedure to incorporate it with learning frameworks. This study analyzes the effects of adding or applying different noise models of varying magnitudes to Convolutional Neural Network (CNN) architectures. Noise models that are distributed with different density functions are given common magnitude levels via Structural Similarity (SSIM) metric in order to create an appropriate ground for comparison. The basic results are conforming with the most of the common notions in machine learning, and also introduces some novel heuristics and recommendations on noise injection. The new approaches will provide better understanding on optimal learning procedures for image classification.", "pdf": "/pdf/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "code": "https://drive.google.com/open?id=1GwQFo2QtW_O6AebR-ZGUYqlv6ItVx2_2", "paperhash": "akbiyik|data_augmentation_in_training_cnns_injecting_noise_to_images", "original_pdf": "/attachment/723ef5520dde3c36f2259a7308dea1c3538fa425.pdf", "_bibtex": "@misc{\nakbiyik2020data,\ntitle={Data Augmentation in Training {\\{}CNN{\\}}s: Injecting Noise to Images},\nauthor={Murtaza Eren Akbiyik},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeKtyHYPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeKtyHYPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference/Paper1849/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1849/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1849/Reviewers", "ICLR.cc/2020/Conference/Paper1849/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1849/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1849/Authors|ICLR.cc/2020/Conference/Paper1849/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150008, "tmdate": 1576860538090, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1849/Authors", "ICLR.cc/2020/Conference/Paper1849/Reviewers", "ICLR.cc/2020/Conference/Paper1849/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1849/-/Official_Comment"}}}], "count": 7}