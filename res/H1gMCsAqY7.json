{"notes": [{"id": "H1gMCsAqY7", "original": "H1l3OTpYY7", "number": 874, "cdate": 1538087882016, "ddate": null, "tcdate": 1538087882016, "tmdate": 1545361900131, "tddate": null, "forum": "H1gMCsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 20, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Byewd0_mlE", "original": null, "number": 1, "cdate": 1544945263502, "ddate": null, "tcdate": 1544945263502, "tmdate": 1545354490689, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Meta_Review", "content": {"metareview": "This paper proposed a method that creates neural networks that can run under different resource constraints. The reviewers have consensus on accept. The pro is that the paper is novel and provides a practical approach to adjust model for different computation resource, and achieved performance improvement on object detection. One concern from reviewer2 and another public reviewer is the inconsistent performance impact on classification/detection (performance improvement on detection, but performance degradation on classification). Besides, the numbers reported in Table 1 should be confirmed: MobileNet v1 on Google Pixel 1 should have less than 120ms latency [1], not 296 ms. \n\n\n[1] Table 4 of https://arxiv.org/pdf/1801.04381.pdf", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "train a single neural network at different widths"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper874/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353052964, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353052964}}}, {"id": "Skxg-ZFjkE", "original": null, "number": 6, "cdate": 1544421624255, "ddate": null, "tcdate": 1544421624255, "tmdate": 1544425356160, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "Dear authors,\n\nThis is a very interesting work. And I think it is closely related to the mutual learning frameworks [1,2], where the core idea is also to jointly train several models for improving the performance of training each model separately. The main difference is with/without weight sharing, which is one of the contributions of the paper. And I recommend you to cite these works in the paper. \n\n1: Zhang et al. \"Deep Mutual Learning\", CVPR2018. http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.pdf\n\n2: Zhuang et al. \"Towards Effective Low-bitwidth Convolutional Neural Networks\", CVPR2018\nhttp://openaccess.thecvf.com/content_cvpr_2018/papers/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.pdf\n", "title": "Very interesting work, and recommend some related works"}, "signatures": ["~Bohan_Zhuang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Bohan_Zhuang1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}, {"id": "BJxHanYjJV", "original": null, "number": 11, "cdate": 1544424636590, "ddate": null, "tcdate": 1544424636590, "tmdate": 1544424636590, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "Skxg-ZFjkE", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work! We will add the citation once revision period is re-opened. "}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "S1g9rv-fJN", "original": null, "number": 10, "cdate": 1543800642007, "ddate": null, "tcdate": 1543800642007, "tmdate": 1543800642007, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "SyeIKWl11N", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work! However, we can not fully agree with your suggestion. Our reasons are summarized below:\n\n1. In your referenced paper [1], the major focus is to compress (Section 3) and sparsify/pruning filters, channels and layers with scheduling (Section 4), and get a \"nested sparse networks\". The resulted network can be used for model compression, knowledge distillation and hierarchical classification (Section 5).\nIn our work, the focus is not to compress, sparsify or pruning, but to simply train a single neural network executable at different width, with the spotlight on the accuracy/performance of standard image recognition benchmarks (ImageNet classification, COCO object detection, instance segmentation, keypoints detection). While the motivation is similar, our focus, methodology, analysis and experimental results are completely different.\n\n2. Moreover, the only related experiment, hierarchical classification, is also different to our experiments and standard benchmarks. In your referenced paper [1] in Section 5.3:\n\n\"We also provide experimental results on the ImageNet (ILSVRC 2012) dataset. From the dataset, we collected a subset, which consists of 100 diverse classes including natural objects, plants, animals, and artifacts.\"\n\nIn efficient deep learning, none of MobileNet v1 [2], MobileNet v2 [3], ShuffleNet [4] evaluate proposed methods on Cifar-10, Cifar-100 or sub-sampled \"100-class ImageNet\". Many methods that work on toy dataset can not generalize to real scenarios in the topic of efficient models, thus we think challenging settings like standard 1000-class ImageNet is essential to make the work solid and to ensure fair comparisons. Since the motivation is similar, we will be happy to add a citation in related work. We will always be happy to highlight and add comparison to any work that is related and has standard benchmark results.\n\n\n[1] Kim, Eunwoo, Chanho Ahn, and Songhwai Oh. \"Learning Nested Sparse Structures in Deep Neural Networks.\" arXiv preprint arXiv:1712.03781 (2017).\n[2] Howard, Andrew G., et al. \"Mobilenets: Efficient convolutional neural networks for mobile vision applications.\" arXiv preprint arXiv:1704.04861 (2017).\n[3] Sandler, Mark, et al. \u201cMobileNet v2: Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation.\" arXiv preprint arXiv:1801.04381 (2018).\n[4] Zhang et al. Shufflenet: An extremely efficientconvolutional neural network for mobile devices.arXiv preprint arXiv:1707.01083, 2017."}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "SyeIKWl11N", "original": null, "number": 5, "cdate": 1543598462135, "ddate": null, "tcdate": 1543598462135, "tmdate": 1543598462135, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "This paper introduces a deep neural network that provides different inference paths with respect to different widths for accuracy-efficiency trade-off at test time, but the concept has been already introduced in prior work \n[Kim et al., NestedNet: Learning Nested Sparse Structures in Deep Neural Networks, CVPR, 2018]\nwhich suggests a nested network to produce multiple different inference paths with different widths (they call \"channel scheduling\" which is one of their strategies to allow multiple different sparse networks).\n\nExcept the missing related work, your paper still has value in terms of different methodology as well as promising experimental results including detection and semantic segmentation.\n\nIt would be good to not only introduce additional related work but make the contribution/positioning clear.", "title": "Missing related work"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}, {"id": "Byg13FQjRm", "original": null, "number": 9, "cdate": 1543350694615, "ddate": null, "tcdate": 1543350694615, "tmdate": 1543350694615, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "HJgcCEmjCQ", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work! We will add the citation once revision period is re-opened. Code will be released soon and we warmly welcome the community to work together on related topics!"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "HJgcCEmjCQ", "original": null, "number": 4, "cdate": 1543349457831, "ddate": null, "tcdate": 1543349457831, "tmdate": 1543349457831, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "Very interesting work and congratulations! \n\nI am the first author of paper Runtime Neural Pruning (RNP, in NIPS 2017), where we also partitioned the channels of each convolutional layers into 4 equal sets and used a reinforcement learning agent to determine how many sets to run according to the difficulty of input images, in an incremental way. RNP can also adjust the workload according to the available hardware resources by adjusting the computation penalty.\n\nI think your paper has solved some of the training difficulty in RNP, and it would be very interesting to try a network-level dynamic inference according to the input image. Also, it would be very nice if you can include a reference to our paper. Thanks!", "title": "Interesting work and a related paper"}, "signatures": ["~Ji_Lin1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Ji_Lin1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}, {"id": "rkgxjlo9Am", "original": null, "number": 8, "cdate": 1543315608107, "ddate": null, "tcdate": 1543315608107, "tmdate": 1543315608107, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "r1xT_6ICTX", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Thanks for addressing my questions", "comment": "Thanks for addressing my questions!"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "rylzSkDA6X", "original": null, "number": 7, "cdate": 1542512442395, "ddate": null, "tcdate": 1542512442395, "tmdate": 1542512442395, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "rklrgxdT37", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Review", "comment": "Thanks for your review efforts! We have addressed all questions below:\n\n1. We aim to train single neural network executable at different widths. We find slimmable networks achieve better results especially for small models (e.g., 0.25x) on detection tasks. We have mentioned that it is probably due to implicit distillation, richer supervision and better learned representation (since detection results are based on pre-trained ImageNet learned representation). We try to avoid strong claims of any deep reason because none of them is strictly proved by us yet. Explaining deep reasons for improvements are not the motivation or the focus of this paper. But we are actively exploring on these questions!\n\n2. In fact, on average the image classification results are also improved (0.5 better top-1 accuracy in total), especially for small models. After submission, we have improved accuracy of S-ShuffleNet due to an additional ReLU layer (our implementation bug) between depthwise convolution and group convolution (Figure 2 of ShuffleNet [3]). Our models will be released.\n\n3. Thanks for the good suggestion! Currently we conduct detection experiments mainly on Detectron [1] and MMDetection [2] framework where ResNet-50 is among the most efficient models. We do value this suggestion and will try to implement mobilenet-based detectors. Besides, all code (including classification and detection) and pre-trained models will be released soon and we warmly welcome the community to work on together.\n\nThanks!\n\n\n[1] https://github.com/facebookresearch/Detectron\n[2] https://github.com/open-mmlab/mmdetection\n[3] Zhang et al. Shufflenet: An extremely efficientconvolutional neural network for mobile devices.arXiv preprint arXiv:1707.01083, 2017."}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "r1xT_6ICTX", "original": null, "number": 6, "cdate": 1542511989002, "ddate": null, "tcdate": 1542511989002, "tmdate": 1542511989002, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1lytDzo2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Review", "comment": "Thanks for your review efforts! We have addressed all three questions below:\n\n1. As mentioned in Section 3.3, the only modification is to accumulate all gradients from different switches. It means that the optimizer (SGD for image recognition tasks) is exactly the same as training individual models (same momentum, etc.). The only difference is the value of gradient for each parameter. In Algorithm 1, we follow pytorch-style API and use optimizer.step() to indicate applying gradients. We have not observed any difficulty in optimization of slimmable networks using default optimizer in Algorithm 1.\n\n2. There is no \"unbalanced gradient\" problem in training slimmable networks (it may seem like so). The parameters of 0.25x seem to have \"more gradients\", but in the forward view, these parameters of 0.25x are also used four times in Net 0.25x, 0.5x, 0.75x and 1.0x. It means the parameters in 0.25x are more important for the overall performance of slimmable networks. In fact, back-propagation is strictly based on forward feature propagation. In the forward view, as mentioned in Section 3.3, our primary objective to train a slimmable network is to optimize its accuracy averaged from all switches.\n\n3. Our reported ResNet-50 accuracy is correct (23.9 top-1 error). We evaluate single-crop testing accuracy instead of 10-crop following all our baselines. The ResNet-50 single-crop testing accuracy is publicly reported in ResNeXt paper (Table 3, 1st row) [1], released code [2] and many other publications. Our ResNet-50 has same implementation with PyTorch official pre-trained model zoo [3] where the top-1 error is also 23.9 instead of <21% (in fact ResNet-152 still has > 21% single-crop top-1 error rate).\n\nWe sincerely hope the rating can be reconsidered if it was affected by above questions. Thanks for your time and review efforts!\n\n\n[1] Xie, Saining, et al. \"Aggregated residual transformations for deep neural networks.\" Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017.\n[2] https://github.com/facebookresearch/ResNeXt\n[3] https://pytorch.org/docs/stable/torchvision/models.html"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "HJe6pnUA6m", "original": null, "number": 5, "cdate": 1542511812818, "ddate": null, "tcdate": 1542511812818, "tmdate": 1542511812818, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "BJez1UBa27", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Review", "comment": "Thanks for your positive review and encouragements! We also believe the discovery of slimmable network opens up the possibility to many related fields including model distillation, network compression and better representation learning. We are actively exploring on these topics and hope this submission may contribute to ICLR community."}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "HyeH_nUAaX", "original": null, "number": 4, "cdate": 1542511725341, "ddate": null, "tcdate": 1542511725341, "tmdate": 1542511725341, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "r1gelBGgTm", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work! However, we cannot agree with your comments. We have addressed your questions and concerns below:\n\n1. As introduced in Sec. 1 and concluded by all reviewers, this work aims to \"train a single neural network executable at different widths for different devices\" \nWe never claim \"training runtime is the key problem\". And our focus is not on \"training a single network\" but on \"a single network executable at different widths\". The testing runtime and flexible accuracy-efficiency trade-offs are what we care. \n2. In Table 3 for ImageNet classification, the top-1 accuracy is actually improved by 0.5 in total.\n\n3. Although all experiments are conducted with same settings for both individual and slimmable models, we also noticed that the reproduced performance of individual models was lower than original papers. A potential reason is included in Appendix B of the first submitted version (original *-RCNN papers use ResNet-50 with strides on 1x1 convolution, while we follow PyTorch official implemented ResNet-50 with strides on 3x3). After submission, we found a recently released detection framework MMDetection [1] that has settings for pytorch-style ResNet-50. Thus we have conducted another set of detection experiments and included the results in Appendix C (same mAP is reproduced, for example, Faster-R-50-FPN-1x with 36.4 mAP).\nAnd our conclusion still holds: on detection tasks, slimmable models have better performance than individually trained models, especially for small models. Specifically, for 0.25x models, slimmable network has 2.0+ mAP, which is indeed significant. For 1.0x models, slimmable also have 0.4+ mAP, 0.7+ mAP for Faster-RCNN and Mask-RCNN. We will fully release our code (both training and testing) and pre-trained models on both ImageNet classification and COCO detection sets. \n\n4. Image classification trains models from scratch, while COCO detection fine-tunes pre-trained ImageNet models. The improvement on detection may due to better learned representation of slimmable models on ImageNet when transfer to COCO tasks. We have also mentioned in our submission that it is probably due to implicit distillation and richer supervision. The reason behind the improvements is beyond the motivation of this submission and requires future investigation. We try to avoid strong claims of any deep reason because none of them is strictly proved by us yet.\n\nWe sincerely thank you for posting these concerns and we will always try our best to address them. Please let us know if you have further question or concern. Thanks!\n\n\n[1] https://github.com/open-mmlab/mmdetection"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "rkgg7sI0TQ", "original": null, "number": 3, "cdate": 1542511384416, "ddate": null, "tcdate": 1542511384416, "tmdate": 1542511384416, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "ryl2OdD8p7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work. Our claim is correct: at runtime reducing depth cannot reduce memory footprint.\n\nFor a simple example, consider a layer-by-layer network stacking same convolution layers, the output of layer N can always be placed into the memory of its input after computation, and feed into next layer (N+1). Because at runtime, there is no need to store feature of previous layers generally (in training, they are required for gradient computation).\n\nA good reference is MobileNet v2 paper [1], section 5.1 memory efficient inference. It shows that the memory footprint can be simplified to: M = max_{layer_i \\in all layers} (memory_input of layer_i + memory_output of layer_i).\n\nThe memory footprint M is a MAX operation over all layers, instead of SUM, during inference.\n\n\n[1] Sandler, Mark, et al. \u201cMobileNet v2: Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation.\" arXiv preprint arXiv:1801.04381 (2018)."}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "rkxP-cICpm", "original": null, "number": 2, "cdate": 1542511103238, "ddate": null, "tcdate": 1542511103238, "tmdate": 1542511103238, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "Byg-61r4n7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "content": {"title": "Authors' Reply to Comment", "comment": "Thanks for your interest in our work! We have added the citation."}, "signatures": ["ICLR.cc/2019/Conference/Paper874/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618355, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1gMCsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper874/Authors|ICLR.cc/2019/Conference/Paper874/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618355}}}, {"id": "ryl2OdD8p7", "original": null, "number": 3, "cdate": 1541990516405, "ddate": null, "tcdate": 1541990516405, "tmdate": 1541990516405, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "It is claimed in the 3rd paragraph in introduction that, \n\n \"Nevertheless, in contrast to width (number of channels), reducing depth cannot reduce memory footprint which is commonly constrained during runtime.\"\n\nHowever, in my understanding, the momory reduces linearly when reducing depth for deep neural network. Could you please explain more on this?\n\n", "title": "\"reducing depth cannot reduce memory footprint\"?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}, {"id": "r1gelBGgTm", "original": null, "number": 2, "cdate": 1541575912179, "ddate": null, "tcdate": 1541575912179, "tmdate": 1541575912179, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "The motivation to train one model end deploy in multiple devices is quite interesting.  However, the experimental results are not convincing. \n\nIn Table 3, most of the S-networks reduce performance compared to their individual counterparts. It's not cumbersome to train individual slimmed model that has higher accuracy in portable device and the same FLOPs as the S-model, since training runtime is not the key problem with increasing amount of computational powers.\n\nIn Table 5, the baselines of R-50-FPN-1\u00d7 are much lower than those reported in the original paper of Faster R-CNN and Mask R-CNN.  In previous work, the box and mask AP of Mask+R-50-FPN-1\u00d7 are 37.3 and 33.7, while box AP for Faster+R-50-FPN-1\u00d7 is 36.4. These results are already comparable and even better than the S-networks. The same problem applies to the keypoints. Therefore, it is unclear that S-model would still bring performance gain when the standard baselines are employed.\n\nAnother concern is that S-model seems to degenerate performance in ImageNet, as the paper mentioned \"a slimmable network is expected to have lower performance than individually trained ones intuitively\". But it turns out that the pretrained S-model in ImageNet has large improvement when finetuned in detection and segmentation. This violates common sense.", "title": "Good motivation but not convincing results"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}, {"id": "rklrgxdT37", "original": null, "number": 3, "cdate": 1541402605455, "ddate": null, "tcdate": 1541402605455, "tmdate": 1541533618621, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "content": {"title": "The paper proposes an idea of combining different size models together into one shared net. And the performance is claimed to be slightly worse for classification and much better for detection.", "review": "The idea is really interesting. One only need to train and maintain one single model, but use it in different platforms of different computational power.\n\nAnd according to the experiment results of COCO detection, the S-version models are much better than original versions (eg. faster-0.25x, from 24.6 to 30.0) . The improvement is huge to me. However the authors do not explain any deep reasons.\n\nAnd for classification, there are slightly performance drop instead of a large improvement which is also hard to understand. \n\nFor detection, experiments on depth-wise convolution based models (such as mobilenet and shufflenet) are suggested to make this work more solid and meaningful.\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "cdate": 1542234357363, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822756, "tmdate": 1552335822756, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJez1UBa27", "original": null, "number": 2, "cdate": 1541391834438, "ddate": null, "tcdate": 1541391834438, "tmdate": 1541533618412, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "content": {"title": "Very exciting work", "review": "This paper presents a straightforward looking approach for creating a neural networks that can run under different resource constraints, e.g. less computation but lower quality solution and expensive high quality solution, while all the networks are having the same filters. The idea is to share the filters of the cheapest network with those of the larger more expensive networksa and train all those networks jointly with weight sharing. One important practical observation is that the batch-normalization parameters should not be shared between those filters in order to get good results. However, the most interesting surprising observation, that is the main novelty of the work that even the highest quality vision network get substantially better by this training methodology as compared to be training alone without any weight sharing with the smaller networks, when trained for object detection and segmentation purposes (but not for recognition). This is a highly unexpected result and provides a new unanticipated way of training better segmentation models. It is especially nice that the paper does not pretend that this phenomenon is well understood but leaves its proper explanation for future work. I think a lot of interesting work is to be expected along these lines.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "cdate": 1542234357363, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822756, "tmdate": 1552335822756, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1lytDzo2Q", "original": null, "number": 1, "cdate": 1541248886961, "ddate": null, "tcdate": 1541248886961, "tmdate": 1541533618138, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "content": {"title": "algo details and numbers", "review": "This paper trains a single network executable at different widths. This is implemented by maintaining separate BN parameter and statistics for different width. The problem is well-motivated and the proposed method can be very helpful for deployment of deep models to devices with varying capacity and computational ability.\n \nThis paper is well-written and the experiments are performed on various structures. Still I have several concerns regarding the algorithm.\n1. In algo 1, while gradients for convolutional and fully-connected layers are accumulated for all switches before update, how are the parameters for different switches updated?\n2. In algo 1, the gradients of all switches are accumulated before the update. This may result in implicit unbalanced gradient information, e.g. the connections in 0.25x model in Figure 1 has gradient flows on all four different switches,  while the right-most 0.25x connections in 1.0x model has only one gradient flow from the 1.0x switch, will this unbalanced gradient information increase optimization difficulty and how is it solved?\n3.  In the original ResNet paper, https://arxiv.org/pdf/1512.03385.pdf, the top-1 error of RestNet-50 is <21% in Table 4. The number reported in this paper (Table 3) is 23.9. Where does the difference come from? ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper874/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Official_Review", "cdate": 1542234357363, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper874/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822756, "tmdate": 1552335822756, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper874/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Byg-61r4n7", "original": null, "number": 1, "cdate": 1540800441478, "ddate": null, "tcdate": 1540800441478, "tmdate": 1540802106971, "tddate": null, "forum": "H1gMCsAqY7", "replyto": "H1gMCsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "content": {"comment": "Nice work! I had a paper published at CVPR 2018 on training convolutional networks that support instant and adaptive accuracy-efficiency trade-offs at runtime, via early downsampling rather than networking slimming. My paper also includes a similar technique of using independent BatchNorm parameters (just means and stds in my paper, whereas you \"unshare\" all of BatchNorm parameters) for different trade-off configurations. \n\nI'd appreciate if you would include a reference to it - \"Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks\". Thanks.\n", "title": "A related work"}, "signatures": ["~Jason_Kuen1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper874/Reviewers/Unsubmitted"], "writers": ["~Jason_Kuen1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Slimmable Neural Networks", "abstract": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations, we train a shared network with switchable batch normalization. At runtime, the network can adjust its width on the fly according to on-device benchmarks and resource constraints, rather than downloading and offloading different models. Our trained networks, named slimmable neural networks, achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1, MobileNet v2, ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection, instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: https://github.com/JiahuiYu/slimmable_networks", "keywords": ["Slimmable neural networks", "mobile deep learning", "accuracy-efficiency trade-offs"], "authorids": ["jyu79@illinois.edu", "linjie.yang@snap.com", "ning.xu@snap.com", "jianchao.yang@bytedance.com", "huang@ifp.uiuc.edu"], "authors": ["Jiahui Yu", "Linjie Yang", "Ning Xu", "Jianchao Yang", "Thomas Huang"], "TL;DR": "We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer), permitting instant and adaptive accuracy-efficiency trade-offs at runtime.", "pdf": "/pdf/9b4ba376f6df2dab93e37984d71cf1acae349395.pdf", "paperhash": "yu|slimmable_neural_networks", "_bibtex": "@inproceedings{\nyu2018slimmable,\ntitle={Slimmable Neural Networks},\nauthor={Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1gMCsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper874/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732185, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1gMCsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper874/Authors", "ICLR.cc/2019/Conference/Paper874/Reviewers", "ICLR.cc/2019/Conference/Paper874/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732185}}}], "count": 21}