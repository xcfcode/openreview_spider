{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396319025, "tcdate": 1486396319025, "number": 1, "id": "SyPojf8Og", "invitation": "ICLR.cc/2017/conference/-/paper36/acceptance", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper is about learning distributed representations. All reviewers agreed that the first draft was not clear enough for acceptance.\n \n Reviewer time is limited and a paper that needed a complete overhaul after the reviews were written is not going to get the same consideration as a paper that was well-drafted from the beginning.\n \n It's still the case that it's unclear from the paper how the learning updates or derived. The results are not visually impressive in themselves. It's also still the case that more is needed to demonstrate that this direction is promising compared to other approaches to representation learning."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396319517, "id": "ICLR.cc/2017/conference/-/paper36/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396319517}}}, {"tddate": null, "tmdate": 1484071525554, "tcdate": 1484071525554, "number": 6, "id": "SJavfsf8e", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "S1zNjzGNg", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: Potentially interesting paper, but not clear enough", "comment": "Thanks for your feedback! We substantially reorganized our paper to make it more accesible.\n1) The introduction was completely rewritten and now clearly states the goal of the paper, the contributions and provides the necessary framework/background of our work.\n2) Comparisons with other work are now bundled in Section 3 rather than being scatterd across the paper.\n3) We added more references and tried to justify our statements."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "tmdate": 1484071489274, "tcdate": 1484071489274, "number": 5, "id": "BkFHzsMLl", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "SJXnoez4e", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: Improve the exposition", "comment": "Thanks for your feedback!\n1) The introduction was completely reorganized. The first paragraph verbally describes the goal of the paper and the second paragraph formalizes it. We then introduce partition models, which form the basis of our work. The main implication of our paper (that it's not necessary to use multiple experts to explain individual variables in HD data) is stated in the last paragraph.\n2) The statement \"experts only have a small variance for some subset of the variables while the variance of the other variables is large\" was clarified and rephrased in Section 2.2.2.\n3) Yes, sparse dictionary learning attempts to do something similar. The main difference is that opinion pools of the form sum_k h(k)*w_k(d) are used (instead of only one expert per variable). We added a reference in Section 3. There is also an experimental comparison in Section 4.1.\n4) I'm not sure if I correctly understand your last comment. Do you mean the number of factors of variation in the dataset? In this experiment we show that a very HD dataset can be reduced to a small number of experts (here 20) while still allowing reasonable reconstructions. If there are more factors of variation then more experts will be needed."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "tmdate": 1484071455792, "tcdate": 1484071455792, "number": 4, "id": "SkdmfoGLg", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "By4XeQeVe", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: A type of PoE but the probability seems undefined and the EM algorithms remains obscure. Experiments are illustrative only.", "comment": "We substantially revised our paper and think that the exposition is now much clearer."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484071341261, "tcdate": 1478051771844, "number": 36, "id": "BJ46w6Ule", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BJ46w6Ule", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "content": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481939754402, "tcdate": 1481939754402, "number": 3, "id": "S1zNjzGNg", "invitation": "ICLR.cc/2017/conference/-/paper36/official/review", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/conference/paper36/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper36/AnonReviewer1"], "content": {"title": "Potentially interesting paper, but not clear enough", "rating": "3: Clear rejection", "review": "The paper addresses the problem of learning compact binary data representations. I have a hard time understanding the setting and the writing of the paper is not making it any easier. For example I can't find a simple explanation of the problem and I am not familiar with these line of research. I read all the responses provided by authors to reviewer's questions and re-read the paper again and I still do not fully understand the setting and thus can't really evaluate the contributions of these work. The related work section does not exist and instead the analysis of the literature is somehow scattered across the paper. There are no derivations provided. Statements often miss references, e.g. the ones in the fourth paragraph of Section 3. This makes me conclude that the paper still requires significant work before it can be published.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512720768, "id": "ICLR.cc/2017/conference/-/paper36/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper36/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper36/AnonReviewer3", "ICLR.cc/2017/conference/paper36/AnonReviewer2", "ICLR.cc/2017/conference/paper36/AnonReviewer1"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512720768}}}, {"tddate": null, "tmdate": 1481931690970, "tcdate": 1481931690970, "number": 2, "id": "SJXnoez4e", "invitation": "ICLR.cc/2017/conference/-/paper36/official/review", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/conference/paper36/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper36/AnonReviewer2"], "content": {"title": "Improve the exposition", "rating": "6: Marginally above acceptance threshold", "review": "The goal of this paper is to learn \u201c a collection of experts that are individually\nmeaningful and that have disjoint responsibilities.\u201d Unlike a standard mixture model, they \u201cuse a different mixture for each dimension d.\u201d While the results seem promising, the paper exposition needs significant improvement.\n\nComments:\n\nThe paper jumps in with no motivation at all. What is the application, or even the algorithm, or architecture that this is used for? This should be addressed at the beginning.\n\nThe subsequent exposition is not very clear. There are assertions made with no justification, e.g. \u201cthe experts only have a small variance for some subset of the variables while the variance of the other variables is large.\u201d \n\nSince you\u2019re learning both the experts and the weights, can this be rephrased in terms of dictionary learning? Please discuss the relevant related literature.\n\nThe horse data set is quite small with respect to the feature dimension, and so the conclusions may not necessarily generalize.\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512720768, "id": "ICLR.cc/2017/conference/-/paper36/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper36/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper36/AnonReviewer3", "ICLR.cc/2017/conference/paper36/AnonReviewer2", "ICLR.cc/2017/conference/paper36/AnonReviewer1"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512720768}}}, {"tddate": null, "tmdate": 1481809948364, "tcdate": 1481809948358, "number": 3, "id": "By4XeQeVe", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "HyRxUhRQg", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: A type of PoE but the probability seems undefined and the EM algorithms remains obscure. Experiments are illustrative only.", "comment": "Thanks a lot for you comments. You raised some important points.\n1) In this work we focus on learning a compact distributed representation. The experts are trained such that the conditional likelihood of the data given the latent state is maximized. Just as for autoencoders or sparse dictionaries we are not explicitly specifying the distribution of the latent variables. But you are right, in order to obtain a fully generative model this has to be added. In our case P(h) is a relatively low-dimensional distribution with weak dependencies, so there are many ways to model that. We will add some possible options to the discussion.\n2) Since we do not have a joint model, maybe we should not have called it an EM algorithm since the proposed algorithm does not formally improve a lower bound.\n3) Thanks for your effort in trying to optimize the objective function in 3.2. In your derivation you probably left out the denominator of the gradient (see 6.1.2), which also depends on the expert opinions. We actually do not think that there is an analytic expression for the solution. One option would then be to use numeric optimization, but we discussed the problems with that. Our proposal is a heuristic, which works very well and which is quite stable. The update rule is directly motivated by the exact update that is available in the unsmoothed model, see equation (1).\n4) Thanks for the important reference. We will discuss how that approach relates to our work and add it to the paper.\n5) In section 4.1 we are comparing our results with autoencoders, sparse dictionaries and restricted Boltzmann machines. On that dataset our model clearly outperforms the other three. Our earlier paper (http://arxiv.org/abs/1412.3708) contains quantitative results for a similar dataset and a similar model, also comparing to autencoders and RBMs. We left this out here due to space constraints."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "tmdate": 1481717237828, "tcdate": 1481717237821, "number": 1, "id": "HyRxUhRQg", "invitation": "ICLR.cc/2017/conference/-/paper36/official/review", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/conference/paper36/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper36/AnonReviewer3"], "content": {"title": "A type of PoE but the probability seems undefined and the EM algorithms remains obscure. Experiments are illustrative only. ", "rating": "3: Clear rejection", "review": "This paper proposes a new kind of expert model where a sparse subset of most reliable experts is chosen instead of the usual logarithmic opinion pool of a PoE.\nI find the paper very unclear. I tried to find a proper definition of the joint model p(x,z) but could not extract this from the text. The proposed \u201cEM-like\u201d algorithm should then also follow directly from this definition. At this point I do not see if such as definition even exists. In other words, is there is an objective function on which the iterates of the proposed algorithm are guaranteed to improve on the train data?\nWe also note that the \u201cproduct of unifac models\u201d from Hinton tries to do something very similar where only a subset of the experts will get activated to generate the input: http://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf\nI tried to derive the update rule on top of page 4 from the \u201cconditional objective for p(x|h)\u201d in sec. 3.2 But I am getting something different (apart form the extra smoothing factors eps and mu_o). Does this follow? (If we define R=R_nk, mu-mu_k and X=X_n, I get mu = (XR)*inv(R^TR) as the optimal solution, which then needs to be projected back onto the probability simplex).\nThe experiments are only illustrative. They don\u2019t compare with other methods (such as an RBM or VAE) nor do they give any quantitative results. We are left with eyeballing some images. I have no idea whether what we see is impressive or not. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512720768, "id": "ICLR.cc/2017/conference/-/paper36/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper36/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper36/AnonReviewer3", "ICLR.cc/2017/conference/paper36/AnonReviewer2", "ICLR.cc/2017/conference/paper36/AnonReviewer1"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512720768}}}, {"tddate": null, "tmdate": 1481481087948, "tcdate": 1481481087943, "number": 2, "id": "BJuYiGomx", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "SkU9Ld1ml", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: Extensions to data with temporal structure", "comment": "Thanks for the question. Our approach can directly be applied to discrete-time signals with finitely many time points. If there are T time points and D dimensions then the samples can simply be treated as T*D dimensional data. We are not directly employing spatial or temporal information (in contrast to the mentioned reference). Deciding whether variables, which are close in space or in time, should be explained by the same expert is part of the learning process. However, a prior that favors such assignments of expertise could in principle be added. Since we do not assume that the expert opinions are already available (learning them is one of the main tasks) it seems difficult to work with online observations (one variable at a time) because the expert opinions and levels of expertise have to be learned at the same time. However, if one D-dimensional sample at a time is observed then we can use a simple online variant of our EM algorithm."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "tmdate": 1481481055441, "tcdate": 1481481055435, "number": 1, "id": "BJwvsMome", "invitation": "ICLR.cc/2017/conference/-/paper36/public/comment", "forum": "BJ46w6Ule", "replyto": "HJygUsyme", "signatures": ["~Marc_Goessling1"], "readers": ["everyone"], "writers": ["~Marc_Goessling1"], "content": {"title": "Re: Clarifications", "comment": "Thanks for the important references. Their online framework is rather different from our (offline) setup. They focus on sequential predictions while we have all observations available from the beginning. We added a paragraph at the end of section 2 to discuss the differences. For example, they consider a single sequence of variables with a fixed partitioning into experts supports. In our setup the partitioning changes dynamically depending on the observed sample. However, the biggest difference to our work is that they do not learn the individual experts opinions but only focus on training the levels of expertise. It is assumed that a stream of predictions from the experts is already available while in our work learning of the expert opinions is one of the main tasks (in addition to learning the expertise)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287755344, "id": "ICLR.cc/2017/conference/-/paper36/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ46w6Ule", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper36/reviewers", "ICLR.cc/2017/conference/paper36/areachairs"], "cdate": 1485287755344}}}, {"tddate": null, "tmdate": 1480730087384, "tcdate": 1480730087378, "number": 2, "id": "HJygUsyme", "invitation": "ICLR.cc/2017/conference/-/paper36/pre-review/question", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/conference/paper36/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper36/AnonReviewer1"], "content": {"title": "Clarifications", "question": "Could you contrast your work with some other common learning-with-experts approaches like static expert or fixed-share etc.? In example see [M. Herbster and M. K. Warmuth. Tracking the best expert. Machine Learning, 32:151\u2013178,1998] or [Olivier Bousquet and Manfred K. Warmuth. Tracking a small set of experts by mixing\npast posteriors. Journal of Machine Learning Research, 3:363\u2013396, 2002] etc."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959499102, "id": "ICLR.cc/2017/conference/-/paper36/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper36/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper36/AnonReviewer2", "ICLR.cc/2017/conference/paper36/AnonReviewer1"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959499102}}}, {"tddate": null, "tmdate": 1480717965808, "tcdate": 1480717965804, "number": 1, "id": "SkU9Ld1ml", "invitation": "ICLR.cc/2017/conference/-/paper36/pre-review/question", "forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "signatures": ["ICLR.cc/2017/conference/paper36/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper36/AnonReviewer2"], "content": {"title": "Extensions to data with temporal structure", "question": "Could your approach be extended to have level of expertise be temporally dependent? If not in the most general setting of non-stationarity, then even in a special case in which different experts specialize in different time periods (for different variables), or even in a periodic fashion (e.g. \"sleeping experts\" as in \"Putting Bayes to Sleep,\" Koolen et al., NIPS 2012)? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Partition Models", "abstract": "We present a new approach for learning compact and intuitive distributed representations with binary encoding. Rather than summing up expert votes as in products of experts, we employ for each variable the opinion of the most reliable expert. Data points are hence explained through a partitioning of the variables into expert supports. The partitions are dynamically adapted based on which experts are active. During the learning phase we adopt a smoothed version of this model that uses separate mixtures for each data dimension. In our experiments we achieve accurate reconstructions of high-dimensional data points with at most a dozen experts.", "pdf": "/pdf/b9e974f1ed60a55c828f66e47def806b28b20140.pdf", "TL;DR": "Learning of compact binary representations through partitioning of the variables", "paperhash": "goessling|dynamic_partition_models", "conflicts": ["uchicago.edu"], "authorids": ["goessling@uchicago.edu"], "keywords": [], "authors": ["Marc Goessling", "Yali Amit"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959499102, "id": "ICLR.cc/2017/conference/-/paper36/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper36/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper36/AnonReviewer2", "ICLR.cc/2017/conference/paper36/AnonReviewer1"], "reply": {"forum": "BJ46w6Ule", "replyto": "BJ46w6Ule", "writers": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper36/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959499102}}}], "count": 13}