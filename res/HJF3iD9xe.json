{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396577238, "tcdate": 1486396577238, "number": 1, "id": "HyKjhGIux", "invitation": "ICLR.cc/2017/conference/-/paper426/acceptance", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper studies neural models that can be applied to set-structured inputs and thus require permutation invariance or equivariance. After a first section that introduces necessary and sufficient conditions for permutation invariance/equivariance, the authors present experiments in supervised and semi-supervised learning on point-cloud data as well as cosmology data.\n \n The reviewers agreed that this is a very promising line of work and acknowledged the effort of the authors to improve their paper after the initial discussion phase. However, they also agree that the work appears to be missing more convincing numerical experiments and insights on the choice of neural architectures in the class of permutation-covariant. \n \n In light of these reviews, the AC invites their work to the workshop track. \n Also, I would like to emphasize an aspect of this work that I think should be addressed in the subsequent revision.\n \n As the authors rightfully show (thm 2.1), permutation equivariance puts very strong constraints in the class of 1-layer networks. This theorem, while rigorous, reflects a simple algebraic property of matrices that commute with permutation matrices. It is therefore not very surprising, and the resulting architecture relatively obvious. So much so that it already exists in the literature. In fact, it is a particular instance of the graph neural network model of Scarselli et al. '09 (http://ieeexplore.ieee.org/abstract/document/4700287/) when you consider a complete graph, which has been used in the setup of full set equivariance for example in 'Learning Multiagent communication with backpropagation', Sukhbaatar et al NIPS'16; see also 'Order Matters: sequence to sequence for sets', Vinyals et al. https://arxiv.org/abs/1511.06391. \n The general question of how to model point-cloud data, or more generally data defined over graphs, with neural networks is progressing rapidly; see for example https://arxiv.org/abs/1611.08097 for a recent survey.\n \n The question then is what is the contribution of the present work relative to this line of work. The authors should answer this question explicitly in the revised manuscript, either with a new application of the model, or with theory that advances our understanding of these models, or with new numerical applications.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396577794, "id": "ICLR.cc/2017/conference/-/paper426/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396577794}}}, {"tddate": null, "tmdate": 1484770233199, "tcdate": 1484770233199, "number": 5, "id": "HyWaiHT8g", "invitation": "ICLR.cc/2017/conference/-/paper426/official/comment", "forum": "HJF3iD9xe", "replyto": "B1QElZ3Ue", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "-", "comment": "I slightly disagree. Basically, they do not know the graphs, and they learn it. However, their representation is invariant w.r.t. a large family of permutations that is defined by the graph. (for example, if two nodes are paired, the representation invariant by this permutation) The framework they present is more general, in the sens that given a permutation that has been averaged, they recover the missing information by using the corresponding wavelets. The construction of such wavelets is very well introduced in this paper: https://pdfs.semanticscholar.org/d6b6/3e12c44129b0dc06bb242ab1777c152cff89.pdf\nAt the end, your two representations want to be invariants to several class of permutations. They showed it is possible to recover the grid, but as well building a representation that is discriminative without the knowledge of it. However, I totally agree that they did it in an unsupervised setting.\n\nIt would be interesting, to use their techniques to discover graphs with your techniques to design the filters. Anyway, that's more an open suggestion than a requirement.\n\nThanks again for your answers and the numbers."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287581894, "id": "ICLR.cc/2017/conference/-/paper426/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287581894}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484685882641, "tcdate": 1478290352633, "number": 426, "id": "HJF3iD9xe", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HJF3iD9xe", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "content": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 19, "writable": false, "overwriting": ["Bkj2v6XYl"], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1484685355523, "tcdate": 1484685355523, "number": 9, "id": "B1QElZ3Ue", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "rk3j7Fi8l", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": " ", "comment": "Thanks for your comments! We have added a paragraph explaining the relation of Chen et al.\u201914 to our work. Scattering features are permutation invariant, however, they cannot be used for semi-surpervised learning where we need \u201cequivariance\u201d. Their other requirement seems to be an underlying graph structure to guide the partitioning of the nodes. Also note that we believe the scrambled MNIST results in their paper is produced by permuting the pixels with an \u201cidentical\u201d permutation matrix for all instances and their result on this dataset is not permutation-invariant by our definition. They only intend to show that they are able to find the underlying pixel neighborhood and leverage it in supervised learning (We intended to compare our method against their method on this task before we noticed this issue.)\n\nWe have also added another baseline for the red-shift improvement experiments from the original redMaPPer catalog, per your request.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1484653476078, "tcdate": 1484653476078, "number": 4, "id": "rk3j7Fi8l", "invitation": "ICLR.cc/2017/conference/-/paper426/official/comment", "forum": "HJF3iD9xe", "replyto": "HJIvka5Ix", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "Comment", "comment": "Hi,\n\nCould you add some baseline accuracies to your redshift prediction dataset? The improvement is demonstrated, however I do not know well those problems and I wish you could add some numbers to see how good you perform.(as you did with mnist)\n\nOne more comment (and please let me know if I am doing a mistake). In the way you wrote this new version, I see some connexions between your work and a haar transform(or lifting scheme) on graphs. For example this paper: https://arxiv.org/pdf/1406.2390v2.pdf . Basically, they can learn a graph associated to the data and find out an appropriate representation for classification, yet in an unsupervised setting. And, as far as I understand, they build as well an invariant representation to permutations. (the fact they use filters with support 2^j is not a limitation, as far as I understand) However, they are still discriminative because they can recover some missing information lost after the averaging. As far as I understand your equation (2) in a convolutioonal setting, you combine a dirac and an averaging (say A). In some sens, you are at the first step to build an isometric operator(eg {A,I-A}). Interestingly, you set up this in a supervised setting.\n\nThis being said, I find the applications interesting."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287581894, "id": "ICLR.cc/2017/conference/-/paper426/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287581894}}}, {"tddate": null, "tmdate": 1484604471585, "tcdate": 1484604390541, "number": 8, "id": "BkCk4pcUe", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Major Revision", "comment": "We thank all reviewers for their comments! A commonl issue in reviews was regarding the disconnect between our general treatment of invariance and experimental results. The other major issue was regarding the clarity of the first part. \n\nTo resolve both issues we have removed our general treatment and focused on \"deep learning with sets and point-clouds\", incorporating all reviewer feedback on this part. We welcome any further comments on the revised version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1484603230129, "tcdate": 1484603230129, "number": 7, "id": "HJIvka5Ix", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "S1cGMcb4g", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re:A promising work!", "comment": "Thanks for your feedback! \nTo remove the gap between our general formalism and the experimental treatment that was limited to sets and point-clouds, we have extensively revised the paper, solely focusing on the application of deep permutation-equivariant/invariant models. We have added new experimental results and clarified the formalism for sets. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1484603154093, "tcdate": 1484603154093, "number": 6, "id": "HJ5Gk69Ie", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "H1bCVY-4x", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re:interesting topic, but hard to follow for a non-expert", "comment": "Thank you very much for your feedback! We appreciate the time you have spent on our paper and based on your comments we have extensively rewritten the paper. We have removed all the abstract and general treatments of invariance and focused solely on the case of sets and point-clouds. We have included more experimental results and baseline evaluations as well. Any further feedback is appreciated.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1484603031327, "tcdate": 1484603031327, "number": 5, "id": "SJJj0h58e", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "BkY_LYbNe", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re:Interesting formalization of invariance in neural networks, but too abstract and weak experimental results", "comment": "Thank you very much for your feedback! Based on your comments, we have extensively revised the paper. In particular, we have removed the general treatment of invariances from this paper in favour of clarity and focused solely on the case of permutation-invariance/equivariance for set structure. \n\nRegarding the choice of set-layer, a new theorem in our paper shows that parameter-sharing of our set-layer is the only way of achieving permutation-equivariance in \u201cstandard\u201d neural network layers. \n\nWRT baselines: We have added new experiments as well as more baseline results for \u201call\u201d settings to address your concern. \n\nWRT composition: in the revised paper, we show that functional composition preserves permutation-equivariance.\n\nWRT connections to symmetric function theory: the permutation-invariant function in our case is indeed a so-called \u201csymmetric function\u201d. We have added citations for this. However, symmetric function theory is concerned with polynomial forms while we study symmetric functions in the form of abstract neurons.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1484602960063, "tcdate": 1484602960063, "number": 4, "id": "HkOIA258g", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "HyLUaojHx", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re:Excellent choice of topic, but more work is needed for the results to be actionable.", "comment": "Dear Andrew, thank you for your feedback. We have basically rewritten the paper, focusing only on sets and point-clouds. We do agree with you that treatment of point-cloud data is highly useful in many modern applications and hope that our work motivates researchers in robotics and vision to directly employ point-cloud data.\n\nWRT concerns regarding design of the layer: We have added a theorem showing that our parameter-sharing is the only mechanism to achieve permutation-equivariance in \u201cstandard\u201d neural network layers. Your suggestion of sharing a FC layer between the instances in the set is what we refer to as set-pooling and only works for supervised settings.\n\n\nWRT your concern regarding the invariance to spatial transformations in the point-cloud data: great observation! We are aware of this. If in any application a reference point is needed in the point-cloud, it can be added as another point (possibly outside the boundary of the cloud) to fix an origin.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1483615782955, "tcdate": 1483615566134, "number": 1, "id": "HyLUaojHx", "invitation": "ICLR.cc/2017/conference/-/paper426/public/review", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["~Andrew_William_Wagner1"], "readers": ["everyone"], "writers": ["~Andrew_William_Wagner1"], "content": {"title": "Excellent choice of topic, but more work is needed for the results to be actionable.", "rating": "6: Marginally above acceptance threshold", "review": "Pros:\n* Part of the paper addresses an industrially important topic, namely how to make deep networks work properly on point clouds, i.e. in many (most?) potential applications they should be invariant to permutations of the points within the cloud, as well as rigid transformations of the cloud (depends on the application).\n* The authors propose a formalism for dealing with compositions of different kinds of invariance.\n\nCons:\n* For me the explanation of the generalization is really hard to follow. For me, the paper would be stronger if were less broad, but went into more depth for the permutation-invariance case.\n* It is very easy to sit down and come up with network structures that are permutation invariant. It seems the author tried a few networks in the family (a few different point cloud sizes, a couple options for the number of parameters, averaging vs. max in the set, dropout vs. no dropout), but unless the space is more completely and systematically explored, there's not much reason for a practitioner to use the proposed structure vs. some other random structure they cook up that is also permutation invariant. i.e. what about just using a FC layer that is shared between the points instead of your three \"set invariant\" layers? Seems simpler, more general, and also permutation invariant...\n* It is not clear to me how valuable the author's definition of \"minimally invariant\" is. Is a sufficiently large composition of \"set invariant\" layers a universal approximator for permutation invariant functions?\n* I'm concerned that proposed \"set invariant layer\" might be strongly variant to spatial transformations, as well as vulnerable to large outliers. In particular there is a term that subtracts a corner of the clouds bounding box (i.e. the max over set operator inside the first layer), before the cloud goes through a learned affine transform and pixelwise nonlinearity. Seems like that could saturate the whole network...\n\nI'm reviewing with low confidence, because there's a chance the formalism in the first part of the paper is more valuable than I realize; I haven't fully understood it. ", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1483615566770, "id": "ICLR.cc/2017/conference/-/paper426/public/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "noninvitees": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu", "ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs", "~Andrew_William_Wagner1"], "cdate": 1483615566770}}}, {"tddate": null, "tmdate": 1481909689439, "tcdate": 1481909689439, "number": 3, "id": "H1ZpBsZVe", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "ry6mm9-4l", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re: Invariance to structure", "comment": "Thanks for your follow up! \n\nIn the case of convolution, \"permutation over relations\" does not result in the final translation equivariance. That is the commutative summation plays no role here. What does the trick for 2D-grid is the fact that individual functions f^{i,j}(x_{S}) defined on the neighborhood of (i,j) pixel, share their parameters -- i.e. f^{i',j'} = f^{i,j} = f_{theta} for all 0<i,j<N associated with pixels; see figure 2(a)-left.\n\nIn general there are two factors at play in producing invariances of a structure: 1) invariance to permutation over relations in the structure S; 2) parameter-sharing across functions f(x_S) for x \\in \\mathcal{X}, also encoded in the structure S.\n\n  \n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1481904932818, "tcdate": 1481904932818, "number": 3, "id": "ry6mm9-4l", "invitation": "ICLR.cc/2017/conference/-/paper426/official/comment", "forum": "HJF3iD9xe", "replyto": "SyIAEIgEe", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "Invariance to structure", "comment": "Thank you very much for your detailed explanation.\n\nOne more comment: your framework handle 2D convolutions, but I think mentionning it can be slightly confusig in the following sens. Your framework permits to build invariance with respect to permutations to the relation. A linear averaging builds an invariant to translation, and permutations. However, from your framework, one can not derive the fact that the layers need to be covariant with the action of translation to build this invariance. Here, (please correct me if I'm wrong), the invariance which is obtained is different: a convolution at a position i of an image x can be written as a dot product with a filter f, such that the resulting filtered image is result[i]=sum_j x[i+j]f[j] In your frame work, the structure is given by the neighbors(they are as uch relations as the number of elements in the support of the filters), f is the weights, and the invariance here means that the sum over j is commutative, which is not much informative."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287581894, "id": "ICLR.cc/2017/conference/-/paper426/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287581894}}}, {"tddate": null, "tmdate": 1481904657866, "tcdate": 1481904657866, "number": 3, "id": "S1cGMcb4g", "invitation": "ICLR.cc/2017/conference/-/paper426/official/review", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "A promising work!", "rating": "5: Marginally below acceptance threshold", "review": "Pros : \n- New and clear formalism for invariance on signals with known structure\n- Good numerical results\n\nCons :\n- The structure must be specified.\n- The set structure dataset is too simple\n- There is a gap between the large (and sometimes complex) theory introduced and the numerical experiments ; consequently a new reader could be lost since examples might be missing\n\nBesides, from a personal point of view, I think the topic of the paper and its content could be suitable for a big conference as the author improves its content.  Thus, if rejected, I think you should not consider the workshop option for your paper if you wish to publish it later in a conference, because big conferences might consider the workshop papers of ICLR as publications. (that's an issue I had to deal with at some points)", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512590603, "id": "ICLR.cc/2017/conference/-/paper426/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper426/AnonReviewer2", "ICLR.cc/2017/conference/paper426/AnonReviewer3", "ICLR.cc/2017/conference/paper426/AnonReviewer1"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512590603}}}, {"tddate": null, "tmdate": 1481904292896, "tcdate": 1481901256757, "number": 1, "id": "H1bCVY-4x", "invitation": "ICLR.cc/2017/conference/-/paper426/official/review", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer2"], "content": {"title": "interesting topic, but hard to follow for a non-expert ", "rating": "7: Good paper, accept", "review": "This review is only an informed guess - unfortunately I cannot assess the paper due to my lack of understanding of the paper. \nI have spent several hours trying to read this paper - but it has not been possible for me to follow - partially due to my own limitations, but also I think due to an overly abstract level of presentation. The paper is clearly written, but in the same way that a N. Bourbaki book is clearly written.\n\nI would prefer to leave the accept/reject decision to the other reviewers who may have a better understanding - even if the authors had made a serious mistake, I would not be able to tell. My proposal is positive because the paper is apparently clearly written and the empirical evaluation is quite promising. But some effort will be needed in order to address the broader audience that could potentially be interested in the topic. \n\nI therefore would like to provide feedback only at the level of presentation. \n\nMy main source of problems is that the authors do not try to ground their abstract formalism with concrete examples; when the examples show up it is by \"revelation\" rather than by explaining how they connect to the previous concepts. \n\nThe one example that could unlock most people's understanding is how convolution, or inner product operations connect with the setting described here. For what I know convolution is tied with space (or time) and is understood as an equivariant operation - shifting the signal shifts the output. \nIt is not explained how the '(x, x')' pairs used by the authors in order to build relations, structures and then to define invariance relate to this setting. \nGoing from sets, to relations, to functions, to operators, and then to shift-invariant operators (convolutions) involves many steps, and some hand-holding is needed.\n\nWhy is the 3x3 convolution associated to 9 relations? \nAre these relations referring to the input at a given coordinate and its contribution to the output? (w_{offset} x_{i-offset})? In that case, why is there a backward arrow from the center node to the other nodes? And why are there arrows across nodes? \nWhat is a Cardinal and what is a Cartesian convolution in signal processing terms? (clearly these are not standard terms). \nAre we talking about separable filters? \nWhat are the X and Square symbols in Figure 2? And what are the horizontal and vertical sub-graphs standing for? What is x_1 and what is x_{11},x_{1,2},x_{1,3} and what is the relationship between them?\n\nI realize that to the authors these questions may seem to be trivial and left as  homework for the reader. But I think part of publishing a paper is doing a big part of the homework for the readers so that it becomes easy to get the idea. \n\nClearly the authors target the more general case - but spending some time to explain how the particular case is an instance of the the general case would be a good use of space. \n\nI would propose that the authors explain what are  x, x_{I}, and x_{S} for the simplest possible example, e.g. convolving a 1x5 signal with a 1x3 filter, how the convolution filter parameters show up in the function f, as well as how the spatial invariance (or, equivariance) of convolution is reflected here. ", "confidence": "1: The reviewer's evaluation is an educated guess"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512590603, "id": "ICLR.cc/2017/conference/-/paper426/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper426/AnonReviewer2", "ICLR.cc/2017/conference/paper426/AnonReviewer3", "ICLR.cc/2017/conference/paper426/AnonReviewer1"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512590603}}}, {"tddate": null, "tmdate": 1481901681496, "tcdate": 1481901681496, "number": 2, "id": "BkY_LYbNe", "invitation": "ICLR.cc/2017/conference/-/paper426/official/review", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer3"], "content": {"title": "Interesting formalization of invariance in neural networks, but too abstract and weak experimental results", "rating": "5: Marginally below acceptance threshold", "review": "\nThis paper discusses ways to enforce invariance in neural networks using weight sharing.  The authors formalize a way for feature functions to be invariant to a collection of relations and the main invariance studied is a \u201cset-invariant\u201d function, which is used in an anomaly detection setting and a point cloud classification problem.  \n\n\u201cInvariance\u201d is, at a high level, an important issue of course, since we don\u2019t want to spend parameters to model spurious ordering relationships, which may potentially be quite wasteful and I like the formalization of invariance presented in this paper.  However, there are a few weaknesses that I feel prevent this from being a strong submission.  First, the exposition is too abstract and this paper could really use a running and *concrete* example starting from the very beginning.\n\nSecond, \u201cset invariance\u201d, which is the main type of invariance studied in the paper is defined via the author\u2019s formalization of invariance, but is never explicitly related to what I might think of as \u201cset invariance\u201d \u2014 e.g. to permutations of input or output dimensions.  Explicitly defining set invariance in some other way, then relating it to the  \u201cstructural invariance\u201d formulation may be a better way to explain things.  It is never made clear, for example, why Figure 1(b) is *the* set data-structure.\n\nI like the discussion of compositionality of structures (one question I have here is: are the resulting compositional structures are still valid as structures?).  But the authors have ignored the other kind of compositionality that is important to neural networks \u2014 specifically that relating the proposed notion of invariance to function composition seems important \u2014 i.e. under what conditions do compositions of invariant functions remain invariant?  And  It is clear to me that just by having one layer of invariance in a network doesn\u2019t make the entire network invariant, for example.  So if we look at the anomaly detection network at the end for example, is it clear that the final predictor is \u201cset invariant\u201d in some sense?  \n\nRegarding experiments, there are no baselines presented for anomaly detection.  Baselines *are* presented in the point cloud classification problem, but the results of the proposed model are not the best, and this should be addressed.  (I should say that I don\u2019t know enough about the dataset to say whether these are exactly fair comparisons or not).  It is also never really made clear why set invariance is a desirable property for a point cloud classification setting.  As a suggestion: try a network that uses a fully connected layer at the end, but uses data augmentation to enforce set invariance.  Also, what about classical set kernels?\n\nOther random things:\n* Example 2.2: Shouldn\u2019t |S|=5 in the case of left-right and up-down symmetry?\n* \u201cParameters shared within a relation\u201d is vague and undefined.\n* Why is \u201cset convolution\u201d called \u201cset convolution\u201d in the appendix?  What is convolutional about it?\n* Is there a relationship to symmetric function theory?\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512590603, "id": "ICLR.cc/2017/conference/-/paper426/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper426/AnonReviewer2", "ICLR.cc/2017/conference/paper426/AnonReviewer3", "ICLR.cc/2017/conference/paper426/AnonReviewer1"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512590603}}}, {"tddate": null, "tmdate": 1481823437708, "tcdate": 1481823437702, "number": 2, "id": "SyIAEIgEe", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "r1Gx5XxVl", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re: Clarifications", "comment": "\nThank you for your follow up!\n\nThe product structure is indeed central in our approach to handling of structure. According to our partial ordering of structures, they appear between two extreme cases of \u201call\u201d structure --that requires using fully connected layer-- and \u201cnull\u201d structure of the mini-batch. Note that the set-structure (handled by set-invariant layer) is not at either extremes of this partial order.  \nNow, to handle the product of any structures (not limited to \u201cnull\u201d, \u201call\u201d or \u201cset\u201d structures), one could obtain the product (as defined on page 3) and proceed by defining the parameter-sharing of the layers according to eq(1). A faster \u201cheuristic\u201d is to handle one structure at a time, which as our extreme example 4.3 shows could lead to trouble. \n\nLet me clarify where and why we use this heuristic:\n\nWe present three sets of experiments on 1) point-cloud-classification; 2) face outlier detection and; 3) semi-supervised learning with sets. The product-structures in experiments (1) and (3) are the product of \u201cnull\u201d, \u201cset\u201d and \u201call\u201d structures, which only require using the set-invariant layer of section 5.1. Here, note that multiple input channels correspond to the \u201call\u201d structure in the product structure. \n\nHowever, in the face outlier detection experiment (2), we also have the 2D grid structure that requires using the parameter-sharing of the 2D-convolution layer. Here the complete product structure is: \n\nS = null \\times set \\times all \\times 2D-Grid\n\nWhere \u201cnull\u201d structure reflects the mini-batch, set structure is due to having a set of 16 face images, \u201call\u201d structure is due to multiple input channels (e.g. R, G, B) and 2D-grid reflects the structure of 2D image. To correctly handle this product structure, we need to use the parameter-sharing implied by the resulting product. However, for handling the product of 2D-grid and set structures, we could not use the efficient implementation of convolution layer. That is why we use the heuristic of section 4.1 for handling one structure at a time: first we define multiple convolution-pooling layers to capture the spatial/grid structure and then use the set-invariant layer of section 4.1 to handle the product of \u201cnull\u201d, \u201call\u201d and \u201cset\u201d structures (details are in Appendix D.1.). As our result for face outlier detection indicates, handling one structure at a time, works well here. \n\nHere, while one could use the heuristic of section 4.1 followed by some other technique (as you suggest) to reduce the \u201cinformation loss\u201d, for best results one might as well avoid the heuristic of section 4.1 altogether.\n\nAlthough we repeatedly acknowledge the fact that our experiments are limited to the set structure, our framework is more general; demonstrated by deriving other types of layers as special cases. We believe this alternative approach to structure based on parameter-sharing is useful on its own -- for example our derivation of graph convolution is much simpler and gives complementary view to current derivation. We are currently investigating applications of this framework for more complex structures such as nested sets and graph of graphs for multi-resolution handling of point-clouds and graphs. We agree with you that it would be very useful to be able to automatically infer the structure from data, however we have no idea for an efficient solution at the moment.\n\nI hope this addresses your questions and comments. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1481812458040, "tcdate": 1481812458032, "number": 2, "id": "r1Gx5XxVl", "invitation": "ICLR.cc/2017/conference/-/paper426/official/comment", "forum": "HJF3iD9xe", "replyto": "rJPInXkQl", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "Clarifications", "comment": "Thank you for your answers, please read carefully my final questions as I will use them for my final review.\n\n# When the invariance is not \"minimal\" (as defined in section 4), one could lose discriminative information. The only place this lack of minimal invariance comes up in our paper is as an easy way to handle the product structure. Example 4.3 gives an extreme scenario to see the possible issues with using this trick with product structures. This inadvertent loss of information does not happen with correct (but possibly cumbersome) way of handling a product structure using minimally invariant layer (of eq. 1).\n\n>>>>> Product structures are extremely important since they permit to combine progressively more complex invariants. My understanding of this invariance is that you are either dealing between two extreme cases: a fully connected layer(null set) or a global average pooling(all set). In the linear case, the agregation(the structure S) of the elements correspond to local pooling of groups of nodes(the x_i). It is totally possible to go over this issue with techniques such as lifting scheme ( https://en.wikipedia.org/wiki/Generalized_lifting ) where you could recover the loss of information due to an average of two nodes, via for instance the difference between those two nodes. Do you think this might make sens in your framework? I do not understand how it is possible to recover the loss of information of a projection otherwise, even with a non-trivial minimal invariance.\n\n\n# This means the set-invariat layer (as well-as other structured discussed, such as graph-convolution) is minimally invariant -- e.g., the output of point-cloud classification is indeed invariant to the permutation of points. You are correct in relating the set structure to graph structure. However, note that our proposed set-layer, eq(4), is different from what you get from graph-convolution in using the max operation and its linear (rather than quadratic) complexity.\n\n>>>>> If I understand correctly, you have a better implementation and you apply it on a new dataset, which is a pros of your work. However, the properties you have introduced are not fully exploited and the set data-structures are very specific, and one can wonder why introducing them: indeed, a reader could start its reading at the Section 5 and its understanding of the numerical experiments should be OK. I believe you should apply your theoretical results on others objects than set data-structures. Obviously, one of the difficulty would be to build the structure S. Do you have some suggestions to obtain(learn?) it, or do you know different structures and datasets that could fit your paper?\n\nThank you!\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287581894, "id": "ICLR.cc/2017/conference/-/paper426/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287581894}}}, {"tddate": null, "tmdate": 1480698959479, "tcdate": 1480698959474, "number": 1, "id": "rJPInXkQl", "invitation": "ICLR.cc/2017/conference/-/paper426/public/comment", "forum": "HJF3iD9xe", "replyto": "SJf7U6CGx", "signatures": ["~Siamak_Ravanbakhsh1"], "readers": ["everyone"], "writers": ["~Siamak_Ravanbakhsh1"], "content": {"title": "Re: Set structure questions", "comment": "When the invariance is not \"minimal\" (as defined in section 4), one could lose discriminative information. The only place this lack of minimal invariance comes up in our paper is as an easy way to handle the product structure. Example 4.3 gives an extreme scenario to see the possible issues with using this trick with product structures. This inadvertent loss of information does not happen with correct (but possibly cumbersome) way of handling a product structure using minimally invariant layer (of eq. 1).\n\nThis means the set-invariat layer (as well-as other structured discussed, such as graph-convolution) is minimally invariant -- e.g.,\n the output of point-cloud classification is indeed invariant to the permutation of points. You are correct in relating the set structure to graph structure. However, note that our proposed set-layer, eq(4), is different from what you get from graph-convolution in using the max operation and its linear (rather than quadratic) complexity.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582017, "id": "ICLR.cc/2017/conference/-/paper426/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJF3iD9xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper426/reviewers", "ICLR.cc/2017/conference/paper426/areachairs"], "cdate": 1485287582017}}}, {"tddate": null, "tmdate": 1480672794250, "tcdate": 1480672794245, "number": 1, "id": "SJf7U6CGx", "invitation": "ICLR.cc/2017/conference/-/paper426/pre-review/question", "forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "signatures": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "content": {"title": "Set structure questions", "question": "If I understand correctly, one issue with the invariance to permutation of the graph is that one can loose discriminative information (example 4.3). Might it be possible to recover the loss of information due to the averaging?\n\nI understand why one needs a set structure for the set anomaly detection, but not for the point cloud detection. Indeed, in the anomaly detection case, the objective of the problem is to seprate the set E of faces into E\\{x} and {x} where x is the anomaly, and E\\{x} is invariant by permutations. But, in the point cloud detection, I would have expected the final objective to be invariant by any permutations of the points. I guess I am doing a logical error, could you correct me? Is it to avoid discriminability issues? Why did you chose this graph? In this case, can we interpret your model as a graph convolution, with the edges at x being {(x,x'),x'\\neq x}?\n\nIf the relational dependencies are not given, could they be learned?\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Learning with Sets and Point Clouds", "abstract": "We introduce a simple permutation equivariant layer for deep learning with set structure. This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.", "pdf": "/pdf/62d4b9419407ca08fcbb011eaf4daca8fbb7bda6.pdf", "TL;DR": "Parameter-sharing for permutation-equivariance and invariance with applications to point-cloud classification.", "paperhash": "ravanbakhsh|deep_learning_with_sets_and_point_clouds", "keywords": ["Deep learning", "Structured prediction", "Computer vision", "Supervised Learning", "Semi-Supervised Learning"], "conflicts": ["cs.cmu.edu", "cs.ualberta.ca"], "authors": ["Siamak Ravanbakhsh", "Jeff Schneider", "Barnabas Poczos"], "authorids": ["mravanba@cs.cmu.edu", "bapoczos@cs.cmu.edu", "jeff.schneider@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959287495, "id": "ICLR.cc/2017/conference/-/paper426/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper426/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper426/AnonReviewer1"], "reply": {"forum": "HJF3iD9xe", "replyto": "HJF3iD9xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper426/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959287495}}}], "count": 20}