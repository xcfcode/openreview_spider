{"notes": [{"id": "69EFStdgTD2", "original": "WuMNcc4X1lC", "number": 3018, "cdate": 1601308334567, "ddate": null, "tcdate": 1601308334567, "tmdate": 1614985682530, "tddate": null, "forum": "69EFStdgTD2", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "dJPrAe9w1mi", "original": null, "number": 1, "cdate": 1610040470464, "ddate": null, "tcdate": 1610040470464, "tmdate": 1610474074431, "tddate": null, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper presents a secure aggregation method to ensure byzantine robustness. The reviewers thought that the idea was interesting, but had the following concerns.\n* Relaxing the assumptions used in the theoretical analysis as much as possible\n* Run more extensive experiments\nI encourage the authors to their feedback into account when preparing the revised draft. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040470451, "tmdate": 1610474074415, "id": "ICLR.cc/2021/Conference/Paper3018/-/Decision"}}}, {"id": "W5Ott1m1A3N", "original": null, "number": 3, "cdate": 1605442859227, "ddate": null, "tcdate": 1605442859227, "tmdate": 1605826929970, "tddate": null, "forum": "69EFStdgTD2", "replyto": "VKk4nUv1dVA", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment", "content": {"title": "Reply R1", "comment": "We thank the reviewer for the suggestions, which we are glad to incorporate. We will first give more context of our scheme, and then address issues individually. We will address the reviewer\u2019s concerns as follows:\n\n- While we agree that assuming that the servers do not collude is not ideal, this is a very standard and common setting in privacy-preserving machine learning (Mohassel et al., 2017; Wagh et al., 2018; Corrigan-Gibbs et al., 2017; Wagh et al., 2020 [1]). Practically, non-collusion can be ensured by \u201cgovernment regulations or other social deterrents which are sufficient enforcers\u201d (Wagh et al., 2020 [1]). This model is also seeing real-world implementations e.g. a secret-sharing based multi-party setup similar to ours has been adopted in the sugar beet auction in Denmark (Bogetoft et al., 2009 [2]).\n\n  Alternative crypto primitives (oblivious transfer, garbled circuits) are used for two-party computation while distributed training is typically multi-party computation. Therefore the secret-sharing is more widely used for distributed machine learning. On the other hand, using secret-sharing with one server means asking workers to compute pairwise distances and send them to the server. However, it has serious problems comparing to two-server:\n  1. They have significantly higher communication overhead because worker to worker communication is much slower than the server to server.\n  2. Dealing with fault tolerance and straggler is more complicated and time-consuming (Bonawitz et al., 2017).\n  3. One server scheme can be not compatible with robust aggregation rules (Bagdasaryan et al., 2020).\n\n  Overall, the two-server model is efficient and its non-colluding assumptions are not strong which makes it suitable for robust aggregation.\n\n- We have also considered not adding an experiment section. Since our scheme guarantees to give the same convergence rate/outcome as the non-secure version, we ignore the epoch-to-accuracy curve. Benchmarking secret sharing based algorithms, on the other hand, has already been conducted in (Mohassel et al., 2017) and (Wagh et al., 2020 [1]), and the results suggest secret-sharing is much more efficient than its alternatives. The number of triples required (thus the number of communication) is O(dn^2) for the Krum aggregation rule (Blanchard et al., 2017), and O(dn) for the more efficient RFA aggregation rule (Pillutla et al., 2019).\n\n  In the end, we chose to put a simulation in this paper to demonstrate that the overhead of our primitive is small. This is in contrast to other crypto primitives like zero-knowledge proof which takes 0.03 second to process a vector of 100 integers (Corrigan-Gibbs et al., 2017).\n\n  We agree with the points made by the reviewer about the experiments and we are runing a new experiment on Google cloud with a larger cluster. We don\u2019t have good competing methods yet for the aforementioned reasons, so the goal of the new experiments is to set a baseline for future work. We will update this thread as soon as the results are ready.\n\nAdditional References:\n\n[1]: Wagh, Sameer, et al. \"FALCON: Honest-Majority Maliciously Secure Framework for Private Deep Learning.\" arXiv preprint arXiv:2004.02229 (2020).\n\n[2]: Bogetoft, Peter, et al. \"Secure multiparty computation goes live.\" International Conference on Financial Cryptography and Data Security. Springer, Berlin, Heidelberg, 2009.\n\n================================================================================\n\nWe have updated the experiments in Appendix F."}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "69EFStdgTD2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3018/Authors|ICLR.cc/2021/Conference/Paper3018/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment"}}}, {"id": "gbNn8bQfug", "original": null, "number": 5, "cdate": 1605443238220, "ddate": null, "tcdate": 1605443238220, "tmdate": 1605443238220, "tddate": null, "forum": "69EFStdgTD2", "replyto": "ZhZ-0sEL67", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment", "content": {"title": "Assuming full precision is standard in analyses of ML methods", "comment": "We thank the reviewer for their close reading of our work. The major concern seems to be the realism of the schemes proposed. We admittedly work with a simplified model, where we have access to full precision numbers (as opposed to floating point). However, this is par for the course in optimization and deep learning and we don\u2019t think this diminishes our contribution. We expand upon the individual points below and believe that we address all the concerns raised. We request the reviewer to re-evaluates our work in light of our replies below and also with a broader ML (and not just cryptography/security) community in mind.\n\n> Analysis of security in floating-point of secret sharing and Beaver triplets schemes. \n\nFirstly, our schemes are fully realizable and secure assuming access to full precision computation. We give simple schemes for both Beaver triplets (Section B.1) and secret sharing schemes (Section B.2). Note that the secret sharing scheme in B.2 assumes that all vectors have a known bounded norm. This is also a prevalent assumption in differential privacy and is commonly enforced simply by clipping the gradient (Abadi et al., 2016). In contrast, schemes which rely on homomorphic encryption, or Yao\u2019s garbled circuits are inherently designed for integers/quantized values unlike ours.\n\nSecondly, assuming access to full precision is standard in ML, mathematical optimization, and differential privacy (Abadi et al., 2016). This is because, unlike in traditional cryptographic applications, deep learning methods are very robust to rounding errors (Gupta et al., 2015 [1]) and additional noise (Neelakantan et al., 2016 [2]), with current models routinely trained in 16-bit precision [3]. Thus while rounding errors may occur when using our schemes in floating-point, these do not affect the convergence of our schemes. \n\nFinally, we agree that we do not investigate additional leakage of information due to the use of floating-point, nor do we provide a secure floating-point implementation, but have added your suggested reference (Aliasgari et al. 2013) for this case. We have written a new remark in Section 3.4 and hope that our work will inspire more follow up analysis from security experts.\n\n> Reliance on and cost of cryptographic schemes.\n\nWe wanted to convey that our schemes only use simple arithmetic operations (addition and multiplication) as opposed to e.g. zero-knowledge proofs, key agreement, homomorphic encryption, or garbled circuits. We have changed our claim to state we do not use *heavy* cryptographic primitives.\n\nWhile we do require Beaver\u2019s triplets to be computed, these are independent of the data and can be precomputed during an *offline* stage by the two servers. The number of triplets required is O(dn^2) for Krum and O(dn) for RFA. Our scheme is extremely computationally light from the perspective of the workers, who are typically much more resource constrained, as e.g. in federated learning. Further, optimizing the generation of Beaver\u2019s triples has itself been a well-studied topic with established benchmarks (see for e.g. in Table 2 of (Mohassel & Zhang, 2017), or (Blanchard et al., 2017)). \n\n> Cannot claim Byzantine robustness with semi-honest servers.\n\nByzantine robustness is always with respect to the workers. All prior works in the area use the notion of Byzantine in this same sense (Blanchard et al., 2017; Yin et al., 2018; Pillutla et al., 2019;...). Even when dealing with privacy and security for training and federated learning, the assumption of semi-honest servers is standard (Bonawitz et al., 2017; Mohassel & Zhang, 2017;...), and of significant interest to the entire ICLR community.\n\nIn summary, it has been commonly held that (quoting Bagdasaryan et al., 2020) *\u201cRobust aggregation mechanisms ... are incompatible with secure aggregation.\u201d* We challenge this belief and make significant progress combining the two.\n\nAdditional References:\n\n[1] Gupta, S., Agrawal, A., Gopalakrishnan, K., & Narayanan, P. Deep learning with limited numerical precision. ICML 2015.\n\n[2] Neelakantan, A., Vilnis, L., Le, Q. V., Kaiser, L., Kurach, K., Sutskever, I., & Martens, J.. Adding Gradient Noise Improves Learning for Very Deep Networks. ICLR 2016.\n\n[3] https://www.tensorflow.org/guide/mixed_precision"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "69EFStdgTD2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3018/Authors|ICLR.cc/2021/Conference/Paper3018/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment"}}}, {"id": "IWm74e9k_mE", "original": null, "number": 4, "cdate": 1605443022029, "ddate": null, "tcdate": 1605443022029, "tmdate": 1605443022029, "tddate": null, "forum": "69EFStdgTD2", "replyto": "BbGuwSQvWd7", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment", "content": {"title": "Reply R2", "comment": "We thank Reviewer 2 for reading our work and insightful opinions. We address the concerns as follows:\n\n- As is mentioned by the reviewer, the best way to address the pairwise distance leakage is to use the protocol in Appendix D which achieves information-theoretic guarantees. For the two-server case, quantifying the exact privacy leakage is hard. But it is reasonable to believe that the adversaries can not reconstruct the other worker\u2019s inputs. Note that this information is leaked only to server 2, which does not have access to any other information. Thus even if distance=0, the server can figure out that two workers have the same update, but cannot figure out what the actual update was. The workers do not gain any information whatsoever.\n\n- It is very interesting to combine security with dimension-independent robust aggregation rules. However, this is quite challenging because of the difficulty of the secure computation of eigenvalue/eigenvectors. A possible direction could be to implement a secure version of the power method, but we leave this for future work. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "69EFStdgTD2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3018/Authors|ICLR.cc/2021/Conference/Paper3018/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment"}}}, {"id": "v_naYQBTIrl", "original": null, "number": 2, "cdate": 1605442531029, "ddate": null, "tcdate": 1605442531029, "tmdate": 1605442531029, "tddate": null, "forum": "69EFStdgTD2", "replyto": "cpxiMevkolO", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment", "content": {"title": "Reply R3", "comment": "We thank the reviewer for reading our work and the suggestions. We are glad to incorporate the suggestions of the reviewer. We will address the issues as follows:\n\n- Yes. We mean the shares are  $(x_i+\\xi_i)/2$ and $(x_i-\\xi_i)/2$. We will correct that.\n- Thanks for pointing out the typo.\n- By saying \"S2 secret shares with S1 the values of {<p_i>}\", we mean S2 splits each p_i into two parts $(p_i + \\xi_i)/2$ and $(p_i - \\xi_i)/2$ where the $\\xi$ is different and independent from the worker randomness. Then S2 sends a share, e.g.  $(p_i + \\xi_i)/2$, to S1 such that S1 does not know $p_i$ (Step 2c of Algorithm 2). Finally, both S1 and S2 are holding shares of $\\{p_i\\}$ and $\\{x_i\\}$, so that they can securely compute weighted average $\\sum_i p_i x_i$  through multiplication (using Beaver\u2019s triple) (Step 3a of Algorithm 2). We polish the description of algorithm to make it more clear.\n- Thanks for the proofreading.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "69EFStdgTD2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3018/Authors|ICLR.cc/2021/Conference/Paper3018/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Comment"}}}, {"id": "ZhZ-0sEL67", "original": null, "number": 1, "cdate": 1603861996822, "ddate": null, "tcdate": 1603861996822, "tmdate": 1605024085058, "tddate": null, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review", "content": {"title": "Failed assumptions regarding secure computation", "review": "Summary:\nThe paper presents a system for collaborative training where two central servers compute the model update using two-party computation. There are two variants, one where the update are not checked, and one where the server use algorithm (Aggr) to weight the updates such that outliers are excluded.\n\nPros:\nThe basic ideas are presented succinctly, and the overall setup solves a relevant problem.\n\nCons:\n- The main issue I have is that the authors claim in Section 4.3 that they \"can\" use full-precision (real) values in the computation but the underlying techniques (secret sharing and Beaver triples) have only been proposed for integer/quantized values. In particular, if the actual value is small, adding a large random value will override it due to rounding in floating-point representation. I cannot find any treatment of this issue or any reference to works to have tackled floating-point secure computation such as Aliasgari et al., NDSS '13.\n- Similarly, the claim that the paper does not rely on cryptographic primitives seems exaggerated given the use of secret sharing and Beaver triples.\n- The cost of generating Beaver triples is ignored. The paper does not estimate how many are needed.\n- Claiming Byzantine robustness seems too strong when the two central servers have to be semi-honest.\n\nConclusion:\nI recommend rejection because of the irrealistic approach regarding real-valued computation. The authors should either present credible secure floating-point computation or change their claim to quantized computation.\n\nMinor issues:\n3.1: x_i +- \\xi_i is not an additive secret sharing of x_i but 2*x_i.\n3.1: sum of (the) other share\n3.1: \"sum of other share\" should be \\sum *p_i* x_i^(2)?\n3.1: It is not surprising that S2 does not learn anything in secure computation.\n3.3: In particular, (unfinished sentence)\n3.3: don't face\n4.2: vetor (twice)\n6: median and trimmed-mean -based (odd positioning of dash)\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083995, "tmdate": 1606915792159, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3018/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review"}}}, {"id": "BbGuwSQvWd7", "original": null, "number": 2, "cdate": 1603904862190, "ddate": null, "tcdate": 1603904862190, "tmdate": 1605024084992, "tddate": null, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review", "content": {"title": "A good paper that tackles both privacy and adversarial machines", "review": "**Paper summary**\n\n1. The paper introduces a two server protocol to handle privacy concerns and Byzantine threats in a Federated Learning system simultaneously.\n2. In the protocol, each client secretly shares their model update with the two servers by splitting its model update such that neither server can know what the model update is without colluding with the other server. The servers are able to compute pairwise distances of all updates securely. These distances are used by byzantine robust aggregators to find a robust model update.\n\n\n**Strengths**\n1. The paper handles two very relevant and important issues with Federated Learning simultaneously - privacy and Byzantine resilience (which includes data poisoning attacks). \n2. The proposed algorithm is shown to have theoretical guarantees.\n3. A wide array of byzantine robust aggregation rules can be incorporated easily into the framework.\n5. There isn't much communication overhead between the workers and the server.\n6. The two server protocol does not seem to be too difficult to implement in practice. The algorithm requires that the two servers should not collude. This requirement does not seem too difficult to be enforced onto big companies that will use FL.\n7. In the absence of Byzantine machines, the non-robust protocol seems to be compatible with differential privacy.\n\n**Concerns**\n1. Can it be quantified (using some information theoretic bound) that only pairwise distances cannot leak much information? In the worst case, it can leak some information. For example if the pairwise distance is 0 for some pair, then each machine exactly knows the other's model update. However, I believe that using some assumption on distribution of model updates, we can still get some information theoretic guarantee. The three server algorithm in Appendix D seems to address this, but I wonder if we can say something for the two server algorithm too.\n2. Can it be extended to dimension-independent robust mean estimation techniques? The paper only considers distance based aggregators (with the exception of  (Alistarh et al., 2018), which I discuss later). These aggregators all seem to suffer from an error that grows with dimensions as $\\sqrt{d}$ (see section 2 in (Wang et al., 2020). A recent line of works has given robust mean estimators that have errors that are dimension independent (Dong et al., 2019; Diakonikolas et al., 2017; Diakonikolas et al., 2016; Lai et al., 2016). However these use second order information like the empirical covariance matrix too. Can the algorithm proposed in this paper be extended to these algorithms too? \n\nAlistarh et al. (2018) also give dimension independent guarantees, but they require the workers to sample a new data point at every iteration, which may not hold for many FL systems.\n\n**Score justification**\n\nThe paper tackles a very relevant problem for Federated Learning. Further, the proposed algorithm has nice theoretical guarantees and it looks like the algorithm can be easily implemented in a variety of large FL systems.\n\n\n**References**\n\nWang, L., Pang, Q., Wang, S. and Song, D., 2020. F2ED-Learning: Good Fences Make Good Neighbors. arXiv preprint arXiv:2010.01175.\n\nDong, Y., Hopkins, S. and Li, J., 2019. Quantum entropy scoring for fast robust mean estimation and improved outlier detection. In Advances in Neural Information Processing Systems (pp. 6067-6077).\n\nDiakonikolas, I., Kamath, G., Kane, D.M., Li, J., Moitra, A. and Stewart, A., 2017. Being robust (in high dimensions) can be practical. arXiv preprint arXiv:1703.00893.\n\nDiakonikolas, I., Kamath, G., Kane, D.M., Li, J., Moitra, A. and Stewart, A., 2016, October. Robust Estimators in High Dimensions without the Computational Intractability. In 2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS) (pp. 655-664).\n\nLai, K.A., Rao, A.B. and Vempala, S., 2016, October. Agnostic estimation of mean and covariance. In 2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS) (pp. 665-674). IEEE.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083995, "tmdate": 1606915792159, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3018/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review"}}}, {"id": "cpxiMevkolO", "original": null, "number": 5, "cdate": 1604001608414, "ddate": null, "tcdate": 1604001608414, "tmdate": 1605024084930, "tddate": null, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review", "content": {"title": "When all assumptions hold a nice method", "review": "\n\nThe paper proposes a method combining privacy and byzantine-robustness for distnace-based aggregation.  This is a relevant and interesting topic.\n\nThe paper assumes that it is not a problem that one of the server learns all pairwise distances.  Still, every known pairwise distance |&x_i-x_j|| more tightly connects the relative position of the points x_i together.  If the dimension of the vectors x_i isn't large, then knowledge of a limited set of x_i vectors may allow this server to deduce all other vectors (or may allow him to determine significant constraints all other vectors x_j must satisfy).\n\nOnce we accept the above assumption, the paper seems mostly sound, sometimes with minor issues in writing or precision (a few examples below).\nThe approach doesn't introduce fundamentally new techniques but combines existing ideas to realize a more powerful solution.  The text is quite well written.\n\n\nDETAILS\n\n* \"WorkerSecretSharing (Figure 1a): ... This can be done e.g. by sampling a large noise \\xi_i and then using x_i \\pm \\xi_i as the shares.\" -> as x_i must be the sum of the shares, I guess you mean the shares are (x_i+\\xi_i)/2 and (x_i-\\xi_i)/2\n* Section 3.2: RobustWeightSelection (Figure 1b): seleced subset -> selected subset\n* Section 3.2: RobustWeightSelection (Figure 1b): \"S2 secret shares with S1 the values of {<p_i>}\" -> please make clear what exactly is \"secret-shares\", it is not the secret sharing used by workers to split x=x_1+x_2.   (I guess you describe here step 3b in algo 2)\n* \"Compatibility with local differential privacy. One byproduct of our protocol can be used to convert differentially private mechanisms, such as (Abadi et al., 2016) which only of the aggregate model which guarantees privacy,\" -> the last \"which only ...\" subphrase needs a verb\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083995, "tmdate": 1606915792159, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3018/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review"}}}, {"id": "VKk4nUv1dVA", "original": null, "number": 4, "cdate": 1603993344553, "ddate": null, "tcdate": 1603993344553, "tmdate": 1605024084868, "tddate": null, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "invitation": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review", "content": {"title": "Novel proposal of robust and secure federated learning", "review": "This work proposes a method to robustly (<.5 adversarial workers) aggregate model updates using two non-colluding servers. The proposed method scales well with the number of workers and is compatible with local DP and different robust aggregation protocols. Especially the scalability is a big improvement compared to previous methods. The authors discuss related work that relies on public key infrastructure and requires pairwise secrets between clients. One big advantage of the proposed protocol is that there is no communication between the workers.\n\nPositives\n- The paper is very well written and easy to follow. \n- The contributions are significant in terms of scalability, compared to other protocols discussed in the literature review. \n- The theoretical justifications seem sound and are relatively easy to follow, although I didn't verify the proofs in detail.\n\nNegatives\n- The assumptions are still strong (non-colluding servers), but I am not very familiar with the literature to fully assess the implications. It would be great to put the strong assumption of non-colluding servers more into context. How does it compare to other protocols? (somewhat discussed in the lit section) \n- The experimental section is lacking a bit. It's not entirely clear what additional insights the provided analysis gives, especially also given the unrealistic setup of only five workers. It's not clear what the actual experiments are, referred to with S1 Avg, S2 Avg, S2 Krum (S1/S2 also refer to the servers in the rest of the paper). Is S2 Avg the proposed protocol, just w/o the robust computation? A more detailed discussion why the robust version increases the server communication significantly (even though the authors claim it doesn't. AFAICT it almost doubles the total cost) would be welcome. Is it because of the Beaver's triple communication to share the pairwise distances? (TBH, I am not sure this paper really needed an experimental section, but the current one has serious gaps).\n\nWhile the paper proposes a novel idea with significant improvements, the paper is lacking wrt putting it into context of the existing field and a more detailed interpretation of the experiments would be welcome. For these reasons the recommendation is to reject the paper in it's current state.", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper3018/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3018/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Secure Byzantine-Robust Machine Learning", "authorids": ["~Lie_He1", "~Sai_Praneeth_Karimireddy1", "~Martin_Jaggi1"], "authors": ["Lie He", "Sai Praneeth Karimireddy", "Martin Jaggi"], "keywords": ["Byzantine robustness", "distributed learning", "secure aggregation"], "abstract": "Increasingly machine learning systems are being deployed to edge servers and devices (e.g. mobile phones) and trained in a collaborative manner. Such distributed/federated/decentralized training raises a number of concerns about the robustness, privacy, and security of the procedure. While extensive work has been done in tackling with robustness, privacy, or security individually, their combination has rarely been studied. In this paper, we propose a secure multi-server protocol that offers both input privacy and Byzantine-robustness. In addition, this protocol is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "one-sentence_summary": "We propose a multi-server protocol that offers both input privacy and Byzantine-robustness and demonstrate it is communication-efficient, fault-tolerant, and enjoys local differential privacy.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "he|secure_byzantinerobust_machine_learning", "supplementary_material": "/attachment/bdfc7c6927b9c338bd2e80795457c56a7c9a937e.zip", "pdf": "/pdf/91d61fc7d1563e1fe0e5b64567bb8ab8bce53193.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YXlIOCMIxP", "_bibtex": "@misc{\nhe2021secure,\ntitle={Secure Byzantine-Robust Machine Learning},\nauthor={Lie He and Sai Praneeth Karimireddy and Martin Jaggi},\nyear={2021},\nurl={https://openreview.net/forum?id=69EFStdgTD2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "69EFStdgTD2", "replyto": "69EFStdgTD2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3018/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083995, "tmdate": 1606915792159, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3018/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3018/-/Official_Review"}}}], "count": 10}