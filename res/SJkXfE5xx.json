{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1490792532675, "tcdate": 1478275607165, "number": 211, "id": "SJkXfE5xx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "SJkXfE5xx", "signatures": ["~David_Lopez-Paz2"], "readers": ["everyone"], "content": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 21, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396435102, "tcdate": 1486396435102, "number": 1, "id": "BkizhGU_e", "invitation": "ICLR.cc/2017/conference/-/paper211/acceptance", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The reviewers agree that the paper is a valuable contribution to the literature.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396435592, "id": "ICLR.cc/2017/conference/-/paper211/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396435592}}}, {"tddate": null, "tmdate": 1485266197198, "tcdate": 1485266197198, "number": 12, "id": "Skafa0Vvg", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "By9rr3Ewe", "signatures": ["~David_Lopez-Paz2"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz2"], "content": {"title": "Thank you", "comment": "Dear AnonReviewer3,\n\nWe have revised the manuscript to correct our mistake. We now state the approximate alternative distribution in terms of the asymptotic normality of the Binomial approximation to the Poisson Binomial distribution.\n\nThank you very much for your time.\n\nSincerely,\nThe authors."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1485256001714, "tcdate": 1485256001714, "number": 2, "id": "By9rr3Ewe", "invitation": "ICLR.cc/2017/conference/-/paper211/official/comment", "forum": "SJkXfE5xx", "replyto": "Hki1b3Vwg", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "content": {"title": "Why binomial under the alternative?", "comment": "In section 3.1, I am not sure why you still consider Binomial(nte, p=p_risk) under H1. Under H1, I understand that it is clearly not Binomial (please see the review ICLR 2017 conference paper211 AnonReviewer3, 14 Dec 2016). Thus, there is no need to consider a Binomial, and put \"if that is not the case\" in remark 1. Bernoulli terms in the sum are just not i.i.d. under H1. Perhaps I miss something trivial. Could you please clarify? If you mean to say that the statistic is approximately Binomial, that is fine. But please make it clear.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683488, "id": "ICLR.cc/2017/conference/-/paper211/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683488}}}, {"tddate": null, "tmdate": 1485254883190, "tcdate": 1485254883190, "number": 11, "id": "Hki1b3Vwg", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["~David_Lopez-Paz2"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz2"], "content": {"title": "Updated revision", "comment": "Dear all,\n\nThank you very much for your insightful feedback.\n\nWe have tried our best to incorporate all your suggestions into a revised version of our manuscript.\n\nPlease let us know how we could improve our submission further.\n\nSincerely,\nThe authors."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1482240463602, "tcdate": 1482240463602, "number": 1, "id": "SJdCb3I4l", "invitation": "ICLR.cc/2017/conference/-/paper211/official/comment", "forum": "SJkXfE5xx", "replyto": "B1SI7Ln7x", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "content": {"title": "Hyper-parameters ", "comment": "How should we interpret the fact that any choice of hyper-parameters gives the same performance? (in terms of type I and type II errors?) "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683488, "id": "ICLR.cc/2017/conference/-/paper211/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683488}}}, {"tddate": null, "tmdate": 1482240118006, "tcdate": 1482240118006, "number": 3, "id": "BJROx3I4e", "invitation": "ICLR.cc/2017/conference/-/paper211/official/review", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "content": {"title": "a very interesting framework; could improve clarity; significance to ICLR?", "rating": "7: Good paper, accept", "review": "I would like first to apologize for the delay.\n\nSummary: A framework for two-samples statistical test using binary\nclassification is proposed. It allows multi-dimensional sample testing and\nan interpretability that other tests lack. A theoritical analysis is\nprovided and various empirical tests reported.\n\nA very interesting approach. I have however two main concerns.\n\nThe clarity of the presentation is obscured by too much content. It would\nbe more interesting if the presentation could be somewhat\nself-contained. You could consider making 2 papers out of this paper.\n\nSeriously, you cram a lot of experiments in this paper. But the setting\nof the experiments is not really explained. We are supposed to have read\nJitkrittum et al., 2016, Radford et al., 2016, Yu et al., 2015, etc. All \nthis is okay but reduces your public to a very few.\n\nFor example, if I am not mistaken, you never explained what SCF is, despite\nthe fact that its performances are reported. \n\nAs a second point, given also that the number of submissions to this conference are exploding,\nI would like to challenge you with the following question:\n\nWhy is this work significant to the representation learning community?\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512662938, "id": "ICLR.cc/2017/conference/-/paper211/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512662938}}}, {"tddate": null, "tmdate": 1482150715403, "tcdate": 1482150715403, "number": 2, "id": "H1XSQ8BVe", "invitation": "ICLR.cc/2017/conference/-/paper211/official/review", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer1"], "content": {"title": "A generally useful and interesting approach to 2-sample tests", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The submission considers the setting of 2-sample testing from the perspective of evaluating a classifier.  For a classifier between two samples from the same distribution, the distribution of the classification accuracy follows a simple form under the null hypothesis.  As such, a straightforward threshold can be derived for any classifier.  Finding a more powerful test then amounts to training a better classifier.  One may then focus efforts, e.g. on deep neural networks, for which statistics such as the MMD may be very difficult to characterize.\n\n+ The approach is sound and very general\n+ The paper is timely in that deep learning has had huge impacts in classification and other prediction settings, but has not had as big an impact on statistical hypothesis testing as kernel methods have\n\n- The discussion of the relationship to kernel-MMD has not always been as realistic as it could have been.  For example, the kernel-MMD can also be seen as a classifier based approach, so a more fair discussion could be provided.  Also, the form of kernel-MMD used in the comparisons is a bit contradictory to the discussion as well\n * The linear kernel-MMD is used which is less powerful than the quadradic kernel-MMD (the authors have justified this from the perspective of computation time)\n * The kernel-MMD is argued against due to its unwieldy distribution under the null, but the linear time kernel-MMD (see also Zaremba et al., NIPS 2013) has a Gaussian distribution under the null.\n\nArthur Gretton's comment from Dec 14 during the discussion period was very insightful and helpful.  If these insights and additional experiments comparing the kernel-MMD to the classifier threshold on the blobs dataset could be included, that would be very helpful for understanding the paper.  The open review format gives an excellent opportunity to assign proper credit for these experiments and insights by citing the comment.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512662938, "id": "ICLR.cc/2017/conference/-/paper211/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512662938}}}, {"tddate": null, "tmdate": 1481997344203, "tcdate": 1481997344203, "number": 10, "id": "SJu72g7Vl", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "BkGGI2RXe", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Reply", "comment": "Thank you for your comment.\n\nWe will use the references from your comment to discuss the relationship between two-sample testing and density-ratio estimation. Since density-ratio estimation is a more general problem than two-sample testing, it is correct that the algorithms [1,2] could be used for two-sample testing. Also, we believe that [3] is a very enlightening survey.\n\nSincerely,\nDavid and Maxime."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481997315300, "tcdate": 1481997315300, "number": 9, "id": "ryib2lQVl", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "BJRVukJEx", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Reply", "comment": "Dear AnonReviewer3,\n\nThank you very much for your detailed comments on Theorem 1. We will make its statement and proof precise in the next revision of the manuscript, as to include all our assumptions and approximations explicitly.\n\nSection 3.1 assumes \"identically and independently distributed errors\" to derive a Binomial asymptotic distribution under the alternative hypothesis. If this assumption is violated, then the alternative asymptotic distribution will follow a Poisson Binomial distribution, as correctly discussed in your review and in Remark 1 from our submission.\n\nWe will make these points clearer. Overall we will discuss that, in both theory and practice, we require and use the Normal approximations to the null and alternative asymptotic distributions.\n\nThe experiments regarding independence testing were added for completeness, but we will mention that these are just illustrative.\n\nFinally, we will add a discussion comparing the power of direct two-sample tests (which use fixed data representations, such as MMD) and classifier two-sample tests (which learn the data representation from data). For more details, please see our response to the comment by Arthur Gretton in this same page.\n\nSincerely,\nDavid and Maxime."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481997223144, "tcdate": 1481997223144, "number": 8, "id": "rJyhilmNl", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "ry-le414x", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "reply", "comment": "Dear Arthur and Wittawat,\n\nThank you for your interesting comment.\n\nWe will add the NIPS 2009 citation, and mention the interpretation of MMD as a binary classifier. Also, we will point out the trade-off involved in choosing between a simple test statistic that allows for variance control (such as MMD) versus a complex classifier that does not allow for variance control but may learn more intricate patterns from data flexibly (such as C2ST).\n\nAs a side note, we discuss in Remark 3 a possible synergy between the two alternatives: train C2ST using the ratio between the expected value and the variance of a continuously-valued loss (such as the binary cross entropy) to control the norm of the classifier, and then perform two-sample testing using the classification accuracy (which follows simple null and alternative asymptotic distributions). However, such procedure needs more investigation.\n\nBest,\nDavid and Maxime."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481748457177, "tcdate": 1481748457167, "number": 7, "id": "ry-le414x", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["~Arthur_Gretton1"], "readers": ["everyone"], "writers": ["~Arthur_Gretton1"], "content": {"title": "Discussion of variance for \"testing as classification\"", "comment": "We are writing both to provide a perspective on the proposed \u201cclassification approach\u201d to testing, and to expand on the reviews of AnonReviewer3 and AnonReviewer1, which suggested considering the relation between the MMD and classification. We discuss this link with reference to some earlier work, and then look into the broader implications for testing using classification error.\n\n\nFirst, the MMD can indeed be thought of as a classifier. In Section 2 of the paper:\n\n\nSriperumbudur, B., Fukumizu, K., Gretton, A., Lanckriet, G., and Schoelkopf, B., Kernel choice and classifiability for RKHS embeddings of probability distributions, NIPS 2009.\n\n\nwe show that the MMD is the negative of the optimal risk corresponding to a linear loss function, associated with the kernel classifier. The \u201cwitness function\u201d of the MMD can then be thought of as the decision function for that classifier, returning labels +1 for positive values (class P), and -1 for negative values (class Q). See figure 1 in Gretton et al (2012a) for an illustration of the witness function.\n\n\nThis is a particularly useful result, since it allows the direct comparison between two alternative tests:\n\n\n1) the original MMD test, based on the asymptotic distribution of the norm of the witness function under the null distribution (obtained in practice by permutation)\n\n\n2)  the proposed test strategy, based on the expected chance level performance of this classifier on a held-out test set, where the test threshold is set to the appropriate quantile of the binomial distribution. \n\n\nWe look at the 2-D blobs dataset from the paper of Chwialkowski et al. (NIPS 2015), for 1000 samples, and the same kernel bandwidth for each approach. The results are:\n\n\nOriginal MMD test: 85% true positives\nClassification-based approach: 63% true positives.\n\n\nThis can easily be understood, for two reasons: first, binomial variables have relatively high variance, hence the resulting test may be conservative. A more direct way to detect chance level would be to measure that the decision boundary is as \u201cflat\u201d as one would expect if there were no differences in the distributions generating the samples, as done for the original MMD test. Second, a classification test uses half its samples to create a decision function, and the other half for testing, whereas the MMD test uses the entire sample for testing.\n\n\nAll this being said, the approach proposed by the paper remains a very interesting one, and well worth publishing. When a classifier is highly complex and/or expensive to train, it may not be possible to cheaply obtain a suitable test threshold based on the decision function.  The proposed binomial test threshold might then be the only way to construct a test. In this case, the gain in test sensitivity by using a powerful classifier could be more important the loss in power due to the two issues raised in the paragraph above.\n\n\nArthur Gretton, Wittawat Jitkrittum"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481730351820, "tcdate": 1481730102455, "number": 1, "id": "BJRVukJEx", "invitation": "ICLR.cc/2017/conference/-/paper211/official/review", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "content": {"title": "a review", "rating": "7: Good paper, accept", "review": "\n\n## Paper summary\n\nThe paper reconsiders the idea of using a binary classifier to do two-sample testing. The idea is to split the sample into two disjoint training and test sets, train a classifier on the training set, and use the accuracy on the test set as the test statistic. If the accuracy is above chance level, one concludes that the two samples are from different distributions i.e., reject H0.\n\nA theoretical result on an asymptotic approximate test power is provided. One implication is that the test is consistent, assuming that the classifier is better than coin tossing. Experiments on toy problems, evaluation of GANs, and causal discovery verify the effectiveness of the test. In addition, when the classifier is a neural net, examining the first linear filter layer allows one to see features which are most activated. The result is an interpretable visual indicator of how the two samples differ.\n\n## Review summary \n\nThe paper is well written and easy to follow. The idea of using a binary classifier for a two-sample testing is not new, as made clear in the paper. The main contributions are the analysis of the asymptotic test power, the use of modern deep nets as the classifier in this context, and the empirical studies on various tasks. The empirical results are satisfactorily convincing.  Although not much discussion is made on why the method works well in practice, overall contributions have a potential to start a new direction of research on model criticisms of generative models, as well as visualization of where a model fails. I vote for an acceptance.\n\n## Major comments / questions \n\nMy main concern is on Theorem 1 (asymptotic test power) and its assumptions.  But, I understand that these can be fixed as discussed below.\n\n* Under H0, the distribution of the test statistic (i.e., sum of 0-1 classification results) follows Binomial(nte, 1/2) as stated.  However, under H1, terms in the sum are independent but *not* identical Bernoulli random variable. This is because each term depends on a data point z_i, which can be from either P or Q. So, in the paragraph in Sec3.1: \"... the random variable n_te \\hat{t} follows a Binomial(nte, p)...\" is not correct. Essentially p depends on z_i. It should follow a Poisson binomial distribution.\n\n* In the same paragraph, for the same reason, the alternative distribution of Binomial(nte, p=p_{risk}) is probably not correct. I guess you mention it to use Moivre-Laplace to get the asymptotic normality. \n\nAnyway, I see no reason why you would need this statement as the Binomial is not required in the proof, but only its asymptotic normality. A variant of the central limit theorem (instead of the Moivre-Laplace theorem) for independent, non-identical variables would still allow you to conclude the asymptotic normality of the Poisson binomial (with some conditions). See for example http://stats.stackexchange.com/questions/5347/how-can-i-efficiently-model-the-sum-of-bernoulli-random-variables\n\n* The statement in Theorem 1 should be more precise. For instance, \"Assume the assumptions on the classifier given in the previous paragraph. Then, for large n, the power of C2ST is approximate \\Phi(..).\" \n\nThe current version is \"The power of C2ST is \\Phi(..).\"\n\n\n* The proof of Theorem 1 should be more precise regarding which quantities are exact, which are approximate. Both the null and alternative normal distributions are approximate for finite nte, for instance.\n\n* It is unclear to me why the paper includes independence tests in the experiments. It does imply that the proposed test can be used to do an independence test. But, isn't this also true for other two-sample tests where x,y can be stacked together? This seems ad-hoc and raises further questions regarding the consistency, what type of dependency can be detected, etc. These points are not discussed.\n\n* Comment: By using classification accuracy as a proxy, one should expect the test power, for a given sample size n, to be lower than a direct statistic like MMD. A vague analogy would be the t-test (based on the values of the data) vs. the sign test (based on only whether x_i < y_j, not the actual values). The classifier test is in some sense reminiscent of the sign test i.e., passing data points through a classifier and binarizing the output. For sufficiently large n, the test can still correctly detect the difference as shown empirically.\n\n## Minor comments / questions\n\n* Section 2, in the paragraph on the four steps of testing, the random variable for the statistic T is undefined.\n\n* In the last paragraph of Sec.2: \"kernel two-sample tests require the prescription of a manually-engineered representation of the data under study, and return values in units that are difficult to interpret.\" This is too vague. Manually-engineered representation? Wouldn't a neural net require even more of the explicitness of the representation?\n\n* In sec.3.2, it is better to also state the assumptions on the classifier in a slightly less technical way. Specifically, under H0, you assume that the classifier is not biased, and under H1 you assume that it can learn well (better than coin tossing).\n\n\n\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512662938, "id": "ICLR.cc/2017/conference/-/paper211/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512662938}}}, {"tddate": null, "tmdate": 1481717258398, "tcdate": 1481717258393, "number": 6, "id": "BkGGI2RXe", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Is this work similar to the previous work?", "comment": "Is this work similar to the following work [1], [2]?\nThe papers [1], [2] propose an algorithm of doing a two sample test using density ratio.\nDensity ratio estimation is essentially same as the class probability estimation [3]. \nThat means that the algorithm of [1], [2] is a two sample test using classifiers.\nI'm sorry if I made a mistake.\nThank you. \n\n[1] Kanamori et.al, 2012\nhttps://arxiv.org/abs/1010.4945\n\n[2] Wornowizki & Fried, 2016\nhttp://link.springer.com/article/10.1007/s00180-015-0633-3\n\n[3] Menon & Ong, 2016\nhttp://www.jmlr.org/proceedings/papers/v48/menon16.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481564956872, "tcdate": 1481564956867, "number": 5, "id": "HkHm7D27x", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "ByCO-wJXl", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Response to \"Theoretical questions on classifier two-sample test\"", "comment": "Regarding 1), testing for statistical independence is an easier problem than two-sample testing. In this task, specialized statistical independence tests (such as HSIC) will have higher power than general two-sample tests. To achieve consistent statistical independence testing using a consistent two-sample test, one would need to consider all possible random permutations of the sample (cf. permutation tests). We will make this clear in the next revision of our submission.\n\nWith respect to 2), the whole phrase reads \"the size of the test set n_te\", which is the number of samples held-out to train the classifier, and later used to compute the test statistic.\n\nTo answer 3), we considered one-dimensional toy examples to compare against classic one-dimensional two-sample tests, such as the Wilcoxon, Kolmogorov-Smirnov, and Kuiper tests. In addition, we considered the Student-vs-Gaussian and sinusoid examples because they allowed us to control the testing difficulty easily."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481563257179, "tcdate": 1481563257172, "number": 4, "id": "Bk-thInmg", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "BJaq_Fkmx", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Response to \"comparison to MMD\"", "comment": "When comparing against MMD, we used the code [https://github.com/wittawatj/interpretable-test]. There, the kernel is the Gaussian kernel, and the kernel hyper-parameters are chosen as to maximize power (Gretton et al., 2012a). We compare against quadratic-time MMD in our smaller-scale experiments (see Tables 1 and 2). Because of computational constraints, we use the linear-time MMD estimate in the larger-scale experiments.\n\nC2ST requires an explicit description of the function class, which is rarely known for RKHSs. Therefore, RKHS-based methods and classifier-based methods are complimentary. Choosing one over another is a problem-specific issue: while RKHS-based methods allow to define the function class implicitly, classifier-based methods allow to learn very general function classes explicitly.\n\nOn the other hand, one can use the inner-product of the features provided by C2ST to build a kernel function, and then use this kernel function on top of MMD. We do not know if this two-stage two-sample test would outperform the state-of-the-art.\n\nWe will add the suggested citations. Thank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1481560909516, "tcdate": 1481560909508, "number": 3, "id": "B1SI7Ln7x", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "rJsL1jbQg", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Response to \"Hyper-parameters and more\"", "comment": "Regarding hyper-parameter selection, we use the \"square-root of number of training examples\" rule-of-thumb (Duda et al., 1973) for KNN. The size of the hidden layer of our neural networks was chosen to be small. The size of the test set was set to one-half, as in (Jitkrittum et al., 2016). We will specify these details in the next revision. Also, we will mention in the text that we did not observe a significant impact in the performance of the two-sample test when varying these parameters.\n\nWe appreciate your second and third questions. These are typos: the symbol \"n\" in Appendix B should be \"n_te\", and there is indeed an \\mathbb{I} missing in the second line of Section 3.1.\n\nThank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1480859474718, "tcdate": 1480859474712, "number": 3, "id": "rJsL1jbQg", "invitation": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer2"], "content": {"title": "Hyper-parameters and more", "question": "- How do you choose the value of the hyper-parameters ? The ones related to the optimal classifier (K for KNN, the size of the hidden layer)? The ones related to the test (n_te)? Maybe you explained in somewhere but I missed the explanation.\n\n- In the appendix B, *n* refers to something different than the size of learning examples in one class.\n\n- In section 3.1, I think there is an *I* missing in the expression in the 2nd line. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959403940, "id": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959403940}}}, {"tddate": null, "tmdate": 1480722581412, "tcdate": 1480722581408, "number": 2, "id": "BJaq_Fkmx", "invitation": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer1"], "content": {"title": "comparison to MMD", "question": "It is stated that a comparison is performed \"against the linear-time estimate of the Maximum Mean Discrepancy (MMD)\"\n- what kernel and perameters were used for this?\n- why the linear MMD?  That is a higher variance, lower-power estimate than the quadratic MMD at a fixed sample size.\n\nThe MMD is itself a kind of discriminant function, which in the 2 sample literature has recently been assumed to be constrained to be in a unit ball of a RKHS.  Classifier 2-sample tests also require the assumption of a specific function space (effect of regularization also a bit complex?), so are there still advantages if the function space is a RKHS, too?  That should be provable, possibly leading to an improved kernel 2-sample test.\n\nCould you optimize the MMD definition with your proposed classifier function spaces (k-nn & neural network)?  Would that have provably worse properties than the proposed test?\n\nMissing relevant citations using MMD for model selection are:\n- A Test of Relative Similarity For Model Selection in Generative Models\n- Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959403940, "id": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959403940}}}, {"tddate": null, "tmdate": 1480712565853, "tcdate": 1480712565847, "number": 1, "id": "ByCO-wJXl", "invitation": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper211/AnonReviewer3"], "content": {"title": "Theoretical questions on classifier two-sample test", "question": "This is still a pre-review phase. At this point, I only skimmed through the paper. \n\n1. You mentioned that \".. two-sample tests can measure statistical dependence...\" on page 2. This is intuitively easy to understand since a two-sample test relies on a distance between distributions P and Q. One can set P to be P_xy and Q to be P_x*P_y to turn a distance into a dependence measure. What I do not understand is that in practice we do not have sample from P_x*P_y. As mentioned in the paper that a permutation to break the xy pairs is needed to simulate a sample from P_x*P_y. But what can we say theoretically about this approach? Say, assume that the two-sample test is consistent, is the independence test done in this way consistent as well?\n\n2. On page 4, \"... maximizing the size of the test ...\", what is \"the size\"? Type-I error?\n\n3. The chosen toy examples chosen do not seem to illustrate well the advantages of the proposed method (Fig. 1). Why are these examples considered? Have you considered other toy problems?\n\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959403940, "id": "ICLR.cc/2017/conference/-/paper211/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper211/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper211/AnonReviewer3", "ICLR.cc/2017/conference/paper211/AnonReviewer1", "ICLR.cc/2017/conference/paper211/AnonReviewer2"], "reply": {"forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper211/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959403940}}}, {"tddate": null, "tmdate": 1479377716298, "tcdate": 1479377716293, "number": 2, "id": "HJn4QWo-g", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "HJUQPrcxg", "signatures": ["~David_Lopez-Paz1"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz1"], "content": {"title": "Thanks!", "comment": "We have added the citation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}, {"tddate": null, "tmdate": 1478282047900, "tcdate": 1478280990207, "number": 1, "id": "HJUQPrcxg", "invitation": "ICLR.cc/2017/conference/-/paper211/public/comment", "forum": "SJkXfE5xx", "replyto": "SJkXfE5xx", "signatures": ["~Luke_Vilnis1"], "readers": ["everyone"], "writers": ["~Luke_Vilnis1"], "content": {"title": "Evaluating generative models with classifiers", "comment": "This is interesting work. Another reference for Section 5 of this paper: the use of binary classifiers to evaluate generative models was also used in Bowman et al. 2016 (https://arxiv.org/abs/1511.06349), in that case for evaluating conditional imputations of sentences whose conditional likelihood is intractable."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Classifier Two-Sample Tests", "abstract": "The goal of two-sample tests is to assess whether two samples, $S_P \\sim P^n$ and $S_Q \\sim Q^m$, are drawn from the same distribution.  Perhaps intriguingly, one relatively unexplored method to build two-sample tests is the use of binary classifiers. In particular, construct a dataset by pairing the $n$ examples in $S_P$ with a positive label, and by pairing the $m$ examples in $S_Q$ with a negative label. If the null hypothesis ``$P = Q$'' is true, then the classification accuracy of a binary classifier on a held-out subset of this dataset should remain near chance-level.  As we will show, such \\emph{Classifier Two-Sample Tests} (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have a simple null distribution, and their predictive uncertainty allow to interpret where $P$ and $Q$ differ.\n\nThe goal of this paper is to establish the properties, performance, and uses of C2ST.  First, we analyze their main theoretical properties.  Second, we compare their performance against a variety of state-of-the-art alternatives.  Third, we propose their use to evaluate the sample quality of generative models with intractable likelihoods, such as Generative Adversarial Networks (GANs).  Fourth, we showcase the novel application of GANs together with C2ST for causal discovery.", "pdf": "/pdf/f810ace79b2282d0ac7c553a182c01b0670ce8dc.pdf", "TL;DR": "Modern binary classifiers can be easily turned into powerful two-sample tests, and used to evaluate generative models.", "paperhash": "lopezpaz|revisiting_classifier_twosample_tests", "authorids": ["dlp@fb.com", "qas@fb.com"], "keywords": ["Theory", "Unsupervised Learning"], "conflicts": ["fb.com", "ens.fr", "inria.fr", "microsoft.com"], "authors": ["David Lopez-Paz", "Maxime Oquab"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287683620, "id": "ICLR.cc/2017/conference/-/paper211/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJkXfE5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper211/reviewers", "ICLR.cc/2017/conference/paper211/areachairs"], "cdate": 1485287683620}}}], "count": 22}