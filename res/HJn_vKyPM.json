{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124448579, "tcdate": 1518471028002, "number": 291, "cdate": 1518471028002, "id": "HJn_vKyPM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HJn_vKyPM", "signatures": ["~Jiayu_Li1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "FaceGANs: Stable Generative Adversarial Networks with High-Quality Images", "abstract": "Generative Adversarial Networks (GANs) have shown impressive performance in producing images highly similar to original dataset under unsupervised learning. However, the losses of discriminator and generator are highly fluctuated, which affects the quality of fake images produced by the generator. In this work, we propose Face Generative Adversarial Network(FaceGANs). Compared to the conventional GANs, our new structure can stabilize the loss fluctuation of discriminator and generator. It also improves the capabilities of generator and discriminator. In order to fully investigate FaceGANs, we compare the performance of FaceGANs with Deep Convolution Generative Adversarial Network (DCGANs) on the Celeba dataset. Experimental results show that our FaceGANs structure can fast generate images with better quality than DCGANs in a facial reconstruction. ", "paperhash": "li|facegans_stable_generative_adversarial_networks_with_highquality_images", "keywords": ["FaceGANs", "GANs", "High-Quality Images", "Stablization"], "_bibtex": "@misc{\n  li2018facegans:,\n  title={FaceGANs: Stable Generative Adversarial Networks with High-Quality Images},\n  author={Jiayu Li and Zheng Zhan and Caiwen Ding and Yanzhi Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=HJn_vKyPM}\n}", "authorids": ["jli221@syr.edu", "zzhan03@syr.edu", "cading@syr.edu", "ywang393@syr.edu"], "authors": ["Jiayu Li", "Zheng Zhan", "Caiwen Ding", "Yanzhi Wang"], "TL;DR": "FaceGANs can generate images with better quality fast and stably ", "pdf": "/pdf/e4e128080c54e5e53010cb0c8e0345c0a496a781.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582998730, "tcdate": 1519325912101, "number": 1, "cdate": 1519325912101, "id": "rklk752Pz", "invitation": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "signatures": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer2"], "content": {"title": "No novelty.", "rating": "1: Trivial or wrong", "review": "This method, inexplicably called FaceGANs (despite not being limited to the domain of faces), appears to propose an innovation in the network architecture used for the generator and the discriminator that reduces fluctuations in the losses being optimized. The contribution appears to be a particular network architecture with nothing novel or interesting about it.\n\nThis seems to make a lot of unstated assumptions, such as that the learned model is \"good\" if the values for the losses are similar (which is necessary at equillibrium but not a sufficient condition for it), and that a more stable learning curve is desirable, and that faster convergence necessarily means the model is better.\n\nThe losses appear to be similar (or identical) to the classic GAN losses. Where the original paper presumed the range of D to be (0, 1), the authors here seem to find it necessary to explicitly introduce the sigmoid function. I am assuming that the second term of (2) is an error, and that they mean to say log(1 - sigmoid(....))) and not log(sigmoid(1 - ...)) which doesn't make any sense.\n\nEvaluation involves qualitative inspection of plots and generated samples. The authors claim their samples are \"better quality and closer to real pictures than what DCGAN does\". I find this claim uninteresting and, besides that, impossible to judge.\n\nThe paper is confusingly written and hard to follow. Many statements are unclear, vague, or simply don't follow. For example:\n\n- \"DCGANs have shown the applicability of general image representations.\" Applicability to what? What representations?\n- \"The discriminator of GANs is often unstable\" -- what does this mean? How can a neural network itself be unstable?\n- \"The situation will affect the quality of images from a generator\" -- Stated without citation, explanation or justification\n- \"This innovation allows training to be adjusted between using the discriminators.\" -- This is only in the discussion of related work but it remains unclear what this means.\n- \"With more training, discriminator and generator become more adversarial.\" I don't have any idea what this means.\n- \"The distance of loss from discriminator and generator becomes smaller, which means their capacities are close.\" There is no reason to believe that this follows.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FaceGANs: Stable Generative Adversarial Networks with High-Quality Images", "abstract": "Generative Adversarial Networks (GANs) have shown impressive performance in producing images highly similar to original dataset under unsupervised learning. However, the losses of discriminator and generator are highly fluctuated, which affects the quality of fake images produced by the generator. In this work, we propose Face Generative Adversarial Network(FaceGANs). Compared to the conventional GANs, our new structure can stabilize the loss fluctuation of discriminator and generator. It also improves the capabilities of generator and discriminator. In order to fully investigate FaceGANs, we compare the performance of FaceGANs with Deep Convolution Generative Adversarial Network (DCGANs) on the Celeba dataset. Experimental results show that our FaceGANs structure can fast generate images with better quality than DCGANs in a facial reconstruction. ", "paperhash": "li|facegans_stable_generative_adversarial_networks_with_highquality_images", "keywords": ["FaceGANs", "GANs", "High-Quality Images", "Stablization"], "_bibtex": "@misc{\n  li2018facegans:,\n  title={FaceGANs: Stable Generative Adversarial Networks with High-Quality Images},\n  author={Jiayu Li and Zheng Zhan and Caiwen Ding and Yanzhi Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=HJn_vKyPM}\n}", "authorids": ["jli221@syr.edu", "zzhan03@syr.edu", "cading@syr.edu", "ywang393@syr.edu"], "authors": ["Jiayu Li", "Zheng Zhan", "Caiwen Ding", "Yanzhi Wang"], "TL;DR": "FaceGANs can generate images with better quality fast and stably ", "pdf": "/pdf/e4e128080c54e5e53010cb0c8e0345c0a496a781.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582998491, "id": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper291/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer1"], "reply": {"forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582998491}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582838384, "tcdate": 1520595949104, "number": 2, "cdate": 1520595949104, "id": "B1BgNxltz", "invitation": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "signatures": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer3"], "content": {"title": "assumptions without backing, lack of novelty and justification", "rating": "4: Ok but not good enough - rejection", "review": "The paper starts off with:\n\n> \"However, we find that the loss of discriminator and generator are not stable enough and highly fluctuated in GANs and DCGANs. The situation will affect the quality of images from a generator.\"\n\nThere is no backing for this statement, and afaik this is simply not true. The loss of a GAN (Goodfellow 2014)  is not correlated with sample quality.\n\nThe paper pitches an architectural rule that make sure that \"the generator and discriminator have similar capacity and therefore, the losses of generator and discriminator can be stabilized and close to each other.\"\n\nThe rule is that you find inverted equivalents of generator architectures for discriminator architectures. For example Conv in discriminator is ConvTranspose in generator, with same capacity.\nThis is also a property of the DCGAN architecture that they put together as a baseline, so I am not sure what the novelty is.\n\nFinally, I find the results section weak, even for a workshop paper. They show loss curves and show that loss \"gaps\" are more subdued with FaceGANs, but I fail to see why this is significant or why it's correlated with sample quality.\n\nThe Images Comparison is likely cherry-picked to whatever epoch is suited for FaceGANs, because the original DCGAN paper has faces of better quality than what they report.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FaceGANs: Stable Generative Adversarial Networks with High-Quality Images", "abstract": "Generative Adversarial Networks (GANs) have shown impressive performance in producing images highly similar to original dataset under unsupervised learning. However, the losses of discriminator and generator are highly fluctuated, which affects the quality of fake images produced by the generator. In this work, we propose Face Generative Adversarial Network(FaceGANs). Compared to the conventional GANs, our new structure can stabilize the loss fluctuation of discriminator and generator. It also improves the capabilities of generator and discriminator. In order to fully investigate FaceGANs, we compare the performance of FaceGANs with Deep Convolution Generative Adversarial Network (DCGANs) on the Celeba dataset. Experimental results show that our FaceGANs structure can fast generate images with better quality than DCGANs in a facial reconstruction. ", "paperhash": "li|facegans_stable_generative_adversarial_networks_with_highquality_images", "keywords": ["FaceGANs", "GANs", "High-Quality Images", "Stablization"], "_bibtex": "@misc{\n  li2018facegans:,\n  title={FaceGANs: Stable Generative Adversarial Networks with High-Quality Images},\n  author={Jiayu Li and Zheng Zhan and Caiwen Ding and Yanzhi Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=HJn_vKyPM}\n}", "authorids": ["jli221@syr.edu", "zzhan03@syr.edu", "cading@syr.edu", "ywang393@syr.edu"], "authors": ["Jiayu Li", "Zheng Zhan", "Caiwen Ding", "Yanzhi Wang"], "TL;DR": "FaceGANs can generate images with better quality fast and stably ", "pdf": "/pdf/e4e128080c54e5e53010cb0c8e0345c0a496a781.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582998491, "id": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper291/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer1"], "reply": {"forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582998491}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582721723, "tcdate": 1520682017813, "number": 3, "cdate": 1520682017813, "id": "rk9QVBZFf", "invitation": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "signatures": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer1"], "content": {"title": "Insufficient empirical validation of proposed changes", "rating": "3: Clear rejection", "review": "The paper proposes an architectural modification to a DCGAN. The changes include using LeakyRelu and fully connected layers in the generator. For a loss function, standard Non-Saturating GAN (NS-GAN) is used though the language of section 2.2 does not make it clear that this is the same approach used in the original GAN paper. For a quantitative metric, the paper reports NS-GAN generator and discriminator losses. This is known to not be a meaningful loss metric for convergence as discussed in Section 4.2 of Wasserstein GAN (Arjovsky et al. 1701.07875) and is not an established evaluation metric. The only other experimental result is a snapshot of samples from a DCGAN and the paper's model at 3160 updates. As a reviewer I can maybe visually distinguish the two a little bit, but there is no significant difference and the results are far worse than those reported in the original DCGAN paper ~2.5 years ago (see Figure 10 from Radford et al. 1511.06434). Given the heuristic motivation of the proposed changes, thorough empirical work is needed to demonstrate a valuable contribution has been made. Currently the paper does not convincingly do this. ", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FaceGANs: Stable Generative Adversarial Networks with High-Quality Images", "abstract": "Generative Adversarial Networks (GANs) have shown impressive performance in producing images highly similar to original dataset under unsupervised learning. However, the losses of discriminator and generator are highly fluctuated, which affects the quality of fake images produced by the generator. In this work, we propose Face Generative Adversarial Network(FaceGANs). Compared to the conventional GANs, our new structure can stabilize the loss fluctuation of discriminator and generator. It also improves the capabilities of generator and discriminator. In order to fully investigate FaceGANs, we compare the performance of FaceGANs with Deep Convolution Generative Adversarial Network (DCGANs) on the Celeba dataset. Experimental results show that our FaceGANs structure can fast generate images with better quality than DCGANs in a facial reconstruction. ", "paperhash": "li|facegans_stable_generative_adversarial_networks_with_highquality_images", "keywords": ["FaceGANs", "GANs", "High-Quality Images", "Stablization"], "_bibtex": "@misc{\n  li2018facegans:,\n  title={FaceGANs: Stable Generative Adversarial Networks with High-Quality Images},\n  author={Jiayu Li and Zheng Zhan and Caiwen Ding and Yanzhi Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=HJn_vKyPM}\n}", "authorids": ["jli221@syr.edu", "zzhan03@syr.edu", "cading@syr.edu", "ywang393@syr.edu"], "authors": ["Jiayu Li", "Zheng Zhan", "Caiwen Ding", "Yanzhi Wang"], "TL;DR": "FaceGANs can generate images with better quality fast and stably ", "pdf": "/pdf/e4e128080c54e5e53010cb0c8e0345c0a496a781.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582998491, "id": "ICLR.cc/2018/Workshop/-/Paper291/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper291/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper291/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper291/AnonReviewer1"], "reply": {"forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper291/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582998491}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573608125, "tcdate": 1521573608125, "number": 274, "cdate": 1521573607788, "id": "ryelkJkcz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HJn_vKyPM", "replyto": "HJn_vKyPM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FaceGANs: Stable Generative Adversarial Networks with High-Quality Images", "abstract": "Generative Adversarial Networks (GANs) have shown impressive performance in producing images highly similar to original dataset under unsupervised learning. However, the losses of discriminator and generator are highly fluctuated, which affects the quality of fake images produced by the generator. In this work, we propose Face Generative Adversarial Network(FaceGANs). Compared to the conventional GANs, our new structure can stabilize the loss fluctuation of discriminator and generator. It also improves the capabilities of generator and discriminator. In order to fully investigate FaceGANs, we compare the performance of FaceGANs with Deep Convolution Generative Adversarial Network (DCGANs) on the Celeba dataset. Experimental results show that our FaceGANs structure can fast generate images with better quality than DCGANs in a facial reconstruction. ", "paperhash": "li|facegans_stable_generative_adversarial_networks_with_highquality_images", "keywords": ["FaceGANs", "GANs", "High-Quality Images", "Stablization"], "_bibtex": "@misc{\n  li2018facegans:,\n  title={FaceGANs: Stable Generative Adversarial Networks with High-Quality Images},\n  author={Jiayu Li and Zheng Zhan and Caiwen Ding and Yanzhi Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=HJn_vKyPM}\n}", "authorids": ["jli221@syr.edu", "zzhan03@syr.edu", "cading@syr.edu", "ywang393@syr.edu"], "authors": ["Jiayu Li", "Zheng Zhan", "Caiwen Ding", "Yanzhi Wang"], "TL;DR": "FaceGANs can generate images with better quality fast and stably ", "pdf": "/pdf/e4e128080c54e5e53010cb0c8e0345c0a496a781.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}