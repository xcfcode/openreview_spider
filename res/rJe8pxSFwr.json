{"notes": [{"id": "rJe8pxSFwr", "original": "S1gCzWbtPH", "number": 2574, "cdate": 1569439933909, "ddate": null, "tcdate": 1569439933909, "tmdate": 1577168269502, "tddate": null, "forum": "rJe8pxSFwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["ronan.fablet@imt-atlantique.fr", "lucas.drumetz@imt-atlantique.fr", "francois.rousseau@imt-atlantique.fr"], "title": "End-to-end learning of energy-based representations for irregularly-sampled signals and images", "authors": ["Ronan Fablet", "Lucas Drumetz", "Fran\u00e7ois Rousseau"], "pdf": "/pdf/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "TL;DR": "We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.", "abstract": "For numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular space-time sampling patterns and large missing data rates. These sampling properties is a critical issue to apply state-of-the-art learning-based (e.g., auto-encoders, CNNs,...) to fully benefit from the available large-scale observations and reach breakthroughs in the reconstruction and identification of processes of interest. In this paper, we address the end-to-end learning of representations of signals, images and image sequences from irregularly-sampled data, {\\em i.e.} when the training data involved missing data. From an analogy to Bayesian formulation, we consider energy-based representations. Two energy forms are investigated: one derived from auto-encoders and one relating to Gibbs energies. The learning stage of these energy-based representations (or priors) involve a joint interpolation issue, which resorts to solving an energy minimization problem under observation constraints. Using a neural-network-based implementation of the considered energy forms, we can state an end-to-end learning scheme from irregularly-sampled data. We demonstrate the relevance of the proposed representations for different case-studies: namely, multivariate time series, 2{\\sc } images and image sequences.", "keywords": ["end-to-end-learning", "irregularly-sampled data", "energy representations", "optimal interpolation"], "paperhash": "fablet|endtoend_learning_of_energybased_representations_for_irregularlysampled_signals_and_images", "original_pdf": "/attachment/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "_bibtex": "@misc{\nfablet2020endtoend,\ntitle={End-to-end learning of energy-based representations for irregularly-sampled signals and images},\nauthor={Ronan Fablet and Lucas Drumetz and Fran{\\c{c}}ois Rousseau},\nyear={2020},\nurl={https://openreview.net/forum?id=rJe8pxSFwr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "4lVMROrsN7", "original": null, "number": 1, "cdate": 1576798752445, "ddate": null, "tcdate": 1576798752445, "tmdate": 1576800883164, "tddate": null, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "invitation": "ICLR.cc/2020/Conference/Paper2574/-/Decision", "content": {"decision": "Reject", "comment": "This work looks at ways to fill in incomplete data, through two different energy terms.\nReviewers find the work interesting, however it is very poorly written and nowhere near ready for publication. This comes on top of poorly stated motivation and insufficient comparison to prior work.\nAuthors have chosen not to answer the reviewers' comments.\nWe recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ronan.fablet@imt-atlantique.fr", "lucas.drumetz@imt-atlantique.fr", "francois.rousseau@imt-atlantique.fr"], "title": "End-to-end learning of energy-based representations for irregularly-sampled signals and images", "authors": ["Ronan Fablet", "Lucas Drumetz", "Fran\u00e7ois Rousseau"], "pdf": "/pdf/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "TL;DR": "We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.", "abstract": "For numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular space-time sampling patterns and large missing data rates. These sampling properties is a critical issue to apply state-of-the-art learning-based (e.g., auto-encoders, CNNs,...) to fully benefit from the available large-scale observations and reach breakthroughs in the reconstruction and identification of processes of interest. In this paper, we address the end-to-end learning of representations of signals, images and image sequences from irregularly-sampled data, {\\em i.e.} when the training data involved missing data. From an analogy to Bayesian formulation, we consider energy-based representations. Two energy forms are investigated: one derived from auto-encoders and one relating to Gibbs energies. The learning stage of these energy-based representations (or priors) involve a joint interpolation issue, which resorts to solving an energy minimization problem under observation constraints. Using a neural-network-based implementation of the considered energy forms, we can state an end-to-end learning scheme from irregularly-sampled data. We demonstrate the relevance of the proposed representations for different case-studies: namely, multivariate time series, 2{\\sc } images and image sequences.", "keywords": ["end-to-end-learning", "irregularly-sampled data", "energy representations", "optimal interpolation"], "paperhash": "fablet|endtoend_learning_of_energybased_representations_for_irregularlysampled_signals_and_images", "original_pdf": "/attachment/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "_bibtex": "@misc{\nfablet2020endtoend,\ntitle={End-to-end learning of energy-based representations for irregularly-sampled signals and images},\nauthor={Ronan Fablet and Lucas Drumetz and Fran{\\c{c}}ois Rousseau},\nyear={2020},\nurl={https://openreview.net/forum?id=rJe8pxSFwr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795724487, "tmdate": 1576800276145, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2574/-/Decision"}}}, {"id": "rJx-I2HJ9S", "original": null, "number": 1, "cdate": 1571933257501, "ddate": null, "tcdate": 1571933257501, "tmdate": 1572972320463, "tddate": null, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "invitation": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes an end-to-end learning framework for interpolation problems, motivated by problems such as irregularly-sampled images or time-series.\n\nIt was not clear after reading the paper where the key novelty of the proposal lies. The energy formulations for U\u03b8, namely an autoencoder and Gibbs model, are not to my knowledge new in this context. I gather the novelty must then be in Section 3.2, which uses a neural-network based interpolation scheme. This builds on an existing update scheme (Equation 8), but replaces the full operator \u03c8 with an iterative update. The key idea is then to replace the full gradient for the energy function with a learned function, based on a CNN. While this is not my area of expertise, I am not sure as to technical significance or novelty of such a proposal.\n\nThe paper emphasises their view of an interpolation operator I, which is a little confusing in an autoencoder context. Typically, we pick \\hat{X} to be the solution attaining minimal squared error compared to the reference Y. It was not clear why one needs a further invocation of a minimisation between Y^i and I(U\u03b8, Y^i, \u03a9^i).\n\nThe writing could be improved, as there are a number of grammatical issues, as well as missing section or equation #'s. In terms of presentation, the Introduction delves far too soon into a detailed discussion of related work in the area. I would suggest instead to provide a crisp high-level overview of the limitations of existing work, and how they are overcome in the present paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ronan.fablet@imt-atlantique.fr", "lucas.drumetz@imt-atlantique.fr", "francois.rousseau@imt-atlantique.fr"], "title": "End-to-end learning of energy-based representations for irregularly-sampled signals and images", "authors": ["Ronan Fablet", "Lucas Drumetz", "Fran\u00e7ois Rousseau"], "pdf": "/pdf/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "TL;DR": "We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.", "abstract": "For numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular space-time sampling patterns and large missing data rates. These sampling properties is a critical issue to apply state-of-the-art learning-based (e.g., auto-encoders, CNNs,...) to fully benefit from the available large-scale observations and reach breakthroughs in the reconstruction and identification of processes of interest. In this paper, we address the end-to-end learning of representations of signals, images and image sequences from irregularly-sampled data, {\\em i.e.} when the training data involved missing data. From an analogy to Bayesian formulation, we consider energy-based representations. Two energy forms are investigated: one derived from auto-encoders and one relating to Gibbs energies. The learning stage of these energy-based representations (or priors) involve a joint interpolation issue, which resorts to solving an energy minimization problem under observation constraints. Using a neural-network-based implementation of the considered energy forms, we can state an end-to-end learning scheme from irregularly-sampled data. We demonstrate the relevance of the proposed representations for different case-studies: namely, multivariate time series, 2{\\sc } images and image sequences.", "keywords": ["end-to-end-learning", "irregularly-sampled data", "energy representations", "optimal interpolation"], "paperhash": "fablet|endtoend_learning_of_energybased_representations_for_irregularlysampled_signals_and_images", "original_pdf": "/attachment/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "_bibtex": "@misc{\nfablet2020endtoend,\ntitle={End-to-end learning of energy-based representations for irregularly-sampled signals and images},\nauthor={Ronan Fablet and Lucas Drumetz and Fran{\\c{c}}ois Rousseau},\nyear={2020},\nurl={https://openreview.net/forum?id=rJe8pxSFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872599124, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2574/Reviewers"], "noninvitees": [], "tcdate": 1570237720900, "tmdate": 1575872599137, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review"}}}, {"id": "Byetnaz8cr", "original": null, "number": 2, "cdate": 1572380080643, "ddate": null, "tcdate": 1572380080643, "tmdate": 1572972320415, "tddate": null, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "invitation": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes a framework to learn representations of signals when they the signals are irregularly sampled.  They propose to do this by using some modified iteration steps from DINEOF algorithm. In addition to this, they propose a new energy function which is inspired by the idea of Gibbs distribution. The parametrize the energy function by some convolutional filters with a constraint. As claimed by the paper in the introduction, they only use the under sampled signals to learn as opposed to using the fully sampled ground truth signals in the previous deep learning basic approaches.\n\nI choose to reject this paper. 1) The paper doesn't justify what these representations are or where these representations will be used 2) There is no theoretical or extensive empirical motivation that the representation that is coming out of this network is actually useful for downstream tasks of interest. 3) Ill-defined evaluation metrics 4) Missing comparisons with basic models - why not compare with in-painting models for images and time series in experiments? 5) The paper is hard to read, not well organized and missing a lot of details. \n\nMain Argument:\nIt is not clear to me the motivation for learning these representations or how the usefulness of this representation will be evaluated. The only place where I see a use for representation other than reconstruction of the signal is in Table 1. They use a 3 layered MLP on top of the representation from auto encoder. Why is this interesting? If you're trying to claim that the representation is powerful enough, shouldn't you be able to do the classification with just a linear classifier? Can you justify the usefulness of representation for some downstream tasks in your other experiments? \n\nIn any case, I don't understand why the authors don't compare with a simple auto-encoder. The authors assumes that they know where the signal is sampled and where is is not. Why not train an auto-encoder with MSE loss, but calculating MSE over only those pixels which the authors know are sampled. Comparison with such a model will be helpful in understanding if the framework is adding anything of value.\n\nAuthors useful I-Score, R-Score, AE-Score and C-Score to compare across models. These metrics are not defined in the main text (or any reference) but there is a loose (english) definition in the caption of Table 1. For example, R-Score, is the \"reconstruction performance of known image areas\". Why are these numbers in percentages? Shouldn't you be using MSE, PSNR or SSIM? Why are some of scores negative?\n\nIf you are comparing how well you're interpolating for natural images or time series, you should compare with standard interpolation techniques in image processing and time series analysis. \n\nThe paper have a lot of missing details, including simple things like not linking to a Figure or Section the authors are referring to. Some examples are:\n1. Authors motivate using Gibbs energy by saying that in auto encoders you have to project to a lower dimensional representation and gibbs energy based solution has no such dimensionality reduction constraint. There are no such constraint in AE as well - you can vey well have your hidden representation to be over complete - so this is not a good motivation for Gibbs energy\n2. Main section of 4.1 says that they use MNIST but the caption of Table 1 says they use Fashion MNIST\n3. The naming convention of the model is hard to follow and the authors notation itself is inconsistent. \n\nSome other problems:\n1. In Abstract, they say 2. images. Why 2?\n2. Introduction, the citation for Gaussian priors is empty\n3. Last word before beginning of section to, broken link\n4. In the second para of 3.2 did you mean to say solve for (2) instead of (3)?\n5.  What is \"XXX\" matrix in second para of 3.2?\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ronan.fablet@imt-atlantique.fr", "lucas.drumetz@imt-atlantique.fr", "francois.rousseau@imt-atlantique.fr"], "title": "End-to-end learning of energy-based representations for irregularly-sampled signals and images", "authors": ["Ronan Fablet", "Lucas Drumetz", "Fran\u00e7ois Rousseau"], "pdf": "/pdf/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "TL;DR": "We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.", "abstract": "For numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular space-time sampling patterns and large missing data rates. These sampling properties is a critical issue to apply state-of-the-art learning-based (e.g., auto-encoders, CNNs,...) to fully benefit from the available large-scale observations and reach breakthroughs in the reconstruction and identification of processes of interest. In this paper, we address the end-to-end learning of representations of signals, images and image sequences from irregularly-sampled data, {\\em i.e.} when the training data involved missing data. From an analogy to Bayesian formulation, we consider energy-based representations. Two energy forms are investigated: one derived from auto-encoders and one relating to Gibbs energies. The learning stage of these energy-based representations (or priors) involve a joint interpolation issue, which resorts to solving an energy minimization problem under observation constraints. Using a neural-network-based implementation of the considered energy forms, we can state an end-to-end learning scheme from irregularly-sampled data. We demonstrate the relevance of the proposed representations for different case-studies: namely, multivariate time series, 2{\\sc } images and image sequences.", "keywords": ["end-to-end-learning", "irregularly-sampled data", "energy representations", "optimal interpolation"], "paperhash": "fablet|endtoend_learning_of_energybased_representations_for_irregularlysampled_signals_and_images", "original_pdf": "/attachment/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "_bibtex": "@misc{\nfablet2020endtoend,\ntitle={End-to-end learning of energy-based representations for irregularly-sampled signals and images},\nauthor={Ronan Fablet and Lucas Drumetz and Fran{\\c{c}}ois Rousseau},\nyear={2020},\nurl={https://openreview.net/forum?id=rJe8pxSFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872599124, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2574/Reviewers"], "noninvitees": [], "tcdate": 1570237720900, "tmdate": 1575872599137, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review"}}}, {"id": "B1lNNWYdcr", "original": null, "number": 3, "cdate": 1572536619841, "ddate": null, "tcdate": 1572536619841, "tmdate": 1572972320365, "tddate": null, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "invitation": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper discusses various approaches to predict missing values in the input (filling/inpainting task).\nThey define an energy function equal to the squared L2 distance between the input and its reconstruction by various kinds of neural nets. They show slightly better performance compared to a PCA-based baseline.\n\nPositive things about this work\n- the topic is interesting\n- the last application is interesting (water temperature prediction) \n\nNegative things about this work\n- this work is very poorly  written and lacks sufficient clarity. This work needs a major rewrite. I do not even know where to start, but to give an example:\n1st sentence  of the abstract reads:  \u201cFor numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular spacetime sampling patterns and large missing data rates.\u201d, a sentence that misses the verb.\n2nd sentence of the abstract reads: \"These sampling properties is\u201d which is not grammatically correct\nAnd so on so forth. Speaking of which, the Authors make excessive use of \"....\".\n- because of the lack of clarity throughout the paper, I have had hard time figuring out what exactly the authors do. From the limited understanding I got after reading this draft twice, I think they consider a few different variants of auto-encoder and a \"log-prior\"/energy function equal to the squared L2 distance between input and its reconstruction. However, this formulation has barely any novelty. For instance, see old work like:\nS. Roth and M. J. Black, \u201cFields of experts: A framework for learning image priors,\u201d in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 2, San Diego, California, June 2005, pp. 860\u2013867\nwhere they used a different log-prior, but essentially the same optimization process. If the novelty is the use of auto-encoders, then the comparison should be against methods that do not auto-encode (like the above or more modern versions of it).\n- several choices made by the Authors seem not well motivated. For instance, it's written that computing gradients is too expensive and therefore these are replaced by the G network. However, doesn't the G network also need gradients to be updated?\n- the terminology is not standard and confusing. Hidden state usually refers to the encoder output, not to the decoder output.\n- the Authors never introduce the metrics they use, reconstruction and interpolation scores.\n- in general, the motivation is unclear. Why is it a problem if the data does not come from a grid? In vision, inpainting on unconstrained masks has been standard for decades. \nMore recently, transformer architectures and GNNs seem quite good at representing sets and graph structured data.\nSo considering this context, the current motivation provided by the authors needs some refinement. In fact, the authors could consider building on top of these other more modern approaches."}, "signatures": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2574/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ronan.fablet@imt-atlantique.fr", "lucas.drumetz@imt-atlantique.fr", "francois.rousseau@imt-atlantique.fr"], "title": "End-to-end learning of energy-based representations for irregularly-sampled signals and images", "authors": ["Ronan Fablet", "Lucas Drumetz", "Fran\u00e7ois Rousseau"], "pdf": "/pdf/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "TL;DR": "We address the end-to-end learning of energy-based representations for signal and image observation dataset with irregular sampling patterns.", "abstract": "For numerous domains, including for instance earth observation, medical imaging, astrophysics,..., available image and signal datasets often irregular space-time sampling patterns and large missing data rates. These sampling properties is a critical issue to apply state-of-the-art learning-based (e.g., auto-encoders, CNNs,...) to fully benefit from the available large-scale observations and reach breakthroughs in the reconstruction and identification of processes of interest. In this paper, we address the end-to-end learning of representations of signals, images and image sequences from irregularly-sampled data, {\\em i.e.} when the training data involved missing data. From an analogy to Bayesian formulation, we consider energy-based representations. Two energy forms are investigated: one derived from auto-encoders and one relating to Gibbs energies. The learning stage of these energy-based representations (or priors) involve a joint interpolation issue, which resorts to solving an energy minimization problem under observation constraints. Using a neural-network-based implementation of the considered energy forms, we can state an end-to-end learning scheme from irregularly-sampled data. We demonstrate the relevance of the proposed representations for different case-studies: namely, multivariate time series, 2{\\sc } images and image sequences.", "keywords": ["end-to-end-learning", "irregularly-sampled data", "energy representations", "optimal interpolation"], "paperhash": "fablet|endtoend_learning_of_energybased_representations_for_irregularlysampled_signals_and_images", "original_pdf": "/attachment/62920292397c23d4bb5d3e3018070b8654a39baa.pdf", "_bibtex": "@misc{\nfablet2020endtoend,\ntitle={End-to-end learning of energy-based representations for irregularly-sampled signals and images},\nauthor={Ronan Fablet and Lucas Drumetz and Fran{\\c{c}}ois Rousseau},\nyear={2020},\nurl={https://openreview.net/forum?id=rJe8pxSFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJe8pxSFwr", "replyto": "rJe8pxSFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2574/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872599124, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2574/Reviewers"], "noninvitees": [], "tcdate": 1570237720900, "tmdate": 1575872599137, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2574/-/Official_Review"}}}], "count": 5}