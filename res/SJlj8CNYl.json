{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028612379, "tcdate": 1490028612379, "number": 1, "id": "r1g3rdY6sx", "invitation": "ICLR.cc/2017/workshop/-/paper121/acceptance", "forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Motion Flow estimation by Generative Adversarial Networks", "abstract": "In this paper we address the challenging problem of unsupervised motion flow estimation. Under the assumption that image reconstruction is a super-set of the motion flow estimation problem, we train a convolutional neural network to interpolate adjacent video frames and then compute the motion flow via region-based sensitivity analysis by backpropagation. We postulate that better interpolations should result in better motion flow estimation. We then leverage the modeling power of energy-based generative adversarial networks (EbGAN's) to improve interpolations over standard L2 loss. Preliminary experiments on the KITTI database confirm that better interpolations from EbGAN's significantly improve motion flow estimation compared to both hand-crafted features and deep networks relying on standard losses such as L2.", "pdf": "/pdf/3df56f03fafb74d57ebe38fa57ab0a5976cf2a3d.pdf", "TL;DR": "In this paper we estimate the motion flow between consecutive frames unsupervisedly using generative adversarial networks trained for image interpolation and performing sensitivity analysis by backpropagation.", "paperhash": "alletto|unsupervised_motion_flow_estimation_by_generative_adversarial_networks", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "conflicts": ["unimore.it", "uniud.it", "panasonic.com"], "authors": ["Stefano Alletto", "Luca Rigazio"], "authorids": ["stefano.alletto@unimore.it", "luca.rigazio@us.panasonic.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028612951, "id": "ICLR.cc/2017/workshop/-/paper121/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028612951}}}, {"tddate": null, "tmdate": 1489583414714, "tcdate": 1489583414714, "number": 2, "id": "H1yB628ig", "invitation": "ICLR.cc/2017/workshop/-/paper121/official/review", "forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "signatures": ["ICLR.cc/2017/workshop/paper121/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper121/AnonReviewer2"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposes a GAN architecture that given frames t,t+2 interpolates to find t+1, building upon the method of Long et al for optical flow estimation through frame interpolation, by adding a discriminator to the output image. However, it does not compare against Long et al., so we do not know at the end, if adding the adversarial network helps. If the authors could clarify that, it would be important for the paper. My other note would be for them to provide one paragraph describing the method of Long et al a bit more in detail, as now someone needs to read Long's paper to get the full picture.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Motion Flow estimation by Generative Adversarial Networks", "abstract": "In this paper we address the challenging problem of unsupervised motion flow estimation. Under the assumption that image reconstruction is a super-set of the motion flow estimation problem, we train a convolutional neural network to interpolate adjacent video frames and then compute the motion flow via region-based sensitivity analysis by backpropagation. We postulate that better interpolations should result in better motion flow estimation. We then leverage the modeling power of energy-based generative adversarial networks (EbGAN's) to improve interpolations over standard L2 loss. Preliminary experiments on the KITTI database confirm that better interpolations from EbGAN's significantly improve motion flow estimation compared to both hand-crafted features and deep networks relying on standard losses such as L2.", "pdf": "/pdf/3df56f03fafb74d57ebe38fa57ab0a5976cf2a3d.pdf", "TL;DR": "In this paper we estimate the motion flow between consecutive frames unsupervisedly using generative adversarial networks trained for image interpolation and performing sensitivity analysis by backpropagation.", "paperhash": "alletto|unsupervised_motion_flow_estimation_by_generative_adversarial_networks", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "conflicts": ["unimore.it", "uniud.it", "panasonic.com"], "authors": ["Stefano Alletto", "Luca Rigazio"], "authorids": ["stefano.alletto@unimore.it", "luca.rigazio@us.panasonic.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489583415308, "id": "ICLR.cc/2017/workshop/-/paper121/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper121/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper121/AnonReviewer1", "ICLR.cc/2017/workshop/paper121/AnonReviewer2"], "reply": {"forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper121/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper121/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489583415308}}}, {"tddate": null, "tmdate": 1489183297015, "tcdate": 1489183297015, "number": 1, "id": "ryKBGigsg", "invitation": "ICLR.cc/2017/workshop/-/paper121/official/review", "forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "signatures": ["ICLR.cc/2017/workshop/paper121/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper121/AnonReviewer1"], "content": {"title": "Official review", "rating": "5: Marginally below acceptance threshold", "review": "The paper proposes an unsupervised learning approach to image matching. The authors train a deep network for video frame interpolation, and use the trained model to infer the correspondences between frames with backpropagation-based sensitivity analysis. The authors show that adversarial training of the interpolation network improves the accuracy of the predicted matches.\n\nThis general approach to learning to match images has been introduced by (Long et al., ECCV 2016). The contribution of the paper is in adding adversarial loss to the method and showing it improves the quality of the predicted matches.\n\nThe paper is written clearly, contains novel and fairly interesting results.\n\nPros:\n- The fact that adversarial training on image interpolation indirectly improves the quality of the matches (~10% relative improvement in accuracy@5, ~20% relative decrease in EPE) is interesting.\n- The method is using a somewhat non-standard GAN formulation based on EbGAN. It is not clear if this formulation is advantageous, though\n- The method is compared to relevant baselines\n\nCons:\n- Limited novelty: \"take an existing method and add a GAN\" is not a very original approach\n- The results of the method are on par with (Long et al., ECCV 2016) and worse than another unsupervised method by (Yu et al., arxiv 2016)\n\nI am not sure how to calibrate my score for the workshop track, so please take the rating with a grain of salt. This is not a bad paper, but I don't see \"very novel ideas\" in it.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Motion Flow estimation by Generative Adversarial Networks", "abstract": "In this paper we address the challenging problem of unsupervised motion flow estimation. Under the assumption that image reconstruction is a super-set of the motion flow estimation problem, we train a convolutional neural network to interpolate adjacent video frames and then compute the motion flow via region-based sensitivity analysis by backpropagation. We postulate that better interpolations should result in better motion flow estimation. We then leverage the modeling power of energy-based generative adversarial networks (EbGAN's) to improve interpolations over standard L2 loss. Preliminary experiments on the KITTI database confirm that better interpolations from EbGAN's significantly improve motion flow estimation compared to both hand-crafted features and deep networks relying on standard losses such as L2.", "pdf": "/pdf/3df56f03fafb74d57ebe38fa57ab0a5976cf2a3d.pdf", "TL;DR": "In this paper we estimate the motion flow between consecutive frames unsupervisedly using generative adversarial networks trained for image interpolation and performing sensitivity analysis by backpropagation.", "paperhash": "alletto|unsupervised_motion_flow_estimation_by_generative_adversarial_networks", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "conflicts": ["unimore.it", "uniud.it", "panasonic.com"], "authors": ["Stefano Alletto", "Luca Rigazio"], "authorids": ["stefano.alletto@unimore.it", "luca.rigazio@us.panasonic.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489583415308, "id": "ICLR.cc/2017/workshop/-/paper121/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper121/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper121/AnonReviewer1", "ICLR.cc/2017/workshop/paper121/AnonReviewer2"], "reply": {"forum": "SJlj8CNYl", "replyto": "SJlj8CNYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper121/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper121/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489583415308}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "writable": true, "revisions": false, "tmdate": 1487366951526, "tcdate": 1487361688421, "number": 121, "replyCount": 0, "id": "SJlj8CNYl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "SJlj8CNYl", "signatures": ["~Stefano_Alletto1"], "readers": ["everyone"], "content": {"title": "Unsupervised Motion Flow estimation by Generative Adversarial Networks", "abstract": "In this paper we address the challenging problem of unsupervised motion flow estimation. Under the assumption that image reconstruction is a super-set of the motion flow estimation problem, we train a convolutional neural network to interpolate adjacent video frames and then compute the motion flow via region-based sensitivity analysis by backpropagation. We postulate that better interpolations should result in better motion flow estimation. We then leverage the modeling power of energy-based generative adversarial networks (EbGAN's) to improve interpolations over standard L2 loss. Preliminary experiments on the KITTI database confirm that better interpolations from EbGAN's significantly improve motion flow estimation compared to both hand-crafted features and deep networks relying on standard losses such as L2.", "pdf": "/pdf/3df56f03fafb74d57ebe38fa57ab0a5976cf2a3d.pdf", "TL;DR": "In this paper we estimate the motion flow between consecutive frames unsupervisedly using generative adversarial networks trained for image interpolation and performing sensitivity analysis by backpropagation.", "paperhash": "alletto|unsupervised_motion_flow_estimation_by_generative_adversarial_networks", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "conflicts": ["unimore.it", "uniud.it", "panasonic.com"], "authors": ["Stefano Alletto", "Luca Rigazio"], "authorids": ["stefano.alletto@unimore.it", "luca.rigazio@us.panasonic.com"]}, "writers": [], "tags": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}