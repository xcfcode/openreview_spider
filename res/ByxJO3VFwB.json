{"notes": [{"id": "ByxJO3VFwB", "original": "r1x-YMWCrH", "number": 27, "cdate": 1569438823503, "ddate": null, "tcdate": 1569438823503, "tmdate": 1577168226161, "tddate": null, "forum": "ByxJO3VFwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "YZ8xf1k5vA", "original": null, "number": 1, "cdate": 1576798685344, "ddate": null, "tcdate": 1576798685344, "tmdate": 1576800949577, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Decision", "content": {"decision": "Reject", "comment": "This paper makes a claim that the iid assumption for NN parameters does not hold. The paper then expresses the joint distribution as a Gibbs distribution and PoE. Finally, there are some results on SGD as VI. Reviewers have mixed opinion about the paper and it is clear that the starting point of the paper (regarding iid assumption) is unclear. I myself read through the paper and discussed this with the reviewer, and it is clear that there are many issues with this paper.\n\nHere are my concerns:\n- The parameters of DNN are not iid *after* training. They are not supposed to be. So the empirical results where the correlation matrix is shown does not make the point that the paper is trying to make.\n- I agree with R2 that the prior is subjective and can be anything, and it is true that the \"trained\" NN may not correspond to a GP. This is actually well known which is why it is difficult to match the performance of a trained GP and trained NN.\n- The whole contribution about connection to Gibbs distribution and PoE is not insightful. These things are already known, so I don't know why this is a contribution.\n- Regarding connection between SGD and VI, they do *not* really prove anything. The derivation is *wrong*. In eq 85 in Appendix J2, the VI problem is written as KL(P||Q), but it should be KL(Q||P). Then this is argued to be the same as Eq. 88 obtained with SGD. This is not correct.\n\nGiven these issues and based on reviewers' reaction to the content, I recommend to reject this paper. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795712724, "tmdate": 1576800262166, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper27/-/Decision"}}}, {"id": "BJgMJnNvFH", "original": null, "number": 1, "cdate": 1571404762220, "ddate": null, "tcdate": 1571404762220, "tmdate": 1574337904294, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #1", "review": "Summary of the Paper:\n  \nThe authors claim the that i.i.d hypothesis that is often used in the prior when looking for the equivalence between neural networks and GP is not valid. Then, they propose a new interpretation of neural networks as Gibbs distributions (in the case of fully connected layers) and a MRF in the case of convolutional layers. Some simulations are done to verify this.\n\n\nDetailed comments:\n\nOverall I believe that the writing of the paper is very sloppy and difficult to read and follow. It is not clear that the GP interpretation cannot be valid simply because the activations and weights are not i.i.d. I.I.D is a sufficient condition but not required in the central limit theorem. For example, the sum of correlated Gaussian variables also tends to a Gaussian distribution. The same for non-Gaussian variables. Therefore, I do not think that the GP interpretation of the NN is wrong simply for that. This simply shows that the i.i.d. prior may be suboptimal.\n\nSumming up, I think that this paper needs more work. Currently, I do not think I can extract anything useful from it.\n\nThe prior is subjective and can be chosen by the user. So if an i.i.d. prior is actually chosen, the corresponding Bayesian  neural network will converge to a GP.\n\nAn i.i.d. prior may be sub-optimal. However, it can be used to interpret neural networks as GP. There is no problem with that.\n\nIt is well known that the sum of random variables can also converge to a Gaussian distribution even though they are not independent. This questions the claims of the paper.\n\nThe witting of the paper needs to be improved. There are several expressions that do not sound well. E.g., \", GP with i.i.d.\"\n\nZ'y in Eq. (9) should depend on l.\n\nIt is not clear what is the distribution of a hidden layer (activations weights etc..).\n\n\"...and f Y is an estimation of the true distribution P (Y |X)\" what do you mean by that?\n\nEq. (8) seems to be a prob. distribution for the random variable Fy. However, the authors give an expression for f_yl, which does not make sense.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575576808396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper27/Reviewers"], "noninvitees": [], "tcdate": 1570237720465, "tmdate": 1575576808408, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Review"}}}, {"id": "rJx3GcA6KS", "original": null, "number": 2, "cdate": 1571838483706, "ddate": null, "tcdate": 1571838483706, "tmdate": 1574215524053, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #27", "review": "\nMain contribution of the paper\n- The paper argues that the base assumption, the i.i.d. of the activated elements (activations) in the hidden layers, the existing methods (lee.et.al 2018) hold is not convincible.\n- Instead, the author proposes a new way to probabilistically model the hidden layers, activations, and layer/layer connections.\n- Based on the probabilistic model, the paper proposes a new regularizer.\n\nMethods\n- The author argues that the activation is not iid by empirically showing that the trained MLP (in most cases) does not un-correlated.\n- The author proposes a new probabilistic model for MLP, and CNN assuming the Gibbs distribution to each activation and also assuming the product of expert (poE) model to explain the layer/layer relationship.\n- And according to their model, CNN will be explained by the MRF model.\n- The author proposes a regularization term regarding layer/layer connection.\n- They argue that the SGD training can be seen as a first-order approximation of the inference of the hidden activations in MLP.\n\nQuestions\n- See the Concerns\n\nStrongpoints\n- The probabilistic explanation of the MLP and the CNN seems novel and was interesting to the reviewer\n- The proposed explanation assumes a weaker condition compared to the existing methods.\n\nConcerns\n- The main concern is that the reviewer cannot fully convince that i.i.d. assumption is wrong. \nEven though the trained MLP does not support the i.i.d. condition, one can suppose that the reason would be the typical training method (SGD), just finding the local minima in a deterministic way.\nMaybe the proof in Appendix.G. supports the argument of the author, but the reviewer failed to clearly agree with the argument.\nA clear explanation regarding the issue would be required.\n- As far as the author understands, the paper proposes a probabilistic (Bayesian) model for explaining MLP, but it seems that they just used SGD for training the model. \nIn that case, the reviewer is little suspicious of the role of the proposed regularization in that the regularization comes from Bayesian formulation, but the model was trained in a deterministic way.\nThe reviewer wants to ask the author that \n(1) is it possible to infer the model in a Bayesian manner such as sampling?\n(2) Is there any justification for using SGD when conducting the experiments regarding the regularization? If it is related to Appendix.G, clearer explanation would be appreciated.\n- As far as the reviewer understands, the regularization deals with the practical part of the paper. It would be better to see the effect of the regularization of widely used networks such as small-layered ResNet or others.\nIf the proposed formulation has other practical strongpoints, it would be nice to clarify them.\n- The explanation using Gibbs distribution and PoE looks similar to RBM. The reviewer strongly wants a clear explanation of the difference and the strongpoints compared to RBM.\n\nConclusion\n- The author proposed a new probabilistic explanation of the neural network, which seems novel and worth reporting.\n- However, the reviewer failed to fully agree on some steps in the process of the paper.\nTherefore, the reviewer temporary rates the paper as weak-reject, but this can be adjusted after seeing the answers of the author.\n \nInquiries\n- See the concerns parts.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575576808396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper27/Reviewers"], "noninvitees": [], "tcdate": 1570237720465, "tmdate": 1575576808408, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Review"}}}, {"id": "H1ePYbcssH", "original": null, "number": 11, "cdate": 1573785982894, "ddate": null, "tcdate": 1573785982894, "tmdate": 1573854130682, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Updated version of the paper", "comment": "We thank all reviewers for their comments. They are extremely insightful and help us to make our paper better. To address their comments, we have been actively refining our paper since the review is released. A new version is uploaded with lots of new results.\n\nHere is the summary of the latest version of the paper.\n(1) Refine the discussion part (Section 6)\n           Section 6.1 demonstrates the equivalence between SGD and the variational inference.\n           Section 6.2 demonstrates that the entire architecture of DNNs can be explained as a Bayesian network.\n           Section 6.3 provides more justifications for the proposed regularization algorithm.\n(2) Refine Appendix J\n            Appendix J.1 proves P(F_Y|X) is also a Gibbs distribution and its energy function is determined by the entire architecture of DNNs.\n            Appendix J.2 proves the equivalence between SGD and the variational inference.\n            Appendix J.3 proves the equivalence between SGD and the energy minimization optimization.\n(3) Refine Appendix K\n             Appendix K.1 demonstrates the equivalence between SGD and energy minimization optimization.\n             Appendix K.2 demonstrates that the parameters of DNNs are not i.i.d. during the training procedure.\n             Appendix K.3 demonstrates that a better prior distribution indicates a better generalization performance.\n(4) Refine the background part (Section 3) for providing more information about Gibbs distribution.\n(5) Refine Section 4.3 and Appendix H to make the derivation and proof more clear. \n(6) Refine Section 5.1 to make the simulation easily to understand. \n(7) Accordingly, refine the abstract, introduction, and conclusion part."}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "H1lmEnZHiB", "original": null, "number": 2, "cdate": 1573358634977, "ddate": null, "tcdate": 1573358634977, "tmdate": 1573849131694, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Why should we care about the i.i.d. assumption when explaining DNNs as a Gaussian process?", "comment": "Let us review the central limit theorem and use a simple example to clarify the Gaussian Process (GP) explanation for deep learning.\n\n(1) The Central Limit Theorem (CLT)\nGiven a sequence of $\\textbf{i.i.d.}$ random variables $\\{x_1, \\cdots, x_n\\}$ with expectation $\\mu$ and variance $\\sigma^2$, we can derive the average of these random variables, i.e., $S_n = \\frac{1}{n}(x_1 + \\cdots + x_n)$. CLT proves that the distribution of the random variable $\\sqrt{n}(S_n - \\mu)$ approaches to a Gaussian distribution as n goes to infinity.\n$$\\sqrt{n}(S_n - \\mu) \\rightarrow N(0, \\sigma^2) \\text{ as } n \\rightarrow \\infty$$\nTo some extent, we can say the summation of i.i.d. random variables obeys a Gaussian distribution. \nIt is important to note that $\\{x_1, \\cdots, x_n\\} \\text{ being } \\textbf{i.i.d.}$ is the prerequisite of CLT. \n\nAlso note that CLT is the statistical foundation of using GP to explain the distribution of hidden layers of DNNs. \nTherefore, I.I.D is very important for GP explanation. However, to the best of our knowledge, none of previous works thoroughly study if the activations of DNNs satisfy I.I.D. That is an important reason for we write the paper.\n\n(2) Now let us use a simple neural network to clarify the GP explanation. \n***A toy example***\nAssuming we have a linear neural network with an input layer {$x_1, x_2$},  a hidden layer {$f_{11}, f_{12}$}, and an output layer {$f_{21}, f_{22}$}. Here we do not consider bias and non-linear activation function for simplicity.\n\nThe activations of f_1 can be formulated as \n$$f_{11} = a_{11} \\cdot x_1 + a_{21} \\cdot x_2$$\n$$f_{12} = a_{12} \\cdot x_1 + a_{22} \\cdot x_2$$\nwhere $a_{11}$, $a_{21}$, $a_{12}$, and $a_{22}$ are parameters.\n\nThe activations of f_2 can be formulated as \n$$f_{21} = b_{11} \\cdot f_{11} + b_{21} \\cdot f_{12} $$\n$$f_{22} = b_{12} \\cdot f_{11} + b_{22 } \\cdot f_{12} $$\nwhere $b_{11}$, $b_{21}$, $b_{12}$, and $b_{22}$ are parameters.\n\nIf we want to derive $P(f_{21})$ is a Gaussian distribution based on CLT, the necessary condition is $f_{11}$ and  $f_{12}$ being i.i.d.. To satisfy the necessary condition,  all the previous works simply assume all the parameters are i.i.d.. Specifically, if $a_{11}$, $a_{21}$, $a_{12}$, and $a_{22}$ are i.i.d., then $f_{11}$ and $f_{12}$ are i.i.d.. \nAs a result, $P(f_{21})$ would approach a Gaussian distribution as the number of neurons in $f_1$ goes to infinity based on CLT. \n\n***Problems****\nThe i.i.d. assumption could be correct for simple neural networks. However, considering the extremely complex architecture of DNNs, it is necessary to derive rigorous proof and implement intensive experiments to examine if the i.i.d. assumption is valid for DNNs. We think the rigorous logic of using GP to explain DNNs can be summarized as the following three steps. That is also the structure of our paper.\n\nStep1. Check if the parameters of DNNs are i.i.d.. If they are i.i.d., we are safe to directly use GP to explain DNNs, this is the most ideal situation. However, we demonstrate that the parameters are not i.i.d..\n\nStep2. Though the parameters of DNNs are not i.i.d., the activations of hidden layers still could be i.i.d.. If the activations of hidden layers are i.i.d., we are also safe to use GP to explain DNNs, the only thing we need to modify is choosing another prior distribution for the parameters of DNNs.\nHowever, we demonstrate that activations being i.i.d. is not valid for all the hidden layer of DNNs.\n\nStep3. Since neither the parameters of DNNs nor the activations of hidden layers are i.i.d., we cannot use GP to model the distribution of all the hidden layers of DNNs.  We need to propose an alternative explanation.\n\nIn addition, previous works [1,2] have already demonstrated that GP is sensitive to the curse of dimensionality and cannot explain the hierarchical representation, an essential of deep learning.\n\n\n[1] G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. Deep neural networks for acoustic modeling in speech recognition. IEEE Signal Processing Magazine, 2012. \n[2] Alexander Matthews, Mark Rowland, Jiri Hron, Richard E. Turner, and Zoubin Ghahramani. Gaussian process behavior in wide deep neural networks. In ICLR, 2018. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "ByxWPxfriB", "original": null, "number": 4, "cdate": 1573359705386, "ddate": null, "tcdate": 1573359705386, "tmdate": 1573828255080, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "rylK6ur15r", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Response to Review #1", "comment": "Thank you for your encouraging review! Please find our replies to your specific comments below. \n\n>>> Fig 4: What is the information presented by each neuron? How would this have looked with the i.i.d. prior in place. \n\nFig 4 visualizes the feature defined by the weights of each neuron in the fully connected hidden layer. Since the input is a vectorized image with dimension 1024\u00d71, thus the dimension of the weights for each neuron is also 1024\u00d71. In order to clearly show the feature defined by the weights of each neuron, we reshape the dimension of weights as 32\u00d732 in Fig 4. Since the input image is sorted in the primary diagonal direction, the input feature can be described as high values above the secondary diagonal (the red line) and low values below the red line. Figure 4 shows that Neuron1, Neuron 2 and Neuron 4 correctly describe the input feature, thus they derive large positive outputs (i.e., g1(x) = 122.09, g2(x) = 113.70, and g4(x) = 140.20).  The probability of corresponding neurons, i.e., P (f1) = P (f2) = P (f4) = 0.20, indicates that the features defined by Neuron 1, Neuron 2 and Neuron 4 have high probability occurring in the input. (We have already refined the corresponding section to make it more clear)\n\nPrevious works assume that the weights of neural networks are i.i.d., the experiment shows the i.i.d. assumption is not valid in two aspects. First, most weights in a single neuron are correlated to their neighbors, e.g., if a weight with high value at the top left position in Neuron 1, its neighbors have high probability be high value, and vice versa. Second, the weights in different neurons are correlated, e.g., the weights at the same position in Neuron 1 and Neuron 2 are positively correlated and the weights at the same position in Neuron 1 and Neuron 7 are negatively correlated. (Appendix A.4 provides more information about the weights of neurons are not i.i.d..)\n\n>>> There are places in the paper where one must refer to the supplementary, for example, sections H and J with the simulations. Do consider moving these crucial sections to the main paper. \n\nThe page limitation of the main paper is the main reason why we put these parts in the Appendix. We will refine our paper to make it better based on your comments. Thank you!\n\n>>> How would you stand by your claim of explaining a DNN's layers to be modeled as a BHM? \n\nThat is a very fundamental and important question for deep learning. Thanks for asking! \n\nTheoretically, since the output of a hidden layer is commonly the input of the next layer, we can form a Markov chain to describe the entire architecture of DNNs. Based on the Markov chain, we can derive two conclusions: (1) a hidden layer corresponds to a random variable (the definition of a hidden layer here is general, e.g., a linear convolutional layer and a non-linear layer like ReLU is viewed as a single layer) and (2) the entire architecture of DNNs corresponds a joint distribution.\n\nGiven the first conclusion, i.e., a hidden layer corresponds to a random variable, we explain the random variable as a Gibbs distribution. Based on the Gibbs explanation, we experimentally find that the first hidden layer formulates a distribution of the dataset, i.e., a prior distribution. In addition, previous work [1] proves that DNNs estimate a posterior distribution P(Y|X), thus the output layer could be explained as a likelihood distribution. The two points trigger our interests to explain DNNs in a Bayesian way. \n\nBeyond your question, here is a more understanding of deep learning in a Bayesian way. \n\nThe entire architecture of DNNs can be explained as joint distribution, the hidden layers close to the input correspond to prior distributions, the output layer defines a likelihood distribution given the prior distributions, e.g., DNN = {x, f_1, f_2, f_Y}, the joint distribution is P(F_Y, F_2, F_1|X) = P(F_Y|F_2) P(F_Y|F_1) P(F_1|X)\n\nThe SGD aims to derive a posterior inference from the joint distribution, i.e., P(F_Y|X) = \\int  P(F_Y, F_2, F_1|X)dF_1dF_2, where \\int denotes integral.\n\nThanks again for your comments! We have already refined the paper. Look forward to your feedback!\n\n[1] M.D. Richard and R.P. Lippmann. Neural network classifiers estimate Bayesian a posteriori probabilities. Neural Computation, pages 461\u2013483, 1991. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "rJepUczHiB", "original": null, "number": 6, "cdate": 1573362260754, "ddate": null, "tcdate": 1573362260754, "tmdate": 1573822337162, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "BJgMJnNvFH", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Response to Review #2", "comment": "Thank you for your detailed comments! We post a single comment \u2018Why should we care about the i.i.d. assumption?\u2019. We hope that can clarify our idea. \n\nBelow are our replies to your specific comments. \n\n>>>I.I.D is a sufficient condition but not required in the central limit theorem. For example, the sum of correlated Gaussian variables also tends to a Gaussian distribution. The same for non-Gaussian variables. Therefore, I do not think that the GP interpretation of the NN is wrong simply for that. \n\nAs we presented in the comment \u2018Why should we care about the i.i.d. assumption\u2019, we can find that I.I.D. is the prerequisite of CLT. \n\nWe agree that the sum of correlated Gaussian variables tends to be Gaussian. However, that is not valid for non-Gaussian variables unless they are i.i.d. In other words, if we want to use CLT to derive a Gaussian distribution, we must guarantee all the random variables are i.i.d., otherwise, the result derived from CLT is not correct.\n\n>>>It is well known that the sum of random variables can also converge to a Gaussian distribution even though they are not independent. This questions the claims of the paper. \n\nTo the best of our knowledge, only the summation of I.I.D. random variables converges to a Gaussian distribution. The Lyapunov CLT could relax the I.I.D premise to be independence only under certain conditions. \n\n>>>The prior is subjective and can be chosen by the user. So if an i.i.d. prior is actually chosen, the corresponding Bayesian neural network will converge to a GP. An i.i.d. prior may be sub-optimal. However, it can be used to interpret neural networks as GP. There is no problem with that. \n\nI agree that the prior is subjective. We have the freedom to choose any prior. However, if we want the posterior distribution derived from the chosen prior to precisely explain something of interest, we must choose a prior distribution that conveys correct prior knowledge. For example, assuming some dataset obeys a Laplace distribution, it would be very hard to use a Gaussian distribution to precisely model the dataset, right? \n\nBack to the GP explanation for DNNs, when we find GP cannot explain some important properties of DNNs, we should consider if he GP explanation is reasonable or correct and try to propose a better explanation. Are you agree?\n\n>>>There are several expressions that do not sound well. E.g., \", GP with i.i.d.\" \n\nGP with i.i.d. prior means one use GP to explain the distribution of hidden layers and assume all the parameters of DNNs obey i.i.d. Gaussian prior distribution. We already refine the paper to make it clear. Thank you!\n\n>>>Z'y in Eq. (9) should depend on l. It is not clear what is the distribution of a hidden layer (activations weights etc..). \n\nZ_Y is not dependent on the index l. As we written in the paper, Z_Y = \\sum_{l=1}^L exp(f_yl) is the partition function to guarantee P(F_Y) is a valid probability measure.\n\n>>>\"...and f Y is an estimation of the true distribution P (Y |X)\" what do you mean by that?\n\nThe previous work [1] proves that the output of DNNs estimates a Bayesian posterior distribution. Following this explanation, f_Y is the output of DNNs and P(Y|X) is the true posterior distribution determined by the training dataset.\nWe explain all the notations in the preliminaries section.\n\n[1] M.D. Richard and R.P. Lippmann. Neural network classifiers estimate Bayesian a posteriori probabilities. Neural Computation, pages 461\u2013483, 1991. \n\n>>>Eq. (8) seems to be a prob. distribution for the random variable Fy. However, the authors give an expression for f_yl, which does not make sense.\n\nSince the output layer f_Y has L nodes, i.e., f_Y = {f_y1, f_y2, \u2026, f_yL}. As a result, F_Y is a random vector with L random variables corresponding to the L output nodes. \n\nWe appreciate your detailed comments. We have already refined our paper based on your comments. Please let us know if you have more questions about our paper. Thank you!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "ryg3jE8soS", "original": null, "number": 9, "cdate": 1573770404329, "ddate": null, "tcdate": 1573770404329, "tmdate": 1573786742458, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxWPxfriB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Clarifying the probabilistic explanation for the entire architecture of DNNs", "comment": "Dear reviewer,\n\nThanks again for your professional and encouraging comments. Here we want to plus more explanations for the entire architecture of DNNs. \n\n>>> Above all, we think the entire architecture of DNNs cannot be explained as a Bayesian hierarchical model (BHM) after deliberately thoughts and discussion with our coauthors. Notably, BHM forms a hierarchical structure by defining a series of prior distributions for the parameters of the likelihood distribution. However, the proposed Gibbs distribution is actually a distribution of the activations of a hidden layer. Though the activations entirely depend on the parameters of the hidden layer given the input, we cannot say activations are entirely equivalent to the parameters, thus we could not use BHM to explain the entire architecture of DNNs. We apologize for the inappropriate explanation.\n\n>>> Second, we relax our explanation, i.e., the entire architecture of DNNs can be explained as a Bayesian network because of two reasons.  (1) The entire architecture of DNNs corresponds to a joint distribution, and (2) we use the Bayesian inference method to infer the true posterior distribution P(Y|X). In particular, we provide rigorous proof (Appendix J) and intense simulations (Appendix K) for the two points. \n\n>>> Third, the Bayesian network's explanation for the entire architecture of DNNs does not affect the main part of the paper. We can still derive that GP cannot explain DNNs correctly because the I.I.D assumption for parameters and activations is not satisfied. Bayesian networks still can explain the hierarchical property of DNNs.  Pre-training the hidden layers corresponding to prior distributions still can improve the generalization performance of DNNs since the previous work [1] has already demonstrated that pre-training an effective regularization to capture more features of the training dataset.\n\nWe have already updated the paper, please check the latest version. If you have more questions, please let us know. Thanks again for your comments making our paper better!\n\n[1] Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and Samy Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11(Feb):625\u2013660, 2010.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "r1giw_Yssr", "original": null, "number": 10, "cdate": 1573783651148, "ddate": null, "tcdate": 1573783651148, "tmdate": 1573783651148, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "SygEQLzHoH", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Extra justification for the proposed regularization algorithm", "comment": "Dear reviewer,\n\nThanks again for your professional and helpful comments. \nHere we show extra justification for the proposed regularization algorithm. \n\n>>>First, [1] demonstrates that the unsupervised pre-training is an effective regularization for DNNs through capturing the prior knowledge of the input. However, since they do not know which hidden layer corresponds to a prior distribution, they have to pre-training all the hidden layers, which restricts its wide application due to the computation complexity. Moreover, [2] proves that incorporating the prior knowledge of the input results in uniform stability and provides a bound on generalization error for a specific DNN, i.e., the supervised auto-encoders. The two previous work provides theoretical and empirical justification for the proposed regularization algorithm by pre-training the hidden layers serving as prior distributions.\n\n>>>Second, Appendix K.3 demonstrates that a better prior distribution indeed indicates a better generalization performance based on CNNs for classifying the synthetic dataset. \n\nWe have already updated the paper, please check the latest version. If you have more questions, please let us know. Thanks again for your comments making our paper better!\n\n[1] Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and Samy Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11(Feb):625\u2013660, 2010.\n[2]  Lei Le, Andrew Patterson, and Martha White. Supervised autoencoders: Improving generalization performance with unsupervised regularizers. In Advances in Neural Information Processing Systems, pp. 107\u2013117, 2018. "}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "SkguKe5OoS", "original": null, "number": 8, "cdate": 1573589120068, "ddate": null, "tcdate": 1573589120068, "tmdate": 1573615250988, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "SygEQLzHoH", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "More explanations for SGD and i.i.d. assumption", "comment": "Dear reviewer,\n\nThanks again for your comments. Do you think our answers resolve your concern?  Here we make more explanations for SGD and the i.i.d. assumption. \n\nFirst, we demonstrate that the parameters learned by SGD are not I.I.D. To validate that point, we use SGD to train the MLP defined in Table 3 and the CNN defined in Table 5. Following the commonly used initialization approach, we initialize the weights of the MLP by Gaussian random matrices, i.e., all parameters can be viewed as I.I.D.. before training.  We use the sample correlation define by Equation 2 to indicate the dependence between the different neurons. We visualize the variation of average correlation for each layer over all the training epochs. \n\nOur simulations show that the correlation value initially is very low, because we initialize the weights as Gaussian random numbers. However, as the training procedure continues, the correlation values of some hidden layers have a huge increase, and finally achieve a stationary status. It means that the learned parameters cannot keep the I.I.D. status during the whole training procedure. The detailed simulations are included in Appendix K.2, please check the new version of our paper.\n\nWe think the I.I.D assumption contradicts the hierarchical property of DNNs. It is known that DNNs combine some low-level features together to derive high-level features [1]. Since high-level features are generated from low-level features, these high-level features should have certain correlations, which can be validated by the parameter's correlation. However, the I.I.D assumption contradicts the hierarchical property.\nIn particular, the previous work has already demonstrated that the Gaussian process is a flat representation [2].\n\nIn addition, the reason we use SGD to train DNNs is that SGD is the most popular and fundamental algorithm to train DNNs. In other words, using SGD to train DNNs can help us to derive a general probabilistic conclusion about the I.I.D assumption.\n\nIf you have questions about our paper, please feel free to let us know. Thank you!\n\n[1] LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436\u2013444 (2015)\n[2] Alexander Matthews, Mark Rowland, Jiri Hron, Richard E. Turner, and Zoubin Ghahramani. Gaussian process behavior in wide deep neural networks. In ICLR, 2018.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "SygEQLzHoH", "original": null, "number": 5, "cdate": 1573361180450, "ddate": null, "tcdate": 1573361180450, "tmdate": 1573439058209, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "rJx3GcA6KS", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"title": "Response to Review #3", "comment": "Thank you for your insightful and detailed comments. \n\n>>>>Above all, we understand your main concern that we cannot justify the Bayesian explanation for DNNs unless we prove the training procedure, i.e., SGD, works in a Bayesian manner as well. In order to answer this question well, we add Appendix J and Appendix K.1 to the paper. \n\nBriefly speaking, we prove that SGD can be explained as a Bayesian variational inference by three steps.\n*Step1, we prove the distribution of the output layer given the input, i.e., P(F_Y|X), is also a Gibbs distribution and its energy function is determined by the entire architecture of DNNs (Appendix J.1).\n\n*Step2, following previous works [1,2] proving the equivalence between SGD and variational inference, we further confirm the equivalence based on the proposed Gibbs explanation (Appendix J.2). In a word, SGD aims to find an optimal P*(F_Y|X) from a family of Gibbs distribution defined by DNNs, such that it can minimize the distance between P(Y|X) and P(F_Y|X), i.e.,\nP*(F_Y|X) = argmin KL[P(Y|X) || P(F_Y|X)]\n\n*Step3, we prove the equivalence between SGD and energy minimization optimization. Since the later is commonly used to optimize Gibbs distribution (a.k.a. the energy-based model), which in turn validates the Gibbs explanation for DNNs (Appendix J.3).\n\nIn addition, new simulations on MLP and CNNs validate the equivalence between SGD and the energy minimization optimization (Appendix K.1). Overall, we propose probabilistic explanations for both the architecture of DNNs and the training procedure of DNNs. Therefore, we are safe to explain the i.i.d. assumption and the regularization in a statistical way. \n\n>>>>Below are our replies to your specific comments.\n\n>>>The main concern is that the reviewer cannot fully convince that i.i.d. assumption is wrong. \n\nWe post a single comment \u2018Why should we care about the i.i.d. assumption?\u2019. Hope that can clarify our idea.  Please let us know if you have more questions about i.i.d.\n\n>>> is it possible to infer the model in a Bayesian manner such as sampling?\nYes, we prove SGD is equivalent to the variational inference, which is a dominant paradigm for Bayesian posterior inference (Appendix J.2)\n\n>>> Is there any justification for using SGD when conducting the experiments regarding the regularization? \n\nTheoretically, a regularization corresponds to a prior distribution based on Bayesian theory [3]. \nExperimentally, we demonstrate that SGD indeed learns a prior distribution and the prior distribution has a positive relation to the generalization performance, i.e., if SGD learns a better prior distribution, the testing error becomes smaller. (Appendix K.2) \nDo you agree with that answer?\n\n>>>It would be better to see the effect of the regularization of widely used networks such as small-layered ResNet or others. If the proposed formulation has other practical strongpoints, it would be nice to clarify them.\n\nExtending the regularization to ResNet is our research direction now. Different neural networks need to find different methods to pre-train the hidden layers corresponding to prior distributions, which requires lots of time. We will try our best to post the simulation results on ResNet in the final version. Since we explain DNNs in a Bayesian way, our research could be helpful to the neural architecture search based on Bayesian optimization.\n\n>>> The explanation using Gibbs distribution and PoE looks similar to RBM. The reviewer strongly wants a clear explanation of the difference and the strongpoints compared to RBM.\n\nGibbs distribution is equivalent to Boltzmann distribution. Actually, they have different names in different backgrounds. In machine learning, Gibbs distribution is named as the energy-based model. In statistical physics, Gibbs distribution is named as renormalization group. \n\nRBM is a special case of Gibbs distribution. However, RBM only considers the connections between visible units x and hidden units h but overlooks the internal connections within x and h, thus it cannot explain complicated DNNs, e.g., CNNs. We refine the background section and provide more information about Gibbs distribution, the comparison between Gibbs and RBM, and previous works evolving deep learning and Gibbs distribution.\n\nThanks again for your insightful comments! We have already refined the paper, please check the latest version. Hope we answer your questions correctly and look forward to your feedback again!\n \n[1] Stephan Mandt, Matthew D Hoffman, and David M Blei. Stochastic gradient descent as approximate Bayesian inference. The Journal of Machine Learning Research, 18(1):4873\u20134907, 2017. \n[2] Pratik Chaudhari and Stefano Soatto. Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks. In 2018 Information Theory and Applications Workshop (ITA), pp. 1\u201310. IEEE, 2018. \n[3] Harald Steck and Tommi S. Jaakkola. On the dirichlet prior and Bayesian regularization. In NeurIPS, 2003. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "rylK6ur15r", "original": null, "number": 3, "cdate": 1571932352851, "ddate": null, "tcdate": 1571932352851, "tmdate": 1572972316584, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors show that parameters of a DNN do not satisfy the i.i.d. prior assumption and that neural layer activations considered as i.i.d. are not valid assumptions for all hidden layers of the network. One can therefore not rightfully use GPs to describe the network\u2019s hidden layers. The authors suggest formulating the neurons per layer as energy functions thereby rendering a hidden layer as a Gibbs distribution and the connection between adjacent hidden layers as a PoE model. \n\nThe paper is well written and well postulated. \n\n> Fig 4: What is the information presented by each neuron? How would this have looked with the i.i.d. prior in place.\n\n> There are places in the paper where one must refer to the supplementary, for example sections H and J with the simulations. Do consider moving these crucial sections to the main paper.\n\n> One recurring thought I had when the authors bring up Bayesian Hierarchical model, is that most of the BHMs rely on i.i.d assumptions both in the prior space and with the observations. How would you stand by your claim of explaining a DNN's layers to be modelled as a BHM? \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575576808396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper27/Reviewers"], "noninvitees": [], "tcdate": 1570237720465, "tmdate": 1575576808408, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Review"}}}, {"id": "SklvKpFJOS", "original": null, "number": 1, "cdate": 1569852798626, "ddate": null, "tcdate": 1569852798626, "tmdate": 1569852798626, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "BkxI83I1uS", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment", "content": {"comment": "We found the revision was enabled somehow then, so we refined the submission a little bit.", "title": "The revision was enabled somehow at that time"}, "signatures": ["ICLR.cc/2020/Conference/Paper27/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper27/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper27/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper27/Authors|ICLR.cc/2020/Conference/Paper27/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504177446, "tmdate": 1576860556789, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Official_Comment"}}}, {"id": "BkxI83I1uS", "original": null, "number": 1, "cdate": 1569840206210, "ddate": null, "tcdate": 1569840206210, "tmdate": 1569840283902, "tddate": null, "forum": "ByxJO3VFwB", "replyto": "ByxJO3VFwB", "invitation": "ICLR.cc/2020/Conference/Paper27/-/Public_Comment", "content": {"comment": "Hi, how did you make it to modify your submission on 27 Sep 2019? Thanks. ", "title": "modified: 27 Sep 2019"}, "signatures": ["~Xinshao_Wang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Xinshao_Wang1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lxjbit@udel.edu", "barner@udel.edu"], "title": "Probabilistic modeling the hidden layers of deep neural networks", "authors": ["Xinjie Lan", "Kenneth E. Barner"], "pdf": "/pdf/680aaf81ec0c73c2842c92974ab77f1e80ec1c04.pdf", "TL;DR": "The Gaussian Process cannot correctly explain all the hidden layers of neural networks. Alternatively, we propose a novel probabilistic representation for deep learning ", "abstract": "In this paper, we demonstrate that the parameters of Deep Neural Networks (DNNs) cannot satisfy the i.i.d. prior assumption and activations being i.i.d. is not valid for all the hidden layers of DNNs. Hence, the Gaussian Process cannot correctly explain all the hidden layers of DNNs. Alternatively, we introduce a novel probabilistic representation for the hidden layers of DNNs in two aspects: (i) a hidden layer formulates a Gibbs distribution, in which neurons define the energy function, and (ii) the connection between two adjacent layers can be modeled by a product of experts model. Based on the probabilistic representation, we demonstrate that the entire architecture of DNNs can be explained as a Bayesian hierarchical model. Moreover, the proposed probabilistic representation indicates that DNNs have explicit regularizations defined by the hidden layers serving as prior distributions. Based on the Bayesian explanation for the regularization of DNNs, we propose a novel regularization approach to improve the generalization performance of DNNs. Simulation results validate the proposed theories. ", "keywords": ["Neural Networks", "Gaussian Process", "Probabilistic Representation for Deep Learning"], "paperhash": "lan|probabilistic_modeling_the_hidden_layers_of_deep_neural_networks", "original_pdf": "/attachment/0120e04b696d98e13cbd0b3a4ba32f63a2f2d316.pdf", "_bibtex": "@misc{\nlan2020probabilistic,\ntitle={Probabilistic modeling the hidden layers of deep neural networks},\nauthor={Xinjie Lan and Kenneth E. Barner},\nyear={2020},\nurl={https://openreview.net/forum?id=ByxJO3VFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByxJO3VFwB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504214985, "tmdate": 1576860589918, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper27/Authors", "ICLR.cc/2020/Conference/Paper27/Reviewers", "ICLR.cc/2020/Conference/Paper27/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper27/-/Public_Comment"}}}], "count": 15}