{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457681973068, "tcdate": 1457681973068, "id": "ZY9A3BkDNH5Pk8ELfEPX", "invitation": "ICLR.cc/2016/workshop/-/paper/146/review/11", "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "signatures": ["ICLR.cc/2016/workshop/paper/146/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/146/reviewer/11"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "The paper describes a method for segmenting body parts in depth images of humans in real time. It uses an existing neural network architecture and a simple loss that has been used before for segmentation tasks. The model is trained on synthetic data and applied to Kinect camera images. \n\nThe paper is quite straightforward as far as segmentation work goes. I believe none of the components are novel, the only potential novelty is the application domain (segmenting depth images rather than RGB images). More segmentation work on RGB images could be cited, for example: \nVijay Badrinarayanan, Alex Kendall and Roberto Cipolla \"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.\", which uses a more advanced network architecture for a seemingly harder task. \n\nThere are strong assumptions in the approach: a single body type was used for training and it's placed at a fixed position relative to the camera. At test time, it is assumed that it is possible to accurately remove the background in scenes, although I am not convinced that this is the case for cluttered scenes. \n\nThe experimental results are lacking numerical analysis on real data-- only a single result for eyeballing is presented. It would have been helpful to show more results along with the failures of the model in more detail.  On synthetic data, it would have been helpful to show how accuracy varies with an increasing amount of noise. Most body parts other than torso have accuracy in the 60-70% range which is not necessarily very high. Finally, if the goal is to estimate body skeletons, why not directly regress to the 3D joint locations, like \"DeepPose: Human Pose Estimation via Deep Neural Networks\" by Alexander Toshev, Christian Szegedy. \n\nFor an application paper, I would have expected a little more in depth experimental analysis. Right now it's a bit thin even for a workshop submission. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Fully Convolutional Nerual Network for Body Part Segmentation", "abstract": "This paper presents the foundation of a new system for human body segmentation. It is based on a Fully Convolutional Neural Network that uses depth images as input and produces a per-pixel labeling of the image where each pixel has been labeled as a body segment of interest or as non-person. The training data are fully synthetic which allow for large amounts of data to be generated in a relatively short period of time. By using a GPU accelerated implementation of the convolutional neural network, the system is capable of segmenting an image in 8.5 milliseconds. This work will form the basis for more robust system in the future that will be suitable for finding pose skeletons in more cluttered environments.\n", "pdf": "/pdf/3QxgDBPQxIp7y9wltPq9.pdf", "paperhash": "frank|fully_convolutional_nerual_network_for_body_part_segmentation", "conflicts": ["cse.unr.edu", "unr.edu", "nasa.gov", "flirtey.com"], "authors": ["David Frank", "Richard Kelley", "David Feil-Seifer"], "authorids": ["davidfrank@unr.edu", "rkelley@unr.edu", "dave@cse.unr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580032991, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580032991, "id": "ICLR.cc/2016/workshop/-/paper/146/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/146/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457639218344, "tcdate": 1457639218344, "id": "zvwrjqVAptM8kw3ZinoB", "invitation": "ICLR.cc/2016/workshop/-/paper/146/review/12", "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "signatures": ["ICLR.cc/2016/workshop/paper/146/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/146/reviewer/12"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "This works at segmenting body parts from depth images using a convolutional network. The authors propose a modification of an existing architecture designed to fit on a \"consumer grade GPU.\"  The authors train this network on synthetically generate data and applied on images captured by the Kinect camera.\n\nMost of the evaluation was done on synthetic data, and no effort was made to establish the quality of the segmentation of real images except for visually inspecting the results on a few such images.\n\nOn the plus side, I think the results seem very reasonable on the synthetic dataset. On the down-side, I am very worried about the transfer capabilities which were not evaluated except by eyeballing, and the quirks in the training dataset (i.e., a single 3D model was used, arbitrary transforms were performed on the limbs, which may or may not reflect plausible positions for humans).\n\nI see a lot of potential in this work, but it simply seems much too early to publish even as a workshop paper. I would have hoped for a more detailed explanation of the network and maybe some example images where the network fails to segment correctly the limbs + additional commentary on why is this happening. In addition, it would have made a lot of sense to also discuss in slightly more detail of the choice to put the 3D subject at a fixed distance from the camera, and maybe also explain whether the focal length of the 3D sensor has any effect on the segmentations produced by this algorithm.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Fully Convolutional Nerual Network for Body Part Segmentation", "abstract": "This paper presents the foundation of a new system for human body segmentation. It is based on a Fully Convolutional Neural Network that uses depth images as input and produces a per-pixel labeling of the image where each pixel has been labeled as a body segment of interest or as non-person. The training data are fully synthetic which allow for large amounts of data to be generated in a relatively short period of time. By using a GPU accelerated implementation of the convolutional neural network, the system is capable of segmenting an image in 8.5 milliseconds. This work will form the basis for more robust system in the future that will be suitable for finding pose skeletons in more cluttered environments.\n", "pdf": "/pdf/3QxgDBPQxIp7y9wltPq9.pdf", "paperhash": "frank|fully_convolutional_nerual_network_for_body_part_segmentation", "conflicts": ["cse.unr.edu", "unr.edu", "nasa.gov", "flirtey.com"], "authors": ["David Frank", "Richard Kelley", "David Feil-Seifer"], "authorids": ["davidfrank@unr.edu", "rkelley@unr.edu", "dave@cse.unr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580032780, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580032780, "id": "ICLR.cc/2016/workshop/-/paper/146/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/146/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1456960012691, "tcdate": 1456960012691, "id": "3QxWx1q1yTp7y9wltP2P", "invitation": "ICLR.cc/2016/workshop/-/paper/146/review/10", "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "signatures": ["ICLR.cc/2016/workshop/paper/146/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/146/reviewer/10"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "This work aims to segment human body parts in depth images in real-time, using the approach of training a convolutional network on synthetic data.  This is a nice, simple approach and obtains what looks like promising initial results.  Significant gaps remain in order to turn this in a working system, most notably variation in body shape; however, the authors acknowledge this and it looks good for a preliminary result.\n\nThe paper seems a bit on the light side, even for an extended abstract, and I think it could be fleshed out a some more.  One possible suggestion, what do the results look like using the current system for a downstream joint or skeleton estimation?  Also, while accuracy numbers are reported, it is hard to place them in context without some baseline comparisons (maybe Shotton et al.?)\n\nOverall, this is a simple system with what looks like good preliminary results, but I think would be stronger if the presentation in the paper were a little further developed.\n\n\nA few additional comments:\n\n- \"final layer of this network was shaped such that it had the same height and width as the input\":  Do the max-pooling layers downsample the resolution of the output?  Fig 2 shows that the network output is upsampled -- is the upsampled result what is reshaped?  How much spatial downsampling is there within the network?  Additional details of the network structure and sizes would be good to include.\n\n- \"structure of the network was similar to Long ... skip layers were also not inculded\":  The skip-layers combining scales by adding is, I think, actually the largest defining feature of Long et al., so I'm not sure I'd call this a \"similar\" network.  It is a ConvNet that is simple and geared to the task, though.\n\n- It would be good to show comparisons with other systems, at least Shotton et al.\n\n- Relevant reference re: pose estimation with convnets:  Tompson et al., \"Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation\", NIPS 2014.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Fully Convolutional Nerual Network for Body Part Segmentation", "abstract": "This paper presents the foundation of a new system for human body segmentation. It is based on a Fully Convolutional Neural Network that uses depth images as input and produces a per-pixel labeling of the image where each pixel has been labeled as a body segment of interest or as non-person. The training data are fully synthetic which allow for large amounts of data to be generated in a relatively short period of time. By using a GPU accelerated implementation of the convolutional neural network, the system is capable of segmenting an image in 8.5 milliseconds. This work will form the basis for more robust system in the future that will be suitable for finding pose skeletons in more cluttered environments.\n", "pdf": "/pdf/3QxgDBPQxIp7y9wltPq9.pdf", "paperhash": "frank|fully_convolutional_nerual_network_for_body_part_segmentation", "conflicts": ["cse.unr.edu", "unr.edu", "nasa.gov", "flirtey.com"], "authors": ["David Frank", "Richard Kelley", "David Feil-Seifer"], "authorids": ["davidfrank@unr.edu", "rkelley@unr.edu", "dave@cse.unr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580033301, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580033301, "id": "ICLR.cc/2016/workshop/-/paper/146/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "3QxgDBPQxIp7y9wltPq9", "replyto": "3QxgDBPQxIp7y9wltPq9", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/146/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455827909740, "tcdate": 1455827909740, "id": "3QxgDBPQxIp7y9wltPq9", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "3QxgDBPQxIp7y9wltPq9", "signatures": ["~David_Frank1"], "readers": ["everyone"], "writers": ["~David_Frank1"], "content": {"CMT_id": "", "title": "Fully Convolutional Nerual Network for Body Part Segmentation", "abstract": "This paper presents the foundation of a new system for human body segmentation. It is based on a Fully Convolutional Neural Network that uses depth images as input and produces a per-pixel labeling of the image where each pixel has been labeled as a body segment of interest or as non-person. The training data are fully synthetic which allow for large amounts of data to be generated in a relatively short period of time. By using a GPU accelerated implementation of the convolutional neural network, the system is capable of segmenting an image in 8.5 milliseconds. This work will form the basis for more robust system in the future that will be suitable for finding pose skeletons in more cluttered environments.\n", "pdf": "/pdf/3QxgDBPQxIp7y9wltPq9.pdf", "paperhash": "frank|fully_convolutional_nerual_network_for_body_part_segmentation", "conflicts": ["cse.unr.edu", "unr.edu", "nasa.gov", "flirtey.com"], "authors": ["David Frank", "Richard Kelley", "David Feil-Seifer"], "authorids": ["davidfrank@unr.edu", "rkelley@unr.edu", "dave@cse.unr.edu"]}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 4}