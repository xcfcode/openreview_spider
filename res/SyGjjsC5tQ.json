{"notes": [{"id": "SyGjjsC5tQ", "original": "Hygo2bK9F7", "number": 652, "cdate": 1538087842923, "ddate": null, "tcdate": 1538087842923, "tmdate": 1548602992185, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Bke6hKRlgN", "original": null, "number": 1, "cdate": 1544772020922, "ddate": null, "tcdate": 1544772020922, "tmdate": 1545354521903, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Meta_Review", "content": {"metareview": "This paper provides interesting results on convergence and stability in general differentiable games. The theory appears to be correct, and the paper reasonably well written. The main concern is in connections to an area of related work that has been omitted, with overly strong statements in the paper that there has been little work for general game dynamics. This is a serious omission, since it calls into question some of the novelty of the results because they have not been adequately placed relative to this work. The authors should incorporate a thorough discussion on relations to this work, and adjust claims about novelty (and potentially even results) based on that literature.", "confidence": "3: The area chair is somewhat confident", "recommendation": "Accept (Poster)", "title": "Correct and reasonably well-written paper with some concerns on missing literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper652/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353139595, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353139595}}}, {"id": "SJg1HSY30m", "original": null, "number": 8, "cdate": 1543439670640, "ddate": null, "tcdate": 1543439670640, "tmdate": 1543439670640, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "S1g8jRe9AX", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Thank you for these references", "comment": "Thank you for these important references. Unfortunately we were not aware of this literature, especially the monograph of Facchinei and Kanzow and the older work mentioned. Thanks also for linking to the preprint on general games with continuous action sets. This is a great starting point to explore further in this area: apologies for having been unaware of this in the first place. We will be sure to cite and discuss a number of these related works in a revision of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "S1lFlwbjR7", "original": null, "number": 7, "cdate": 1543341809476, "ddate": null, "tcdate": 1543341809476, "tmdate": 1543341809476, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "r1gygsCu07", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Response", "comment": "Thank you for reading through our clarifications in detail, and for providing further comments.\n\n- We will be sure to clarify the question of twice/thrice differentiability in a note following Definition 1.\n\n- The application of Cauchy-Schwartz goes as follows. Writing $u = -\\alpha \\chi$ and $v = \\xi_0$, we have $-||u|| * ||v||  \\leq <u, v>$ by (one half of) the Cauchy-Schwartz inequality. Taking opposites and inverses on both sides, we obtain $1/(||u|| * ||v||) \\leq -1/<u, v>$. This is how the negative sign disappears from one fraction to the next. We will add an extra step in the equation to make this clearer.\n\nWe will add derivations and check our proofs/equations before submitting a final revision. Thanks again for your helpful and thorough review."}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "S1g8jRe9AX", "original": null, "number": 1, "cdate": 1543274142354, "ddate": null, "tcdate": 1543274142354, "tmdate": 1543325393075, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Public_Comment", "content": {"comment": "I was disappointed to see that the authors make no reference to the rich literature on continuous games where the positive-definiteness of the Hessian has been explored quite extensively as a stability criterion.\n\nThe role of this condition dates back (at least) to the work of Rosen in the 60's (Econometrica, 1965), wherein it was introduced precisely as a stability criterion for the convergence of first-order learning methods in N-player games with continuous action sets.\n\nFor a more recent take, the authors might also want to consult the monograph of Facchinei and Kanzow (Annals of OR, 2010): Hessian stability is discussed extensively in Section 5 of said paper (Algorithms), and plays the same role as in the current paper.\n\nIt should be noted that the above papers concern a model which is (in at least one sense) even more general than that of the authors, because the admissible actions of a player may depend on the actions of all other players (hence the term \"generalized Nash equilibrium problem\"/GNEP). Also, even though the above papers concern games with individually convex loss functions, the extension to non-convex games under local stability conditions has also been explored in the literature - see e.g., the recent preprint https://arxiv.org/abs/1608.07310.\n\nThe above goes to show that statements like \"the only theoretical work on general game dynamics is Symplectic Gradient Adjustment (SGA) by Balduzzi et al. (2018)\" are not representative of the state of the art in the subject. The same also holds for the authors' complete lack of references to this literature in Section 2.2 (and, to be clear, the papers mentioned above comprise but a small sample of a very active literature on games with continuous action spaces).\n\nTo state things frankly, the field is not a virgin territory only recently discovered, so I would urge the authors to take this into account in their bibliographical policy - the papers above could provide a starting point in that respect, so they should be properly cited and discussed.", "title": "Related literature on stable equilibria and continuous games"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311785341, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SyGjjsC5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311785341}}}, {"id": "r1gygsCu07", "original": null, "number": 6, "cdate": 1543199463354, "ddate": null, "tcdate": 1543199463354, "tmdate": 1543199652475, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "Ske-EpPQTm", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Thanks for the response", "comment": "Thank you for addressing all the comments.\n\n- I am satisfied with the explanation from the authors regarding Theorem D.4 and the revision adequately addresses most of the comments.\n\n- Regarding differentiability, it is fine to retain the original definition of differentiable games while your result requiring thrice differentiable losses. However, the justification you provided in your response needs to be added in to the paper and preferably as a note immediately after Definition 1 to avoid the misinterpretation. \n\n- Another question Lemma D.7 - Towards the end of proof, the application of Cauchy Schwartz is not clear. You show that ||-\\alphaX(\\theta)|| = \\alpha^2||X(\\theta)|| < c. However, it is not clear how the equation below that holds? Specifically, why does the negative sign in the first fraction disappear and somehow the overall term becomes >= \\alpha||\\Psi_0||/||-\\alphaX||.\n\nIt is recommended that the authors proofread all the proofs and equations and try to use notations and show derivations without making them confusing for the overall presentation. It would also help to number equations for quick reference.\n\nOverall the paper presents strong theoretical results with adequate empirical evidence. It certainly addresses an important problem of trade-off between convergence and stability in multi-objective settings and I have updated my score from 6 to 8 to strongly support it for acceptance.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper652/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "HkeiQRSTnQ", "original": null, "number": 3, "cdate": 1541393955226, "ddate": null, "tcdate": 1541393955226, "tmdate": 1543199489712, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "content": {"title": "Interesting paper, strong theoretical results but concerns with the main theorem ", "review": "This paper focuses on the problem of convergence in multi-objective optimisation with differentiable losses. This topic is timely and relevant, given the increasing amount of recent work on multi-objective architectures, e.g. GANs, adversarial learning, multi-agent reinforcement learning. The authors focus on stable fixed points (SFP), rather than Nash equilibria, as the solution concept in the entirety of their analysis. Casting the recently proposed LOLA gradient adjustment into a general matrix form, they diagnose an example where the shaping term in LOLA prevents convergence to SFP. They also find that discarding the shaping term leads to an earlier method (which they name ''LA'') with convergence guarantees in two-player two-action games. However, this also loses the opponent shaping ability of LOLA. To address these limitation, the authors propose SOS, which interpolates between LA and LOLA, and dynamically chooses the interpolation coefficient $p$ so that their adjusted gradient preserves LOLA's shaping ability only to the extent allowed by the constraint of moving in LA's direction. The main goal of the paper is to show that SOS converges locally to SFP, and to fixed points only, while avoiding strict saddles. Experiments on synthetic games show that SOS preserves the benefit of LOLA while avoiding its theoretically-predicted issues, and a more complex Gaussian mixture GAN experiment shows SOS is empirically competitive with other gradient adjustment methods.\n\nThe main conceptual novelty consists of the dynamic interpolation term to combine advantages of LOLA and LA while avoiding pitfalls of both. The major strength of the paper lies in the clear justification for this interpolation approach. The paper contains strong theoretical results for general differentiable games, and deserves the notice of the ICLR community if valid. However, I have major concerns with the proof of Theorem 2 (i.e. Theorem D.4 in the appendix), which affects the validity of Corollary 3 and Theorem 4. \n\nIn the proof of Theorem D.4:\n1. How does the expression $u^T M^{-1}GMu$ have conformable dimensions, when $G \\in R^{d \\times d}$ while $u \\in R^{d-1}$? Was any assumption made about the matrix $M = (I + \\alpha H_d)^{1/2}$?\n2. In the middle of page 14, a unit vector $u \\in S^m$ is defined, but it is not clear what vector space is meant by $S^m$.\n3. In the second-to-last line of page 14, a quantity $S$ is used but not defined clearly in any preceding part of the proof. Remark D.5 refers to $S$ as the symmetric part of $G$, and asserts that S is not positive definite. If the quantity $S$ used in the proof is the same non-PD quantity, then $S$ does not have a Cholesky factorisation. So how is Cholesky decomposition conducted at end of page 14?\n4. In the first line of page 15, a quantity $A$ is used but not defined anywhere else in the entire paper. \n5. From the subsequent line, it appears to be the anti-symmetric part of H. Is it correct assumption? If so, $H^2$ is not $(S^T - A^T)(S + A)$. If you replace it with correct form, whole quantity does not compute to be positive or becomes meaningless.\n\nAs Theorem 2 is the crux for all the theoretical advancement presented in the paper, clarifications on above correctness questions is very important for clear acceptance of this work.\n\nWhile Definition 1 precisely defines differentiable games to have *twice* differentiable losses, why do the authors assume *thrice* differentiable losses at the start of Section 4?\n\nIn Section 2.2, the authors make a broad statement that ''Nash equilibria cannot be the right solution concept for multi-agent learning.'' They provide one example where Nash is undesirable (L^1 = L^2 = xy). However, since this example can be viewed as a fully cooperative game with joint loss L = 2xy, it does not support the broader statement that Nash is undesirable in all games. Because this statement directly motivates the authors to focus on stable fixed points, rather than Nash, as the solution concept in their subsequent analysis, it is very important to provide better justification for the claim.\n\nMinor comments:\n1. Under Proposition 1, the authors suddenly speak of ''...the policy being optimal''. Since the author's work pertains to general multi-objective settings, not solely multi-agent reinforcement learning, the word ''policy'' sounds strange in context.\n2. The statement of Proposition B.1, and the concluding line of the derivation, left out a coefficient $\\alpha$ that is present in Proposition 1 in the main text.\n3. While the authors claim and prove independence of theoretical results from choice of a and b, are there any practical implications in terms of performance or convergence?\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper652/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "cdate": 1542234410807, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335772699, "tmdate": 1552335772699, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1l_xkOXa7", "original": null, "number": 4, "cdate": 1541795568131, "ddate": null, "tcdate": 1541795568131, "tmdate": 1541795568131, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "BkeyQHEcnQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Response to your review", "comment": "Thank you for this review. Some of the notation could certainly have been made clearer. Each point is addressed below and will be incorporated in a revision of the paper.\n\n1. If agent $i$ has parameters $\\theta^i_t$ at some fixed time $t$, the \"current parameters\" are simply defined as $\\hat{\\theta}^i = \\theta^i_t$. The point is that these parameters are updated at each step to minimise a loss function. In LOLA, each agent assumes that the opponent updates their parameters dynamically, *after* their own optimisation step. In reality, they can only see the *current* parameters $\\theta^i_t$ instead of the *optimised* (next) parameters $\\theta^i_{t+1}$. Noticing this leads to an alternative algorithm, LookAhead.\n\n2. The stop-gradient operator is really a *computational* operator rather than a formal, mathematical one. This is known in PyTorch as *detach* and in Tensorflow as *stop_gradient*. This operator acts on functions, setting their gradient to zero while keeping their value intact. In other words, $\\bot f(x) = f(x)$ when evaluated at any $x$, while $\\nabla (\\bot f) (x) = 0$ for any $x$.\n\n3. You are absolutely right: the diag operator in Proposition 1 should be defined as taking diagonal *blocks* since we are working with block matrices, not diagonal *entries*. Thank you for noticing this."}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "SkgljTPmTQ", "original": null, "number": 3, "cdate": 1541795224003, "ddate": null, "tcdate": 1541795224003, "tmdate": 1541795224003, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "H1l2AeXanm", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Response to your review", "comment": "Thank you for this review. We will be sure to incorporate your comment in a revision of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "Ske-EpPQTm", "original": null, "number": 2, "cdate": 1541795113399, "ddate": null, "tcdate": 1541795113399, "tmdate": 1541795152830, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "HkeiQRSTnQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "content": {"title": "Response to your review", "comment": "Thank you for your detailed and thoughtful comments. Below we address each point regarding the proof of Theorem D.4. We will also revise the paper to clarify these points and want to emphasise that these details do not affect the validity of our results.\n\n1. This is a notational confusion: $u$ lives in $R^d$, not $R^{d-1}$, while $G$ and $M$ are both square $d \\times d$ matrices. Indeed $u$ is defined to be an arbitrary vector in $S^{d-1}$, the unit (d-1)-sphere living in Euclidian space $R^d$. This is a standard but confusing convention (see https://en.wikipedia.org/wiki/N-sphere ).\n\n2. As above, $S^m$ with $m = d-1$ is the space of unit vectors in $R^d$.\n\n3. $S$ and $A$ are the symmetric and antisymmetric parts of $H$ respectively, which we mistakenly failed to define in the paper. The definitions are $S = (H+H^T)/2$ and $A = (H-H^T)/2$, so that $H = S + A$. In the specific example of Remark D.5, $S$ is not positive definite. However, one can easily show that a matrix $H$ is positive semi-definite iff its symmetric part $S$ is positive semi-definite (consider $u^T H u = u^T S u + u^T A u = u^T S u$ by antisymmetry of $A$). By assumption in Theorem D.4, it follows that $S$ is positive semi-definite and thus has a Cholesky decomposition.\n\n4. See point 3.\n\n5. This is the correct assumption. Regarding your concern about the expression for $H^2$, we have $H = S + A$ but also $H = S^T - A^T$ by symmetry of $S$ and antisymmetry of $A$. It follows that $H^2 = (S^T - A^T)(S + A)$ as claimed.\n\nDefinition 1 was chosen to be in line with prior work (Balduzzi et al, ICML 2018), where losses are *twice* differentiable. Our results require *thrice* differentiable losses because both Ostrowski and Stable Manifold Theorems require continuous differentiability of the gradient adjustment. Now the gradient adjustment for SOS contains second-order gradients of the losses through the Hessian $H$, so will only be continuously differentiable if the losses themselves are *thrice* continuously differentiable. We chose to make this extra (very weak) assumption explicit before stating our results, instead of changing the definition of differentiable games to fit our purposes. We are happy to alter the definition if this helps at all.\n\nAppendix A provides a more detailed justification for choosing stable fixed points over Nash equilibria as the correct solution concept for gradient-based optimisation in games. Though the example given in the main body is insufficient by itself, the aim was not to show that Nash are *always* undesirable (this is not true), but to show that optimisation algorithms should not aim/succeed in converging to *all* Nash equilibria. The appendix was referenced for further detail about stable fixed points, but we will further clarify this in the main paper in the final version.\n\nReplies to minor comments:\n\n1. Agreed: speaking of \"policy\" is indeed too specific and inappropriate.\n\n2. Well-spotted typo! We will correct this.\n\n3. Choosing $a$ closer to $0$ means that SOS is forced to agree strongly with the direction of LA, while $a$ close to $1$ gives more flexibility (larger angle between the adjustments). In other words: smaller $a$ means potentially faster convergence, larger $a$ allows for more opponent shaping. Similarly for $b$: the parameter $p$ will be shrunk in a $b$-neighbourhood of fixed points, so larger $b$ ensures convergence in a wider radius while smaller $b$ allows for more opponent shaping. As briefly mentioned in the paper, we found that these hyperparameters were quite robust in experiments overall, though choosing $b = 0.1$ (quite small) for the IPD and Gaussian Mixtures was necessary to guarantee strong opponent shaping in a large region of parameter space. We hope this helps shed some light on the practical implications of choice on $a$ and $b$, though all theoretical results are indeed independent from this choice."}, "signatures": ["ICLR.cc/2019/Conference/Paper652/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621329, "tddate": null, "super": null, "final": null, "reply": {"forum": "SyGjjsC5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper652/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper652/Authors|ICLR.cc/2019/Conference/Paper652/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers", "ICLR.cc/2019/Conference/Paper652/Authors", "ICLR.cc/2019/Conference/Paper652/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621329}}}, {"id": "H1l2AeXanm", "original": null, "number": 2, "cdate": 1541382355808, "ddate": null, "tcdate": 1541382355808, "tmdate": 1541533805264, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "content": {"title": "Review for Stable Opponent Shaping in Differentiable Games ", "review": "This paper studies differential games, in which there are n players and each has a loss function. The loss function depends on all parameters. Differential games appear naturally in GANs, where the two players are the generator and the discriminator. The authors first argue why Nash equilibria should not be the right solution concept for multi-agent learning and propose \u201cstable fixed points\u201d (SFP) as a possible solution concept. The authors then show the LOLA algorithm (Foerster et al. (2018)) fails to preserve fixed points by explicitly constructing an instance (the tandem game). In fact in the tandem game, LOLA will converge to sub-optimal scenarios with worse losses for both agents. The authors then show that an known algorithm LookAhead (Zhang & Lesser (2010)) has local convergence to SPF. However, LookAhead does not have the capacity to exploit opponent dynamics and encourage cooperation. To alleviate this issue, the authors propose a new algorithm SOS, which can be seen as an interpolation between LOLA and LookAhead, characterized by a parameter p. The authors also discuss how to choose the parameter p and prove that SOS will have local convergence to SFP and can avoid strict saddles.  \n\nOverall, this paper is well-written and develops algorithms for a well-motivated problem. Although I am not an expert on this topic, the paper seems interesting to me. \n\nMinor Comment:\nFirst paragraph in Section 2.2, \"It is highly undesirable to converge to Nash in this game\" -> Nash equilibria \n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper652/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "cdate": 1542234410807, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335772699, "tmdate": 1552335772699, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BkeyQHEcnQ", "original": null, "number": 1, "cdate": 1541190934660, "ddate": null, "tcdate": 1541190934660, "tmdate": 1541533805053, "tddate": null, "forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "content": {"title": "Stable Opponent Shaping in Differentiable Games ", "review": "This paper introduces a new algorithm for differential game, where the goal is to find a optimize several objective functions simultaneously in a game of n players. The proposed algorithm is an interpolation between LOLA and LookAhead, and it perserves both the stability from LOLA and the \"convergence to fixed point\" property of LookAhead. The interpolation parameter is chosen in Section 3.2.\n\nThe paper looks novel, though some notations are not completely clear to me. For example, the defintions of the \"current parameters\" \\hat{\\theta}_1 and \\hat{\\theta}_2 in Section 3.1, and the stop-gradient operator. Also, how is the diag operator in Propostion 1 is defined? Normally it only represents the diagonal entries but here it might represent the diagonal blocks.\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Conference/Paper652/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stable Opponent Shaping in Differentiable Games", "abstract": "A growing number of learning methods are actually differentiable games whose players optimise multiple, interdependent objectives in parallel \u2013 from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in these games, accounting for player influence on others\u2019 updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm that exploits this response and leads to cooperation in settings like the Iterated Prisoner\u2019s Dilemma. Although experimentally successful, we show that LOLA agents can exhibit \u2018arrogant\u2019 behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all (n-player, non-convex) games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead converges locally to equilibria and avoids strict saddles in all differentiable games. SOS inherits these essential guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.", "keywords": ["multi-agent learning", "multiple interacting losses", "opponent shaping", "exploitation", "convergence"], "authorids": ["ahp.letcher@gmail.com", "jakobfoerster@gmail.com", "dbalduzzi@google.com", "tim.rocktaeschel@gmail.com", "shimon.whiteson@cs.ox.ac.uk"], "authors": ["Alistair Letcher", "Jakob Foerster", "David Balduzzi", "Tim Rockt\u00e4schel", "Shimon Whiteson"], "TL;DR": "Opponent shaping is a powerful approach to multi-agent learning but can prevent convergence; our SOS algorithm fixes this with strong guarantees in all differentiable games.", "pdf": "/pdf/70c1f902a0584a62f83691cdcb6cd15b62433c8b.pdf", "paperhash": "letcher|stable_opponent_shaping_in_differentiable_games", "_bibtex": "@inproceedings{\nletcher2018stable,\ntitle={Stable Opponent Shaping in Differentiable Games},\nauthor={Alistair Letcher and Jakob Foerster and David Balduzzi and Tim Rockt\u00e4schel and Shimon Whiteson},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SyGjjsC5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper652/Official_Review", "cdate": 1542234410807, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SyGjjsC5tQ", "replyto": "SyGjjsC5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper652/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335772699, "tmdate": 1552335772699, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper652/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}