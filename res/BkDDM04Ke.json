{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028609241, "tcdate": 1490028609241, "number": 1, "id": "r1tHOKpje", "invitation": "ICLR.cc/2017/workshop/-/paper116/acceptance", "forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge\nin machine learning. In this paper we introduce new methods for the improved\ntraining of generative adversarial networks (GANs) for image synthesis.\nWe construct a variant of GANs employing label conditioning that results in\n128 \u00d7 128 resolution image samples exhibiting global coherence. We expand\non previous work for image quality assessment to provide two new analyses for\nassessing the discriminability and diversity of samples from class-conditional image\nsynthesis models. These analyses demonstrate that high resolution samples\nprovide class information not present in low resolution samples. Across 1000\nImageNet classes, 128 \u00d7 128 samples are more than twice as discriminable as artificially\nresized 32 \u00d7 32 samples. In addition, 84.7% of the classes have samples\nexhibiting diversity comparable to real ImageNet data.", "pdf": "/pdf/39d84b2db2411d602a31453dd9c9b34683377037.pdf", "TL;DR": "New GAN architecture that generates samples from all 1000 ImageNet classes. Two new methods for measuring sample quality and diversity.", "paperhash": "odena|conditional_image_synthesis_with_auxiliary_classifier_gans", "conflicts": ["google.com"], "keywords": [], "authors": ["Augustus Odena", "Christopher Olah & Jonathon Shlens"], "authorids": ["augustusodena@google.com", "colah@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028609794, "id": "ICLR.cc/2017/workshop/-/paper116/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028609794}}}, {"tddate": null, "tmdate": 1489188117339, "tcdate": 1489188117339, "number": 2, "id": "rkafBhgsg", "invitation": "ICLR.cc/2017/workshop/-/paper116/official/review", "forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "signatures": ["ICLR.cc/2017/workshop/paper116/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper116/AnonReviewer1"], "content": {"title": "Not much different", "rating": "5: Marginally below acceptance threshold", "review": "This work proposes to add a class label to both the generator and discriminator of the GAN network. This is intuitive, but is NOT novel. Conditioning the posterior distribution on the class label is an old idea. I also agree with the other reviewer that filling the appendix with a lot of new and relevant content is poor form.\n\nThe presentation is a bit sloppy. The curves in Figure 4 are missing a legend.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge\nin machine learning. In this paper we introduce new methods for the improved\ntraining of generative adversarial networks (GANs) for image synthesis.\nWe construct a variant of GANs employing label conditioning that results in\n128 \u00d7 128 resolution image samples exhibiting global coherence. We expand\non previous work for image quality assessment to provide two new analyses for\nassessing the discriminability and diversity of samples from class-conditional image\nsynthesis models. These analyses demonstrate that high resolution samples\nprovide class information not present in low resolution samples. Across 1000\nImageNet classes, 128 \u00d7 128 samples are more than twice as discriminable as artificially\nresized 32 \u00d7 32 samples. In addition, 84.7% of the classes have samples\nexhibiting diversity comparable to real ImageNet data.", "pdf": "/pdf/39d84b2db2411d602a31453dd9c9b34683377037.pdf", "TL;DR": "New GAN architecture that generates samples from all 1000 ImageNet classes. Two new methods for measuring sample quality and diversity.", "paperhash": "odena|conditional_image_synthesis_with_auxiliary_classifier_gans", "conflicts": ["google.com"], "keywords": [], "authors": ["Augustus Odena", "Christopher Olah & Jonathon Shlens"], "authorids": ["augustusodena@google.com", "colah@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489188117991, "id": "ICLR.cc/2017/workshop/-/paper116/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper116/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper116/AnonReviewer2", "ICLR.cc/2017/workshop/paper116/AnonReviewer1"], "reply": {"forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper116/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper116/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489188117991}}}, {"tddate": null, "tmdate": 1489064678637, "tcdate": 1489064678637, "number": 1, "id": "BykxQ0C9g", "invitation": "ICLR.cc/2017/workshop/-/paper116/official/review", "forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "signatures": ["ICLR.cc/2017/workshop/paper116/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper116/AnonReviewer2"], "content": {"title": "Uninsightful and in need of much more work", "rating": "2: Strong rejection", "review": "Let me preface my review by saying that I didn\u2019t read the appendix because I think it is bad form to add a paper worth of additional material to what is supposed to be an extended abstract, and the main text unfortunately did not inspire me to read further either.\n\nThe authors propose to combine two ideas for improving generative modeling with GANs: conditioning the generator on class labels and training the discriminator to reconstruct the labels.\n\nGiven that both ideas are simple and have been used in isolation, the project has little to offer conceptually. This could still be an interesting abstract if it evaluated well the effect of combing both ideas. Unfortunately, this does not seem to be the case. \n\nAny evaluation based on samples is necessarily very limited, as a model which simply stores the training data will score as well as the true distribution of natural images. A more useful comparison would have been to compare samples of two generators with the same architecture and trained on the same data, one trained with the proposed changes and one without.\n\nThe value of the analysis in Figure 2 is not at all clear to me. Showing the effect of throwing away high-spatial frequency information tells me that the classifier is using that information, and that the generator is not merely interpolating low-resolution images. But it tells me very little about the effectiveness of the proposed changes to GAN training.\n\nThe paper also seems sloppily written. E.g., in the introduction the authors claim that Balle et al. (2015) describe an advance in the state of the art in image denoising. Looking at the paper I couldn\u2019t find such a claim or a comparison to the state of the art (non-parametric methods such as BM3D and discriminative methods such as feed-forwardly trained neural nets). The authors cite Toderici et al. (2016) as an example of image models advancing compression, but to my knowledge this paper uses binarized hidden states of a recurrent neural network and no image model.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge\nin machine learning. In this paper we introduce new methods for the improved\ntraining of generative adversarial networks (GANs) for image synthesis.\nWe construct a variant of GANs employing label conditioning that results in\n128 \u00d7 128 resolution image samples exhibiting global coherence. We expand\non previous work for image quality assessment to provide two new analyses for\nassessing the discriminability and diversity of samples from class-conditional image\nsynthesis models. These analyses demonstrate that high resolution samples\nprovide class information not present in low resolution samples. Across 1000\nImageNet classes, 128 \u00d7 128 samples are more than twice as discriminable as artificially\nresized 32 \u00d7 32 samples. In addition, 84.7% of the classes have samples\nexhibiting diversity comparable to real ImageNet data.", "pdf": "/pdf/39d84b2db2411d602a31453dd9c9b34683377037.pdf", "TL;DR": "New GAN architecture that generates samples from all 1000 ImageNet classes. Two new methods for measuring sample quality and diversity.", "paperhash": "odena|conditional_image_synthesis_with_auxiliary_classifier_gans", "conflicts": ["google.com"], "keywords": [], "authors": ["Augustus Odena", "Christopher Olah & Jonathon Shlens"], "authorids": ["augustusodena@google.com", "colah@google.com", "shlens@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489188117991, "id": "ICLR.cc/2017/workshop/-/paper116/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper116/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper116/AnonReviewer2", "ICLR.cc/2017/workshop/paper116/AnonReviewer1"], "reply": {"forum": "BkDDM04Ke", "replyto": "BkDDM04Ke", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper116/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper116/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489188117991}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1487365672321, "tcdate": 1487360607316, "number": 116, "id": "BkDDM04Ke", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "BkDDM04Ke", "original": "rJXTf9Bxg", "signatures": ["~Augustus_Odena1"], "readers": ["everyone"], "content": {"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge\nin machine learning. In this paper we introduce new methods for the improved\ntraining of generative adversarial networks (GANs) for image synthesis.\nWe construct a variant of GANs employing label conditioning that results in\n128 \u00d7 128 resolution image samples exhibiting global coherence. We expand\non previous work for image quality assessment to provide two new analyses for\nassessing the discriminability and diversity of samples from class-conditional image\nsynthesis models. These analyses demonstrate that high resolution samples\nprovide class information not present in low resolution samples. Across 1000\nImageNet classes, 128 \u00d7 128 samples are more than twice as discriminable as artificially\nresized 32 \u00d7 32 samples. In addition, 84.7% of the classes have samples\nexhibiting diversity comparable to real ImageNet data.", "pdf": "/pdf/39d84b2db2411d602a31453dd9c9b34683377037.pdf", "TL;DR": "New GAN architecture that generates samples from all 1000 ImageNet classes. Two new methods for measuring sample quality and diversity.", "paperhash": "odena|conditional_image_synthesis_with_auxiliary_classifier_gans", "conflicts": ["google.com"], "keywords": [], "authors": ["Augustus Odena", "Christopher Olah & Jonathon Shlens"], "authorids": ["augustusodena@google.com", "colah@google.com", "shlens@google.com"]}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "original": {"tddate": null, "replyto": null, "ddate": null, "active": true, "tmdate": 1477972667027, "tcdate": 1477972667018, "number": 27, "id": "rJXTf9Bxg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJXTf9Bxg", "signatures": ["~Augustus_Odena1"], "readers": ["everyone"], "content": {"title": "Conditional Image Synthesis With Auxiliary Classifier GANs", "abstract": "Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.", "pdf": "https://arxiv.org/pdf/1610.09585v1.pdf", "TL;DR": "We introduce a special GAN architecture that results in high quality 128x128 ImageNet samples; we introduce 2 new quantitative metrics of sample quality.", "paperhash": "odena|conditional_image_synthesis_with_auxiliary_classifier_gans", "keywords": ["Deep learning"], "conflicts": ["google.com"], "authors": ["Augustus Odena", "Christopher Olah", "Jonathon Shlens"], "authorids": ["augustusodena@google.com", "colah@google.com", "shlens@google.com"]}, "writers": [], "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}