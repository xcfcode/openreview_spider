{"notes": [{"id": "H1ebhnEYDH", "original": "SJxYvZFZDB", "number": 178, "cdate": 1569438888850, "ddate": null, "tcdate": 1569438888850, "tmdate": 1583912021636, "tddate": null, "forum": "H1ebhnEYDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "NiXjfjM_ff", "original": null, "number": 1, "cdate": 1576798689467, "ddate": null, "tcdate": 1576798689467, "tmdate": 1576800945680, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "All the reviewers found the paper to contain an interesting idea with insightful experiments. The rebuttal further improved confidence of the reviewers. The paper is accepted.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795730246, "tmdate": 1576800283000, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper178/-/Decision"}}}, {"id": "rkl8oJhKsS", "original": null, "number": 7, "cdate": 1573662621965, "ddate": null, "tcdate": 1573662621965, "tmdate": 1573662621965, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "S1xzZE9DoB", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Thanks", "comment": "Thanks for the response and for adding the result on ImageNet. I will keep my score as weak accept and support the acceptance of this work. \n\nI think this paper has an interesting perspective and many solid experiments to justify the existence of bias. This paper could be a good contribution to ICLR'20. "}, "signatures": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer4", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "r1eaIOsFoB", "original": null, "number": 6, "cdate": 1573660757446, "ddate": null, "tcdate": 1573660757446, "tmdate": 1573660757446, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "Hyl3w6GSjH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Further discussion on Bashivan et al., and related works", "comment": "Bashivan et al. mention two limitations of ANNs, lack of interpretability and weak generalization. \nThey used an ANN (matched to data) to synthesize novel \u201ccontroller\u201d images based on the model\u2019s implicit knowledge of the ventral visual stream. The ANN was used it to construct images predicted to either broadly activate large populations of neurons or selectively activate one population while keeping the others unchanged. \n\nIn addition to activation maximization (called stretch method in their paper), Bashivan et al use another method they call \"one-hot population\u201d that tries to maximize the activity of a v4 neuron while maximally suppressing \nactivity of other neurons. The latter is reminiscent of some theories of neural coding in visual search (e.g., optimal gain theory; Navalpakkam and Itti, Neuron 2007). While both methods were effective, the synthesized images by the latter approach seem to have more structures in them.\n\nSome of our analysis here suggest complementary experiments to works in this real.\nFor example, we were able to find the biases in each layer of a CNN by sending noise throughout the network. We could then add these biases to a particular layer of neurons when an image was presented to the network which led to biasing the final decision of the network in some cases (See Figs 20 and 21 in the supplement). Perhaps approaches like this (i/e., adding bias to all neurons in a layer or increasing gains of individual neurons based on their activations; multiplicative gain) can be also tested in electrophysiology by using neural-data matched CNNs, akin to Bashivan et al.\u2019 work. Further, our computational analysis on microstimulating neurons in different layers of CNNs provides an opportunity to assess how well CNNs can explain neural data, for example by using biases computed from models to drive a neuron when stimulus is augmented with noise (See Fig. 9 main text and Figs 23-25 supplement).\n\nWe believe this path in using models and neurophysiology in a closed-loop manner is very promising in improving our understanding of deep neural networks, in particular CNNs, and holds a great promise for brain-computer interfacing. Further, our work opens an opportunity to relate several areas in computational neuroscience and deep learning (adversarial ML, visual search, neural coding, microsimulation, neural models of ventral stream, and BCI)."}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "rylmiRMHor", "original": null, "number": 3, "cdate": 1573363355227, "ddate": null, "tcdate": 1573363355227, "tmdate": 1573660387732, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "rJg3yGj6FB", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Insights and computational complexity/run-time", "comment": "> As the authors clearly state, the techniques used are not novel (they have been used\nin neuroscience) but the results are interesting. \n\nThat is true. These are well-established sound tools in neurosciences and are quite popular. We have contributed in several ways. First, we \nconduct the first white noise analysis of deep neural networks, in fact any type of neural network, to the best of our knowledge. Second, we show that these tools are quite efficient in understanding a black box system in terms of gaining a first order approximation of its functionality, influencing its response, as well as diagnosing backdoor attacks. Third, we show, again for the first time, that deep neural networks show a similar behavior as humans during microsimulation, yet another evidence that deep networks might indeed be a decent model of the nervous system (at least in the visual domain). Our work looks at the problem from a basic science perspective and provides tangible engineering applications, perhaps not the state of the art but with high potential to improve upon. We believe these are important insights here that can drive future research in this direction and in bridging research on biological and artificial neural networks.\n\n\n\n\n>  How long does it take (and with what hardware) to create the classification images for the trojan networks?  \nIt takes about 9 minutes, on a single 2080Ti GPU with 11G RAM, to feed 1 million CIFAR10 RGB images (32 x 32 pixels; batch size 250) to compute the bias maps. The corresponding number for MNIST gray images (28 x 28 pixels) is about 2 minutes. Using the Gabor filter technique (section 3.1, page 5; and appendix), we were able to cut these numbers down to 25 seconds, including both PCA and bias computation steps. As is shown in Figure 14 (Supplement), 100K samples is enough to reveal the bias in a CNN. We will add and thoroughly discuss computational complexity of our approach to the paper.\n\n\nPlease see also our response to the Reviewer #4 and #1."}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "S1xzZE9DoB", "original": null, "number": 5, "cdate": 1573524473747, "ddate": null, "tcdate": 1573524473747, "tmdate": 1573524522087, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "HkgkErQSiB", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Results on ImageNet!", "comment": "We conducted new experiments to test the proposed methods on large scale recognition datasets. ImageNet validation set including 50K images covering 1000 categories and 1M samples using Gabor PCA sampling and deep CNNs pretraiend on ImageNet train set, were utilized.\n\n\nAs results in the table below show, even with 1M samples, and without parameter tuning, we can get an improvement over the chance level  which is 0.0010 or 0.1%. We obtain 2x better accuracy than the chance using ResNet152. It seems that 1M samples is not enough to cover all classes. For example, no noise pattern gets classified under almost half of the classes using ResNet152. For some other models, even a larger number of classes remain empty (yet another evidence that white noise can reveal biases in models). We believe it is possible to improve these results with more samples. As you can see with more number of classes filled, a better accuracy can be achieved. It takes only few minutes (about 2) to process all 1M images at resolution 32 x 32. Notice that ImageNet models have been trained on 224 x 224 images, while here we test them on 32 x 32 images for the sake of computational complexity. A better way would be to train the models on 32 x 32 images or feed the noise at 224 x 224 resolution. This may takes more time but may result in better performance. \n\nRegarding the generated filters, we found that the same types of edge detectors emerge in the early layer of CNNs just like the ones we observed over CIFAR10 dataset.\n\n\nBackbone\t\tAccuracy\t       Run Time\t    Number of classes with 0 samples \n----------------------------------------------------------------------------------------------------------------------------\nResNet152 \t\t0.00180\t    \t\t2:15 mins           564\nResNet101 \t\t0.00152\t    \t\t1:36 mins           539\ndensenet201\t\t0.00118\t    \t\t2:12 mins           998\nsqueezenet1_1\t0.00104\t    \t\t0:13 mins           999\ngooglenet\t        0.00102\t    \t\t0:26 mins           999\nmnasnet1_3          0.00082\t\t\t0:32 mins           922\nvgg_19_bn\t\t0.00074\t\t\t1:51 mins           994\n\n\n\n\nOverall, our pilot investigation on large scale datasets are promising. We believe better results than the ones reported above are possible with further modifications (e.g., using better distance measures between an image and the average noise map for each class). Also, it is highly likely that increasing the number of samples (white noise inputs) will lead to better performance. \n\n\nWe will add these results in the paper and will discuss them. "}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "HkgkErQSiB", "original": null, "number": 4, "cdate": 1573365031489, "ddate": null, "tcdate": 1573365031489, "tmdate": 1573365031489, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "BJlIMrw3cS", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Limitations of the approach", "comment": "We thank the reviewer for the constructive feedback. \n\nWe have scratched the surface of possibilities for employing tools from computational neuroscience and psychology for machine learning and computer vision, especially for understanding and improving ANNs (it is actually a two-way street!). We will further discuss other tools, techniques, and ideas that researchers can borrow from neuroscience to improve deep learning models (e.g., normalization techniques, short and long range dependencies; Linsley et al).\n\n> 1. One concern I have is that the result on CIFAR-10 is not interpretable ... \n\nNotice that since we generate the white noise input completely random for all three color channels, the resulting average is inevitably jittered. Averaging images also does not represent objects\u2019 higher level structures, especially when the data is not calibrated. Although the mean noise maps are not visually interpretable, they do contain useful information that can used for classification and attack diagnosis.\nThe higher layers are visualized through averaging the input white noise that triggered that particular filter, instead of giving real images. That is why visualizations in Figure 8 resemble lower level features. STA can not fully characterize the type of stimuli a neuron in mid and higher layers responds to. It is average response. Other techniques such as spike triggered covariance aim to find dimensions to which a neuron responds to, akin to visualization methods in ANNs (e.g., Zeiler et al., 2014). \n\nThis is the major limitation of these techniques and is well-known in the literature. It is in fact the main reason why they have not been widely adopted to natural scenes. Here, we tried to mitigate this limitation by generating noise patterns with faint strutters. We were able to gain significantly better results using much less number of samples. See Figure 4.\n\nNonetheless, despite these limitations, these tools are very effective, in particular when we other options are off the table (i.e., no assumptions can be made). This makes them quite appealing to inspect black-box adversarial attacks. We will add these comments and more discussions to the main text.\n\n> 2. The inferior result on CIFAR-10 might indicate  ...\n\nObjects in datasets like ImageNet are uncentered and uncalibrated, which will result in losing too much information through averaging, making them unsuitable to apply this particular technique.\n\nAs we discussed above, we do not expect to obtain bias maps that look quite like target classes (using STA). Why not? Because even averaging the real samples does not lead to anything visually meaningful! Nonetheless, the computed bias maps contain rich information that can be used for classification and also to inspect models. For example, a model that performs close to random will not be able to generate bias maps that are informative. On the other hand, a perfect classifier will generate bias maps equal to mean images (i.e.,upper-bound is the mean images). As a result, we do not expect the bias maps to improve much with AlexNet or even ResNet beyond what mean images already provide. What we aimed to convey was mainly the point that bias maps indeed contain significant information and are useful for a number of purposes.\n\n> 3. There is no comparison for other bias visualization ...\n\nThis is what we have actually done. There is a subtlety here, though. In psychophysics experiments, usually signal is embedded in white noise and tasks are usually binary. The main reason is to lower the number of trials. For artificial classifiers, however, we do not have this limitation. Thus, we can bombard a classifier with tons of just noise patterns in large scale (even multi-way classifiers).\n\nThe mean images we showed are conditioned on the predicted labels, namely we average noise that are predicted into a certain class to get the classification image of that class. We believe for well-calibrated datasets like MNIST and FashionMNIST, the results are very similar to psychophysics results: class difference are highlighted and common parts are disregarded (darker color). In neuroscience experiments, the designed stimuli are also often centered and calibrated. Higher-level biases (e.g., semantic level instead of shape level) might not be detected.\n\nAlso, there are really not many ways to pinpoint the biases of neural networks. We would be happy to try new ones if you can suggest some.\n\nRegarding the limitations and failures of the approach, we have clearly stated them in the paper in several occasions. For example, the method has a high sample complexity to work well but can be mitigated to some extent. At the end of the day these tools have some pros and cons, but are certainly a nice addition to the deep learning toolbox.\n\nReference:\n-Linsley,et al., Learning long-range spatial dependencies with horizontal gated recurrent units, NIPS 2018\n-Zeiler, et al. Visualizing and understanding convolutional networks. ECCV.  2014."}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "Hyl3w6GSjH", "original": null, "number": 2, "cdate": 1573363044142, "ddate": null, "tcdate": 1573363044142, "tmdate": 1573363044142, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "HyxVi6e0tB", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Further discussion on confluence of biological and artificial neural networks and future potentials", "comment": "Thank you for constructive feedback.\n\n> what is the difference between other more frequent approaches such as activation maximization and the approach the authors present. \n What could we understand with these tools that cannot be understood through activation maximization (i.e. using backprop to find optimal stimuli)? \n \nThe main difference lies in the types of assumptions and available information about a system. Almost all activation maximization models assume access to the gradients as well as network response whereas here we only need the latter. \n\n \n \n > One problem with classification images is that the pattern is limited to low level patterns unless the random images have structure in them. The authors solve this problem using more complex random sample (e.g. with Gabor features). But a more in depth discussion is necessarily about the additional understanding that is procured from such an approach in comparison to activation maximization. It's an important discussion because even neuroscientists are now interested (and finally able) to properly perform activation maximization to test their hypotheses more strongly (see Bashivan et al 2019 science for a great example). \n \n\nBashivan et al 2019 is indeed a very interesting work. \nThe technique they used is activation maximization from the original 2009 paper (Erhan et al.). They iteratively changed the pixel values in the direction of the gradient to maximize the firing rate. This requires gradient obviously. The interesting point of the paper is building the mapping between ANN and V4 neurons, so as to achieve better understanding of brain network functions using ANNs. Our goal is the opposite, namely using human visual methods to understand a blackbox ANN. We believe our approach can be useful to improve such activation maximization approaches. For example, instead of working in pixel domain, perhaps activation maximization can be applied on subtle image structures to Lower sample complexity. This is very important when dealing with human subjects in behavioral experiments or animals in electrophysiology experiments. Other than that, we believe our work carries immense potential for psychiatric applications to study the behavior of patients and diagnosis.\n\n\n\n\n> Even though I think the lack of this discussion is currently a limitation, I think this paper is a good opportunity to have this discussion and bring together the specifics of these two different approaches.\n Thanks for the suggestion. We will indeed discuss this more thoroughly in section 4 and invite other researchers to comment on this.\n\n\n\nReference:\nErhan, Dumitru, et al. \"Visualizing higher-layer features of a deep network.\" University of Montreal 1341.3 (2009): 1.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "S1xgFFGBiB", "original": null, "number": 1, "cdate": 1573362040186, "ddate": null, "tcdate": 1573362040186, "tmdate": 1573362040186, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "r1loJKssqB", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment", "content": {"title": "Impact and potential for future", "comment": "Thank you very much for the encouragement. \n\n> Interpretability is a very important problem and the authors present ways of thinking about it from the lens of computational neuroscience. This paper has the potential to inspire future research in this direction.\n\nWe have indeed introduced new tools, borrowed from computational neuroscience, to the artificial neural networks community. These are quite interesting, powerful, and general tools with high potential for defending against adversarial attacks as well as interpreting neural networks, not only in the visual domain but also other areas.\n\n \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1ebhnEYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper178/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper178/Authors|ICLR.cc/2020/Conference/Paper178/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175201, "tmdate": 1576860529093, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper178/Authors", "ICLR.cc/2020/Conference/Paper178/Reviewers", "ICLR.cc/2020/Conference/Paper178/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Comment"}}}, {"id": "rJg3yGj6FB", "original": null, "number": 1, "cdate": 1571824099704, "ddate": null, "tcdate": 1571824099704, "tmdate": 1572972628961, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper uses classification images and spike triggered averages to\nreveal hidden structure in deep neural networks.  As the authors\nclearly state, the techniques used are not novel (they have been used\nin neuroscience) but the results are interesting.\n\nOne interesting aspect is that the classification image technique is\nquite good (better than the average gradient of the classification\nloss with respect to the image) at revealing trojan (adversarial\npatch) networks - networks trained with trojan patches that change the\nclassified class of the image - (and the area of the trojan attack).\nHow long does it take (and with what hardware) to create the\nclassification images for the trojan networks?\n\nThe authors also show how the method can be used for black-box adversarial\nattacks without need for gradients or logits and model microstimulation\nexperiments.\n\nI don't feel there is quite enough insights here for ICLR publication.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910950954, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper178/Reviewers"], "noninvitees": [], "tcdate": 1570237755904, "tmdate": 1575910950967, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Review"}}}, {"id": "HyxVi6e0tB", "original": null, "number": 2, "cdate": 1571847580139, "ddate": null, "tcdate": 1571847580139, "tmdate": 1572972628919, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This is an interesting paper that uses two techniques from neuroscience (eletrophysiology) to interpret CNNs. The \"classification images\" technique allows the authors to build an input specific bias map for CNNs, from different images that are randomly generated using different methods. STA is also used to visualize filters. The authors find interesting similarities between CNNs and animal/human brain such as the shift of the psychometric curve. The paper is well written and the experiments are thorough.\n\nThis paper has comprehensive use of neuroscience method, nicely bringing the two fields together. Even though the authors mention other approaches, perhaps one weakness is the limited discussion of other visualization tools: what is the difference between other more frequent approaches such as activation maximization and the approach the authors present. What could we understand with these tools that cannot be understood through activation maximization (i.e. using backprop to find optimal stimuli)? One problem with classification images is that the pattern is limited to low level patterns unless the random images have structure in them. The authors solve this problem using more complex random sample (e.g. with Gabor features). But a more in depth discussion is necessarily about the additional understanding that is procured from such an approach in comparison to activation maximization. It's an important discussion because even neuroscientists are now interested (and finally able) to properly perform activation maximization to test their hypotheses more strongly (see Bashivan et al 2019 science for a great example). \n\nEven though I think the lack of this discussion is currently a limitation, I think this paper is a good opportunity to have this discussion and bring together the specifics of these two different approaches.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910950954, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper178/Reviewers"], "noninvitees": [], "tcdate": 1570237755904, "tmdate": 1575910950967, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Review"}}}, {"id": "r1loJKssqB", "original": null, "number": 3, "cdate": 1572743395256, "ddate": null, "tcdate": 1572743395256, "tmdate": 1572972628877, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary:\nThis paper introduces two tools from spike analysis to understand the bias neural networks have. The first tool is classification images and the second, spike-triggered analysis.\n\nThe broad goal of the paper is to add more tooling to add interpretability and robustness to a neural network.\n\nClassification images can be summarized as: Produce a stimulus from the sum of a signal image and a noise image. Then average the response over many trials to determine what template the network used.\n\nSpike-triggered analysis can be understood as measuring a neuron's response to time-varying stimuli (ie: neuron responding to a line) which scopes out the receptive field.\n\nThe paper is well written. Experimentation section is thorough. The related work is well discussed.\nThe overall techniques are interesting and can help the community think about interpretability by using tools from related disciplines.\n\nDecision:\nAccept\n\nReasoning:\nInterpretability is a very important problem and the authors present ways of thinking about it from the lens of computational neuroscience. This paper has the potential to inspire future research in this direction.\n\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910950954, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper178/Reviewers"], "noninvitees": [], "tcdate": 1570237755904, "tmdate": 1575910950967, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Review"}}}, {"id": "BJlIMrw3cS", "original": null, "number": 4, "cdate": 1572791565637, "ddate": null, "tcdate": 1572791565637, "tmdate": 1572972628832, "tddate": null, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "invitation": "ICLR.cc/2020/Conference/Paper178/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This work inspects the bias existing in the neural network classifiers through two techniques from computational neuroscience, the classification image techniques and spike-triggered covariance (STA) analysis. The classification image is generated as the difference map between all the averaged images with predicted classes under noise perturbation. STA is used to generate the eigenvector as the input and response, as a visualization. Both of the tools are the standard psychophysics tools. \n\nThe authors use the two tools to visualize the bias learned by various classifiers, CNN, MLP, and logistic regression, trained on three datasets MNIST, Fashion-MNIST and CIFAR 10. There are interesting patterns that emerged from the classifiers trained on MNIST and Fashion-MNIST by the classification image technique, but the result from the CIFAR 10 is not explainable. The classification image is further used to analyze the adversarial attack and defense while STA is used to visualize the internal units. \n\nStrengths:\nThe paper is well-written and easy to follow. With detailed and complete psychophysics experiments, several interesting properties of the filters and the biases of the neural network classifiers are revealed. It is great to see that more tools from psychophysics can be applied to understand neural network classifiers.\n\nWeakness:\n1. One concern I have is that the result on CIFAR-10 is not interpretable. See figure 3. On the other hand, the visualization of filters in higher layers (conv4 and conv6) from the net trained on CIFAR-10 in Figure 8 still looks like edge detectors. There are not so many discussions and explanations on what possibly happened here. \n\n2. The inferior result on CIFAR-10 might indicate that the techniques cannot be generalized to interpret large-scale networks such as AlexNet or resnet, trained on ImageNet or Places. It is 2019 now, I expect to see more experiments on at least AlexNet or VGG, rather than tiny sets MNIST or CIFAR. I will suggest the authors run experiments on AlexNet trained on ImageNet/Places, then we can compare the visualization with the other filter visualization to see the difference.\n\n3. There is no comparison for other bias visualization methods. Following the idea of mean images, I think you can also show the mean images conditional on the predicted labels (average all the testing images with certain predicted labels). How the result from the psychophysics is different from that? How well the proposed methods are able to identify the bias? What other bias cannot be identified? Some discussions on the failure cases would be appreciated\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper178/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["aliborji@gmail.com", "sikun@ucsb.edu"], "title": "White Noise Analysis of Neural Networks", "authors": ["Ali Borji", "Sikun Lin"], "pdf": "/pdf/5120942744671f7a1fe805ca238fdf3520036552.pdf", "abstract": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our analysis is\nbased on two popular and related methods in psychophysics and neurophysiology\nnamely classification images and spike triggered analysis. These methods have\nbeen widely used to understand the underlying mechanisms of sensory systems\nin humans and monkeys. We leverage them to investigate the inherent biases of\ndeep neural networks and to obtain a first-order approximation of their functionality.\nWe emphasize on CNNs since they are currently the state of the art methods\nin computer vision and are a decent model of human visual processing. In\naddition, we study multi-layer perceptrons, logistic regression, and recurrent neural\nnetworks. Experiments over four classic datasets, MNIST, Fashion-MNIST,\nCIFAR-10, and ImageNet, show that the computed bias maps resemble the target\nclasses and when used for classification lead to an over two-fold performance than\nthe chance level. Further, we show that classification images can be used to attack\na black-box classifier and to detect adversarial patch attacks. Finally, we utilize\nspike triggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our\neffort illustrates a successful example of borrowing from neurosciences to study\nANNs and highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience.", "keywords": ["Classification images", "spike triggered analysis", "deep learning", "network visualization", "adversarial attack", "adversarial defense", "microstimulation", "computational neuroscience"], "paperhash": "borji|white_noise_analysis_of_neural_networks", "code": "https://github.com/aliborji/WhiteNoiseAnalysis.git", "_bibtex": "@inproceedings{\nborji2020unveiling,\ntitle={Unveiling Hidden Biases in Deep Networks with Classification Images and Spike Triggered Analysis},\nauthor={Ali Borji and Sikun Lin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1ebhnEYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/221c2ff9cbef0736840efc810f545bf2ae69996e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1ebhnEYDH", "replyto": "H1ebhnEYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper178/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910950954, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper178/Reviewers"], "noninvitees": [], "tcdate": 1570237755904, "tmdate": 1575910950967, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper178/-/Official_Review"}}}], "count": 13}