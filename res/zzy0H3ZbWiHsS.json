{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1362725700000, "tcdate": 1362725700000, "number": 3, "id": "qbjSYWhow-bDl", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzy0H3ZbWiHsS", "replyto": "zzy0H3ZbWiHsS", "signatures": ["\u80e1\u632f"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Thank you. We will revise our paper as soon as possible.\r\n\r\nZhen"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Audio Artist Identification by Deep Neural Network", "abstract": "Since officially began in 2005, the annual Music Information Retrieval Evaluation eXchange (MIREX) has made great contributions to the Music Information Retrieval (MIR) research. By defining some important tasks and providing a meaningful comparison system, the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), organizer of the MIREX, drives researchers in the MIR field to develop more advanced system to fulfill the tasks. One of the important tasks is the Audio Artist Identification task, or the AAI task. We implemented a Deep Belief Network (DBN) to identify the artist by audio signal. As a matter of copyright, IMIRSEL didn't publish there data set and we had to construct our own. In our data set we got an accuracy of 69.87% without carefully choosing parameters while the best result reported on MIREX is 69.70%. We think our method is promising and we want to discuss with others.", "pdf": "https://arxiv.org/abs/1301.3195", "paperhash": "|audio_artist_identification_by_deep_neural_network", "keywords": [], "conflicts": [], "authors": ["\u80e1\u632f", "Kun Fu", "Changshui Zhang"], "authorids": ["eblis.hu@gmail.com", "Tsinghua Univ.", "Tsinghua Univ."]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362479820000, "tcdate": 1362479820000, "number": 1, "id": "Zg8fgYb5dAUiY", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzy0H3ZbWiHsS", "replyto": "zzy0H3ZbWiHsS", "signatures": ["anonymous reviewer 589d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Audio Artist Identification by Deep Neural Network", "review": "A brief summary of the paper\u2019s contributions. In the context of prior work:\r\nThis paper builds a hybrid model based on Deep Belief Network (DBN) and Stacked Denoising Autoencoder (SDA) and applies it to Audio Artist Identification (AAI) task. Specifically, the proposed model is constructed with a two-layer SDA in the lower layers, a two-layer DBN in the middle, and a logistic regression classification layer on the top. The proposed model seems to achieve good classification performance.\r\n\r\n\r\nAn assessment of novelty and quality:\r\nThe paper proposes a hybrid deep network by stacking denoising autoencoders and RBMs.\r\nAlthough this may be a new way of building a deep network, it seems to be a minor modification of the standard methods. Therefore, the novelty seems to be limited.\r\n\r\nMore importantly, motivation or justification about hybrid architecture is not clearly presented. Without a clear motivation or justification, this method doesn\u2019t seem to be technically interesting. To make a fair comparison to other baseline methods, the SDA2-DBN2 should be compared to DBN4 or SDA4, but there are no such comparisons.\r\n\r\nAlthough the classification performance by the proposed method is good, the results are not directly comparable to other work in the literature. It will be helpful to apply some widely used methods in authors\u2019 data set as additional control experiments;\r\n\r\nThe paper isn\u2019t well polished. There are many awkward sentences and grammatical errors.\r\n\r\n\r\nOther comments:\r\nFigure 2 is anecdotal and is not convincing enough.\r\n\r\nAuthors use some non-standard terminology. For example, what does \u201cMAP paradigm\u201d mean?\r\n\r\nIn Table 3, rows corresponding to \u201c#DA layers\u201d, \u201c#RBM layers\u201d, \u201c#logistic layers\u201d are unnecessary.\r\n\r\n\r\n\r\nA list of pros and cons (reasons to accept/reject)\r\n\r\npros:\r\n+ Literature review seems fine.\r\n+ good (but incomplete) empirical classification results\r\n\r\ncons:\r\n- lack of clear motivation or justification of the hybrid method; lack of proper control experiments\r\n- the results are not comparable to other published work\r\n- unpolished writing (lots of awkward sentences and grammatical errors)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Audio Artist Identification by Deep Neural Network", "abstract": "Since officially began in 2005, the annual Music Information Retrieval Evaluation eXchange (MIREX) has made great contributions to the Music Information Retrieval (MIR) research. By defining some important tasks and providing a meaningful comparison system, the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), organizer of the MIREX, drives researchers in the MIR field to develop more advanced system to fulfill the tasks. One of the important tasks is the Audio Artist Identification task, or the AAI task. We implemented a Deep Belief Network (DBN) to identify the artist by audio signal. As a matter of copyright, IMIRSEL didn't publish there data set and we had to construct our own. In our data set we got an accuracy of 69.87% without carefully choosing parameters while the best result reported on MIREX is 69.70%. We think our method is promising and we want to discuss with others.", "pdf": "https://arxiv.org/abs/1301.3195", "paperhash": "|audio_artist_identification_by_deep_neural_network", "keywords": [], "conflicts": [], "authors": ["\u80e1\u632f", "Kun Fu", "Changshui Zhang"], "authorids": ["eblis.hu@gmail.com", "Tsinghua Univ.", "Tsinghua Univ."]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362226800000, "tcdate": 1362226800000, "number": 4, "id": "k3fr32tl6qARo", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzy0H3ZbWiHsS", "replyto": "zzy0H3ZbWiHsS", "signatures": ["anonymous reviewer b7e1"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Audio Artist Identification by Deep Neural Network", "review": "This paper describes work to collect a new dataset with music from 11 classical composers for the task of audio composer identification (although the title, abstract, and introduction use the phrase 'audio artist identification' which is a different task).  It describes experiments training a few different deep neural networks to perform this classification task.\r\n\r\nThe paper is not very novel.  It describes existing deep architectures applied to a new version of an existing dataset for an existing task.\r\n\r\nThe quality of the paper is not very high.  The comparisons of the models were not systematic and because it is a new dataset, they cannot be compared directly to results on other datasets of existing models.  There are very few specifics given about the models used (layer sizes, cost functions, input feature types, specific input features).\r\n\r\nThe use of mel frequency spectrum seems dubious for this task.  What distinguishes classical works from different composers is generally harmonic and melodic content, which mel frequency spectrum ignores almost entirely.\r\n\r\nFew details are given about the make-up of the new dataset.  Are these orchestral pieces, chamber pieces, concertos, piano pieces, etc?  How many clips came from each piece?  How many clips came from each movement?  The use of clips from different movements of the same piece in the training and test sets might account for the increase in accuracy scores relative to previous MIREX results.  Movements from the same piece generally share many characteristics like recording conditions, production, instrumentation, and timbre, which are the main characteristics captured by mel frequency spectrum.  They also generally share harmonic and melodic content.\r\n\r\nAnd finally, the 'Three B's' that the authors refer to, Bach, Beethoven, and Brahms, are very different composers from different musical eras.  Their works should not be easily confused with each other, and so the fact that the proposed algorithm does confuse them is concerning.  Potentially it indicates the weakness of the mel spectrum for performing this task.\r\n\r\nPros:\r\n- Literary presentation of the paper is high (although there are a number of strange word substitutions)\r\n- Decent summary of existing work\r\n- New dataset might be useful, if it is made public, although it is pretty small\r\n\r\nCons:\r\n- Little novelty\r\n- Un-systematic comparisons of systems\r\n- Features don't make much sense\r\n- Few details on actual systems compared and on the dataset\r\n- Few generalizable conclusions"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Audio Artist Identification by Deep Neural Network", "abstract": "Since officially began in 2005, the annual Music Information Retrieval Evaluation eXchange (MIREX) has made great contributions to the Music Information Retrieval (MIR) research. By defining some important tasks and providing a meaningful comparison system, the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), organizer of the MIREX, drives researchers in the MIR field to develop more advanced system to fulfill the tasks. One of the important tasks is the Audio Artist Identification task, or the AAI task. We implemented a Deep Belief Network (DBN) to identify the artist by audio signal. As a matter of copyright, IMIRSEL didn't publish there data set and we had to construct our own. In our data set we got an accuracy of 69.87% without carefully choosing parameters while the best result reported on MIREX is 69.70%. We think our method is promising and we want to discuss with others.", "pdf": "https://arxiv.org/abs/1301.3195", "paperhash": "|audio_artist_identification_by_deep_neural_network", "keywords": [], "conflicts": [], "authors": ["\u80e1\u632f", "Kun Fu", "Changshui Zhang"], "authorids": ["eblis.hu@gmail.com", "Tsinghua Univ.", "Tsinghua Univ."]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362137160000, "tcdate": 1362137160000, "number": 2, "id": "obqUAuHWC9mWc", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzy0H3ZbWiHsS", "replyto": "zzy0H3ZbWiHsS", "signatures": ["anonymous reviewer 8eb9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Audio Artist Identification by Deep Neural Network", "review": "This paper present an application of an hybrid deep learning model to the task of audio artist identification.\r\n\r\nNovelty:\r\n+ The novelty of the paper comes from using an hybrid unsupervised learning approach by stacking Denoising Auto-Encoders (DA) and Restricted Boltzman Machines (RBM). \r\n= Another minor novelty is the application of deep learning to artist identification. However, deep learning has already been applied to similar tasks before such as genre recognition and automatic tag annotation.\r\n- Unfortunately, I found that the major contributions of the paper are not exposed clearly enough in the introduction.\r\n\r\nQuality of presentation:\r\n- The quality of the presentation leaves to be desired. A more careful proofreading would have been required. There are several sentences with gramatical errors. Several verbs or adjectives are wrong. The writing style is also sometimes inadequate for a scientific paper (ex. 'we will review some fantastic work', 'we can build many outstanding networks'). The quality of the english is, in general, inadequate.\r\n- The abstract does not present in a relevant and concise manner the essential points of the paper.\r\n- Also, there is a bit of confusion in between the introduction and related work sections, as most of the introduction is also about related work.\r\n\r\nReference to previous work:\r\n+ Previous related work coverage is good. Previous work in deep learning and its applications in MIR, as well as work in audio artist identification are well covered.\r\n- In the beginning of section 5: 'It's known that Bach, Beethoven and Brahms, known as the three Bs, shared some style when they wrote their composition.' I find this claim, without any reference,  hard to understand.  Bach, Beethoven and Brahms are from 3 different musical eras. How are these 3 composers more related than the others?\r\n\r\nQuality of the research.\r\n- Although the idea of using a hybrid deep learning system might be new, no justification as to why such a system should work better is presented in the paper.\r\n- In the experiments, the authors compare the hybrid model to pure models. However, the pure models all have less layers than the hybrid model. Why didn't the authors compare same-depth models? I feel it would have made a much stronger point.\r\n- Although the authors describe in details the theory behind SDAs and DBNs, there is little to no detail about the hyper-parameters used in the actual model (number of hidden units, number of unsupervised epochs, regularization, etc.). How was the data corrupted for the DA? White Noise, or random flipped bits? How many steps in the CD? These details would be important to reproduce the results.\r\n- In the beginning of section 3 and 6, the authors mention that they think their model will project the data into a semantic space which is very sparse. How is your model learning a sparse representation? Have you used sparseness constraints in your training? If so, there is no mention of it in the paper."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Audio Artist Identification by Deep Neural Network", "abstract": "Since officially began in 2005, the annual Music Information Retrieval Evaluation eXchange (MIREX) has made great contributions to the Music Information Retrieval (MIR) research. By defining some important tasks and providing a meaningful comparison system, the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), organizer of the MIREX, drives researchers in the MIR field to develop more advanced system to fulfill the tasks. One of the important tasks is the Audio Artist Identification task, or the AAI task. We implemented a Deep Belief Network (DBN) to identify the artist by audio signal. As a matter of copyright, IMIRSEL didn't publish there data set and we had to construct our own. In our data set we got an accuracy of 69.87% without carefully choosing parameters while the best result reported on MIREX is 69.70%. We think our method is promising and we want to discuss with others.", "pdf": "https://arxiv.org/abs/1301.3195", "paperhash": "|audio_artist_identification_by_deep_neural_network", "keywords": [], "conflicts": [], "authors": ["\u80e1\u632f", "Kun Fu", "Changshui Zhang"], "authorids": ["eblis.hu@gmail.com", "Tsinghua Univ.", "Tsinghua Univ."]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358325000000, "tcdate": 1358325000000, "number": 1, "id": "zzy0H3ZbWiHsS", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "zzy0H3ZbWiHsS", "signatures": ["eblis.hu@gmail.com"], "readers": ["everyone"], "content": {"decision": "reject", "title": "Audio Artist Identification by Deep Neural Network", "abstract": "Since officially began in 2005, the annual Music Information Retrieval Evaluation eXchange (MIREX) has made great contributions to the Music Information Retrieval (MIR) research. By defining some important tasks and providing a meaningful comparison system, the International Music Information Retrieval Systems Evaluation Laboratory (IMIRSEL), organizer of the MIREX, drives researchers in the MIR field to develop more advanced system to fulfill the tasks. One of the important tasks is the Audio Artist Identification task, or the AAI task. We implemented a Deep Belief Network (DBN) to identify the artist by audio signal. As a matter of copyright, IMIRSEL didn't publish there data set and we had to construct our own. In our data set we got an accuracy of 69.87% without carefully choosing parameters while the best result reported on MIREX is 69.70%. We think our method is promising and we want to discuss with others.", "pdf": "https://arxiv.org/abs/1301.3195", "paperhash": "|audio_artist_identification_by_deep_neural_network", "keywords": [], "conflicts": [], "authors": ["\u80e1\u632f", "Kun Fu", "Changshui Zhang"], "authorids": ["eblis.hu@gmail.com", "Tsinghua Univ.", "Tsinghua Univ."]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 5}