{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730179884, "tcdate": 1509108870435, "number": 376, "cdate": 1518730179875, "id": "SkAK2jg0b", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "SkAK2jg0b", "original": "rJpthog0Z", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "pdf": "/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf", "TL;DR": "We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.", "paperhash": "garciagasulla|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks", "_bibtex": "@misc{\ngarcia-gasulla2018an,\ntitle={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\nauthor={Dario Garcia-Gasulla and Armand Vilalta and Ferran Par\u00e9s and Jonatan Moreno and Eduard Ayguad\u00e9 and Jes\u00fas Labarta and Ulises Cort\u00e9s and Toyotaro Suzumura},\nyear={2018},\nurl={https://openreview.net/forum?id=SkAK2jg0b},\n}", "keywords": ["Embedding spaces", "feature extraction", "transfer learning."], "authors": ["Dario Garcia-Gasulla", "Armand Vilalta", "Ferran Par\u00e9s", "Jonatan Moreno", "Eduard Ayguad\u00e9", "Jes\u00fas Labarta", "Ulises Cort\u00e9s", "Toyotaro Suzumura"], "authorids": ["dario.garcia@bsc.es", "armand.vilalta@bsc.es", "ferran.pares@bsc.es", "jonatan.moreno@bsc.es", "eduard.ayguade@bsc.es", "jesus.labarta@bsc.es", "ia@cs.upc.edu", "suzumurat@gmail.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260083138, "tcdate": 1517249965492, "number": 654, "cdate": 1517249965476, "id": "B1ShH1arf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "Three reviewers recommended rejection, and there was no rebuttal."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "pdf": "/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf", "TL;DR": "We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.", "paperhash": "garciagasulla|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks", "_bibtex": "@misc{\ngarcia-gasulla2018an,\ntitle={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\nauthor={Dario Garcia-Gasulla and Armand Vilalta and Ferran Par\u00e9s and Jonatan Moreno and Eduard Ayguad\u00e9 and Jes\u00fas Labarta and Ulises Cort\u00e9s and Toyotaro Suzumura},\nyear={2018},\nurl={https://openreview.net/forum?id=SkAK2jg0b},\n}", "keywords": ["Embedding spaces", "feature extraction", "transfer learning."], "authors": ["Dario Garcia-Gasulla", "Armand Vilalta", "Ferran Par\u00e9s", "Jonatan Moreno", "Eduard Ayguad\u00e9", "Jes\u00fas Labarta", "Ulises Cort\u00e9s", "Toyotaro Suzumura"], "authorids": ["dario.garcia@bsc.es", "armand.vilalta@bsc.es", "ferran.pares@bsc.es", "jonatan.moreno@bsc.es", "eduard.ayguade@bsc.es", "jesus.labarta@bsc.es", "ia@cs.upc.edu", "suzumurat@gmail.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642440805, "tcdate": 1511838444208, "number": 1, "cdate": 1511838444208, "id": "BkNxXL5ef", "invitation": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "signatures": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Lack of novelty", "rating": "3: Clear rejection", "review": "This paper proposes an out-of-the-box embedding for image classification task. Instead of taking one single layer output from pre-trained network as the feature vector for new dataset, the method first extracts the activations from all the layers, then runs spatial average pooling on all convolutional layers, then normalizes the feature and uses two predefined thresholds to discretize the features to {-1, 0, 1}. Final prediction is learned through a SVM model using those embeddings. Experimental results on nine different datasets show that this embedding outperforms baseline of using one single layer. I think in general this paper lacks novelty and it shouldn't be surprising that activations from all layers should be more representative than one single layer representation. Moreover, in Table 4, it shows that discretization actually hurts the performance. It is also very heuristic to choose the two thresholds.  \n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "pdf": "/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf", "TL;DR": "We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.", "paperhash": "garciagasulla|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks", "_bibtex": "@misc{\ngarcia-gasulla2018an,\ntitle={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\nauthor={Dario Garcia-Gasulla and Armand Vilalta and Ferran Par\u00e9s and Jonatan Moreno and Eduard Ayguad\u00e9 and Jes\u00fas Labarta and Ulises Cort\u00e9s and Toyotaro Suzumura},\nyear={2018},\nurl={https://openreview.net/forum?id=SkAK2jg0b},\n}", "keywords": ["Embedding spaces", "feature extraction", "transfer learning."], "authors": ["Dario Garcia-Gasulla", "Armand Vilalta", "Ferran Par\u00e9s", "Jonatan Moreno", "Eduard Ayguad\u00e9", "Jes\u00fas Labarta", "Ulises Cort\u00e9s", "Toyotaro Suzumura"], "authorids": ["dario.garcia@bsc.es", "armand.vilalta@bsc.es", "ferran.pares@bsc.es", "jonatan.moreno@bsc.es", "eduard.ayguade@bsc.es", "jesus.labarta@bsc.es", "ia@cs.upc.edu", "suzumurat@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642440716, "id": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper376/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer3", "ICLR.cc/2018/Conference/Paper376/AnonReviewer1", "ICLR.cc/2018/Conference/Paper376/AnonReviewer2"], "reply": {"forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper376/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642440716}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642440767, "tcdate": 1512045876046, "number": 2, "cdate": 1512045876046, "id": "H1n46uTxf", "invitation": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "signatures": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "has novelty issue, results are not impressive", "rating": "4: Ok but not good enough - rejection", "review": "The paper addresses the scenario when using a pretrained deep network as learnt feature representation for another (small) task where retraining is not an option or not desired. In this situation it proposes to use all layers of the network to extract feature from, instead of only one layer. \nThen it proposes to standardize different dimensions of the features based on their response on the original task. Finally, it discretize each dimension into {-1, 0, 1} to compress the final concatenated feature representation. \nDoing this, it shows improvements over using a single layer for 9 target image classification datasets including object, scene, texture, material, and animals.\n\nThe reviewer does not find the paper suitable for publication at ICLR due to the following reasons:\n- The paper is incremental with limited novelty.\n- the results are not encouraging\n- the pipeline of standardization, discretization is relatively costly, the final feature vector still large. \n- combining different layers, as the only contribution of the paper, has been done in the literature before,  for instance:\n\u201cThe Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling\nfor Image Classification\u201d CVPR 2016\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "pdf": "/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf", "TL;DR": "We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.", "paperhash": "garciagasulla|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks", "_bibtex": "@misc{\ngarcia-gasulla2018an,\ntitle={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\nauthor={Dario Garcia-Gasulla and Armand Vilalta and Ferran Par\u00e9s and Jonatan Moreno and Eduard Ayguad\u00e9 and Jes\u00fas Labarta and Ulises Cort\u00e9s and Toyotaro Suzumura},\nyear={2018},\nurl={https://openreview.net/forum?id=SkAK2jg0b},\n}", "keywords": ["Embedding spaces", "feature extraction", "transfer learning."], "authors": ["Dario Garcia-Gasulla", "Armand Vilalta", "Ferran Par\u00e9s", "Jonatan Moreno", "Eduard Ayguad\u00e9", "Jes\u00fas Labarta", "Ulises Cort\u00e9s", "Toyotaro Suzumura"], "authorids": ["dario.garcia@bsc.es", "armand.vilalta@bsc.es", "ferran.pares@bsc.es", "jonatan.moreno@bsc.es", "eduard.ayguade@bsc.es", "jesus.labarta@bsc.es", "ia@cs.upc.edu", "suzumurat@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642440716, "id": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper376/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer3", "ICLR.cc/2018/Conference/Paper376/AnonReviewer1", "ICLR.cc/2018/Conference/Paper376/AnonReviewer2"], "reply": {"forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper376/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642440716}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642440731, "tcdate": 1513034371616, "number": 3, "cdate": 1513034371616, "id": "By2YMc3WM", "invitation": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "signatures": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Poor presentation and lack of novelty", "rating": "4: Ok but not good enough - rejection", "review": "Paper claims to propose a deep transfer learning method. There are several reasons not to consider this paper for ICLR at this point.\n\nPaper is badly written and the problem it tries to solve is not clearly stated.\nProposed feature embedding is incremental (lack of novelty and technical contribution)\nObtained results are encouraging but not good enough.\nLack of experimental validation.\nI think paper can be improved significantly and is not ready for publication at this point.\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An Out-of-the-box Full-network Embedding for Convolutional Neural Networks", "abstract": "Transfer learning for feature extraction can be used to exploit deep representations in contexts where there is very few training data, where there are limited computational resources, or when tuning the hyper-parameters needed for training is not an option. While previous contributions to feature extraction propose embeddings based on a single layer of the network, in this paper we propose a full-network embedding which successfully integrates convolutional and fully connected features, coming from all layers of a deep convolutional neural network. To do so, the embedding normalizes features in the context of the problem, and discretizes their values to reduce noise and regularize the embedding space. Significantly, this also reduces the computational cost of processing the resultant representations. The proposed method is shown to outperform single layer embeddings on several image classification tasks, while also being more robust to the choice of the pre-trained model used for obtaining the initial features. The performance gap in classification accuracy between thoroughly tuned solutions and the full-network embedding is also reduced, which makes of the proposed approach a competitive solution for a large set of applications.", "pdf": "/pdf/784d0b148acef99c89eb735824294354f772a27d.pdf", "TL;DR": "We present a full-network embedding of CNN which outperforms single layer embeddings for transfer learning tasks.", "paperhash": "garciagasulla|an_outofthebox_fullnetwork_embedding_for_convolutional_neural_networks", "_bibtex": "@misc{\ngarcia-gasulla2018an,\ntitle={An Out-of-the-box Full-network Embedding for Convolutional Neural Networks},\nauthor={Dario Garcia-Gasulla and Armand Vilalta and Ferran Par\u00e9s and Jonatan Moreno and Eduard Ayguad\u00e9 and Jes\u00fas Labarta and Ulises Cort\u00e9s and Toyotaro Suzumura},\nyear={2018},\nurl={https://openreview.net/forum?id=SkAK2jg0b},\n}", "keywords": ["Embedding spaces", "feature extraction", "transfer learning."], "authors": ["Dario Garcia-Gasulla", "Armand Vilalta", "Ferran Par\u00e9s", "Jonatan Moreno", "Eduard Ayguad\u00e9", "Jes\u00fas Labarta", "Ulises Cort\u00e9s", "Toyotaro Suzumura"], "authorids": ["dario.garcia@bsc.es", "armand.vilalta@bsc.es", "ferran.pares@bsc.es", "jonatan.moreno@bsc.es", "eduard.ayguade@bsc.es", "jesus.labarta@bsc.es", "ia@cs.upc.edu", "suzumurat@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642440716, "id": "ICLR.cc/2018/Conference/-/Paper376/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper376/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper376/AnonReviewer3", "ICLR.cc/2018/Conference/Paper376/AnonReviewer1", "ICLR.cc/2018/Conference/Paper376/AnonReviewer2"], "reply": {"forum": "SkAK2jg0b", "replyto": "SkAK2jg0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper376/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642440716}}}], "count": 5}