{"notes": [{"id": "c_E8kFWfhp0", "original": "Kg5xVSxkm-O", "number": 2601, "cdate": 1601308288017, "ddate": null, "tcdate": 1601308288017, "tmdate": 1616033867798, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ULPGE6t-IGe", "original": null, "number": 1, "cdate": 1610040419054, "ddate": null, "tcdate": 1610040419054, "tmdate": 1610474017607, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper presents a framework for joint differentiable simulation of physics and image formation for inverse problems. It brings together ideas from differentiable physics and differentiable rendering in a compelling framework."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040419041, "tmdate": 1610474017591, "id": "ICLR.cc/2021/Conference/Paper2601/-/Decision"}}}, {"id": "Jz0zr6tT0QL", "original": null, "number": 6, "cdate": 1606191409767, "ddate": null, "tcdate": 1606191409767, "tmdate": 1606277411572, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "v2AWkPsL5S0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment", "content": {"title": "Thank you for the feedback", "comment": "Thank you for your feedback, We have revised our manuscript to address your concerns.\n\n\n**Comment: \"I would improve the quality ... plots in the paper ...\"**\n\nResponse: We have added a summary figure to better ground the applications presented in our paper. We have revised _Figure 6_ (now numbered as _Figure 7_) and added a more comprehensive explanation to the manuscript. For a cleaner demonstration, we exclusively focused on 3 variants, as opposed to 7 in the earlier version.\nWe also attempted creating hi-res photorealistic timelapse versions of _Figure 3_ and _Figure 5_, but noticed that the outputs were visually cluttered and hard to interpret. We therefore retained original versions of these figures, and intend to use the photorealistic variants in our video abstract.\n\n\n**Comment: \"How to differentiate through the physical simulator was not obvious ...\"**\n\nResponse: We thank you for raising this concern. This was by design, as our primary objective was the unification of differentiable physics and rendering. The precise details of our simulation framework are deferred to the Appendix (Sections A through E). We have added a note to this effect in the main paper. We hope the release of our code (including data and pretrained models, upon acceptance) will help to alleviate this concern.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "c_E8kFWfhp0", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2601/Authors|ICLR.cc/2021/Conference/Paper2601/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846476, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment"}}}, {"id": "iyl_kwuSlyj", "original": null, "number": 5, "cdate": 1606191371143, "ddate": null, "tcdate": 1606191371143, "tmdate": 1606277328393, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "MKPyV_I8NfR", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment", "content": {"title": "Thank you for the insightful review", "comment": "Thank you for your review. Based on your comments, we have significantly revised the presentation of our results and ablation studies.\n\n**Comment: \"All experiments ... use ... videos from the same pipeline ... It would be useful to see if video ... from a different simulator ...\"**\n\nResponse: We have added a more thorough analysis of our experiments with unmodeled dynamics and rendering effects. We believe these experiments help characterize 'out-of-distribution' performance. Furthermore, we investigate the effect of purely relying on the dynamics (under a fixed differentiable renderer) and, likewise, the impact of differentiable rendering cues under a fixed differentiable dynamics model. We find (as reported in _Section 4.3.1_) that dynamics cues tend to have a larger impact on performance compared to rendering cues. We also investigate several other phenomena, including \"what happens if contact goes unmodelled?\", and \"what if a deformable object is accidentally modeled as a rigid object? (and vice versa)\". Our experiments include results on photorealistic videos (albeit under perfect object delineation/segmentation), although we agree that an extension to real-world images is the next hurdle to overcome.\n\n**Comment: \"Analysis is mostly with one object in an empty scene ...\"**\n\nResponse: This is largely due to our system identification underpinnings, where we typically estimate the physical attributes of a single object (with known geometry). To the best of our knowledge, there are no technical limitations to handling multiple objects interacting with each other, however it may be the case that multi-object scenes might impose larger sensitivity to initial conditions due to a potentially larger number of contacts.\n\n\n**Comment: \"Analysis wrt forward/backward timings ...\"**\n\nResponse: Thank you for pointing out this detail. Our timing trends depend on the number of tetrahedra/triangles since we currently match each pair of plausible contacts to detect collisions. While this allows for dense differentiability (gradients are available w.r.t. each element of the object geometry), for scalability one might look at ideas similar to those proposed in a recent paper titled \"Scalable differentiable physics\" [ICML 2020]. It is worthwhile noting that we achieve a forward pass frequency of 3721 Hz and backward pass frequency of 248 Hz when 10,000 tetrahedra are present -- large enough to handle multiple objects with fine-grained details.\n\n\n**Comment: \"Reality gap ...\"**\n\nResponse: We have revised our draft, including a thorough revision of _Section 4.3_ which details experiments to address unmodeled dynamics and rendering effects. As stated in response to an earlier comment, we assess the impact of unmodeled dynamics as well as unmodeled shading. Moreover, _Table 2_ presents an assessment of unmodelled geometry (shape) -- another important real-world attribute.\n\n\n**Comment: \"The scale on the loss landscape is quite small ... How good does the initial guess need to be ...\"**\n\nResponse: We pick a mass uniformly randomly in our operating range of mass densities ([2, 12] kg/m^3). While originally featured in the appendix (_Sec. G_), we have now highlighted this aspect in the main paper (_Sec. 4.1.1_). We also emphasize that our loss landscape is smooth for a wide range of initialization errors (cf. _Fig. 4_). Thank you for raising this issue.\n\n\n**Comment: \"Currently a single impulse is used ... extended to handle more continuous actions?\"**\n\nResponse: We indeed support continuous actions in all our experiments. While an impulse seemed to be the best choice for rigid bodies, all our cloth and deformable solid experiments use continuous (time-varying) actions.\n\n\n**Comment: \"Presenting qualitative results for baselines would be helpful.\"**\n\nResponse: Thank you for this suggestion. We believe this is best showcased in a video format and plan to incorporate this in our revised video abstract.\n\n\n**Comment: \"Some baselines not clearly explained ...\"**\n\nResponse: We\u2019ve updated the paper to include more details about the baselines. Additionally, we have referred readers to the appendices (_Sections G and H_) where we explain our baselines, parameters, and training details.\n\n\n**Comment: \"How does performance scale to the length of the video ...\"**\n\nResponse: We have included an additional analysis to this effect in our appendix (_Section F.3._ and _Fig. 12_). We observe that the loss landscape is much steeper for smaller videos than longer ones, indicating longer convergence times. In all cases, it is very smooth and has the same global minimum.\n\n\nWe found your feedback both insightful and instrumental in revising our manuscript. Thank you.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "c_E8kFWfhp0", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2601/Authors|ICLR.cc/2021/Conference/Paper2601/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846476, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment"}}}, {"id": "kx4hfiZJtpi", "original": null, "number": 3, "cdate": 1603953044712, "ddate": null, "tcdate": 1603953044712, "tmdate": 1606273876409, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review", "content": {"title": "Review", "review": "- Summary\n\nThis paper presents a framework for performing both differentiable physics simulations and differentiable rendering. This fully differentiable simulation and rendering pipeline is then employed to perform system identification tasks, directly from video frames, being able to match or outperform both visual-based and state-based baselines. Moreover, the potential of this framework to be applied for visuomotor control is also demonstrated.\n \n\n- Pros\n\nThis method unified advances in the differentiation of both physics simulation and rendering.\n\nThe experimental results demonstrate a good ability to perform system identification for diverse parameters and control directly from videos.\nThe ability to identify parameters or direct control tasks directly from images is useful, since it reduces the need for direct supervision/annotation in the form of state information.\n\nThe presented simulator supports a variety of \"domains\", such as rigid and deformable body dynamics, cloth simulation, and these are efficient enough to be run faster than real time (at least for simple tasks).\n\n\n\n- Cons\n\nOverall, the proposed method is mostly a unification of pre-existing techniques from different fields, such as differentiable rigid and deformable body dynamics, differentiable rendering.\n\nThe paper itself admits that a limitation of this method is that it currently \"has limited capability to handle contact-rich motion that introduces a large number of discontinuities\", which limits its applicability to real-world scenes. It cannot also currently handle joints. All of these would be important for possible robotic applications, for example.\n\nThe tasks demonstrated in the experiments are simple, and issues from model mismatch does not seem to have been thoroughly evaluated (see comments below for more).\n\n\n\n- Reasons for score\n\n[Edit: Score updated, see discussion below]\n\nOverall, given the \"pros\" described above, notably the interesting results achieved for system identification and control directly from video frames by combining differentiable physics and rendering into a single framework, I recommend this paper for acceptance. Given some of the concerns raised in the \"cons\" and in more detail in the comments below, I for now will score this paper as a little above the acceptance threshold.\n\n \n\n- Additional comments\n\nThe scenarios used for the system identification and control tasks are fairly simple, with usually only a single object and few contact points.\nWas the ground truth for the scenarios in the system identification tasks generated using gradsim itself? If so, isn't it unfair that it is compared to other models (e.g., pybullet), for which there would be model mismatch? (While not mismatch would be present for gradsim)\n\nAlong the same direction, the experiments present a section on \"Impact of imperfect dynamics and rendering models\". It would also be interesting to see a quantification of the impact of model mismatch (possibly both while using the same renderer, i.e. only dynamics mismatch, or also different renderers)\n\nIn the experiments section, it is said that \"Inference ... is done by picking an initial guess of the mass (at random)\". From what distribution is this random initial guess picked from? What are these starting guesses in relation to the true parameters?\n\nThe section on \"Impact of shading and texture cues\" seems a little too short, which renders it hard to understand in detail what is going on.\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092686, "tmdate": 1606915777933, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2601/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review"}}}, {"id": "9fD8GHS6uug", "original": null, "number": 8, "cdate": 1606273829145, "ddate": null, "tcdate": 1606273829145, "tmdate": 1606273829145, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "3R_NoR8mr0n", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your thorough response.\n\nFor the points I had raised in the comments for which I had doubts, your response has clarified these. Moreover, the additions to the paper also greatly improve the paper and help address these points.  Finally, for the few negative points and limitations I have pointed out, I agree that these are natural for a work at this stage. Therefore, given the information contained in the response and the updated paper, I will improve my previous overall assessment of the paper to a \"good paper, accept\" evaluation.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "c_E8kFWfhp0", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2601/Authors|ICLR.cc/2021/Conference/Paper2601/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846476, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment"}}}, {"id": "3R_NoR8mr0n", "original": null, "number": 4, "cdate": 1606191318253, "ddate": null, "tcdate": 1606191318253, "tmdate": 1606236018133, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "kx4hfiZJtpi", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment", "content": {"title": "Thank you for the constructive review", "comment": "Thank you for your highly constructive review.\n\nWe appreciate your suggestions, particularly those concerning additional analyses and ablations. We have since revised our manuscript to address many of these concerns.\n\n**Comment: \"Overall, the proposed method is mostly a unification of ... differentiable dynamics, differentiable rendering\"**\n\nResponse: We acknowledge existing work _independently_ addresses differentiable physics/dynamics and differentiable rendering. However, existing differentiable physics and differentiable rendering methods also have several non-differentiable components (discontinuities), the interactions between which have not yet been fully explored. Surprisingly, we found the unification of these two paradigms results in superior performance compared to state-of-the-art methods, requiring far less supervision (we do not assume access to the true states, e.g.: positions/velocities, and only require image sequences and geometry).\n\nOur performance gain can be explained by comparing the loss landscape in gradSim with that of prevailing methods (e.g. non-differentiable simulators + gradient estimation, such as our PyBullet + REINFORCE baseline, see _Fig. 4_).\n\n\n**Comment: \"The paper itself admits .... limited capability to handle contact-rich motion ... cannot handle joints\"**\n\nResponse: We strongly agree that these and related obstacles are interesting and important avenues for future work. While our contact models (_Section C_) can already handle complex collisions between deformable, cloth and rigid bodies and we have successfully implemented simple articulated bodies such as pendula (as listed in our appendix), we acknowledge that there is a \u201creality gap\u201d to be overcome for application of gradSim to robotics tasks.\n\n\n**Comment: \"The tasks ... are simple, and issues from model mismatch does not seem to have been thoroughly evaluated\"** \n\nResponse: We have revised our draft to contain a thorough analysis of several model mismatch issues. We have also performed several ablation studies to investigate the impact of modifying dynamics under a fixed differentiable renderer, and the modifying the differentiable renderer under a fixed differentiable dynamics model. We find (as reported in _Sec. 4.3.1_ and _Sec. 4.3.2_) that dynamics cues tend to have a larger effect than rendering cues. We also investigate several other interesting phenomena, such as \"what happens if contact goes unmodelled?\", and \"what if a deformable object is accidentally modeled as a rigid object? (and vice versa)\".\n\n\n**Comment: \"the scenarios used for the system identification and control tasks are fairly simple ... few contact points\"**\n\nResponse: Our rationale for using a single object stems from the system identification motivation, where a single object of interest is assumed. Our experiments featuring deformable object and cloth meshes contain 5k -10k vertices, and use all-pairs testing to generate contacts, handled differentiably at each timestep. These meshes are fairly complex and involve tens of thousands of contacts. We agree that system identification in the wild would be an exciting follow-up direction.\n\n**Comment: \"Was the ground truth ... generated using gradSim itself? If so, isn't it unfair ...\"**\n\nResponse: This is a good question and prompted us to add clarification in the paper (please see updated caption for _Fig. 4_). For a fair evaluation, we use rollouts from each simulator to independently define its ground truth (e.g. for the PyBullet + REINFORCE baseline, ground truth rollouts were collected from PyBullet).\n\n\n\n\n**Comment: \"Inference ... is done by picking an initial guess of the mass (at random) ...\"**\n\nResponse: We pick a mass uniformly at random from our operating range of mass densities ($[2, 12] kg/m^3$). While originally featured in the appendix (_Sec. G_), we have now highlighted this point in the main text (_Sec. 4.1.1_). We also emphasize that our loss landscape is smooth for a wide range of initialization errors (cf. _Fig. 4_). We thank the reviewer for raising this issue.\n\n**Comment: \"The section on impact of shading and texture cues seems a little too short ...\"**\n\n Response: We agree with the assessment, and have added a more elaborate discussion in _Section 4.3.3_ (including a clarified _Figure 6_ (now _Figure 7_) to address other reviewers\u2019 concerns). For a cleaner demonstration, we exclusively focused on 3 variants, as opposed to 7 in the earlier version.\n\nWe hope that our clarification and revision address your primary concerns. We are grateful for your feedback, which played an instrumental role in improving our manuscript.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "c_E8kFWfhp0", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2601/Authors|ICLR.cc/2021/Conference/Paper2601/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846476, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment"}}}, {"id": "Iq7TQrgM4VS", "original": null, "number": 7, "cdate": 1606191480663, "ddate": null, "tcdate": 1606191480663, "tmdate": 1606235496490, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment", "content": {"title": "Revised draft uploaded", "comment": "We thank all our reviewers for their thoughtful and constructive feedback. We have revised our manuscript to address most of the comments received. We summarize the major changes here, and respond individually to reviewers to address more specific concerns.\n\n* We have added a thorough explanation of our analysis of **imperfect dynamics and rendering models** (_Section 4.3.1._, _Section 4.3.2._)\n* We have revised our section on **imperfect shading cues** (_Section 4.3.3._) with higher resolution figures and a more detailed explanation.\n* We have clarified our **choice of baselines** (_Section 4.1.1._) and other design decisions, pointing readers to appropriate locations in the appendix where applicable.\n* We added an additional analysis (**impact of video length on performance**) in our appendix (_Section F.3._ and _Fig. 12_)\n* We added more details about our **run time** (_Section 4.3.4._ and _Section I_)\n* We added an **overview figure** to help better ground our range of applications (_Fig. 1_)"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "c_E8kFWfhp0", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2601/Authors|ICLR.cc/2021/Conference/Paper2601/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846476, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Comment"}}}, {"id": "MKPyV_I8NfR", "original": null, "number": 2, "cdate": 1603894985623, "ddate": null, "tcdate": 1603894985623, "tmdate": 1605024172736, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review", "content": {"title": "Interesting research direction that will spur follow up work despite preliminary nature of evaluation", "review": "This work presents a fully differentiable physics simulation coupled with neural rendering such that input video can be used to estimate object properties or find control policies to move those objects by trying to generate the same video at the output.\n\nThe paper is well motivated by presenting a natural progression of ideas from this literature and it does a thorough job discussing related work. The paper is light on details in section 3 and it is necessary to refer to the appendix to get a complete picture. Overall, the technical contribution is solid and thus worth accepting the paper even if the validation is with relatively simpler experiments since they are sufficient to motivate this direction to be further researched. Below are a few comments to aid in improving the current work:\n\n- All experiments use what I am guessing are input (desired) videos from the same pipeline and then later hiding some parameters (to be learned). While this is a good validation the learning done here is still 'in distribution'. It would be useful to see if video (even simplistic) from a different simulator or simplified from a real world video could be applied. To what extent is this possible and are there any fundamental limitations that prevent this at the moment?\n\n- Analysis is mostly with one object in an empty scene. Are there technical limitations to handling realistic scenes where there are multiple objects and those objects interact with each other as well the environment? How does this affect performance wrt forward and backward pass timings? With such experiments, it would be helpful to understand if the released code can be easily extended to such (more complex) settings or if someone would need to start a new implementation from scratch.\n\n- The scale on the loss landscape is quite small, '0.4 pixelwise mse'. How good does the initial guess need to be to stay in the range, do the curves in fig 3 continue the trend beyond these values for larger error?\n\n- Reality gap: while this is discuss in reference to visual appearances, since the current experiments deal with synthetic scenes, the more relevant topic to discuss is the reality gap wrt physics and object motions. Experiments designed to study this would boost confidence in this approach.\n\n\nOther comments:\n\n- How much does the performance depend on good initial guess?\n\n- Currently a single impulse is used to set things in motion, can this be extended to handle more continuous actions?\n\n- Presenting qualitative results for baselines would be helpful\n\n- Some baselines not clearly explained: average, random, ConvLSTM\n\n- How does performance scale with the length of the video?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092686, "tmdate": 1606915777933, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2601/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review"}}}, {"id": "v2AWkPsL5S0", "original": null, "number": 1, "cdate": 1603807776310, "ddate": null, "tcdate": 1603807776310, "tmdate": 1605024172609, "tddate": null, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "invitation": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review", "content": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "review": "This work focuses on the problem of estimating object physical properties from video sequences. \n\nThe proposed framework combines differentiable physical simulations and differentiable rendering to map physical parameters into images differentiably. This paradigm is then used to recover physical parameters from image sequences by means of gradient based optimisation.\n\nValidation of the proposed method is carried through two main synthetic applications, parameter identification and visuomotor control. \n\nAlthough the proposed approach still requires 3D ground truth information to yield reliable estimates, it is and encouraging step towards unsupervised physics understanding from image/video data. \n\nPositive:\n\n-Crucially and differently from previous attempts, the proposed approach does not require 3D supervision - except for geometry and appearance of the static scene (i.e. at t=0). \n\n-Approach is clever, simple and yields interpretable representation\n\n-First step towards physics understanding from videos\n\nNegative:\n\n- I would improve the quality of the visualisations and plots in the paper (e.g. I found Figure 6 impossible to read)\n\n-  How to differentiate through the physical simulator was not obvious to me. I would have appreciated a more detailed explanation of how that is done in practice for one of the physical problems studied in the paper to be included in the main manuscript, in an effort to make the paper more readable. \n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2601/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2601/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "gradSim: Differentiable simulation for system identification and visuomotor control", "authorids": ["~J._Krishna_Murthy1", "~Miles_Macklin1", "~Florian_Golemo1", "~Vikram_Voleti1", "~Linda_Petrini1", "~Martin_Weiss4", "~Breandan_Considine2", "~J\u00e9r\u00f4me_Parent-L\u00e9vesque2", "kevincxie@cs.toronto.edu", "kenny@di.ku.dk", "~Liam_Paull1", "~Florian_Shkurti1", "~Derek_Nowrouzezahrai1", "~Sanja_Fidler1"], "authors": ["J. Krishna Murthy", "Miles Macklin", "Florian Golemo", "Vikram Voleti", "Linda Petrini", "Martin Weiss", "Breandan Considine", "J\u00e9r\u00f4me Parent-L\u00e9vesque", "Kevin Xie", "Kenny Erleben", "Liam Paull", "Florian Shkurti", "Derek Nowrouzezahrai", "Sanja Fidler"], "keywords": ["Differentiable simulation", "System identification", "Physical parameter estimation", "3D scene understanding", "3D vision", "Differentiable rendering", "Differentiable physics"], "abstract": "In this paper, we tackle the problem of estimating object physical properties such as mass, friction, and elasticity directly from video sequences. Such a system identification problem is fundamentally ill-posed due to the loss of information during image formation. Current best solutions to the problem require precise 3D labels which are labor intensive to gather, and infeasible to create for many systems such as deformable solids or cloth. In this work we present gradSim, a framework that overcomes the dependence on 3D supervision by combining differentiable multiphysics simulation and differentiable rendering to jointly model the evolution of scene dynamics and image formation. This unique combination enables backpropagation from pixels in a video sequence through to the underlying physical attributes that generated them. Furthermore, our unified computation graph across dynamics and rendering engines enables the learning of challenging visuomotor control tasks, without relying on state-based (3D) supervision, while obtaining performance competitive to/better than techniques that require precise 3D labels.", "one-sentence_summary": "Differentiable models of time-varying dynamics and image formation pipelines result in highly accurate physical parameter estimation from video", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "murthy|gradsim_differentiable_simulation_for_system_identification_and_visuomotor_control", "supplementary_material": "/attachment/d61fe4120f9b585415fc4048b21edd66c264b77f.zip", "pdf": "/pdf/4a6d5a30558be4f1d305beba6c91e7617ddb5c96.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmurthy2021gradsim,\ntitle={gradSim: Differentiable simulation for system identification and visuomotor control},\nauthor={J. Krishna Murthy and Miles Macklin and Florian Golemo and Vikram Voleti and Linda Petrini and Martin Weiss and Breandan Considine and J{\\'e}r{\\^o}me Parent-L{\\'e}vesque and Kevin Xie and Kenny Erleben and Liam Paull and Florian Shkurti and Derek Nowrouzezahrai and Sanja Fidler},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=c_E8kFWfhp0}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "c_E8kFWfhp0", "replyto": "c_E8kFWfhp0", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2601/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092686, "tmdate": 1606915777933, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2601/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2601/-/Official_Review"}}}], "count": 10}