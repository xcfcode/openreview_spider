{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124434008, "tcdate": 1518472291551, "number": 317, "cdate": 1518472291551, "id": "H1nD3tkPz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "H1nD3tkPz", "signatures": ["~Yao-Hung_Hubert_Tsai1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study", "abstract": "Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs.  However, the measurement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures. ", "paperhash": "wu|dependency_bottleneck_in_autoencoding_architectures_an_empirical_study", "_bibtex": "@misc{\n  wu2018\"dependency,\n  title={\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study},\n  author={Denny Wu and Yixiu Zhao and Yao-Hung Hubert Tsai and Makoto Yamada and Ruslan Salakhutdinov},\n  year={2018},\n  url={https://openreview.net/forum?id=H1nD3tkPz}\n}", "authorids": ["yiwu1@andrew.cmu.edu", "yixiuz@andrew.cmu.edu", "yaohungt@cs.cmu.edu", "makoto.yamada@riken.jp", "rsalakhu@cs.cmu.edu"], "authors": ["Denny Wu", "Yixiu Zhao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Ruslan Salakhutdinov"], "keywords": ["Dependency Measure", "Kernel Methods", "Auto-Encoders", "Information Bottleneck"], "pdf": "/pdf/87ff7e4566c5aac301fdf21fd4519e203f62274b.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582805128, "tcdate": 1520621342441, "number": 1, "cdate": 1520621342441, "id": "rkI7wLlYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "signatures": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer3"], "content": {"title": "Interesting idea for estimation of dependency in neural networks.", "rating": "7: Good paper, accept", "review": "The authors investigate dependence between layers of a deep neural network, and in particular propose to use a normalised Hilbert-Schmidt criterion to measure dependency instead of Mutual Information. They perform experiments using an autoencoder and show the HSIC between the input and the representation, with the results suggesting different behaviours for reconstruction and prediction. The results are still very preliminary but this is a step in an interesting direction. \n\nQuestions and comments:\nWas the type of kernel used in the experiments Gaussian?\nIt would be interesting to show results obtained with SMI, especially since the authors seem to have already performed some experiments with SMI.\n\nOn formulation:\nIn the abstract the sentence \u201cwe propose to measure dependency instead of MI\u201d is confusing since MI is also a measure of dependency. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study", "abstract": "Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs.  However, the measurement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures. ", "paperhash": "wu|dependency_bottleneck_in_autoencoding_architectures_an_empirical_study", "_bibtex": "@misc{\n  wu2018\"dependency,\n  title={\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study},\n  author={Denny Wu and Yixiu Zhao and Yao-Hung Hubert Tsai and Makoto Yamada and Ruslan Salakhutdinov},\n  year={2018},\n  url={https://openreview.net/forum?id=H1nD3tkPz}\n}", "authorids": ["yiwu1@andrew.cmu.edu", "yixiuz@andrew.cmu.edu", "yaohungt@cs.cmu.edu", "makoto.yamada@riken.jp", "rsalakhu@cs.cmu.edu"], "authors": ["Denny Wu", "Yixiu Zhao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Ruslan Salakhutdinov"], "keywords": ["Dependency Measure", "Kernel Methods", "Auto-Encoders", "Information Bottleneck"], "pdf": "/pdf/87ff7e4566c5aac301fdf21fd4519e203f62274b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582804934, "id": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper317/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer2"], "reply": {"forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582804934}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582761358, "tcdate": 1520643438414, "number": 2, "cdate": 1520643438414, "id": "BkLO6ogKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "signatures": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer1"], "content": {"title": "Nice motivation, experiments fall short", "rating": "5: Marginally below acceptance threshold", "review": "This paper is motivated by recent work which argues that the generalization performance of a DNN can perhaps be understood in terms of its \"information bottleneck.\"  In particular, the recent work of Shwartz-Ziv and Tishby (2017) argues that DNN training has two phases: In the first, the mutual information (MI) between the latent representations and the output increases.  In the second, the mutual information between the input and the latent representations decreases.  Because the MI is difficult to estimate accurately, the authors of this paper propose to measure the Hilbert-Schmidt Independence Criterion (\"HSIC\") instead.  They measure the HSIC (which is related to the squared mutual information) between the input and the latent representations of two different autoencoders: A reconstruction autoencoder (which reconstructs x_t from x_t), and a prediction autoencoder (which predicts x_{t + n} given x_t).  They observe that for the reconstruction autoencoder, the HSIC begins to consistently + gradually drop after an initial increase at the beginning of training (as predicted by the Shwartz-Ziv and Tishby (2017) paper).  For the prediction autoencoder, on the other hand, no noticeable drop occurs.  The authors were surprised by this difference behavior, and currently offer no explanation, leaving that for future work. \n\nThe primary contribution of this paper appears to be its proposal to use HSIC instead of MI to measure the dependence between different layers of a neural net.  This is an interesting proposition.  Unfortunately, the experimental section of this work is quite limited, only considering two models.  Also, the authors were unable to explain their primary observation.  Lastly, I did not understand why they only measured the HSIC between in input and the latent representations, and not between the latent representations and the output.  In particular, why didn't they compute a new version of the \"Information Bottleneck\" which replaces the MI terms with HSIC terms, and explore whether this metric correlates with generalization performance?\n\nPros\n-- Nice idea of measuring HSIC instead of of MI.\n-- Experimental observations are interesting.\n\nCons\n-- Paper doesn't really explain the relationship between HSIC and MI.  What are the important differences between these?  Why should we be able to replace MI with HSIC?\n-- Experimental results are quite limited (only two models).  Why are autoencoders the only models considered?\n-- Experimental results aren't particularly well understood, and aren't explained very clearly.\n-- Paper doesn't perform analysis of correlation between information bottleneck (estimated with HSIC) and generalization performance.\n-- The section about approximating SMI seems quite tangential to the work in the paper (also, shouldn't the summand in equation 5 be squared?).", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study", "abstract": "Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs.  However, the measurement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures. ", "paperhash": "wu|dependency_bottleneck_in_autoencoding_architectures_an_empirical_study", "_bibtex": "@misc{\n  wu2018\"dependency,\n  title={\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study},\n  author={Denny Wu and Yixiu Zhao and Yao-Hung Hubert Tsai and Makoto Yamada and Ruslan Salakhutdinov},\n  year={2018},\n  url={https://openreview.net/forum?id=H1nD3tkPz}\n}", "authorids": ["yiwu1@andrew.cmu.edu", "yixiuz@andrew.cmu.edu", "yaohungt@cs.cmu.edu", "makoto.yamada@riken.jp", "rsalakhu@cs.cmu.edu"], "authors": ["Denny Wu", "Yixiu Zhao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Ruslan Salakhutdinov"], "keywords": ["Dependency Measure", "Kernel Methods", "Auto-Encoders", "Information Bottleneck"], "pdf": "/pdf/87ff7e4566c5aac301fdf21fd4519e203f62274b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582804934, "id": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper317/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer2"], "reply": {"forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582804934}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582701609, "tcdate": 1520698487339, "number": 3, "cdate": 1520698487339, "id": "B11FNYbKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "signatures": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer2"], "content": {"title": "A well-written paper but the empirical study is weak", "rating": "5: Marginally below acceptance threshold", "review": "The paper is clearly written and the authors do a good job quickly introducing the pre-requisite concepts (information bottleneck, HS independence criterion, ...). Unfortunately the empirical study itself is quite lightweight. Hopefully the paper can spark some interesting discussions though.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study", "abstract": "Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs.  However, the measurement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures. ", "paperhash": "wu|dependency_bottleneck_in_autoencoding_architectures_an_empirical_study", "_bibtex": "@misc{\n  wu2018\"dependency,\n  title={\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study},\n  author={Denny Wu and Yixiu Zhao and Yao-Hung Hubert Tsai and Makoto Yamada and Ruslan Salakhutdinov},\n  year={2018},\n  url={https://openreview.net/forum?id=H1nD3tkPz}\n}", "authorids": ["yiwu1@andrew.cmu.edu", "yixiuz@andrew.cmu.edu", "yaohungt@cs.cmu.edu", "makoto.yamada@riken.jp", "rsalakhu@cs.cmu.edu"], "authors": ["Denny Wu", "Yixiu Zhao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Ruslan Salakhutdinov"], "keywords": ["Dependency Measure", "Kernel Methods", "Auto-Encoders", "Information Bottleneck"], "pdf": "/pdf/87ff7e4566c5aac301fdf21fd4519e203f62274b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582804934, "id": "ICLR.cc/2018/Workshop/-/Paper317/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper317/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper317/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper317/AnonReviewer2"], "reply": {"forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582804934}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573581096, "tcdate": 1521573581096, "number": 162, "cdate": 1521573580761, "id": "Hyr00C0tf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "H1nD3tkPz", "replyto": "H1nD3tkPz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study", "abstract": "Recent works investigated the generalization properties in deep neural networks (DNNs) by studying the Information Bottleneck in DNNs.  However, the measurement of the mutual information (MI) is often inaccurate due to the density estimation. To address this issue, we propose to measure the dependency instead of MI between layers in DNNs. Specifically, we propose to use Hilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which can measure the dependence of two random variables without estimating probability densities. Moreover, HSIC is a special case of the Squared-loss Mutual Information (SMI). In the experiment, we empirically evaluate the generalization property using HSIC in both the reconstruction and prediction auto-encoding (AE) architectures. ", "paperhash": "wu|dependency_bottleneck_in_autoencoding_architectures_an_empirical_study", "_bibtex": "@misc{\n  wu2018\"dependency,\n  title={\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical Study},\n  author={Denny Wu and Yixiu Zhao and Yao-Hung Hubert Tsai and Makoto Yamada and Ruslan Salakhutdinov},\n  year={2018},\n  url={https://openreview.net/forum?id=H1nD3tkPz}\n}", "authorids": ["yiwu1@andrew.cmu.edu", "yixiuz@andrew.cmu.edu", "yaohungt@cs.cmu.edu", "makoto.yamada@riken.jp", "rsalakhu@cs.cmu.edu"], "authors": ["Denny Wu", "Yixiu Zhao", "Yao-Hung Hubert Tsai", "Makoto Yamada", "Ruslan Salakhutdinov"], "keywords": ["Dependency Measure", "Kernel Methods", "Auto-Encoders", "Information Bottleneck"], "pdf": "/pdf/87ff7e4566c5aac301fdf21fd4519e203f62274b.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}