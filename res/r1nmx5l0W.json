{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730181075, "tcdate": 1509101603592, "number": 344, "cdate": 1518730181063, "id": "r1nmx5l0W", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "r1nmx5l0W", "original": "H1s7g9g0W", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260089095, "tcdate": 1517249718927, "number": 446, "cdate": 1517249718911, "id": "BkkpEyaBz", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "Pros and cons of the paper can be summarized as follows:\n\nPros:\n* The underlying idea may be interesting\n* Results are reasonably strong on the test set used\n\nCons:\n* Testing on the single dataset indicates that the model may be of limited applicability\n* As noted by reviewer 2, core parts of the paper are extremely difficult to understand, and the author response did little to assuage these concerns\n* There is little mathematical notation, which compounds the problems of clarity\n\nAfter reading the method section of the paper, I agree with reviewer 2: there are serious clarity issues here. As a result, I do cannot recommend that this paper be accepted to ICLR in its current form. I would suggest the authors define their method precisely in mathematical notation in a future submission."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642436442, "tcdate": 1511754272789, "number": 1, "cdate": 1511754272789, "id": "SJK75ZFef", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "signatures": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Interesting idea, but requires more datasets to show.", "rating": "5: Marginally below acceptance threshold", "review": "The paper proposed a method that tries to generate both accurate and diverse samples from RNNs. \nI like the basic intuition of this paper, i.e., using mistakes for creativity and refining on top of it. I also think the evaluation is done properly. I think my biggest concern is that the method was only tested on a single dataset hence it is not convincing enough. Also on this particular dataset, the method does not seem to strongly dominate the other methods. Hence it's not clear how much better this method is compared to previously proposed ones.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642436351, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer3", "ICLR.cc/2018/Conference/Paper344/AnonReviewer2", "ICLR.cc/2018/Conference/Paper344/AnonReviewer1"], "reply": {"forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642436351}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642436403, "tcdate": 1511788274871, "number": 2, "cdate": 1511788274871, "id": "Skie1qFxM", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "signatures": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "A novel architecture for generating greater variety on QuickDraw dataset, but seems confused about what it's actually doing.", "rating": "4: Ok but not good enough - rejection", "review": "This paper baffles me. It appears to be a stochastic RNN with skip connections (so it's conditioned on the last two states rather than last one) trained by an adversarial objective (which is no small feat to make work for sequential tasks) with results shown on the firetruck category of the QuickDraw dataset. Yet the authors claim significantly more importance for the work than I think it merits.\n\nFirst, there is nothing variational about their variational RNN. They seem to use the term to be equivalent to \"stochastic\", \"probabilistic\" or \"noisy\" rather than having anything to do with optimizing a variational bound. To strike the right balance between pretension and accuracy, I would suggest substituting the word \"stochastic\"  everywhere \"variational\" is used.\n\nSecond, there is nothing self-improving or collaborative about their self-improving collaborative GAN. Once the architecture is chosen to share the weights between the weak and strong generator, the only difference between the two is that the weak generator has greater noise at the output. In this sense the architecture should really be seen as a single model with different noise levels at alternating steps. In this sense, I am not entirely clear on what the difference is between the SIC-GAN and their noisy GAN baseline - presumably the only difference is that the noisy GAN is conditioned on a single timestep instead of two at a time? The claim that these models are somehow \"self-improving\" baffles me as well - all machine learning models are self-improving, that is the point of learning. The authors make a comparison to AlphaGo Zero's use of self-play, but here the weak and strong generators are on the same side of the game, and because there are no game rules provided beyond \"reproduce the training set\", there is no possibility of discovery beyond what is human-provided, contrary to the authors' claim.\n\nThird, the total absence of mathematical notation made it hard in places to follow exactly what the models were doing. While there are plenty of papers explaining the GAN framework to a novice, at least some clear description of the baseline architectures would be appreciated (for instance, a clearer explanation of how the SIC-GAN differs from the noisy GAN). Also the description of the soft $\\ell_1$ loss (which the authors call the \"1-loss\" for some reason) would benefit from a clearer mathematical exposition.\n\nFourth, the experiments seem too focused on the firetruck category of the QuickDraw dataset. As it was the only example shown, it's difficult to evaluate their claim that this is a general method for improving variety without sacrificing quality. Their chosen metrics for variety and detail are somewhat subjective, as they depend on the fact that some categories in the QuickDraw dataset resemble firetrucks in the fine detail while others resemble firetrucks in outline. This is not a generalizable metric. Human evaluation of the relative quality and variety would likely suffice.\n\nLastly, the entire section on the strong-weak collaborative GAN seems to add nothing. They describe an entire training regiment for the model, yet never provide any actual experimental results using that model, so the entire section seems only to motivate the SIC-GAN which, again, seems like a fairly ordinary architectural extension to GANs with RNN generators.\n\nThe results presented on QuickDraw do seem nice, and to the best of my knowledge it is the first (or at least best) applications of GANs to QuickDraw - if they refocused the paper on GAN architectures for sketching and provided more generalizable metrics of quality and variety it could be made into a good paper.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642436351, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer3", "ICLR.cc/2018/Conference/Paper344/AnonReviewer2", "ICLR.cc/2018/Conference/Paper344/AnonReviewer1"], "reply": {"forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642436351}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642436367, "tcdate": 1511794009949, "number": 3, "cdate": 1511794009949, "id": "ByfDSjtlf", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "signatures": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Very interesting approach for training a sequential generator adversarially", "rating": "7: Good paper, accept", "review": "Overall the paper is good: good motivation, insight, the model makes sense, and the experiments / results are convincing. I would like to see some evidence though that the strong generator is doing exactly what is advertised: that it\u2019s learning to clean up the mistakes from variation. Can we have some sort of empirical analysis that what you say is true? \n\nThe writing grammar quality fluctuates. Please clean up.\n\nDetailed notes\nP1:\nWhy did you pass on calling it Self-improving collaborative adversarial learning (SICAL)?\nI\u2019m very surprised you don\u2019t mention VAE RNN here (Chung et al 2015) along with other models that leverage an approximate posterior model of some sort.\n\nP2:\nWhat about scheduled sampling?\nIs the quality really better? How do you quantify that? To me the ones at the bottom of 2(c) are of both lower quality *and* diversity.\n\u201cFigure 2(d) displays human-drawn sketches of fire trucks which demonstrate that producing sequences\u2013in this case sketches\u2013with both quality and variety is definitely achievable in real-world applications\u201d: I\u2019m not sure I follow this argument. Because people can do it, ML should be able to?\n\nP3:\n\u201cRecently, studies start to apply GANs to generate the sequential output\u201d: fix this\nGrammar takes a brief nose-dive around here, making it a little harder to read.\nCaption: \u201cbean search\u201d\nChe et al also uses something close to Reinforcement learning for discrete sequences.\n\u201cnose-injected\u201d: now you\u2019re just being silly\nMaybe cite Bahdanau et al 2016 \u201cAn actor-critic algorithm for sequence prediction\u201d\n\u201cdoes not require any variety reward/measure to train\u201d What about the discriminator score (MaliGAN / SeqGAN)? Could this be a simultaneous variety + quality reward signal? If the generator is either of poor-quality or has low variety, the discriminator could easily distinguish its samples from the real ones, no?\n\nP6:\nDid you pass only the softmax values to the discriminator?\n\nP7:\nI like the score scheme introduced here. Do you see any connection to inception score?\nSo compared to normal GAN, does SIC-GAN have more parameters (due to the additional input)? If so, did you account for this in your experiments?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642436351, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper344/AnonReviewer3", "ICLR.cc/2018/Conference/Paper344/AnonReviewer2", "ICLR.cc/2018/Conference/Paper344/AnonReviewer1"], "reply": {"forum": "r1nmx5l0W", "replyto": "r1nmx5l0W", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642436351}}}, {"tddate": null, "ddate": null, "tmdate": 1515189746389, "tcdate": 1515189519781, "number": 2, "cdate": 1515189519781, "id": "H1dfBd6Xz", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "forum": "r1nmx5l0W", "replyto": "Skie1qFxM", "signatures": ["ICLR.cc/2018/Conference/Paper344/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper344/Authors"], "content": {"title": "Thanks.", "comment": "We thank the reviewer for constructive comments. Following is our reply:\n\nQ: Once the architecture is chosen to share the weights between the weak and strong generator, ...it appears to be a stochastic RNN with skip connections (so it's conditioned on the last two states rather than last one) trained by an adversarial objective...\nA: We are sorry for not describing the \u201ctying\u201d precisely. It is done in a soft manner; that is, we add a loss term for the weak generator that require its parameters to be similar to those of the strong generator. Please see Section 4 for more details. Actually, the extra input taken by the strong generator is not necessary and are not implemented. We just described it for the cases when the hyperparameter of the term is high. We have remove the irrelevant sentences to avoid confusion.\n\nQ: I am not entirely clear on what the difference is between the SIC-GAN and their noisy GAN baseline...\nA: The noisy GAN just weakens the ordinary RNN generator of the naive GAN to achieve the \u201ccovering\u201d effect similar to that of the strong-weak collaborative GAN\u2014if a point is made bad, the RNN may learn to generate better points at later time steps in order to fool the discriminator. However, the \u201cnext points\u201d in the weakened RNN are made bad too (since the entire RNN is weakened) and may not be able to actually cover the previous point. To fool the discriminator in such a situation, the RNN may instead learn to output points that, after being weakened, are more easily \u201ccovered\u201d by the future (bad) points. In effect, this makes the RNN conservative to generating novel sequence and reduces variety. We call this the covering-or-covered paradox. On the other hand, once trained, the strong generator in the strong-weak collaborative GAN is used to generate an entire sequence. This means that the strong generator should have enough based temperature (or noise level) to ensure the variety. One naive way to do so is to add a base-temperature to both the strong and weak generators during the training time. However, the strong generator faces the covering-or-covered paradox now and may learn to be conservative. We can instead train the strong-weak collaborative GAN multiple times using a self-improving technique. We start by adding a low base-temperature to both the strong and weak generators and train them in the first phase. Then we set the weak generator in the next phase as the strong one we get from the previous phase and train the generators with increased base-temperature. We then repeat this process until the target base-temperature is reached. We call the process \u201cself-improving\u201d because the strong generator in the next phase learns to cover itself in the previous phase. It is important to note that in a later phase, the weak generator is capable of covering the negative effect due to the variety of the strong generator (because that weak generator is a strong generator in the previous phase). So, the strong generator in the current phase can focus on the \u201ccovering\u201d rather than \u201ccovered,\u201d preventing the final RNN from being conservative. \n\nQ: ...because there are no game rules provided beyond \u201creproduce the training set,\u201d there is no possibility of discovery beyond what is human-provided, contrary to the authors' claim.\nA: The generator can exploit up to the generalizability of the generator."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825735263, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1nmx5l0W", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper344/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper344/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper344/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers", "ICLR.cc/2018/Conference/Paper344/Authors", "ICLR.cc/2018/Conference/Paper344/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825735263}}}, {"tddate": null, "ddate": null, "tmdate": 1515189559958, "tcdate": 1515189559958, "number": 3, "cdate": 1515189559958, "id": "Sk1SSO6Xz", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "forum": "r1nmx5l0W", "replyto": "SJK75ZFef", "signatures": ["ICLR.cc/2018/Conference/Paper344/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper344/Authors"], "content": {"title": "Thanks.", "comment": "We thank the reviewer for constructive comments. \n\nQ: I think my biggest concern is that the method was only tested on a single dataset...\nA: Thanks. Following the suggestion of reviewer 2, we have changed the paper title to Sketch RNN so we believe this is no longer a concern."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825735263, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1nmx5l0W", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper344/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper344/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper344/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers", "ICLR.cc/2018/Conference/Paper344/Authors", "ICLR.cc/2018/Conference/Paper344/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825735263}}}, {"tddate": null, "ddate": null, "tmdate": 1515189472572, "tcdate": 1515189472572, "number": 1, "cdate": 1515189472572, "id": "rJtkrOaQf", "invitation": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "forum": "r1nmx5l0W", "replyto": "ByfDSjtlf", "signatures": ["ICLR.cc/2018/Conference/Paper344/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper344/Authors"], "content": {"title": "Thanks", "comment": "We thank the reviewer for the positive comments. We have fixed the typos and grammar issues in the new version and cited more relevant work including the Bahdanau et al. 2016 \u201cAn actor-critic algorithm for sequence prediction\u201d and the VAE RNN by Chung et al. 2015. Following is our reply to your specific comments: \n\nQ: Did you pass only the softmax values to the discriminator? \nA: No, we pass the mean and variance of each point generated by the Sketch RNN to the discriminator. \n\nQ: So compared to normal GAN, does SIC-GAN have more parameters (due to the additional input)?\nA: No, the parameter numbers of the unfolded Noisy GAN and SIG-GAN are roughly the same.\n\nQ: \u201cFigure 2(d) displays human-drawn sketches of fire trucks which demonstrate that producing sequences\u2013in this case sketches\u2013with both quality and variety is definitely achievable in real-world applications\u201d: I\u2019m not sure I follow this argument. Because people can do it, ML should be able to?\nA: You are right. Here we just want to emphasize that the quality and variety is both achievable \u201cby humans.\u201d We have corrected the sentence in the paper. \n\nQ: Discriminator in MaliGAN/SeqGAN a simultaneous variety + quality reward signal?\nA: Yes it is. The MaliGAN/SeqGAN is proposed for the RNNs with the discrete output. While we use the continuous Sketch-RNN to demonstrate the Strong-Weak Collaborative GAN and SIC-GAN, the ideas could be readily applied to discrete cases. This is our future work."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SIC-GAN: A Self-Improving Collaborative GAN for Decoding Sketch RNNs", "abstract": "Variational RNNs are proposed to output \u201ccreative\u201d sequences. Ideally, a collection of sequences produced by a variational RNN should be of both high quality and high variety. However, existing decoders for variational RNNs suffer from a trade-off between quality and variety. In this paper, we seek to learn a variational RNN that decodes high-quality and high-variety sequences. We propose the Self-Improving Collaborative GAN (SIC-GAN), where there are two generators (variational RNNs) collaborating with each other to output a sequence and aiming to trick the discriminator into believing the sequence is of good quality. By deliberately weakening one generator, we can make another stronger in balancing quality and variety. We conduct experiments using the QuickDraw dataset and the results demonstrate the effectiveness of SIC-GAN empirically. ", "pdf": "/pdf/77a5bad2a2db85895ff2d771baeb99b6a4f9709e.pdf", "paperhash": "chuang|sicgan_a_selfimproving_collaborative_gan_for_decoding_sketch_rnns", "_bibtex": "@misc{\nchuang2018sicgan,\ntitle={{SIC}-{GAN}: A Self-Improving Collaborative {GAN} for Decoding Sketch {RNN}s},\nauthor={Chi-Chun Chuang and Zheng-Xin Weng and Shan-Hung Wu},\nyear={2018},\nurl={https://openreview.net/forum?id=r1nmx5l0W},\n}", "keywords": ["RNNs", "GANs", "Variational RNNs", "Sketch RNNs"], "authors": ["Chi-Chun Chuang", "Zheng-Xin Weng", "Shan-Hung Wu"], "authorids": ["ccchuang@datalab.cs.nthu.edu.tw", "zxweng@datalab.cs.nthu.edu.tw", "shwu@cs.nthu.edu.tw"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825735263, "id": "ICLR.cc/2018/Conference/-/Paper344/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1nmx5l0W", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper344/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper344/Authors|ICLR.cc/2018/Conference/Paper344/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper344/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper344/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper344/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper344/Reviewers", "ICLR.cc/2018/Conference/Paper344/Authors", "ICLR.cc/2018/Conference/Paper344/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825735263}}}], "count": 8}