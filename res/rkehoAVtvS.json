{"notes": [{"id": "rkehoAVtvS", "original": "BJeDmmt_vr", "number": 1333, "cdate": 1569439395520, "ddate": null, "tcdate": 1569439395520, "tmdate": 1577168278140, "tddate": null, "forum": "rkehoAVtvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Adversarial Paritial Multi-label Learning", "authors": ["Yan Yan", "Yuhong Guo"], "authorids": ["yanyan.nwpu@gmail.com", "yuhongguo.cs@gmail.com"], "keywords": [], "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify noisy labels and uses a multi-label prediction network to map the training instances to the disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels. Extensive experiments are conducted on multiple datasets, while the proposed model demonstrates the state-of-the-art performance for partial multi-label learning.", "pdf": "/pdf/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "paperhash": "yan|adversarial_paritial_multilabel_learning", "original_pdf": "/attachment/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "_bibtex": "@misc{\nyan2020adversarial,\ntitle={Adversarial Paritial Multi-label Learning},\nauthor={Yan Yan and Yuhong Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=rkehoAVtvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "nULDhM5_GG", "original": null, "number": 1, "cdate": 1576798720817, "ddate": null, "tcdate": 1576798720817, "tmdate": 1576800915784, "tddate": null, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "invitation": "ICLR.cc/2020/Conference/Paper1333/-/Decision", "content": {"decision": "Reject", "comment": "The paper considers a problem of clearly practical importance: multi-label classification where the ground truth label sets are noisy, specifically they are known (or at least assumed) to be a superset of the true ground truth labels. Learning a classifier in this setting require simultaneous identification of irrelevant labels. The proposed solution is a 4-part neural architecture, wherein a multi-label classifier is composed with a disambiguation or \"cleanup\" network, which is used as conditioning input to a conditional GAN which learns an inverse mapping, trained via an adversarial loss and also a least squares reconstruction loss (\"generation loss\"). \n\nReviews were split 2 to 1 in favour of rejection, and the discussion phase did not resolve this split, as two reviewers did not revisit their assessments. R2 and R3 were concerned about the overall novelty and degeneracy of the inverse mapping problem. R1 increased their score after the rebuttal phase as they felt their concerns were addressed in comments (regarding issues surrounding the related work, the possibility of trivial solutions, and intuition for why the adversarial objective helps), but these were not addressed in the text as no updates were made.\n\nI agree with the authors that PML is an important problem (one that receives perhaps less attention than it should from our community), and their empirical validation seems to support that their method outperforms (marginally, in many cases) methods from the literature. While the ablation study offers preliminary evidence that the inverse mapping is responsible for some of the gains, there are a lot of moving parts here and the authors haven't done a great job of motivating why this should help, or investigating why it in fact does. Based on the scores and my own reading of the paper, I'd recommend rejection at this time.\n\nMy own comments for the authors: I'd urge efforts to clarify the motivation for learning the inverse mapping, in particular adversarially (rather than just with the generation loss) in the text of the paper as you have in your rebuttals, and to improve the notation (the use of both D-tilde and D is confusing, and the omega notation seems unnecessary). I'm also not entirely clear whether the generator is stochastic or not, as the notation doesn't mention a randomly sampled latent variable (the traditional \"z\" here is a conditioning vector). Either way, the answer should be made more explicit.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Paritial Multi-label Learning", "authors": ["Yan Yan", "Yuhong Guo"], "authorids": ["yanyan.nwpu@gmail.com", "yuhongguo.cs@gmail.com"], "keywords": [], "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify noisy labels and uses a multi-label prediction network to map the training instances to the disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels. Extensive experiments are conducted on multiple datasets, while the proposed model demonstrates the state-of-the-art performance for partial multi-label learning.", "pdf": "/pdf/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "paperhash": "yan|adversarial_paritial_multilabel_learning", "original_pdf": "/attachment/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "_bibtex": "@misc{\nyan2020adversarial,\ntitle={Adversarial Paritial Multi-label Learning},\nauthor={Yan Yan and Yuhong Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=rkehoAVtvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727111, "tmdate": 1576800279334, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1333/-/Decision"}}}, {"id": "S1gWhqG2Yr", "original": null, "number": 1, "cdate": 1571723945309, "ddate": null, "tcdate": 1571723945309, "tmdate": 1574574150895, "tddate": null, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "invitation": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1333", "review": "This paper proposed a new method for partial multi-label learning, based on the idea of generative adversarial networks. The partial multi-label learning is the problem that one instance is associated with several ground truth labels simultaneously, but we are given a superset of the ground truth labels for training. To solve the problem, the paper proposes a learning model composing of four deep neural networks, two of them for prediction the ground truth labels (the prediction network, and the disambiguation network), one of them to generate instances based on the disambiguated labels, and one discriminative network to discriminated generated instance versus true instances. The four network are concatenated, and the paper proposed to optimize the sum of generation loss, the classification loss, and the adversarial loss. Theoretical results like the theories in the original GAN paper are also given. Finally, the paper does thorough empirical studies compared the proposed method with four other baselines and three variants on fourteen datasets with various settings.  \n\nThe paper is the first paper to proposes a GAN-style algorithm for the partial multi-label learning problem. The empirical results also validate its superior performance compared to other baselines on the data sets used. On the other hand, the paper fails to give enough intuition on why the GAN can naturally be used to solve the partial multi-label learning problem, and why the proposed method can perform better than other baselines. There is also some inaccuracy in discussing related work. Overall, given the contribution to introduce GAN to partial multi-label learning problem and the thorough empirical studies, I think this paper can be weakly accepted. \n\nMain arguments\nThe paper argues that existing methods may not be good on this problem is due to the fact that they generally learn a \u201cconfidence score\u201d for every candidate labels, while the learned \u201cconfidence score\u201d may not be accurate enough, and the errors may accumulate through these process. I agree with the paper on this aspect. However, in the paper, it also learns something similar to the \u201cconfidence\u201d score in the disambiguation network \\tilde D, so why the proposed method is better than previous baselines? I guess the reason is due to the adversarial training part in the latter steps. But the paper fails to give clear intuition why the adversarial training part can lead to better performance.\n\nI am also wondering will the proposed model leads to a trivial solution. For example, one possible solution may be that both the prediction network F and the disambiguation network \\tilde D get the same solution: the given partial label set. In this way, the classification error can always be zero, and we can train the generation network to give a ground truth instance x, given that the generation network G is strong enough. So I also guess the discrimination network is the key part for the success of the proposed method empirically. So I am curious if we only use the adversarial loss without training the prediction network F, what the results will be. In the Ablation Study Sec. 5.3, the paper does not compare the results optimizing only the adversarial loss. I believe the results of such a study can help us understand what the key part of the proposed method is.\n\nIn the related work part, the arguments on \u201cweak label learning\u201d cannot be used for partial multi-label learning is not accurate. In fact, \u201cweak label learning\u201d studies the problem when positive labels are missing, and partial multi-label learning studies the problem when negative labels are missing. So in general, the methods for \u201cweak label learning\u201d can be used for \u201cpartial multi-label learning\u201d if we exchange the role of positive labels and negative labels in both problems. So why we need to study partial multi-label learning? I think the reason is that, generally, in multi-label learning, the number of negative labels will be much larger than the number of positive labels. So \u201cpartial multi-label\u201d is actually more strong supervision information than \u201cweak labels\u201d because positive labels are more important. Such arguments and related empirical studies (when the number of negative labels is much larger than positive labels) are suggested to be added into the further version of the paper.\n\nAlthough the paper has some deficiencies, it does a good job of introducing GAN into partial multi-label learning, and it is also the first paper to use the powerful deep neural networks into this problem, which may trigger some interesting studies given the booming of neural networks these days. And thorough empirical studies are done by comparing to not only baselines but also different loss parts of the proposal it owes. It is worth reading especially it may have an impact on further studies. \n\n---------------------------------------\nI am satisfied with the rebuttal and tend to increase my score. Although the paper is not perfect, it does a good job of introducing GAN into partial multi-label learning, and it is also the first paper (thus it is novel) to use the powerful deep neural networks into this problem, which may trigger some interesting studies given the booming of neural networks these days.\n\nActually, I think partial multi-label learning problem is difficult and it may not possible to have perfect solution nowadays. Partial multi-class learning may be easier since you know only one label is true, but partial multi-label learning is difficult since you do not know how many true labels there are. It makes no point to require a perfect solution for such a dirty problem. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Paritial Multi-label Learning", "authors": ["Yan Yan", "Yuhong Guo"], "authorids": ["yanyan.nwpu@gmail.com", "yuhongguo.cs@gmail.com"], "keywords": [], "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify noisy labels and uses a multi-label prediction network to map the training instances to the disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels. Extensive experiments are conducted on multiple datasets, while the proposed model demonstrates the state-of-the-art performance for partial multi-label learning.", "pdf": "/pdf/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "paperhash": "yan|adversarial_paritial_multilabel_learning", "original_pdf": "/attachment/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "_bibtex": "@misc{\nyan2020adversarial,\ntitle={Adversarial Paritial Multi-label Learning},\nauthor={Yan Yan and Yuhong Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=rkehoAVtvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575940552360, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1333/Reviewers"], "noninvitees": [], "tcdate": 1570237738898, "tmdate": 1575940552375, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review"}}}, {"id": "HkeQUY2aYS", "original": null, "number": 2, "cdate": 1571830090733, "ddate": null, "tcdate": 1571830090733, "tmdate": 1572972482459, "tddate": null, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "invitation": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors propose a novel GAN-based method to tackle PML problem. By using Encoder-Decoder architecture, the authors combine four neural networks including disambiguator, predictor, generator, and discriminator to implement the integrated model and get an overall good performance in various experiment settings and datasets.\n\nPros:\n- It's novel to introduce GAN to solve the PML problem.\n-The model works better than other state-of-art models overall.\n\nCons:\n- The novelty of this paper is limited to some extent. It seems that the model just combines ideas of GAN and PML. \n- I wonder if GAN still works in this architecture in some situations. Under the condition when the dimension of labels is small enough, it will be hard to generate good samples because the information which can be utilized for the generator mightn't be sufficient. However, when the dimension of labels is large, there will be some combinations of labels that aren't in the training set, which may harm the performance of the generator.\n- Because the relations between instances and labels aren't one-to-one in most cases, I wonder whether the five-layer perceptron still works well as a generator if one setting of labels can correspond to various kinds of instances.\n- It will be better to compare the generator part proposed in this paper with a simple interpolation method in the process of extending the dataset."}, "signatures": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Paritial Multi-label Learning", "authors": ["Yan Yan", "Yuhong Guo"], "authorids": ["yanyan.nwpu@gmail.com", "yuhongguo.cs@gmail.com"], "keywords": [], "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify noisy labels and uses a multi-label prediction network to map the training instances to the disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels. Extensive experiments are conducted on multiple datasets, while the proposed model demonstrates the state-of-the-art performance for partial multi-label learning.", "pdf": "/pdf/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "paperhash": "yan|adversarial_paritial_multilabel_learning", "original_pdf": "/attachment/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "_bibtex": "@misc{\nyan2020adversarial,\ntitle={Adversarial Paritial Multi-label Learning},\nauthor={Yan Yan and Yuhong Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=rkehoAVtvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575940552360, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1333/Reviewers"], "noninvitees": [], "tcdate": 1570237738898, "tmdate": 1575940552375, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review"}}}, {"id": "S1xtGfhRFS", "original": null, "number": 3, "cdate": 1571893777197, "ddate": null, "tcdate": 1571893777197, "tmdate": 1572972482410, "tddate": null, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "invitation": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The motivation of this paper is to handle noise candidate multi-labels by co-training two networks. The work trains the disambiguation network, which learns to predict the probability of each class label being the additive irrelevant label and then is used to get the disambiguated label confidence vector, and the prediction network, which learns to predict the probability of the disambiguated labels.\nThe additional adversarial loss and generation loss is aimed to enhance the label disambiguation by learning the mapping from the disambiguated labels to the input features. \n\nPros:\nBy minimizing the disagreement between the confidence of being the disambiguated label and the predicted probability of each label, the partial multi-label learning gets better results. \n\nThe experiments in this paper are complete and thorough. The authors have tested the model in many datasets and designed the ablation study to verify the effect of each loss. And the proposed model achieved the state-of-art results.\n\nCons:\nHowever, the effect of the adversarial loss and the generation loss is doubtful because:\n1) The mapping from the labels to the input features is hard to learn since the label space does not contain the complete information of input features. It is doubtful that the generation is helpful.\n\n2) The results of the ablation study do not show consistently significant improvements.\n\n3) In the appendix, the variant of PML-GAN, which considers an auxiliary classification loss on the generated data, has little improvement compared to PML-GAN. The author claims that it is because of sufficient training data. What if considering the insufficient training data and testing the variant of PML-GAN? I think it can somehow verify the effect of the generation.\n\nAbout the writing of this paper, the motivation of the work is not clearly defined. Although we can get what the work was done, we cannot get why the work did this."}, "signatures": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1333/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Paritial Multi-label Learning", "authors": ["Yan Yan", "Yuhong Guo"], "authorids": ["yanyan.nwpu@gmail.com", "yuhongguo.cs@gmail.com"], "keywords": [], "abstract": "Partial multi-label learning (PML), which tackles the problem of learning multi-label prediction models from instances with overcomplete noisy annotations, has recently started gaining attention from the research community. In this paper, we propose a novel adversarial learning model, PML-GAN, under a generalized encoder-decoder framework for partial multi-label learning. The PML-GAN model uses a disambiguation network to identify noisy labels and uses a multi-label prediction network to map the training instances to the disambiguated label vectors, while deploying a generative adversarial network as an inverse mapping from label vectors to data samples in the input feature space. The learning of the overall model corresponds to a minimax adversarial game, which enhances the correspondence of input features with the output labels. Extensive experiments are conducted on multiple datasets, while the proposed model demonstrates the state-of-the-art performance for partial multi-label learning.", "pdf": "/pdf/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "paperhash": "yan|adversarial_paritial_multilabel_learning", "original_pdf": "/attachment/c8d39b52e88f5a22a5b92bc8d78415fe5bcbb98f.pdf", "_bibtex": "@misc{\nyan2020adversarial,\ntitle={Adversarial Paritial Multi-label Learning},\nauthor={Yan Yan and Yuhong Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=rkehoAVtvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkehoAVtvS", "replyto": "rkehoAVtvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1333/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575940552360, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1333/Reviewers"], "noninvitees": [], "tcdate": 1570237738898, "tmdate": 1575940552375, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1333/-/Official_Review"}}}], "count": 5}