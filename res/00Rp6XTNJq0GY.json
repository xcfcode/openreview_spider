{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1394418000000, "tcdate": 1394418000000, "number": 1, "id": "vVxEQxc6YsvBo", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "00Rp6XTNJq0GY", "replyto": "DDmlwSIalchBA", "signatures": ["Son Tran"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "The visualisation is the same if we use logistic function to normalize the filter bases."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1394417280000, "tcdate": 1394417280000, "number": 1, "id": "DDmlwSIalchBA", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "00Rp6XTNJq0GY", "replyto": "GgAKg-XrKUaHf", "signatures": ["Son Tran"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "In order to treat all filter bases equally we used the min,max from all of them. The visualization makes sense because the high-scored bases seem to capture more information about the domain while leaving the low-scored ones almost empty."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1393988160000, "tcdate": 1393988160000, "number": 2, "id": "GgAKg-XrKUaHf", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "00Rp6XTNJq0GY", "replyto": "aj9769n_gHUqJ", "signatures": ["anonymous reviewer 656d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "The complete reference is: Yoshua Bengio, 'Deep Learning of Representations for Unsupervised and Transfer Learning', JMLR: Workshop and Conference Proceedings 7 (2011) 1--20, available at http://www.iro.umontreal.ca/~lisa/pointeurs/DL_tutorial.pdf\r\n\r\nI found these new results using PCA convincing that the proposed ranking function has an advantage for transfer learning.\r\n\r\nIf the filter bases were normalized to 0-1 using min-max in Figure 2b, each filter should have at least one perfectly black and one perfectly white pixel, which I can not see in the figure. Is there a reason for this?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1393001040000, "tcdate": 1393001040000, "number": 1, "id": "DEpwCBOMgsKJr", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "00Rp6XTNJq0GY", "replyto": "aj9769n_gHUqJ", "signatures": ["Son Tran"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "[1] Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer, and Andrew Y. Ng. Self-taught learning: transfer learning from unlabeled data. In Proceedings of the 24th international conference on Machine learning, ICML \u201907, page 759766, New York, NY, USA, 2007. ACM\r\n[2] Gr\u00e9goire Mesnil, Yann Dauphin, Xavier Glorot, Salah Rifai, Yoshua Bengio, Ian J. Goodfellow, Erick Lavoie, Xavier Muller, Guillaume Desjardins, David Warde-Farley, Pascal Vincent, Aaron C. Courville, James Bergstra: Unsupervised and Transfer Learning Challenge: a Deep Learning Approach. ICML Unsupervised and Transfer Learning 2012: 97-110\r\n[3] WEI, B.; PAL, C.. Heterogeneous Transfer Learning with RBMs. AAAI Conference on Artificial Intelligence, North America, aug. 2011\r\n[4] Honglak Lee, Chaitanya Ekanadham, and Andrew Y. Ng. Sparse deep belief net model for visual area v2. In Advances in Neural Information Processing Systems. MIT Press, 2008."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1393001040000, "tcdate": 1393001040000, "number": 3, "id": "Z_q4Z3Gi4SywC", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "00Rp6XTNJq0GY", "replyto": "00Rp6XTNJq0GY", "signatures": ["Son Tran"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank the reviewer for the comments, and we have carried out further experiments as suggested, as follows: we\u2019ve updated Figures 4 and 5 to include a comparison between pruning of low-scoring units and pruning of high-scoring units.\r\n \r\nThe results seem to confirm that high-scored units capture more relevant information. Furthermore, Figure 7 indicates that high-scored units are more significant for transfer learning. Therefore, the role of high-scored units seems relevant for transfer learning. \r\n\r\nFor transfer low-scored features, we performed experiments follows what we have done with transferring high-scored features (we use the validation sets to select the features for transfer, but in this case the features are ranked from low-scores to high-scores). The results show that the highest accuracies were achieved only when a large number of high-scored features are among those which have been transferred. \r\nMNIST_30k: ICDAR_d  : 38.86%  \u00b1 0.32 (when transfer 2000/2000 units)\r\nMNIST_30k: TiCC_w_A : 76.99%  \u00b1 0.58 (when transfer 2000/2000 units)\r\nMNIST_5k : TiCC_a   : 62.50%  \u00b1 0.16 (when transfer  500/500 units)\r\nMNIST_5k : TiCC_d   : 65.19%  \u00b1 0.15 (when transfer 500/500 units)\r\n\r\nTo the best of our knowledge, most connectionist transfer learning use labels in the source domain or self-taught learning [1 2 3 4]. For the task of unsupervised representation transfer learning, as proposed in this paper, we have therefore chosen to focus on comparisons with our closest competitor: self-taught learning [1]. In addition, we propose to study how much knowledge should be transferred to the target domain, which has not been studied yet in self-taught mode.\r\n \r\n[1] Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer, and Andrew Y. Ng. Self-taught learning: transfer learning from unlabeled data. In Proceedings of the 24th international conference on Machine learning, ICML \u201907, page 759766, New York, NY, USA, 2007. ACM\r\n[2] Gr\u00e9goire Mesnil, Yann Dauphin, Xavier Glorot, Salah Rifai, Yoshua Bengio, Ian J. Goodfellow, Erick Lavoie, Xavier Muller, Guillaume Desjardins, David Warde-Farley, Pascal Vincent, Aaron C. Courville, James Bergstra: Unsupervised and Transfer Learning Challenge: a Deep Learning Approach. ICML Unsupervised and Transfer Learning 2012: 97-110\r\n[3] WEI, B.; PAL, C.. Heterogeneous Transfer Learning with RBMs. AAAI Conference on Artificial Intelligence, North America, aug. 2011\r\n[4] Honglak Lee, Chaitanya Ekanadham, and Andrew Y. Ng. Sparse deep belief net model for visual area v2. In Advances in Neural Information Processing Systems. MIT Press, 2008."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1393000980000, "tcdate": 1393000980000, "number": 1, "id": "aj9769n_gHUqJ", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "00Rp6XTNJq0GY", "replyto": "GGSwoM3J_-WZg", "signatures": ["Son Tran"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "We thank the reviewer for the suggestion of the JMLR paper. Unfortunately we could not find the paper as referred to by the reviewer; please could you point us to the complete reference? \r\n \r\nIn what concerns comparisons with competing approaches, we discuss a number of approaches in our literature review. In particular, [2, 3] transfer the knowledge selected specifically based on the target, and (in some cases) with the provision of labels in the source domain. Instead, in this paper we are interested in selecting the representations that can be transferred in general to the target without the provision of labels in the source domain. This is similar to self-taught learning [1, 4], and therefore, we have focused on comparisons with self-taught learning, showing that improvements can be achieved.\r\n \r\nWe hope that this paper will trigger further study and experimental evaluations of such an unsupervised transfer learning method.\r\n \r\nWe have run experiments using PCA, as suggested. The results, reported below, are similar to those obtained by sparse coding [1], as reported in Figure 7. This seems to confirm our analysis.\r\n \r\npca icdar 46.23%  compared to 40.43% \u00b1 0.328 from our approach\r\npca ticc  72.88%   compared to 77.56 \u00b1 0.564 from our approach\r\npca tialp 58.99%  compared to 63.00% \u00b1 0.160 from our approach\r\npca tidig 57.85%  compared to 65.82% \u00b1 0.262 from our approach\r\n \r\nWe have used character recognition problems in our experiments, but also writer recognition, using the TiCC_w dataset.\r\n \r\nIn Tables 3 and 4, each row shows the classification accuracies of a transfer method on a number of target domains. The last and second to last rows contain the accuracies on target domains for RBMs trained using adaptive learning, as proposed in Section 3. The difference is that in the second to last row only features from the additional hidden units are taken into account (see Figure 1), while in the last row, the entire hidden layer is used.\r\n \r\nNotice that the filter bases are scored and ranked before being visualized. In Figures 2a and 2b, we use min-max to normalize the bases to 0-1.  In Figure 3a and 3b there is no direct link between the visualization and the scores since, as discussed, PCA is used for preprocessing the input images in this experiment. After scoring and inverse transforming the bases to the pixel space, the min-max norm is applied to scale the data to 0-1."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391719740000, "tcdate": 1391719740000, "number": 2, "id": "zz89zXqT0UBuO", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "00Rp6XTNJq0GY", "replyto": "00Rp6XTNJq0GY", "signatures": ["anonymous reviewer a8e0"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Adaptive Feature Ranking for Unsupervised Transfer Learning", "review": "The submission proposes a scoring method for RBMs to rank hidden units according to their information content, and to use that ranking to prune networks and to do transfer learning. The transfer learning mechanism uses the ranking in the original domain to choose which hidden units to use when training in the target domain, and then uses the output of those transferred units to affect the training of the added units.   \r\n\r\nThe submission is clearly written, has relevance and interest to the ICLR community, and a number of experiments are described that validate the method. The results are promising, however there are a number of missing experiments that would have helped to validate the method. An important baseline experiment would be to compare the pruning of low-scoring units with the pruning of randomly selected, or even high-scoring units. Similarly, with the transfer learning experiments, it would be important to verify that the author's metric for replacement of sub-networks is optimal, or at least better than random choice. The submission also suffers from not making comparisons to other approaches to transfer learning in neural networks. \r\n \r\npros: well-written, relevant and interesting\r\ncons: simple approach, not adequately validated, not adequately compared against other transfer learning approaches."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391662980000, "tcdate": 1391662980000, "number": 1, "id": "GGSwoM3J_-WZg", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "00Rp6XTNJq0GY", "replyto": "00Rp6XTNJq0GY", "signatures": ["anonymous reviewer 656d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Adaptive Feature Ranking for Unsupervised Transfer Learning", "review": "This paper presents a feature ranking method for RBMs and a method to transfer RBM representations from a source domain to a target domain in an adaptive manner. While the method achieves good performance when transfering between very similar domains, the paper suffers from the following problems:\r\n\r\n- The proposed ranking function is equivalent to the L1 norm of the weight vector associated with each hidden unit, which makes the method qualitatively similar to PCA in that it prioritizes the components that explain the most variance in the data (Bengio, JMLR 7 (2011) 1--20). However, it is not obvious from the experiments that the proposed ranking has an advantage for transfer learning. A connection with the existing literature also seems lacking.\r\n\r\n- To the best of the reviewer's knowledge, the adaptive learning method for RBMs (with theta=1) is novel, but many very similar approaches to transfer learning using RBMs already exist and, once again, a review and comparison with competing approaches would be crucial.\r\n\r\n- Despite the simplicity of the concepts presented, I have found the paper confusing at times. For example, what exact setup does each row correspond to in Tables 3 and 4? What is the difference between the last and second to last rows?\r\n\r\n- Finally, the experimental section considers only the task of character recognition.\r\n\r\nOther questions:\r\n\r\n- In Figure 2(b), would we get a different interpretation if the fitler bases were normalized? Using the L1 norm of the bases for scoring, it is hardly surprising that the low-score bases have a lower magnitude when plotted on the same scale.\r\n- In Figure 3 (sparse RBM), are the bases normalized by the L2 norm?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387875900000, "tcdate": 1387875900000, "number": 50, "id": "00Rp6XTNJq0GY", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "00Rp6XTNJq0GY", "signatures": ["son.tran.1@city.ac.uk"], "readers": ["everyone"], "content": {"title": "Adaptive Feature Ranking for Unsupervised Transfer Learning", "decision": "submitted, no decision", "abstract": "Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with unsupervised learning and knowledge-based transfer.", "pdf": "https://arxiv.org/abs/1312.6190", "paperhash": "tran|adaptive_feature_ranking_for_unsupervised_transfer_learning", "keywords": [], "conflicts": [], "authors": ["Son N. Tran", "Artur d'Avila Garcez"], "authorids": ["son.tran.1@city.ac.uk", "aag@soi.city.ac.uk"]}, "writers": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 9}