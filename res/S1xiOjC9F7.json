{"notes": [{"id": "S1xiOjC9F7", "original": "rJxCN_4cYQ", "number": 384, "cdate": 1538087794905, "ddate": null, "tcdate": 1538087794905, "tmdate": 1545355442939, "tddate": null, "forum": "S1xiOjC9F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HkxVEgpugV", "original": null, "number": 1, "cdate": 1545289772328, "ddate": null, "tcdate": 1545289772328, "tmdate": 1545354474610, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Meta_Review", "content": {"metareview": "This is a tough choice as it is a reasonably strong paper.\nI am similar to another reviewer quite confused how this graph matching can \"only focus on important nodes in the graph\"\nThis seems counter-intuitive and the only reason given in the rebuttal is that other people have done it also..\n\nRelatedly: \"In graph matching, we not only care about the overall similarity of two graphs but also are interested in finding the correspondence between the nodes of two graphs\"\n\nI am sorry for the authors and hope they will get it accepted at the next conference.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Very borderline paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper384/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper384/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353235010, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper384/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper384/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper384/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353235010}}}, {"id": "ryxIsgyc27", "original": null, "number": 2, "cdate": 1541169309588, "ddate": null, "tcdate": 1541169309588, "tmdate": 1543201367678, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "content": {"title": " Interesting  application but inadequate experiments", "review": "The authors introduce a Graph Matching Network for retrieval and matching of graph structured objects. The proposed methods demonstrates improvements compared to baseline methods. However, I have have three main concerns: \n1) Unconvining experiments.\n\ta) Experiments in Sec4.1. The experiments seem not convincing. Firstly, no details of dataset split is given. Secondly, I am suspicious the proposed model is overfitted, although proposed GSL models seem to bring some improvements on the WL kernel method. As shown in Tab.3, performance of GSL models dramatically decreases when adapting to graphs with more nodes or edges. Besides, performance of the proposed GSLs also drops when adapting to different combines of k_p and k_n as pointed in Sec.B.1. However, the baseline WL kernel method demonstrates favourable generalization ability.\n\n\tb\uff09Experiments in Sec4.2. Only holding out 10% data into the testing set is not a good experiment setting and easily results in overfitting. The authors are suggested to hold more data out for testing. Besides, I wonder the generalization ability of the proposed model. The authors are suggested to test on the small unrar dataset mentioned in Sec.B.2 with the proposed model trained on the ffmpeg dataset in Sec4.2.\n\n2) Generalization ability. The proposed model seems sensitive to the size and edge density of the graphs. The authors is suggested to add experiments mentioned in (1).\n\n3) Inference time and model size. Although the proposed model seems to achieve increasing improvements with the increasing propagation layers. I wonder the cost of inference time and model size compared to baselines methods. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper384/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "cdate": 1542234473768, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335711939, "tmdate": 1552335711939, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJlK8IVhTX", "original": null, "number": 3, "cdate": 1542370897424, "ddate": null, "tcdate": 1542370897424, "tmdate": 1542370897424, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "r1g2n75E3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "content": {"title": "Author Response", "comment": "> \u201cI think that this is an interesting article, which can be accepted for ICLR provided that the cross-graph attention mechanism is discussed in more detail.\u201d\n\nThank you for your appreciation.  We hope the comments below can address your concerns.\n\n\n\n> \u201cthis is not the case for graphs with symmetries (automorphisms) \u2026 A discussion of such examples would be helpful and would make the concept of cross-graph attention clearer.\u201d\n\nIndeed the visualizations are only used to qualitatively show what the models have learned, and in practice it is not easy to see all nodes in the pair of graphs match exactly as a bijection, precisely because of the existence of a lot of symmetry.  This can be demonstrated on some very simple graphs, for example two chains of 5 nodes A1-B1-C1-D1-E1 and A2-B2-C2-D2-E2, we observe that using a trained model A1 is matched to both A2 and E2 because of symmetry, but C1 is only matched to C2.  We have added such a visualization in the revised paper (page 18, figure 7) with a bit more discussion on this.  We will make sure this clear.\n\n\n> \u201cthe proposed approach is motivated by graph matching and a connection to the graph edit distance is implied\u201d\n\nThe motivation of our graph matching networks model comes from the intuition of more efficiently fusing information from the pair of graphs.  Despite the name, this model is not directly connected to the classic graph matching problems, and the nodes are not explicitly encouraged to match.  The model can choose not to use this cross-graph matching mechanism if it learns not to.\n\nOn the other side, we didn\u2019t aim to solve the graph edit distance problem, but rather used it to study the properties of our models, and demonstrate that (1) the graph similarity learning models are competitive against hand-designed baselines and (2) they can be adapted to any similarity metric.  Our models are competitive against WL kernel, but we are also not claiming it is the state-the-art.\n\n\n> \u201cEq.3, self-attention\u201d\n\nThis form of aggregation across nodes first appeared in (Li et al. 2015), and we used exactly the same formulation (we will make this clear in the paper).  In all the experiments we have tried, this gated sum outperformed simple sum or mean aggregation by a significant margin.  The choice of this aggregation function is purely based on performance.\n\n\n> \u201cWhy do you chose the cross-graph similarity to be non-trainable?\u201d\n\nCould you clarify?  The h_i vectors are learned, hence the attention weights a_{ij} can adapt as h_i and h_j changes.  The similarity metric s_h is fixed to be a pre-specified metric, we didn\u2019t feel there\u2019s really a need to change it as the h_i\u2019s can adapt to this metric.  In hindsight, making s_h a learnable module may even improve performance further.\n\n\n> \u201cThe note on page 5 is misleading because two isomorphic graphs will lead to identical representations even if communication is not reduced to zero vectors\u201d\n\nThe note on page 5 says when (1) the nodes can perfectly match and (2) the attention weights are peaked, the cross-graph message vector will be reduced to 0, and hence the node representations will continue to be identical in the next round of propagation.  This doesn\u2019t exclude the possibility that when the cross-graph message vector is non-zero, the node representation can still be identical, as in the example you mentioned.  We will make this clear.\n\n\n> \u201chow much slower is the proposed approach in practice? \u2026 how would one solve this problem given two very large graphs\u201d\n\nWe have benchmarked the efficiency of GMN models against GNNs.  On the graph edit distance learning problem, GMNs take 1-2x as much time as GNNs on graphs from 20 nodes to 200 nodes, taking ~3 seconds to compute similarity for 1000 pairs of graphs of size 20, and ~80 seconds for 1000 pairs of graphs of size 200, when running on CPU with a tensorflow implementation.\n\nAs discussed in the paper, the GMN model scales quadratically w.r.t. number of nodes, making it very expensive for large graphs.  Therefore the setting we targeted in this paper is mostly about computing the similarity of pairs of small graphs, which already has a lot of applications.  On the other hand, sampling may be used for deploying GMNs to large graphs, by for example use a constant number of sampled nodes from the other graph to compute the cross-graph vectors.  Serious discussions and solutions for solving this scaling problem is the topic of another paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper384/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619021, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1xiOjC9F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper384/Authors|ICLR.cc/2019/Conference/Paper384/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619021}}}, {"id": "rklATS4npm", "original": null, "number": 2, "cdate": 1542370757831, "ddate": null, "tcdate": 1542370757831, "tmdate": 1542370789099, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "ryxIsgyc27", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "content": {"title": "Author Response", "comment": "> Experiments in sec 4.1:\n\nIn this experiment we were training on procedurally generated data, rather than a fixed training set.  We set aside a set of generated data and use these to compare all models.  In this setting the models will not overfit in the traditional sense, as the data generator can be queried as many times as needed to get new data for training from the data distribution, and the models will learn to fit this distribution well.\n\nOn the other hand, whether the learned model generalizes to out-of-distribution data is a separate question, and this is a challenge for any learning-based approaches.  In the graph edit distance case, generalizing across graphs of drastically different sizes is very challenging.  In the experiments in the appendix, we are training on graphs of 20-50 nodes, and testing on graphs of 100 or 200 nodes.  This is difficult as graphs with 200 nodes have 10x more nodes than graphs with only 20 nodes, and 100x more edges.\n\nWe do not claim our approach can beat the state-of-the-art on graph edit distance, and this experiment is only to show that our model can adapt to any definition of similarity.  On the other hand the WL kernel is a non-learning approach, and cannot easily adapt well to other domains when the graphs are feature-rich.  When used on large graphs WL kernel has a unique advantage over our approach as the effective feature size for a graph scales as O(T|V|), with T being the number of steps to run and |V| the number of nodes in the graph.  On the other hand, the models we studied in the paper used a constant graph feature size of 128.  Training larger models with larger graph features, and on graphs of more diverse sizes can improve the performance of our model.\n\n\n> Experiments in Sec 4.2:\n\nHolding out 10% data as the test set is a widely accepted practice in machine learning, for example the widely used ImageNet dataset contains roughly 10% data in the validation and test sets.\n\nWe didn\u2019t expect the model learned on ffmpeg to generalize to unrar, as the two softwares are very different and the distribution of the control flow graphs from the two datasets are also very different.  However, we did try this generalization experiment suggested by the reviewer and to our surprise, the GNN and GMN models does generalize quite well across datasets as shown below:\n\nTraining on ffmpeg:\nGMN: 98.01 / 97.48 (test on ffmpeg), 97.84 / 97.92 (test on unrar)\nGNN: 95.58 / 95.21 (test on ffmpeg), 94.66 / 96.35 (test on unrar)\nbaseline: 90.24 / 89.61 (test on ffmpeg)\n\nTraining on unrar:\nGMN: 96.23 / 97.92 (test on unrar), 91.82 / 91.56 (test on ffmpeg)\nGNN: 95.19 / 94.79 (test on unrar), 86.36 / 85.77 (test on ffmpeg)\nbaseline: 87.22 / 87.50 (test on unrar)\n\nHere the two numbers in each pair are pair AUC and triplet accuracy.  The models we tested are the ones that uses the graph structure only.\n\nWe can see that the models trained on ffmpeg clearly transfers very well to unrar, with performance on par with and in some cases even better than models trained on unrar alone.  While in the opposite direction, models trained on unrar doesn\u2019t transfer as well to ffmpeg as overfitting is more of a problem on the unrar dataset because it is significantly smaller.\n\n\n> Experiments in Sec 4.3:\n\nThe f_node in our formulation refers to a module that updates node representations, and we have tested MLPs, RNNs, GRUs and LSTMs for this.  When we say \u201cto aggregate the messages, we use a simple sum\u201d we were referring to the sum inside eq.2, not the form of f_node.  The GNN model described in this paper is very similar to the GCNs but more general. In particular the GNN model we described can use nonlinear MLPs for both message computation and node updates.  See references (Gilmer et al. 2017; Battaglia et al. 2018) for more discussions about different variants of GNN architectures.\n\n\n> Inference time and model size:\n\nIn the paper we have discussed the computation complexity of our models (see e.g. Sec 3.2 and Sec 5).  The GNN model scales linearly w.r.t. the number of propagation layers T, the dimensionality of h_i (D), and the number of nodes (|V|) and edges (|E|), as O(TD(|V| + |E|)).  The GMN model on the other hand scales as O(TD|V|^2).\n\nWe have benchmarked the efficiency of GMN models against GNNs.  On the graph edit distance problem, GMNs take 1-2x as much time as GNNs on graphs from 20 nodes to 200 nodes, taking ~3 seconds to compute similarity for 1000 pairs of graphs of size 20, and ~80 seconds for 1000 pairs of graphs of size 200, when running on CPU with a tensorflow implementation.\n\nComparing the wall clock time of different implementations of different approaches optimized to different levels is not very meaningful.  But just to provide an extra data point, the open source  WL kernel implementation (written in python) we used is >10x slower than both the GMN and GNNs on the same 1000 pairs of graphs with the same T, which scales as O(T(|V| + |E|)) in principle."}, "signatures": ["ICLR.cc/2019/Conference/Paper384/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619021, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1xiOjC9F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper384/Authors|ICLR.cc/2019/Conference/Paper384/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619021}}}, {"id": "r1lkzfN3TQ", "original": null, "number": 1, "cdate": 1542369799428, "ddate": null, "tcdate": 1542369799428, "tmdate": 1542369799428, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "BkercW6an7", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "content": {"title": "Author Response", "comment": "Q: \u201cit is not clear where the performance improvement comes from\u2026  not clear whether the performance improvement comes from the cross-graph interaction, or the attention module is also important ... nice if the author can do some ablation study on the structure of the new matching module.\u201d\n\nA: The experiments we did in section 4.1 and 4.2 is exactly designed to address two questions: (1) can we learn graph similarity metrics from data, and be competitive with non-learning baselines, and (2) is the cross-graph matching module really useful.  The experiment results clearly showed both.\n\nIn particular, to isolate the contributions from different factors, we made sure that when comparing the graph embedding model (GNN) and the graph matching model (GMN), all the possible confounding factors are carefully controlled*, and the only difference between them is that GMNs use the cross-graph matching mechanism, while GNNs do not.  Therefore the results reported in section 4.1 and 4.2 can clearly show that the cross-graph matching mechanism really does provide a significant improvement.\n\nIn addition to this, we provided more ablation studies in section 4.3, where we compared the effect of different node update modules f_node (GNN vs GCN), and different strategies for fusing information from both graphs (embedding vs Siamese vs matching).  We believe this is a reasonably thorough study of these important modeling decisions, and again the results show that the improvement we get from using cross-graph-matching is consistent.\n\n\nQ: \u201c... we not only care about the overall similarity of two graphs but also are interested in finding the correspondence between the nodes of two graphs, which requires the similarities between vertexes of two graphs ...\u201d\n\nA: Graph matching is an important problem, but it is not the problem we address in this paper.  The goal of the matching problem tackled in [1] is to find accurate matching between two sets of vertices, while the problem we are solving in this paper is mostly focused on learning graph-level similarity metrics.  Such a problem alone has a lot of practical applications.  On the other side, as the reviewer commented, we are also interested in finding correspondence between the nodes.  Since the focus of the approaches described in this paper is to estimate the similarity between graphs, the models don\u2019t have any explicit incentive to really match nodes.  However, we did show through the visualization of the attention maps that our GMN model can find some soft node-level matches, which is a nice by-product of our approach.\n\n\n* We did thorough hyperparameter searches over all the important hyperparameters, including number of propagation layers T, dimensionality of h_i, the type of the aggregation function (eq.3), learning rate etc., and the set of candidate hyperparameter combinations are the same for all models."}, "signatures": ["ICLR.cc/2019/Conference/Paper384/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619021, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1xiOjC9F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper384/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper384/Authors|ICLR.cc/2019/Conference/Paper384/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers", "ICLR.cc/2019/Conference/Paper384/Authors", "ICLR.cc/2019/Conference/Paper384/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619021}}}, {"id": "BkercW6an7", "original": null, "number": 3, "cdate": 1541423501484, "ddate": null, "tcdate": 1541423501484, "tmdate": 1541534040906, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "content": {"title": "A good paper, but requires more ablation study", "review": "Graph matching is a classic and import problem in computer vision, data mining, and other sub-areas of machine learning. Previously, the graph matching problems are often modeled as combinatorial optimization problems, e.g. Quadratic Assignment Problems. While these optimization problems are often NP-hard, researchers often focus on improving the efficiency of the solvers. The authors attack the problem in another way. They proposed an extension of graph embedding networks, which can embed a pair of graphs to a pair of vector representations, then the similarity between two graphs can be computed via computing the similarities of the pair of vector representations. The proposed model is able to match graphs in graph level as it can predict the similarities of the two graphs.\n\nCompare to Graph Embedding Networks (GNN), the authors proposed a new model, in which a new matching module accepts the hidden vector of nodes from two graphs and maps them to a hidden matching variable, then the hidden matching variable serves as messages as in Graph Embedding Networks. This is the main contribution of the paper compared to GNN.\n\nThe main problem of the paper is that it is not clear where the performance improvement comes from. The authors proposed a cross-graph attention-based matching module. However, it is not clear whether the performance improvement comes from the cross-graph interaction, or the attention module is also important. It would be nice if the author can do some ablation study on the structure of the new matching module.\n\nIn graph matching, we not only care about the overall similarity of two graphs but also are interested in finding the correspondence between the nodes of two graphs, which requires the similarities between vertexes of two graphs. Compared to another [1] deep learning based graph matching model, the author did not show that the proposed are able to give the matching constraints. For example, while the authors show that it is possible to use GMN to learn graph edit distances, is it possible to use the GMN to help to the exact editing?\n\n\n\n[1] Zanfir, Andrei, and Cristian Sminchisescu. \"Deep Learning of Graph Matching.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper384/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "cdate": 1542234473768, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335711939, "tmdate": 1552335711939, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1g2n75E3Q", "original": null, "number": 1, "cdate": 1540821940100, "ddate": null, "tcdate": 1540821940100, "tmdate": 1541534040500, "tddate": null, "forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "invitation": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "content": {"title": "Novel concept of cross-graph attention -- lack of in depth discussion", "review": "The authors present two methods for learning a similarity score between pairs of graphs. They first is to use a shared GNN for each graph to produce independent graph embeddings on which a similarity score is computed. The authors improve this model using pairs of graphs as input and utilizing a cross-graph attention-mechanism in combination with graph convolution. The proposed approach is evaluated on synthetic and real world tasks. It is clearly shown that the proposed approach of cross-graph attention is useful for the given task (at the cost of extra computation).\n\nA main contribution of the article is that ideas from graph matching are introduced to graph neural networks and it is clearly shown that this is beneficial. However, in my opinion the intuition, effect and limitations of the cross-graph attention mechanism should be described in more detail. I like the visualizations of the cross-graph attention, which gives the impression that the process converges to a bijection between the nodes. However, this is not the case for graphs with symmetries (automorphisms); consider, e.g., two star graphs. A discussion of such examples would be helpful and would make the concept of cross-graph attention clearer.\n\nThe experimental comparison is largely convincing. However, the proposed approach is motivated by graph matching and a connection to the graph edit distance is implied. However, in the experimental comparison graph kernels are used as baseline. I would like to suggest to also use a simple heuristics for the graph edit distance as a baseline (Riesen, Bunke. Approximate graph edit distance computation by means of bipartite graph matching. Image and Vision Computing, 27(7), 2009).\n\n\nThere are several other questions that have not been sufficiently addressed in the article.\n\n* In Eq. 3, self-attention is used to compute graph level representations to \"only focus on important nodes in the graph\". How can this be reconciled with the idea of measuring similarities across the whole graph? Can you give more insights in how the attention coefficients vary for positive as well as negative examples? How much does the self-attention affects the performance of the model in contrast to mean or sum aggregation?\n* Why do you chose the cross-graph similarity to be non-trainable? Might there be any benefits in doing so?\n* The note on page 5 is misleading because two isomorphic graphs will lead to identical representations even if communication is not reduced to zero vectors (this happens neither theoretically nor in practice).\n* Although theoretical complexity of the proposed approach is mentioned, how much slower is the proposed approach in practice? As similarity is computed for every pair of nodes across two graphs, the proposed approach, as you said, will not scale. In practice, how would one solve this problem given two very large graphs which do not fit into GPU memory? To what extent can sampling strategies be used (e.g., from GraphSAGE)? Some discussion on this would be very fruitful.\n\n\nIn summary, I think that this is an interesting article, which can be accepted for ICLR provided that the cross-graph attention mechanism is discussed in more detail.\n\n\nMinor remarks:\n\n* p3: The references provided for the graph edit distance in fact consider the (more specific) maximum common subgraph problem.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper384/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Matching Networks for Learning the Similarity of Graph Structured Objects", "abstract": "This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how  Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.", "keywords": ["Similarity learning", "structured objects", "graph matching networks"], "authorids": ["yujiali@google.com", "gcj@google.com", "thomasdullien@google.com", "vinyals@google.com", "pushmeet@google.com"], "authors": ["Yujia Li", "Chenjie Gu", "Thomas Dullien", "Oriol Vinyals", "Pushmeet Kohli"], "TL;DR": "We tackle the problem of similarity learning for structured objects with applications in particular in computer security, and propose a new model graph matching networks that excels on this task.", "pdf": "/pdf/66aa6fbe79298e8b0fdb69f8118a45d1a38f4fd7.pdf", "paperhash": "li|graph_matching_networks_for_learning_the_similarity_of_graph_structured_objects", "_bibtex": "@misc{\nli2019graph,\ntitle={Graph Matching Networks for Learning the Similarity of Graph Structured Objects},\nauthor={Yujia Li and Chenjie Gu and Thomas Dullien and Oriol Vinyals and Pushmeet Kohli},\nyear={2019},\nurl={https://openreview.net/forum?id=S1xiOjC9F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper384/Official_Review", "cdate": 1542234473768, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1xiOjC9F7", "replyto": "S1xiOjC9F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper384/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335711939, "tmdate": 1552335711939, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper384/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}