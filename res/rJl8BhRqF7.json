{"notes": [{"id": "rJl8BhRqF7", "original": "BklWKIp5KQ", "number": 1545, "cdate": 1538087998118, "ddate": null, "tcdate": 1538087998118, "tmdate": 1545355402355, "tddate": null, "forum": "rJl8BhRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1xywymlxV", "original": null, "number": 1, "cdate": 1544724311194, "ddate": null, "tcdate": 1544724311194, "tmdate": 1545354510546, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Meta_Review", "content": {"metareview": " The paper presents a new annotation of the CIFAR-10 dataset (the test set) as a distribution over labels as opposed to one-hot annotations. This datasets forms a testbed analysis for assessing the generalization abilities of the state-of-the-art models and their robustness to adversarial attacks.\n \nAll the reviewers and AC acknowledge the contribution of dataset annotation and that the idea of using label distribution for training the models is sound and should improve the generalization performance of the models.\nHowever the reviewers and AC note the following potential weaknesses: (1) the paper requires major improvement in presentation clarity and in-depth investigation and evidence of the benefits of the proposed framework \u2013 see detailed comments of R3 on what to address in a subsequent revision; see the suggestions of R2 for improving the scope of the empirical evaluations (e.g. distortions of the images, incorporating time limits for doing the classifications) and the requests of R1 for clarifications; (2) the related work is inadequate and should be substantially extended \u2013 see the related references suggested by the R2; also R1 rightly pointed out that two out of four future extensions of this framework have been addressed already, which questions the significance of findings in this submission.\nThe R2 raised concerns that the current evaluation is missing comparisons to a) the calibration approaches and b) cheaper/easier ways of getting soft labels -- see R2\u2019s suggestion to use the Brier score for model calibration and to use a cost matrix about how critical a misclassification is (cat <-> dog, versus cat <-> car) as soft labels.\nAmong these, (2) did not have a substantial impact on the decision, but would be helpful to address in a subsequent revision. However, (1) and (3) makes it very difficult to assess the benefits of the proposed approach, and was viewed by the AC as a critical issue.\n \nThere is no author response for this paper. The reviewer with a positive view on the manuscript (R3) was reluctant to champion the paper as the authors have not addressed the concerns of the other reviewers (no rebuttal).\n ", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Meta-Review"}, "signatures": ["ICLR.cc/2019/Conference/Paper1545/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1545/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352799435, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1545/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1545/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1545/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352799435}}}, {"id": "SJgtofrqnm", "original": null, "number": 3, "cdate": 1541194401190, "ddate": null, "tcdate": 1541194401190, "tmdate": 1541533046575, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "content": {"title": "Interesting idea, but the empirical investigation seems lacking", "review": "The authors create a new dataset with label distributions (rather than one-hot annotations) for the CIFAR-10 test set. They then study the effect of fine-tuning using this dataset on the generalization performance of SOTA deep networks. They also study the effects on adversarial robustness.\n\nI think that datasets such as the one generated in this paper could indeed be a valuable testbed to study deep network generalization and robustness. There are many nice benefits of label distributions over one hot labels (that the authors summarize in Section 2.) The paper is also clear and well-written. \n\nThat being said, I do not find the investigation of this paper completely satisfactory. For instance in the generalization experiments, the numbers presented seem to show some interesting (and somewhat surprising) trends, however the authors do not really pursue these or provide any insight as to why this is the case. I also find the section on robustness very weak.\n\nDetailed comments:\n\n- The theoretical contribution mentioned in the appendix does not really seem to be a contribution - it is just a simple derivation of the loss under label distributions. Theoretical contributions are not necessary for a paper to have merit - the authors should remove this statement from the introduction as it detracts from the value of the paper.\n\n- I find it somewhat surprising that the accuracy of the models does not change on training with Cifar10H. Do the authors have any intuition as to why this is the case? The model cross entropy seems to go down, indicating that probability assigned to the correct class increases. I would think that training with label distributions would actually reduce misclassification on confusing instances. It would be interesting to see how the logit distributions change for different examples. For instance, how does the model confidence change on correctly vs wrongly classified examples?\n\n- The authors mention that they run each hyperparameter configuration for three random seeds. It would be nice then to see error bars for the results reported Tables 1 and 2, particularly because the differences in accuracy are small. Did the authors try different train-test splits of the test set? It would also be helpful if the authors could make plots for the results in these tables (at least in the appendix). It is hard to compare numbers across different tables.\n\n-I find the results in Table 2 confusing. Comparing the numbers to Table 1, it seems that mixup does not really change accuracies/loss. The model names in Table 2 do not exactly match Table 1 so it is hard to identify the additional gain from using mixup that the authors mention. The authors should add plots for these results to illustrate the effect of adding mixup more clearly.\n\n-I am not convinced by the section on robustness. Firstly, it is not clear to me why the authors chose FGSM which is known to be a somewhat simple attack to illustrate improved robustness of their model. To perform a useful study of robustness, the authors should study SOTA attacks such as PGD [Madry et al., 2017]. I also do not understand the claim that the top-1 choice becomes less confident after training with CIFAR10H -- this seems to be contradicted by the fact that the cross entropy loss goes down. The authors should provide supporting evidence for this claim by looking at changes in confidence (see point 3 above). Also, the comment about the trade-off between accuracy and robustness seems vague - could the authors clarify what they mean?\n\nOverall, I like the premise of this paper and agree that with the potential benefits of the dataset generated. However, I think that the current experiments are not strong enough to corroborate this.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1545/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "cdate": 1542234206896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1545/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335969289, "tmdate": 1552335969289, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1545/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1gzsT493Q", "original": null, "number": 2, "cdate": 1541193114076, "ddate": null, "tcdate": 1541193114076, "tmdate": 1541533046323, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "content": {"title": "Multiple GT labels", "review": "The authors propose to improve classification accuracy in a supervised learning framework, by providing richer ground truth in the form a distribution over labels, that is not a Dirac delta function of the label space. This idea is sound and should improve performance.\n\nUnfortunately this work lacks novelty and isn't clearly presented.\n(1) Throughout the paper, there are turns that used without definition prior to use, all table headers in table 1. \n(2) Results are hard to interpret in the tables, and there are limited details. Mixup for example, doesn't provide exact parameters, but only mentions that its a convex sum.\n(3) There is no theoretical justification for the approach.\n(4) This approach isn't scalable past small datasets, which the authors acknowledge. \n(6) This has been already done. In the discussion the authors bring up two potential directions of work:\n   (a) providing a distribution over classes by another model - > this is distillation (https://arxiv.org/abs/1503.02531)\n   (b) adding a source of relationships between classes into the objective function -> this is (https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42854.pdf)\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1545/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "cdate": 1542234206896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1545/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335969289, "tmdate": 1552335969289, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1545/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJl5F7-53m", "original": null, "number": 1, "cdate": 1541178241646, "ddate": null, "tcdate": 1541178241646, "tmdate": 1541533046116, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "content": {"title": "Official Review: Not fully motivated and related to previous work on learning with class uncertainty and calibration", "review": "The paper presents a new version of CIFAR10 that is labelled by multiple people (the test part of the data). They use it to improve the calibration of several image classifiers through \u201cfine-tuning\u201d and other techniques\nThe title is too general, taking into account that this setting has appeared in classification in many domains, with different names (learning from class distributions, crowd labellers, learning from class scores, etc.). See for instance,\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3994863/\nhttp://www.cs.utexas.edu/~atn/nguyen-hcomp15.pdf \nAlso, at the end of section 2 we simply reach logloss, which is a traditional way of evaluating the calibration of a classifier, but other options exist, such as the Brier score. At times, the authors mention the trade-off between classification accuracy and cross-entropy. This sounds very much the trade-off between refinement and calibration, as one of the possible decompositions of the Brier score.\nThe authors highlight the limitations of this work, and they usually mention that the problem must be difficult (e.g., low resolution). Otherwise, humans are too good to be useful. I suggest the authors to compare with psychophysics and possible distortions of the images, or time limits for doing the classifications. \nNevertheless, the paper is not well motivated, and the key procedures, such as \u201cfine-tuning\u201d lack detail, and comparison with other options.\nIn section 2, which is generally good and straightforward, we find that p(x|c) being non-overlapping as a situation where uncertainty would be not justified. Overlap would simply say that it is a categorisation (multilabel classification) problem rather than a classification problem, but this is different from the situation where labels are soft or given by several users. \nIn the end, the paper is presented from the perspective of image recognition, but it should be compared with many other areas in classification evaluation where different metrics, presentation of the data, levels of uncertainty, etc., are used, including different calibration methods, as alternatives to the expensive method presented here based on crowd labelling.\nPros:\n-\tMore information about borderline cases may be useful for learning. This new dataset seems to capture this information.\nCons:\n-\tThe extra labelling is very costly, as the authors recognise.\n-\tThe task is known in the classification literature, and a proper comparison with other approaches is required.\n-\tNot compared with calibration approaches or other ways where boundaries can be softened with less information from human experts. For instance, a cost matrix about how critical a misclassification is considered by humans (cat <-> dog, versus cat <-> car) could also be very useful, and much easier to obtain.\n", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1545/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Official_Review", "cdate": 1542234206896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1545/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335969289, "tmdate": 1552335969289, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1545/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syg4O1pYcm", "original": null, "number": 2, "cdate": 1539063660233, "ddate": null, "tcdate": 1539063660233, "tmdate": 1539063660233, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rkeWn1Q4qX", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Public_Comment", "content": {"comment": "Thanks. I would like to use your data/code and I'm waiting for the release. ", "title": "That's nice"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1545/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311572148, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rJl8BhRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311572148}}}, {"id": "rkeWn1Q4qX", "original": null, "number": 1, "cdate": 1538695081087, "ddate": null, "tcdate": 1538695081087, "tmdate": 1538695081087, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "HJgVn7UX9Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Official_Comment", "content": {"title": "Dataset release", "comment": "Thanks for your interest. We are indeed planning to release the dataset (both the aggregate and individual human responses) as soon as the paper lands. We also intend to release some code and trained models. It's intended to serve as a new benchmark, target of research questions, and even a training/tuning dataset."}, "signatures": ["ICLR.cc/2019/Conference/Paper1545/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1545/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626646, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJl8BhRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1545/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1545/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1545/Authors|ICLR.cc/2019/Conference/Paper1545/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626646}}}, {"id": "HJgVn7UX9Q", "original": null, "number": 1, "cdate": 1538642860378, "ddate": null, "tcdate": 1538642860378, "tmdate": 1538642860378, "tddate": null, "forum": "rJl8BhRqF7", "replyto": "rJl8BhRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1545/Public_Comment", "content": {"comment": "It is a neat idea to, for CIFAR classification problem, create soft labels by collecting human supervision, which should be useful to improve generalization ability. Do you have any plan to release the data CIFAR10H?", "title": "Interesting data"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1545/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving machine classification using human uncertainty measurements", "abstract": "As deep CNN classifier performance using ground-truth labels has begun to asymptote at near-perfect levels, a key aim for the field is to extend training paradigms to capture further useful structure in natural image data and improve model robustness and generalization. In this paper, we present a novel natural image benchmark for making this extension, which we call CIFAR10H. This new dataset comprises a human-derived, full distribution over labels for each image of the CIFAR10 test set, offering the ability to assess the generalization of state-of-the-art CIFAR10 models, as well as investigate the effects of including this information in model training. We show that classification models trained on CIFAR10 do not generalize as well to our dataset as it does to traditional extensions, and that models fine-tuned using our label information are able to generalize better to related datasets, complement popular data augmentation schemes, and provide robustness to adversarial attacks. We explain these improvements in terms of better empirical approximations to the expected loss function over natural images and their categories in the visual world.", "keywords": ["image classification", "human experiments", "risk minimization"], "authorids": ["ruairidh.battleday@gmail.com", "peterson.c.joshua@gmail.com", "tomg@princeton.edu"], "authors": ["Ruairidh M. Battleday", "Joshua C. Peterson", "Thomas L. Griffiths"], "TL;DR": "improving classifiers using human uncertainty measurements", "pdf": "/pdf/7fe14a2b7afca18c80478cb120b1fc064becdc48.pdf", "paperhash": "battleday|improving_machine_classification_using_human_uncertainty_measurements", "_bibtex": "@misc{\nbattleday2019improving,\ntitle={Improving machine classification using human uncertainty measurements},\nauthor={Ruairidh M. Battleday and Joshua C. Peterson and Thomas L. Griffiths},\nyear={2019},\nurl={https://openreview.net/forum?id=rJl8BhRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1545/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311572148, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rJl8BhRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1545/Authors", "ICLR.cc/2019/Conference/Paper1545/Reviewers", "ICLR.cc/2019/Conference/Paper1545/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311572148}}}], "count": 8}