{"notes": [{"id": "9kwvuuKmRQA", "original": "lx3Llt6Vm6W", "number": 7, "cdate": 1615595597563, "ddate": null, "tcdate": 1615595597563, "tmdate": 1615844206814, "tddate": null, "forum": "9kwvuuKmRQA", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission", "content": {"title": "Neurons learn slower than they think", "authorids": ["ICLR.cc/2021/Workshop/Learning_to_Learn/Paper7/Authors"], "authors": ["Anonymous"], "keywords": ["explainable and reliable AI", "optimization", "convergence rate", "generalization error", "differential capability", "item response theory"], "TL;DR": "Neurons learn slower than they think", "abstract": "Recent studies revealed complex convergence dynamics in gradient-based methods, which has been little understood so far. Changing the step size to balance between high convergence rate and small generalization error may not be sufficient: maximizing the test accuracy usually requires a larger learning rate than minimizing the training loss. To explore the dynamic bounds of convergence rate, this study introduces \\textit{differential capability} into an optimization process, which measures whether the test accuracy increases as fast as a model approaches the decision boundary in a classification problem. The convergence analysis showed that: 1) a higher convergence rate leads to slower capability growth; 2) a lower convergence rate results in faster capability growth and decay; 3) regulating a convergence rate in either direction reduces differential capability.", "pdf": "/pdf/89317c9d24994247cb3c1a2010b07a4ba448bf79.pdf", "proposed_reviewers": "", "paperhash": "anonymous|neurons_learn_slower_than_they_think", "_bibtex": "@inproceedings{\nanonymous2021neurons,\ntitle={Neurons learn slower than they think},\nauthor={Anonymous},\nbooktitle={Submitted to Learning to Learn - Workshop at ICLR 2021},\nyear={2021},\nurl={https://openreview.net/forum?id=9kwvuuKmRQA},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "proposed_reviewers": {"value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615595596483, "tmdate": 1615844205826, "id": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}