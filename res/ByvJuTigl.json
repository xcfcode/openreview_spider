{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396704145, "tcdate": 1486396704145, "number": 1, "id": "SyumpGUul", "invitation": "ICLR.cc/2017/conference/-/paper607/acceptance", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "In many respects, this is a strong paper, in my opinion better than the reviews thus far in the system suggest. The idea of learning the parameters of a state estimation system, even if it is a simple example like a histogram filter, is an interesting idea from both the ML and robotics perspectives.\n \n However, I think it's also fairly clear (from the reviews if nothing else), that substantial additional work needs to be done if this paper is to convey these ideas clearly and impactfully to the ICLR community. The value of the histogram filter may be obvious to the robotics community (though even there it seems like it would be worth pursuing the extension of these ideas to the case e.g. of particle filters), as these have historically been an important conceptual milestone in robotic perception, but the examples shown in this paper are extremely simplistic. Given that histogram filters inherently scale poorly with dimension, it's not clear from this paper itself why the techniques show particular promise for scaling up to realistic domains in the future.\n \n Pros:\n + Interesting idea of using training a state estimator end-to-end for robotics tasks\n \n Cons:\n - Histogram filters, while well-motivated historically from the robotics standpoint, are really toy examples at this point except in a very small number of settings.\n - The results aren't all that compelling, showing modest improvement (over seemingly not-very-tuned alternatively approaches), on fairly simple domains."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396704674, "id": "ICLR.cc/2017/conference/-/paper607/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396704674}}}, {"tddate": null, "tmdate": 1485820478827, "tcdate": 1485820478827, "number": 7, "id": "HJDHfIpvl", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "Retraction", "comment": "We are retracting our paper \"End-to-End Learnable Histogram Filters\" from ICLR to submit a revised version to another venue."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1483539603200, "tcdate": 1483539603200, "number": 6, "id": "Bkjq4Y5Hx", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "Sy3ue5QSx", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "Answer to AnonReviewer2", "comment": "Thank you very much for your review. We would like to comment on the two negative points.\n\n1) The paper does not assume that deep learning is the natural choice for learning state estimation. It assumes that deep learning with generic networks marks one end of a spectrum of approaches while Bayes filters mark the other end of this spectrum. Our work demonstrates by example how to construct intermediate approaches that balance the benefits of both extremes.\n\nAll our experiments do have a \"pure Bayesian filter baseline\", a pure histogram filter (HF), whose models are fit to the data of the task to have a fair comparison (these models are virtually identical to the \"correct\" models for the given tasks).\n\n2) We would like to clarify that the state space in the task is continuous in all our experiments.\n\nAs pointed out in the paper, the discretization employed by the filter is a bottle neck, as is the use of discrete (although not necessarily binary) observations. We are currently working on both issues using different representations of the belief."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1483537747157, "tcdate": 1478379487182, "number": 607, "id": "ByvJuTigl", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ByvJuTigl", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "content": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1483083891772, "tcdate": 1483083891772, "number": 3, "id": "Sy3ue5QSx", "invitation": "ICLR.cc/2017/conference/-/paper607/official/review", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/conference/paper607/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper607/AnonReviewer2"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "Summary: This paper presents a differentiable histogram filter for state estimation/tracking. The proposed histogram filter is a particular Bayesian filter that represents the discretized states using beliefs. The prediction step is parameterized by a locally linear and translation-invariant motion model while the measurement model is represented by a multi-layered neural network. The whole system is learned with both supervised and unsupervised objectives and experiments are carried out on two synthetic robot localization tasks (1D and 2D). The major claim of this paper is that the problem-specific model structure (Bayesian filter for state estimation) should improve pure deep learning approach in data-efficiency and generalization ability. \n+This paper has nice arguments about the importance of prior knowledge to deep learning approach for specific tasks. \n+An end-to-end histogram filter is derived for state estimation and unsupervised learning is possible in this model.\n-This paper seems to have a hidden assumption that deep learning (RNN) is a natural choice for recursive state estimation and the rest of paper is built upon this assumption including LSTM baselines. However, this assumption itself may not be true, because Bayesian filter is a first-established approach for this classic problem, so it it more important to justify if deep learning is even necessary for solving the tasks presented. This requests pure Bayesian filter baselines in the experiments. \n-The derived histogram filter seems to be particularly designed for discretized state space. It is not clear how well it can be generalized to continuous state space using the notation \"x\". More interestingly, the observation is discrete (binary) as well, which eventually makes it possible to derive a closed-form measurement update model. This setup might be too constrained. Generalizing to continuous observations is not a trivial task, not even to mention using images as observations like Haarnoja et al 2016. These design choices overall narrow down the scope of applicability.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483083892630, "id": "ICLR.cc/2017/conference/-/paper607/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper607/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper607/AnonReviewer3", "ICLR.cc/2017/conference/paper607/AnonReviewer1", "ICLR.cc/2017/conference/paper607/AnonReviewer2"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483083892630}}}, {"tddate": null, "tmdate": 1482014006687, "tcdate": 1482014006687, "number": 5, "id": "HkkSa4m4g", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "SkM7mibVg", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "Answer to AnonReviewer1", "comment": "Thank you very much for your review. We would like to comment on the negative points 1-4 and clarify the contribution and the aim of our paper.\n\nPoints 1 and 2 question the novelty/contribution of the motion model and the measurement model, but neither the motion model nor the measurement model are the core contributions of our paper. The main technical contribution is the differentiable implementation of the histogram filter algorithm to enable end-to-end learning (where any model can be plugged in). The---equally important---conceptual contribution is the idea of using existing algorithms as priors in deep learning, or put differently, using the differentiable implementation of existing algorithms as a principled approach to explore new deep learning models.\n\nThe main objection in points 1-3 of this review (and the main objection of AnonReviewer3) is: *This model is too simplistic to be useful in practice.* This statement is true---for this paper and for the majority of basic research. The end-to-end histogram filter is not supposed to be the final answer to learning state estimation, it is only supposed to demonstrate an explorative step in a new direction. The results are not meant to prove practicality of the model but show that there is a gradient that might be worthwhile following. We absolutely agree that more work needs to be done to make this practical. But only by sharing new ideas and experimental findings with the community can we enable such future work, which is why we are writing this paper.\n\nTL;DR: We agree that the presented method is not practical yet, but we are surprised that this should be the most important measure of scientific value.\n\nMore detailed comments:\n\n1. Even when the motion model is implemented as a generic feed-forward network, the resulting E2E-HF still uses structural assumptions of the Bayes filter algorithm: (a) It forces the hidden activations to represent a belief over states (rather than any combinations of features over the history). (b) It assumes conditional independence of observations and actions given the state by separating the update and prediction steps. (c) It constrains the measurement update to multiplicatively influence the belief. (d) It constrains the prediction step to \"move\" beliefs in the state space. All of these constraints are optimal for state estimation when we consider the problem to be an MDP, a model that has proven very useful. (We will add this explanation to the paper.)\n\n2. See above.\n\n3. While the histogram representation of the belief does not scale well, the aforementioned structure does. Following the conceptual approach presented in the paper, the histogram filter can be extended naturally to a particle filter (by enabling the histogram bins to move in the state space). Particle filters have been applied to very high-dimensional problems (e.g. SLAM). This extension of the presented work has the potential to scale to highly complex settings.\n\n4. This is an excellent suggestion. We will perform additional experiments to find out if/with how much data LSTMs start outperforming E2E-HFs."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1481909018310, "tcdate": 1481909018310, "number": 2, "id": "SkM7mibVg", "invitation": "ICLR.cc/2017/conference/-/paper607/official/review", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/conference/paper607/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper607/AnonReviewer1"], "content": {"title": "Review", "rating": "4: Ok but not good enough - rejection", "review": "\nSummary:\n--------\nThe authors propose a histogram based state representation with differentiable motion models and observation updates for state tracking from observations. Linear model with Gaussian noise is used as the motion model, while a neural network is used to learn the measurement model. They track robot states in: (1) 1-D hallway, and (2) a 2D arena.\n\n\nPositives:\n----------\n1. Show how to encode prior knowledge about state-transitions in the architecture.\n2. No assumptions about the observation model, which is learned purely from data.\n3. Better accuracy than baselines with limited training data.\n\nNegatives:\n----------\n1. The motion model is too simplistic. The authors in their response to earlier questions say that a generic feed-forward neural network could be used to model more complicated motions. However, then the novelty of their framework is not clear -- as then the proposed model would just be a couple of neural networks to learn the motion and observation models.\n\n2. The observation model again is too simplistic (e.g., one dimensional observations), and is proposed to be a generic feed-forward network. Here again, the technical novelty is not clear.\n\n3. The histogram based representation is not scalable as also highlighted by the authors. Hence, the proposed approach as it is, cannot be applied to more complicated settings.\n\n4. In Figure 5(a,b), where they compare the state-estimation accuracy with other baselines (i.e., LSTMs), it is clear that the accuracy of the LSTM has not saturated, while that of their model has. They should do larger scale experiments with more training data (e.g., 10k,100k,500k samples). \nNote that while sample efficiency is a desirable property (also discussed in Section 6.2), we do expect models with prior knowledge to work better for small number of samples than models which do not assume any structure. Experiments with larger number of samples would be insightful.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483083892630, "id": "ICLR.cc/2017/conference/-/paper607/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper607/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper607/AnonReviewer3", "ICLR.cc/2017/conference/paper607/AnonReviewer1", "ICLR.cc/2017/conference/paper607/AnonReviewer2"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483083892630}}}, {"tddate": null, "tmdate": 1481835863912, "tcdate": 1481835863906, "number": 4, "id": "SygwHFgVg", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "HkFYrQeVx", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "Answer to AnonReviewer3", "comment": "We think that it is difficult to compare to E2C (Watter et al. 2015) because they solve a different problem. While E2C estimates the state from a single observation (assuming it to be Markov), we are concerned with partially observable problems where a single observation is insufficient to estimate the state---which is the case for most robotic problems. There are a number of approaches that learn state representations from pixels assuming Markov observations, including our own work (Jonschkowski and Brock, 2015), but these are unable to learn recursive state estimation loops. Hence, this paper.\n\nWe compare to LSTMs because LSTMs are the state of the art in sequence-based learning. We are unsure which other models we should compare against. We are also not aware of prior work that combines HMM/MDP structure with neural networks that would applicable for learning state estimation in partially observable problems. Could you please provide references to these works?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1481811329552, "tcdate": 1481811329545, "number": 1, "id": "HkFYrQeVx", "invitation": "ICLR.cc/2017/conference/-/paper607/official/review", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/conference/paper607/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper607/AnonReviewer3"], "content": {"title": "", "rating": "3: Clear rejection", "review": "The authors propose a time-series model with discrete states for robotics applications. I think the proposed method is too simplistic to be useful in the presented form, eg. 1) the state space (dimensionality & topology) is exactly matched to the experiments 2) displacements in the transition model are linear in the actions 3) observations are one-dimensional. This seems to be quite behind the current state of the art, eg \u201cEmbed to Control\u201d by Watter et al 2015, where a state representation is learned directly from pixels.\nFurthermore the authors do not compare to any other method except for an out-of-the-box LSTM model. Also, I feel like there must be a lot of prior work for combining HMMs + NNs out there, I think it would be necessary for the authors to relate their work to this literature. \u00a0\u00a0", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483083892630, "id": "ICLR.cc/2017/conference/-/paper607/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper607/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper607/AnonReviewer3", "ICLR.cc/2017/conference/paper607/AnonReviewer1", "ICLR.cc/2017/conference/paper607/AnonReviewer2"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483083892630}}}, {"tddate": null, "tmdate": 1481564945806, "tcdate": 1481564945798, "number": 3, "id": "BJqzQPn7l", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "r1GlP-PQl", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "UPDATE on LSTM baselines ", "comment": "I have just rerun a few experiments with larger LSTMs (64 hidden units / 128 hidden units per layer) and it did not substantially affect the learning curves. I will continue investigating this and update the learning curves in the paper using the best performing baseline (64 hidden units might be a little bit better than 32, but with 128 units performance is already decreasing again). And what I did not mention before: We are using gradient clipping (clipping parameter = 5) to ensure stability for training the LSTMs."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1481237127506, "tcdate": 1481237127375, "number": 2, "id": "HJJqzvwmx", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "r1GlP-PQl", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "LSTM hyper-parameters", "comment": "Thank you for your questions.\n\nWe used a stacked (two-layer) LSTM with 32 hidden units per layer. \n\nIn a previous workshop-version of the paper, we compared against different architectures (LSTMs and vanilla RNNs with one or two layers), see Fig. 3 in that preliminary paper (http://www.robotics.tu-berlin.de/fileadmin/fg170/Publikationen_pdf/Jonschkowski-16-IROS_WS.pdf). All baseline models performed about the same with two-layer LSTMs having a slightly better performance than the other baselines. We also performed a rough search over the number of hidden units and 32 seemed to lead to a reasonable underfitting/overfitting trade-off for the tasks and the given amounts of data. To further reduce the amount of hyper-parameter tuning, we used an adaptive learning rate method for gradient descent: ADAM with default parameters for all methods (including ours), and we performed early stopping with patience of 100 episodes to automatically adjust the complexity of the learned models to the given amounts of data.\n\nHaving said that, we did not perform an exhaustive search over all possible baseline architectures. We don't think that the qualitative results would be different. It should not be surprising that the histogram filter outperforms LSTMs in a setting with little data since there is so much information that the LSTM would have to learn from data which is hard-coded into the histogram filter (that is the very point of our paper).\n\nBut I definitely see your point and I am interested in a fair comparison. If you think that it is crucial, I could perform another search over the LSTM hyper-parameters. Which ones would you vary and in what ranges?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1481213674063, "tcdate": 1481213674053, "number": 2, "id": "r1GlP-PQl", "invitation": "ICLR.cc/2017/conference/-/paper607/pre-review/question", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/conference/paper607/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper607/AnonReviewer3"], "content": {"title": "Details of the LSTM baseline?", "question": "How large were the LSTM baseline models? Did the authors perform hyper-parameter optimization (eg on model size & learning rate) to a reasonable degree for the baselines?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481213674893, "id": "ICLR.cc/2017/conference/-/paper607/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper607/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper607/AnonReviewer1", "ICLR.cc/2017/conference/paper607/AnonReviewer3"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481213674893}}}, {"tddate": null, "tmdate": 1481030912961, "tcdate": 1481030775981, "number": 1, "id": "HylYnEEQx", "invitation": "ICLR.cc/2017/conference/-/paper607/public/comment", "forum": "ByvJuTigl", "replyto": "HydBs217x", "signatures": ["~Rico_Jonschkowski1"], "readers": ["everyone"], "writers": ["~Rico_Jonschkowski1"], "content": {"title": "Answers to AnonReviewer1", "comment": "Thank you very much for your questions. We will answer each question first concisely and then give more detailed explanations.\n\n---\n\n1. Linear motion models are not a limitation of end-to-end learnable histogram filters (E2E-HFs). a) Linear motion models were only needed to make unsupervised learning work. Supervised learning worked well with generic motion models in all our experiments. b) Locally linear or other simple motion models have proven useful in practice and are widely applied in robotics. c) More complex/generic motion models can be used instead. Overall, E2E-HFs present an opportunity, not a requirement, to insert prior knowledge about robot motion. However, as mentioned in the paper, the assumption that motion is independent of the state is a restriction of E2E-HFs. We are currently addressing this problem to scale the approach to more complex settings as described below (see 2.b).\n\na) In our experiments, we found that the restrictions on the motion model were only required in the unsupervised setting, while training the E2E-HF using supervised learning worked well even when we used a generic feed forward network as motion model (we omitted these experiments due to space constraints).\n\nb) Practical experience in robotics shows that it is often sufficient to ignore the environment in the motion model (Thrun et al.: Probabilistic Robotics), especially when the robot has access to odometry/inertial measurements, which already include the result of actual physical interactions. When robots are blocked by obstacles, their wheel odometers or inertial sensors will show no movement, which will be the action-input to the filter. The only remaining issues are wrong predictions of movements through obstacles. However, this can typically be ignored because faulty motion predictions lead to wrong observation predictions in the future (and are thus discarded in the measurement updates).\n\nc) More complex motion models can be used as long as the motion is not affected by the state, which our implementation of the measurement update cannot handle due to our reformulation of the prediction using convolution, as mentioned in our paper. Below, we describe how we will address this issue in future work (see 2.b).\n\n---\n\n2. The scenario you are describing is in fact very similar to the one we used in the paper, and even if we make it harder still, our method can be adapted to it (a). We agree that we must, ultimately, test our approach in more realistic, complex settings. However, we are currently addressing shortcomings of our method that are required before it can be scaled to really complex high-dimensional settings (b). Knowing that the presented work is only an intermediate step, we want to share it with the community such that other people can pick up this idea and work on it simultaneously in order to reach the goal of solving complex real world tasks.\n\na) In the scenario of Question 2, we would use the inertial measurements (i.e. robot velocities) instead of fan velocities as actions for the filter (as described in 1.b), which brings us to the scenario used in the paper. The existence of obstacles and the fan-velocity actions would only affect motion generation, not navigation. Now, if you remove the inertial sensor from the drone so that fan-velocities are the only action-related information that we have, then there are two options: (i) if we have knowledge about the kinematics of the drone, we can define a suitably structured motion model or (ii) if we don't have this knowledge, we can use a generic neural network for the motion model. In the latter case, however, we will have to balance this loss of information, e.g. by providing more data, by adding a few labels to otherwise unsupervised data, or by adding additional information elsewhere (e.g. in the form of suitable loss functions as described in our work: \"Learning State Representations with Robotic Priors\"). \n\nb) The main bottlenecks of our method are that computation scales exponentially with number of state dimensions and the fact that motion must be independent of the state. We point out both issues in the paper and we are currently working on an extension of this work that addresses both of these concerns by going from the histogram filter to a particle filter. This extension will allow to use the state as input for the motion model and to represent the belief with non-uniform resolution, which are important next steps to scale to more complex settings."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287502363, "id": "ICLR.cc/2017/conference/-/paper607/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByvJuTigl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper607/reviewers", "ICLR.cc/2017/conference/paper607/areachairs"], "cdate": 1485287502363}}}, {"tddate": null, "tmdate": 1480735551761, "tcdate": 1480735551757, "number": 1, "id": "HydBs217x", "invitation": "ICLR.cc/2017/conference/-/paper607/pre-review/question", "forum": "ByvJuTigl", "replyto": "ByvJuTigl", "signatures": ["ICLR.cc/2017/conference/paper607/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper607/AnonReviewer1"], "content": {"title": "Scaling to Complex Settings", "question": "1. A strong prior on the motion model is assumed -- linear motion with Gaussian noise. This is applicable only in simple scenarios: such motion model is not directly applicable in settings, where either: (1) the actions relate to the resulting motion in a more complicated way, or (2) the environment effects the transition -- which is the case for most practical settings. \nHow can this approach be scaled to such more complex settings?\n\n2. How does the proposed method perform in more realistic settings, e.g. drone navigation in a complex environment (with obstacles) with inertial measurements and fan-velocity actions?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Learnable Histogram Filters", "abstract": "Problem-specific algorithms and generic machine learning approaches have complementary strengths and weaknesses, trading-off data efficiency and generality. To find the right balance between these, we propose to use problem-specific information encoded in algorithms together with the ability to learn details about the problem-instance from data. We demonstrate this approach in the context of state estimation in robotics, where we propose end-to-end learnable histogram filters---a differentiable implementation of histogram filters that encodes the structure of recursive state estimation using prediction and measurement update but allows the specific models to be learned end-to-end, i.e. in such a way that they optimize the performance of the filter, using either supervised or unsupervised learning.", "pdf": "/pdf/e074094d321fa15bcb3ac8fc42954ef29afd269f.pdf", "TL;DR": "a way to combine the algorithmic structure of Bayes filters with the end-to-end learnability of neural networks", "paperhash": "jonschkowski|endtoend_learnable_histogram_filters", "conflicts": ["tu-berlin.de"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Rico Jonschkowski", "Oliver Brock"], "authorids": ["rico.jonschkowski@tu-berlin.de", "oliver.brock@tu-berlin.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481213674893, "id": "ICLR.cc/2017/conference/-/paper607/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper607/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper607/AnonReviewer1", "ICLR.cc/2017/conference/paper607/AnonReviewer3"], "reply": {"forum": "ByvJuTigl", "replyto": "ByvJuTigl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper607/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481213674893}}}], "count": 14}