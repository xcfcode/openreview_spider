{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396672764, "tcdate": 1486396672764, "number": 1, "id": "B1Y-6M8_x", "invitation": "ICLR.cc/2017/conference/-/paper552/acceptance", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "Three knowledgable reviewers recommend rejection. The main concern is missing related work on fashion product search, and thus also baselines. The authors did not post a rebuttal to address the concerns. The AC agrees with the reviewers' recommendation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396673267, "id": "ICLR.cc/2017/conference/-/paper552/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396673267}}}, {"tddate": null, "tmdate": 1482199078798, "tcdate": 1482199078798, "number": 3, "id": "rJJNlzU4g", "invitation": "ICLR.cc/2017/conference/-/paper552/official/review", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/conference/paper552/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper552/AnonReviewer3"], "content": {"title": "interesting exploration but several major concerns", "rating": "4: Ok but not good enough - rejection", "review": "The paper presents a large-scale visual search system for finding product images given a fashion item. The exploration is interesting and the paper does a nice job of discussing the challenges of operating in this domain. The proposed approach addresses several of the challenges. \n\nHowever, there are several concerns.\n\n1) The main concern is that there are no comparisons or even mentions of the work done by Tamara Berg\u2019s group on fashion recognition and fashion attributes, e.g., \n-  \u201cAutomatic Attribute Discovery and Characterization from Noisy Web Data\u201d ECCV 2010 \n- \u201cWhere to Buy It: Matching Street Clothing Photos in Online Shops\u201d ICCV 2015,\n- \u201cRetrieving Similar Styles to Parse Clothing, TPAMI 2014,\netc\nIt is difficult to show the contribution and novelty of this work without discussing and comparing with this extensive prior art.\n\n2) There are not enough details about the attribute dataset and the collection process. What is the source of the images? Are these clean product images or real-world images? How is the annotation done? What instructions are the annotators given? What annotations are being collected? I understand data statistics for example may be proprietary, but these kinds of qualitative details are important to understand the contributions of the paper. How can others compare to this work?\n\n3) There are some missing baselines. How do the results in Table 2 compare to simpler methods, e.g., the BM or CM methods described in the text?\n\nWhile the paper presents an interesting exploration, all these concerns would need to be addressed before the paper can be ready for publication.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512545126, "id": "ICLR.cc/2017/conference/-/paper552/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper552/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper552/AnonReviewer1", "ICLR.cc/2017/conference/paper552/AnonReviewer2", "ICLR.cc/2017/conference/paper552/AnonReviewer3"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512545126}}}, {"tddate": null, "tmdate": 1482127034494, "tcdate": 1482127034494, "number": 2, "id": "B1Mp8grVl", "invitation": "ICLR.cc/2017/conference/-/paper552/official/review", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/conference/paper552/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper552/AnonReviewer2"], "content": {"title": "Good practical visual search system but lack novelty", "rating": "3: Clear rejection", "review": "This paper introduces a pratical large-scale visual search system for a fashion site. It uses RNN to recognize multi-label attributes and uses state-of-art faster RCNN to extract features inside those region-of-interest (ROI). The technical contribution of this paper is not clear. Most of the approaches used are standard state-of-art methods and there are not a lot of novelties in applying those methods. For multi-label recognition task, there are other available methods, e.g. using binary models, changing cross-entropy loss function, etc. There aren't any comparison between the RNN method and other simple baselines. The order of the sequential RNN prediction is not clear either. It seems that the attributes form a tree hierarchy and that is used as the order of sequence.\n\nThe paper is not well written either. Most results are reported in the internal dataset and the authors won't release the dataset. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512545126, "id": "ICLR.cc/2017/conference/-/paper552/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper552/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper552/AnonReviewer1", "ICLR.cc/2017/conference/paper552/AnonReviewer2", "ICLR.cc/2017/conference/paper552/AnonReviewer3"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512545126}}}, {"tddate": null, "tmdate": 1481946690984, "tcdate": 1481946690984, "number": 1, "id": "BkjrLVG4x", "invitation": "ICLR.cc/2017/conference/-/paper552/official/review", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/conference/paper552/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper552/AnonReviewer1"], "content": {"title": "Contribution not clear enough; concerns about data set itself", "rating": "3: Clear rejection", "review": "The manuscript is a bit scattered and hard to follow. There is technical depth but the paper doesn't do a good job explaining what shortcoming the proposed methods are overcoming and what baselines they are outperforming. \n\nThe writing could be improved. There are numerous grammatical errors.\n\nThe experiments in 3.1 are interesting, but you need to be clearer about the relationship of your ResCeption method to the state-of-the-art. The use of extensive footnotes on page 5 is a bit odd. \"That is a competitive result\" is vague. A footnote links to \"http://image-net.org/challenges/LSVRC/2015/results\" which doesn't seem to even show the same task you are evaluating. ResCeption: \"The best validation error is reached at 23.37% and 6.17% at top-1 and top-5, respectively\". Single model ResNet-152 gets 19.38 and 4.49, respectively. Resnet-34 is 21.8 and 5.7, respectively. VGGv5 is 24.4 and 7.1, respectively.  [source: Deep Residual Learning for Image Recognition, He et al. 2015]. I think it would be more honest for you to report results of competitors and say that your model is worse than ResNet and slightly better than VGG on ImageNet classification.\n\n3.5, retrieval on Holidays, is a bit too much of a diversion from the goal of this paper. If this paper is more about the novel architecture and less about the particular fashion attribute task then the narrative needs to change accordingly.\n\nPerhaps my biggest concern is that this paper is missing baselines (e.g. non recurrent models, attribute classification instead of detection) and comparisons to prior work by Berg et al.\n\n\"Our policy restricts to reveal much more details about the internal dataset\" This is a significant issue. The dataset used in this work cannot be shared? How are future works going to compare to your benchmark?\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512545126, "id": "ICLR.cc/2017/conference/-/paper552/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper552/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper552/AnonReviewer1", "ICLR.cc/2017/conference/paper552/AnonReviewer2", "ICLR.cc/2017/conference/paper552/AnonReviewer3"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512545126}}}, {"tddate": null, "tmdate": 1481801950981, "tcdate": 1481801950976, "number": 3, "id": "ByP1ZZeNg", "invitation": "ICLR.cc/2017/conference/-/paper552/public/comment", "forum": "HyWDCXjgx", "replyto": "Hk2TQH97e", "signatures": ["~Taewan_Kim1"], "readers": ["everyone"], "writers": ["~Taewan_Kim1"], "content": {"title": "Experiments for baseline", "comment": "Dear AnonReviewer1\n\nThank you for your valuable comments. As you mentioned, We also tried to the multi-label classification using the cross-entropy. We are going to perform several experiments formally, and will finish the revision of our manuscript as soon as possible.\nPlease give us more time.\n\nSincerely,\nTaewan Kim"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287524391, "id": "ICLR.cc/2017/conference/-/paper552/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWDCXjgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper552/reviewers", "ICLR.cc/2017/conference/paper552/areachairs"], "cdate": 1485287524391}}}, {"tddate": null, "tmdate": 1481801667714, "tcdate": 1481801667706, "number": 2, "id": "Bkh6k-eNx", "invitation": "ICLR.cc/2017/conference/-/paper552/public/comment", "forum": "HyWDCXjgx", "replyto": "S1KRTXCMg", "signatures": ["~Taewan_Kim1"], "readers": ["everyone"], "writers": ["~Taewan_Kim1"], "content": {"title": "Updating our manuscript", "comment": "Dear AnonReviewer3\n\nThank you for your valuable comments. We keep updating to our manuscript.\nPlease give us more time. We will finish the revision of our manuscript as soon as possible.\n\nBest regards\nTaewan Kim"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287524391, "id": "ICLR.cc/2017/conference/-/paper552/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWDCXjgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper552/reviewers", "ICLR.cc/2017/conference/paper552/areachairs"], "cdate": 1485287524391}}}, {"tddate": null, "tmdate": 1481425860397, "tcdate": 1481425860389, "number": 2, "id": "Hk2TQH97e", "invitation": "ICLR.cc/2017/conference/-/paper552/pre-review/question", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/conference/paper552/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper552/AnonReviewer1"], "content": {"title": "Non-recurrent basline?", "question": "The main focus of this paper is the recurrent architecture, but do you have a non-recurrent baseline? Instead of conditioning each arttribute decision on previous attribute decisions, you can try to recognize them all at once. It's easy enough to write a multi-label loss function. The most common multi-label loss is referred to as \"cross entropy\" loss (but then the definition of soft-max vs cross-entropy get confusing). For example, see \"Deep Convolutional Ranking for Multilabel Image Annotation. Yunchao Gong, Yangqing Jia, Thomas Leung, Alexander Toshev, Sergey Ioffe. 2013\".\n\nAnother question, in Table 2 you're reporting a particular precision and recall, not average precision? I think average precision pe attribute would be the more meaningful metric."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481425861147, "id": "ICLR.cc/2017/conference/-/paper552/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper552/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper552/AnonReviewer3", "ICLR.cc/2017/conference/paper552/AnonReviewer1"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481425861147}}}, {"tddate": null, "tmdate": 1480633809167, "tcdate": 1480633809163, "number": 1, "id": "S1KRTXCMg", "invitation": "ICLR.cc/2017/conference/-/paper552/pre-review/question", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["ICLR.cc/2017/conference/paper552/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper552/AnonReviewer3"], "content": {"title": "Clarifications, relationship to prior work, and baselines", "question": "1) Please explain more about the attribute dataset and the collection process. What is the source of the images? Are these clean product images or real-world images? How is the annotation done? What instructions are the annotators given? What annotations are being collected? (I understand data statistics for example may be proprietary, but these kinds of qualitative details are important to understand the contributions of the paper)\n\n2) How is this work related to the work done by Tamara Berg\u2019s group on fashion recognition and fashion attributes, e.g., \n-  \u201cAutomatic Attribute Discovery and Characterization from Noisy Web Data\u201d ECCV 2010 ( I understand that the proposed method is deep learning-based and that the data is manually annotated, I\u2019m wondering how the types of attributes, the data, the intuitions, etc. are different),\n- \u201cWhere to Buy It: Matching Street Clothing Photos in Online Shops\u201d ICCV 2015,\n- \u201cRetrieving Similar Styles to Parse Clothing, TPAMI 2014,\netc.\n\n3) How do the results in Table 2 compare to simpler methods, e.g., the BM or CM methods described in the text?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481425861147, "id": "ICLR.cc/2017/conference/-/paper552/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper552/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper552/AnonReviewer3", "ICLR.cc/2017/conference/paper552/AnonReviewer1"], "reply": {"forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper552/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481425861147}}}, {"tddate": null, "tmdate": 1479533253689, "tcdate": 1479533253684, "number": 1, "id": "SkC6Gv6-g", "invitation": "ICLR.cc/2017/conference/-/paper552/public/comment", "forum": "HyWDCXjgx", "replyto": "HyWDCXjgx", "signatures": ["~Taewan_Kim1"], "readers": ["everyone"], "writers": ["~Taewan_Kim1"], "content": {"title": "Revision for minor typographical error", "comment": "We fixed minor typographical error in author's name and Section. 4. etc.\nOur policy restricts to reveal much more details about the internal dataset and results of the end-user satisfaction measure, however, we did our best to introduce how our idea is to be used for multi-label learning in an application to computer vision, especially e-commerce industry. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287524391, "id": "ICLR.cc/2017/conference/-/paper552/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWDCXjgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper552/reviewers", "ICLR.cc/2017/conference/paper552/areachairs"], "cdate": 1485287524391}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1479532460757, "tcdate": 1478340184592, "number": 552, "id": "HyWDCXjgx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HyWDCXjgx", "signatures": ["~Taewan_Kim1"], "readers": ["everyone"], "content": {"title": "Multi-label learning with the RNNs for Fashion Search", "abstract": "We build a large-scale visual search system which finds similar product images given a fashion item. Defining similarity among arbitrary fashion-products is still remains a challenging problem, even there is no exact ground-truth. To resolve this problem, we define more than 90 fashion-related attributes, and combination of these attributes can represent thousands of unique fashion-styles. We then introduce to use the recurrent neural networks (RNNs) recognising multi fashion-attributes with the end-to-end manner. To build our system at scale, these fashion-attributes are again used to build an inverted indexing scheme. In addition to these fashion-attributes for semantic similarity, we extract colour and appearance features in a region-of-interest (ROI) of a fashion item for visual similarity. By sharing our approach, we expect active discussion on that how to apply current deep learning researches into the e-commerce industry.", "pdf": "/pdf/8727cae92fcd5b5602f6c9e0979201896bd42e7f.pdf", "TL;DR": "Works for applying LSTM into the multi-label learning in an application to computer vision", "paperhash": "kim|multilabel_learning_with_the_rnns_for_fashion_search", "authors": ["Taewan Kim"], "authorids": ["taey.16@navercorp.com"], "conflicts": ["sk.com", "navercorp.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 10}