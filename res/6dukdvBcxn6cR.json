{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1391638440000, "tcdate": 1391638440000, "number": 2, "id": "xheJhouLQlYLp", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "6dukdvBcxn6cR", "replyto": "6dukdvBcxn6cR", "signatures": ["Ludovic Denoyer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We first thank the reviewer for the comment.\r\n\r\nConcerning the fact that most difficult versions of mountain car have been already solved, we perfectly agree. In our paper, we are using a very simple version of mountain car in order to demonstrate the ability of our approach to extract hidden information from observations and from the dynamicity of the system. More difficult versions of mountain car and of other complex reinforcement learning tasks are under investigation, and we plan to present these experiments in a full paper in the next months.\r\n\r\nSince the paper size was restricted to 3 pages in the call for papers, we have focused on the relation of our model with the closest/lastest models of the literature and thus we agree that this submission lacks some important references. We will submit quickly a longer version of the paper discussing the differences between our approach and other existing methods that are not described in the current version.\r\n\r\nThe three papers cited by the reviewer propose to tackle a control problem where the reward function is known: the recurrent neural networks are used as controllers for the task to solve, and thus are able to extract an hidden representation that depends on the task. Our approach is unsupervised and learn representations using randomly chosen trajectories without using the reward function. On this regard, our work is closer to the approach of (Gisslen et al., 2011) and (Duell et al., 2012) that are also based on unsupervised learning. In comparison to these last approaches, the originality is to propose a transductive model that directly learns the model of the world in the representation space, allowing us to compute simulations of the future of the system even if no information is observed (we note that (Schmidhuber,1990) could be adaptated to do so in RL applications). This also allows different ways to infer representations on new observations.\r\nWe'd like to stress out that the representations learned with our model could also be used for different tasks than RL.\r\n\r\n==\r\n'This is not accurate - the representation of (Gissl en et al., 2011) had fixed size, but in principle the history could have arbitrary depth, because they used a RAAM like Pollack's (NIPS 1989) as unsupervised sequence compressor: J. B. Pollack. Implications of Recursive Distributed Representations. Advances in Neural Information Processing Systems I, NIPS, 527-536, 1989.'\r\n\r\nYes, thank you for pointing out the lack of clarity of this sentence, it will be modified in the next version."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning States Representations in POMDP", "decision": "submitted, no decision", "abstract": "We propose to deal with sequential processes where only partial observations are available by learning a latent representation space on which policies may be accurately learned.", "pdf": "https://arxiv.org/abs/1312.6042", "paperhash": "contardo|learning_states_representations_in_pomdp", "keywords": [], "conflicts": [], "authors": ["Gabriella Contardo", "Ludovic Denoyer", "Thierry Artieres", "patrick gallinari"], "authorids": ["gabriella.contardo@lip6.fr", "ludovic.denoyer@lip6.fr", "thierry.artieres@lip6.fr", "patrick.gallinari@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391443260000, "tcdate": 1391443260000, "number": 1, "id": "GGBm_ztp7nyT5", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "6dukdvBcxn6cR", "replyto": "6dukdvBcxn6cR", "signatures": ["anonymous reviewer 2349"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning States Representations in POMDP", "review": "Learning States Representations in POMDP\r\nGabriella Contardo, Ludovic Denoyer, Thierry Artieres, Patrick Gallinari\r\n\r\nSummary: The authors present a model that learns representations of sequential inputs on random trajectories through the state space, then feed those into a reinforcement learner, to deal with partially observable environments. They apply this to a POMDP mountain car problem, where the velocity of the car is not visible but has to be inferred from successive observations.\r\n\r\nComments:\r\n\r\nPrevious work has solved more difficult versions of the POMDP mountain car problem, where the input was raw vision as opposed to the very low-dimensional state space of the authors. Please discuss in the context of the present approach:\r\n\r\nG. Cuccu, M. Luciw, J. Schmidhuber, F. Gomez. Intrinsically Motivated Evolutionary Search for Vision-Based Reinforcement Learning. In Proc. Joint IEEE International Conference on Development and Learning (ICDL) and on Epigenetic Robotics (ICDL-EpiRob 2011), Frankfurt, 2011.\r\nFrom the abstract: 'The method is successfully demonstrated on a vision-based version of the well-known mountain car benchmark, where controllers receive only single high-dimensional visual images of the environment, from a third-person perspective, instead of the standard two-dimensional state vector which includes information about velocity.' \r\n\r\nSec 4: 'For example (Gissl\u0013en et al., 2011) proposed to learn reprentations with an auto-associative model with a fi\fxed-size history'\r\n\r\nThis is not accurate - the representation of  (Gissl\u0013en et al., 2011) had fixed size, but in principle the history could have arbitrary depth, because they used a RAAM like Pollack's (NIPS 1989) as unsupervised sequence compressor:\r\n\r\nJ. B. Pollack. Implications of Recursive Distributed Representations. Advances in Neural Information Processing Systems I, NIPS, 527-536, 1989.\r\n\r\nOf course, RNN for POMPD RL have been around since 1990 - please discuss differences to the approach of the authors:\r\n\r\nJ.  Schmidhuber. An on-line algorithm for dynamic reinforcement learning and planning in reactive environments. In Proc. IEEE/INNS International Joint Conference on Neural Networks, San Diego, volume 2, pages 253-258, 1990.\r\n\r\nOne should probably also discuss recent results with huge RNN for vision-based POMDP RL:\r\n\r\nJ. Koutnik, G. Cuccu, J. Schmidhuber, F. Gomez. Evolving Large-Scale Neural Networks for Vision-Based Reinforcement Learning. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO), Amsterdam, 2013.\r\n\r\nGeneral recommendation: It is not quite clear to this reviewer how this work goes beyond the previous work mentioned above. At the very least, the authors should make the differences very clear."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning States Representations in POMDP", "decision": "submitted, no decision", "abstract": "We propose to deal with sequential processes where only partial observations are available by learning a latent representation space on which policies may be accurately learned.", "pdf": "https://arxiv.org/abs/1312.6042", "paperhash": "contardo|learning_states_representations_in_pomdp", "keywords": [], "conflicts": [], "authors": ["Gabriella Contardo", "Ludovic Denoyer", "Thierry Artieres", "patrick gallinari"], "authorids": ["gabriella.contardo@lip6.fr", "ludovic.denoyer@lip6.fr", "thierry.artieres@lip6.fr", "patrick.gallinari@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387808880000, "tcdate": 1387808880000, "number": 9, "id": "6dukdvBcxn6cR", "invitation": "ICLR.cc/2014/workshop/-/submission", "forum": "6dukdvBcxn6cR", "signatures": ["gabriella.contardo@lip6.fr"], "readers": ["everyone"], "content": {"title": "Learning States Representations in POMDP", "decision": "submitted, no decision", "abstract": "We propose to deal with sequential processes where only partial observations are available by learning a latent representation space on which policies may be accurately learned.", "pdf": "https://arxiv.org/abs/1312.6042", "paperhash": "contardo|learning_states_representations_in_pomdp", "keywords": [], "conflicts": [], "authors": ["Gabriella Contardo", "Ludovic Denoyer", "Thierry Artieres", "patrick gallinari"], "authorids": ["gabriella.contardo@lip6.fr", "ludovic.denoyer@lip6.fr", "thierry.artieres@lip6.fr", "patrick.gallinari@gmail.com"]}, "writers": [], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357014, "id": "ICLR.cc/2014/workshop/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357014}}}], "count": 3}