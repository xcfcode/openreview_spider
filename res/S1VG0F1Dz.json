{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124438485, "tcdate": 1518472716132, "number": 341, "cdate": 1518472716132, "id": "S1VG0F1Dz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "S1VG0F1Dz", "signatures": ["~Scott_Gigante1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Deep Transition-Encoding Networks for Learning Dynamics", "abstract": "Markov processes, both classical and higher order, are often used to model dynamic processes, such as stock prices, molecular dynamics, and Monte Carlo methods. Previous works have shown that an autoencoder can be formulated as a specific type of Markov chain. Here, we propose a generative neural network known as a transition encoder, or transcoder, which learns such continuous-state dynamic processes. We show that the transcoder is able to learn both deterministic and stochastic dynamic processes on several systems. We explore a number of applications of the transcoder including generating unseen trajectories and examining the propensity for chaos in a dynamic system. Finally, we show that the transcoder can speed up Markov Chain Monte Carlo (MCMC) sampling to a convergent distribution by training it to make several steps at a time.", "paperhash": "dijk|deep_transitionencoding_networks_for_learning_dynamics", "keywords": ["markov process", "autoencoder", "deep learning", "unsupervised learning", "generative models"], "_bibtex": "@misc{\n  dijk2018deep,\n  title={Deep Transition-Encoding Networks for Learning Dynamics},\n  author={David van Dijk and Scott Gigante and Alexander Strzalkowski and Guy Wolf and Smita Krishnaswamy},\n  year={2018},\n  url={https://openreview.net/forum?id=S1VG0F1Dz}\n}", "authorids": ["david.vandijk@yale.edu", "scott.gigante@yale.edu", "alexander.strzalkowski@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["David van Dijk", "Scott Gigante", "Alexander Strzalkowski", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "The transcoder is a generative neural network that is able to learn any stochastic or deterministic Markov process.", "pdf": "/pdf/cb3cbc7132930b492969510dee3f3a124773fc73.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521583001756, "tcdate": 1519240113094, "number": 1, "cdate": 1519240113094, "id": "SyKhQHswf", "invitation": "ICLR.cc/2018/Workshop/-/Paper341/Official_Review", "forum": "S1VG0F1Dz", "replyto": "S1VG0F1Dz", "signatures": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer3"], "content": {"title": "Lazy cut down of longer paper", "rating": "2: Strong rejection", "review": "This submission is effectively a lazy cut down of the preprint \n\nhttps://arxiv.org/pdf/1802.03497.pdf?fname=cm&font=TypeI \n\nwhere the authors have simply taken the introduction and some of the empirical results (without any noticeable rewriting) and hoped that these still make sense with most of the paper removed.  Unsurprisingly, this is not the case and results in a somewhat nonsensical submission without any clear technical content.  The method is left almost completely unexplained and the technical contribution is very unclear.  As such it is very difficult to argue for acceptance.\n\nSpecific points:\n- The \"reinterpretation of existing autoencoders as deterministic Markov chains\" is completely unclear.  I have no idea what you mean by this other than the obvious and uninteresting fact that both are mappings from an input space to an output space.\n- Monte Carlo methods are neither a dynamic process nor something that you model.  I understand that what you mean is that stochastic Markov processes are used for inference via MCMC, but what you actually say is quite different to this.\n- The transcoder will clearly convergence to the wrong distribution for the MCMC context (see e.g. figure 2.3D) and so the last sentence of the abstract is at best misleading and worst straight up wrong.  Same goes for the last sentence of the first paragraph of section 2.\n- The concept of fast-forwarding MCMC is itself rather spurious, or at least a very convoluted view of the problem.  An MCMC sampler that carries out multiple steps in one go is itself an MCMC sampler, just one with a better proposal.  Thus what you are really doing here is proposal adaptation, something which is well established in the Bayesian inference literature (see e.g. Approximate Inference with Amortised MCMC by Li et al 2017, for some recent work in the area).", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Transition-Encoding Networks for Learning Dynamics", "abstract": "Markov processes, both classical and higher order, are often used to model dynamic processes, such as stock prices, molecular dynamics, and Monte Carlo methods. Previous works have shown that an autoencoder can be formulated as a specific type of Markov chain. Here, we propose a generative neural network known as a transition encoder, or transcoder, which learns such continuous-state dynamic processes. We show that the transcoder is able to learn both deterministic and stochastic dynamic processes on several systems. We explore a number of applications of the transcoder including generating unseen trajectories and examining the propensity for chaos in a dynamic system. Finally, we show that the transcoder can speed up Markov Chain Monte Carlo (MCMC) sampling to a convergent distribution by training it to make several steps at a time.", "paperhash": "dijk|deep_transitionencoding_networks_for_learning_dynamics", "keywords": ["markov process", "autoencoder", "deep learning", "unsupervised learning", "generative models"], "_bibtex": "@misc{\n  dijk2018deep,\n  title={Deep Transition-Encoding Networks for Learning Dynamics},\n  author={David van Dijk and Scott Gigante and Alexander Strzalkowski and Guy Wolf and Smita Krishnaswamy},\n  year={2018},\n  url={https://openreview.net/forum?id=S1VG0F1Dz}\n}", "authorids": ["david.vandijk@yale.edu", "scott.gigante@yale.edu", "alexander.strzalkowski@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["David van Dijk", "Scott Gigante", "Alexander Strzalkowski", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "The transcoder is a generative neural network that is able to learn any stochastic or deterministic Markov process.", "pdf": "/pdf/cb3cbc7132930b492969510dee3f3a124773fc73.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521583001522, "id": "ICLR.cc/2018/Workshop/-/Paper341/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper341/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper341/AnonReviewer2"], "reply": {"forum": "S1VG0F1Dz", "replyto": "S1VG0F1Dz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper341/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper341/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521583001522}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582592891, "tcdate": 1521052105347, "number": 2, "cdate": 1521052105347, "id": "rybAK1PYM", "invitation": "ICLR.cc/2018/Workshop/-/Paper341/Official_Review", "forum": "S1VG0F1Dz", "replyto": "S1VG0F1Dz", "signatures": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer2"], "content": {"title": "Unclear presentation, contribution, and results.", "rating": "3: Clear rejection", "review": "This paper seems to be very early work on reinterpreting autoencoders as Markov chains. This idea by itself is not new, and has been explored extensively in the literature, and it's not clear from the presentation if there is anything new the authors want to add to the conversation.\n\nIt's not at all clear what the algorithm/model actually is, since the authors chose to use an imprecise language (English) to describe it, instead of mathematical notation or an algorithm box. A reader unfamiliar with the literature would not gain anything at all from reading since they wouldn't be able to appreciate what the algorithm even is.\n\nEven if the reader manages to deduce the algorithm (using their prior expertise), the results are not presented well. It's not clear what to expect, and what the authors are trying to show.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Transition-Encoding Networks for Learning Dynamics", "abstract": "Markov processes, both classical and higher order, are often used to model dynamic processes, such as stock prices, molecular dynamics, and Monte Carlo methods. Previous works have shown that an autoencoder can be formulated as a specific type of Markov chain. Here, we propose a generative neural network known as a transition encoder, or transcoder, which learns such continuous-state dynamic processes. We show that the transcoder is able to learn both deterministic and stochastic dynamic processes on several systems. We explore a number of applications of the transcoder including generating unseen trajectories and examining the propensity for chaos in a dynamic system. Finally, we show that the transcoder can speed up Markov Chain Monte Carlo (MCMC) sampling to a convergent distribution by training it to make several steps at a time.", "paperhash": "dijk|deep_transitionencoding_networks_for_learning_dynamics", "keywords": ["markov process", "autoencoder", "deep learning", "unsupervised learning", "generative models"], "_bibtex": "@misc{\n  dijk2018deep,\n  title={Deep Transition-Encoding Networks for Learning Dynamics},\n  author={David van Dijk and Scott Gigante and Alexander Strzalkowski and Guy Wolf and Smita Krishnaswamy},\n  year={2018},\n  url={https://openreview.net/forum?id=S1VG0F1Dz}\n}", "authorids": ["david.vandijk@yale.edu", "scott.gigante@yale.edu", "alexander.strzalkowski@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["David van Dijk", "Scott Gigante", "Alexander Strzalkowski", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "The transcoder is a generative neural network that is able to learn any stochastic or deterministic Markov process.", "pdf": "/pdf/cb3cbc7132930b492969510dee3f3a124773fc73.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521583001522, "id": "ICLR.cc/2018/Workshop/-/Paper341/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper341/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper341/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper341/AnonReviewer2"], "reply": {"forum": "S1VG0F1Dz", "replyto": "S1VG0F1Dz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper341/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper341/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521583001522}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573608794, "tcdate": 1521573608794, "number": 277, "cdate": 1521573608443, "id": "H1Weyyk9M", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "S1VG0F1Dz", "replyto": "S1VG0F1Dz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Transition-Encoding Networks for Learning Dynamics", "abstract": "Markov processes, both classical and higher order, are often used to model dynamic processes, such as stock prices, molecular dynamics, and Monte Carlo methods. Previous works have shown that an autoencoder can be formulated as a specific type of Markov chain. Here, we propose a generative neural network known as a transition encoder, or transcoder, which learns such continuous-state dynamic processes. We show that the transcoder is able to learn both deterministic and stochastic dynamic processes on several systems. We explore a number of applications of the transcoder including generating unseen trajectories and examining the propensity for chaos in a dynamic system. Finally, we show that the transcoder can speed up Markov Chain Monte Carlo (MCMC) sampling to a convergent distribution by training it to make several steps at a time.", "paperhash": "dijk|deep_transitionencoding_networks_for_learning_dynamics", "keywords": ["markov process", "autoencoder", "deep learning", "unsupervised learning", "generative models"], "_bibtex": "@misc{\n  dijk2018deep,\n  title={Deep Transition-Encoding Networks for Learning Dynamics},\n  author={David van Dijk and Scott Gigante and Alexander Strzalkowski and Guy Wolf and Smita Krishnaswamy},\n  year={2018},\n  url={https://openreview.net/forum?id=S1VG0F1Dz}\n}", "authorids": ["david.vandijk@yale.edu", "scott.gigante@yale.edu", "alexander.strzalkowski@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["David van Dijk", "Scott Gigante", "Alexander Strzalkowski", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "The transcoder is a generative neural network that is able to learn any stochastic or deterministic Markov process.", "pdf": "/pdf/cb3cbc7132930b492969510dee3f3a124773fc73.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}