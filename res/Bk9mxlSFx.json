{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028635251, "tcdate": 1490028635251, "number": 1, "id": "rk7Put6jx", "invitation": "ICLR.cc/2017/workshop/-/paper153/acceptance", "forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Combinatorial Optimization with Reinforcement Learning", "abstract": "We present a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city \\mbox{coordinates}, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to $100$ nodes. These results, albeit still quite far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.", "pdf": "/pdf/df63d4e834036329d2e0785a34df7956200671a0.pdf", "TL;DR": "neural combinatorial optimization, reinforcement learning", "paperhash": "bello|neural_combinatorial_optimization_with_reinforcement_learning", "conflicts": ["google.com"], "keywords": [], "authors": ["Irwan Bello", "Hieu Pham", "Quoc Le", "Mohammad Norouzi", "Samy Bengio"], "authorids": ["ibello@google.com", "hyhieu@google.com", "qvl@google.com", "mnorouzi@google.com", "bengio@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028635768, "id": "ICLR.cc/2017/workshop/-/paper153/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028635768}}}, {"tddate": null, "tmdate": 1489185817030, "tcdate": 1489185817030, "number": 2, "id": "Bybm2sljl", "invitation": "ICLR.cc/2017/workshop/-/paper153/official/review", "forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "signatures": ["ICLR.cc/2017/workshop/paper153/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper153/AnonReviewer1"], "content": {"title": "Neural networks for NP-hard problems", "rating": "7: Good paper, accept", "review": "This paper is basically pointer networks but with reinforcement learning. The reward is the negative tour length.\n\nI think this approach is superior to the original pointer networks, which assumed a supervised signal. Since we're working with NP-hard problems, this is difficult to obtain.\n\nPros:\n+ Good ablation study. I particularly liked the Active Learning ablation, which tries to train a network from scratch for one instance of the problem.\n+ Results on toy TSP problems (lengths 25, 50, 100) are near optimal.\n+ Authors recognize the limitations of their approach w.r.t. order of magnitude worse running time\n\nCons:\n- Unclear how well this approach will scale up to non-toy scales\n- Would like to have seen other NP-hard problems\n\nThis paper is a good fit for the workshop.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Combinatorial Optimization with Reinforcement Learning", "abstract": "We present a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city \\mbox{coordinates}, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to $100$ nodes. These results, albeit still quite far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.", "pdf": "/pdf/df63d4e834036329d2e0785a34df7956200671a0.pdf", "TL;DR": "neural combinatorial optimization, reinforcement learning", "paperhash": "bello|neural_combinatorial_optimization_with_reinforcement_learning", "conflicts": ["google.com"], "keywords": [], "authors": ["Irwan Bello", "Hieu Pham", "Quoc Le", "Mohammad Norouzi", "Samy Bengio"], "authorids": ["ibello@google.com", "hyhieu@google.com", "qvl@google.com", "mnorouzi@google.com", "bengio@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489185817827, "id": "ICLR.cc/2017/workshop/-/paper153/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper153/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper153/AnonReviewer2", "ICLR.cc/2017/workshop/paper153/AnonReviewer1"], "reply": {"forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper153/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper153/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489185817827}}}, {"tddate": null, "tmdate": 1489182014475, "tcdate": 1489182014475, "number": 1, "id": "By8B65xjx", "invitation": "ICLR.cc/2017/workshop/-/paper153/official/review", "forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "signatures": ["ICLR.cc/2017/workshop/paper153/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper153/AnonReviewer2"], "content": {"title": "review", "rating": "7: Good paper, accept", "review": "This is a well written and interesting paper.\nTo carry out the inference for TSP problem by REINFORCE algorithm make a lot more sense.\nHowever, I feel to apply LSTM as the encoder is still not perfect.\nAs the extension of pointer network on this problem, the paper could have more explorations on the model design or combination of heuristics instead of simply reusing the ptrNet structure with REINFORCE algorithm. \nThough I would be conservative about using vanilla pointer network on combinatorial optimization problems, the paper gave enough insights and experiments showing the significance of applying neural network on the classical problems.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Combinatorial Optimization with Reinforcement Learning", "abstract": "We present a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city \\mbox{coordinates}, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to $100$ nodes. These results, albeit still quite far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.", "pdf": "/pdf/df63d4e834036329d2e0785a34df7956200671a0.pdf", "TL;DR": "neural combinatorial optimization, reinforcement learning", "paperhash": "bello|neural_combinatorial_optimization_with_reinforcement_learning", "conflicts": ["google.com"], "keywords": [], "authors": ["Irwan Bello", "Hieu Pham", "Quoc Le", "Mohammad Norouzi", "Samy Bengio"], "authorids": ["ibello@google.com", "hyhieu@google.com", "qvl@google.com", "mnorouzi@google.com", "bengio@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489185817827, "id": "ICLR.cc/2017/workshop/-/paper153/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper153/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper153/AnonReviewer2", "ICLR.cc/2017/workshop/paper153/AnonReviewer1"], "reply": {"forum": "Bk9mxlSFx", "replyto": "Bk9mxlSFx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper153/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper153/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489185817827}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487368226168, "tcdate": 1487368226168, "number": 153, "id": "Bk9mxlSFx", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "Bk9mxlSFx", "original": "rJY3vK9eg", "signatures": ["~Hieu_Pham1"], "readers": ["everyone"], "content": {"title": "Neural Combinatorial Optimization with Reinforcement Learning", "abstract": "We present a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city \\mbox{coordinates}, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to $100$ nodes. These results, albeit still quite far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.", "pdf": "/pdf/df63d4e834036329d2e0785a34df7956200671a0.pdf", "TL;DR": "neural combinatorial optimization, reinforcement learning", "paperhash": "bello|neural_combinatorial_optimization_with_reinforcement_learning", "conflicts": ["google.com"], "keywords": [], "authors": ["Irwan Bello", "Hieu Pham", "Quoc Le", "Mohammad Norouzi", "Samy Bengio"], "authorids": ["ibello@google.com", "hyhieu@google.com", "qvl@google.com", "mnorouzi@google.com", "bengio@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "replyto": null, "ddate": null, "active": true, "tmdate": 1485326312519, "tcdate": 1478297522043, "number": 506, "id": "rJY3vK9eg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJY3vK9eg", "signatures": ["~Hieu_Pham1"], "readers": ["everyone"], "content": {"title": "Neural Combinatorial Optimization with Reinforcement Learning", "abstract": "This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city coordinates, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. We compare learning the network parameters on a set of training graphs against learning them on individual test graphs. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to 100 nodes. Applied to the KnapSack, another NP-hard problem, the same method obtains optimal solutions for instances with up to 200 items. These results, albeit still far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.", "pdf": "/pdf/dc0c13426b0f4e480cb06f70c0e511ea499242ce.pdf", "TL;DR": "This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning.", "paperhash": "bello|neural_combinatorial_optimization_with_reinforcement_learning", "conflicts": ["google.com"], "keywords": ["Reinforcement Learning", "Deep learning"], "authors": ["Irwan Bello*", "Hieu Pham*", "Quoc V. Le", "Mohammad Norouzi", "Samy Bengio"], "authorids": ["ibello@google.com", "hyhieu@google.com", "qvl@google.com", "mnorouzi@google.com", "bengio@google.com"]}, "writers": [], "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}