{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392819900000, "tcdate": 1392819900000, "number": 4, "id": "732i7lUnhD9_E", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "M7uvMK0-IZCh9", "replyto": "M7uvMK0-IZCh9", "signatures": ["Yolanda Liao"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Thanks for the comments. We have revised the paper and here are some responses below.\r\n-------------------------------------------\r\n\u201cI found the whole paper hard work to follow.\u201d \r\nWe have revised the paper in many places and submit a new version.\r\n-------------------------------------------\r\n\u201cResults tables don't give column headings. It wasn't clear what the variable was - the dimension? \u201d\r\nIt would be clearer to break out the 'error measure' into a separate column. \r\nEach column is the class we used in the clustering or semi-supervised tasks. It is also equivalent to the dimension of hidden layer or representation. The \u2018error measure\u2019 is given in the first column, each row indicates a method in a error measure with respect to different number of classes we use.\r\n-------------------------------------------\r\n\u201cThe two metrics used weren't very clear to me \u2013 \r\nthe mapping from unsupervised k-means clusters to class labels \u201d\r\nIt follows the evaluation method in the GNMF paper which is on the dimension reduction too.\r\nhttp://www.cad.zju.edu.cn/home/dengcai/Publication/Journal/TPAMI-GNMF.pdf\r\n-------------------------------------------\r\n\u201cHow does it compare to a simple 1-NN hinge-loss technique similar to those used by Weston e.g. for training joint embeddings? http://www.thespermwhale.com/jaseweston/papers/wsabie-ijcai.pdf\u201d\r\nWe have read the paper. The technique in this paper gives an idea to preserve the local property. However, it takes much time to implement this algorithm. We will try to use it in our work in the future. In this paper, we mainly want to show whether the local invariant can be applied in deep architecture.\r\n-------------------------------------------\r\n\u201cWhat parameters eta, lambda $k$ (for the graph construction) were chosen? How did this $k$ affect the results? \u201d\r\nThe parameters are chosen using a grid based search on the validation set. We give the performance with the best parameter configuration.\r\n-------------------------------------------\r\n\u201cHow expensive is the proposed technique compared to the alternative?\u201d\r\nThe time complexity is similar to sparse auto-encoders, as it is a change of constraint. The main problem is space complexity of graph matrix. However, we use the sparse matrix to save the information. Since the graph connection is sparse, there are many zero entries."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392819780000, "tcdate": 1392819780000, "number": 1, "id": "01eFZdqG9Y0Vo", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "M7uvMK0-IZCh9", "replyto": "kCK_izo04OivH", "signatures": ["Yolanda Liao"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thanks for the comments. We have some responses below, and uploaded a new version of paper to clarify some problems. In our new version, we mainly revised Section 1 and Section 2, and we add some experiments at Section 4.1. The experiments we add may give some insights about the comparison to [6] and the meaning of the reconstruction error.\r\n-------------------------------------------\r\n\u201c\u2026related to methods for dimensionality reduction like deep parametric t-sne\u2026. Deep Supervised t-Distributed Embedding\u201d\r\nFor the similar works \u2018Deep Learning from Temporal Coherence in Video\u2019 and \u2018Deep Supervised t-Distributed Embedding\u2019 mentioned. The inspiration of pairwise constraint is different. The pairwise constraints in these papers are derived from supervised or human knowledge information while ours, derived from a manifold property, which is more slight and available in an unsupervised work. \r\n-------------------------------------------\r\n\u201cIn this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance. The major difference is that the reconstruction error replaces the \u201cpull apart\u201d term in the loss function. What\u2019s the advantage of having an explicit decoder? Doesn\u2019t it introduce even more parameters in the model?\u201d\r\nCompared with [6], the convolutional neural network may be a reason, making it can be trained with a single graph loss function. In our case of fully connected neural network, we can\u2019t minimize the graph regularizer directly, we need layer-wise pre-training. Furthermore, in our experiment, pre-training with only graph regularization cannot work. It may give some insights on the reconstruction error term.\r\nBesides, in supervised learning, one can fine-tune the deep architecture with supervised weight matrix since they have training labels. However, in unsupervised learning, samples with different labels may be connected in unsupervised weight matrix. If we fine-tune the deep architecture with unsupervised graph regularization, clustering result might be worse since the wrong information would be fitted better. So we only use pre-training since the reconstruction error and the graph regularization can interact on each other, and we can find the balance through grid based search so that the local invariants are kept and the effect of wrong information is small.\r\n-------------------------------------------\r\n\u201cFinally, the empirical validation could be more convincing if the authors used larger datasets\u201d\r\nThe datasets we choose are more frequently used for clustering, which is an evaluation method of dimension reduction techniques. We would like to take experiments on large dataset for supervised learning in future work."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392819240000, "tcdate": 1392819240000, "number": 1, "id": "1UCG1i6IY41IQ", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "M7uvMK0-IZCh9", "replyto": "llrd5e-aKxZyi", "signatures": ["Yolanda Liao"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thanks for the comments. We have some responses below, and uploaded a new version of paper to clarify some problems. In our new version, we mainly revised Section 1 and Section 2, and we add some experiments at Section 4.1.\r\n-------------------------------------------\r\nAbstract:\r\n\u201cThe abstract is ramble and not very focused. \u2026\u201d\r\nWe have revised our abstract.\r\n-------------------------------------------\r\n\u201c\u2018we introduce the multiple- layer auto-encoder into image representation\u2019: definitely not true\u201d\r\nWe have deleted this claim in our new version, we want to express that we introduce the combination of graph regularizer and deep architecture for image representation.\r\n-------------------------------------------\r\n\u201cWhat does encouraging mean?\u201d\r\nCompare to sparse regularization auto-encoder and GNMF, GAE implements the similar or better clustering results. We try to combine the expressive power of deep architecture and the idea of local Euclidean preservation to implement a non-linear dimension reduction algorithm, or at least an option to the existing deep techniques on unsupervised or semi-supervised tasks.\r\n-------------------------------------------\r\nIntroduction\r\nPar 1\r\n\u201cf(H)? H hasn't been introduced yet. Do you mean f(X)? What do you mean by well approximate X?\u201d\r\nIt means f(X), and we mean H should preserve information about X. We have revised in our new version.\r\n-------------------------------------------\r\nPar 2\r\n\u201cYou cite a purely supervised method\u2026\u201d\r\nWe have removed this claim in our new version.\r\n-------------------------------------------\r\nPar 3\r\n\u201cTypo: Locally Linear Embedding is LLE, not LEE\u201d\r\nWe have revised in our new version.\r\n-------------------------------------------\r\nPar 4\r\n\u201cWhat does \u2018weighted connected\u2019 mean? The wording of this paragraph is not especially clear\u2026\u201d\r\nThis paragraph has been removed in our new version. \r\n-------------------------------------------\r\nWe rewrite the Par2 and Par4 at the perspective of dimension reduction, and clarify the motivation of our method. And Par3 has been moved to section 2 as related works.\r\n-------------------------------------------\r\nSection 3 Graph Regularized Auto-Encoder\r\nPar 1\r\n\u201cThis paragraph seems incredibly dismissive of the body of work that develops our understanding of auto encoders as learning manifolds, and how these manifolds relate to classification problems. I would say previous work such as the manifold tangent classifier definitely explores ideas related to the \u2018geometrical and discriminating structure of the data\u2019\u201d\r\nWe have removed this claim in our new version.\r\n-------------------------------------------\r\nPar 2\r\n\u201cThis paragraph consists of nothing but the letter 'f'\u201d\r\nThe letter has been removed in our new version.\r\n-------------------------------------------\r\nSection 3.1\r\n\u201cEquations 4 and 5: 'sigmoid' should not be in all caps\u2026\u201d\r\nWe have revised all \u2018sigmoid\u2019 we used throughout the paper as \u2018S(x)\u2019.\r\n-------------------------------------------\r\n\u201cEquation 7: when you say V is 'the weight matrix' do you mean\u2026\u201d\r\nWe have put in a forward reference to section 3.3 in our new version.\r\n-------------------------------------------\r\nSection 3.2\r\n\u201cYou really do not need to spend so much space describing\u2026\u201d\r\nWe want to make the definition clear and show that graph regularizer is applied to the training process at each layer.\r\n-------------------------------------------\r\nSection 4\r\n\u201cWhat is ORL? You should cite\u2026\u201d\r\nWe have cited the publication in the new version.\r\n-------------------------------------------\r\n\u201cIn general I do not find these experiments very compelling because they are mostly done on small and obscure datasets. It's also not clear to me which of the baselines you ran yourself and which if any are taken from the literature. Baselines that you ran yourself are less compelling because you may not have the same familiarity with pre-existing methods as the inventors of those methods, and you certainly have less incentive to make them perform well.\u201d\r\nThe datasets we choose are more frequently used for clustering, which is an evaluation method of dimension reduction techniques. We would like to take experiments on large dataset for supervised learning in future work.\r\nFor the baselines, we download the code of GNMF from the author\u2019s website, and the CNMF is implemented by ourselves which achieves similar performance as the results on their papers. \r\n-------------------------------------------\r\n\u201cAt a minimum, I'd like to see some more explanation of why the baselines you're improving upon are impressive. What would be better is to demonstrate good results on datasets that are used more frequently by people in the deep learning community. You are introducing a new kind of auto encoder so you should compare it to pre-existing auto encoders on datasets where auto encoders are frequently used, such as MNIST or Cover Type.\u201d\r\nWe compare our method to sparse auto-encoder, the result tells that the graph regularization can capture the manifold of the input data. We think the similar or better results compared to SAE show the effectiveness of graph regularization as we wanted. Besides, the comparison to GNMF and CNMF proves that expressive power is important when we want to capture the manifold structure of data set. We choose deep network to achieve better performance beyond the existing many interesting linear functions with its nonlinearity. Finally, at the perspective of dimensional reduction, clustering is often used for evaluation, so we take experiments on clustering to evaluate our method (like Deng.Cai et al\u2019s Graph regularized nonnegative matrix factorization for data representation ).\r\n-------------------------------------------\r\nSection 4.1\r\n\u201cDid you also optimize the SAE hyper parameters by grid search?\u201d\r\nYes, we have specified this point in our new version.\r\n-------------------------------------------\r\n\u201cYou say that the GAE has 2 coefficients to be set by grid search, k and lambda, but it seems like there must be a whole lot of other values to set, such as the dimensionality of H. What did you do about these?\u201d\r\nLike all the method we compare, the dimensionality of H is set to be the number of the classes in the input data set.\r\n-------------------------------------------\r\nSection 4.2\r\n\u201cFootnote 3: why is a single sample per class \u2018meaningless\u2019?... If you've added more labels, isn't your work no longer comparable to previous work on the same data set?\u201d\r\nThe weight between two samples which have the same labels will be denote as 1, since single sample per class means there are no sample have the same labels to others. So it\u2019s meaningless. We implement the experiment follow the work in CNMF. They use 10% or 20% labeled samples in their experiment. More labels won\u2019t influence our performance."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391832900000, "tcdate": 1391832900000, "number": 3, "id": "sPZis6owNIs3D", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "M7uvMK0-IZCh9", "replyto": "M7uvMK0-IZCh9", "signatures": ["anonymous reviewer 6561"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Image Representation Learning Using Graph Regularized Auto-Encoders", "review": "An algorithm is presented to generate a representation for unsupervised and partially labelled data  with graph-based regularization to keep nearest-neighbors close.\r\nEnglish is not clear in some places. \r\n\r\nI found the whole paper hard work to follow. \r\n\r\nResults tables don't give column headings. It wasn't clear what the variable was - the dimension? \r\nIt would be clearer to break out the 'error measure' into a separate column.\r\n\r\nThe two metrics used weren't very clear to me -\r\nthe mapping from unsupervised k-means clusters to class labels\r\n\r\nHow does it compare to a simple 1-NN hinge-loss technique similar to those used by Weston e.g. for training joint embeddings? \r\nhttp://www.thespermwhale.com/jaseweston/papers/wsabie-ijcai.pdf\r\n\r\nWhat parameters eta, lambda $k$ (for the graph construction) were chosen? How did this $k$ affect the results?\r\n\r\nHow expensive is the proposed technique compared to the alternative?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391729520000, "tcdate": 1391729520000, "number": 2, "id": "kCK_izo04OivH", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "M7uvMK0-IZCh9", "replyto": "M7uvMK0-IZCh9", "signatures": ["anonymous reviewer 0ee0"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Image Representation Learning Using Graph Regularized Auto-Encoders", "review": "A new auto-encoder method is proposed. Features are learned by minimizing the sum of the square reconstruction error and a penalty on feature dissimilarity weighted according to a variety of criteria. The basic idea is to weight more strongly the features that are in the neighborhood of the training sample or based on the class labels.\r\nA multi-layer version of the autoencoder is proposed by following the layer-wise training protocol.\r\nThe method is tested using several metric on a few small datasets.\r\n\r\nStrengths\r\nThe problem is relevant and interesting.\r\nThe method is technically sound.\r\n\r\nWeaknesses\r\nThe paper lacks clarity. It does not read well and the language is often vague (what does it mean \u201crepresent well\u201d or \u201cpositive impact\u201d or \u201churt numerical optimization\u201d?).\r\nThe paper is also rather incremental. The idea is similar to [6] but also related to methods for dimensionality reduction like deep parametric t-sne (see R. Min, L.J.P. van der Maaten, Z. Yuan, A. Bonner, and Z. Zhang. Deep Supervised t-Distributed Embedding. In Proceedings of the International Conference on Machine Learning (ICML), pages 791-798, 2010 ) and methods like H. Mobahi, R. Collobert, J. Weston. Deep Learning from Temporal Coherence in Video. ICML 2009.\r\nIn this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance. The major difference is that the reconstruction error replaces the \u201cpull apart\u201d term in the loss function. What\u2019s the advantage of having an explicit decoder? Doesn\u2019t it introduce even more parameters in the model?\r\nFinally, the empirical validation could be more convincing if the authors used larger datasets where many other authors already benchmarked (e.g., cifar, mnist, timit, svhn, to mention a few)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390610400000, "tcdate": 1390610400000, "number": 1, "id": "llrd5e-aKxZyi", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "M7uvMK0-IZCh9", "replyto": "M7uvMK0-IZCh9", "signatures": ["anonymous reviewer 41b4"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Image Representation Learning Using Graph Regularized Auto-Encoders", "review": "Summary of contributions:\r\n\tProposes to regularize auto encoders so that the encoded dataset has a similar nearest neighbor graph structure to the raw pixels. This method is advocated specifically for images. \r\n\r\nNovelty: moderate (note: the authors seem to believe they are introducing the use of multi-layer auto encoders on images, but they are not)\r\nQuality of results: low - moderate\r\nQuality of presentation: low\r\n\r\nPros:\r\n\tDemonstrates improvements in clustering and semi-supervised learning performance\r\nCons:\r\n\tPresentation is confusing and in many cases factually incorrect\r\n\tPresentation lacks motivation and reasoning about why the method should work\r\n\tQuantitative results are on small and obscure datasets, and improvements are relative to baselines of unclear value\r\n\r\nDetailed comments:\r\n\r\nAbstract:\r\n\tThe abstract is ramble and not very focused. This is a conference on representation learning, we don't need you to explain representation learning and deep nets in the abstract. Focus on how you've changed the auto encoder.\r\n\t\r\n\t'we introduce the multiple- layer auto-encoder into image representation': definitely not true, you even cite papers from 5 years ago that use multi-layer auto encoders on images.\r\n\r\n\tThe abstract should say something about what your new method actually is / does and why you think it is a good idea. I can't tell from the abstract what your method is except that you've changed auto-encoders in some way.\r\n\r\n\t'Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.'\r\n\tBe up-front about what your results are. What does encouraging mean? \r\n\r\nIntroduction\r\n\tPar 1\r\n\tf(H)? H hasn't been introduced yet. Do you mean f(X)?\r\n\tWhat do you mean by well approximate X? If H is meant to be similar to X, what's the point of switching to it? Do you mean it should preserve info about X?\r\n\r\n\tPar 2\r\n\tYou cite a purely supervised method (Krivhevsky et al's ImageNet classifier) and then say 'Those methods normally need to use the auto-encoders to pre-train\u2026' Not true. \r\n\t'It has been generally accepted as the consensus that the pre-trained network does provide a better representation for the original data.' Definitely not true! See for example Charle's Cadieu's work presented at ICLR last year.\r\n\r\n\tPar 3\r\n\tTypo: Locally Linear Embedding is LLE, not LEE\r\n\t\r\n\tPar 4\r\n\tWhat does 'weighted connected' mean?\r\n\tThe wording of this paragraph is not especially clear, but I take it to mean you want f(x_1) to be near f(x_2) if x_2 is a nearest neighbor of x_1. Why do you think this is a desirable property? It's well known that Euclidean distances in images are not very meaningful. That's the whole reason we want to use representation learning on them.\r\n\r\nSection 3 Graph Regularized Auto-Encoder\r\n\tPar 1\r\n\tThis paragraph seems incredibly dismissive of the body of work that develops our understanding of auto encoders as learning manifolds, and how these manifolds relate to classification problems. I would say previous work such as the manifold tangent classifier definitely explores ideas related to the 'geometrical and discriminating structure of the data'\r\n\r\n\tPar 2\r\n\tThis paragraph consists of nothing but the letter 'f'\r\n\r\nSection 3.1\r\n\r\n\tEquations 4 and 5: 'sigmoid' should not be in all caps, that makes it looks like the product between variables s, i, g, etc.    (This comment applies throughout the paper, not just these equations)\r\n\t\r\n\tEquation 7: when you say V is 'the weight matrix' do you mean it is a weighted adjacency matrix describing which examples should be near each other? Usually in auto encoder literature people use 'the weight matrix' to refer to W_H or W_Q. If V is indeed this adjacency matrix you should describe how it is computed and what the weights mean. Even just putting in a forward reference to section 3.3 can help the reader be less confused.\r\n\r\nSection 3.2\r\n\r\n\tYou really do not need to spend so much space describing the extremely well-known concept of greedy layer wise pre training\r\n\r\nSection 3.3\r\n\tOK, so V is the graph encoding matrix.\r\n\r\n\t3.3.1: Could you please explain the motivation for each of these? i.e., what effect you are hoping their use will have on the learning algorithm?\r\n\r\nSection 4\r\n\tWhat is ORL? You should cite the publication that introduced it. Is this ORL? http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html It looks like the name has changed.\r\n\r\n\tYou might want to get the datasets you work on added here: http://rodrigob.github.io/are_we_there_yet/build/\r\n\tThis will make it easier for reviewers to understand your work in context.\r\n\r\n\tIn general I do not find these experiments very compelling because they are mostly done on small and obscure datasets. It's also not clear to me which of the baselines you ran yourself and which if any are taken from the literature. Baselines that you ran yourself are less compelling because you may not have the same familiarity with pre-existing methods as the inventors of those methods, and you certainly have less incentive to make them perform well.\r\n\r\n\tAt a minimum, I'd like to see some more explanation of why the baselines you're improving upon are impressive. What would be better is to demonstrate good results on datasets that are used more frequently by people in the deep learning community. You are introducing a new kind of auto encoder so you should compare it to pre-existing auto encoders on datasets where auto encoders are frequently used, such as MNIST or Cover Type.\r\n\r\nSection 4.1\r\n\tI notice you specify the hyper parameters for GAE and GNMF are optimized by grid search, but you have no mention of this for the SAE. Did you also optimize the SAE hyper parameters by grid search?\r\n\r\n\tYou say that the GAE has 2 coefficients to be set by grid search, k and lambda, but it seems like there must be a whole lot of other values to set, such as the dimensionality of H. What did you do about these?\r\n\r\nSection 4.2\r\n\tFootnote 3: why is a single sample per class 'meaningless'? I agree it's really hard to do well in this case, but why is 1 sample totally worthless and 2 acceptable? If you've added more labels, isn't your work no longer comparable to previous work on the same data set?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387357320000, "tcdate": 1387357320000, "number": 4, "id": "M7uvMK0-IZCh9", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "M7uvMK0-IZCh9", "signatures": ["yyliao@iipc.zju.edu.cn"], "readers": ["everyone"], "content": {"title": "Image Representation Learning Using Graph Regularized Auto-Encoders", "decision": "submitted, no decision", "abstract": "We consider the problem of image representation for the tasks of unsupervised learning and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering. Inspired by the recent research works on deep neural network and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.", "pdf": "https://arxiv.org/abs/1312.0786", "paperhash": "liao|image_representation_learning_using_graph_regularized_autoencoders", "keywords": [], "conflicts": [], "authors": ["Yiyi Liao", "Yue Wang", "Yong Liu"], "authorids": ["yyliao@iipc.zju.edu.cn", "wangyue@iipc.zju.edu.cn", "cckaffe@gmail.com"]}, "writers": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 7}