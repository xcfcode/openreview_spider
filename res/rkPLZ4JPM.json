{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124281223, "tcdate": 1518448975390, "number": 136, "cdate": 1518448975390, "id": "rkPLZ4JPM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rkPLZ4JPM", "signatures": ["~Thomas_Mensink1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1524752833930, "tcdate": 1524752833930, "number": 1, "cdate": 1524752833930, "id": "HJqpbwyTz", "invitation": "ICLR.cc/2018/Workshop/-/Paper136/Official_Comment", "forum": "rkPLZ4JPM", "replyto": "HyU9C9YKf", "signatures": ["ICLR.cc/2018/Workshop/Paper136/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper136/Authors"], "content": {"title": "Thank you for the suggestions, we have incorporated them.", "comment": "Dear reviewer,\n\nThank you for the extensive feedback. We have included your suggestions and updated the paper (and experiments) accordingly. However, this took quite some time, therefore I can only now respond on your review.\n\nIn the new version, we have removed the generalisation experiments, to make place for more extensive online mean, mean condensation and mean decay experiments. We show learning curves and the relative mean distance. (And more experiments are in the Github online). From the results we conclude the following: while decay and condensation have a positive impact on the relative mean distance, their performance is (slightly) lower than normal online means. Albeit all similar to softmax baseline. \n\nThe idea of \"learning\" the weights is also interesting. We're aiming to include that in a future version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222448683, "id": "ICLR.cc/2018/Workshop/-/Paper136/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkPLZ4JPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper136/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper136/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper136/Reviewers", "ICLR.cc/2018/Workshop/Paper136/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222448683}}, "tauthor": "thomas.mensink@uva.nl"}, {"tddate": null, "ddate": null, "tmdate": 1524752559868, "tcdate": 1524752559868, "number": 1, "cdate": 1524752559868, "id": "BJOhgP1Tz", "invitation": "ICLR.cc/2018/Workshop/-/Paper136/Public_Comment", "forum": "rkPLZ4JPM", "replyto": "HJKpC00YG", "signatures": ["~Thomas_Mensink1"], "readers": ["everyone"], "writers": ["~Thomas_Mensink1"], "content": {"title": "Thanks! See you next week.", "comment": "Thanks! See you next week."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712626109, "id": "ICLR.cc/2018/Workshop/-/Paper136/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper136/Reviewers"], "reply": {"replyto": null, "forum": "rkPLZ4JPM", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712626109}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582628846, "tcdate": 1520820501737, "number": 1, "cdate": 1520820501737, "id": "SkRfWD7Kz", "invitation": "ICLR.cc/2018/Workshop/-/Paper136/Official_Review", "forum": "rkPLZ4JPM", "replyto": "rkPLZ4JPM", "signatures": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer1"], "content": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "rating": "5: Marginally below acceptance threshold", "review": "The paper proposes an enhanced version of a Deep version of the Nearest Class Mean classification method (DeepNCM). This enhanced version is based on using the data in each training mini-batch to efficiently update the class means. In other words, they use an online approximation for the class means. This type of approximation of the means of different groups has been used before in several techniques, as an example, incremental clustering using K-means. In this sense, the proposed contribution is marginal and I do not see a relevant impact. \n\nIn terms of results, authors show that DeepNCM performs similarly to Soft-Max in small data image classification cases such as MNIST, CIFAR-10, and CIFAR-100, although, soft-max still outperforms DeepNCM in this cases. In this sense, testing is limited and still  Soft-Max offers better performance.\n\n\t", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582628658, "id": "ICLR.cc/2018/Workshop/-/Paper136/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper136/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper136/AnonReviewer3"], "reply": {"forum": "rkPLZ4JPM", "replyto": "rkPLZ4JPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582628658}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582588834, "tcdate": 1521229453754, "number": 2, "cdate": 1521229453754, "id": "HyU9C9YKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper136/Official_Review", "forum": "rkPLZ4JPM", "replyto": "rkPLZ4JPM", "signatures": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer3"], "content": {"title": "I like the NCM idea in general but some key baselines should be tried", "rating": "7: Good paper, accept", "review": "This paper proposes an extension of the nearest mean classifier by Mensink et al. that applies a deep neural network to the underlying features, rather than computing NCM in the original data space under a learned Malahanobis metric. To deal with the issue of scaling to large datasets, they propose two techniques: online mean updates and mean condensation. Online mean updates simply refers to using an online update formula to calculate the mean. This is technically incorrect though, as the underlying representation changes with each step, and further, each new point\u2019s contribution to the current mean gets smaller with time. To counteract this, mean condensation simply resets the count of the number of examples to 1 at each epoch.\n\nThe experiments show that mean condensation helps to stabilize deep NCM training, that deep NCM performs slightly comparably (albeit slightly worse) than softmax, and that NCM provides a good representation for learning new classes.\n\nThe results are still preliminary and don\u2019t quite demonstrate the benefits of an NCM classifier over a standard softmax, but this is a workshop and I do think that NCM-like ideas are worth exploring. I would recommend a baseline of using an exponential moving average to compute the online mean updates, as opposed to the current online arithmetic average. It would take this form:\n\n\\mu <- \\beta * \\mu + (1 - \\beta) * mean(\\phi(x))\n\nWhere mean(\\phi(x)) is the mean over the current minibatch. This would allow you to backpropagate through some of the mean computation, and avoid the issue of a stale mean. I would set \\beta to something like 0.9 here.\n\nAn alternative baseline is to directly parameterize \\mu as weight vectors like a softmax, but compute the softmax energy as -||\\phi(x) - \\mu_i||^2 (for class i). This is a hybrid that might still allow you to approximate a new class using the average of \\phi(x). It\u2019s also equivalent to a constrained softmax.\n\nThese baselines should help to settle whether online updates + mean condensation is actually necessary.\n\nI\u2019d like to see a version of Figure 1, where the curves indicate train/test error of online NCM vs online + mean condensation. Also, how do these compare to softmax? Do they learn faster or slower?\n\nFor a conference version of the paper, I definitely recommend exploring some of the settings suggested in the conclusion.\n\nQuestions:\nWith online mean updates, are you backpropagating through the computation of \\mu at all? Otherwise wouldn\u2019t the gradient be biased (incorrect) with respect to the objective?\nWhat does SFT-50 in table 1b refer to? Did you train a softmax classifier and use the representation with NCM + fine-tuning? I think this result warrants more explanation.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582628658, "id": "ICLR.cc/2018/Workshop/-/Paper136/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper136/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper136/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper136/AnonReviewer3"], "reply": {"forum": "rkPLZ4JPM", "replyto": "rkPLZ4JPM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper136/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582628658}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573569232, "tcdate": 1521573569232, "number": 115, "cdate": 1521573568834, "id": "HJKpC00YG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rkPLZ4JPM", "replyto": "rkPLZ4JPM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepNCM: Deep Nearest Class Mean Classifiers", "abstract": "In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.\n", "paperhash": "guerriero|deepncm_deep_nearest_class_mean_classifiers", "keywords": [], "_bibtex": "@misc{\n  guerriero2018deepncm:,\n  title={DeepNCM: Deep Nearest Class Mean Classifiers},\n  author={Samantha Guerriero and Barbara Caputo and Thomas Mensink},\n  year={2018},\n  url={https://openreview.net/forum?id=rkPLZ4JPM}\n}", "authorids": ["samantha.guerriero94@gmail.com", "barbara.caputo@iit.it", "thomas.mensink@uva.nl"], "authors": ["Samantha Guerriero", "Barbara Caputo", "Thomas Mensink"], "TL;DR": "We propose DeepNCM, an efficient NCM classifier which learns deep visual representations", "pdf": "/pdf/b0f57d769a96fbb4246049a81674036533b76942.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 6}