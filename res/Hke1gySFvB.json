{"notes": [{"id": "Hke1gySFvB", "original": "B1eM4xo_vH", "number": 1490, "cdate": 1569439462843, "ddate": null, "tcdate": 1569439462843, "tmdate": 1577168281183, "tddate": null, "forum": "Hke1gySFvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "AYB0xheCUL", "original": null, "number": 1, "cdate": 1576798724613, "ddate": null, "tcdate": 1576798724613, "tmdate": 1576800911878, "tddate": null, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "invitation": "ICLR.cc/2020/Conference/Paper1490/-/Decision", "content": {"decision": "Reject", "comment": "This paper introduces the idea of \"empathy\" to improve learning in communication emergence. The reviewers all agree that the idea is interesting and well described. However, this paper clearly falls short on delivering the detailed and sufficient experiments and results to demonstrate whether and how the idea works.\n\nI thank the authors for submitting this research to ICLR and encourage following up on the reviewers' comments and suggestions for future submission. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726756, "tmdate": 1576800278950, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1490/-/Decision"}}}, {"id": "ryeJqt0UiB", "original": null, "number": 1, "cdate": 1573476743435, "ddate": null, "tcdate": 1573476743435, "tmdate": 1573476743435, "tddate": null, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "invitation": "ICLR.cc/2020/Conference/Paper1490/-/Official_Comment", "content": {"title": "Thank you", "comment": "I am very grateful for the feedback. It helps me better understand the requirements for a full ICLR paper.\nI'm happy, that the reviewers liked the overall idea, I will work on improving the experimental base."}, "signatures": ["ICLR.cc/2020/Conference/Paper1490/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1490/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hke1gySFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1490/Authors", "ICLR.cc/2020/Conference/Paper1490/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1490/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1490/Reviewers", "ICLR.cc/2020/Conference/Paper1490/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1490/Authors|ICLR.cc/2020/Conference/Paper1490/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155243, "tmdate": 1576860534982, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1490/Authors", "ICLR.cc/2020/Conference/Paper1490/Reviewers", "ICLR.cc/2020/Conference/Paper1490/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1490/-/Official_Comment"}}}, {"id": "ryeHqlTZFB", "original": null, "number": 1, "cdate": 1571045516611, "ddate": null, "tcdate": 1571045516611, "tmdate": 1572972461904, "tddate": null, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "invitation": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper takes the reference-game setup of Lazaridou et al. (2018), as a means of enabling emergent communication, and adds an auxiliary task to demonstrate that this helps with language emergence. The auxiliary task is to enable the speaker to predict the hidden state of the listener, after the message has been received. This is (not unreasonably) likened to providing the speaker with some empathy, in that it enables the speaker to try and predict what the effect of the message will be on the listener.\n\nThe main result is that the learning exhibits a speed-up, arriving at roughly the same level of overall reward but in fewer training steps.\n\nThe idea of adding an \"empathy\" auxiliary task to the reference-game setup is an interesting one, and the approach is well-motivated and described, including a background section. Unfortunately, however, the contributions of the paper are some way off what would be required for a full ICLR paper. Note that the main experimental results section takes up only 1/3 of a page, and the overall paper has only 5 pages of content. (As far as I know there is no requirement for an ICLR paper to take up the whole 8 pages, but a submission with only 5 pages is quite unusual.) So the overall contribution could be summarised as taking an existing emergent-language setup with the same speaker and listener neural architectures; adding a single MLP to the speaker; and showing two graphs of training reward, varying the number of candidates (2 and 5). I hope that the authors can perhaps see that this submission would be better suited to a dedicated workshop on emergent communication (and even then it would need more experiments and analysis).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603342795, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1490/Reviewers"], "noninvitees": [], "tcdate": 1570237736621, "tmdate": 1575603342807, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review"}}}, {"id": "S1e1TaJRYS", "original": null, "number": 2, "cdate": 1571843511387, "ddate": null, "tcdate": 1571843511387, "tmdate": 1572972461864, "tddate": null, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "invitation": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper starts with a conceptual claim that incorporating a notion of \u201cempathy\u201d in language emergency would help agents learn faster.  The paper then proposes a learning mechanism for implementing this, and looks at its empirical effect for the case of a Speaker-Listener game.\n\nThe concept at the core of the paper is thought-provoking, somewhat grounded in human communication, and it\u2019s interesting to see how this can be translated into a learning mechanism for the multi-agent setting.   The specific implementation proposed seems reasonable at a high level, however there are many technical details missing which really hamper the paper\u2019s message & potential scientific impact.   The results are limited to a single game, with just a pairwise comparison (with and without \u201cempathy\u201d), and provide a narrow view into the effectiveness of the proposed technique.\n\nMy main problem with the paper is the clarity & organization problems.  Usually I tend to be lenient on this, thinking poor writing is much easier to fix than poor science.  But in this case the problems are large enough that the paper is just too far from the standard for ICLR publication.  It also fits in 5 pages, so the authors had lots of space to write a much better paper.   I encourage them to do this for a future submission, in addition to more extensive results, because I think the ideas are worthwhile.\n\nSpecific comments:\n\nDesign of the empathy mechanism. Can you motivate why it\u2019s reasonable to \u201cachieve a high relation between the hidden states of both agents\u201d? Is this necessary / sufficient for empathy?  What are alternate framings of this?  What are properties and pros/cons of this framing?\n\nSec.4 needs a lot more detail!   Sections Agent setup, Learning and Empathy Extension in Sec.5 should be moved to Sec.4, since they describe the method, rather than the experiments.\n\nSec.5 needs better clarity.\no\tWhat are m^l_t and M^{<l}_t in Eqn 5?  Define how h_S and h_L are parameterized, and how each is trained.\no\tFig.2 gives a high-level view of the approach, but lacks important details.  Do you apply a loss at both the Speaker\u2019s Decoder output, and the Listener\u2019s Decoder output?  Or just the latter?  What is the loss specifically? I assume combination of Eqn 5 and Eqn 6, but not sure.\no\tIf you train just on the loss of the Listener\u2019s Decoder, does this mean this is backpropagated all the way to train the Speaker?  How would this be done in a real system?  It\u2019s a very strong assumption to say that the Listener will share gradients with the Speaker.  It seems more realistic to assume they will each observe a loss and train independently.\n\nResults are very brief.\no\tHow robust are the results to the specification of the \\alpha (the loss weight from Eqn 6)?  How much data goes to finding a good \\alpha?\no\tWhat is the difference between the left and the right plot?  Is one for the Speaker and the other for the Listener?\no\tHow do you measure \u201clearning speed\u201d, which is the main metric discussed in the text of Sec.6?\no\tHow do the results change by number of concepts in the game?\no\tDo you do any pre-training of the encoder/decoder networks?\no\tCan you show confidence intervals on each curve?\no\tCan you show test performance?\no\tAre there other related games to consider?\n\nMany references missing throughout to support statements, e.g.\no\t\u201cNatural language is not as rule-based as\u2026\u201d \no\t\u201cThese considerations led to the research field of emergent communication\u2026\u201d\no\tSec.2:  Earlier refs to RL in general (e.g. work Sutton in the 1980\u2019s). Earlier refs to RL with neural networks (e.g. work of G. Tesauro; work of M. Riedmiller).\no\tReferential game in Fig.1 caption.\n\nSome minor language issues, e.g.\no\t\u201cThe field was then alleviated\u201d -> Do you mean elevated?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603342795, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1490/Reviewers"], "noninvitees": [], "tcdate": 1570237736621, "tmdate": 1575603342807, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review"}}}, {"id": "Hkx7J160Yr", "original": null, "number": 3, "cdate": 1571897051273, "ddate": null, "tcdate": 1571897051273, "tmdate": 1572972461817, "tddate": null, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "invitation": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary: This paper aims to take insight from human language acquisition and the importance of empathic connection to learn better models for emergent language. The authors propose an approach to introduce the notion of empathy to multi-agent deep RL by extending existing approaches on referential games with an auxiliary task for the speaker to predict the listener\u2019s empathy/mind. Experiments show that this gives some improvement with faster convergence.\n\nStrengths:\n- The concept is interesting and grounded in human communication.\n\nWeaknesses:\n- I like the motivation of predicting empathy, but the paper vastly oversells this part: I don't see how predicting the listener's hidden state is the same as modeling empathy. Empathy is a complex human state/emotion that should not be reduced to this.\n- This paper is very preliminary. There are multiple typos in the paper. Figures are not professionally created. There are multiple training details not included such as how the agents are modeled and trained. The authors seem to have run out of time given the short length of the paper.\n- The experimental results are not convincing at all. The improvement is too small and it would help to run the experiment multiple times to see the improvement with respect to variance in the model. There should also be experiments testing the effect of \\alpha on performance. There is no analysis of how well the model is able to predict empathy, as well as ablation studies testing for various design decisions. The authors should also add an analysis of the learned communication protocols and whether they are different in a meaningful way."}, "signatures": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1490/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Language Emergence through Empathy", "authors": ["Marie Ossenkopf"], "authorids": ["mos@vs.uni-kassel.de"], "keywords": ["multi-agent deep reinforcement learning", "emergent communication", "auxiliary tasks"], "TL;DR": "An auxiliary prediction task can speed up learning in language emergence setups.", "abstract": "The emergence of language in multi-agent settings is a promising research direction to ground natural language in simulated agents. If AI would be able to understand the meaning of language through its using it, it could also transfer it to other situations flexibly. That is seen as an important step towards achieving general AI. The scope of emergent communication is so far, however, still limited. It is necessary to enhance the learning possibilities for skills associated with communication to increase the emergable complexity. We took an example from human language acquisition and the importance of the empathic connection in this process. We propose an approach to introduce the notion of empathy to multi-agent deep reinforcement learning. We extend existing approaches on referential games with an auxiliary task for the speaker to predict the listener's mind change improving the learning time. Our experiments show the high potential of this architectural element by doubling the learning speed of the test setup. ", "code": "https://github.com/AnonymRobotika/ICLR2020", "pdf": "/pdf/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "paperhash": "ossenkopf|enhancing_language_emergence_through_empathy", "original_pdf": "/attachment/3a54ce0ab2b727b28df5a619acc1cf9471941527.pdf", "_bibtex": "@misc{\nossenkopf2020enhancing,\ntitle={Enhancing Language Emergence through Empathy},\nauthor={Marie Ossenkopf},\nyear={2020},\nurl={https://openreview.net/forum?id=Hke1gySFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hke1gySFvB", "replyto": "Hke1gySFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1490/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575603342795, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1490/Reviewers"], "noninvitees": [], "tcdate": 1570237736621, "tmdate": 1575603342807, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1490/-/Official_Review"}}}], "count": 6}