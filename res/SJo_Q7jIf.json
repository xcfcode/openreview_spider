{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124479359, "tcdate": 1518183282864, "number": 44, "cdate": 1518183282864, "id": "SJo_Q7jIf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJo_Q7jIf", "signatures": ["~Ghouthi_BOUKLI_HACENE1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Transfer Incremental Learning using Data Augmentation", "abstract": "Due to catastrophic forgetting, deep learning remains highly inappropriate when facing incremental learning of new classes and examples over time. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA combines transfer learning from a pre-trained Deep Neural Network (DNN) as feature extractor, a Nearest Class Mean (NCM) inspired classifier and majority vote using data augmentation on both training and test vectors. The obtained methodology allows learning new examples or classes on the fly with very limited computational and memory footprints.  We perform experiments on challenging vision datasets and obtain performance significantly better than existing incremental counterparts. ", "paperhash": "hacene|transfer_incremental_learning_using_data_augmentation", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Transfer Learning"], "_bibtex": "@misc{\n  hacene2018transfer,\n  title={Transfer Incremental Learning using Data Augmentation},\n  author={Ghouthi Boukli Hacene and Vincent Gripon and Nicolas Farrugia and Matthieu Arzel and Michel Jezequel},\n  year={2018},\n  url={https://openreview.net/forum?id=SJo_Q7jIf}\n}", "authorids": ["ghouthi.bouklihacene@imt-atlantique.fr", "vincent.gripon@imt-atlantique.fr", "nicolas.farrugia@imt-atlantique.fr", "matthieu.arzel@imt-atlantique.fr", "michel.jezequel@imt-atlantique.fr"], "authors": ["Ghouthi Boukli Hacene", "Vincent Gripon", "Nicolas Farrugia", "Matthieu Arzel", "Michel Jezequel"], "TL;DR": "Combining NCM-inspired classifiers with quantized outputs of a Deep CNN enables lightweight one shot incremental learning.", "pdf": "/pdf/9e147717e9b67d28db8993cf3792c3f356c39996.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582972097, "tcdate": 1520002613010, "number": 1, "cdate": 1520002613010, "id": "H1aEIkP_z", "invitation": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "signatures": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer2"], "content": {"title": "Using NCM style classifiers on subvectors for incremental learning, yet unclear if results are just due to pre-trained DNN.", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes to use a NCM style algorithm for class/example incremental learning.\nIt starts from a pre-trained ConvNet, then split feature vector into P subvectors, use NCMC (NCM with multiple class representatives) with k-centroids, and then a majority vote over the P subverters for the class predictions. To improve results at both train and test-time data augmentation is used.\n\nI have two major problems with the current submission:\n1) Due to the use of the pre-trained DNN comparison to (eg) iCARL are unfair, which explicitly aims to train the DNN while learning classifiers. Moreover, the results on ImageNet are skewed as well, given that the DNN is also pre-trained on ImageNet. In conclusion: using pre-trained DNN makes comparison to related methods unclear/unfair, and makes some experimental results of little added value.\n\n2) The important aspects of the proposed method are not explored: influence of data augmentation, of number of subvectors  P, of number of NCMC centroids k. Moreover, it is unclear what is \"learned\" during training. From the setup it seems that just the means of classes (or k-means centroids) are obtained. Why does that work well with random assignment (Algorithm 1)?\n\nMinor issues:\n- Unclear how it relates to iCARL/NCM etc, does the method reduces to (say) iCARL when data augmentation is not used, P=1, and K=1.\n- Unclear what the baselines are exactly, what is learned with NCM? How well is the NCMC baseline? Does NCM(C) improve with data augmentation? Or with subvectors?\n- Experimentally unclear if the performance increase is just due to the DNN (ie which methods are based on the pre-trained DNN?", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Transfer Incremental Learning using Data Augmentation", "abstract": "Due to catastrophic forgetting, deep learning remains highly inappropriate when facing incremental learning of new classes and examples over time. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA combines transfer learning from a pre-trained Deep Neural Network (DNN) as feature extractor, a Nearest Class Mean (NCM) inspired classifier and majority vote using data augmentation on both training and test vectors. The obtained methodology allows learning new examples or classes on the fly with very limited computational and memory footprints.  We perform experiments on challenging vision datasets and obtain performance significantly better than existing incremental counterparts. ", "paperhash": "hacene|transfer_incremental_learning_using_data_augmentation", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Transfer Learning"], "_bibtex": "@misc{\n  hacene2018transfer,\n  title={Transfer Incremental Learning using Data Augmentation},\n  author={Ghouthi Boukli Hacene and Vincent Gripon and Nicolas Farrugia and Matthieu Arzel and Michel Jezequel},\n  year={2018},\n  url={https://openreview.net/forum?id=SJo_Q7jIf}\n}", "authorids": ["ghouthi.bouklihacene@imt-atlantique.fr", "vincent.gripon@imt-atlantique.fr", "nicolas.farrugia@imt-atlantique.fr", "matthieu.arzel@imt-atlantique.fr", "michel.jezequel@imt-atlantique.fr"], "authors": ["Ghouthi Boukli Hacene", "Vincent Gripon", "Nicolas Farrugia", "Matthieu Arzel", "Michel Jezequel"], "TL;DR": "Combining NCM-inspired classifiers with quantized outputs of a Deep CNN enables lightweight one shot incremental learning.", "pdf": "/pdf/9e147717e9b67d28db8993cf3792c3f356c39996.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582971867, "id": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper44/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer3"], "reply": {"forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582971867}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582763085, "tcdate": 1520641660802, "number": 2, "cdate": 1520641660802, "id": "BkBtIsxtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "signatures": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer1"], "content": {"title": "no title", "rating": "6: Marginally above acceptance threshold", "review": "[ Paper Summary ]\n\nThe paper proposed NCM based classifier for incremental learning, which combines pre-trained DNN, data augmentation, feature splitting, and NCM.\n\n- novelty\n\nThe approach seems to be novel, though the topic is not my expertise.\n\n- clarity\n\nThe procedure is clear, though it is a bit difficult for those who are not familiar with NCM.\n\n- significance \n\nThe problem setting would be significant, and performance on experiments is good.\n\n- quality\n\nThe entire quality of the paper would be ok, and the main claims are supported by the results.\n\n[ Comments ]\n\n- pros\n\nThe method works well in the experiments.\n\nThe method seems to be easy to implement.\n\n- cons\n\nThe effect of each of four components in the proposed method is not clear. Discussing component-wise effect might be informative.\n\nRobustness to P would be important.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Transfer Incremental Learning using Data Augmentation", "abstract": "Due to catastrophic forgetting, deep learning remains highly inappropriate when facing incremental learning of new classes and examples over time. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA combines transfer learning from a pre-trained Deep Neural Network (DNN) as feature extractor, a Nearest Class Mean (NCM) inspired classifier and majority vote using data augmentation on both training and test vectors. The obtained methodology allows learning new examples or classes on the fly with very limited computational and memory footprints.  We perform experiments on challenging vision datasets and obtain performance significantly better than existing incremental counterparts. ", "paperhash": "hacene|transfer_incremental_learning_using_data_augmentation", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Transfer Learning"], "_bibtex": "@misc{\n  hacene2018transfer,\n  title={Transfer Incremental Learning using Data Augmentation},\n  author={Ghouthi Boukli Hacene and Vincent Gripon and Nicolas Farrugia and Matthieu Arzel and Michel Jezequel},\n  year={2018},\n  url={https://openreview.net/forum?id=SJo_Q7jIf}\n}", "authorids": ["ghouthi.bouklihacene@imt-atlantique.fr", "vincent.gripon@imt-atlantique.fr", "nicolas.farrugia@imt-atlantique.fr", "matthieu.arzel@imt-atlantique.fr", "michel.jezequel@imt-atlantique.fr"], "authors": ["Ghouthi Boukli Hacene", "Vincent Gripon", "Nicolas Farrugia", "Matthieu Arzel", "Michel Jezequel"], "TL;DR": "Combining NCM-inspired classifiers with quantized outputs of a Deep CNN enables lightweight one shot incremental learning.", "pdf": "/pdf/9e147717e9b67d28db8993cf3792c3f356c39996.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582971867, "id": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper44/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer3"], "reply": {"forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582971867}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582639585, "tcdate": 1520808881123, "number": 3, "cdate": 1520808881123, "id": "BkF3QEXKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "signatures": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer3"], "content": {"title": "insufficient technical contribution", "rating": "3: Clear rejection", "review": "This paper proposes a method for incremental learning of deep neural networks while adding new samples and new classes.  To avoid drift and forgetting, a set of anchor points are maintained via a nearest neighbours approach.  \n\n+ somewhat compelling results on CIFAR10/100 and ImageNet\n- insufficient technical novelty and contribution", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Transfer Incremental Learning using Data Augmentation", "abstract": "Due to catastrophic forgetting, deep learning remains highly inappropriate when facing incremental learning of new classes and examples over time. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA combines transfer learning from a pre-trained Deep Neural Network (DNN) as feature extractor, a Nearest Class Mean (NCM) inspired classifier and majority vote using data augmentation on both training and test vectors. The obtained methodology allows learning new examples or classes on the fly with very limited computational and memory footprints.  We perform experiments on challenging vision datasets and obtain performance significantly better than existing incremental counterparts. ", "paperhash": "hacene|transfer_incremental_learning_using_data_augmentation", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Transfer Learning"], "_bibtex": "@misc{\n  hacene2018transfer,\n  title={Transfer Incremental Learning using Data Augmentation},\n  author={Ghouthi Boukli Hacene and Vincent Gripon and Nicolas Farrugia and Matthieu Arzel and Michel Jezequel},\n  year={2018},\n  url={https://openreview.net/forum?id=SJo_Q7jIf}\n}", "authorids": ["ghouthi.bouklihacene@imt-atlantique.fr", "vincent.gripon@imt-atlantique.fr", "nicolas.farrugia@imt-atlantique.fr", "matthieu.arzel@imt-atlantique.fr", "michel.jezequel@imt-atlantique.fr"], "authors": ["Ghouthi Boukli Hacene", "Vincent Gripon", "Nicolas Farrugia", "Matthieu Arzel", "Michel Jezequel"], "TL;DR": "Combining NCM-inspired classifiers with quantized outputs of a Deep CNN enables lightweight one shot incremental learning.", "pdf": "/pdf/9e147717e9b67d28db8993cf3792c3f356c39996.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582971867, "id": "ICLR.cc/2018/Workshop/-/Paper44/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper44/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper44/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper44/AnonReviewer3"], "reply": {"forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper44/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582971867}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573597656, "tcdate": 1521573597656, "number": 234, "cdate": 1521573597314, "id": "B1UJJkJqM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJo_Q7jIf", "replyto": "SJo_Q7jIf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Transfer Incremental Learning using Data Augmentation", "abstract": "Due to catastrophic forgetting, deep learning remains highly inappropriate when facing incremental learning of new classes and examples over time. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA combines transfer learning from a pre-trained Deep Neural Network (DNN) as feature extractor, a Nearest Class Mean (NCM) inspired classifier and majority vote using data augmentation on both training and test vectors. The obtained methodology allows learning new examples or classes on the fly with very limited computational and memory footprints.  We perform experiments on challenging vision datasets and obtain performance significantly better than existing incremental counterparts. ", "paperhash": "hacene|transfer_incremental_learning_using_data_augmentation", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Transfer Learning"], "_bibtex": "@misc{\n  hacene2018transfer,\n  title={Transfer Incremental Learning using Data Augmentation},\n  author={Ghouthi Boukli Hacene and Vincent Gripon and Nicolas Farrugia and Matthieu Arzel and Michel Jezequel},\n  year={2018},\n  url={https://openreview.net/forum?id=SJo_Q7jIf}\n}", "authorids": ["ghouthi.bouklihacene@imt-atlantique.fr", "vincent.gripon@imt-atlantique.fr", "nicolas.farrugia@imt-atlantique.fr", "matthieu.arzel@imt-atlantique.fr", "michel.jezequel@imt-atlantique.fr"], "authors": ["Ghouthi Boukli Hacene", "Vincent Gripon", "Nicolas Farrugia", "Matthieu Arzel", "Michel Jezequel"], "TL;DR": "Combining NCM-inspired classifiers with quantized outputs of a Deep CNN enables lightweight one shot incremental learning.", "pdf": "/pdf/9e147717e9b67d28db8993cf3792c3f356c39996.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}