{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487794123775, "tcdate": 1478279703828, "number": 241, "id": "HyxQzBceg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HyxQzBceg", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "content": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396453771, "tcdate": 1486396453771, "number": 1, "id": "ByCQ2zLux", "invitation": "ICLR.cc/2017/conference/-/paper241/acceptance", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper discussses applying an information bottleneck to deep networks using a variational lower bound and reparameterization trick. The paper is well written and the examples are compelling. The paper can be improved with more convincing results on MNIST.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396454335, "id": "ICLR.cc/2017/conference/-/paper241/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396454335}}}, {"tddate": null, "tmdate": 1485030976826, "tcdate": 1481938340704, "number": 3, "id": "By6srMMVx", "invitation": "ICLR.cc/2017/conference/-/paper241/official/review", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer4"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "Update: raised the score, because I think the arguments about adversarial examples are compelling.  I think that the paper convincingly proves that this method acts as a decent regularizer, but I'm not convinced that it's a competitive regularizer.  For example, I don't believe that there is sufficient evidence that it gives a better regularizer than dropout/normalization/etc.  I also think that it will be much harder to tune than these other methods (discussed in my rebuttal reply).  \n\n----\n\nSummary: If I understand correctly, this paper proposes to take the \"bottleneck\" term from variational autoencoders which pulls the latent variable towards a noise prior (like N(0,1)) and apply it in a supervised learning context where the reconstruction term log(p(x|z)) is replaced with the usual supervised cross-entropy objective.  \n\nThe argument is that this is an effective regularizer and increases robustness to adversarial attacks.  \n\nPros: \n\n-The presentation is quite good and the paper is easy to follow.  \n\n-The idea is reasonable and the relationship to previous work is well described.  \n\n-The robustness to adversarial examples experiment seems convincing, though I'm not an expert in this area.  Is there any way to compare to an external quantitative baseline on robustness to adversarial examples?  This would help a lot, since I'm not sure how the method here compares with other regularizers in terms of combatting adversarial examples.  For example, if one uses a very high dropout rate, does this confer a comparable robustness to adversarial examples (perhaps at the expense of accuracy)?  \n\nCons: \n\n-MNIST accuracy results don't seem very strong, unless I'm missing something.  The Maxout paper from ICML 2013 listed many permutation invariant MNIST results with error rates below 1%.  So the 1.13% error rate listed here doesn't necessarily prove that the method is a competitive regularizer.  I also suspect that tuning this method to make it work well is harder than other regularizers like dropout.  \n\n-There are many distinct architectural choices with this method, particularly in how many hidden layers come before and after z.  For example, the output could directly follow z, or there could be several layers between z and the output.  As far as I can tell the paper says that p(y | z) is a simple logistic regression (i.e. one weight matrix followed by softmax), but it's not obvious why this choice was made.  Did it work best empirically?  \n\nOther: \n\n-I wonder what would happen if you \"trained against\" the discovered adversarial examples while also using the method from this paper.  Would it learn to have a higher variance p(z | x) when presented with an adversarial example?  ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512652947, "id": "ICLR.cc/2017/conference/-/paper241/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper241/AnonReviewer3", "ICLR.cc/2017/conference/paper241/AnonReviewer1", "ICLR.cc/2017/conference/paper241/AnonReviewer4"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512652947}}}, {"tddate": null, "tmdate": 1484952794645, "tcdate": 1484952794645, "number": 10, "id": "ryXyrzgvl", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "SJVU4HPIe", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Imagenet Experiments", "comment": "We have added some preliminary experiments based on a SOTA Imagenet classifier, namely Inception ResNet V2. In particular, we took a pre-trained network, removed the final softmax layer, and used the resulting 1536 dimensional feature vector as the input to our experiments. \nUsing these features, it is possible to classify with 80.4% accuracy using only logistic regression, which is the same performance as the original network. \n\nWe then performed the following experiment. The input was passed through two fully connected layers with 1024 units each, followed by a stochastic layer encoding a diagonal 1024 dimensional Gaussian representation with learned means and standard deviations, which was then passed to our variational classifier, which again for simplicity we took to be simple logistic regression. Although we were not able to improve classification accuracy, we were able to achieve essentially the same performance (80.12%) using \u03b2 of 0.01; this corresponds to a very \"narrow\" (in the information-theoretic sense) bottleneck: we estimate  the mutual information as only I(X,Z) \u223c 45 bits. (Contrast this to the estimate we observe in the \u03b2 = 0 case, where the capacity is about 10,000 bits, but with an accuracy of only 78.87%.) \n\nMore interestingly, we show that this narrow bottleneck is substantially more robust to adversarial attacks than the original deterministic model. In particular, the VIB network requires much larger perturbations in order to fool the classifier.\n\nSee Section 4.2.5 for further details on our new Imagenet experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484952767558, "tcdate": 1484952767558, "number": 9, "id": "B1OT4zxDx", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "SJ3zXBw8x", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Imagenet experiments", "comment": "We have added some preliminary experiments based on a SOTA Imagenet classifier, namely Inception ResNet V2. In particular, we took a pre-trained network, removed the final softmax layer, and used the resulting 1536 dimensional feature vector as the input to our experiments. \nUsing these features, it is possible to classify with 80.4% accuracy using only logistic regression, which is the same performance as the original network. \n\nWe then performed the following experiment. The input was passed through two fully connected layers with 1024 units each, followed by a stochastic layer encoding a diagonal 1024 dimensional Gaussian representation with learned means and standard deviations, which was then passed to our variational classifier, which again for simplicity we took to be simple logistic regression. Although we were not able to improve classification accuracy, we were able to achieve essentially the same performance (80.12%) using \u03b2 of 0.01; this corresponds to a very \"narrow\" (in the information-theoretic sense) bottleneck: we estimate  the mutual information as only I(X,Z) \u223c 45 bits. (Contrast this to the estimate we observe in the \u03b2 = 0 case, where the capacity is about 10,000 bits, but with an accuracy of only 78.87%.) \n\nMore interestingly, we show that this narrow bottleneck is substantially more robust to adversarial attacks than the original deterministic model. In particular, the VIB network requires much larger perturbations in order to fool the classifier.\n\nSee Section 4.2.5 for further details on our new Imagenet experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484949027529, "tcdate": 1484949027529, "number": 8, "id": "H1oQUZxPg", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "B19DfEjLe", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Imagenet added", "comment": "Thanks for your comments, which we respond to below.\n\n\"First, why not try to show an improvement on a model that's near the state-of-the-art?\"\n\nWe have added some preliminary experiments based on a SOTA Imagenet classifier, namely Inception ResNet V2. In particular, we took a pre-trained network, removed the final softmax layer, and used the resulting 1536 dimensional feature vector as the input to our experiments. \nUsing these features, it is possible to classify with 80.4% accuracy using only logistic regression, which is the same performance as the original network. \n\nWe then performed the following experiment. The input was passed through two fully connected layers with 1024 units each, followed by a stochastic layer encoding a diagonal 1024 dimensional Gaussian representation with learned means and standard deviations, which was then passed to our variational classifier, which again for simplicity we took to be simple logistic regression. Although we were not able to improve classification accuracy, we were able to achieve essentially the same performance (80.12%) using \u03b2 of 0.01; this corresponds to a very \"narrow\" (in the information-theoretic sense) bottleneck: we estimate  the mutual information as only I(X,Z) \u223c 45 bits. (Contrast this to the estimate we observe in the \u03b2 = 0 case, where the capacity is about 10,000 bits, but with an accuracy of only 78.87%.) \n\nMore interestingly, we show that this narrow bottleneck is substantially more robust to adversarial attacks than the original deterministic model. In particular, the VIB network requires much larger perturbations in order to fool the classifier.\n\nSee Section 4.2.5 for further details on our new Imagenet experiments.\n\n\n \"I'm not sure that there's any point in trying to get a SOTA on PI-MNIST, but it would be nice to see a result on top of a model that's closer to the SOTA\".\n\nWe deliberately chose to pick a simple baseline that is fairly close to SOTA on MNIST, but which still left some \"headroom\" in order to show the benefits of our method. \n\n\n\"What was the criteria for deciding what models were to be included in Table 1?\"\n\nWe chose the architecture from the  Pereya 2016 paper (also in submission to ICLR'17) simply because they are our colleagues, and that way, we could be more confident we were doing a fair comparison.\n\n\n\n\"You could fairly easily apply this to the end of the PI-MNIST NN from the maxout paper and see if it improves upon that result.  \"\n\nComparing against the permutation invariant maxout network would be difficult, because it introduces another source of stochasticity beyond our own (namely in the dropout that is required with maxout activations).  This would make it hard to discern the source of benefit: is improvement a consequence of our stochasticity or theirs? \n\n\n\"The caption implies that it's having a \"bottleneck of k=256\" but I'm not sure exactly what this means\".\n\nYou are right, this is not well explained. We have clarified it in the text.\nThe Pereya  architecture is 784 - 1024 - 1024 - 10.\nIn our case all (MNIST) networks were 784 - 1024 - 1024 - K - 10, where K is the size of the latent bottleneck.\n\n\n\"It seems like tuning the beta parameter (figure 1a,1b) isn't too different from tuning a dropout rate.  Is your point that one can compute I(x,z) and quantify how much information from x is kept in z?\"\n\nThat's exactly right.  By adjusting beta one can target different amounts of information allowed to pass through the network (with respect to input data, X).  By tuning beta, one dials up or down the \"fidelity\" between the compressed representation Z and the ground-truth evidence X.  Through this mechanism we explore how different architectures respond to varying levels of \"fidelity\", i.e. strength of the bottleneck.\n\n\n\"My guess is that if you use this in early layers in a deep network, the model will immediately set mu=0 and sigma=1 for those layers because the gradient from the information bottleneck is less noisy than the gradient from the following layers in the just-initialized deep network.  It may be very hard to find a beta parameter that avoids this. \"\n\nThis is a valid concern. Unfortunately we have not had time to try this experiment (we have instead focused our energies on scaling up the adversarial experiments to Imagenet, as mentioned above). We leave exploration of this issue to future work."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484632673927, "tcdate": 1484632673927, "number": 1, "id": "B19DfEjLe", "invitation": "ICLR.cc/2017/conference/-/paper241/official/comment", "forum": "HyxQzBceg", "replyto": "HJ2jbHP8g", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer4"], "content": {"title": "response", "comment": "\"To us the most impressive aspect of the VIB performance on MNIST was not that we exceeded state-of-the-art, but rather how close we got with a relatively simple model\"\n\nFirst, why not try to show an improvement on a model that's near the state-of-the-art?  For example, you could fairly easily apply this to the end of the PI-MNIST NN from the maxout paper and see if it improves upon that result.  I'm not sure that there's any point in trying to get a SOTA on PI-MNIST, but it would be nice to see a result on top of a model that's closer to the SOTA.  \n\nIn terms of the model being relatively simple: I'm somewhat open to the idea of accepting an empirical comparison on a restricted set of models (for example disallowing convolutions or data augmentation) but it needs to be very clear how the models in the comparison are all constrained.  What was the criteria for deciding what models were to be included in Table 1?  The caption implies that it's having a \"bottleneck of k=256\" but I'm not sure exactly what this means.  All of the results reference Pereya 2016.  Are there no other papers with MNIST results that ought to be included here?  \n\n\"Furthermore, the VIB framework permits spanning a continuum of model complexities within a given architecture, and in a principled manner.\"\n\nCan you clarify what you mean here?  It seems like tuning the beta parameter (figure 1a,1b) isn't too different from tuning a dropout rate.  Is your point that one can compute I(x,z) and quantify how much information from x is kept in z?  \n\n\"We did not explore additional model architectures, viz., adding/removing layers before/after z. In a future submission we hope to explore different structures. Along these lines--and perhaps even more exciting--is the prospect of studying applications of the VIB principle to every layer of the net (not just the penultimate).  That said, the goal of this paper was to show that despite p(y|z) being a simple logistic regression--and making the simplest architecture choices we could--we were able to get good results.\"\n\nMy guess is that if you use this in early layers in a deep network, the model will immediately set mu=0 and sigma=1 for those layers because the gradient from the information bottleneck is less noisy than the gradient from the following layers in the just-initialized deep network.  It may be very hard to find a beta parameter that avoids this.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670025, "id": "ICLR.cc/2017/conference/-/paper241/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670025}}}, {"tddate": null, "tmdate": 1484375318546, "tcdate": 1484375318546, "number": 7, "id": "BkCMrBDLl", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "rJi2qM1Qe", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Cross validation", "comment": "The beta in Table 1 was chosen as the optimal from the test set.  The regularization experiments were not meant to establish a new state of the art, just to demonstrate that VIB can be competitive.  You are correct: in general, the best beta would have to be chosen by doing cross validation. For these experiments, it seems there is a wide range of beta values that do better than no beta whatsoever, so initial indications are that it is not a very hard hyperparameter to tune decently.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484375193906, "tcdate": 1484375193906, "number": 6, "id": "r1ziVHwIe", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "ryssfEy7x", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Variational CCA link", "comment": "You are correct: it seems that our objective is basically the same as yours, apart from 2 differences. First, since we creating a discriminative model, we do not have a  p(x|z) likelihood term. Second, since we are coming from the IB perspective, we have a beta term in front of our KL. Beta is an important \"knob\" in our framework; it is not clear how to introduce this to VCCA. Nevertheless, the connection between the two methods is very interesting, and we will be sure to add a citation to the arxiv version of your  paper (which was submitted concurrently with our ICLR submission).\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484375116201, "tcdate": 1484375116201, "number": 5, "id": "SJVU4HPIe", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "r1dPtY0me", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Notation and VAE", "comment": "Thank you for your feedback and apologies for the notational headaches. We added some clarifying remarks regarding p(y|x) (which is, as you pointed out \"p(y|x) = \\int q(y|z) p(z|x) dz\").  We're approximating this distribution in two ways: by averaging over samples, z~p(.|x) and of course using q as a surrogate for p(y|z)=\\int dx p(y,x|z).  Unlike standard applications of variational inference our surrogate q(y|z) replaces a marginal (not a posterior).  However, the motivation behind both approaches is identical: the posterior is computationally challenging due to its normalization term, i.e., the computation of some marginal. Hopefully this clears up how our inference engine differs from typical regimes.\n\nRegarding your comment about VAE and r(z): we were making the case that the VIB formalism subsumes the VAE loss function. You are correct that the underlying (assumed) model is different: the VIB makes assumptions about the latent \"bottleneck\" space which are not made in a VAE. The connection is made only under the variational loss, which has a degree of freedom permitting recovery of the VAE loss when choosing r(z) appropriately.\n\nThank you for catching the typos as well -- we've fixed those in this draft."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484374804406, "tcdate": 1484374804406, "number": 4, "id": "SJ3zXBw8x", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "rJ_3n_ZNx", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Experiments, clarifications, and related work", "comment": "Thank you for your feedback. We've added some additional experiments using fast gradient sign adversarial examples and included dropout in Figures 4 and 5. We've also added a brief comment on how we chose 12 samples (answer: it was a somewhat arbitrary choice which we did not tune yet apparently worked well). The error bars in Figure 1 (a) are one +- std. dev. Regarding \u201cthe posterior covariance becomes larger,\u201d we corrected this typo and clarified the caption.\n\nThe variational fair autoencoder is an interesting connection, and we have added a brief comparison in Section 2. Thanks for bringing it to our attention!\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1484374436510, "tcdate": 1484374436510, "number": 3, "id": "HJ2jbHP8g", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "By6srMMVx", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Architectures and Adversaries", "comment": "Thank you for your feedback, particularly with respect to MNIST experiments and architectural choices.  We've revised the text to better reflect what we believe is our primary value-add.  To us the most impressive aspect of the VIB performance on MNIST was not that we exceeded state-of-the-art, but rather how close we got with a relatively simple model. Furthermore, the VIB framework permits spanning a continuum of model complexities within a given architecture, and in a principled manner.\n\nWe did not explore additional model architectures, viz., adding/removing layers before/after z. In a future submission we hope to explore different structures. Along these lines--and perhaps even more exciting--is the prospect of studying applications of the VIB principle to every layer of the net (not just the penultimate).  That said, the goal of this paper was to show that despite p(y|z) being a simple logistic regression--and making the simplest architecture choices we could--we were able to get good results.\n\nAdditionally we added several changes to the adversarial section and accompanying figures. Hopefully this improves clarity while showing some additional experiments with the fast gradient sign method of generating adversarial examples. \n\nYour idea of training against the discovered adversarial examples is a good idea -- Goodfellow et al. 2014 demonstrated that doing such training can also improve robustness to adversarial examples, and it\u2019s likely to improve things in the VIB model as well.  We don\u2019t include adversarial training in this work, since we are trying to focus on the question of whether the information bottleneck on its own improves robustness relative to reasonable baselines, but it is certainly something we would want to do when trying to train a maximally robust model.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1481899184228, "tcdate": 1481899184228, "number": 2, "id": "rJ_3n_ZNx", "invitation": "ICLR.cc/2017/conference/-/paper241/official/review", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer1"], "content": {"title": "Great idea, lacking empirical section", "rating": "6: Marginally above acceptance threshold", "review": "Summary:\nThe paper \u201cDeep Variational Information Bottleneck\u201d explores the optimization of neural networks for variational approximations of the information bottleneck (IB; Tishby et al., 1999). On the example of MNIST, the authors show that this may be used for regularization or to improve robustness against adversarial attacks.\n\nReview:\nThe IB is potentially very useful for important applications (regularization, adversarial robustness, and privacy are mentioned in the paper). Combining the IB with recent advances in deep learning to make it more widely applicable is an excellent idea. But given that the theoretical contribution is a fairly straight-forward application of well-known ideas, I would have liked to see a stronger experimental section.\n\nSince the proposed approach allows us to scale IB, a better demonstration of this would have been on a larger problem than MNIST. It is also not clear whether the proposed approach will still work well to regularize more interesting networks with many layers.\n\nWhy is dropout not included in the quantitative comparison of robustness to adversarial examples (Figure 4)?\n\nHow was the number of samples (12) chosen?\n\nWhat are the error bars in Figure 1 (a)?\n\nOn page 7 the authors claim \u201cthe posterior covariance becomes larger\u201d as beta \u201cdecreases\u201d (increases?). Is this really the case? It\u2019s hard to judge based on Figure 1, since the figures are differently scaled.\n\nIt might be worth comparing to variational fair autoencoders (Louizos et al., 2016), which also try to learn representations minimizing the information shared with an aspect of the input.\n\nThe paper is well written and easy to follow.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512652947, "id": "ICLR.cc/2017/conference/-/paper241/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper241/AnonReviewer3", "ICLR.cc/2017/conference/paper241/AnonReviewer1", "ICLR.cc/2017/conference/paper241/AnonReviewer4"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512652947}}}, {"tddate": null, "tmdate": 1481705823709, "tcdate": 1481705823701, "number": 1, "id": "r1dPtY0me", "invitation": "ICLR.cc/2017/conference/-/paper241/official/review", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer3"], "content": {"title": "A paper with interesting methods, but the presentation is a bit confusing", "rating": "6: Marginally above acceptance threshold", "review": "Thank you for an interesting read. I personally like the information bottleneck principle and am very happy to see its application to deep neural networks. To my knowledge, this is the first paper that applies IB to train deep networks (the original papers only presented the concept), but see below for the note of independent work claim. \n\nThe derivation of the variational lowerbound is very clear, even for those who are not very familiar with variational inference. Also the explanation of the IB principle is clear. Experimental results seem to be very promising.\n\nI found the presentation for the model a bit confusing. In variational inference/information maximisation, p usually denotes the model and q represents the \"inference engine\". This means the choice of inference method is independent to the modelling procedure. However the presented VIB assumed p(x, y) as the **underlying data distribution** (and approximated by the empirical distribution), thus here the model is actually q(y|z)p(z|x). Then the authors presented p(y|x) as the **predictive distribution** in page 8, paragraph 2 of section 4.2.3. Predictive in what sense? I guess you meant p(y|x) = \\int q(y|z) p(z|x) dz in this case, but this makes the two definitions contradict to each other!\n\nThe authors have made an interesting connection to variational auto-encoder and the warm-up training (by tuning beta). However, even when the loss function formula is the same to the variational lowerbound used in VAE (in this case beta = 1), the underlying model is different! For example, r(z) in VIB is the variational approximation to p(z) (which means r(z) is not a component in the model), while in VAE it is the prior distribution which is actually defined in the modelling procedure. Similaly p(z|x) in VIB is included in the model, while in VAE that is the approximate posterior and can be independently chosen (e.g. you can use p(x|z) as a deep NN but p(z|x) as a deep NN or a Gaussian process).\n\nIn summary, I think the presentation for the modelling procedure is unclear. I hope these point would be made clearer in revision since the current presentation makes me uncomfortable as a Bayesian person. In the VAE part, it's better to clearly mention the difference between VIB and VAE, and provide some intuitions if the VIB interpretation is preferred.\n\n\nTypos:\nEq. 9-11: did you mean q(y|z) instead of q(z|y)?\nFig 2 \"as beta becomes smaller\": did you mean \"larger\"?\n\n**claim for independent work**\nThe authors claimed that the manuscript presented an independent work to Chalk et al. 2016 which is online since May 2016. It seems to me that nowadays deep learning research is very competitve that many people publish the same idea at the same time. So I would trust this claim and commend the authors' honesty, but in case this is not true, I would not recommend the manuscript for acceptance.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512652947, "id": "ICLR.cc/2017/conference/-/paper241/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper241/AnonReviewer3", "ICLR.cc/2017/conference/paper241/AnonReviewer1", "ICLR.cc/2017/conference/paper241/AnonReviewer4"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512652947}}}, {"tddate": null, "tmdate": 1480700579283, "tcdate": 1480700579278, "number": 2, "id": "ryssfEy7x", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["~Weiran_Wang1"], "readers": ["everyone"], "writers": ["~Weiran_Wang1"], "content": {"title": "connection to variational CCA", "comment": "This is an interesting paper. \n\nIt is known that IB for Gaussian variables is equivalent to CCA in certain sense\nGal Chechik and Amir Globerson and Naftali Tishby and Yair Weiss. Information Bottleneck for Gaussian variables. JMLR 2005.\n\nAnd although the motivations and approximations used are somewhat different, DVIB and our deep variational CCA paper (also in submission to ICLR, https://openreview.net/pdf?id=H1Heentlx): if I am not mistaken, your objective (17) is essentially the objective of our basic VCCA model (eqn 4 in our paper) without the likelihood for the first view. But of course you motivated the use of the trade-off parameter beta in your IB formulation.\n\nThe equivalence between IB and CCA in the deep variational models is satisfying."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1480694450549, "tcdate": 1480694450545, "number": 2, "id": "rJi2qM1Qe", "invitation": "ICLR.cc/2017/conference/-/paper241/pre-review/question", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer1"], "content": {"title": "Optimal beta", "question": "How was beta in Table 1 chosen? If it was chosen based on the test set, the performance may be too optimistic. Since the training set cannot be used to choose beta (one would end up with beta=0), cross-validation has to be used. This step seems important since the optimal beta depends on the size of the bottleneck and the number of samples, so that using a fixed beta would be sub-optimal."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959387111, "id": "ICLR.cc/2017/conference/-/paper241/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper241/AnonReviewer3", "ICLR.cc/2017/conference/paper241/AnonReviewer1"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959387111}}}, {"tddate": null, "tmdate": 1480612731203, "tcdate": 1480612731199, "number": 1, "id": "BJ7ts0pGg", "invitation": "ICLR.cc/2017/conference/-/paper241/public/comment", "forum": "HyxQzBceg", "replyto": "S1ZRJcvzl", "signatures": ["~Ian_Fischer1"], "readers": ["everyone"], "writers": ["~Ian_Fischer1"], "content": {"title": "Details on adversarial attack", "comment": "Nicholas Carlini shared his implementation of the attacks in his recent paper https://arxiv.org/abs/1608.04644 with us.  We used the code for his L2 attack directly, including using the same parameters as he used for the the results in his paper (which we confirmed by replicating his results on the same network he used in his paper -- he also shared the trained checkpoint for that network).\n\nHis L2 attack uses the Adam optimizer to find perturbations to an input image that cause the classifier to change its result on that input image to a different class.  This attack works in both untargeted and targeted variants.  I.e., you can have the optimizer generate perturbations that change the classification to another arbitrary class, or you can specify that the perturbation must change the classification to a particular class.  The loss that is optimized combines an L2 measure between the original image and the perturbed image, and a second loss computed from the original classification (or target classification, if it\u2019s a targeted attack) and the output classification.  In order to constrain the adversarial example to be a valid image (where all of the pixels are in a constrained range), the attack also passes the perturbed image through a tanh function before doing the classification.\n\nSince the Deep VIB model is a classifier, this  adversarial attack (and most others) can be applied directly.  We did not need to change anything to run the attack on the different networks, so all of the networks mentioned in the paper were attacked in exactly the same way, including the same attack parameters."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670163, "id": "ICLR.cc/2017/conference/-/paper241/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyxQzBceg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper241/reviewers", "ICLR.cc/2017/conference/paper241/areachairs"], "cdate": 1485287670163}}}, {"tddate": null, "tmdate": 1480200136893, "tcdate": 1480200136888, "number": 1, "id": "S1ZRJcvzl", "invitation": "ICLR.cc/2017/conference/-/paper241/pre-review/question", "forum": "HyxQzBceg", "replyto": "HyxQzBceg", "signatures": ["ICLR.cc/2017/conference/paper241/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper241/AnonReviewer3"], "content": {"title": "Adversarial example", "question": "Thank you for an interesting read.\n\nCould you clarify how exactly did you generate the adversarial examples for each method you tested, especially for Deep VIB?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Variational Information Bottleneck", "abstract": "We present a variational approximation to the information bottleneck of Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \u201cDeep Variational Information Bottleneck\u201d, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.", "pdf": "/pdf/8c41248f88f7436402feb8fd572711569713d314.pdf", "TL;DR": "Applying the information bottleneck to deep networks using the variational lower bound and reparameterization trick.", "paperhash": "alemi|deep_variational_information_bottleneck", "conflicts": ["google.com"], "keywords": ["Theory", "Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Alexander A. Alemi", "Ian Fischer", "Joshua V. Dillon", "Kevin Murphy"], "authorids": ["alemi@google.com", "iansf@google.com", "jvdillon@google.com", "kpmurphy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959387111, "id": "ICLR.cc/2017/conference/-/paper241/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper241/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper241/AnonReviewer3", "ICLR.cc/2017/conference/paper241/AnonReviewer1"], "reply": {"forum": "HyxQzBceg", "replyto": "HyxQzBceg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper241/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959387111}}}], "count": 18}