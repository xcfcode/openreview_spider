{"notes": [{"id": "7FNqrcPtieT", "original": "4tmYCJJxlNg", "number": 1052, "cdate": 1601308118586, "ddate": null, "tcdate": 1601308118586, "tmdate": 1611607624958, "tddate": null, "forum": "7FNqrcPtieT", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "mmQwMQyQhIQ", "original": null, "number": 1, "cdate": 1610040397662, "ddate": null, "tcdate": 1610040397662, "tmdate": 1610473993094, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper provides some theoretical perspective on the use of data augmentation in consistency regularization-based semi-supervised learning. The framework used in the paper argues that high-quality data augmentation should move along the data manifold. This generic view allows the paper's ideas to be applied across datasets (as opposed to image-specific data augmentation used in state-of-the-art semi-supervised learning algorithms). I am not aware of any other work raising these points, and indeed this paper is significant in that it provides a new and potentially useful perspective on the most performative semi-supervised learning approach. Reviewers agreed that the paper was clear and useful. The main concern was that the paper only included experiments in toy settings. Indeed, it would have been much more impactful to apply these ideas to state-of-the-art semi-supervised learning methods, but I think it can be excused given the theoretical focus of the work."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040397649, "tmdate": 1610473993078, "id": "ICLR.cc/2021/Conference/Paper1052/-/Decision"}}}, {"id": "MFoll9c0_VQ", "original": null, "number": 2, "cdate": 1603910177840, "ddate": null, "tcdate": 1603910177840, "tmdate": 1606772032027, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review", "content": {"title": "Insufficient experimental confirmation and there are some apparent contradictions in the proposed explanation, notably with MixUp", "review": "# Summary\n\nThis paper proposes a theoretical framework for understanding consistency-based semi-supervised learning. While establishing this framework based on the Hidden Manifold Model, this paper frames the SSL in the context of Manifold Tangent Classifiers.\n\n# Pros\n\n1. Formal understanding of SSL is indeed currently limited and theoretical works are needed.\n2. The formalization of minimizers as harmonic function leads to the non-obvious prediction that SSL methods are insensitive, or at least very robust, to the weighting of the consistency loss $\\lambda$. To me, this is the most important result of the paper.\n3. The bibliography is well documented.\n\n# Cons\n1. The experimental verification of insensitivity to the weighting of consistency loss is unconvincing: it is done on a trivial low-dimensional toy dataset. It would be more convincing to take the GitHub code of one or more, possibly recent, SSL methods and vary $\\lambda$ on real datasets.\n2. I fail to see any other takeaway from the theoretical framework than the predicted insensitivity to $\\lambda$.\n3. Technically, if I understand correctly, the insensitivity to $\\lambda$ is not a takeaway of the Hidden Manifold Model but of the Minimizers are Harmonic Functions.\n4. I didn\u2019t see where the claim \u201c... demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances\u201d has indeed been demonstrated.\n\n# Questions and nits\n1. \u201cSeveral extensions such as the Mean Teacher (TV17) and the Virtual Adversarial Training (VAT) (MMIK18) schemes have been recently proposed and have been shown to lead to state-of-the-art results in many SSL tasks.\u201d They are far from the current state of the art, especially so for few labels, this would have been true before the advent of MixMatch but the state of the art changed drastically with its introduction.\n2. \u201c... consider as well the tangent plane Tx to M at x.\u201d Here I have a hard time visualizing it. Say the manifold M is a 2D Gaussian point cloud for example, what would be the tangent plane for a point x in that cloud?\n3. Following on question 2, how is the tangent plane property exploited other than by defining an orthonormal basis on it? And why can\u2019t an orthonormal basis of the Manifold space itself be enough if instead we assume it is dense?\n4. \u201cEnriching the set of data-augmentation degrees of freedom with transformations such as elastic deformation or non-linear pixel intensity shifts is crucial to obtaining a high-dimensional local exploration manifold.\u201d This seems in direct contradiction with MixMatch results which does not use any sophisticated augmentation: just pixel shift, mirroring and random pixel-wise linear interpolation between samples and labels (MixUp).\n5. Proposition 4.1: Here I was hoping for a prediction for your method. You mention the \u201csequence of processes converges weakly\u201d and I was hoping it would explain why SSL techniques are much slower than fully supervised to converge. But then, it seems this statement is not exploited in any way other than saying that it does indeed converge to the solution of the ODE.\n6. \u201cThis indicates that the improved performances of the Mean Teacher approach sometimes reported in the literature are either not statistically meaningful, or due to poorly executed comparisons, or due to mechanisms not captured by the \u03b7 \u2192 0 asymptotic.\u201d This is vague, considering Mean Teacher outperforms VAT, would this mean that the last option holds (due to mechanisms not captured by the \u03b7 \u2192 0 asymptotic)? Just to clarify what the last option actually means: does it mean the proposed analysis relies on assumptions that don\u2019t capture the reality of the phenomenon?\n7. \u201cThese results are achieved by leveraging more sophisticated data augmentation schemes such as ... Mixup\u201d. It seems odd to see MixUp being referred to as sophisticated (as in domain specific). MixUp is domain agnostic, it simply linearly combines a pair of samples and their labels. So in fact, it seems even simpler than a pixel shift since it\u2019s linear.\n8. \u201c... with a neural network with a single hidden layer with N = 100 neurons\u201d. What non-linearity was used? I didn\u2019t seem to find it, or I may have missed it.\n9. \u201cFigure 3 (Left) shows that, contrary to several other types of regularizations such as weight-decay, this method is relatively insensitive to the parameter \u03bb\u201d. I didn\u2019t see it. It indeed shows that (a) the method is relatively insensitive to the parameter \u03bb in the context of the toy task but it doesn\u2019t show that (b) the method is sensitive to other types of regularization such as weight-decay.\n\nNote: Ultimately I must admit a lot of the maths are above my head and I have no idea whether they are correct or not, therefore I didn't comment on them and only focused on the parts that I understand. On the other hand, I'm pretty confident in my understanding of SSL techniques and MixUp.\n\n=====POST-REBUTTAL COMMENTS======== \nI thank the authors for the response and the efforts in the updated draft. Most of my queries were clarified and I raised my rating accordingly. However, unfortunately, I still think a more realistic validation (e.g. on non-toy dataset) would benefit the paper. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128236, "tmdate": 1606915771921, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1052/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review"}}}, {"id": "-pQna_M3Nxm", "original": null, "number": 4, "cdate": 1606239595629, "ddate": null, "tcdate": 1606239595629, "tmdate": 1606277061558, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "MFoll9c0_VQ", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment", "content": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning: answer to AnonReviewer4", "comment": "Thank you for these interesting comments that have allowed us, we hope, to better ground our manuscript within modern methodological SSL practices.\n- \"The formalization of minimizers as harmonic function leads to the non-obvious prediction that SSL methods are insensitive, or at least very robust, to the weighting of the consistency loss \\lambda. To me, this is the most important result of the paper.\" Thank you. To us, the main take-away of the manuscript is the use of the Hidden Manifold framework to spearhead the study of SSL methods (which is still extremely limited, contrarily to the fully supervised settings). \n- \"The experimental verification of insensitivity to the weighting of consistency loss is unconvincing: it is done on a trivial low-dimensional toy dataset.\" : Thank you. We do not consider this example as trivial. Exploring a 10-dimensional manifold \"hidden\" in a D=100 dimensional ambient space is, we believe, challenging. The **intrinsic** dimension of the MNIST/CIFAR datasets, for example, are not that much higher. We could have ran a few experiments on more realistic datasets. We have chosen to continue with our synthetic example because of (1) tight compute constraints (2) our goal to illustrate the usefulness of the Hidden Manifold framework for studying SSL methods (3) the difficulty to control/quantify the data-augmentation schemes when applied to real datasets.\n- \u201cI didn\u2019t see where the claim ... demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances has indeed been demonstrated.\u201d: thank you. We have now expanded the experimental part and numerically \"quantified\" that the quality [in our case, the dimensionality of the exploration of the latent manifold] directly influence the generalisation performance of the Pi-model. Although this can be characterized as \"intuitive\" (ie. better DA leads to better performace), having a modeling framework (i.e. Hidden Manifold generative model) that allows to investigate and empirically observe this phenomenon is, we believe, an important step for the study of SSL methods. As far as we are aware, no other article has followed this road for studying SSL methods.\n- \"They are far from the current state of the art\": thank you, this is an important point and we have clarified accordingly. Note nevertheless that the (sota) BYOL approach relies on mechanisms that are **very** similar to the MT/Pi-models [ie. basic consistency regularisation]. We believe that our framework could be useful to investigate SSL approaches such as the BYOL method.\n- \"This seems in direct contradiction with MixMatch results which does not use any sophisticated augmentation: just pixel shift, mirroring and random pixel-wise linear interpolation between samples and labels (MixUp)\": Thank You. There are many situations (eg. in other projects, we have ran many experiments in medical imaging settings) where elastic transformations are absolutely crucial [ie. MixMatch is far from enough for obtaining robust generalisation properties]. We do believe, though, that your point is indeed valid in many other situations. Conclusion: we need more theoretical investigations to understand when/why  MixMatch-type augmentations, for example, are enough in some situations, and far from enough in other settings.\n- \"[...] I was hoping it would explain why SSL techniques are much slower [...]\". thank you. Our results does *not* explain this phenomenon. It *is* a very interesting question. We do *not* have an explanation for it. Our framework is *unlikely* to easily lead to an understanding of this phenomenon.\n- \"[...] This is vague, considering Mean Teacher outperforms VAT, would this mean that the last option holds [...]\". Thank you. You are correct, our analysis relies on fix learning rate and in the limit when learning rate vanishes [ie. \"fluid limit\" asymptotic]. Standard practices such as adaptive learning rates / cyclic learning rates / momentums and other common optimisation practices are not covered by our analysis. We do agree that our result is only a (small) step towards understanding this class of methods.\n- \"What non-linearity was used? I didn\u2019t seem to find it, or I may have missed it.\" Thank you. We always used the ELU activation for keeping everything differentiable. It is now clarified in the text, thanks.\n- \"I didn\u2019t see it. It indeed shows that (a) the method is relatively insensitive to the parameter \\lambda in the context of the toy task but it doesn\u2019t show that (b) the method is sensitive to other types of regularization such as weight-decay.\" Thank you, it is a good point. We have removed this sentence (because of space considerations: we do believe that methods are often sensitive to the weight-decay parameter).\n- \" maths are above my head [...] I only focused on the parts that I understand. \" Thank you. your comments on the practical aspects of the manuscript *were* very useful to us."}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "7FNqrcPtieT", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1052/Authors|ICLR.cc/2021/Conference/Paper1052/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864233, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment"}}}, {"id": "Sn-oB7pD9CN", "original": null, "number": 5, "cdate": 1606239791713, "ddate": null, "tcdate": 1606239791713, "tmdate": 1606241032064, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "m_P572d9-gk", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment", "content": {"title": "ON DATA-AUGMENTATION AND CONSISTENCYBASED SEMI-SUPERVISED LEARNING: answer to AnonReviewer3", "comment": "Thank you for your comments:\n- \"The experiments are a bit weak only using simple synthetic settings. Some of the claims in the paper are not backed up by experimental results.\" Thank you. We have now expanded further our investigations of the Hidden Manifold generative model to (1) show that the MT method and \u03a0-model approach share the same solutions (2) the Hidden Manifold is a convenient framework for studying/controlling the quality+amount of the data-augmentation schemes. We have chosen to expand the synthetic example. This choice is motivated by our belief that the Hidden Manifold generative model is a good framework for (empirically) analysing SSL methods since it allows to quantify/control several key parameters (eg. quality/quantity of the Data-Augmentation) that are otherwise difficult to investigate on real datasets. We do believe that obtaining a theoretical understanding of SSL methods within the Hidden Manifold generative model is possible [eg. by considering the appropriate limiting regime when the dimensionality of the hidden layers goes to infinity], although it is (completely) out of the scope of the current manuscript.\n- \"It will be nice to demonstrate this with an experiment for the reader to better understand why this happens.\" Thank you. We have followed your suggestion and added this empirical study and confirmed that MT/Pi-model do lead to similar solutions (at least in the regime considered in our manuscript)."}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "7FNqrcPtieT", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1052/Authors|ICLR.cc/2021/Conference/Paper1052/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864233, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment"}}}, {"id": "Anc-u2qFTHU", "original": null, "number": 3, "cdate": 1606239391462, "ddate": null, "tcdate": 1606239391462, "tmdate": 1606239391462, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "Qd3y0k6NgTv", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment", "content": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "comment": "Thank you for your comments.\n- \"The quality of the paper will be improved if it uses MTC and provides some new results which do not exist in the SSL literature\": to the best of our knowledge, a study of (1) the influence of the parameter \\lambda that controls the trade-off between supervised and consistency loss terms (2) the equivalence of MT and Pi-model, and (3) [most importantly to our views] the use of Hidden Manifold generative framework for studying SSL, are new.\n- \"This is because MTC may not be the only approach to analyze these points\": agreed.\n- \"someone may ask what is special in your approach to analysis consistency-based SSL methods in contrast to other tools/techniques?\": Thank you. It allowed us to obtain a few results theoretical results, which is quite special to us. Furthermore, the Hidden Manifold framework, as we now empirically demonstrate at the very end of the article, allows to efficiently design controlled numerical experiments where the amount of DA can be accurately controlled + the quality of the exploration of the (latent) data-manifold can be quantified.\n- \"there are many other approaches based on optimal transport (e.g., Wasserstein Distances) that consider the geometry of the data and can be used to analyze the effect of perturbation on the SSL performance.\" Thank you. We are not aware of these studies and have not managed to find appropriate references.\n- \"providing more experiments on some claims discussed in the paper (e.g., Mean Teacher method and \u03a0-model approach share the same solutions in the cases where the data-augmentations are small) is necessary and can improve the quality of the paper\": thank you for this suggestion. We have now expanded further our investigations of the Hidden Manifold generative model to (1) show that the MT method and \u03a0-model approach share the same solutions (2) the Hidden Manifold is a convenient framework for studying/controlling the quality+amount of the data-augmentation schemes."}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "7FNqrcPtieT", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1052/Authors|ICLR.cc/2021/Conference/Paper1052/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864233, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Comment"}}}, {"id": "Qd3y0k6NgTv", "original": null, "number": 3, "cdate": 1603960180600, "ddate": null, "tcdate": 1603960180600, "tmdate": 1605024542424, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review", "content": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning ", "review": "This paper analyses the consistency-based SSL methods in settings  where  data lie a manifold of much lower dimension than the input space and obtains tractable results. The paper relates the analysis with Manifold Tangent Classifiers and shows that the quality of the perturbations plays a key role  to achieve a promising results in this set of SSL methods. Finally, the paper extends the Hidden Manifold Model by incorporating data-augmentation techniques and proposes a framework  to provide a direction for analyzing consistency-based SSL methods.\n\n+This work might be useful for those who want to work in the theoretical part of SSL. \n\n+The paper analytically discusses that the type of data augmentation plays a significant role in the performance  of the SSL models based on consistency regularization.  \n\n-While many points discussed in the paper are natural to me and well-discussed in the SSL literature (e.g.,  considering geometry of the data to develop an SSL algorithm or effect of the perturbation quality on the performance), relating and analyzing them with Manifold Tangent Classifiers (MTC) is interesting and new to me.  However, I still think that the theoretical part of the work is not strong enough and can be improved. The quality of the paper will be  improved if it uses MTC and provides some new results which do not exist in the SSL literature. This is because  MTC may not be the only approach to analyze these points.  For example, there are many other approaches based on optimal transport (e.g., Wasserstein Distances) that consider the geometry of the data and can be used to analyze the effect of perturbation on the SSL performance.  Then, someone may ask what is special in your approach to analysis consistency-based SSL methods in contrast to other tools/techniques?\n\n-While this paper is mostly an analytical paper, providing more experiments on some claims discussed in the paper  (e.g., Mean Teacher method and \u03a0-model approach share the same solutions in the cases where the data-augmentations are small)  is necessary and can improve the quality of the paper. Furthermore, authors may  use the exact same underlying model, training set-up,  and then try different types of data-augmentation methods on several recent and effective consistency-based SSL methods to show the differences on the performance experimentally. This can better contextualize the paper as we will know how much is the difference in terms of accuracy between different consistency-based SSL methods  with respect to perturbation, or other data-augmentation methods. \n\nGenerally,  I think this  paper provides a good direction for understanding the consistency based-SSL methods.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128236, "tmdate": 1606915771921, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1052/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review"}}}, {"id": "m_P572d9-gk", "original": null, "number": 1, "cdate": 1603817969135, "ddate": null, "tcdate": 1603817969135, "tmdate": 1605024542361, "tddate": null, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "invitation": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review", "content": {"title": "ON DATA-AUGMENTATION AND CONSISTENCYBASED SEMI-SUPERVISED LEARNING", "review": "Summary: The authors analyze consistency-based models in specific settings where analytically tractable results can be obtained. They establish that leveraging more sophisticated data augmentation schemes is crucial to obtain huge gains when using consistency based models. Finally, they propose an extension of Hidden Manifold Model that incorporates data augmentation for understanding and experimenting with SSL methods.\n\nPros:\nThe paper is theoretically well grounded and the authors do a good job of connecting to previous works.\n\nThe paper is interesting and well written. It tries to explain the why consistency based method achieve good performance compared to other semi-supervised models. I find this relevant and helpful in understanding what makes these models work the way they do.\n\nCons:\nThe experiments are a bit weak only using simple synthetic settings.\nSome of the claims in the paper are not backed up by experimental results.\n\nComments:\nMore experiments should be provided to establish some of the claims in the paper. Additionally, it will be good to see an experiment on a real dataset albeit small rather than simple synthetic experiments.\n\nOne of the claims of the paper is that mean teacher and simple \u03a0-model approach share the same solutions in the regime where the data augmentations are small but advanced data augmentations performs better. It will be nice to demonstrate this with an experiment for the reader to better understand why this happens.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1052/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1052/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Data-Augmentation and Consistency-Based Semi-Supervised Learning", "authorids": ["~Atin_Ghosh1", "~Alexandre_H._Thiery1"], "authors": ["Atin Ghosh", "Alexandre H. Thiery"], "keywords": ["Semi-Supervised Learning", "Regularization", "Data augmentation"], "abstract": "Recently proposed consistency-based Semi-Supervised Learning (SSL) methods such as the Pi-model, temporal ensembling, the mean teacher, or the virtual adversarial training, achieve the state of the art results in several SSL tasks. These methods can typically reach performances that are comparable to their fully supervised counterparts while using only a fraction of labelled examples. Despite these methodological advances, the understanding of these methods is still relatively limited. To make progress, we analyse (variations of) the Pi-model in settings where analytically tractable results can be obtained. We establish links with Manifold Tangent Classifiers and demonstrate that the quality of the perturbations is key to obtaining reasonable SSL performances. Furthermore, we propose a simple extension of the Hidden Manifold Model that naturally incorporates data-augmentation schemes and offers a tractable framework for understanding SSL methods.", "one-sentence_summary": "We propose a simple and natural framework leveraging the Hidden Manifold Model to study modern SSL methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ghosh|on_dataaugmentation_and_consistencybased_semisupervised_learning", "pdf": "/pdf/b336e63b29c715b76018ba42cb29f2592569ab56.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nghosh2021on,\ntitle={On Data-Augmentation and Consistency-Based Semi-Supervised Learning},\nauthor={Atin Ghosh and Alexandre H. Thiery},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=7FNqrcPtieT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "7FNqrcPtieT", "replyto": "7FNqrcPtieT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1052/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128236, "tmdate": 1606915771921, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1052/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1052/-/Official_Review"}}}], "count": 8}