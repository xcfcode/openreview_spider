{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124435732, "tcdate": 1518472958078, "number": 353, "cdate": 1518472958078, "id": "SJ8W1c1Pz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJ8W1c1Pz", "signatures": ["~Ishaan_Gulrajani1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Evaluating Implicit Generative Models With Large Samples", "abstract": "We study the problem of evaluating a generative model using only a finite sample from the model. For many common evaluation functions, generalization is meaningless because trivially memorizing the training set attains a better score than the models we consider state-of-the-art. We clarify a necessary condition for an evaluation function not to behave this way: estimating the function must require a large sample from the model. In search of such a function, we turn to parametric adversarial divergences, which are defined in terms of a neural network trained to distinguish between distributions: as we make the network larger, the function is less easily minimized by memorizing the training set. We implement a reliable evaluation function based on these ideas, validate it experimentally, and show models which achieve better scores than memorizing the training set.\n", "paperhash": "gulrajani|evaluating_implicit_generative_models_with_large_samples", "keywords": ["generative modeling"], "_bibtex": "@misc{\n  gulrajani2018evaluating,\n  title={Evaluating Implicit Generative Models With Large Samples},\n  author={Ishaan Gulrajani and Colin Raffel and Luke Metz},\n  year={2018},\n  url={https://openreview.net/forum?id=SJ8W1c1Pz}\n}", "authorids": ["igul222@gmail.com", "craffel@google.com", "lmetz@google.com"], "authors": ["Ishaan Gulrajani", "Colin Raffel", "Luke Metz"], "TL;DR": "Evaluating generalization in implicit generative models by considering millions of sample points rather than thousands", "pdf": "/pdf/4d81046c08dcbbfd5d346024eb5de9ac49565c2e.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582940755, "tcdate": 1520273194435, "number": 1, "cdate": 1520273194435, "id": "SkzVP-idf", "invitation": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "signatures": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer2"], "content": {"title": "Interesting initial contribution", "rating": "7: Good paper, accept", "review": "This paper provides an interesting initial version of a proposal for a very important topic, and is clearly worthy of inclusion in the workshop.\n\nThere remain many practical and theoretical considerations to be made for this method: for example, does it \"unfairly\" favor models based on similar architectures? Though the variance is low, the bias is clearly high (from e.g. Figure 2) -- how big of a deal is this? In particular, does this bias make it difficult to compare estimates between different distributions (which is what you really care about)? How sensitive are the evaluations to minor changes in the architecture / training procedure / etc? Are the gains in evaluation worth the large amount of additional computational required over an Inception score / FID-type evaluation? These and others are all important questions to grapple with for this type of evaluation method, but beyond the scope of a three-page workshop abstract.\n\nOne minor correction: you say in section 2 that the FID and MMD-like methods \"have runtime quadratic (or worse) in the number of sample points.\" This is not at all true for the FID, whose default estimator has runtime O(n d^2 + d^3) for n the number of sample points and d the dimension. Additionally, although the \"default\" estimator for the MMD does take time quadratic in the samples, there is also a linear-time estimator given by Gretton et al. (2012), a generalization that can still be chosen to be linear-time by Zaremba et al. (NIPS 2013), and a different linear-time estimator of a closely related distance by Chwialkowski et al. (NIPS 2015) / Jitkrittum et al. (NIPS 2016).", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating Implicit Generative Models With Large Samples", "abstract": "We study the problem of evaluating a generative model using only a finite sample from the model. For many common evaluation functions, generalization is meaningless because trivially memorizing the training set attains a better score than the models we consider state-of-the-art. We clarify a necessary condition for an evaluation function not to behave this way: estimating the function must require a large sample from the model. In search of such a function, we turn to parametric adversarial divergences, which are defined in terms of a neural network trained to distinguish between distributions: as we make the network larger, the function is less easily minimized by memorizing the training set. We implement a reliable evaluation function based on these ideas, validate it experimentally, and show models which achieve better scores than memorizing the training set.\n", "paperhash": "gulrajani|evaluating_implicit_generative_models_with_large_samples", "keywords": ["generative modeling"], "_bibtex": "@misc{\n  gulrajani2018evaluating,\n  title={Evaluating Implicit Generative Models With Large Samples},\n  author={Ishaan Gulrajani and Colin Raffel and Luke Metz},\n  year={2018},\n  url={https://openreview.net/forum?id=SJ8W1c1Pz}\n}", "authorids": ["igul222@gmail.com", "craffel@google.com", "lmetz@google.com"], "authors": ["Ishaan Gulrajani", "Colin Raffel", "Luke Metz"], "TL;DR": "Evaluating generalization in implicit generative models by considering millions of sample points rather than thousands", "pdf": "/pdf/4d81046c08dcbbfd5d346024eb5de9ac49565c2e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582940534, "id": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper353/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer1"], "reply": {"forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582940534}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582742449, "tcdate": 1520660747995, "number": 2, "cdate": 1520660747995, "id": "Sy4fZeZKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "signatures": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer3"], "content": {"title": "Interesting idea but lacks of new / claim-supporting quantitative results", "rating": "5: Marginally below acceptance threshold", "review": "This paper tries to quantitatively argue that the parametric adversarial divergences are good metrics to evaluate implicit generative models with large samples. But i have concerns on the new results presented in this work. Tracking the convergence of training (Figure 1) and overfitting issues (Figure 3) have already been explored by the original WGAN work (Figure 3) and the follow-up WGAN-GP work (Figure 5).\n\nFor the analysis in Table 1, I do not think it would directly relate to Definition 1. The divergence D in Definition 1 is the same for both sides of the inequality. But the trained parametric adversarial divergences on different sides of the inequality in Table 1 are trained on different datasets suggesting they are in high probability different divergences. Even though different training of the network on the same pair of (test data, generated data) results consistent evaluations, i do not believe this could be extended to different pairs of data.\n\nOne of the emphasis of the work is to use \"large sample\" from the generative model for evaluation. The result shown in Figure 2 suggests that \"it might be safe to use a small test set\" from the data distribution. My understanding is that this comparison is based on fixed number of samples from the generative model. What we usually deal with in practice is a fix number of test samples from the data distribution. Wouldn't this result also suggest that it might also be safe to a use a small set from the generative model, which would undermine the usage of \"large sample\".\n\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating Implicit Generative Models With Large Samples", "abstract": "We study the problem of evaluating a generative model using only a finite sample from the model. For many common evaluation functions, generalization is meaningless because trivially memorizing the training set attains a better score than the models we consider state-of-the-art. We clarify a necessary condition for an evaluation function not to behave this way: estimating the function must require a large sample from the model. In search of such a function, we turn to parametric adversarial divergences, which are defined in terms of a neural network trained to distinguish between distributions: as we make the network larger, the function is less easily minimized by memorizing the training set. We implement a reliable evaluation function based on these ideas, validate it experimentally, and show models which achieve better scores than memorizing the training set.\n", "paperhash": "gulrajani|evaluating_implicit_generative_models_with_large_samples", "keywords": ["generative modeling"], "_bibtex": "@misc{\n  gulrajani2018evaluating,\n  title={Evaluating Implicit Generative Models With Large Samples},\n  author={Ishaan Gulrajani and Colin Raffel and Luke Metz},\n  year={2018},\n  url={https://openreview.net/forum?id=SJ8W1c1Pz}\n}", "authorids": ["igul222@gmail.com", "craffel@google.com", "lmetz@google.com"], "authors": ["Ishaan Gulrajani", "Colin Raffel", "Luke Metz"], "TL;DR": "Evaluating generalization in implicit generative models by considering millions of sample points rather than thousands", "pdf": "/pdf/4d81046c08dcbbfd5d346024eb5de9ac49565c2e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582940534, "id": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper353/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer1"], "reply": {"forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582940534}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582702214, "tcdate": 1520698040645, "number": 3, "cdate": 1520698040645, "id": "S1ZpMt-Fz", "invitation": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "signatures": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer1"], "content": {"title": "Maybe it contains some valuable empirical insights, but the paper currently doesn't work", "rating": "2: Strong rejection", "review": "There's something fundamental that I don't understand about this paper. The premise is that, for many evaluation metrics, memorising the training set yield good generalisation performance. I just can't make sense of that statement. What are those evaluation metrics? What's the exact technical statement you are making? The closest to an explanation that I can find in the paper is the following paragraph:\n\n  Let p\u02c6n be an empirical distribution of n points from p. For some D, we have that D(\u02c6ptest, \u02c6p) \u2192\n  D(\u02c6ptest, p) as n \u2192 \u221e. This means that even trivially memorizing the training set generalizes to\n  some extent under D, since it minimizes D(\u02c6ptest, q) to some extent\n\nThat's extremely hand-wavy and clearly insufficient motivation for the paper. A concept such as generalisation (or just convergence) is pretty subtle and I'd suggest the authors review statistical learning theory and take a more principled approach to this issue. How do you even define D(\u02c6ptest, p\u02c6n) if the two empirical distributions have different support? That's what you need learning for, to go from \u02c6p_n to a function on the whole input space including \u02c6p_test. But there's no mention of a learning algorithm anywhere.\n\nI think that the authors are implicitly thinking about the GAN case and probably have an interesting good point to make from an empirical perspective, but they need to focus on the specific issue they have in mind and be much more precise instead of talking about key concepts such as generalisation in such a broad-stroked manner.\n\nMinor points\n* Lacking definitions: Just based on the first few lines: what is an implicit model in this context? what are p_test and q? I can have educated guesses, but I shouldn't have to.\n* Writing is \"amateur\" in general and doesn't read like a proper paper", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating Implicit Generative Models With Large Samples", "abstract": "We study the problem of evaluating a generative model using only a finite sample from the model. For many common evaluation functions, generalization is meaningless because trivially memorizing the training set attains a better score than the models we consider state-of-the-art. We clarify a necessary condition for an evaluation function not to behave this way: estimating the function must require a large sample from the model. In search of such a function, we turn to parametric adversarial divergences, which are defined in terms of a neural network trained to distinguish between distributions: as we make the network larger, the function is less easily minimized by memorizing the training set. We implement a reliable evaluation function based on these ideas, validate it experimentally, and show models which achieve better scores than memorizing the training set.\n", "paperhash": "gulrajani|evaluating_implicit_generative_models_with_large_samples", "keywords": ["generative modeling"], "_bibtex": "@misc{\n  gulrajani2018evaluating,\n  title={Evaluating Implicit Generative Models With Large Samples},\n  author={Ishaan Gulrajani and Colin Raffel and Luke Metz},\n  year={2018},\n  url={https://openreview.net/forum?id=SJ8W1c1Pz}\n}", "authorids": ["igul222@gmail.com", "craffel@google.com", "lmetz@google.com"], "authors": ["Ishaan Gulrajani", "Colin Raffel", "Luke Metz"], "TL;DR": "Evaluating generalization in implicit generative models by considering millions of sample points rather than thousands", "pdf": "/pdf/4d81046c08dcbbfd5d346024eb5de9ac49565c2e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582940534, "id": "ICLR.cc/2018/Workshop/-/Paper353/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper353/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper353/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper353/AnonReviewer1"], "reply": {"forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper353/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582940534}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573591224, "tcdate": 1521573591224, "number": 206, "cdate": 1521573590878, "id": "S1yy11J9z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJ8W1c1Pz", "replyto": "SJ8W1c1Pz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating Implicit Generative Models With Large Samples", "abstract": "We study the problem of evaluating a generative model using only a finite sample from the model. For many common evaluation functions, generalization is meaningless because trivially memorizing the training set attains a better score than the models we consider state-of-the-art. We clarify a necessary condition for an evaluation function not to behave this way: estimating the function must require a large sample from the model. In search of such a function, we turn to parametric adversarial divergences, which are defined in terms of a neural network trained to distinguish between distributions: as we make the network larger, the function is less easily minimized by memorizing the training set. We implement a reliable evaluation function based on these ideas, validate it experimentally, and show models which achieve better scores than memorizing the training set.\n", "paperhash": "gulrajani|evaluating_implicit_generative_models_with_large_samples", "keywords": ["generative modeling"], "_bibtex": "@misc{\n  gulrajani2018evaluating,\n  title={Evaluating Implicit Generative Models With Large Samples},\n  author={Ishaan Gulrajani and Colin Raffel and Luke Metz},\n  year={2018},\n  url={https://openreview.net/forum?id=SJ8W1c1Pz}\n}", "authorids": ["igul222@gmail.com", "craffel@google.com", "lmetz@google.com"], "authors": ["Ishaan Gulrajani", "Colin Raffel", "Luke Metz"], "TL;DR": "Evaluating generalization in implicit generative models by considering millions of sample points rather than thousands", "pdf": "/pdf/4d81046c08dcbbfd5d346024eb5de9ac49565c2e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}