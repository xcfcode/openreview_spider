{"notes": [{"id": "SyewFf46-r", "original": null, "number": 1, "cdate": 1563406975281, "ddate": null, "tcdate": 1563406975281, "tmdate": 1563406975281, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "rkecjeQQo4", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Public_Comment", "content": {"comment": "Dear Authors,\n\nAs a random reader of your paper, I really appreciate your honesty. Also a thank to the ICLR organizer for hosting papers in OpenReview. It is a great platform for a continual review!\n\nThank you", "title": "Thank you for your honesty "}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311738052, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkeRTsAcYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311738052}}}, {"id": "rkecjeQQo4", "original": null, "number": 10, "cdate": 1556455586377, "ddate": null, "tcdate": 1556455586377, "tmdate": 1556455586377, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Retracted from ICLR2019.", "comment": "Dear readers, this is the announcement of the retraction of our paper \"Phase-Aware Speech Enhancement with Deep Complex U-Net\" from ICLR2019. \n\nFirst, we thank you for the interest in our work.\n\nWe are truly sorry, however, to inform that a significant error was found by ourselves in the experimental process of our paper \u201cPhase-aware Speech Enhancement with Deep Complex U-Net\u201d, which was accepted for ICLR2019. After careful examinations, we therefore have made a decision to retract the accepted paper.\n\nTo be more specific about the error, we found out that the training data path was accidentally set to the evaluation data path which means the reported numbers in the table are utterly wrong (possibly overfitted results).\n\nLastly, we sincerely apologize for the mistake we made and promise it will not happen again.\n\nBest regards,\nAuthors"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "SkeRTsAcYm", "original": "ryg5G0OqYm", "number": 850, "cdate": 1538087877800, "ddate": null, "tcdate": 1538087877800, "tmdate": 1549296198581, "tddate": null, "forum": "SkeRTsAcYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BkeutKjWgV", "original": null, "number": 1, "cdate": 1544825215883, "ddate": null, "tcdate": 1544825215883, "tmdate": 1545354529716, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Meta_Review", "content": {"metareview": "The authors propose an algorithm for enhancing noisy speech by also accounting for the phase information. This is done by adapting UNets to handle features defined in the complex space, and by adapting the loss function to improve an appropriate evaluation metric.\n\nStrengths\n- Modifies existing techniques well to better suit the domain for which the algorithm is being proposed. Modifications like extending UNet to complex Unet to deal with phase, redefining the mask and loss are all interesting improvements.\n- Extensive results and analysis.\n\nWeaknesses\n- The work is centered around speech enhancement, and hence has limited focus. \n\nEven though the paper is limited to speech enhancement, the reviewers agreed that the contributions made by the paper are significant and can help improve related applications like ASR. The paper is well written with interesting results and analysis. Therefore, it is recommended that the paper be accepted.\n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Application specific paper, but well written with interesting evaluations and analysis"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper850/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353062381, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353062381}}}, {"id": "r1lmk_KH0X", "original": null, "number": 6, "cdate": 1542981595464, "ddate": null, "tcdate": 1542981595464, "tmdate": 1542981935231, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Our revised paper has been uploaded.", "comment": "We would like to thank all the reviewers for their fruitful comments and suggestions that help make our paper more complete and comprehensive. \nWe have uploaded a newly revised paper reflecting almost all the comments, concerns and suggestions. \nWe mainly focused on revising the Introduction and Conclusion sections to make the manuscript more comprehensible to general audiences by clarifying the motivation of our work and by describing the potential applications of our work. \nIn addition, we conducted subjective listening tests and demonstrated that the proposed approach yields superior performance qualitatively.\nIf there are any further recommendations for the revised paper, we would like to reflect those until the due date."}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "SygPU_KB0Q", "original": null, "number": 7, "cdate": 1542981711067, "ddate": null, "tcdate": 1542981711067, "tmdate": 1542981711067, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "rylC1oN4p7", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Response to Reviewer 3 regarding the mask performance.", "comment": "Reflecting the concern by the Reviewer 3, we conducted further experiments by implementing the \u2018tanh compression\u2019 mask.\nAs expected, our method gave better performance by every quantitative measure.\n\n                                    CSIG      CBAK    COVL    PESQ    SSNR\nBDT (ours)                 4.18        3.77      3.63       3.06     13.29\nTanhCompression    4.11       3.33      3.56       3.01       7.01"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "Hke4DDVN6m", "original": null, "number": 1, "cdate": 1541846875543, "ddate": null, "tcdate": 1541846875543, "tmdate": 1541856217033, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SyxRGSbR37", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Response to Reviewer#1", "comment": "Thank you for your review.\n\nBelow are the responses to each of your concerns.\n\nThe methodological contribution is mild, essentially changing a building block in a state-of-the-art neural architecture.\n-> Answer:\nWe agree that the change of building block (DCUNet) itself might be considered as a mild contribution with respect to methodological points. However, in addition to the modification, our main contributions include a novel masking approach and an advanced loss function design. We believe it is not trivial to successfully incorporate these components, as this results in remarkable performance improvement from the previously proposed methods. Furthermore, as far as we are concerned, this is the first work that enables efficient phase estimation using continuous regression with a complex-valued method.\n\n\nThe paper is for the expert audience mostly and is difficult to grasp without a good background on deep learning for speech enhancement.\n-> Answer:\nThank you for pointing this out. As most of the general audience may have less understanding about speech signal modeling, we added additional explanations to the Introduction we consider fundamental for a wider range of audience."}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "rylC1oN4p7", "original": null, "number": 3, "cdate": 1541847781837, "ddate": null, "tcdate": 1541847781837, "tmdate": 1541855938343, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "S1lX3gYqhm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Response to Reviewer#3", "comment": "Thank you for your review and comments.\n\nBelow are the responses to each of your comments.\n\nFor me, the complex-valued network is already there and weighted SDR loss is not difficult to think. The modified complex ratio mask is a bit interesting. However, I think it better to compare with [Donald S Williamson et al] where the hyperbolic tangent compression is used.\n-> Answer:\nThank you for your suggestion. In fact, we tried this before. Since the perceptual quality of hyperbolic tangent compression was not good compared to the other masking methods, we did not add the results in our manuscript. However, as you suggested, we think it is fair to have the actual quantitative results to compare, and thus we are currently retraining the network using hyperbolic tangent compression and will report the result as soon as the training finishes.\n\n\nApart from the objective metrics, a human listening test using MOS or preference score should be conducted.\n-> Answer:\nThank you for your suggestion. We will conduct a user listening study with random samples from the test dataset and update the manuscript by adding the results as soon as possible.\n\n\nOn Fig 3, the unbounded complex mask might suffer from the infinity problem leading to training failure. However, on table 2, the performance of the unbounded mask is quite close to your method. It is a bit strange for me.\n-> Answer:\nAlthough it may seem to theoretically suffer from the infinite search space, the real distribution of the ideal complex masks are most likely bounded to a small finite region, which is likely to help alleviate the problem. In our case, we had no such problems when training our models."}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "rklUSYVEpX", "original": null, "number": 2, "cdate": 1541847358047, "ddate": null, "tcdate": 1541847358047, "tmdate": 1541855695281, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "HylyWCnnnm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "content": {"title": "Response to Reviewer#2", "comment": "We thank the reviewer for the extensive comments, which were very constructive and helpful for building a better paper.\n\nBelow are the responses to each of your comments.\n\nMy major concern about this paper is that this paper is a little bit too specific to the speech enhancement applications, which will not be accepted with so many researches in the major ICLR community. My suggestion is to describe some potential applications of this method to the other (speech) applications including speech separation, noise-robust front-end for ASR, TTS, or other speech analysis, and also discuss the possibility of extending this method for multichannel input. \n-> Answer:\nThank you for your suggestion. We will add more explanations on potential applications and describe speech enhancement as a fundamental problem for general audio tasks.\n\n\nI\u2019m more interested in the multichannel enhancement because the phase (difference) is critical in this scenario. \n-> Answer:\nWe acknowledge the importance of such scenarios and also are interested in studying the case. We will add a discussion in the future work.\n\n\n- Introduction: It\u2019s better to cite and discuss the paper of \u201cE. Hakan et al, \u201cPhase-sensitive and recognition-boosted speech separation using deep recurrent neural networks,\u201d Proc. ICASSP\u201915, pp. 708--712 (2015). This paper is one of the first studies tries to incorporate the phase information to DNN based speech enhancement.\n-> Answer:\nThank you for the suggestion. We will add sentences to the Introduction as one of the initial dnn-based approaches incorporating phase information.\n\n\n- Several researchers prefer to use LSTM based enhancement method. Please discuss whether this method (objective function and complex masks) can be applied to complex extensions of LSTMs instead of complex U-net.\n-> Answer:\nThank you for your idea for extension. As you mentioned, our objective function and complex masking method can be applied to complex-valued LSTMs, which will be expected to be effective for sequential representation learning and potentially improve the performance. We will add this discussion to the Conclusion.\n\n\n- Page 2, the first paragraph: You may also refer https://arxiv.org/abs/1810.01395\n-> Answer:\nThank you for notifying us, but we were not aware of this paper since the deadline was the end of September. As it is very relevant in terms of phase estimation, we will refer to this work in the paper.\n\n\n- Page 3, it\u2019s better to explicitly mention that h = x + i y\n-> Answer:\nWe will fix this in the updated version soon.\n\n\n- Section 3.3: discuss how we treat STFT/iSTFT operations under a computational graph representation. It is not so obvious.\n-> Answer:\nWe will add the description in Section 3.3.\n\n\n- Section 3.3: again it\u2019s better to mention E. Hakan\u2019s method here.\n-> Answer:\nWe will refer to the E. Haken\u2019s method in Section 3.2 as it is more related to the masking method.\n\n\n- Page 6 footnote: I cannot access to the URL. Please check it.\n-> Answer:\nWe think the URL doesn\u2019t work because the underbars have been removed from from the hyperlink. We will fix this.\n\n- Experiments: I think it would be more interesting to add SDR (using speech and noise as a source) to the experimental measure. Some people use SDR as a speech enhancement measure, and I\u2019m expecting that this method can have more reasonable performance since it is optimized based on wSDR.\n-> Answer:\nFor quick comparison, we evaluated SDR for DCUnet-20 with the BDT mask setting, and obtained the following results:\n\t       Spc      Wav     wSDR\nSDR      23.17 | 23.99 | 24.16\nSSNR     9.54  | 12.34 | 13.29 \nAs expected, wSDR yielded the best performance among the three loss terms compared in the paper.\nHowever, we would like to note that SDR is essentially scale-invariant SNR, and since wSDR loss tries to fit the scale of the target source, it leads to maximizing SNR (not scale-invariant) more than maximizing SDR. This can be confirmed by the fact that more dramatic improvement is observed in terms of SSNR rather than SDR.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621614946, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkeRTsAcYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper850/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper850/Authors|ICLR.cc/2019/Conference/Paper850/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers", "ICLR.cc/2019/Conference/Paper850/Authors", "ICLR.cc/2019/Conference/Paper850/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621614946}}}, {"id": "SyxRGSbR37", "original": null, "number": 3, "cdate": 1541440789865, "ddate": null, "tcdate": 1541440789865, "tmdate": 1541533638673, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "content": {"title": "well written & rather experimental paper -- for the experts mostly", "review": "The paper is written, provides good description of the state-of-the-art and comprehensive experimental results.\nThe methological contribution is mild, essentially changing a buiding block in a state-of-the-art neural architecture.\nThe paper is for the expert audience mostly and is difficult to grasp without a good background on deep learning for speech enhancement.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "cdate": 1542234362843, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335816483, "tmdate": 1552335816483, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HylyWCnnnm", "original": null, "number": 2, "cdate": 1541357047506, "ddate": null, "tcdate": 1541357047506, "tmdate": 1541533638460, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "content": {"title": "review of \"Phase-Aware Speech Enhancement with Deep Complex U-Net\"", "review": "This paper tackles one of important speech enhancement issues of how to predict phase information. The authors work on this problem based on three novel techniques, one is to use complex U-net, second is to propose a new complex mask representation, which is well bounded and well model complex mask distribution, and the last is an objective function motivated by SDR. The paper is well written, and also shows the experimental effectiveness of the proposed method by analyzing these three novel techniques and also by comparing the method with other speech enhancement methods. My major concern about this paper is that this paper is a little bit too specific to the speech enhancement applications, which will not be accepted with so many researches in the major ICLR community. My suggestion is to describe some potential applications of this method to the other (speech) applications including speech separation, noise-robust front-end for ASR, TTS, or other speech analysis, and also discuss the possibility of extending this method for multichannel input. I\u2019m more interested in the multichannel enhancement because the phase (difference) is critical in this scenario. \n\nComments:\n- Introduction: It\u2019s better to cite and discuss the paper of \u201cE. Hakan et al, \u201cPhase-sensitive and recognition-boosted speech separation using deep recurrent neural networks,\u201d Proc. ICASSP\u201915, pp. 708--712 (2015). This paper is one of the first studies tries to incorporate the phase information to DNN based speech enhancement.\n- Several researchers prefer to use LSTM based enhancement method. Please discuss wether this method (objective function and complex masks) can be applied to complex extensions of LSTMs instead of complex U-net.\n- Page 2, the first paragraph: You may also refer https://arxiv.org/abs/1810.01395\n- Page 3, it\u2019s better to explicitly mention that h = x + i y\n- Section 3.3: discuss how we treat STFT/iSTFT operations under a computational graph representation. It is not so obvious.\n- Section 3.3: again it\u2019s better to mention E. Hakan\u2019s method here.\n- Page 6 footnote: I cannot access to the URL. Please check it.\n- Experiments: I think it would be more interesting to add SDR (using speech and noise as a source) to the experimental measure. Some people use SDR as a speech enhancement measure, and I\u2019m expecting that this method can have more reasonable performance since it is optimized based on wSDR.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "cdate": 1542234362843, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335816483, "tmdate": 1552335816483, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1lX3gYqhm", "original": null, "number": 1, "cdate": 1541210283377, "ddate": null, "tcdate": 1541210283377, "tmdate": 1541533638256, "tddate": null, "forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "invitation": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "content": {"title": "generally good paper on speech enhancement using complex operations", "review": "This paper used a complex-valued network to learn the modified complex ratio mask with a weighted SDR loss for the speech enhancement task. It can get good enhancement performance.\n\nFor me, the complex-valued network is already there and weighted SDR loss is not difficult to think. The modified complex ratio mask is a bit interesting. However, I think it better to compare with [Donald S Williamson et al] where the hyperbolic tangent compression is used.\n\nApart from the objective metrics, a human listening test using MOS or preference score should be conducted.\n\nOn Fig 3, the unbounded complex mask might suffer from the infinity problem leading to training failure. However, on table 2, the performance of the unbounded mask is quite close to your method. It is a bit strange for me.\n\nThe total idea is good, but the novelty is not much.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper850/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Phase-Aware Speech Enhancement with Deep Complex U-Net", "abstract": "Most deep learning-based models for speech enhancement have mainly focused on estimating the magnitude of spectrogram while reusing the phase from noisy speech for reconstruction. This is due to the difficulty of estimating the phase of clean speech. To improve speech enhancement performance, we tackle the phase estimation problem in three ways. First, we propose Deep Complex U-Net, an advanced U-Net structured model incorporating well-defined complex-valued building blocks to deal with complex-valued spectrograms. Second, we propose a polar coordinate-wise complex-valued masking method to reflect the distribution of complex ideal ratio masks. Third, we define a novel loss function, weighted source-to-distortion ratio (wSDR) loss, which is designed to directly correlate with a quantitative evaluation measure. Our model was evaluated on a mixture of the Voice Bank corpus and DEMAND database, which has been widely used by many deep learning models for speech enhancement. Ablation experiments were conducted on the mixed dataset showing that all three proposed approaches are empirically valid. Experimental results show that the proposed method achieves state-of-the-art performance in all metrics, outperforming previous approaches by a large margin.", "keywords": ["speech enhancement", "deep learning", "complex neural networks", "phase estimation"], "authorids": ["kekepa15@snu.ac.kr", "blue378@snu.ac.kr", "jaesung.huh@navercorp.com", "adrian.kim@navercorp.com", "jungwoo.ha@navercorp.com", "kglee@snu.ac.kr"], "authors": ["Hyeong-Seok Choi", "Jang-Hyun Kim", "Jaesung Huh", "Adrian Kim", "Jung-Woo Ha", "Kyogu Lee"], "TL;DR": "This paper proposes a novel complex masking method for speech enhancement along with a loss function for efficient phase estimation.", "pdf": "/pdf/1037a035894c085a0b8f9aaa69c8ddec2f2a2587.pdf", "paperhash": "choi|phaseaware_speech_enhancement_with_deep_complex_unet", "_bibtex": "@inproceedings{\nchoi2018phaseaware,\ntitle={Phase-Aware Speech Enhancement with Deep Complex U-Net},\nauthor={Hyeong-Seok Choi and Janghyun Kim and Jaesung Huh and Adrian Kim and Jung-Woo Ha and Kyogu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkeRTsAcYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper850/Official_Review", "cdate": 1542234362843, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkeRTsAcYm", "replyto": "SkeRTsAcYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper850/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335816483, "tmdate": 1552335816483, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper850/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}