{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124443597, "tcdate": 1518472412537, "number": 322, "cdate": 1518472412537, "id": "rkN1pF1vz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rkN1pF1vz", "signatures": ["~KiJung_Yoon1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Inference in probabilistic graphical models by Graph Neural Networks", "abstract": "A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.", "paperhash": "yoon|inference_in_probabilistic_graphical_models_by_graph_neural_networks", "keywords": ["Inference", "Probabilistic graphical models", "Graph neural networks"], "_bibtex": "@misc{\n  yoon2018inference,\n  title={Inference in probabilistic graphical models by Graph Neural Networks},\n  author={KiJung Yoon and Renjie Liao and Yuwen Xiong and Lisa Zhang and Ethan Fetaya and Raquel Urtasun and Richard Zemel and Xaq Pitkow},\n  year={2018},\n  url={https://openreview.net/forum?id=rkN1pF1vz}\n}", "authorids": ["kijung.yoon@rice.edu", "rjliao@cs.toronto.edu", "yuwen@cs.toronto.edu", "lczhang@cs.toronto.edu", "ethanf@cs.toronto.edu", "urtasun@cs.toronto.edu", "zemel@cs.toronto.edu", "xaq@rice.edu"], "authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "TL;DR": "We use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves inference tasks in probabilistic graphical models.", "pdf": "/pdf/1482a61ded7c3d4b3c1a24bcf0795915fb216b65.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582926555, "tcdate": 1520359057628, "number": 1, "cdate": 1520359057628, "id": "SkccI82uM", "invitation": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer3"], "content": {"title": "Ineresting new approach to inference in graphical models", "rating": "7: Good paper, accept", "review": "This paper proposes using Graph Neural Networks, originally proposed for other applications such as classification on molecular structures, to do inference in pairwise probabilistic graphical models. The setup is fairly straightforward, and really all you need to know to be able to replicate this is the preceding sentence. That said, the experiments are interesting. As expected, anything other than belief propagation does worse than belief propagation on chain and tree graphs; however, on more complex graph structures the graph neural networks seem to be better than BP at predicting node marginals by the metric used (a calibration plot of predicted vs actual marginal probability for each algorithm for each node in a graph for many different potentials). It's also mildly surprising that out of the two versions the paper explored (one with per-factor messages similar to BP and one with simpler per-node messages) the simpler version outperformed the complex one. Specially for max-product inference, for which loopy belief propagation is really bad, this might be useful.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inference in probabilistic graphical models by Graph Neural Networks", "abstract": "A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.", "paperhash": "yoon|inference_in_probabilistic_graphical_models_by_graph_neural_networks", "keywords": ["Inference", "Probabilistic graphical models", "Graph neural networks"], "_bibtex": "@misc{\n  yoon2018inference,\n  title={Inference in probabilistic graphical models by Graph Neural Networks},\n  author={KiJung Yoon and Renjie Liao and Yuwen Xiong and Lisa Zhang and Ethan Fetaya and Raquel Urtasun and Richard Zemel and Xaq Pitkow},\n  year={2018},\n  url={https://openreview.net/forum?id=rkN1pF1vz}\n}", "authorids": ["kijung.yoon@rice.edu", "rjliao@cs.toronto.edu", "yuwen@cs.toronto.edu", "lczhang@cs.toronto.edu", "ethanf@cs.toronto.edu", "urtasun@cs.toronto.edu", "zemel@cs.toronto.edu", "xaq@rice.edu"], "authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "TL;DR": "We use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves inference tasks in probabilistic graphical models.", "pdf": "/pdf/1482a61ded7c3d4b3c1a24bcf0795915fb216b65.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582926324, "id": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper322/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer2"], "reply": {"forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582926324}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582743601, "tcdate": 1520660156813, "number": 2, "cdate": 1520660156813, "id": "BySpRk-tG", "invitation": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer1"], "content": {"title": "Approach for approximate inference in graphical models using Graph Neural Nets", "rating": "7: Good paper, accept", "review": "The paper describes an approach to perform inference in graphical models using Graph Neural nets. Specifically, the factor graph in loopy belief propagation is encoded as a graph neural net using 2 encodings, i) encoding variables in the factor graph and ii) encoding messages. \n\nPros\ni) Seems like a nice direction given that gains in approximate inference is highly significant for PGMs\nii) Given the space constraints, has a reasonable evaluation\nCons\ni) Complexity of training is not mentioned. For e.g. does BP converge much faster than the proposed GNN method", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inference in probabilistic graphical models by Graph Neural Networks", "abstract": "A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.", "paperhash": "yoon|inference_in_probabilistic_graphical_models_by_graph_neural_networks", "keywords": ["Inference", "Probabilistic graphical models", "Graph neural networks"], "_bibtex": "@misc{\n  yoon2018inference,\n  title={Inference in probabilistic graphical models by Graph Neural Networks},\n  author={KiJung Yoon and Renjie Liao and Yuwen Xiong and Lisa Zhang and Ethan Fetaya and Raquel Urtasun and Richard Zemel and Xaq Pitkow},\n  year={2018},\n  url={https://openreview.net/forum?id=rkN1pF1vz}\n}", "authorids": ["kijung.yoon@rice.edu", "rjliao@cs.toronto.edu", "yuwen@cs.toronto.edu", "lczhang@cs.toronto.edu", "ethanf@cs.toronto.edu", "urtasun@cs.toronto.edu", "zemel@cs.toronto.edu", "xaq@rice.edu"], "authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "TL;DR": "We use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves inference tasks in probabilistic graphical models.", "pdf": "/pdf/1482a61ded7c3d4b3c1a24bcf0795915fb216b65.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582926324, "id": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper322/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer2"], "reply": {"forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582926324}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582679001, "tcdate": 1520732210804, "number": 3, "cdate": 1520732210804, "id": "SkjVdbGtf", "invitation": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer2"], "content": {"title": "GNNs for marginal inference", "rating": "7: Good paper, accept", "review": "The authors propose a method using GNNs for learning to perform marginal inference in graphical models.  The GNN is trained on different graph structures with fixed types of potentials, and the learned models are evaluated on how well the generalize to larger graphs or different potentials versus the belief propagation algorithm for approximate inference.  The results look promising and appear to be novel.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inference in probabilistic graphical models by Graph Neural Networks", "abstract": "A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.", "paperhash": "yoon|inference_in_probabilistic_graphical_models_by_graph_neural_networks", "keywords": ["Inference", "Probabilistic graphical models", "Graph neural networks"], "_bibtex": "@misc{\n  yoon2018inference,\n  title={Inference in probabilistic graphical models by Graph Neural Networks},\n  author={KiJung Yoon and Renjie Liao and Yuwen Xiong and Lisa Zhang and Ethan Fetaya and Raquel Urtasun and Richard Zemel and Xaq Pitkow},\n  year={2018},\n  url={https://openreview.net/forum?id=rkN1pF1vz}\n}", "authorids": ["kijung.yoon@rice.edu", "rjliao@cs.toronto.edu", "yuwen@cs.toronto.edu", "lczhang@cs.toronto.edu", "ethanf@cs.toronto.edu", "urtasun@cs.toronto.edu", "zemel@cs.toronto.edu", "xaq@rice.edu"], "authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "TL;DR": "We use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves inference tasks in probabilistic graphical models.", "pdf": "/pdf/1482a61ded7c3d4b3c1a24bcf0795915fb216b65.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582926324, "id": "ICLR.cc/2018/Workshop/-/Paper322/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper322/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper322/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper322/AnonReviewer2"], "reply": {"forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper322/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582926324}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573554530, "tcdate": 1521573554530, "number": 50, "cdate": 1521573554190, "id": "S1i3A00Ff", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rkN1pF1vz", "replyto": "rkN1pF1vz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inference in probabilistic graphical models by Graph Neural Networks", "abstract": "A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.", "paperhash": "yoon|inference_in_probabilistic_graphical_models_by_graph_neural_networks", "keywords": ["Inference", "Probabilistic graphical models", "Graph neural networks"], "_bibtex": "@misc{\n  yoon2018inference,\n  title={Inference in probabilistic graphical models by Graph Neural Networks},\n  author={KiJung Yoon and Renjie Liao and Yuwen Xiong and Lisa Zhang and Ethan Fetaya and Raquel Urtasun and Richard Zemel and Xaq Pitkow},\n  year={2018},\n  url={https://openreview.net/forum?id=rkN1pF1vz}\n}", "authorids": ["kijung.yoon@rice.edu", "rjliao@cs.toronto.edu", "yuwen@cs.toronto.edu", "lczhang@cs.toronto.edu", "ethanf@cs.toronto.edu", "urtasun@cs.toronto.edu", "zemel@cs.toronto.edu", "xaq@rice.edu"], "authors": ["KiJung Yoon", "Renjie Liao", "Yuwen Xiong", "Lisa Zhang", "Ethan Fetaya", "Raquel Urtasun", "Richard Zemel", "Xaq Pitkow"], "TL;DR": "We use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves inference tasks in probabilistic graphical models.", "pdf": "/pdf/1482a61ded7c3d4b3c1a24bcf0795915fb216b65.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}