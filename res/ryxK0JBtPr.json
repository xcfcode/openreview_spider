{"notes": [{"id": "ryxK0JBtPr", "original": "BkggnvytDB", "number": 2033, "cdate": 1569439697289, "ddate": null, "tcdate": 1569439697289, "tmdate": 1583912053306, "tddate": null, "forum": "ryxK0JBtPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "D6996H75Y", "original": null, "number": 1, "cdate": 1576798738783, "ddate": null, "tcdate": 1576798738783, "tmdate": 1576800897572, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "Reviewers uniformly suggest acceptance. Please take their comments into account in the camera-ready. Congratulations!", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795720845, "tmdate": 1576800271754, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Decision"}}}, {"id": "r1eFtky0tr", "original": null, "number": 2, "cdate": 1571839872714, "ddate": null, "tcdate": 1571839872714, "tmdate": 1574434047119, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "This paper models the quantization errors of weights and activations as additive l_inf bounded perturbations and uses first-order approximation of loss function to derive a gradient norm penalty regularization that encourage the network's robustness to any bit-width quantization. The authors claim that this method is better than previous quantization-aware methods because those methods are dedicated to one specific quantization configuration.\n\nThe derivation of the proposed method is not complex but I like the idea that models quantization error as additive perturbation in this context and how it eventually connects with gradient penalty that's widely used in GAN training and adversarial robustness.\n\nQuestions:\n\n1. What is the capital N in the time complexity of gradient computation in Sec. 4.1? The authors should discuss in details the time complexity of the proposed regularization well because this is an essential problem of the regularization, which involves double back-propagation and should be computationally heavy. For the same reason, I'd like to see the training time comparison, and more results with deeper networks.\n\n2. Compared to STE, one of the quantization-aware methods, the proposed method is not very competitive even in the setting when a STE network, which is specially trained for 6,6 bits but quantized to 4,4 bits, can outperforms the proposed method. This contradicts with the claimed strength of the proposed method. Will it be better when we regularize more, if we want the model to perform well when quantized to 4,4 bits? It would be better if there is a set of experiments of different regularization hyperparameters.\n\n***********************\n\nUpdate: I'd like to keep my score after reading the authors' response to all reviewers. I think the authors do address some questions but the paper still has some weakness in terms of performance.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576560804381, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Reviewers"], "noninvitees": [], "tcdate": 1570237728732, "tmdate": 1576560804397, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review"}}}, {"id": "r1gvs0imcr", "original": null, "number": 3, "cdate": 1572220575014, "ddate": null, "tcdate": 1572220575014, "tmdate": 1574279348925, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper shows that if we add L1 regularization on gradient in the training phase, the obtained model can achieve better post-training quantization performance since it is more robust to Linf perturbation on the weights. I like the intuition of the paper but there are several weaknesses: \n\n1. The main concern is that the proposed method cannot outperform quantization-aware fine-tuning. This probably limits the application of the method --- it will only be used when there's not enough time budget for quantization-aware fine tuning for each specific choice of #bits. It will be good if the authors can discuss in what practical scenario their algorithm can be applied. \n\n2. The method is only tested under uniform symmetric quantization. I believe to demonstrate that the L1 regularized models are indeed easier to be quantized, we need to test it on several different kinds of quantizations. \n\n3. I have concerns about the hyper-parameter selection for lambda. The authors mentioned that lambda is chosen by grid-search, but what's the grid search criteria? In other words, are the hyper-parameters trying to minimize the validation error of the \"unquantized model\", or they are minimizing the validation error of the \"post-quantized model\"? \n\n4. Some minor suggestions: \n\n- The current paper uses boldfaced n as perturbation which is quite confusing (since small n is the dimension). I would suggest to replace it by something else, e.g, \\Delta. \n\n- Section 2.3 seems redundant. It's clearly that L1 regularization is better given it's the dual norm of Linf, so clearly it's better than L2 norm. You have proved L2 is not good anyway in experiments. \n\n===========\n\nAfter seeing the rebuttal, my concerns about the parameters have been well addressed. Also, I agree with the authors that there are use cases for post quantization, and personally I think post quantization is much easier to do in practice than quantization-aware training. However, this is quite subjective so the fact that the proposed method doesn't outperform quantization-aware training is still a weakness of the paper. \n\nI would like to slightly raise the score to borderline/weak-accept. I hope the authors can have some experiments on non-uniform quantization if the paper is being accepted; I really think that will demonstrate the strength of the method. People will likely to use this method if it can consistently improve many different kinds of post quantization. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576560804381, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Reviewers"], "noninvitees": [], "tcdate": 1570237728732, "tmdate": 1576560804397, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review"}}}, {"id": "r1evGIc2jr", "original": null, "number": 4, "cdate": 1573852686966, "ddate": null, "tcdate": 1573852686966, "tmdate": 1573852686966, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "r1eFtky0tr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment", "content": {"title": "Follow-up Response to Review #3", "comment": "Given the reviewer's comment on deeper models we have started experimenting with MobileNet-v2 on ImageNet as well. While not necessarily a deeper architecture, MobileNet has a more demanding backward path and could be a good test for our proposed regularization. Our initial experiments do show promising results of 50.2% top-1 accuracy in the (8-bit weights, 4-bit activations) configuration as opposed to 0.07% for vanilla post-training quantization, and 59% for fine-tuning using STE. However, given that MobileNet architecture is very sensitive to choices such as per-channel quantization vs. per-layer quantization, and BatchNorm folding, we would like to run more extensive tests before including results in the final revision."}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxK0JBtPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2033/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2033/Authors|ICLR.cc/2020/Conference/Paper2033/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147294, "tmdate": 1576860553374, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment"}}}, {"id": "r1lcj_tDor", "original": null, "number": 3, "cdate": 1573521569791, "ddate": null, "tcdate": 1573521569791, "tmdate": 1573663819575, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "r1eFtky0tr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment", "content": {"title": "Response to Review #3", "comment": "We would like to thank the reviewer for the constructive comments.\n\nYour question about capital N is fair. N, in this case, is (roughly) the number of elements w.r.t. which we are computing the gradient (e.g. weights in the case of regular backprop). The point we were trying to make is that, while this is a second-order method, we do not need to compute the full Hessian w.r.t. the weights, which would have O(N^2) time and space complexity in the number of weights.\n\nTo be more exact: auto-differentiation [1] of a function  \"f:  R^n --> R^m\", where \"f\" contains \"E\" elementary operations, requires O(m x C x E) time, where \"C\" is a fixed constant. The gradient_L1 penalty is a function \"p: R^N --> R\", where N is the number of elements in the gradient. This function contains O(N) elementary operations to compute the L1 norm. The function to compute the loss gradient contains O(N) elementary operations as well, one for every node in the original forward computation graph. Thus, from the formula above, the complexity of computing the gradient w.r.t. the gradient L1 norm is O(2xCxN). Since 2xC is a constant that does not depend on the input, the complexity is O(N). We have updated the paper (Section 4.1) to make all of this clearer and provide more details on the complexity of the algorithm.\n\nWe have also added the new \"Appendix E\" to provide justification for enabling the regularization only in the final stages of the training. The appendix depicts the progression of the regularization objective in unregularized networks. We show that the regularization loss becomes smaller (up to a point) during training with no regularization and therefore we can apply the regularization when the regularization loss has plateaued and is oscillating. We have also added wall-time timing measurements of the overhead in Section 4.1of the draft.\n\nWith regards to performance at (4,4) bits and comparison to STE you are absolutely right that this is related to the strength of the regularization. As we discuss in our reply to Review #1 our main criteria for choosing lambda was maintaining the accuracy of the unquantized model. We have now run more experiments with larger values for lambda and that indeed results in improved performance in the (4,4) case, albeit at the cost of overall lower accuracy across all bit-width configurations. We have updated the paper to include this result (Table 2, Section 4.2).\n\n[1] Atilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. \"Automatic differentiation in machine learning: a survey.\", Journal of machine learning research"}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxK0JBtPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2033/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2033/Authors|ICLR.cc/2020/Conference/Paper2033/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147294, "tmdate": 1576860553374, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment"}}}, {"id": "SJgXpIKwsB", "original": null, "number": 2, "cdate": 1573521082868, "ddate": null, "tcdate": 1573521082868, "tmdate": 1573521082868, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "r1gvs0imcr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment", "content": {"title": "Response to Review #1", "comment": "We would like to thank the reviewer for the careful review and useful comments.\n\nRegarding the comparison to quantization-aware training, we would like to emphasize that our proposed method is not meant to serve as a direct substitute for quantization aware fine-tuning. As the reviewer rightly pointed out quantization-aware training/fine-tuning can often achieve better results for the specific target bit-width. Having said that, we believe there are interesting practical applications where quantization-robust models are more appropriate. For example, we can consider the task of using a neural network as part of a mobile application. In such cases, one might be interested in automatically constraining the computational complexity of the network such that it conforms to specific battery consumption requirements, e.g. using a 4-bit variant when the battery is less than 20\\% but the full precision model when the battery is over 80\\%. In these cases, we can quantize to a specific bit-width on-the-fly without worrying about fine-tuning and without having to store multiple (potentially large) quantized models on device. Another challenge with post-training fine-tuning of models is access to the training data which can be challenging in some scenarios e.g. due to GDPR regularizations. We have uploaded an updated version of the paper to clarify such potential use-cases and applications.\n\nRegarding quantization schemes other than uniform symmetric quantization, it should be noted that our proposed method works equally well for asymmetric quantization schemes. Our theoretical derivations hold as long as the quantization noise has bounded support, even if it is not uniformly distributed. We have revised our text in Section 2.3 and the supplementary materials to reflect this issue. We have also moved some of the discussion in Section 2.3 to the supplementary materials as suggested by the reviewer. Non-uniform quantization schemes are currently less hardware-friendly and have limited applicability. Therefore, the focus of our research has been on uniform quantization schemes. We have updated Appendix A to discuss non-uniform cases. Our analysis holds for certain situations in which non-uniform quantization is used. However, a general answer to these questions will require more research and is left for future work.\n\nThe reviewer's comment on the hyper-parameter selection is a fair point and should have been made clearer in the paper. Our criteria for choosing $\\lambda$ was: the highest value of $\\lambda$ within our search space that does not affect the accuracy of the \\emph{unquantized} model, i.e. we did not want regularization to cause any degradation in the accuracy of the model in the normal mode, while maximally regularizing the model. We did not do any quantization for validation or hyper-parameter tuning. Furthermore, as discussed in Section 4.1 we only apply regularization in the final stages of the training (we have now updated the paper with the new Appendix E to include evidence and justification for this), however, we do track the regularization term during the training. This enabled us to have a rough estimate of the scale of regularization term with respect to the cross-entropy term. We then performed the grid search over a few points above and below the scale value that would bring regularization term to the same level as the cross-entropy. We have now updated Section 4.1 to make this clearer.\n\nLastly, since the initial submission of the paper, we have been running more experiments with different values of lambda. One motivation for these experiments was to see if we can recover the (4,4) performance in ResNet-18 on ImageNet. We have updated the Table 2 to include this additional result for the same architecture but with larger lambda. It shows that larger values for lambda do indeed allow much better performance at (4,4) but at the cost of overall accuracy degradation across all quantization targets.\n\nRe. the notation: This is a good suggestion. Our updated draft uses adapts the suggestion notation.\n\nRe. the redundant section: We have incorporated your comment by moving most of Section 2.3 into an appendix."}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxK0JBtPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2033/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2033/Authors|ICLR.cc/2020/Conference/Paper2033/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147294, "tmdate": 1576860553374, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment"}}}, {"id": "ryxSorYvjH", "original": null, "number": 1, "cdate": 1573520796575, "ddate": null, "tcdate": 1573520796575, "tmdate": 1573520796575, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "HyxmIYPEYH", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment", "content": {"title": "Response to Review #2", "comment": "We would like to thank the reviewer for the encouraging words and comments. \n\nWhile sparsity of the gradients is not something that we explicitly target, it is indeed a by-product of the objective. Intuitively our regularization imposes a constraint on the model that encourages it to be insensitive to bounded perturbations, in the first order sense. It should be noted that we recover weight sparsity when we adopt a linear model, as the L1 norm of the gradient is equivalent to the L1 norm of the weights."}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxK0JBtPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2033/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2033/Authors|ICLR.cc/2020/Conference/Paper2033/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147294, "tmdate": 1576860553374, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Authors", "ICLR.cc/2020/Conference/Paper2033/Reviewers", "ICLR.cc/2020/Conference/Paper2033/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Comment"}}}, {"id": "HyxmIYPEYH", "original": null, "number": 1, "cdate": 1571219787185, "ddate": null, "tcdate": 1571219787185, "tmdate": 1572972391913, "tddate": null, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "invitation": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "Summary: the authors propose a regularization scheme that is applied during regular training to ease the pose-training quantization of a network. Modeling the quantization noise as an additive perturbation bounded in \\ell_\\inf norm, they bound from above the first-order term of the perturbations applied to the network by the \\ell_1 norm of the gradients. Their claims are also supported by experiments and qualitative illustrations.\n\nStrengths of the paper:\n- The paper is clearly written and easy to follow. In particular, section 2.1 clearly motivates the formulation of the regularization term from a theoretical point of view (reminiscent of the formulation of adversarial examples) and Figures 1 and 2 motivate the regularization term from a practical point of view. I found Figure 5 particularly enlightening (the regularization term \"expands\" the decision cells). \n- The method is clearly positioned with respect to previous work (in particular using \\ell_2 regularization of the gradients) \n- Experiments demonstrate the effectiveness fo the method. \n\nWeaknesses of the paper:\n- The link between the proposed objective and the sparsity could be made clearer: does this objective enforce sparsity of the gradients, the weights, and how does this affect training?\n\n\nJustification of rating:\nThe paper clearly presents a regularization method to improve post-training quantization. The approach is motivated both from a theoretical point of view and from a practical point of view. The latter aspect is of particular interest for the community. The claims are validated by a limited set of experiments that are seem nonetheless well executed.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2033/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["milada@qti.qualcomm.com", "behboodi@qti.qualcomm.com", "mart@qti.qualcomm.com", "clouizos@qti.qualcomm.com", "tijmen@qti.qualcomm.com", "mwelling@qti.qualcomm.com"], "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": ["Milad Alizadeh", "Arash Behboodi", "Mart van Baalen", "Christos Louizos", "Tijmen Blankevoort", "Max Welling"], "pdf": "/pdf/d03bbe7b1da14a73044d4c4c991c83cdb3d7929e.pdf", "TL;DR": "We show that regularizing the $\\ell_1$-norm of gradients improves robustness to post-training quantization in neural networks.", "abstract": "We analyze the effect of quantizing weights and activations of neural networks on their loss and derive a simple regularization scheme that improves robustness against post-training quantization. By training quantization-ready networks, our approach enables storing a single set of weights that can be quantized on-demand to different bit-widths as energy and memory requirements of the application change. Unlike quantization-aware training using the straight-through estimator that only targets a specific bit-width and requires access to training data and pipeline, our regularization-based method paves the way for ``on the fly'' post-training quantization to various bit-widths. We show that by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the first-order term in the loss expansion can be regularized using the $\\ell_1$-norm of gradients. We experimentally validate our method on different vision architectures on CIFAR-10 and ImageNet datasets and show that the regularization of a neural network using our method improves robustness against quantization noise.", "keywords": ["quantization", "regularization", "robustness", "gradient regularization"], "paperhash": "alizadeh|gradient_\\ell_1_regularization_for_quantization_robustness", "_bibtex": "@inproceedings{\nAlizadeh2020Gradient,\ntitle={Gradient $\\ell_1$ Regularization for Quantization Robustness},\nauthor={Milad Alizadeh and Arash Behboodi and Mart van Baalen and Christos Louizos and Tijmen Blankevoort and Max Welling},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxK0JBtPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/36ae12ff4e99662d1c5ed3440e24c1e9517ad243.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxK0JBtPr", "replyto": "ryxK0JBtPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2033/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576560804381, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2033/Reviewers"], "noninvitees": [], "tcdate": 1570237728732, "tmdate": 1576560804397, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2033/-/Official_Review"}}}], "count": 9}