{"notes": [{"id": "HkgH0TEYwH", "original": "SkxfXYWdwH", "number": 854, "cdate": 1569439180900, "ddate": null, "tcdate": 1569439180900, "tmdate": 1583912040082, "tddate": null, "forum": "HkgH0TEYwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "T8O4Vdqhx1", "original": null, "number": 1, "cdate": 1576798707851, "ddate": null, "tcdate": 1576798707851, "tmdate": 1576800928498, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "Issues raised by the reviewers have been addressed by the authors, and thus I suggest the acceptance of this paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728336, "tmdate": 1576800280732, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper854/-/Decision"}}}, {"id": "SJlHdAKiiB", "original": null, "number": 4, "cdate": 1573785197495, "ddate": null, "tcdate": 1573785197495, "tmdate": 1573785197495, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "SJgDdz7xor", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment", "content": {"title": "Related Work", "comment": "Thank you very much for your comment. We will add your recent paper to our related work. Note that we do compare to semi-supervised anomaly detection methods such as (hybrid) SSAD in the paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper854/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkgH0TEYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper854/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper854/Authors|ICLR.cc/2020/Conference/Paper854/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165189, "tmdate": 1576860531231, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment"}}}, {"id": "SylNjaV9iS", "original": null, "number": 2, "cdate": 1573698971886, "ddate": null, "tcdate": 1573698971886, "tmdate": 1573718551089, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "B1xf_hzkqS", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment", "content": {"title": "Author Response to Review #1", "comment": "We understand your concerns with the \"information-theoretic view,\" nonetheless we think the framework should remain and is of interest to the ML community for a few reasons:\n\n- Previous theoretical work on anomaly detection [1,2] often assumed that the anomalous distribution is unconcentrated (analogously high-entropy or not clustered) and it is reasonable that this intuition would extend to deep anomaly detection. Our framework introduces and explores the idea of using a training objective to incorporate this assumption. This presents an avenue for future work. For example, in our paper we use high-variance as a proxy for distribution not being clustered. Can we find a better loss to enforce anomalies to be unclustered? Further future work could study the detection performance under the information-theoretic rate-distortion curve [3] or derive novel methods from using other non-parametric estimators for mutual information (e.g. [4]) based on our framework.\n\n- Other recent work on deep anomaly detection utilizing self-supervised classification have incorporated the use of anomalies during training in a similar way, albeit without theoretical justification [5]. In these methods normal samples are trained to minimize a classification loss. On the other hand anomalous samples are trained so that the softmax output distribution has high entropy, not for misclassification. This results in a network where the softmax output from normal samples are concentrated around at the corners of the probability simplex, and anomalous samples are diffusely spread around the center. Our information-theoretic framework offers a potential explanation for why such an objective is natural and connects it to our method.\n\n- The Gaussianity assumption for $Z$ used in Eq. (6) is merely a choice of convenience in order to obtain a simple derivation, but is not necessary to derive the claim that the entropy is minimized by minimizing the empirical variance. To see this, note that the upper bound in Eq. (5) is a log determinant of covariance $\\Sigma$, which is a sum of the log eigenvalues of $\\Sigma$. These eigenvalues are variances obtained by projecting the data on certain orthonormal basis vectors $r_e$. By Cauchy-Schwarz inequality, each of these projected variances $E[\\|  (Z \\cdot r_e-E[Z \\cdot r_e]) \\|^2]$ are upper bounded by the scalar variance $E[\\|  (Z-E[Z]) \\|^2]$ since $\\|r_e\\|=1$.\nWe will add a complete derivation of this claim to the appendix.\n\n- Reviewer 2 expressed interest in our framework, so we are reluctant to remove it completely.\n\nIn a final version of the paper we will elaborate on the connection to previous work, with a focus on future work. We will also de-emphasize this framework as a way to derive our method, treating it instead as a possible interpretation for why our loss is somewhat \"natural,\" e.g. why it makes sense to concentrate the nominal samples and let the anomalies be diffuse. We will also remove our \"cute sentence.\"\n\n\n[1] Steinwart, I., Hush, D., and Scovel, C. A Classification Framework for Anomaly Detection. Journal of Machine Learning Research, 6(Feb):211\u2013232, 2005.\n[2] Sch\u00f6lkopf, B. et al. Estimating the Support of a High-Dimensional Distribution. Neural computation, 13(7):1443\u20131471, 2001.\n[3] Alemi, A. et al. Fixing a broken ELBO. In ICML, volume 80, pages 159\u2013168, 2018.\n[4] Hjelm, R. D. et al. Learning Deep Representations by Mutual Information Estimation and Maximization. In ICLR, 2019.\n[5] Hendrycks, D. Mazeika, M., and Dietterich, T. G. Deep Anomaly Detection with Outlier Exposure. In ICLR, 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper854/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkgH0TEYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper854/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper854/Authors|ICLR.cc/2020/Conference/Paper854/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165189, "tmdate": 1576860531231, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment"}}}, {"id": "H1gldRN9jS", "original": null, "number": 3, "cdate": 1573699175586, "ddate": null, "tcdate": 1573699175586, "tmdate": 1573699175586, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "BylBYZcAFH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment", "content": {"title": "Author Response to Review #2", "comment": "We have performed experiments without pre-training as well as incorporating end-to-end autoencoder training. Our method consistently performs worse without pre-training. With an end-to-end autoencoder we achieve performance approximately as good as presented in this paper, provided one uses a training regimen which first emphasizes and then de-emphasizes the autoencoder loss, which is essentially pre-training. We will include these points in our final draft."}, "signatures": ["ICLR.cc/2020/Conference/Paper854/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkgH0TEYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper854/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper854/Authors|ICLR.cc/2020/Conference/Paper854/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165189, "tmdate": 1576860531231, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment"}}}, {"id": "ryg433VciB", "original": null, "number": 1, "cdate": 1573698731568, "ddate": null, "tcdate": 1573698731568, "tmdate": 1573699081093, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment", "content": {"title": "General Author Response", "comment": "We kindly thank the reviewers for taking the time to review our paper and are pleased that our work has been well received overall. The comments of reviewers 1 and 2 were particularly helpful. We found reviews reasonable and there are no particular points we feel need to be rebutted. Indeed the reviewers questions and concerns align with our own and we will incorporate their points into a final draft. We provide our answers to specific questions in individual comments."}, "signatures": ["ICLR.cc/2020/Conference/Paper854/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkgH0TEYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper854/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper854/Authors|ICLR.cc/2020/Conference/Paper854/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165189, "tmdate": 1576860531231, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Comment"}}}, {"id": "SJgDdz7xor", "original": null, "number": 1, "cdate": 1573036654597, "ddate": null, "tcdate": 1573036654597, "tmdate": 1573036654597, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Public_Comment", "content": {"title": "Nice work but closely related references are missing", "comment": "The problem of using a few labeled data , especially limited labeled anomalies, to enhance anomaly detection performance is very important, as such settings are common in real-world applications and we can definitely obtain much better performance than fully unsupervised methods when the labeled data leveraged properly. The authors extend the deep svdd method and provide comprehensive and interesting empirical results. Some main concerns I have are as follows: \n1. some closely related reference s are missing, especially studies on exploiting a small number of labeled anomalies to achieve deep anomaly detection, such as\n\"Deep Anomaly Detection with Deviation Networks\". In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 353-362), 2019. ACM. Actually, labeled normal data does not contribute much to the improved performance, as a large number of normal samples exists in the unlabeled data and can be well captured by the deep svdd term.  Thus, labeled anomaly data plays the critical role here.  The above KDD paper extensively examined this point, including the impact of increasing number of anomalies and increasing anomaly contamination rate.  I suggest the authors to have some discussion of the key differences between their work and those closely relevant work.  \n\n2. Also, currently the competing method list  does not contain semi-supervised anomaly detection methods, which seems to be incomplete.  Comparing to the method in the KDD paper may help well address this problem. "}, "signatures": ["~Guansong_Pang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guansong_Pang1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkgH0TEYwH", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504203221, "tmdate": 1576860564888, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper854/Authors", "ICLR.cc/2020/Conference/Paper854/Reviewers", "ICLR.cc/2020/Conference/Paper854/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper854/-/Public_Comment"}}}, {"id": "Byl7mCRpFr", "original": null, "number": 1, "cdate": 1571839515466, "ddate": null, "tcdate": 1571839515466, "tmdate": 1572972543882, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #854", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nSummary of the work\n- The work proposes a new method two find anomaly (out of distribution) data when some labeled anomalies are given. \n- The authors apply information theory-derived loss based on that the normal (in distribution) data usually have lower entropy compared to that of the abnormal data. \n- The paper conducts extensive experiments on MNIST, Fashion-MNIST, and CIFAR 10, with varying the number of labeled anomlies.\n\nI think the paper is well written and the experiment seems to support the authors argument. Unfortunately, this field is not overlapped to my research field, and it is hard for me to judge this paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574752325685, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper854/Reviewers"], "noninvitees": [], "tcdate": 1570237746020, "tmdate": 1574752325698, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Review"}}}, {"id": "BylBYZcAFH", "original": null, "number": 2, "cdate": 1571885436922, "ddate": null, "tcdate": 1571885436922, "tmdate": 1572972543837, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "[Summary]\nThe paper proposes an abnormal detection (AD) framework under general settings where 1) unlabeled data, 2) labeled positive (normal) data, and 3) labeled negative (abnormal) data are available (with the last two optional), denoted as semi-supervised AD. Starting from the assumption that abnormal data are sampled from background unpredicted distribution, rather than \u201ccluster\u201d assumption, it is argued that conventional discriminative formulation is not applicable. Motivated by the recent deep AD methods (e.g., deep SVDD), the paper proposes to approach semi-supervised AD from the information theoretic perspective where 1) mutual information between raw data and learnt representation should be maximized (infomax principle), 2) entropy of labeled positive data should be minimized (\u201ccompactness\u201d constraint), and 3) enrtropy of labeled negative data should be maximized to reflect the uncertainty assumption of anomaly. The solution is implemented by the encoder of a pre-trained autoencoder that is further fine tuned to enforce entropy assumption on all types of training data. Extensive experiments on benchmarks suggests promising results on the proposed framework versus other state-of-the-arts.\n\n[Comments]\nThe paper is well written and easy to follow (the presentation is especially pleasant to read). The problem is well defined and of interest to the community under fairly general and practical conditions. Despite the fact that the implementation is only marginally tweaked from previous work (deep SVDD), the theoretical motivation, nevertheless, is sound and well justified, and the empirical evaluation is extensive to reveal the behaviors of the proposed method. It would be better if complexity analysis can also be provided for all concerning methods. Overall, the value of the paper is worth circulation in the community. \n\n[Area to improve]\nThe manuscript could be further improved by exploring the training process more. In the current format, the solution follows the strategy of deep SVDD that learns the model in two separate stages: pre-training the autoencoder, and then fitting the encoder to enforce compactness and entropy minimization/maximization. What if these are implemented in an end-to-end fashion? Will this help to achieve a better result?   \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574752325685, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper854/Reviewers"], "noninvitees": [], "tcdate": 1570237746020, "tmdate": 1574752325698, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Review"}}}, {"id": "B1xf_hzkqS", "original": null, "number": 3, "cdate": 1571921002173, "ddate": null, "tcdate": 1571921002173, "tmdate": 1572972543796, "tddate": null, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "invitation": "ICLR.cc/2020/Conference/Paper854/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose in this paper a variant of Deep SVDD which brings semi-supervision to this model. The paper is well written and contains a thorough experimental evaluation (even disregarding the supplementary material). As far as I know, the proposed method is new and improve anomaly detection. The modification of Deep SVDD are in a way minimalistic, but they do the job.\n\nThe only negative aspects, in my opinion, is the \"information-theoretic view\" which is close to hand waving. The authors are indeed 1) disregarding the regularization term 2) considering an upper bound of the entropy 3) pretending the results on the pre-trained NN hold after post training. Putting everything together, I do not see how this reasoning could accepted. In fact, its extension to Deep SVDD is even more problematic as the discussion in the paper contradicts the reasoning. The authors emphasize the fact that anomalies should not fulfill the clustering assumption (which is indeed an important remark). But then the distribution of phi(x,W) cannot be approximated by a Gaussian for anomalies and thus the bound on the entropy is not valid. \n\nI strongly recommend to remove this part of the paper and to derive Deep SAD from Deep SVDD from heuristics consideration (which is fine!). This will provide an opportunity to remove the cute sentence \"We are happy to now introduce Deep SAD\"."}, "signatures": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper854/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["contact@lukasruff.com", "vandermeulen@cs.uni-kl.de", "nico.goernitz@tu-berlin.de", "alexander_binder@sutd.edu.sg", "mueller@bit.uni-bonn.de", "klaus-robert.mueller@tu-berlin.de", "kloft@cs.uni-kl.de"], "title": "Deep Semi-Supervised Anomaly Detection", "authors": ["Lukas Ruff", "Robert A. Vandermeulen", "Nico G\u00f6rnitz", "Alexander Binder", "Emmanuel M\u00fcller", "Klaus-Robert M\u00fcller", "Marius Kloft"], "pdf": "/pdf/b8f71a263a98cfb3bb24d61b3989cb4bbc74895f.pdf", "TL;DR": "We introduce Deep SAD, a deep method for general semi-supervised anomaly detection that especially takes advantage of labeled anomalies.", "abstract": "Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.", "code": "https://github.com/lukasruff/Deep-SAD-PyTorch", "keywords": ["anomaly detection", "deep learning", "semi-supervised learning", "unsupervised learning", "outlier detection", "one-class classification", "deep anomaly detection", "deep one-class classification"], "paperhash": "ruff|deep_semisupervised_anomaly_detection", "_bibtex": "@inproceedings{\nRuff2020Deep,\ntitle={Deep Semi-Supervised Anomaly Detection},\nauthor={Lukas Ruff and Robert A. Vandermeulen and Nico G\u00f6rnitz and Alexander Binder and Emmanuel M\u00fcller and Klaus-Robert M\u00fcller and Marius Kloft},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HkgH0TEYwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/169e2656fcb64ddc73ed048e95708f9424e3d239.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkgH0TEYwH", "replyto": "HkgH0TEYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper854/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574752325685, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper854/Reviewers"], "noninvitees": [], "tcdate": 1570237746020, "tmdate": 1574752325698, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper854/-/Official_Review"}}}], "count": 10}