{"notes": [{"id": "xboZWqM_ELA", "original": "5HW9SDnzKqz", "number": 561, "cdate": 1601308068665, "ddate": null, "tcdate": 1601308068665, "tmdate": 1614985679828, "tddate": null, "forum": "xboZWqM_ELA", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "n4hcpkvYimf", "original": null, "number": 1, "cdate": 1610040474631, "ddate": null, "tcdate": 1610040474631, "tmdate": 1610474078996, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper explores a very challenging problem of biased label selection and its effect on graph neural networks. It highlights that GNNs are indeed vulnerable to this issue, and then proposes a regularizer to reduce the learning of spurious correlations from the node embeddings. All of the reviews agree that the problem is relevant and important, but that there are still some outstanding issues.\n\nIt\u2019s unclear the degree to which this problem occurs in the real world. It is also important to establish the effectiveness of the method across a range of datasets. The four datasets presented in the paper (and the rebuttal) are a good start, but the reviewers feel that more is still needed to present a convincing argument.\n\nOn the theory side, the reviewers are concerned about the linearity assumptions in the theory, and how this will translate into the more realistic nonlinear setting. Even though the authors state that they do not rely on a causal model, the paper and their responses really do seem to point in that direction. This could simply be a clarity issue, in which case I would encourage the authors to revisit this framing this to avoid confusion.\n\nOverall, the paper is promising, but the reviewers feel that more work is needed to provide a comprehensive and convincing case.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040474617, "tmdate": 1610474078980, "id": "ICLR.cc/2021/Conference/Paper561/-/Decision"}}}, {"id": "IDzagb30jvZ", "original": null, "number": 3, "cdate": 1603902686731, "ddate": null, "tcdate": 1603902686731, "tmdate": 1606768638579, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Review", "content": {"title": "Marginal improvement and inconclusive evaluation", "review": "Summary:\nThe authors propose two different regularization terms to help mitigate the effect of label selection bias. The regularizers are well motivated and can be applied to different GNN models.\n\nReasons for score: \nOverall, I recommend a weak reject. While the theoretical analysis is interesting, the experimental evaluation is inconclusive and the performance improvement is marginal (see weak points). If the authors show stronger empirical evidence (see questions) I will consider increasing the score. Moreover, it is not clear whether the type of selection bias studied in the paper is actually relevant in practice.\n\nStrong points:\n* The proposed regularizers are well motivated, theoretically supported and at the same time simple and easy to implement.\n* The causal view analysis of the proposed regularizers is insightful.\n* The regularized have a reasonably small computational complexity.\n\nWeak points:\n* There are no results in the paper which show how the proposed method performs for a standard (non biased) labeling scenario. It is not clear whether the performance of GCN/GAT-VD/DVD in the standard setting is worse, roughly the same or better, and whether there are any trade-off which are incurred by the proposed regularizers. In other words, while the proposed method helps when there is a difference in the distribution of labels between the train and validation/test nodes it is not clear how it performs when there is no difference.\n* It is not clear whether the highlighted label selection bias is actually present in practice. From the definition of r_i we see that this captures the notion of heterophily, i.e. neighboring nodes have dissimilar labels. In most real-world graphs however, we tend to observe homophily (opposite of heterophily), i.e. neighboring nodes tend to have the same labels. Homophily is often either explicitly or implicitly assumed in many GNN models, so it is not surprising that the performance drops when it is not present. Moreover, it is reasonable to assume that in practice the nodes for labeling are selected uniformly at random (or using active learning) in which case we would likely not observe heavy bias (due to underlying homophily).\n* The performance improvement in most cases is marginal and does not seem to effectively mitigate the highlighted issue. In most cases the improvement is between 1% and 2%, and the results for heavy bias are still significantly worse (e.g. >5%) compared to the results for light bias (or no bias, not shown). The two outliers corresponding to 14% and 17% gain might be due to using a fixed data split (see next point).\n* The paper uses the Planetoid data splits from [1] to form the validation/test set. Previous work [2] strongly argues against using a fixed split to evaluate the performance of GNNs since considering different splits of the data leads to dramatically different rankings of models. As far as I understood the results in the paper are averaged over 10 random seeds for selecting the training set, but the validation/test set is keep fixed. For a robust evaluation results show be reported as average of several different random validation/test splits. \n\nQuestion for the authors:\n1. How does the results change if we consider the average over a larger number (e.g. 10) of random validation/test splits?\n2. What is the performance of GCN/GAT-VD/DVD using uniformly sampled training nodes? Are there any trade-offs?\n3. What is the empirical selection bias for standard (uniform sampling) train/validation/test splits, i.e. how large is the difference between the distributions of r_i scores? (For Cora, Citeseer, Pubmed we expect the difference to be small)\n4. How well do the proposed methods perform in the transductive setting?\n5. How does the performance gain of GCN/GAT-VD/DVD over GCN/GAT on the NELL dataset change as we increase the number of labeled nodes from 1 to some large number?\n\nAdditional feedback that did not affect the decision:\n* The paper could benefit from a discussion of how the specified notion of label selection bias is similar or different from the notion of homophily/heterophily (see also weak points).\n* Another potential selection bias is related to the degree of labeled nodes. For simpler models such as Label Propagation previous work has shown that different variants perform better depending on whether we label high or low degree nodes (see e.g. [3]). It would be interesting to discuss whether this also affects GNNs and whether the proposed approach can help mitigate such bias.\n* It would be insightful to investigate whether recent GNN models which can handle heterophily [4, 5] can deal with the label selection bias studied in the paper. The reviewer acknowledges that these papers were made public after the ICLR submission deadline.\n* Evaluating the effect of small sample selection bias on massive graphs from the Open Graph Benchmark (https://ogb.stanford.edu/) would be insightful. \n* It would be interesting to evalute whether we still observe a strong drop in performance if the training set is chosen in a standard fashion (i.e. the training nodes have high homophily) but the test nodes are selected using e.g. the heavy bias sampling.\n\n## After Rebuttal\nThank you for addressing my questions. Since the performance improvement is still marginal and based on the other reviews I have decided to keep the same score.\n\nReferences:\n1. Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. \"Revisiting semi-supervised learning with graph embeddings.\"\n2. Shchur, Oleksandr, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G\u00fcnnemann. \"Pitfalls of graph neural network evaluation.\"\n3. Avrachenkov, Konstantin, Alexey Mishenin, Paulo Gon\u00e7alves, and Marina Sokol. \"Generalized optimization framework for graph-based semi-supervised learning.\"\n4. Zhu, Jiong, Ryan A. Rossi, Anup Rao, Tung Mai, Nedim Lipka, Nesreen K. Ahmed, and Danai Koutra. \"Graph Neural Networks with Heterophily.\"\n5. Zhu, Jiong, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. \"Generalizing graph neural networks beyond homophily.\"\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538140387, "tmdate": 1606915793265, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper561/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Review"}}}, {"id": "WBiU_ePJDWU", "original": null, "number": 4, "cdate": 1604019603520, "ddate": null, "tcdate": 1604019603520, "tmdate": 1606686950627, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Review", "content": {"title": "Important task, unconvincing theory", "review": "#### Goal\n\n- This work presents an experimental investigation that shows the impact of training selection bias in GNNs (bias with respect to the test data). It also proposes a decorrelation approach to eliminate the spurious correlation in the node representations that come from this training bias.\n\n- I like the experimental investigation (since I think the problem is very relevant). I am skeptical about the method and the results.\n\n#### Quality\n\n- I have many doubts about the validity of the claims. \n\n- Assumption 1 gives us a statistical model not a causal model. In order to claim \u201ccausal effects\u201d, one needs to give a structural causal model. The linear models presented later are not linear on the observed variables. \u201cSpecifically, for both training and test environment, E(Y\u2223S = s, V = v) = E(Y\u2223S = s).\u201d is a covariate shift question, not exactly a counterfactual question if not given with a specific structural causal model.\n\n- \u201cAssumption 2. The true generation process of target variable Y contains not only the linear combination of stable variables S, but also the nonlinear transformation of stable variables.\u201d it is unclear what the authors mean by this statement. That the transformation over S is arbitrary?\n\n- Equation (1): Since the node embeddings can be arbitrary, why do we need an extra function g()? Could that be incorporated into \\mathcal{G}(X, A; \u03b8g)_S \u03b2_S? \n\n- \u201cHowever, limited by the nonlinear power of GNNs (Xu et al., 2019), it is reasonable to assume that there is a nonlinear term g(G (X, A; \u03b8g)_S) \u2260 0 that cannot be fitted by the GNNs.\u201d  This is not at all what (Xu et al., 2019) says. It says that there are some topologies that cannot be represented exactly. While other topologies can be represented exactly. It is entirely dependent on the input data, not a broad general statement for any graph dataset.\n\n- \u201cHence the parameters of both stable variables and unstable variables would be biased.\u201d This is a strong claim that requires a formal proof.\n\n- The entire procedure is predicated on the linear models of Kuang et al., 2020, since the X in Kuang et al. (in, say, Eq (8) of Kuang et al.) is the observed data (not some learned representation). In this paper, the corresponding variables are H representations obtained by a GNN. The model is no longer linear on the input. The distinction between H_S and H_V is, hence, hypothetical, non-existent, and changes during training, since it depends on the GNN parameters. \n\n- How do we know that the decorrelation of H is not restricted to the training data? How do we know that in the test data, the same decorrelation holds? Any statement of decorrelation carrying over to the test data must be formally shown. \n\n- In section 3.2, all results are for linear models. Then, at some point, the observables X suddenly become hidden H and, it is stated (without proof) that the results carry over?!?!? If this were true, why are most works in the literature limiting their counterfactual evaluations to linear models? I highly doubt one can prove this is true for this scenario.\n\n#### Clarity\n\n- The paper uses very convoluted reasoning to arrive at conclusions that are not at all supported by theory. It uses a lot of results from linear models into a proposed nonlinear model. How can the results in the literature possibly carry over? It is hard to believe any of the claims.\n\n- How can the distinction between S and V be clear in the model, since they are the outputs of a GNN we have not been trained yet?\n\n- Can we precisely define the assumed covariate shift between train and test? No method can work for any covariate shift.\n\nTypos & Overall fixes:\n\n- \u201cEven transfer learning is able to solve the distribution shift problem, however, it still needs the prior of test distribution, which actually cannot be obtained beforehand.\u201d => \u201cEven tough transfer learning is able to solve the distribution shift problem, it still needs the prior of test distribution, which cannot be obtained beforehand\u201d\n\n#### Originality\n\n- Removing GNN training sampling bias with counterfactual inference would be new.\n\n#### Significance\n\n- The task of removing GNN training sampling bias is very important.\n\n#### Pros\n\n- Important task.\n- Nice demonstration of the issues with biased training data.\n\n#### Cons\n\n- See \u201cQuality\u201d. I am unconvinced by the method.\n\n\n----\n\nAfter rebuttal: My main concerns about (a) no counterfactual model and (b) the linear / nonlinear requirements of the method remain. Generally, bias assumptions are made about the data, not the output of a representation learning procedure.  \"The nonlinear relationship between raw input with the outcome can be encoded into the learned embedding\" yes, but it does not mean H_S and H_V will meaningfully encode anything related to the input bias in any meaningful way. The method needs to precisely describe the structural causal model to be properly evaluated. \n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538140387, "tmdate": 1606915793265, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper561/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Review"}}}, {"id": "4O7ubVur_mf", "original": null, "number": 3, "cdate": 1605761235741, "ddate": null, "tcdate": 1605761235741, "tmdate": 1606144298326, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "o2ljAULTu-X", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #1 (Part 2/3) ", "comment": "Q4.  Xu et al., 2019 does not say the limited nonlinear power of GNNs. \n\nWe agree with Xu et al., 2019 that there are some topologies that cannot be fitted by the GNNs and some can. And  Xu et al., 2019 increase the number of MLP layers in each convolution layer to increase the expressive power of GNNs. Based on this reason, we assume a general form that there is a nonlinear term $g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S)$ in the data generation process.  $g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S) \\neq 0$ means the GNNs cannot fit the relationship between label with features and topologies exactly,  and $g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S) = 0$ otherwise. However, in practice, the true relationship is far more complex, thus we believe there is a term $g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S) \\neq 0$ that cannot be fitted by the GNNs in many graph data. And this paper mainly focuses on this scenario.\n\nQ5. \u201cHence the parameters of both stable variables and unstable variables would be biased.\u201d This is a strong claim that requires a formal proof.\n\nSorry for the confusion. Actually, we have proved the claim following the sentence the reviewer mentioned. As Eq.(3) and Eq.(4) stated, if there is a correlation between $\\mathbf{V}$ and $\\mathbf{S}$ (or $g(\\mathbf{S})$), the estimation of $\\tilde{\\beta}_S$ and $\\tilde{\\beta}_V$ would be biased. We have changed the expression of this paragraph in the revision to make the proof more clear.\n\nQ6. Compared with Kuang et al., 2020, the GNN model is no longer linear on the input, hence the distinction between $\\mathbf{H}_S$ and $\\mathbf{H}_V$ is not clear.\n\nWe propose a general framework\uff0cwhich assumes that there are stable variables $\\mathbf{H}_S$ and unstable variables $\\mathbf{H}_V$ in node embedding, rather than intending to distinguish these two kinds of variables. In real-world scenarios, the proportion of $\\mathbf{H}_S$ and $\\mathbf{H}_V$ could be different. In an ideal situation, we only have $\\mathbf{H}_S$, then the model could be unbiasedly estimated. Nevertheless, the $\\mathbf{H}_V$ is like to exist in many situations, resulting in biased estimation. Meanwhile, the real-world dataset used in Kuang et al., 2020 does not have a strict distinction between the stable variables and unstable variables. We believe this could be a soft concept for variables, which means the latent variable tends to be stable or unstable. And our model and Kuang et al., 2020 both still work in this scenario.\n\nQ7. How do we know that the decorrelation of $\\mathbf{H}$ is not restricted to the training data?\n\nOur model aims to learn a set of parameters $\\hat{\\beta}$ that could approach the true coefficients $\\beta$  in the training stage.  We formulate the GNNs with linear regressor as a linear model on the learned embedding as Eq.(2) stated:\n\n$\\hat{\\mathbf{Y}} = \\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)_S\\hat{\\beta}_S + \\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)_V\\hat{\\beta}_V + \\varepsilon.$\n\nWe partition the GNN model into two parts: the embedding learning part $\\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)$ and the linear regression part $\\hat{\\beta}$. And this is a regular formulation for a GNN with the linear regressor.  In each iteration, we first learn the node embeddings $\\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)$, and then fix node embedding and learn the sample weights to decorrelate output of $\\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)$, then update the parameters $\\hat{\\beta}$  and  $\\theta_g$.  As theoretically analyzed in Section 2.2, if we decorrelate $\\hat{\\mathscr{G}}(\\mathbf{X},\\mathbf{A};\\theta_g)$, we would unbiasedly estimate the parameter $\\hat{\\beta}$. If we could unbiasedly estimate the true effect of learned embedding on label in each iteration, the final estimation would be unbiased, i.e, $\\hat{\\beta}\\approx{\\beta}$.\n\nDue to the estimated coefficients are equal to the true generation coefficients, we can learn the true relationship between stable variables $\\mathbf{S}$ and label $\\mathbf{Y}$,  i.e., $\\mathbb{P}(\\mathbf{Y}|\\mathbf{S})$. And this relationship is consistent in both the training graph and the test graph as stated in Assumption 1, thus we can guarantee that the unbiased parameters learned on the training graph can be well generalized to on the test graph.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "Q19Cajc1NFe", "original": null, "number": 7, "cdate": 1605763913020, "ddate": null, "tcdate": 1605763913020, "tmdate": 1605841270407, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "KUYIGsCMNDA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #3(Part 1/2)", "comment": "We thank the reviewer for her/his insightful comments and discuss the concerns raised point by point below.\n\nQ1.  The novelty of this work is similar to DWR.\n\nOur work is actually quite different from DWR, which can be summarized as follows:\n\n- In the problem level, DWR focuses on attributed data, while our work studies a new important problem in graph learning, i.e., graph learning with agnostic label selection bias. This problem has not been explored by previous literatures. For this new problem, we clarify several issues, which are unclear before. For example, the distribution shift may be induced by label selection bias and small number of selected nodes\uff0cand the selection bias would drastically hinder the generalization ability of GNNs.\n- In the theoretical level, we make the following contributions: (1) We analyze the relationship between the raw input and the learned embedding, and how the spurious correlation of stable variables and unstable variables will induce the parameter estimation bias. (Section 2.2) (2) We bridge the gap between treatment effect estimation with variable decorrelation and apply the differentiated theorem proposed by this work to reweight the variable weights in the variable decorrelation term. (Section 3.1 and 3.2.) (3) We theoretically prove how to make our framework feasible to popular GNNs and classification task. (Section 3.3.)\n- In the model level, DWR is built  on simple regression, which cannot be directly applied to graph data. And GNNs have a more complex structure and properties needed to be considered. Different from the variable decorrelation term proposed in DWR, our work proposes a differentiated variable decorrelation term that is more suitable for semi-supervised learning. Moreover, we prove how to incorporate VD/DVD with GNNs is a more flexible framework,  which can easily incorporate with various popular GNNs.\n\nQ2.  It is not  clear to understand the connection between the example presented in Section 2.1 and the proposed method.\n\nThe example presented in Section 2.1 is used to better demonstrate that the problem we studied does exist in real graphs, i.e., the state-of-the-art GNNs are sensitive to the selection bias. Based on the proposed problem, we provide detailed analysis and propose new method.  Particularly, we perform GNNs on three biased graph datasets. And the results show that the selection bias drastically hinders the generalization ability on test nodes. Based on this experimental investigation, we theoretically analyze the label selection bias will affect the parameter estimation bias on GNNs in Section 2.2. And the parameter estimation bias is mainly induced by the  spurious correlation between stable variables $\\mathbf{S}$ and unstable variables $\\mathbf{V}$. If we can remove the bias term in parameter estimation, we can achieve the stable prediction. To achieve this goal, we propose to decorrelate the embedding of GNNs so that the spurious correlation could be removed. \n\nIn conclusion, the experimental investigation in Section 2.1 motivates our problem, and theoretical analysis in Section 2.2 bridges the gap between data selection bias with parameter estimation bias. Finally, our model is proposed based on the theoretical analysis results of Eq.(3) and Eq.(4) in Section 2.2. Therefore, our method has a close connection with the example in Section 2.1.\n\nQ3.  Why does this paper consider the Newton-Raphson update rule in Equation (9)? How do you efficiently compute the inversion of matrices?\n\nIn Section 2.2, we analyze GNNs based on the least-squares loss. However, most GNNs are designed for the classification task with the cross-entropy loss. In order to be theoretically rigorous, we extend our theory from regression task to multi-classification task. The intention of the Newton-Raphson update rule presented in Eq. (9) is to indicate that every update iteration of GNN with softmax classifier can be viewed as a weighted least-squares problem. Hence, the theory derived from the least-squares loss can also be applied to classification task. The Newton-Raphson update rule is not the update method used in the paper, and it is the thoery to bridge the gap between linear regression and multi-classification. In practice, we use Adam optimizer to optimize the method,  so we do not need to compute the inversion of matrices.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "nndS8j5r91I", "original": null, "number": 6, "cdate": 1605763425162, "ddate": null, "tcdate": 1605763425162, "tmdate": 1605840761697, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "lNBchsDVMnZ", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #2 (Part 2/2) ", "comment": "Q4. How well do the proposed methods perform in the transductive setting?\n\nWe conduct GCN-VD/DVD in transductive setting on Cora dataset with various bias degrees. The following is the results:\n\n||Cora-Light|Cora-Medium|Cora-Heavy|\n| ----| ----  |---- |----|\n|GCN|0.7940|0.7906|0.7590|\n|GCN-VD|0.8074|0.8049|0.7693|\n|GCN-DVD|0.8061|0.8063|0.7728 |\n\nThe results indicate our method outperforms the base model consistently in transductive setting. However, it is not  a rigorous way to validate the effectiveness of our method, because the label information may be leaked to test nodes through neighborhood aggregation. Hence the test data is no longer agnostic.\n\nQ5. How does the performance gain of GCN/GAT-VD/DVD over GCN/GAT on the NELL dataset as we increase the number of labeled nodes?\n\nAs NELL is a large-scale graph, we cannot run GAT on a single GPU with 16GB memory. We only perform GCN-VD/DVD and GCN on this dataset.  The number of labeled nodes increases from 1 per class (NELL-1) to 5 per class (NELL-5)  and 10 per class (NELL-10).  The followings are our results.\n\n||NELL-1|NELL-5|NELL-10|\n| ----| ----  |---- |----|\n|GCN|0.4416|0.7030|0.7615|\n|GCN-VD|0.4652|0.7424|0.7734|\n|GCN-DVD|0.4734|0.7361|0.7727 |\n|Improve. |7.2% |4.2%|1.5%|\n\nFrom the results, we know GCN-VD/DVD still outperform GCN when the number of label nodes increases,  but improvements on NELL-5 and NELL-10 decrease compared with 1-label case.  The reason is that the distribution shift between training and test could be reduced  when we increase the number of labeled nodes. Moreover, GCN-DVD only achieves competitive results with GCN-VD. One possible reason is that the VD term can already decorrelate variables well when we have enough  labeled nodes, in this scenario, we do not need to differentiate the variable weights.\n\nQ6. Discuss the major differences between our method and heterophily methods and whether the highlighted label selection bias is actually present in practice.\n\nTo our best knowledge, the recently proposed heterophily methods are still based on the assumption that the training set and the test set are drawn from the same distribution. They do not conduct the experiments that training with  heterophily nodes and test with homophily nodes, thus there is no evidence that this kind of methods can be applied to our problem. Moreover,  selecting heterophily nodes is only one kind of scenarios to induce distribution shift. In this paper, we also conduct the experiments on small sample label selection bias. In practice,  selection bias could be induced in many scenarios. For example,  in an image similarity network, where images are connected by their similarity and node attributes are image features,  we may only collect images of dogs on the grass for training while testing with dogs in the water.\n\nThanks for the reviewer's all valuable comments. We will polish the paper in the revision, considering your suggestions.  If you have any other concerns, please let us know."}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "lNBchsDVMnZ", "original": null, "number": 5, "cdate": 1605762058784, "ddate": null, "tcdate": 1605762058784, "tmdate": 1605840308069, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "IDzagb30jvZ", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #2 (Part 1/2)", "comment": "We appreciate the extensive review and useful comments from this reviewer.  In the last few days, we have made all efforts to carry out more experiments that the reviewer concerns about. Note that due to the time limitation of rebuttal, we only select relative datasets and base models (GCN and GAT) as baselines to respond the corresponding questions.\n\nQ1. What is the empirical selection bias for standard (uniform sampling) train/validation/test splits, i.e. how large is the difference between the distributions of r_i scores? \n\nThanks for your insightful suggestion to help us to investigate the degree of distribution shift on each dataset more clearly. We calculate the mean value of all r_i for test nodes and also the mean value of all r_i for uniform sampled and biased sampled training nodes respectively.  We summarize the results as follows:\n\n||Test  |Uniform |Light |Medium|Large|\n| ----| ----  |---- |----|----|---- |\n|Cora  |0.1831| 0.1478|0.2182|0.3118|0.3934|\n| Citeseer|0.2587|0.2975|0.3270|0.4539|0.5651|\n|Pubmed|0.2198|0.2515|0.3457|0.4238|0.4729|\n\nAccording to the results, the findings are concluded as follows: 1) The mean value of r_i of the test set and the uniform sampled training set have a relatively small gap. It means that there is a slight distribution shift between the test set and the uniform sampled training set. The phenomenon is reasonable because it is hard to achieve unbiased sampling in real-world applications [1]. 2) Training nodes selected with bias have larger gaps of mean value of r_i with test set compared with the uniformly sampled training set. It means that training nodes selected with bias have larger distribution shifts than the uniformly sampled nodes and heavier selection bias can induce larger distribution shifts from the test set. The statistical results indicate that our label selection process can really achieve our goal to make different degrees of distribution shifts.\n\n[1] Huang J, Gretton A, Borgwardt K, et al. Correcting sample selection bias by unlabeled data. NIPS 2007.\n\nQ2.  How does the results change if we consider the average over a larger number (e.g. 10) of random validation/test splits?\n\nSince the reviewer thinks the large gain of GCN-VD/DVD on Citeseer dataset may be due to the fixed validation/test set, we conduct the GCN-VD/DVD and base model GCN on Citeseer dataset over 10 times random validation/test splits. And we report the average Accuracy. The results are shown as follows:\n\n||Citeseer- Light|Citeseer-Medium|Citeseer-Large|\n| ----| ----  |---- |----|\n|GCN|0.6548|0.5955|0.5224|\n|GCN-VD|0.6929|0.6704 |0.6479|\n|GCN-DVD|0.6945|0.6767|0.6528|\n|Improve.|6.1%|13.6%|24.9 %|\n\nFrom the results, we get a similar trend as we report in Table 1. The reason for our method achieves larger gain on this dataset may be that the dataset has larger distribution shift than other datasets. The detailed distribution shift statistics of r_i on each dataset could be found in Q1.\n\nQ3. What is the performance of GCN/GAT-VD/DVD using uniformly sampled training nodes? Are there any trade-offs?\n\nWe perform GCN/GAT-VD/DVD on three uniformly sampled training nodes datasets (train/val/test split same as [1]) with the inductive setting. \n\n||Cora|Citeseer|Pubmed|\n| ----| ----  |---- |----|\n|GCN|0.7909|0.7075|0.7845|\n|GCN-VD|0.7980|0.7122|0.7888|\n|GCN-DVD|0.7951|0.7128|0.7874|\n|GAT|0.81|0.7224|0.7714|\n|GAT-VD|0.8133|0.7288|0.7732|\n|GAT-DVD|0.8139|0.7294|0.7735|\n\nGCN/GAT-VD/DVD  also outperform the corresponding baselines. From the statistics of r_i , we know that uniformly sampled training nodes also have a slight distribution shift from test set. (Details in Q1.)  Therefore, the slight distribution shift may be the reason for our model outperforms baselines. In real applications, it is hard to control the collection process without any distribution shift from the training set to the test set [2]. Therefore, we believe our method at least has the same performance as the base model, but we can gain larger improvements with larger bias scenarios.\n\n[1] Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with graph embeddings. ICML2016\n\n[2] Huang J, Gretton A, Borgwardt K, et al. Correcting sample selection bias by unlabeled data. NIPS 2007.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "M12qjy4gA4B", "original": null, "number": 4, "cdate": 1605761796215, "ddate": null, "tcdate": 1605761796215, "tmdate": 1605838465877, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "4O7ubVur_mf", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #1 (Part 3/3) ", "comment": "Q8.  In section 3.2, all results are for linear model.\n\nWe propose a general treatment effect estimation framework between the variable $\\mathbf{X}$ and $T$ with outcome $\\mathbf{Y}$ and assume the linearity between them. However, the $\\mathbf{X}$  and $T$ could not only be raw input,  and it can also be the learned embedding. Then we replace the confounder $\\mathbf{X}$ with the embedding $\\mathbf{H}_\\textrm{.-j}$ learned by the GNNs and the treatment $T$ with the embedding $\\mathbf{H}_\\textrm{.j}$ . The nonlinear relationship between raw input with the outcome can be encoded into the learned embedding $\\mathbf{H}$. We have added this explaination in the revision. Thanks for the reviewer's useful comments.\n\nQ9. Can we precisely define the assumed covariate shift between train and test?\n\nWe define the assumed covariate shift between train and test as following:\n\nGiven a training graph $\\mathcal{G}_\\textrm{train} =( \\mathbf{A_\\textrm{train}}, \\mathbf{X_\\textrm{train}}, \\mathbf{Y_\\textrm{train}})$ and a test graph $\\mathcal{G}_\\textrm{test} =(\\mathbf{A_\\textrm{test}}, \\mathbf{X_\\textrm{test}}, \\mathbf{Y_\\textrm{test}})$, and $\\mathbf{S}$  and $\\mathbf{V}$ represent latent stable and unstable variables in $[\\mathbf{A}, \\mathbf{X}]$ respectively , in a covariate shift problem,  we have joint distribution $\\mathbb{P}(\\mathbf{S_\\textrm{train}}, \\mathbf{V_\\textrm{train}}, \\mathbf{Y_\\textrm{train}})\\neq\\mathbb{P}(\\mathbf{S_\\textrm{test}}, \\mathbf{V_\\textrm{test}}, \\mathbf{Y_\\textrm{test}})$  and $\\mathbb{P}(\\mathbf{S_\\textrm{train}}, \\mathbf{V_\\textrm{train}})\\neq\\mathbb{P}(\\mathbf{S_\\textrm{test}}, \\mathbf{V_\\textrm{test}})$,  but conditional distribution between stable variables $\\mathbf{S}$ and outcome $\\mathbf{Y}$ could be equal in both training graph and test graph  $\\mathbb{P}(\\mathbf{Y_\\textrm{train}}|\\mathbf{S_\\textrm{train}})=\\mathbb{P}(\\mathbf{Y_\\textrm{test}}|\\mathbf{S_\\textrm{test}})$.\n\nThanks for the reviewer's all valuable comments. We will polish the paper in the revision, considering your suggestions.  If you have any other concerns, please let us know."}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "FVW2y19K6nY", "original": null, "number": 9, "cdate": 1605764266545, "ddate": null, "tcdate": 1605764266545, "tmdate": 1605802555272, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "QcOPv6ZvrNE", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #4(Part 1/1)", "comment": "Thanks for the reviewer's positive feedback. The reviewer summarizes the strong points properly and also points out valuable suggestions to improve the paper. We respond the reviewer's concerns as follows.\n\nQ1. How to keep the $\\alpha$ computed from Var($\\mathbf{W}^{(K\u22121)}$, axis = 1) has the same meaning of linear regression coefficients?\n\nGiven the transformation matrix $\\mathbf{W}^{(K-1)}\\in\\mathbb{R}^{p\\times K}$ and a node embedding $\\mathbf{H}_\\textrm{l}\\in\\mathbb{R}^{p\\times 1}$,  if we want to classify node embedding into one of $K$ classes by $\\mathbf{W}^{(K-1)}$ and softmax layer, $\\mathbf{H}_\\textrm{l}^{\\text{T}}\\cdot\\mathbf{W}^{(K-1)}_\\textrm{.j}$ will indicate the similarity between node $l$ and class $j$.  Hence,  $\\mathbf{W}^{(K-1)}_\\textrm{.j}\\in\\mathbb{R}^{p\\times 1}$ can be viewed as the class center for $j$-th class and the variance of each row of $\\mathbf{W}^{(K-1)}_\\textrm{.j}$ will reflect each variable's weight for classification which is similar to linear regression coefficients.\n\nQ2. It is better to list all the hyperparameters used in the paper in the Appendix to improve reproducibility.\n\nThank you for your kindly suggestion, and it helps to improve our work's reproducibility. We have added all necessary hyperparameters in the Appendix to reproduce the results in the paper.\n\nThanks again for your useful and positive feedback about our work. If you have any other concerns, please let us know.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "o2ljAULTu-X", "original": null, "number": 2, "cdate": 1605760811532, "ddate": null, "tcdate": 1605760811532, "tmdate": 1605802447537, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "WBiU_ePJDWU", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #1 (Part 1/3)", "comment": "We would like to thank the reviewer very much for the extensive review and useful comments. In the following, we would like to address your comments, hoping they will clarify raised concerns:\n\nQ1. Assumption 1 gives us a statistical model, not a causal model.\n\nActually, we do not aim to introduce a casual model in Assumption 1.  The assumption aims to assume there is a stable relationship that can be leveraged to stable prediction. And this assumption is not related to the counterfactual question.  We agree  $\\mathbb{E}(\\mathbf{Y}|\\mathbf{S}=s,\\mathbf{V}=v)=\\mathbb{E}(\\mathbf{Y}|\\mathbf{S}=s)$ is a covariate shift question, and it means there is an invariant relationship between stable variable $\\mathbf{S}$ and outcome $\\mathbf{Y}$ in both training and test environments, i.e., $\\mathbb{P}(\\mathbf{Y_\\textrm{train}}|\\mathbf{S_\\textrm{train}})=\\mathbb{P}(\\mathbf{Y_\\textrm{test}}|\\mathbf{S_\\textrm{test}})$.  However, the distribution shift between training and test set is mainly induced by the variation in the joint distribution over ($\\mathbf{S}$, $\\mathbf{V}$) , i.e., $\\mathbb{P}(\\mathbf{S_\\textrm{train}}, \\mathbf{V_\\textrm{train}})\\neq\\mathbb{P}(\\mathbf{S_\\textrm{test}}, \\mathbf{V_\\textrm{test}})$. Assumption 1 can be guaranteed by $\\mathbf{Y}\\bot \\mathbf{V}|\\mathbf{S}$. Thus, one can solve the stable prediction problem by developing a function  $f(\\cdot)$ based on $\\mathbf{S}$. However, one can hardly identify such variables in GNNs. Therefore, we propose to decorrelate all the variables in GNN.  In fact, we slightly misuse the term \u201ccausal effect\u201d and do not intend to give a causal model in this assumption. Thanks for your correction and we will modify our expression in the revision to make it unambiguous.  \nMoreover, our model only assumes the linear relationship between the latent variables of raw input that can be learned by the GNN embedding module and outcome, not linearity on the raw input. For more discussion about this question, please refer to Q8.\n\nQ2. The satement of Assumption 2 is unclear.\n\nAssumption 2 attempts to give a general formulation of the relationship between the latent stable variables $\\mathbf{S}$ of raw input that can be learned by GNNs and the label $\\mathbf{Y}$. Assuming $\\mathbf{S}$ is the only input to generate label $\\mathbf{Y}$, we believe the real-world graph data is complicated, hence the generation process of $\\mathbf{Y}$ not only contains the linear transformation of $\\mathbf{S}$ but also the nonlinear transformation of $\\mathbf{S}$. Based on the assumption, the generation process can be formulated as:\n$\\mathbf{Y}=f(\\mathbf{X}, \\mathbf{A}) + \\varepsilon = \\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S\\beta_S + \\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_V\\beta_V + g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S) + \\varepsilon,$\nwhere $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)$ corresponds to an unknown function of $\\mathbf{X}$ and $\\mathbf{A}$ and it can be learned by a GNN.  $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)$ can be composed into stable variables  $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S$ and unstable variables  $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_V$, where $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S$ corresponds to $\\mathbf{S}$ and $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_V$ corresponds to $\\mathbf{V}$ in Assumption 2. As unstable variables  $\\mathbf{V}$ do not contribute to the generation of $\\mathbf{Y}$, we have $\\beta_V$=0. \n\nQ3. Why do we need an extra function g()?\n\nWe need the extra function g() based on the following two reasons: 1) Most GNNs only have several nonlinear layers to achieve the optimal prediction results, e.g., 2 layers for GCN and GAT, hence the nonlinear power may be limited. 2) In real-world graph ,  the relationship between  features and topologies with node label is usually extremely complex. Therefore, the true generation process of $\\mathbf{Y}$ has a nonlinear term $g(\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S)$ that cannot be learned by existing GNNs and be incorporated into $\\mathscr{G}(\\mathbf{X},\\mathbf{A};\\theta_g)_S\\beta_S$. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "E5NWPpB4D6k", "original": null, "number": 8, "cdate": 1605763962983, "ddate": null, "tcdate": 1605763962983, "tmdate": 1605763962983, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "Q19Cajc1NFe", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment", "content": {"title": "Response to Reviewer #3(Part 2/2)", "comment": "Q4. The studied datasets are known to have unstable performance and are also of small scales. Larger datasets such as OGB are strongly encouraged.\n\nThank you for your valuable suggestion. We conduct our experiments on a total of four datasets. In Table 1, we use three widely used datasets in graph learning literatures. Different from the original datasets, we modify each dataset with three different degrees of training label selection bias. And from the results, we know that our methods consistently outperform SOTA baselines and gain larger improvements under heavier bias scenarios. Moreover, in Table 2, we conduct our experiments on a large-scale dataset, NELL,  which has 65,755 nodes, 266,144 edges and only one labeled node for each class node for training, to validate the effectiveness of our method on the small number of labeled node selection bias. For more details about our datasets, please refer to Appendix F.1. It is promising to validate our method on more datasets, but limited by the time of rebuttal we have to leave it as future work.\n\nThanks for the reviewer's all valuable comments. We will polish the paper in the revision, considering your suggestions.  If you have any other concerns, please let us know."}, "signatures": ["ICLR.cc/2021/Conference/Paper561/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "xboZWqM_ELA", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper561/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper561/Authors|ICLR.cc/2021/Conference/Paper561/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923869643, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Comment"}}}, {"id": "QcOPv6ZvrNE", "original": null, "number": 1, "cdate": 1603661409151, "ddate": null, "tcdate": 1603661409151, "tmdate": 1605024659958, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Review", "content": {"title": "An innovative work for an interesting problem", "review": "The paper proposes an important and unexplored problem in GNNs, i.e., the inconsistent distribution between the training set with test set caused by agnostic label selection bias. I believe that studying this problem is very important for generalizing GNNs on unseen test nodes. The paper first conducts an investigated experiment to show the great impact of agnostic selection bias on test performance. Moreover, the theoretical analysis is provided to identify how the label selection bias leads to the estimation bias in GNN parameters. \nTo remove the estimation bias in parameter estimation, the paper proposes a novel DGNN framework by jointly optimizing a differentiated decorrelation regularizer (DVD) and a weighted GNNs model. The DVD regularizer is designed based on the causal view of variable decorrelation terms. I personally like the idea of analyzing variable decorrelation by the casual view. Furthermore, the paper theoretically proves that how to combine variable decorrelation terms with GNNs would be a more flexible framework for most GNNs and how to extend the theory to the multi-classification scenario. Overall, the proposed method is theoretical sound, where some basic claims are all supported by the clear and sound theoretical analysis. \nThe paper conducts extensive experiments on four benchmark datasets with two kinds of selection bias, well showing the effectiveness of the proposed model. Basically, the paper is well motivated and well-organized. \n\nStrong points:\n1.\tThe agnostic label selection bias problem in GNNs proposed by this paper is very important but seldom studied. And the paper shows the effect of label selection bias on the generalization of GNN in both experimental and theoretical way. In practice, the selection bias widely exists, I think this work may attract more attention in this direction, which makes GNNs more robust and stable in unseen environments.\n2.\tThe technique of the proposed method is sound. The differentiated variable decorrelation is well motivated. This is a general framework for enhancing most existing GNNs under label selection bias setting. The idea of analysis and design model is novel, for example, analyze the estimation bias with stable learning theory, differentiated variable decorrelation in causal view, prove how to combine DVD with GNNs is more flexible, and extend the method to the multi-classification setting. I think these ideas are instructive.\n3.\tThe experiment part is comprehensive and convincing. The experiments are conducted on two kinds of selection bias data, i.e., label selection bias and small sample selection bias. These two kinds of selection bias usually happen in real-world scenarios. And the results clearly show that the proposed methods make larger improvements with heavier bias.\n\nQuestion for rebuttal:\n1.\tIn section 3.3, the variable weight \\alpha is computed from Var(W^(K\u22121), axis = 1), and \\alpha_i can only be a positive value, however, in linear regression, the coefficients could also be a negative value. Hence, how to keep the \\alpha computed from Var(W^(K\u22121), axis = 1) has the same meaning of linear regression coefficients?\n2.\tAlthough we can find the hyperparameters for each method from the experiment part and the corresponding paper of baselines, it is better to list all the hyperparameters used in the paper in the Appendix to improve reproducibility.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538140387, "tmdate": 1606915793265, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper561/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Review"}}}, {"id": "KUYIGsCMNDA", "original": null, "number": 2, "cdate": 1603900875318, "ddate": null, "tcdate": 1603900875318, "tmdate": 1605024659891, "tddate": null, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "invitation": "ICLR.cc/2021/Conference/Paper561/-/Official_Review", "content": {"title": "Official review", "review": "This paper presents a novel method to remove the selection bias of graph data, which is neglected by previous methods. Specifically, the authors suspect that all variables observed by GNNs can be decomposed into two parts, stable variables and unstable variables.  Then, DGNN, a differentiable decorrelation regularization is proposed to reweight each variable pair to eliminate estimation bias. Experiments on three datasets confirm its effectiveness.\n\nPros:\n+ The studied problem is general and also practical for real-world applications.\n\nCons:\n+ The novelty of this work is limited. Although the authors claim it is the first work to solve agnostic label selection bias problem, I in person believe this work can be regarded as a special case of DWR [1]. Therefore, on the basis of DWR, this paper presents not much theoretical contribution to this problem.\n+ The presentation of this paper is somewhat confusing and not well-motivated. For example, it is not clear to understand the connection between the example presented in Section 2.1 and the proposed method. Also, why does this paper consider the Newton-Raphson update rule in Equation (9)? Besides, how do you efficiently compute the inversion of matrices?\n+ The studied datasets are known to have unstable performance and are also of small scales. Even so, the performance improvement seems to be marginal with new baselines missing. Larger datasets such as OGB are strongly encouraged.\n\nReference:\n[1] Stable Prediction with Model Misspecification and Agnostic Distribution Shift, AAAI 2020.", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper561/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper561/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias", "authorids": ["~Shaohua_Fan1", "xiaowang@bupt.edu.cn", "shichuan@bupt.edu.cn", "~Kun_Kuang1", "nianliu@bupt.edu.cn", "wangbai@bupt.edu.cn"], "authors": ["Shaohua Fan", "Xiao Wang", "Chuan Shi", "Kun Kuang", "Nian Liu", "Bai Wang"], "keywords": ["GRAPH NEURAL NETWORKS", "LABEL SELECTION BIAS"], "abstract": "Most existing Graph Neural Networks (GNNs) are proposed without considering the selection bias in data, i.e., the inconsistent distribution between the training set with test set. In reality, the test data is not even available during the training process, making selection bias agnostic. Training GNNs with biased selected nodes leads to significant parameter estimation bias and greatly impacts the generalization ability on test nodes. In this paper, we first present an experimental investigation, which clearly shows that the selection bias drastically hinders the generalization ability of GNNs, and theoretically prove that the selection bias will cause the biased estimation on GNN parameters. Then to remove the bias in GNN estimation, we propose a novel Debiased Graph Neural Networks (DGNN) with a differentiated decorrelation regularizer. The differentiated decorrelation regularizer estimates a sample weight for each labeled node such that the spurious correlation of learned embeddings could be eliminated. We analyze the regularizer in causal view and it motivates us to differentiate the weights of the variables based on their contribution on the confounding bias. Then, these sample weights are used for reweighting GNNs to eliminate the estimation bias, thus help to improve the stability of prediction on unknown test nodes. Comprehensive experiments are conducted on several challenging graph datasets with two kinds of label selection bias. The results well verify that our proposed model outperforms the state-of-the-art methods and DGNN is a flexible framework to enhance existing GNNs.", "one-sentence_summary": "It is the first work to propose and solve the agnostic label selection bias problem in graph neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fan|debiased_graph_neural_networks_with_agnostic_label_selection_bias", "supplementary_material": "/attachment/12a4f116e069b1a389957b0155b4cb3d5fad2c92.zip", "pdf": "/pdf/538fa3073a8c62b947c3a467363c5e8fce25c5f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=oI5Cj_-qQ", "_bibtex": "@misc{\nfan2021debiased,\ntitle={Debiased Graph Neural Networks with Agnostic Label Selection Bias},\nauthor={Shaohua Fan and Xiao Wang and Chuan Shi and Kun Kuang and Nian Liu and Bai Wang},\nyear={2021},\nurl={https://openreview.net/forum?id=xboZWqM_ELA}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "xboZWqM_ELA", "replyto": "xboZWqM_ELA", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper561/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538140387, "tmdate": 1606915793265, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper561/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper561/-/Official_Review"}}}], "count": 14}