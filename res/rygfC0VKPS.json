{"notes": [{"id": "rygfC0VKPS", "original": "SkxXpLc_DH", "number": 1423, "cdate": 1569439434429, "ddate": null, "tcdate": 1569439434429, "tmdate": 1577168292931, "tddate": null, "forum": "rygfC0VKPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models", "authors": ["Anand Ramakrishnan", "Warren B. Jackson", "Kent Evans"], "authorids": ["aramakrishnan@wpi.edu", "jackson@parc.com", "kent.evans@parc.com"], "keywords": ["Composition", "extrapolation", "boosting", "autocorrelation", "systematic errors"], "TL;DR": "Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ", "abstract": "Combining domain knowledge models with neural models has been challenging.  End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems. The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.", "pdf": "/pdf/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "paperhash": "ramakrishnan|improved_modeling_of_complex_systems_using_hybrid_physicsmachine_learningstochastic_models", "original_pdf": "/attachment/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "_bibtex": "@misc{\nramakrishnan2020improved,\ntitle={Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models},\nauthor={Anand Ramakrishnan and Warren B. Jackson and Kent Evans},\nyear={2020},\nurl={https://openreview.net/forum?id=rygfC0VKPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "uzhmydBe0i", "original": null, "number": 1, "cdate": 1576798722921, "ddate": null, "tcdate": 1576798722921, "tmdate": 1576800913655, "tddate": null, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "invitation": "ICLR.cc/2020/Conference/Paper1423/-/Decision", "content": {"decision": "Reject", "comment": "All reviewers agree that the paper is to be rejected, provided strong claims that were not answered. In this form (especially with such a title) it could not be published (it is more of a technical/engineering interest).", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models", "authors": ["Anand Ramakrishnan", "Warren B. Jackson", "Kent Evans"], "authorids": ["aramakrishnan@wpi.edu", "jackson@parc.com", "kent.evans@parc.com"], "keywords": ["Composition", "extrapolation", "boosting", "autocorrelation", "systematic errors"], "TL;DR": "Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ", "abstract": "Combining domain knowledge models with neural models has been challenging.  End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems. The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.", "pdf": "/pdf/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "paperhash": "ramakrishnan|improved_modeling_of_complex_systems_using_hybrid_physicsmachine_learningstochastic_models", "original_pdf": "/attachment/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "_bibtex": "@misc{\nramakrishnan2020improved,\ntitle={Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models},\nauthor={Anand Ramakrishnan and Warren B. Jackson and Kent Evans},\nyear={2020},\nurl={https://openreview.net/forum?id=rygfC0VKPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726889, "tmdate": 1576800279096, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1423/-/Decision"}}}, {"id": "B1gffMK5YS", "original": null, "number": 1, "cdate": 1571619338228, "ddate": null, "tcdate": 1571619338228, "tmdate": 1572972470821, "tddate": null, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "invitation": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper conducts several experiments to compare the extrapolative predictions of various hybrid models (sequential, ensemble, and cyclic), which compose physical models, neural networks and stochastic models. \n\nUnmodeled dynamics is a bottleneck for model learning, model-based reinforcement learning and sim-to-real transfer. This paper tries to tackle this important research challenge. However, this research is at its early-stage and the results are preliminary. I would not recommend accepting the paper at this time, and encourage the authors to continue this promising research direction. First, the conclusion of the paper is not clear to me. Which is the best way to compose models? Is it physics+RNN+cyclic LJB loss? It would be helpful to put all the visualizations of the results together and organize it in a way that can easily reveal conclusions across different experiments. If the conclusions are inconsistent across different experiments, detailed analysis and explanations are expected. Second, it is not sufficient to just analyze the regression errors of different hybrid models for an ICLR paper. The paper would be much stronger if the it could demonstrate that with the more accurate hybrid model, model-based learning performs better or transfer learning is more straightforward. For example, it could change Section 6.2 to control a double inverted pendulum using only a rough physics model of a single pendulum. Similarly, it could augment Section 6.3 to control a real inverted pendulum with a DC motor with large backlash.\n\nIn addition, I have a few questions/comments about the clarity of the writing:\n1) Are \\theta in eq. (1) the parameters of the physical system, such as mass, length of the rod for the inverted pendulum case?\n2) I am not familiar with LJB loss function. If it is commonly-used, please add a reference. If not, more explanations would be helpful. Is LJB loss function used alone or combined with the MSE loss?\n3) Is there any particular reason that cos\\theta and sin\\theta are chosen as states for Inverted Pendulum instead of \\theta? In Double Pendulum, \\theta is used.\n4) In DC Motor, \"This input, output pair data was fit to a linear state space model, (i.e. a physics model)...\" Is the output linear to the states (\\theta, \\dot{\\theta}) or linear to the physical parameters (inertia, friction, etc.)? In previous examples, such as Figure 4, physics model and linear model are separate. It is confusing to me that in this example, the linear model seems to be the physics model. Is the dynamics equation of the DC motor linear? Am I missing something?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models", "authors": ["Anand Ramakrishnan", "Warren B. Jackson", "Kent Evans"], "authorids": ["aramakrishnan@wpi.edu", "jackson@parc.com", "kent.evans@parc.com"], "keywords": ["Composition", "extrapolation", "boosting", "autocorrelation", "systematic errors"], "TL;DR": "Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ", "abstract": "Combining domain knowledge models with neural models has been challenging.  End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems. The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.", "pdf": "/pdf/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "paperhash": "ramakrishnan|improved_modeling_of_complex_systems_using_hybrid_physicsmachine_learningstochastic_models", "original_pdf": "/attachment/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "_bibtex": "@misc{\nramakrishnan2020improved,\ntitle={Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models},\nauthor={Anand Ramakrishnan and Warren B. Jackson and Kent Evans},\nyear={2020},\nurl={https://openreview.net/forum?id=rygfC0VKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575478578945, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1423/Reviewers"], "noninvitees": [], "tcdate": 1570237737598, "tmdate": 1575478578957, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review"}}}, {"id": "rye7ynORtB", "original": null, "number": 2, "cdate": 1571879898641, "ddate": null, "tcdate": 1571879898641, "tmdate": 1572972470786, "tddate": null, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "invitation": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper presents approaches for combining neural network (NN) with non-NN models to predict behavior of complex physical systems.  \nI found this paper very hard to read, with a lot of details and key pieces of information missing or vaguely stated.  Following are some specific instances in no particular order:\na) From the results it seems that often approaches using \u2018cyclic-boost\u2019 perform the best.  However the description of cyclic boost in Section 3.3 lacks any precise description of what the cyclic approach does.  For instance, the NN that predicts the inputs from model outputs, how is that used and under what objective is that learnt?\nb) The main claim of the paper is that combining physics models with NNs is better than NNs alone, esp. when tested on \u2018extrapolative data\u2019.  However, if cyclic-boost is the best approach, the paper should include results with cyclic-boost-RNN combination, these do not seem to be there to assess value add of the physics models in the best performing system.\nc) Section 3.2 states a parallel ensemble of NN and non-NN models has the advantage of finding \u2018global optimum\u2019 \u2026 this is a strong statement and needs to be demonstrated.\nd) The description of new loss function in Section 4 is unclear.  For instance, what is \u2019n\u2019 in (7)?\ne) In Section 3.1 I\u2019m assuming that \u2018h_t\u2019 denotes the model being trained in iteration \u2019t\u2019, and some of these are NN whereas others are domain models?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models", "authors": ["Anand Ramakrishnan", "Warren B. Jackson", "Kent Evans"], "authorids": ["aramakrishnan@wpi.edu", "jackson@parc.com", "kent.evans@parc.com"], "keywords": ["Composition", "extrapolation", "boosting", "autocorrelation", "systematic errors"], "TL;DR": "Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ", "abstract": "Combining domain knowledge models with neural models has been challenging.  End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems. The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.", "pdf": "/pdf/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "paperhash": "ramakrishnan|improved_modeling_of_complex_systems_using_hybrid_physicsmachine_learningstochastic_models", "original_pdf": "/attachment/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "_bibtex": "@misc{\nramakrishnan2020improved,\ntitle={Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models},\nauthor={Anand Ramakrishnan and Warren B. Jackson and Kent Evans},\nyear={2020},\nurl={https://openreview.net/forum?id=rygfC0VKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575478578945, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1423/Reviewers"], "noninvitees": [], "tcdate": 1570237737598, "tmdate": 1575478578957, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review"}}}, {"id": "rkequUYRFB", "original": null, "number": 3, "cdate": 1571882610152, "ddate": null, "tcdate": 1571882610152, "tmdate": 1572972470743, "tddate": null, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "invitation": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present a new hybrid models that incorporates traditional models with neural networks by boosting and reducing the residuals in stages. They show 3 different boosting schemes: sequential boosting, parallel boosting and cyclical boosting (inspired by variational autoencoders). Furthermore the authors present the new Ljung-Box (LJB) loss function which reduces autocorrelation. They test on 2 simulated systems and on a physical DC Motor and put an emphasis on testing their result on extrapolated (unseen) data.\n\nStrengths:\n- The authors combine traditional models with deep learning approaches.\n- The models can extrapolate to unseen data better than conventional deep learning approaches.\n- The results show that the authors found a loss function that can reduce autocorrelation.\n\nWeaknesses: \n- The paper lacks an exact explanation for every model that was used. This is made worse by a lack of consistency, e.g. the model Physics-Boost-Dense doesn't explain which of the 3 boosting schemes is used.\n- The authors propose a new Ljung-Box (LJB)  loss function. It contains hyper parameter L \"which should be larger than possible correlations\". It is not mentioned how to find such a value or what the value for the experiments for. They show that this loss function can reduce autocorrelation, but it comes at the expense of higher RMSE. It is not clear in what scenario this is useful.\n- The methodology is difficult to follow. E.g. there is a mathematical explanation in 3.1, but not for 3.2 or 3.3. In Fig. 1(1) and Fig. 1(2), they incorporate a traditional model, but not in Fig. 1(3). Later they show results for a cyclic method that incorporates a physical model, but it's not clear how that was done.\n- The authors claim that they are using \"a new method for creating testing data\". However, testing on extrapolating data is not a new method.\n\nAdditional Comments: \n- Equation (2): I assume the hat should only be above f, not the entire f(x). If not, I don't see this symbol explained or used anywhere else in the paper.\n- h_t in equation (3) and (4) are not explained in the text\n- Fig. 1(1) and Fig. 1(3) are not mentioned in the text\n- Figure 3 and 4 are hard to understand. Instead of State 0/1/2, it should say angle / angular velocity / acceleration. There should be a table to accompany this figure, so that it's easier to compare the models. As is, it's very hard to compare e.g. Physics-Ensemble-Dense with Dense-Ensemble-RNN.\n- There are plenty of typos and a general lack of clarity. E.g. this sentence: \"The  alternative  of  performing  end-to-end  of  all  the  models  at  once  is  an  significant  alternative.\"\n- Add reference for original Ljung-Box test\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1423/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models", "authors": ["Anand Ramakrishnan", "Warren B. Jackson", "Kent Evans"], "authorids": ["aramakrishnan@wpi.edu", "jackson@parc.com", "kent.evans@parc.com"], "keywords": ["Composition", "extrapolation", "boosting", "autocorrelation", "systematic errors"], "TL;DR": "Improved modeling of complex systems uses hybrid neural/domain model composition, new decorrelation loss functions and extrapolative test sets ", "abstract": "Combining domain knowledge models with neural models has been challenging.  End-to-end trained neural models often perform better (lower Mean Square Error) than domain knowledge models or domain/neural combinations, and the combination is inefficient to train.  In this paper, we demonstrate that by composing domain models with machine learning models, by using extrapolative testing sets, and invoking decorrelation objective functions, we create models which can predict more complex systems. The models are interpretable, extrapolative, data-efficient, and capture predictable but complex non-stochastic behavior such as unmodeled degrees of freedom and systemic measurement noise.  We apply this improved modeling paradigm to several simulated systems and an actual physical system in the context of system identification.   Several ways of composing domain models with neural models are examined for time series, boosting, bagging, and auto-encoding on various systems of varying complexity and non-linearity.  Although this work is preliminary, we show that the ability to combine models is a very promising direction for neural modeling.", "pdf": "/pdf/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "paperhash": "ramakrishnan|improved_modeling_of_complex_systems_using_hybrid_physicsmachine_learningstochastic_models", "original_pdf": "/attachment/20a8ad56b07638503c66572a2e34568273c16f7f.pdf", "_bibtex": "@misc{\nramakrishnan2020improved,\ntitle={Improved Modeling of Complex Systems Using Hybrid Physics/Machine Learning/Stochastic Models},\nauthor={Anand Ramakrishnan and Warren B. Jackson and Kent Evans},\nyear={2020},\nurl={https://openreview.net/forum?id=rygfC0VKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rygfC0VKPS", "replyto": "rygfC0VKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575478578945, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1423/Reviewers"], "noninvitees": [], "tcdate": 1570237737598, "tmdate": 1575478578957, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1423/-/Official_Review"}}}], "count": 5}