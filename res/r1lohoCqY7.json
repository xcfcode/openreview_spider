{"notes": [{"id": "r1lohoCqY7", "original": "ryl98139tm", "number": 743, "cdate": 1538087859232, "ddate": null, "tcdate": 1538087859232, "tmdate": 1555376573340, "tddate": null, "forum": "r1lohoCqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rkxo9bEkgE", "original": null, "number": 1, "cdate": 1544663442957, "ddate": null, "tcdate": 1544663442957, "tmdate": 1545354485085, "tddate": null, "forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Meta_Review", "content": {"metareview": "The paper conveys interesting ideas but reviewers are concern about an incremental nature of results, choice of comparators, and in general empirical and analytical novelty.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper743/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353102215, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper743/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353102215}}}, {"id": "B1g6Ld0gaX", "original": null, "number": 2, "cdate": 1541625940643, "ddate": null, "tcdate": 1541625940643, "tmdate": 1543700521038, "tddate": null, "forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "content": {"title": "Unclear problem setting", "review": "Quality/clarity:\n- The problem setting description is neither formal nor intuitive which made it very hard for me to understand exactly the problem you are trying to solve. Starting with S and i: I guess S and i are both simply varying-length sequences in U.\n- In general the intro should focus more on an intuitive (and/or formal) explanation of the problem setting, with some equations that explain the problem you want to work on. Right now it is too heavy on 'related work' (this is just my opinion).\n\nOriginality/Significance:\nI have certainly never seen a ML-based paper on this topic. The idea of 'learning' prior information about the heavy hitters seems original.\n\nPros:\nIt seems like a creative and interesting place to use machine learning. the plots in Figure 5.2 seem promising.\n\nCons:\n- The formalization in Paragraph 3 of the Intro is not very formal. I guess S and i are both simply varying-length sequences in U.\n- In general the intro should focus more on an intuitive (and/or formal) explanation of the problem setting, with some equations that explain the problem you want to work on. Right now it is too heavy on 'related work' (this is just my opinion).\n\n-In describing Eqn 3 there are some weird remarks, e.g. \"N is the sum of all frequencies\". Do you mean that N is the total number of available frequencies? i.e. should it be |D|? It's not clear to me that the sum of frequencies would be bounded if D is not discrete.\n- Your F and \\tilde{f} are introduced as infinite series. Maybe they should be {f1, f2,..., fN}, i.e. N queries, each of which you are trying to be estimate.\n- In general, you have to introduce the notation much more carefully. Your audience should not be expected to be experts in hashing for this venue!! 'C[1,...,B]' is informal abusive notation. You should clearly state using both mathematical notation AND using sentences what each symbol means. My understanding is that that h:U->b, is a function from universe U to natural number b, where b is an element from the discrete set {1,...,B}, to be used as an index for vector C. The algorithm maintains this vector C\\in N^B (ie C is a B-length vector of natural numbers). In other words, h is mapping a varying-length sequence from U to an *index* of the vector C (a.k.a: a bin). Thus C[b] denotes the b-th element/bin of C, and C[h(i)] denotes the h(i)-th element. \n- Still it is unclear where 'fj' comes from. You need to state in words eg \"C[b] contains the accumulation of all fj's such that h(j)=b; i.e. for each sequence j \\in U, if the hash function h maps the sequence to bin b (ie $h(j)=b$), then we include the *corresponding frequency* in the sum.\"\n- What I don't understand is how fj is dependent on h. When you say \"at the end of the stream\", you mean that given S, we are analyzing the frequency of a series of sequences {i_1,...,i_N}?\n- Sorry, it's just confusing and I didn't really understand \"Single Hash Function\" from Sec 3.2 until I started typing this out.\n- The term \"sketch\" is used in Algorithm1, like 10, before 'sketch' is defined!!\n-I'm not going to trudge through the proofs, because I don't think this is self-contained (and I'm clearly not an expert in the area).\n\nConclusion:\nHonestly, this paper is very difficult to follow. However to sum up the idea: you want to use deep learning techniques to learn some prior on the hash-estimation problem, in the form of a heavy-hitter oracle. It seems interesting and shows promising results, but the presentation has to be cleaned up for publication in a top ML venue.\n\n\n\n******\nUpdate after response:\nThe authors have provided improvements to the introduction of the problem setting, satisfying most of my complaints from before. I am raising my score accordingly, since the paper does present some novel results.", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "cdate": 1542234386400, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335793242, "tmdate": 1552335793242, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkeXupr4Am", "original": null, "number": 6, "cdate": 1542901098770, "ddate": null, "tcdate": 1542901098770, "tmdate": 1542901098770, "tddate": null, "forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "content": {"title": "Minor updates to the paper", "comment": "Dear reviewers,\n\nThank you again for the thoughtful comments. We made minor updates in the paper (labeled in blue) to address some of the notation issues. We also included more explanation of our problem in the introduction. We hope that this helps clarify any misunderstandings. Please let us know if you have any other comments."}, "signatures": ["ICLR.cc/2019/Conference/Paper743/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615653, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lohoCqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper743/Authors|ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615653}}}, {"id": "BylBDAB5aQ", "original": null, "number": 5, "cdate": 1542245980541, "ddate": null, "tcdate": 1542245980541, "tmdate": 1542245980541, "tddate": null, "forum": "r1lohoCqY7", "replyto": "SkgtrSEZ67", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thank you for the thoughtful comments. We are glad that you found our problem interesting, and problem formulation/applications of this research well explained. \n\nRegarding the competing algorithms:  Both algorithms that we compare to, Count-Sketch and Count-Min, are state-of-the-art hashing-based algorithms (see e.g., Cormode & Hadjieleftheriou (2008)). Further, they are widely used in practice for processing internet traffic, large databases, query logs, web document repositories, etc.\n\nTo the best of our knowledge, our paper is the first to use machine learning to design better sketches for any streaming problem. We tried to cover related work thoroughly in section 2. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615653, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lohoCqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper743/Authors|ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615653}}}, {"id": "H1gsmAr9aX", "original": null, "number": 4, "cdate": 1542245923068, "ddate": null, "tcdate": 1542245923068, "tmdate": 1542245923068, "tddate": null, "forum": "r1lohoCqY7", "replyto": "B1g6Ld0gaX", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for the thoughtful comments. We are glad that you found our algorithmic approach original, and our experiments promising. \n\nRegarding the notation, given that the topic of our paper is inherently interdisciplinary -- spanning machine learning and algorithm theory -- we need to use notions and notation from both communities. This can lead to misunderstandings, but there is no easy way around it. In the paper we tried to follow the notation used in heavy-hitter analysis in algorithm theory to make it easy to compare the analysis to past work. But since there is no standard notation across both fields, it is difficult to find a notation that is easily accessible to both communities. \n \nIn addition, there are indeed a few places in the paper where our phrasing could have been better, thank you for pointing this out.  We discuss this in more detail below, and hope this should clarify any misunderstandings. \n\nRegarding our proofs, they are all self-contained.\n\n- The problem setting description is neither formal nor intuitive which made it very hard for me to understand exactly the problem you are trying to solve. Starting with S and i: I guess S and i are both simply varying-length sequences in U.\n\nTo clarify, the input S is a sequence *of elements* from some universe U. To give an example, we could have U={0...65535}, in which case the sequence S would consist of integers in the range 0...65535. For example, S = 10101, 21222, 10222, 1, 10, 1, 52233, 62223 is an example sequence of length 8 whose items belong to U. \n\nThe remainder of the problem definition is as described in the introduction: a frequency estimation algorithm reads the sequence S in one pass, and after that, for any element i from U, reports an estimate of  f_i,  the number of times element i occurs in S. In the above example, we have, e.g., f_1=2.\n\n- In general the intro should focus more on an intuitive (and/or formal) explanation of the problem setting, with some equations that explain the problem you want to work on. Right now it is too heavy on 'related work' (this is just my opinion).\n\nThanks for the suggestions. We will include more explanation in the introduction and condense related work while keeping it thorough.\n\n- In describing Eqn 3 there are some weird remarks, e.g. \"N is the sum of all frequencies\". Do you mean that N is the total number of available frequencies? i.e. should it be |D|? It's not clear to me that the sum of frequencies would be bounded if D is not discrete.\n\n N is the sum of all frequencies; i.e., N = \\sum_{ i \\in U }  f_i.\n \n- Your F and \\tilde{f} are introduced as infinite series. Maybe they should be {f1, f2,..., fN}, i.e. N queries, each of which you are trying to be estimate.\n\nThe series are indeed finite, we skipped the last index for simplicity. Formally, it should be F = {f_1, \u2026, f_|U|} and ~F = {~f_1, \u2026, ~f_|U|}\n\n- In general, you have to introduce the notation much more carefully. Your audience should not be expected to be experts in hashing for this venue!! 'C[1,...,B]' is informal abusive notation. You should clearly state using both mathematical notation AND using sentences what each symbol means. \n\nAs stated, C[1...B] is a one-dimensional array. Equivalently, it is a B-dimensional vector. We refer to C as an \u201carray\u201d as opposed to \u201cvector\u201d for the sake of consistency with prior work on frequency estimation, and to avoid nested subscripts. \n\nC[b] indeed denotes the b-th element/bin of C. Regarding the notation h: U -> [B] : we use [B] to denote the set {1...B}. We define it in Section 7, but we should have defined it earlier. The formula h: U->[B] indeed denotes a function h that maps elements of U to {1...B}.\n\n- Still it is unclear where 'fj' comes from. You need to state in words eg \"C[b] contains the accumulation of all fj's such that h(j)=b; i.e. for each sequence j \\in U, if the hash function h maps the sequence to bin b (ie $h(j)=b$), then we include the *corresponding frequency* in the sum.\"\n\nWe hope that after the earlier clarifications, the equation C[b] = sum_{j:h(j)=b} f_j  is more clear now. \n  \n- What I don't understand is how fj is dependent on h. When you say \"at the end of the stream\", you mean that given S, we are analyzing the frequency of a series of sequences {i_1,...,i_N}?\n\nf_j does not depend on h, only on the input sequence S. Since an element j can occur anywhere in S, the equation C[b] = sum_{j:h(j)=b} f_j  holds only after the algorithm scans the whole sequence S. \n\n- The term \"sketch\" is used in Algorithm1, like 10, before 'sketch' is defined!!\n\nAs explained in the description, items not stored in unique buckets \u201care fed to the remaining B \u2212 Br buckets using a conventional frequency estimation algorithm SketchAlg\u201d. The word \u201csketch\u201d in Algorithm 1 refers to the storage used by SketchAlg. To avoid confusion, we will shorten line 10 to \u201cfeed i to SketchAlg\u201d.\n\f"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615653, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lohoCqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper743/Authors|ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615653}}}, {"id": "Skl8UhSqaX", "original": null, "number": 3, "cdate": 1542245453856, "ddate": null, "tcdate": 1542245453856, "tmdate": 1542245453856, "tddate": null, "forum": "r1lohoCqY7", "replyto": "BkeVYzOCnm", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for the thoughtful comments. We are glad that you found our topic interesting and appreciated our theoretical analysis and experimental results. We address other comments below:\n\n[Results are only given for the Zipfian distribution]\nMany real-world data naturally follow the Zipf\u2019s Law, as we showed in Figure 5.1 and Figure 5.3 for internet traffic and search query data. Thus, our theoretical analysis assumes item frequencies follow the Zipfian distribution. While our analysis makes this assumption, our algorithm does not have any assumption on the frequency distribution.\n\n[Assuming query distribution is the same as data distribution]\nAs the reviewer pointed out, the query distribution we use is a natural choice. There might be other types of query distributions, such as the one pointed out by the reviewer.  Intuitively, our overall approach that separates heavy hitters from the rest should still be beneficial to such query distribution.\n\n[Algorithm design]\nWe agree that our algorithms are relatively simple. We believe this is a feature not a bug: as we showed in Sec. 4.1, our algorithm does not need to be more complex. Specifically, our Learned Count-Min algorithm achieves the same asymptotic error as the \u201cIdeal Count-Min\u201d, which is allowed to optimize the whole hash function for the specific given input (Theorem 7.14 and Theorem 8.4 in Table 4.1). The proof of this statement demonstrates that identifying heavy hitters and placing them in unique bins is an (asymptotically) optimal strategy. (In fact, our first attempt at solving the problem was a much more complex algorithm which optimized the allocation of elements to the buckets (i.e., the whole hash function h) to minimize the error. This turned out to be unnecessary, as per the above argument.)\n\n[Novelty compared to Mitzenmacher\u2019 18]\nOur paper, as well as the works of Kraska et al \u201918, Mitzenmacher \u201918,  Lykouris &\nVassilvitskii \u201918, Purohit et al, NIPS\u201918, belong to a growing class of studies that use a machine learning oracle to improve the performance of algorithms. All such papers use a learned oracle of some form. The key differences are in what the oracle does, how it is used, and what can be proved about it. In Kraska\u201918 and Mitzenmacher\u201918, the oracle tries to directly solve the main problem, which is: \u201cis the element in the set?\u201d An analogous approach in our case would be to train an oracle that directly outputs the frequency of each element. However, instead of trying to directly solve the main problem (estimate the frequency of each element), our oracle is a subroutine that tries to predict the best resource allocation --i.e., it tries to answer the question of which elements should be given their own buckets and which should share with others.  \n\nThere are other differences.  For example, the main goal of our algorithm is to reduce collisions between heavy items, as such collisions greatly increase errors. This motivates our design to split heavy and light items using the learned model, and apply separate algorithms for each type. In contrast, in existence indices, all collisions count equally. \n\nFinally, our theoretical analysis is different from M'18 due to the intrinsic differences between the two problems, as outlined in the previous paragraph. \n\n[The analysis is relatively straightforward]\nThere are three main theorems in our paper: Theorem 8.4, Theorem 7.11 and 7.14.  Our proofs of Theorem 7.11 and 7.14 are technically involved, even if the techniques are relatively standard.  On the other hand, the proof of Theorem 8.4 uses entirely different techniques. In particular, it provides a characterization of the hash function optimized for a particular input. \n\n[The machine learned Oracle is assumed to be flawless at identifying the Heavy Hitters]\nActually, this is not the case. The analysis in the paper already takes into account errors in the machine learning oracle. Please see the 2nd paragraph of Sec. 4.1 and Lemma 7.15. In summary, our results hold even if the learned oracle makes prediction errors with probability O(1/ln(n)). We will revise the text to make it clearer.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615653, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lohoCqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper743/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper743/Authors|ICLR.cc/2019/Conference/Paper743/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers", "ICLR.cc/2019/Conference/Paper743/Authors", "ICLR.cc/2019/Conference/Paper743/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615653}}}, {"id": "SkgtrSEZ67", "original": null, "number": 3, "cdate": 1541649728665, "ddate": null, "tcdate": 1541649728665, "tmdate": 1541649728665, "tddate": null, "forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "content": {"title": "A good problem discussed and the proposed ML approach seems reasonable.", "review": "The authors are proposing an end-to-end learning-based framework that can be incorporated into all classical frequency estimation algorithms in order to learn the underlying nature of the data in terms of the frequency in data streaming settings and which does not require labeling. According to my understanding, the other classical streaming algorithms also do not require labeling but the novelty here I guess lie in learning the oracle (HH) which feels like a logical thing to do as such learning using neural networks worked well for many other problems.\n\nThe problem formulation and applications of this research are well explained and the paper is well written for readers to understand. The experiments show that the learning based approach performs better than their all unlearned versions. \n\nBut the only negative aspect is the basis competitor algorithms are very simple in nature without any form of learning and that are very old. So, I am not sure if there are any new machine learning based frequency estimation algorithms.  \n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "cdate": 1542234386400, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335793242, "tmdate": 1552335793242, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BkeVYzOCnm", "original": null, "number": 1, "cdate": 1541468795593, "ddate": null, "tcdate": 1541468795593, "tmdate": 1541533724845, "tddate": null, "forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "content": {"title": "Interesting topic, somewhat trivial algorithms and somewhat narrow results", "review": "This paper introduces the study of the problem of frequency estimation algorithms with machine learning advice. The problem considered is the standard frequency estimation problem in data streams where the goal is to estimate the frequency of the i-th item up to an additive error, i.e. the |\\tilde f_i - f_i| should be minimized where \\tilde f_i is the estimate of the true frequency f_i.\n\nPros:\n-- Interesting topic of using machine learned advice to speed up frequency estimation is considered\n-- New rigorous bounds are given on the complexity of frequency estimation under Zipfian distribution using machine learned advice\n-- Experiments are given to justify claimed improvements in performance\n\nCons:\n\n-- While the overall claim of the paper in the introduction seems to be to speed up frequency estimation using machine learned advice, results are only given for the Zipfian distribution.\n\n-- The overall error model in this paper, which is borrowed from Roy et al. is quite restrictive as at it assumes that the queries to the frequency estimation data structure are coming from the same distribution as that given by f_i\u2019s themselves. While in some applications this might be natural, this is certainly very restrictive in situations where f_i\u2019s are updated not just by +/-1 increments but through arbitrary +/-Delta updates, as in this case it might be more natural to assume that the distribution of the queries might be proportional to the frequency that the corresponding coordinate is being updated, for example.\n\n-- The algorithm proposed in the paper is very straightforward and just removes heavy hitters using oracle advice and then hashes everything else using the standard CountMin sketch.\n\n-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher\u201918.\n\n-- The analysis is relatively straightforward and boils down to bucketing the error and integration over the buckets.\n\n\nOther comments:\n-- The machine learned advice is assumed to be flawless at identifying the Heavy Hitters, authors might want to consider incorporating errors in the analysis.\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper743/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today's streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates.   The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory.  We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts.  We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "keywords": ["streaming algorithms", "heavy-hitters", "Count-Min", "Count-Sketch"], "authorids": ["cyhsu@mit.edu", "indyk@mit.edu", "dina@csail.mit.edu", "vakilian@mit.edu"], "authors": ["Chen-Yu Hsu", "Piotr Indyk", "Dina Katabi", "Ali Vakilian"], "TL;DR": "Data stream algorithms can be improved using deep learning, while retaining performance guarantees.", "pdf": "/pdf/933864fa625dad4f0cacd07d5d9ea5bfad36294e.pdf", "paperhash": "hsu|learningbased_frequency_estimation_algorithms", "_bibtex": "@inproceedings{\nhsu2018learningbased,\ntitle={Learning-Based Frequency Estimation Algorithms},\nauthor={Chen-Yu Hsu and Piotr Indyk and Dina Katabi and Ali Vakilian},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lohoCqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper743/Official_Review", "cdate": 1542234386400, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lohoCqY7", "replyto": "r1lohoCqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper743/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335793242, "tmdate": 1552335793242, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper743/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}