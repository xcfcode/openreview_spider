{"notes": [{"id": "S1lnmLLKu4", "original": "B1xe9UVUP4", "number": 5, "cdate": 1553716772496, "ddate": null, "tcdate": 1553716772496, "tmdate": 1562083042451, "tddate": null, "forum": "S1lnmLLKu4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "DUAL SPACE LEARNING WITH VARIATIONAL AUTOENCODERS", "authors": ["Hirono Okamoto", "Masahiro Suzuki", "Itto Higuchi", "Shohei Ohsawa", "Yutaka Matsuo"], "authorids": ["h-okamoto@weblab.t.u-tokyo.ac.jp", "masa@weblab.t.u-tokyo.ac.jp", "itto.higuchi@weblab.t.u-tokyo.ac.jp", "ohsawa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "keywords": ["variational autoencoder", "image transfer", "multi-class", "dual space"], "TL;DR": " a new framework using dual space for generating images corresponding to multiclass labels when the number of class is large", "abstract": "This paper proposes a dual variational autoencoder (DualVAE), a framework for generating images corresponding to multiclass labels. Recent research on conditional generative models, such as the Conditional VAE, exhibit image transfer by changing labels. However, when the dimension of multiclass labels is large, these models cannot change images corresponding to labels, because learning multiple distributions of the corresponding class is necessary to transfer an image. This leads to the lack of training data. Therefore, instead of conditioning with labels, we condition with latent vectors that include label information. DualVAE divides one distribution of the latent space by linear decision boundaries using labels. Consequently, DualVAE can easily transfer an image by moving a latent vector toward a decision boundary and is robust to the missing values of multiclass labels. To evaluate our proposed method, we introduce a conditional inception score (CIS) for measuring how much an image changes to the target class. We evaluate the images transferred by DualVAE using the CIS in CelebA datasets and demonstrate state-of-the-art performance in a multiclass setting.", "pdf": "/pdf/41b47b87212549427126034ac5fcc6bf576666b4.pdf", "paperhash": "okamoto|dual_space_learning_with_variational_autoencoders"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "S1lOHaeVc4", "original": null, "number": 2, "cdate": 1555463487845, "ddate": null, "tcdate": 1555463487845, "tmdate": 1556906121253, "tddate": null, "forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Official_Review", "content": {"title": "looks good. I mainly have concerns about the inference procedure.", "review": "This work describes a dual variational autoencoder for image style transfer. Different from CVAE, the conditional assumption here is that a label is dependent on the latent representation of the image. The other contribution is a metric for evaluating conditionally transferred images. \n\nThe paper is generally well-written and explained in most parts. Motivations are clear. The experimental results look good. \n\nHowever, I am not very convinced about the inference procedure of the model, as shown in Equation (3). This looks artificial, since you are feeding the linear combination of the latent and dual code (i.e., the label space) into the decoder. I see no reason why this will give good transferred image, since the decoder is trained with different input. I personally think you can have an inference network which takes the latent code and the label to generate the image. Did I miss something?", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DUAL SPACE LEARNING WITH VARIATIONAL AUTOENCODERS", "authors": ["Hirono Okamoto", "Masahiro Suzuki", "Itto Higuchi", "Shohei Ohsawa", "Yutaka Matsuo"], "authorids": ["h-okamoto@weblab.t.u-tokyo.ac.jp", "masa@weblab.t.u-tokyo.ac.jp", "itto.higuchi@weblab.t.u-tokyo.ac.jp", "ohsawa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "keywords": ["variational autoencoder", "image transfer", "multi-class", "dual space"], "TL;DR": " a new framework using dual space for generating images corresponding to multiclass labels when the number of class is large", "abstract": "This paper proposes a dual variational autoencoder (DualVAE), a framework for generating images corresponding to multiclass labels. Recent research on conditional generative models, such as the Conditional VAE, exhibit image transfer by changing labels. However, when the dimension of multiclass labels is large, these models cannot change images corresponding to labels, because learning multiple distributions of the corresponding class is necessary to transfer an image. This leads to the lack of training data. Therefore, instead of conditioning with labels, we condition with latent vectors that include label information. DualVAE divides one distribution of the latent space by linear decision boundaries using labels. Consequently, DualVAE can easily transfer an image by moving a latent vector toward a decision boundary and is robust to the missing values of multiclass labels. To evaluate our proposed method, we introduce a conditional inception score (CIS) for measuring how much an image changes to the target class. We evaluate the images transferred by DualVAE using the CIS in CelebA datasets and demonstrate state-of-the-art performance in a multiclass setting.", "pdf": "/pdf/41b47b87212549427126034ac5fcc6bf576666b4.pdf", "paperhash": "okamoto|dual_space_learning_with_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Official_Review", "cdate": 1554234181070, "reply": {"forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234181070, "tmdate": 1556906083963, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "S1gg8aFW5V", "original": null, "number": 1, "cdate": 1555303751864, "ddate": null, "tcdate": 1555303751864, "tmdate": 1556906121039, "tddate": null, "forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Official_Review", "content": {"title": "The paper is not well-written and the proposed metric is not justified", "review": "This paper proposes a dual variational autoencoder(DualVAE) model for generating images with multi labels. Compared to the existing methods like conditional VAE, the difference is the introduction of a dual vector to the model, which is a parameter of a decision boundary. The author claims that such a change can avoid the exponential dependency of the number of class. \n\nThe second contribution of the paper is to propose a new metric to evaluate the transferred images corresponding to multiclass labels, i.e. Conditional Inception Score (CIS).\n\nEmpirical studies are conducted on the CelebA dataset. DualVAE achieves better CIS scores than three existing methods.\n\nThe paper is not well-written and hard to follow. Some places are not precisely stated, e.g. \u201cexhibit image transfer by changing labels\u201d in the abstract. The experiment is not convincing, as it only compares different methods on the proposed metric. How do you justify CIS is an appropriate metric?", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DUAL SPACE LEARNING WITH VARIATIONAL AUTOENCODERS", "authors": ["Hirono Okamoto", "Masahiro Suzuki", "Itto Higuchi", "Shohei Ohsawa", "Yutaka Matsuo"], "authorids": ["h-okamoto@weblab.t.u-tokyo.ac.jp", "masa@weblab.t.u-tokyo.ac.jp", "itto.higuchi@weblab.t.u-tokyo.ac.jp", "ohsawa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "keywords": ["variational autoencoder", "image transfer", "multi-class", "dual space"], "TL;DR": " a new framework using dual space for generating images corresponding to multiclass labels when the number of class is large", "abstract": "This paper proposes a dual variational autoencoder (DualVAE), a framework for generating images corresponding to multiclass labels. Recent research on conditional generative models, such as the Conditional VAE, exhibit image transfer by changing labels. However, when the dimension of multiclass labels is large, these models cannot change images corresponding to labels, because learning multiple distributions of the corresponding class is necessary to transfer an image. This leads to the lack of training data. Therefore, instead of conditioning with labels, we condition with latent vectors that include label information. DualVAE divides one distribution of the latent space by linear decision boundaries using labels. Consequently, DualVAE can easily transfer an image by moving a latent vector toward a decision boundary and is robust to the missing values of multiclass labels. To evaluate our proposed method, we introduce a conditional inception score (CIS) for measuring how much an image changes to the target class. We evaluate the images transferred by DualVAE using the CIS in CelebA datasets and demonstrate state-of-the-art performance in a multiclass setting.", "pdf": "/pdf/41b47b87212549427126034ac5fcc6bf576666b4.pdf", "paperhash": "okamoto|dual_space_learning_with_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Official_Review", "cdate": 1554234181070, "reply": {"forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234181070, "tmdate": 1556906083963, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper5/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "r1gx-EFP5V", "original": null, "number": 1, "cdate": 1555694583953, "ddate": null, "tcdate": 1555694583953, "tmdate": 1556906120821, "tddate": null, "forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "This paper proposes a VAE for images with multiple labels and a new evaluation metric called Conditional Inception Score (CIS) that measures the influence of the target class to the image. The experiments are reasonable. "}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DUAL SPACE LEARNING WITH VARIATIONAL AUTOENCODERS", "authors": ["Hirono Okamoto", "Masahiro Suzuki", "Itto Higuchi", "Shohei Ohsawa", "Yutaka Matsuo"], "authorids": ["h-okamoto@weblab.t.u-tokyo.ac.jp", "masa@weblab.t.u-tokyo.ac.jp", "itto.higuchi@weblab.t.u-tokyo.ac.jp", "ohsawa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "keywords": ["variational autoencoder", "image transfer", "multi-class", "dual space"], "TL;DR": " a new framework using dual space for generating images corresponding to multiclass labels when the number of class is large", "abstract": "This paper proposes a dual variational autoencoder (DualVAE), a framework for generating images corresponding to multiclass labels. Recent research on conditional generative models, such as the Conditional VAE, exhibit image transfer by changing labels. However, when the dimension of multiclass labels is large, these models cannot change images corresponding to labels, because learning multiple distributions of the corresponding class is necessary to transfer an image. This leads to the lack of training data. Therefore, instead of conditioning with labels, we condition with latent vectors that include label information. DualVAE divides one distribution of the latent space by linear decision boundaries using labels. Consequently, DualVAE can easily transfer an image by moving a latent vector toward a decision boundary and is robust to the missing values of multiclass labels. To evaluate our proposed method, we introduce a conditional inception score (CIS) for measuring how much an image changes to the target class. We evaluate the images transferred by DualVAE using the CIS in CelebA datasets and demonstrate state-of-the-art performance in a multiclass setting.", "pdf": "/pdf/41b47b87212549427126034ac5fcc6bf576666b4.pdf", "paperhash": "okamoto|dual_space_learning_with_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper5/Decision", "cdate": 1555612281686, "reply": {"forum": "S1lnmLLKu4", "replyto": "S1lnmLLKu4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1555612281686, "tmdate": 1556906094993, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}