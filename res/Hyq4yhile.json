{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488575205244, "tcdate": 1478373170630, "number": 571, "id": "Hyq4yhile", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Hyq4yhile", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "content": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396683949, "tcdate": 1486396683949, "number": 1, "id": "rJNM6MLux", "invitation": "ICLR.cc/2017/conference/-/paper571/acceptance", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "pros:\n - tackles a fundamental problem of interest to many\n - novel approach\n \n cons:\n - originally not evaluated against some reasonable benchmarks. Note: now added or addressed\n - little theoretical development cf MDP theory\n - some remaining questions about the necessity (and ability) to find good time alignments\n \n I personally found the ideas to be quite compelling, and believe that this is likely to inspire future work.\n The experiments represent interesting scenarios for transfer, with the caveat that they are just in simulation.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396684441, "id": "ICLR.cc/2017/conference/-/paper571/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396684441}}}, {"tddate": null, "tmdate": 1484952598497, "tcdate": 1484952598497, "number": 2, "id": "BJCMVzePl", "invitation": "ICLR.cc/2017/conference/-/paper571/official/comment", "forum": "Hyq4yhile", "replyto": "ByFcujGIe", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer4"], "content": {"title": "Updated my rating from 6 to 7", "comment": "I think that the additional work and additional details that the authors include make the paper better. In particular all the baselines are welcomed, and the EM with DTW can be considered a baseline for subsequent work that would be based on this paper. I updated my rating from 6 to 7 (accept)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516144, "id": "ICLR.cc/2017/conference/-/paper571/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516144}}}, {"tddate": null, "tmdate": 1484952328004, "tcdate": 1482004218217, "number": 3, "id": "S1zWvGXNg", "invitation": "ICLR.cc/2017/conference/-/paper571/official/review", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer4"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty). The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pixels (5.4). They exhibit transfer from arms with different number of links, and from a torque-driven arm to a tendon-driven arm.\n\nOne limitation of the paper is that the authors suppose that time alignment is trivial, because the tasks are all episodic and in the same domain. Time alignment is one form of domain adaptation / transfer that is not dealt with in the paper, that could be dealt with through subsampling, dynamic time warping, or learning a matching function (e.g. neural network).\n\nGeneral remarks: The approach is compared to CCA, which is a relevant baseline. However, as the paper is purely experimental, another baseline (worse than CCA) would be to just have the random projections for \"f\" and \"g\" (the embedding functions on the two domains), to check that the bad performance of the \"no transfer\" version of the model is due to over-specialisation of these embeddings. I would also add (for information) that the problem of learning invariant feature spaces is also linked to metric learning (e.g. [Xing et al. 2002]). More generally, no parallel is drawn with multi-task learning in ML. In the case of knowledge transfer (4.1.1), it may make sense to anneal \\alpha.\n\nThe experiments feel a bit rushed. In particular, the performance of the baseline being always 0 (no transfer at all) is uninformative, at least a much bigger sample budget should be tested. Also, why does Figure 7.b contain no \"CCA\" nor \"direct mapping\" results? Another concern that I have with the experiments: (if/how) did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer?\n\nOverall, the study of transfer is most welcomed in RL. The experiments in this paper are interesting enough for publication, but the paper could have been more thorough.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512537476, "id": "ICLR.cc/2017/conference/-/paper571/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper571/AnonReviewer1", "ICLR.cc/2017/conference/paper571/AnonReviewer3", "ICLR.cc/2017/conference/paper571/AnonReviewer4"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512537476}}}, {"tddate": null, "tmdate": 1484948662264, "tcdate": 1484948662264, "number": 9, "id": "HJAnNWgDl", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Note to AC and Reviewers", "comment": "Dear Reviewers and Area Chair,\nThe reviewers for the paper provided a positive evaluation, with suggestions for additional experiments providing comparisons with several prior methods, some clarifications, and brought up the important problem of addressing time-based correspondence alignment. We have edited the paper to include additional experiments that address these issues, and therefore believe that the reviewer concerns about the work have been addressed. We discuss the specifics below.\n\nAnonReviewer 1 Comments: \n\u201cCompared to previous work (Ammar et al. 2015)\u201d\n- Performed this comparison and added the results into the Figures 5 and 8. We found that our method performed significantly better than this prior work. \n\u201cIs it possible to use dynamic time warping (or similar method) to achieve reasonable results?  Robustness to misspecification of the pairing correspondence P seems a major concern.\u201d\n- We introduced an EM style algorithm which removes this assumption. Description of this method are in Section 3.3.2, and results in Figures 5 and 8. \n\u201cmore comparison to other transfer methods, including those listed in Sec.2, would be very valuable\u201d\n- We have implemented several more baselines: KCCA, Unsupervised Manifold Alignment as suggested by Bou Ammar et al, Direct mappings, random projections, CCA in Figures 5 and 8.\n\nAnonReviewer3 Comments: \n\u201cpreferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA\u201d, \u201ccomparisons to related approaches is not very up to date\u201d \n-Performed comparisons to Kernel CCA and Manifold Alignment using Unsupervised Manifold Alignment (Wang and Mahadevan, Bou Ammar et al) and added to our experiments in Figures 5 and 8. \n\nAnonReviewer4 Comments: \n\u201cA limitation of the paper is that the authors suppose that time alignment is trivial [...] could be dealt with through subsampling, dynamic time warping, or learning a matching function\u201d \n-We introduce a new EM style algorithm alternating between feature learning and dynamic time warping. Description is in Section 3.3.2 and results in Figures 5 and 8. \n\u201cAnother baseline (worse than CCA) would be to just have the random projections for \"f\" and \"g\"\u201d\n-We added this comparison in Figures 5 and 8.\n\u201cat least a much bigger sample budget should be tested [...] control for the fact that the embeddings were trained with more iterations in the case of doing transfer\u201d \n- We ran the baseline with a significantly higher sample budget as shown in Table 1. The poor performance is likely due to not enough guided exploration happening without good reward shaping for the baseline. \n\u201cproblem of learning invariant feature spaces is also linked to metric learning [...] no parallel is drawn with Multi-Task learning in ML \u201d\n-The additional references suggested have been added in the Related Work (Section 2).\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1484618866674, "tcdate": 1484618866674, "number": 8, "id": "Syo_hloLl", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Note to reviewers", "comment": "Dear reviewers,\n\nWe have addressed the concerns presented in the reviews, including comparisons to several prior methods and a method for automatically determining alignment, as detailed in the individual reviewer responses. If you have suggestions for additional comparisons, we would be happy to add them in the final version. As such, we hope you will consider adjusting your reviews accordingly. \n\nRegards\nAbhishek, Coline, Yuxuan, Pieter, Sergey"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1484073521921, "tcdate": 1484073020057, "number": 4, "id": "HkEruiMIx", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Summary of Updates (Jan 10)", "comment": "We thank the reviewers for their comments. Most comments asked for additional comparisons and learned state correspondences. \nIn response to reviewer comments, we have added the following to our paper:\n\n1. Learning state correspondences by using an alternating optimization to jointly assign the state pairs in P and learn the embedding functions f and g. This significantly relaxes the assumption that states can be paired by time-step and provides better performance in experiment 1. See section 3.3.2 for a description of this method and figures 5 and 7a for results.\n\n2. All of the comparisons suggested by the reviewers: kernel-CCA, unsupervised manifold alignment (Ammar et al. 2015), and random projections. Results are in Figures 5 and 7a.\n\n3. Connections to metric learning and multitask learning in Section 2.\n\nThe comparisons have been run on experiments 1 and 2 and will be added to experiment 3 for the final version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1484073232773, "tcdate": 1484073232773, "number": 7, "id": "HJFGKozLg", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "SyMMfs-Ve", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Author Response", "comment": "Thank you for pointing out the highly related work by (Ammar et al. 2015) . In order to ensure a fair comparison we use the Matlab code provided by Chang Wang (https://sites.google.com/site/changwangnk/home/ma-html). We find that the unsupervised manifold learning method described in (Wang and Mahadevan 2009) and (Ammar et al. 2015) performs poorly. We suspect that this is because the method relies on pairwise distance and the raw state spaces do not provide a meaningful metric space. Ammar et al use a hand-specified feature mapping phi that provides a good metric space for the method. As we assume no prior knowledge about the state space, we do not have a hand-specific feature mapping in our experiments.\n\nWe would like to clarify that our primary contribution is to learn a feature space in which the source and target states can be compared. This differs from prior work because we do not reconstruct the source states from target states, allowing the embeddings to discard information that is not common. This is more suitable for transferring between robots with varying morphologies.\n\nTo address your comment about assuming correspondences, we have formulated an alternating optimization, alternating between establishing common feature space using current correspondences, and reestablishing correspondences using current feature space and dynamic time warping. This is described in detail in Section 3.3.2, and results are seen in Fig 5, Fig 7a. \n\nAs suggested, we have also run comparisons with several prior methods such as (Ammar et al. 2015), kernel CCA, random projections, CCA and using state mappings instead of embeddings. These results are shown in Figures 5 and 7a, and show the advantage of using our proposed method over several prior methods. Although kernel CCA is quite competitive with our method on the tendon task, it performs very poorly on the button task while our method is able to achieve excellent performance on both.\n\nUnfortunately we could not compare to the work in Raimalwala et al (2016) because it is quite specific to systems which have a single input, a single output, and can be modeled as linear time invariant. Our tasks are nonlinear and have multidimensional states.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1484073133402, "tcdate": 1484073133402, "number": 6, "id": "SkHhdofLl", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "SyEvEhMVg", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Author Response", "comment": "Thank you for bringing up several important points in the review. We have added several more comparisons to our results in Figures 5 and 7a. The first is using random projections, which performs slightly better than no transfer. The second is kernel CCA, and the last is unsupervised manifold learning, using the method presented in (Wang and Mahadevan 2009) and (Ammar et al 2015).  Please see the response to Reviewer 3 for more details on why we believe this last method performs poorly in our settings.\n\n\nAdditionally, we have formulated a method to find the state alignment jointly with the feature embedding as described in Section 3.3.2, allowing us to remove the assumption that the states are aligned by timestep. The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space. Figure 5 shows that this method actually provides better results than just assuming correspondences by time-step."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1484073104966, "tcdate": 1484073104966, "number": 5, "id": "ByFcujGIe", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "S1zWvGXNg", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Author Response", "comment": "Thank you for your review. We agree that assuming a trivial time alignment is somewhat unsatisfying, and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings, described in Section 3.3.2. The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space, as described in Section 3.3.2. Results using this method can be found in Figure 5, Figure 7a. Using this approach usually works better than just assuming timestep correspondences, or as well in the case of well aligned data. \n\nAs per the suggestion of comparing with random projections, we have added a comparison using random projections as feature embeddings. As shown in Figures 5 and 7a, this method achieves a low level of performance in between the CCA method and no transfer. Also, as pointed out in the review we do indeed anneal \\alpha over the course of learning in all our experiments.\n\nAs shown in Table 1, we have run the \u201cNo Transfer\u201d method for 75 iterations (seeing 3 times more samples). A likely reason the no transfer baseline doesn\u2019t work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all, leading to the behavior seen. \n\nFinally, we have added a connection to metric learning in the last paragraph of Section 2, as well as a paragraph on multitask learning (the third paragraph in Section 2).\n\nFigure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period. This figure will contain all comparisons for the final version. Thanks!\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1481978971657, "tcdate": 1481978971657, "number": 2, "id": "SyEvEhMVg", "invitation": "ICLR.cc/2017/conference/-/paper571/official/review", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer3"], "content": {"title": "Transfer learning in RL using a nonlinear CCA like approach ", "rating": "6: Marginally above acceptance threshold", "review": "\nThis paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent. The paper is related to much other work on transfer that uses shared latent spaces, such as CCA and its variants, including manifold alignment and kernel CCA. \n\n\nThe paper reports on experiments using a simple physics simulator between robot arms consisting of three vs. four links. For comparison, a simple CCA based approach is shown, although it would have been preferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA. A three layer neural net is used to construct the latent feature spaces. \n\nThe problem of transfer in RL is extremely important, and receives less attention than it should. This work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent. This is a promising approach. However, the comparisons to related approaches is not very up to date, and the domains are fairly simplistic. There is little by way of theoretical development of the ideas using MDP theory. \n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512537476, "id": "ICLR.cc/2017/conference/-/paper571/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper571/AnonReviewer1", "ICLR.cc/2017/conference/paper571/AnonReviewer3", "ICLR.cc/2017/conference/paper571/AnonReviewer4"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512537476}}}, {"tddate": null, "tmdate": 1481908746513, "tcdate": 1481908746513, "number": 1, "id": "SyMMfs-Ve", "invitation": "ICLR.cc/2017/conference/-/paper571/official/review", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer1"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "The paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks.  A core component of the proposed approach is to use a task-invariant future space, which can be shared between tasks & between agents.\n\nCompared to previous work (Ammar et al. 2015), it seems the main contribution here is to \u201cassume that good correspondences in episodic tasks can be extracted through time alignment\u201d (Sec. 2).  This is an interesting hypothesis. There is also similarity to work by Raimalwala et al (2016), but the authors argue their method is better equipped to handle non-linear dynamics. These are two interesting hypotheses, however I don\u2019t see that they have been verified in the presented empirical results.  In particular, the question of the pairing correspondence seems crucial. What happens when the time alignment is not suitable. Is it possible to use dynamic time warping (or similar method) to achieve reasonable results?  Robustness to misspecification of the pairing correspondence P seems a major concern.\n\nIn general, more comparison to other transfer methods, including those listed in Sec.2, would be very valuable.  The addition of Sec.5.1 is definitely a right step in this direction, but represents a small portion of the recent work on transfer learning.  I appreciate that other methods transfer other pieces of information (e.g. the policy), but still if the end goal is better performance, what is worth transferring (in addition to how to do the transfer) should be a reasonable question to explore.\n\nOverall, the paper tackles an important problem, but this is a very active area of research, and further comparison to other methods would be worthwhile.  The method proposed of transferring the representation is well motivated, cleanly described, and conceptually sound.  The assumption that time alignment can be used for the state pairing seems problematic, and should be further validated.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512537476, "id": "ICLR.cc/2017/conference/-/paper571/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper571/AnonReviewer1", "ICLR.cc/2017/conference/paper571/AnonReviewer3", "ICLR.cc/2017/conference/paper571/AnonReviewer4"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512537476}}}, {"tddate": null, "tmdate": 1481669825459, "tcdate": 1481669825298, "number": 3, "id": "BJFp2x0mg", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Summary of Author Responses", "comment": "To address the reviewers\u2019 questions, we have made the following changes:\n-We added comparisons of our method to using canonical correlation analysis to find the embedding functions F and G (see Figures 5 and 8a)\n-We added comparisons of our method to directly predicting the target states from the source states (see Figures 5, 8a)\n-We have clarified the description of P in Sec 4.1\n-We have added two previous approaches to the related work section.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1481669774021, "tcdate": 1481669774015, "number": 2, "id": "rkIqhe0Qe", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "SygYFjTMx", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Author Response", "comment": "Thank you for the pointers to CCA and the papers using unsupervised manifold alignment. We have added experiments in Figures 5 and 7 using CCA to determine the functions F and G. We find that this method performs poorly because a linear mapping into a common feature space is not sufficiently expressive to capture the complex nonlinear interactions present.\n\nWe have also included included an additional comparison between our method (learning a common embedding between robots) and directly mapping from source states to target states. These comparisons show that using invariant nonlinear embedding functions allows for better transfer than a simple linear mapping or a prediction of the whole source state.\n\nWe find that the Bou Ammar et al. reference addresses a complementary problem to the one we aim to solve. For example, it assumes the presence of a feature mapping phi that provides distances between states, and use these (hand designed) features to assign correspondences between states in the different domains. In contrast, we assume that good correspondences in episodic tasks can be extracted through time alignment, and focus on learning the feature mapping itself. The focus in our work is on learning complex nonlinear mappings from states to a shared feature space.\n\nThe work from Raimalwala et al was very effective in enabling transfer in the LTI single input single output systems considered, but we believe it is not suitable for the nonlinear, more complex systems being considered in our experiments without restrictive linearizations. Additionally these methods also learn a direct mapping between state spaces, rather than mappings to a shared feature space, which as seen from our additional comparisons, do not perform as well.  We have added information about these works to Section 2."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1481669710759, "tcdate": 1481669710754, "number": 1, "id": "SJvUhlCme", "invitation": "ICLR.cc/2017/conference/-/paper571/public/comment", "forum": "Hyq4yhile", "replyto": "SkD6YqJme", "signatures": ["~Coline_Manon_Devin1"], "readers": ["everyone"], "writers": ["~Coline_Manon_Devin1"], "content": {"title": "Author Response", "comment": "Thank you for your questions.\n\n> I was confused by P.  Can you define this more precisely: is it a distribution?  or a mapping?  or a function?: \nP is a set of tuples (s_S, s_T) that put the source and target states into correspondence. The correspondences are used to specify which states should be placed close together in the feature space via the contrastive loss.\n\n\n> The loss equation at the beginning of Sec.4.1 should probably have super-script \u201cj\u201d in the last term:\nYes, that is indeed a typo. We have updated the notation accordingly.\n\n> Did you compare to any other transfer method?  What would be the most appropriate?\nWe have added two comparisons: finding the feature space using canonical correlation analysis, and learning a direct mapping between state spaces of domains. Please see Section 5.1 for further descriptions.\n\n\n> How does the Baseline method do if it gets as much data as the transfer method (i.e. 3 times more for Fig.5 to compare with \u201cAll proxies\u201d):\nWe ran the baseline for a larger number of iterations, and the results are shown in Table 1. These results suggest that the baseline method does not substantially benefit from the additional samples. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287516263, "id": "ICLR.cc/2017/conference/-/paper571/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Hyq4yhile", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper571/reviewers", "ICLR.cc/2017/conference/paper571/areachairs"], "cdate": 1485287516263}}}, {"tddate": null, "tmdate": 1480726974977, "tcdate": 1480726974972, "number": 2, "id": "SkD6YqJme", "invitation": "ICLR.cc/2017/conference/-/paper571/pre-review/question", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer1"], "content": {"title": "Questions", "question": "I was confused by P.  Can you define this more precisely: is it a distribution?  or a mapping?  or a function?\n\nThe loss equation at the beginning of Sec.4.1 should probably have super-script \u201cj\u201d in the last term.\n\nDid you compare to any other transfer method?  What would be the most appropriate?\n\nHow does the Baseline method do if it gets as much data as the transfer method (i.e. 3 times more for Fig.5 to compare with \u201cAll proxies\u201d)\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959208385, "id": "ICLR.cc/2017/conference/-/paper571/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper571/AnonReviewer3", "ICLR.cc/2017/conference/paper571/AnonReviewer1"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959208385}}}, {"tddate": null, "tmdate": 1480599928084, "tcdate": 1480599928077, "number": 1, "id": "SygYFjTMx", "invitation": "ICLR.cc/2017/conference/-/paper571/pre-review/question", "forum": "Hyq4yhile", "replyto": "Hyq4yhile", "signatures": ["ICLR.cc/2017/conference/paper571/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper571/AnonReviewer3"], "content": {"title": "Comparison to other work on feature space construction ", "question": "The most widely used method for constructing latent feature spaces across source and domain tasks is canonical correlational analysis (CCA), invented more than 80 years ago. CCA requires explicit correspondences, but recent work by Wang et al. (ICML 2008, IJCAI 2009, IJCAI 2011, AAAI 2014) on manifold alignment generalizes CCA to allow for weak correspondences, as well as enables other objective functions, such as preserving global distances or local geometry. In recent years, a number of researchers in RL and robotics have used manifold alignment methods to show successful transfer in RL. It would be useful to compare against these methods, both experimentally as well as theoretically. \n\nExamples of such work include: \n\nAmar et al., (\"Unsupervised Cross-Domain Transfer in Policy Gradient Reinforcement Learning via Manifold Alignment\", AAAI 2015) apply manifold alignment to show transfer in RL, such as from inverted pendulum to quad rotor control. Raimalwala et al. (\"A Preliminary Study of Transfer Learning between Unicycle Robots\", AAAI SS 2016) apply a similar approach to show transfer in robotics as well "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "pdf": "/pdf/58005d81a2be1dba738fdb9d0109b9d1e40b74a1.pdf", "TL;DR": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "paperhash": "gupta|learning_invariant_feature_spaces_to_transfer_skills_with_reinforcement_learning", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"], "conflicts": ["cs.berkeley.edu", "eecs.berkeley.edu", "berkeley.edu", "google.com"], "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959208385, "id": "ICLR.cc/2017/conference/-/paper571/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper571/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper571/AnonReviewer3", "ICLR.cc/2017/conference/paper571/AnonReviewer1"], "reply": {"forum": "Hyq4yhile", "replyto": "Hyq4yhile", "writers": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper571/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959208385}}}], "count": 17}