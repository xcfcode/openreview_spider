{"notes": [{"id": "Hyffti0ctQ", "original": "S1eUDhAtKX", "number": 425, "cdate": 1538087802001, "ddate": null, "tcdate": 1538087802001, "tmdate": 1545355429567, "tddate": null, "forum": "Hyffti0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["weigao1996@outlook.com", "wei-y15@mails.tsinghua.edu.cn", "liquanquan@sensetime.com", "qinghongwei@sensetime.com", "wanli.ouyang@sydney.edu.cn", "yanjunjie@outlook.com"], "authors": ["Wei Gao", "Yi Wei", "Quanquan Li", "Hongwei Qin", "Wanli Ouyang", "Junjie Yan"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "gao|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@misc{\ngao2019pruning,\ntitle={{PRUNING} {WITH} {HINTS}: {AN} {EFFICIENT} {FRAMEWORK} {FOR} {MODEL} {ACCELERATION}},\nauthor={Wei Gao and Yi Wei and Quanquan Li and Hongwei Qin and Wanli Ouyang and Junjie Yan},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyffti0ctQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BylzGqwNe4", "original": null, "number": 1, "cdate": 1545005578188, "ddate": null, "tcdate": 1545005578188, "tmdate": 1545354486736, "tddate": null, "forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper425/Meta_Review", "content": {"metareview": "This paper proposes a new framework which combines pruning and model distillation techniques for model acceleration. The reviewers have a consensus on rejection due to limited novelty.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "lack novelty"}, "signatures": ["ICLR.cc/2019/Conference/Paper425/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper425/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["weigao1996@outlook.com", "wei-y15@mails.tsinghua.edu.cn", "liquanquan@sensetime.com", "qinghongwei@sensetime.com", "wanli.ouyang@sydney.edu.cn", "yanjunjie@outlook.com"], "authors": ["Wei Gao", "Yi Wei", "Quanquan Li", "Hongwei Qin", "Wanli Ouyang", "Junjie Yan"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "gao|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@misc{\ngao2019pruning,\ntitle={{PRUNING} {WITH} {HINTS}: {AN} {EFFICIENT} {FRAMEWORK} {FOR} {MODEL} {ACCELERATION}},\nauthor={Wei Gao and Yi Wei and Quanquan Li and Hongwei Qin and Wanli Ouyang and Junjie Yan},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyffti0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper425/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353222044, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper425/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper425/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper425/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353222044}}}, {"id": "SkxjvM-upm", "original": null, "number": 3, "cdate": 1542095459210, "ddate": null, "tcdate": 1542095459210, "tmdate": 1542095459210, "tddate": null, "forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "content": {"title": "Propose a model to combine some existing techniques for model acceleration.", "review": "This paper proposes a new framework which combines pruning and model distillation techniques for model acceleration. Though the ``pruning\u201d (Molchanov et al. (2017)) and hint components already exists, the authors claim to be the first to combine them, and experimentally show the benefit of jointly and iteratively applying the two techniques. The authors show better performance of their new framework over baseline, pruning only method and hint only method on a few standard Vision data set.\n\nThe motivation is clearly conveyed in the paper. As a framework of combining two existing techniques, I expect the framework can stably improve its two components without too much additional time cost. I have some small questions.\n\n--What is the ``additional cost\u201d of your proposed framework. For example, how many iterations do you typically use. For each data set, what time delta you spent to get the performance improvement comparing to pruning only or hint only models.\n--In your iterative algorithm (pseudo code in appendix), the teacher model is only used in the very beginning and final step, though richest information is hidden in the original teacher model. In the intermediate steps, you are fine tuning iteratively without accessing the original teacher model.\n--In your reconstruction step, you said due to the randomness, you do not always use the learned new W. How much your algorithm benefit from this selection strategy?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper425/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["weigao1996@outlook.com", "wei-y15@mails.tsinghua.edu.cn", "liquanquan@sensetime.com", "qinghongwei@sensetime.com", "wanli.ouyang@sydney.edu.cn", "yanjunjie@outlook.com"], "authors": ["Wei Gao", "Yi Wei", "Quanquan Li", "Hongwei Qin", "Wanli Ouyang", "Junjie Yan"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "gao|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@misc{\ngao2019pruning,\ntitle={{PRUNING} {WITH} {HINTS}: {AN} {EFFICIENT} {FRAMEWORK} {FOR} {MODEL} {ACCELERATION}},\nauthor={Wei Gao and Yi Wei and Quanquan Li and Hongwei Qin and Wanli Ouyang and Junjie Yan},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyffti0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "cdate": 1542234464549, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper425/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335721194, "tmdate": 1552335721194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper425/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJl2i4dA3X", "original": null, "number": 2, "cdate": 1541469347729, "ddate": null, "tcdate": 1541469347729, "tmdate": 1541534006316, "tddate": null, "forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "content": {"title": "a pruning-with-hints framework for model acceleration", "review": "In this paper, the authors propose a pruning-with-hints framework for model acceleration.  Via performing pruning and hints iteratively, one can leverage the complementary characteristics of these two approaches to boost performance. \n\nHere are the comments:\n1 The framework seems to be technically sound. However, the novelty is limited. Most techniques (e.g., pruning, hints) have been widely investigated in the literature. Reconstruction can be treated as another type of hints. Furthermore, the integration of these strategies is standard.\n2 In the experiment, the pruning rate is relatively low for larger models and data sets.  Hence, the effectiveness should be further investigated.  Additionally, please compare with the state-of-the-art approaches such as light-weight design (e.g., MobileNet, ShuffleNet).  This can further enhance the motivation of choosing the proposed framework for real-life applications. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper425/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["weigao1996@outlook.com", "wei-y15@mails.tsinghua.edu.cn", "liquanquan@sensetime.com", "qinghongwei@sensetime.com", "wanli.ouyang@sydney.edu.cn", "yanjunjie@outlook.com"], "authors": ["Wei Gao", "Yi Wei", "Quanquan Li", "Hongwei Qin", "Wanli Ouyang", "Junjie Yan"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "gao|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@misc{\ngao2019pruning,\ntitle={{PRUNING} {WITH} {HINTS}: {AN} {EFFICIENT} {FRAMEWORK} {FOR} {MODEL} {ACCELERATION}},\nauthor={Wei Gao and Yi Wei and Quanquan Li and Hongwei Qin and Wanli Ouyang and Junjie Yan},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyffti0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "cdate": 1542234464549, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper425/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335721194, "tmdate": 1552335721194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper425/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyencTJY27", "original": null, "number": 1, "cdate": 1541107091940, "ddate": null, "tcdate": 1541107091940, "tmdate": 1541534006106, "tddate": null, "forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "content": {"title": "interesting combination of two methods but low on novelty", "review": "This paper uses pruning and model distillation iteratively to reduce the model sizes. The pruning step is based on Molchanov et al. (2017). This is followed by a hints step that minimizes the feature map difference between student and teacher. Finally, a reconstruction step is used to restore original weights. Results are shown on CIFAR-10, Imagenet and COCO datasets for classification and pose estimation tasks where PWH reduces model costs with a small loss in accuracy.\n\nThe paper is interesting that it proposes a unique combination of existing methods iteratively to improve the compression rates in modern CNNs. However, given that these methods already exist, the novelty aspect of this paper is low. Furthermore, it is also hard to rebut these methods, since they have been published and extensively evaluated in the respective papers. Nevertheless, it is interesting to note that both methods assist one another in your set of experiments.\n\nIn order to improve the paper and for the reviewers to judge the papers more favorably, the authors can compute the time for reconstruction/hints and demonstrate that it is clearly superior to fine-tuning/re-training and offers a clear advantage. This should be emphasized and articulated in related work and introduction and will help the paper.\n\nHow did you arrive at the magic number of pruning just 256 channels in every step?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper425/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING WITH HINTS: AN EFFICIENT FRAMEWORK FOR MODEL ACCELERATION", "abstract": "In this paper, we propose an efficient framework to accelerate convolutional neural networks. We utilize two types of acceleration methods: pruning and hints. Pruning can reduce model size by removing channels of layers. Hints can improve the performance of student model by transferring knowledge from teacher model. We demonstrate that pruning and hints are complementary to each other. On one hand, hints can benefit pruning by maintaining similar feature representations. On the other hand, the model pruned from teacher networks is a good initialization for student model, which increases the transferability between two networks. Our approach performs pruning stage and hints stage iteratively to further improve the\nperformance. Furthermore, we propose an algorithm to reconstruct the parameters of hints layer and make the pruned model more suitable for hints. Experiments were conducted on various tasks including classification and pose estimation. Results on CIFAR-10, ImageNet and COCO demonstrate the generalization and superiority of our framework.", "keywords": ["model acceleration", "mimic", "knowledge distillation", "channel pruning"], "authorids": ["weigao1996@outlook.com", "wei-y15@mails.tsinghua.edu.cn", "liquanquan@sensetime.com", "qinghongwei@sensetime.com", "wanli.ouyang@sydney.edu.cn", "yanjunjie@outlook.com"], "authors": ["Wei Gao", "Yi Wei", "Quanquan Li", "Hongwei Qin", "Wanli Ouyang", "Junjie Yan"], "TL;DR": "This is a work aiming for boosting all the existing pruning and mimic method.", "pdf": "/pdf/0b8f76189d402de4ecf73ec2373a5df2ab4e931c.pdf", "paperhash": "gao|pruning_with_hints_an_efficient_framework_for_model_acceleration", "_bibtex": "@misc{\ngao2019pruning,\ntitle={{PRUNING} {WITH} {HINTS}: {AN} {EFFICIENT} {FRAMEWORK} {FOR} {MODEL} {ACCELERATION}},\nauthor={Wei Gao and Yi Wei and Quanquan Li and Hongwei Qin and Wanli Ouyang and Junjie Yan},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyffti0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper425/Official_Review", "cdate": 1542234464549, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyffti0ctQ", "replyto": "Hyffti0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper425/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335721194, "tmdate": 1552335721194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper425/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}