{"notes": [{"id": "r1gV3nVKPS", "original": "r1etvPbMDr", "number": 185, "cdate": 1569438891848, "ddate": null, "tcdate": 1569438891848, "tmdate": 1577168276116, "tddate": null, "forum": "r1gV3nVKPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Q8Vy0M0hUb", "original": null, "number": 1, "cdate": 1576798689625, "ddate": null, "tcdate": 1576798689625, "tmdate": 1576800945517, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Decision", "content": {"decision": "Reject", "comment": "This submission has been assessed by three reviewers who scored it 3/1/3, and they have remained unconvinced after the rebuttal. The main issues voiced are the difficult readability of the paper, cryptic at times due to a mix of physical and DL notations, and a lack of sufficient experimentation to support all claims. The reviewers acknowledge the authors' efforts to resolve the main issues but find these efforts insufficient. Thus, this paper cannot be accepted to ICLR2020.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795705050, "tmdate": 1576800252750, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper185/-/Decision"}}}, {"id": "rkePgdaptB", "original": null, "number": 2, "cdate": 1571833838960, "ddate": null, "tcdate": 1571833838960, "tmdate": 1574074771506, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #1", "review": "The paper \"Beyond Classical Diffusion: Ballistic Graph Neural Network\" tackles the problem of graph vertices representation. While most existing works rely on classical random walks on the graph, the paper proposes to cope with the \"speed of diffusion\" problem by introducing ballistic walk.\n\nI noticed the comment of the authors that gives a correction for the introduction. But even with it the paper remains very cryptic, with very few pointers to help the reader in understanding the contribution. The introduction (even corrected) is very abrupt and it is very difficult to understand the problem that the authors propose to attack. The problem is that authors start with mathematical discussions before presenting the manipulated concepts and formalizing the adressed problem. I only understood the adressed problem after seing which are the baselines the proposal is compared with in section 4.2. Also, the introduction does not introduce the proposal at all. \n\nA symptomatic example of the lack of paper positioning is the Related Works section which does not even give a single reference !  A related work section with no related works in it appears to have a limited interest to me...  This section should at least introduce other works in the field of graph embedding, such as those reported as baselines. It would also greatly help to understand the contribution of the paper. Also, the ballistic concept is not introduced at all in section 4. Where does this term comes from ? The proposed approach is completely cryptic, with clearly not enough definition of the notations the algorithm deals with. A global view of the approach, from the input graph to the final representation, would also be required to help the reader to understand the proposal. If the contribution is only a new kind of random walk on a graph, is ICLR the good targeted venue ? If authors think so, they should present their contribution in a representation learning perspective, which would highlight the importance of this new walk for the graph representation learning process. \n\n\nFrom my point of view, without a full re-writting of the paper, this work cannot be published in a conference like ICLR.   ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575602260475, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper185/Reviewers"], "noninvitees": [], "tcdate": 1570237755798, "tmdate": 1575602260489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Review"}}}, {"id": "BklYKnt1jr", "original": null, "number": 5, "cdate": 1572998273452, "ddate": null, "tcdate": 1572998273452, "tmdate": 1573633040869, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "rkePgdaptB", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment", "content": {"title": "some responses", "comment": "Thanks for the review.\nThe section after the introduction is called the speed problem, this section discuss the problem in traditional diffusion based method.\nAnswer: We did not find related work on controlling the diffusion speed of the kernel on GCN, so there is no relevant paper. We now delete the Related Works section. \n\nFor understanding the algorithm:\nWe are deeply sorry for introducing some uncommon mathematic notations, these notations are usually used in physics community, we showed a demonstration in the new manuscript, the one-dimensional case to help you understand. also, this link can be very helpful\nhttps://en.wikipedia.org/wiki/Quantum_walk\nplease see part Discrete Time Quantum Walk, it uses a similar notation as we used in this paper.\n\nAnd this  (we have no interests with this blog author)\nhttps://www.youtube.com/watch?v=EVw90GBU_Rg\nhttps://towardsdatascience.com/creating-a-quantum-walk-with-a-quantum-coin-692dcfa30d90\n\nFor \"...a limited interest to me...\" \nAnswer: We are using a a complete new method. The reviewer should read some graph convolutional papers, like some we mentioned in the baseline experiments. They all use classical diffusion methods.\n\nIf the contribution is only a new kind of random walk on a graph, is ICLR the good targeted venue ?\nAnswer: Yes, random walk on graph is a very important problem. In GCN, random walk is the way you collect the information.\n\nFrom my point of view, without a full re-writting of the paper, this work cannot be published in a conference like ICLR.   \nWe re-write the paper.\n\nThanks "}, "signatures": ["ICLR.cc/2020/Conference/Paper185/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gV3nVKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper185/Authors|ICLR.cc/2020/Conference/Paper185/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175102, "tmdate": 1576860537102, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment"}}}, {"id": "Bkl4EiEtor", "original": null, "number": 7, "cdate": 1573632811607, "ddate": null, "tcdate": 1573632811607, "tmdate": 1573632811607, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "HJxcTdsmcH", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment", "content": {"title": "Regrading the last section: the Discussion", "comment": "The objective of the Discussion part of this paper is to show the reader what on earth the ballistic walk is doing.\nAs we discussed in the new manuscript's introduction part: we already know that the laplacian filter the most GCN use is a low pass filter. \nOur paper proposes the ballistic filter and uses the ballistic walk to gather node representation.\n\nAs discussed, the ballistic walk is faster because it put more weight on more distant nodes within the same number of walking steps. And also, the ballistic distribution is more oscillated, since it oscillates, it gathers more frequency information.\n\nHowever, the direct Fourier analysis of ballistic walk is very hard to define because the ballistic algorithm itself can not be easily translated to some matrix operation.\n\nThus, the purpose of the Discussion part is to show that:\n\nTo some extent(1D), the ballistic walk can be seen as a gaussian high pass filter and contain more information."}, "signatures": ["ICLR.cc/2020/Conference/Paper185/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gV3nVKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper185/Authors|ICLR.cc/2020/Conference/Paper185/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175102, "tmdate": 1576860537102, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment"}}}, {"id": "BJlYXXr1iH", "original": null, "number": 4, "cdate": 1572979489028, "ddate": null, "tcdate": 1572979489028, "tmdate": 1573465634063, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "HJxcTdsmcH", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment", "content": {"title": "Some responses", "comment": "Thanks for reviewing our paper,\nWe apologize and will fix the typos soon. \nSome quick answers:\n- Sec 3, Eq 1 seems to have been taken from Eq 1 in Defferard et. al, however there\u2019s no reference to it and the terms g, U, etc. are not defined. \nThe reference is listed, and the details equations are list in the reference. will add the details of that definition.\n\n - Sec 4, Algo 1 contains the main core of the proposed algorithm, but it\u2019s only defined for the 2D grid case. The notation therein is extremely unclear. What is H_space, H_c? How does one sample \\hat{O}_coin.? The net result is that algorithm is undefined. Without a clear definition of the algorithm, it\u2019s completely unclear what the proposed method does.\nH_space, H_c is defined in our paper, \\hat{O}_coin is also defined, and its a MATRIX, we do not sample matrix. \\hat{O}_coin is defined in the Algorithm, see line 4.\n\nWe are deeply sorry for introducing some uncommon mathematic notations, these notations are usually used in physics community, we showed a demonstration in the new manuscript, the one-dimensional case to help you understand. also, this link can be very helpful\nhttps://en.wikipedia.org/wiki/Quantum_walk\nplease see part Discrete Time Quantum Walk, it uses a similar notation as we used in this paper.\n\nAnd this  (we have no interests with this blog author)\nhttps://towardsdatascience.com/creating-a-quantum-walk-with-a-quantum-coin-692dcfa30d90\nhttps://www.youtube.com/watch?v=EVw90GBU_Rg\n\n - Sec 4.2 is completely unparseable. What is problem setting? What is the metric? How have the baselines been implemented? How has data been split for training/testing?\nWe add more details in the new manuscript.\nWhat is problem setting? it MNIST classification test.\nWhat is the metric?How have the baselines been implemented? It is mentioned in our paper.\n How has data been split for training/testing?\nWE are using MNIST data, MNIST is generated by LeCun, please see http://yann.lecun.com/exdb/mnist/ The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\nWe do NOT split MNIST training/testing because it was splitted.\n\n - Section 5 mentions that one-third params are used to get 97% but no details are provided as to how less params are consumed.\nwe provide 1/3 to show the our method is better, it's a estimation, we do not use the same pipeline, the exact comparison of params is meaningless in this case.\n\n - How is figure 7 generated?\nIt generated use two different walkers with different initial conditions, see the caption.\nThe figure means: for classical diffusion-based method, it put small weight on distant nodes. so when you take a 25 steps, since the speed is $\\frac{1}{\\sqrt{k}}$, the average distance is $\\sim \\sqrt{25}=5$. But as you use ballistic ones, the average distance is much larger and will exceed the image size, for MNIST the image size is 28, if you start from the center, then when you talk around 14 steps ballistic walk, the average weight distance(following the linear transportation speed) will reach $\\sim 14$, thus has the exceeding boundary problem.  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper185/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gV3nVKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper185/Authors|ICLR.cc/2020/Conference/Paper185/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175102, "tmdate": 1576860537102, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment"}}}, {"id": "SylSprN1iB", "original": null, "number": 3, "cdate": 1572976061222, "ddate": null, "tcdate": 1572976061222, "tmdate": 1573464800059, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "HJxnbHqiFB", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment", "content": {"title": "Replies", "comment": "1. The motivation of this method is to accelerate the diffusion speed in a graph. However, as we know, a very severe issue of graph neural network is the over-smoothness issue. The reason is that, in the high layer, the node feature is diffused to far neighbours.  When using the proposed ballistic filter, node features diffuse much faster than the regular GNN. Thus, the over-smoothness will appear in the shallow layer very fast. As a result, we cannot use many layers so that the non-linearity of deep neural networks cannot be fully utilized. Thus, is it necessary to accelerate the diffusion speed for graph neural network?\n\nAnswer:  Yes, It is necessary.\nWhen we are saying ballistic filters are faster, it does not mean the filters are smooth, actually the distribution is very oscillated, please see our updated manuscript, we showed the one-dimensional condition. As you use a oscillated filter, unlike the traditional random walk filters, the ballistic distribution make the nodes distinguishable.\nThe over smooth problem: means after layers and layers, the $L^n$ will become smooth on the spatial region, which becomes a low pass filter. In GCN, as long as you use laplacian based methods(in this paper we call classical diffusion based methods), the distribution will always have a similar shape: The central part of the distribution always larger (or at least equal than the boundary part)\nWhen we exponentially accelerate to diffusion, please see our Figure 15, we show the cumulative distribution of 24th and 25step of ballistic diffusion,  NOTE that now the central part is smaller than than boundary part, in that case over smooth will not happen, and classical diffusion will never reach that shape.\nAlthough the feature diffuses faster, but the shape of distribution has changed, for same number of steps $k$, both ballistic one and classical one hit the $k$-distance boundary, the only difference is the weight they put on the node. \n\nThe figure in this link is the comparison between the one dimensional distribution(classical vs ballistic). \nAs you can see, the classical diffusion is not  oscillated enough, thus resulting in the indistinguishable of node representation.\nhttps://upload.wikimedia.org/wikipedia/commons/4/4b/One_dimensional_quantum_random_walk.png\n\nMy guess is that the only some exponentially accelerated kernels will solve the over-smooth problem.\n\n2. There is only one dataset for  the comparison of the performance of different graph neural networks. More datasets are needed to thoroughly verify the performance of the proposed ballistic graph neural network.\n\nPlease see the updated Manuscript. we run experiments on more datasets.\n\n3. Is it possible to slow down the diffusion speed with the proposed ballistic filter?\nYes, we already slow down to a ballistic to classical region, please see Figure 10, slow down the diffusion to classical case means use Laplacian matrix to extract the feature. If you want to slow down to the localization condition, a simple strategy is control how 'lazy' the random walk is:  for example, take $L=(I+\\alpha D^{-1}A)$, $\\alpha$ controls the speed, smaller $\\alpha$ results in slower speed.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper185/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1gV3nVKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper185/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper185/Authors|ICLR.cc/2020/Conference/Paper185/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175102, "tmdate": 1576860537102, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper185/Authors", "ICLR.cc/2020/Conference/Paper185/Reviewers", "ICLR.cc/2020/Conference/Paper185/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Comment"}}}, {"id": "HJxnbHqiFB", "original": null, "number": 1, "cdate": 1571689732075, "ddate": null, "tcdate": 1571689732075, "tmdate": 1572972628012, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed a new diffusion operation for the graph neural network. Specifically, the ballistic graph neural network does not require to calculate any eigenvalue and can propagate exponentially faster comparing to traditional graph neural network. Extensive experiments have been conducted to verify the performance of the proposed method.\n\n1. The motivation of this method is to accelerate the diffusion speed in a graph. However, as we know, a very severe issue of graph neural network is the over-smoothness issue. The reason is that, in the high layer, the node feature is diffused to far neighbours.  When using the proposed ballistic filter, node features diffuse much faster than the regular GNN. Thus, the over-smoothness will appear in the shallow layer very fast. As a result, we cannot use many layers so that the non-linearity of deep neural networks cannot be fully utilized. Thus, is it necessary to accelerate the diffusion speed for graph neural network?\n\n2. There is only one dataset for  the comparison of the performance of different graph neural networks. More datasets are needed to thoroughly verify the performance of the proposed ballistic graph neural network.\n\n3. Is it possible to slow down the diffusion speed with the proposed ballistic filter?\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575602260475, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper185/Reviewers"], "noninvitees": [], "tcdate": 1570237755798, "tmdate": 1575602260489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Review"}}}, {"id": "HJxcTdsmcH", "original": null, "number": 3, "cdate": 1572219073946, "ddate": null, "tcdate": 1572219073946, "tmdate": 1572972627934, "tddate": null, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "invitation": "ICLR.cc/2020/Conference/Paper185/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper was extremely hard to read or comprehend. It\u2019s riddled with typos, inaccurate notations and undefined variables (see below for a sampling). The authors will need to significantly polish and improve the presentation of the paper. \n\nAfter a few forward and backward passes through the paper, I was able to gather the following high level ideas about the paper:\n(1) This paper is somewhat related to the Defferard et. al, 2016 in that the authors want to define a propagation filter for graph neural networks.\n2) This proposed filter known as \u201cballistic filter\u201d should have the property of allowing fast diffusion through the network. \n(3) The authors claim that the ballistic kernel diffuses @ O(k) as compared to O(\\sqrt k) when compared to traditional GCNs, where k is the number of propagation steps.\n(4) The authors additionally claim that their approach needs one-third the number of parameters.\n(5) The authors provide some plots to visualize the linear diffusion rate of their proposed filter.\n\n--- Issues and clarifications ---\n- Sec 3, Eq 1 seems to have been taken from Eq 1 in Defferard et. al, however there\u2019s no reference to it and the terms g, U, etc. are not defined.\n - Sec 4, Algo 1 contains the main core of the proposed algorithm, but it\u2019s only defined for the 2D grid case. The notation therein is extremely unclear. What is H_space, H_c? How does one sample \\hat{O}_coin.? The net result is that algorithm is undefined. Without a clear definition of the algorithm, it\u2019s completely unclear what the proposed method does.\n - Sec 4.2 is completely unparseable. What is problem setting? What is the metric? How have the baselines been implemented? How has data been split for training/testing?\n - Section 5 mentions that one-third params are used to get 97% but no details are provided as to how less params are consumed.\n - How is figure 7 generated?\n - Sec 8, feel totally unrelated to the paper. There are a whole bunch of random, unmotivated diffusion equations  Eq 6, mentions \u201c.. \\hat{g}(f) decreases as f increases and thus can be seen as a low pass filter\u2026\u201d . This is not true from the formula.\n \n\n --- A sampling of typos ---\nSec 4.1, .. consisits \u2026\nSec 5 \u201cREVISIT\u201d -> \u201cREVISITING\u201d\nFigure 6, text, \u201ccassical\u201d\nSec 6.2 title, \u201cSUMMAY\u201d\nSec 8  \u201caggreated\u201d\nSec 8  t=\\-tau to -\\tau\nSeveral typos with Hardmard, Hadmard instead of Hadamard.\n\nOverall, the major criticisms of this paper:\n - The proposed algorithm is not clear. \n - The authors need much more experimentation to bolster their claims in the paper. It\u2019s completely unclear if fast diffusion even if it were possible will help GNNs perform better on a diverse set of tasks.\n - The paper needs a lot more polish and proof reading to make this paper presentable.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper185/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Beyond Classical Diffusion: Ballistic Graph Neural Network", "authors": ["Yimeng Min"], "authorids": ["minyimen@mila.quebec"], "keywords": ["Graph Convolutional Network", "Diffusion", "Transportation", "Machine Learning"], "TL;DR": "A new perspective on how to collect the correlation between nodes based on diffusion properties.", "abstract": "This paper presents the ballistic graph neural network. Ballistic graph neural network tackles the weight distribution from a transportation perspective and has many different properties comparing to the traditional graph neural network pipeline. The ballistic graph neural network does not require to calculate any eigenvalue. The filters propagate exponentially faster($\\sigma^2 \\sim T^2$) comparing to traditional graph neural network($\\sigma^2 \\sim T$). We use a perturbed coin operator to perturb and optimize the diffusion rate. Our results show that by selecting the diffusion speed, the network can reach a similar accuracy with fewer parameters. We also show the perturbed filters act as better representations comparing to pure ballistic ones. We provide a new perspective of training graph neural network, by adjusting the diffusion rate, the neural network's performance can be improved.", "pdf": "/pdf/c03985e3399fbfabf57bdb30d73668a80f2ee7c9.pdf", "paperhash": "min|beyond_classical_diffusion_ballistic_graph_neural_network", "original_pdf": "/attachment/7a71de95d6cfc82658fd8b656056c0199c15103a.pdf", "_bibtex": "@misc{\nmin2020beyond,\ntitle={Beyond Classical Diffusion: Ballistic Graph Neural Network},\nauthor={Yimeng Min},\nyear={2020},\nurl={https://openreview.net/forum?id=r1gV3nVKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1gV3nVKPS", "replyto": "r1gV3nVKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper185/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575602260475, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper185/Reviewers"], "noninvitees": [], "tcdate": 1570237755798, "tmdate": 1575602260489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper185/-/Official_Review"}}}], "count": 9}