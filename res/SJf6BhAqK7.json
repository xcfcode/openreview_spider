{"notes": [{"id": "SJf6BhAqK7", "original": "S1gVAfRqtQ", "number": 1587, "cdate": 1538088005312, "ddate": null, "tcdate": 1538088005312, "tmdate": 1545355376535, "tddate": null, "forum": "SJf6BhAqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "S1gy4rlzx4", "original": null, "number": 1, "cdate": 1544844583392, "ddate": null, "tcdate": 1544844583392, "tmdate": 1545354532211, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Meta_Review", "content": {"metareview": "All reviewers wrote strong and long reviews with good feedback but do not believe the work is currently ready for publication.\nI encourage the authors to update and resubmit.\n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Good but not good enough"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1587/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352782882, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352782882}}}, {"id": "B1lb42diAX", "original": null, "number": 13, "cdate": 1543371817481, "ddate": null, "tcdate": 1543371817481, "tmdate": 1543371817481, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Summary of revision", "comment": "Thank you to all reviewers for useful feedback on the submission. We have posted a revision with the following changes:\n\nMethod:\nOverall, we edited the method section to make the algorithm more clear, give a clearer introduction to meta-learning and episodic optimization, and better delineate our contributions relative to DP-means and prototypical networks.\n\n--Sec 3.1 \u201cFoundations\u201d section was removed and incorporated into the introduction of the section, under the headings \u201cfew-shot meta-learning\u201d, \u201cprototypes\u201d and \u201cmulti-modal clustering\u201d.\n--Sec 3.2 (\u201cmulti-modal clustering\u201d) was wrapped into section 3 with the bolded \u201cmulti-modal clustering\u201d.\n--Sec 3.3 (\u201ccumulative supervision\u201d) was moved to Sec 3.2\n--Sec 3.4 was moved to Sec 3.1 (\u201cProbabilistic Interpretations and Alternatives\u201d to \u201cProbabilistic interpretations of hard and soft clustering\u201d)\n--Sec 3.5 (Implementation details) was redistributed closer to where it was referred to (as suggested by reviewers).\n--Algorithm 1 was significantly expanded, to include detailed loss computation, cluster creation and assignment steps, and clearer definitions for all variables.\n\nResults:\nWe re-ordered the results section to highlight the importance of multi-modality for super-class classification and unsupervised clustering (section 4.1), followed by our variadic setting with extreme-way and extreme-shot results (section 4.2) and finally confirming SOTA performance for few-shot learning (section 4.3). Captions are expanded throughout to ease standalone interpretation of the tables and figures.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "H1xqRlNo0m", "original": null, "number": 12, "cdate": 1543352530024, "ddate": null, "tcdate": 1543352530024, "tmdate": 1543352530024, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "ryx26SYORm", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Alternative terminology, novelty, and clustering quality", "comment": "> the framework does not present any property of the Bayesian methodology such as the possibility of inference over parameters, uncertainty quantification, or model comparison\n> Even the very standard k-means clustering, or a linear model, can be seen as the limit of Bayesian counterparts, but it would be awkward, and not justified\n\nWe thank the reviewer for articulating this definition of a bayesian method. As we have explained in our first response, unlike k-means, the dp-means algorithm of Kulis et al. 2012 was derived via bayesian nonparametrics and relies on this mathematical framework for inferring the number of clusters, and so we reference this to make the origin and properties of the clustering clear. We welcome the reviewer to suggest an alternative to \"bayesian nonparametric\" (as we did before), but to be more concrete we would like to ask if \"infinite mixture modeling\" would be more apt from the reviewer's perspective?\n\n> I stil think that there is a substantial problem of novelty and clarity\n> the difference with respect to the state of the art resides in the use of algorithm 1 for adaptively adding new centres if needed\n\nThe technical novelty of our work is in sec. 3 and algorithm 1: we make use of dp-means for inferring the number of clusters, define and experiment on three multi-modal clustering variants, develop a method to choose the cluster distance threshold lambda episodically, and mask assignments and the loss to handle both labeled and unlabeled data.\n\nIn our first response, we also highlighted our empirical novelty in exploring any-shot/any-way generalization in our proposed variadic setting and theoretical novelty in deriving a theoretical connection to semi-supervised prototypical networks. Could the reviewer please let us know if they are aware of existing work with these experiments and theory?\n\n> critical aspects: stability, dependence on the parameter \\lambda, uniqueness of the solution\n> proposed use of the method is different from the original formulation of [Kulis 2012], as it is not iterated\n> that the authors \"have not found the method to be sensitive to this [the order of data] in practice\" does not represent a strong motivation\n\nWe thank the reviewer for their consideration of clustering quality. We agree this is important, and so we summarize where it is addressed in our work.\n\n- stability and iterations: The clustering converges and multiple iterations maintain the quality of the results for classification (tables 2, 4, and 5 for example) and unsupervised clustering (table 3). While we noted in the text that one iteration was sufficient to achieve our state-of-the-art results, we will edit to explain that multiple iterations are stable in the camera ready version of the paper.\n- dependence on lambda: Our method includes a procedure for choosing lambda that we make use of throughout our experiments (please see section 3, last paragraph). The quality of our results supports this procedure. \n- robustness and order: Noting the lack of sensitivity to the order of the data was a direct response to the reviewer's concern that different orderings might affect the results. Our empirical results show this is not a weakness.\n\nWe thank the reviewer for these points, which can be further highlighted in a final revision.\n\nLast, we would like to note that we have posted a revision incorporating feedback from the reviews, and request to know if the reviewer finds it to be more clear.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "BkgRXxNoR7", "original": null, "number": 11, "cdate": 1543352358317, "ddate": null, "tcdate": 1543352358317, "tmdate": 1543352358317, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "BkxOEjwOA7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Incorporation of latest feedback (thanks!)", "comment": "Thank you again to the reviewer for their attention to detail. We have incorporated these comments into the algorithm in the revision.\n\n>There are also key sentences in the paper that are misleading/unclear.\n>For example, the sentence \" Unlike DP-means, we include cluster variances\" is a bit odd.... \n\nWe have clarified the language in the methods section with respect to DP-means and our contributions. For example, we changed the above sentence to \u201cWhile we use DP-means for cluster creation, we include cluster variances for reassignment.\u201d Is the latest revision clearer?\n\nWe would like to ask the reviewer, given their significant feedback on the theoretical components of the work, if they could comment on the practical contributions of the work for meta-learning. We are thankful for the improvements in the clarity and accessibility of the work due to the reviewer's comments, and we would appreciate further comments on the contributions of the work with respect to prototypical networks and meta-learning methods more generally. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "ByeUA1EsA7", "original": null, "number": 10, "cdate": 1543352270103, "ddate": null, "tcdate": 1543352270103, "tmdate": 1543352270103, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "rylxGxO_A7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Hard/soft clarification, empirical justification, and verification of experiment correctness", "comment": "We thank the reviewer for their continued attention to the theoretical aspects of the work.\n\n> still not satisfied by the proposed hard-soft hybrid\n> an approach that is more complicated and not very well founded compared to one that has a much better interpretation\n\nWe sympathize with the reviewer\u2019s hope for the empirical dominance of the theoretically pure variants of our method, but in practice we have found that their accuracies are worse than existing results, as well as our hard-soft hybrid. We have incorporated the reviewer\u2019s feedback into our exposition of the hard-soft hybrid and the theoretical ramifications of our choices in the revision. We hope our theoretical coverage and empirical investigation of these variants sets the stage for future work to further reconcile theory and practice.\n\n> though I only see one test on one dataset\n> (and thus more confidence it will work on other datasets)\n\nWe have also experimented on mini-ImageNet to cover both standard few-shot learning benchmarks. In the 5-way 1-shot setting with 5 unlabeled examples per class the results are: BANDE is 49.2%, Ren et al. is 48.6%, soft-soft is 47.1%, and hard-hard is 43%. In further experiments at different shot and way the methods keep this ordering. We included only the most common Omniglot setting in the revision for brevity, but can include a full appendix in the camera-ready version. As an alternative, we could compare all three variants throughout our experimental section. Would the reviewer find that more clear? In the existing text we focused on hard-soft for simplicity of description and comparison with prior work, but could revise this for the camera-ready.\n\n> not clear that a fair, correct experiment was done between \"soft-soft\", \"hard-hard\", and \"hard-soft\"\n\nThank you for raising this important point: we assure the reviewer that the experiments comparing the three variants are correct and fair w.r.t. operation over labeled and unlabeled data and new cluster creation. We have clarified this in the revision of appendix A.4. All three variants have the same labeled and unlabeled scope for reassignment. The difference in clustering condition for algorithm 2 derives from the approximation to the Chinese Restaurant Process as a draw from the base distribution and as such is part of the algorithm. The extended A.4 in the revision better delineates the soft-soft variant, which operates on both labeled and unlabeled examples, and its connection to an infinite mixture extension of Ren et al., which is only valid when iterating over unlabeled examples alone and holding variances constant.\n\n> better approach would be to use the MARGINAL likelihood of x_i being assigned to a new cluster, as in the Gibbs sampler for DP mixtures\n\nWe have clarified A.4 to better indicate that algorithm 2  is the \u201csoft-soft\u201d method, which follows exactly the suggestion of using the marginal probabilities to create a new cluster as in the Neal citation.\n\nTo review, we locate the hard-soft, hard-hard, and soft-soft clustering variants in the text of the revision for further consideration:\n\n- hard-soft is our chosen method given by algorithm 1 and explained in sec. 3.\n- hard-hard is a variant that does not include cluster variances and differs only in the \"UpdateAssignments\" step of algorithm 1, as detailed in sec. 3.1.\n- soft-soft is a variant that incorporates variances throughout, and because it requires more derivation and explanation it is found in appendix A.4 and its algorithm 2, which are referenced from sec. 3.1.\n\nAll three clustering variants presented in this work are novel approaches for end-to-end, multi-modal clustering that extend the accuracy and scope of prototypical networks. We do not intend or claim this work to have a complete theory for nonparametric meta-learning methods, but instead seek to explain the theoretical aspects of our own contributions and existing work on semi-supervised prototypical networks (Ren et al. 2018) that did not have a theoretical interpretation. We leave further theoretical investigation to future work."}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "ryx26SYORm", "original": null, "number": 9, "cdate": 1543177668212, "ddate": null, "tcdate": 1543177668212, "tmdate": 1543177668212, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "rJgo9Hiuam", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "reply", "comment": "I thank the authors for their clarification. However, I am still not very convinced about the use of the terminology made in this work.\n\nThe proposed scheme builds upon an algorithm which was obtained as the zero variance limit of a Bayesian mixture model.\nThis does not justify the term Bayesian non-paramteric for the proposed method. As stated in my first review, the framework does not present any property of the Bayesian methodology such as the possibility of inference over parameters, uncertainty quantification, or model comparison. Even the very standard k-means clustering, or a linear model, can be seen as the limit of Bayesian counterparts, but it would be awkward, and not justified, to present a work using these tools as Bayesian.\n\nI stil think that there is a substantial problem of novelty and clarity. As also noted by reviewer 3, the difference with respect to the state of the art resides in the use of algorithm 1 for adaptively adding new centres if needed. While being of interest, this part deserves further clarifications on the many critical aspects: stability, dependence on the parameter \\lambda, uniqueness of the solution. In the current version of the manuscript these aspects are lightly mentioned and not discussed. The fact that the authors \u201c have not found the method to be sensitive to this in practice\u201d does not represent a strong motivation in favour of the method. Moreover, as already mentioned in my previous review, the proposed use of the method is different from the original formulation of [Kulis 2012], as it is not iterated (\u201cIn this clustering scheme a single pass is sufficient \u2026\u201d). This raises further concerns about stability and robustness of the proposed procedure.\n\nFinally, I apologise for the previous use of the term \u201cuni-modal distribution\u201d. I acknowledge that the proposed method is explicitly built to account for multi-modal ones, and I made a mistake while typing my previous review.  "}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "S1xCeCI9nm", "original": null, "number": 3, "cdate": 1541201397788, "ddate": null, "tcdate": 1541201397788, "tmdate": 1543172423441, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "content": {"title": "Hard to read and relies on unjustified, shifting assumptions ", "review": "Update after Author Rebuttal\n--------------\nAfter reading the rebuttal, I'm pleased that the authors have made significant revisions, but I still think more work is needed. The \"hard/soft\" hybrid approach still lacks justification and perhaps wasn't compared to a soft/soft approach in a fair and fully-correct way (see detailed reply to authors). I also appreciate the efforts on revising clarity, but still find many clarity issues in the newest version that make the method hard to understand let alone reproduce. I thus stand by my rating of \"borderline rejection\" and urge the authors to prepare significant revisions for a future venue that avoid hybrids of hard/soft probabilities without justification. \n\n(Original review text below. Detailed replies to authors are in posts below their responses).\n\nReview Summary\n--------------\nWhile the focus on variadic learning is interesting, I think the present version of the paper needs far more presentational polish as well as algorithmic improvements before it is ready for ICLR. I think there is the potential for some neat ideas here and I hope the authors prepare stronger versions in the future. However, the current version is unfortunately not comprehensible or reproducible.\n\nPaper Summary\n-------------\n\nThe paper investigates developing an effective ML method for the \"variadic\" regime, where the method might be required to perform learning from few or many examples (shots) and few or many classes (ways). The term \"variadic\" comes from use in computer science for functions that can a flexible number of arguments. There may also be unlabeled data available in the few shot case, creating semi-supervised learning opportunities.\n\nThe specific method proposed is called BANDE: Bayesian Nonparametric Deep Embedding. The idea is that each data point's feature vector x_i is transformed into an embedding vector h(x_i) using a neural network, and then clustering occurs in the embedding space via a single-pass of the DP-means algorithm (Kulis & Jordan 2012). Each cluster is assumed to correspond to one \"class\" in the eventual classification problem, though each class might have multiple clusters (and thus be multi-modal).  \n\nLearning occurs in an episodic manner. After each episode (single-pass of DP-means), each point in a query set is embedded to its feature vector, then fed into each cluster's Gaussian likelihoods to produce a normalized cluster-assignment-probability vector that sums to one. This vector is then fed into a cross-entropy loss, where the true class's nearest cluster (largest probability value) is taken to be the true cluster. This loss is used to perform gradient updates of the embedding neural network.\n\nThere is also a \"cumulative\" version of the method called BANDE-C. This version keeps track of cluster means from previous episodes and allows new episodes to be initialized with these.\n\nExperiments examine the proposed approach across image categorization tasks on Omniglot, mini-ImageNet, and CIFAR datasets.\n\n\nStrengths\n---------\n* I like that many clusters are used for each true class label, which is better than rigid one-to-one assumptions.\n\n\nLimitations\n-----------\n* Can only be used for classification, not regression\n* The DP-means procedure does not account for the cluster-specific variance information that is used at other steps of the algorithm\n\n\nSignificance and Originality\n----------------------------\nTo me, the method appears original. Any method that could really succeed across various variadic settings would be significant.\n\n\n\nPresentation Concerns\n---------------------\n\nI have serious concerns about the presentation quality of this paper. Each section needs careful reorganization as well as rewording.\n\n## P1: Algo. 1 contains numerous omissions that make it as written not correct.\n\n* the number of clusters count variable \"n\" is not updated anywhere. As writting this algo can only update one extra cluster beyond the original n.\n* the variable \"c\" is unbound in the else clause. You need a line that clarifies that c = argmin_{c in 1 ... n} d_ic\n\nWould be careful about saying that \"a single pass is sufficient\"... you have *chosen* to do only one pass. When doing k-means, we could also make this choice. Certainly the DP-means objective could keep improving with multiple passes.\n\n## P2: Many figures and tables lack appropriate captions/labels\n\nTable 1: What metric is reported? Accuracy percentage? Not obvious from title/caption. Should also make very clear here how much labeled data was used.\n\nTable 2: What metric is reported? Accuracy percentage? Not obvious from title/caption. Should also make how many labeled and unlabeled examples were used easier to find.\n\n## P3: Descriptions of episodic learning and overall algorithm clarity\n\nReaders unfamiliar with episodic learning are not helped with the limited coverage provided here in 3.1 and 3.2. When exactly is the \"support\" set used and the \"query\" set used? How do unlabeled points get used (both support and query appear fully labeled)? What is n? What is k? What is T? Why are some points in Q denoted with apostrophes but not others? Providing a more formal step-by-step description (perhaps with pseudocode) will be crucial.\n\nIn Sec. 3.2, the paragraph that starts with \"The loss is defined\" is very hard to read and parse. I suggest adding math to formally define the loss with equations. What parameters are being optimized? Which ones are fixed?\n\nAdditionally, in Sec. 3.2: \"computed in the same way as standard prototypical networks\"... what is the procedure exactly? If your method relies on a procedure, you should specify it in this paper and not make readers guess or lookup a procedure elsewhere.\n\n\n## P4: Many steps of the algorithm are not detailed\n\nThe paper claims to set \\lambda using a technique from another paper, but does not summarize this technique. This makes things nearly impossible to reproduce. Please add such details in the appendix.\n\nMajor Technical Concerns\n------------------------\n\n## Alg. 1 concerns: Requires two (not one) passes and mixes hard and soft assingments and different variance assumptions awkwardly\n\nThe BANDE algorithm (Alg. 1) has some unjustified properties. Hard assignment decisions which assume vanishing variances are used to find a closest cluster, but then later soft assignments with non-zero variances are used. This is a bit heuristic and lacks justification... why not use soft assignment throughout? The DP means procedure is derived from a specific objective function that assumes hard assignment. Seems weird to use it for convenience and then discard instead of coming up with the small fix that would make soft assignment consistent throughout.\n\nFurthermore, The authors claim it is a one pass algorithm, but in fact as written in Alg. 1 it seems to require two passes: the first pass keeps an original set of cluster centers fixed and then creates new centers whenever an example's distance to the closest center exceeds \\lambda. But then, the *soft* assignment step that updates \"z\" requires again the distance from each point to all centers be computed, which requires another pass (since some new clusters may exist which did not when the point was first visited). While the new soft values will be close to zero, they will not be *exactly* zero, and thus they matter. \n\n## Unclear if/how cluster-specific variance parameters learned\n\nFrom the text on top of page 4, it seems that the paper assumes that there exist cluster-specific variances \\sigma_c. However, these are not mentioned elsewhere, only a general (not cluster-specific) label variance \\sigma and fixed unlabeled variance sigma_u are used.\n\n## Experiments lack comparison to internal baselines\n\nThe paper doesn't evaluate sensitivity to key fixed hyperparameters (e.g. \\alpha, \\lambda) or compare variants of their approach (with and without soft clustering step, with and without multimodality via DP-means). It is difficult to tell which design choices of the method are most crucial.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "cdate": 1542234197611, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335978604, "tmdate": 1552335978604, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rylxGxO_A7", "original": null, "number": 8, "cdate": 1543172103939, "ddate": null, "tcdate": 1543172103939, "tmdate": 1543172103939, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "B1eAoVj_6m", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Hard/soft approach still lacks justification ....", "comment": "Thanks for clarification on many details. I'm glad you have planned a code release. I hope the revised manuscript also includes enough details that readers don't have to go look at code for every detail. \n\nI'm still not satisfied by the proposed hard-soft hybrid. I suppose it may be \"marginally more accurate in experiments\", though I only see one test on one dataset, where soft-soft accuracy is 98.4 and hard-soft accuracy is 99.0, a difference that seems too small to justify an approach that is more complicated and not very well founded compared to one that has a much better interpretation (and thus more confidence it will work on other datasets).\n\nIt's also not clear that a fair, correct experiment was done between \"soft-soft\", \"hard-hard\", and \"hard-soft\". Alg. 1 (hard-soft) can reassign both labeled and unlabeled data to new clusters. However, Alg. 2 (the hard-hard method) in A.4 only operates on unlabeled examples. (Also, the value of \\sigma_0 is unclear). No formal algorithm is given at all for the soft-soft method.  Note also that the condition for creating a new cluster in Alg. 1 is that the distance to the closest cluster exceeds some threshold. However, in the written hard-hard algorithm, the condition is different: distance to some \\mu_0 which is fixed to 0.0. The better approach would be to use the MARGINAL likelihood of x_i being assigned to a new cluster, as in the Gibbs sampler for DP mixtures (see Eq. 3.7 of Radford Neal's \"Sampling methods for Dirichlet Process Mixture Models\" (http://www.stat.columbia.edu/npbayes/papers/neal_sampling.pdf).\n\nGiven all these concerns, it's unclear if there's really a fair comparison here. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "BkxOEjwOA7", "original": null, "number": 7, "cdate": 1543170864252, "ddate": null, "tcdate": 1543170864252, "tmdate": 1543170864252, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "HJxdpNodTX", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Thanks for your revisions! Quality is improving, but there still some issues that make me reluctant to accept", "comment": "P1: I appreciate the expanded Alg. 1. Definitely an improvement, but there are still some significant issues. \n\n* The first line uses \"C\", but \"C\" hasn't been defined. I think you mean the total number of labeled classes in the dataset \"n_s\".  \n* You should clarify that p(x | mu, sigma) is the Gaussian PDF (e.g. a specific function that evaluates to a probability density)\n* The distance computation of d_ic as written asks if y_i == c. But I think you really want to test if y_i == \\ell_c (the label of class c). Otherwise you'll never be able to reuse new clusters you create, since those clusters will have c > n_s and thus y_i == c will always be false.\n* In the final cross entropy expression, the variable \"c\" is unbound in the right hand term. You want it to be defined by the max, but as written it is a separate variable.\n\nThere are also key sentences in the paper that are misleading/unclear. For example, the sentence \" Unlike DP-means, we include cluster variances\" is a bit odd.... the paper does NOT use any variances for the DP-means part of Alg. 1. However, it does use some variance parameters for later stages. So they haven't changed the DP-means algorithm to include variances, they just use variances in a post-processing step"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "HyxmaXDd0Q", "original": null, "number": 6, "cdate": 1543168955420, "ddate": null, "tcdate": 1543168955420, "tmdate": 1543168955420, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SyltxBsuTm", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Proposed method's multi-modality seems distinct from previous work to me", "comment": "R3, any revised thoughts on novelty based on this careful feedback from the authors?\n\nSeems to me that the difference between previous methods and the current approach is given in Fig. 1.... previous methods assume each class has a single center in the learned feature space (e.g. the left panel in Fig. 1), while the proposed approach allows each class to have multiple centers if needed (the far right panel). This multi-modality makes the proposed method more flexible."}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "rJgo9Hiuam", "original": null, "number": 5, "cdate": 1542137235185, "ddate": null, "tcdate": 1542137235185, "tmdate": 1542239003726, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "BJxN_rsOT7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Bayesian Nonparametric Name, Terminology, and Clustering Details", "comment": "> use of the term \u201cBayesian nonparametric\u201d is inappropriate\n\nThe DP-means clustering method of Kulis et al., which our work adapts to end-to-end optimization for metric learning, is derived through bayesian nonparametric infinite mixture modeling in the limit of zero variance. The existence of the method, and others that share this mathematical framework (Broderick et al. 2013, Roychowdhury et al. 2013, Wang & Zhu 2015), are due to bayesian nonparametrics and identify as such in their titles and text. Not acknowledging this connection could obscure the origin and properties of the method. Does the reviewer have an alternate term in mind?\n\n> paper makes often use of abstract terms and jargon\n\nCould the reviewer please be more precise on this point? We have made our best effort to follow the standard terminology for meta-learning and few-shot learning (Vinyals et al. Finn et al., Snell et al, Ren et al.), but would appreciate knowing specifically where this is confusing, so that it can be more clear for a broader audience.\n\n> procedure is also known to be sensitive to the order by which the data is provided, and this point is not addressed in this work. \n\nWhile it is true that the clustering is dependent on the order of the data, we simply have not found the method to be sensitive to this in practice, although we can include this result in the revision. We note that this dependence is likewise mentioned in Kulis et al. 2012 but they make no mention of it impacting the quality of their results.\n\n> proposed method can adapt to account for uni-modal distributions\n\nOur method critically allows for *multi-modality* in the data distribution for both labeled and unlabeled data, adaptively choosing the number of clusters, unlike the prior work by Snell et al. and Ren et al. that assume fixed numbers of clusters, as do [2, 3, 4, 5] cited in the review. This is explained in Section 3.2 and shown to be crucial for diverse classes like alphabets in Section 4.3 Table 4.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "BJxN_rsOT7", "original": null, "number": 4, "cdate": 1542137195537, "ddate": null, "tcdate": 1542137195537, "tmdate": 1542238949233, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "rJeDOoul2m", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Relation/Contrast to Deep Subspace Embedding, Novelty, and Breadth of Results", "comment": "> proposes a learning method based on deep subspace clustering\n> substantial amount of literature on deep subspace embeddings that proposes very similar methodologies to the one of this paper (e.g. [2-5])\n\nWe thank the reviewer for bringing up deep subspace embedding. While our work and these are generally related by metric learning, they are quite separate in approach and purpose. Ours is a meta-learning approach for multi-modal representation (that is, having an adaptive number of centroids per class) of labeled and unlabeled data, it is optimized for classification tasks, and it is evaluated by generalization to new data and tasks. The cited [2-5] address unsupervised clustering, have fixed numbers of clusters, and are evaluated by clustering metrics on the same data they are optimized on.\n\nMost significantly, these works *do not consider generalization*: the clustering methods are optimized on the data that is to be clustered and do not experiment on held-out tasks/classes as in meta-learning settings like ours. Only [5] can incorporate labeled data, and in their experiments they train and test on the same classes, without generalization, on a tiny synthetic dataset and the Oxford flowers dataset of 17 classes and <1000 images.\n\n[2, 3, 4, 5] learn and evaluate unsupervised and zero-shot clustering models on the same train/test data with the same classes without generalization experiments. [2] cannot incorporate labeled data, requires pre-training, and shows results on the toy datasets of MNIST and STL-10. [3] cannot incorporate labeled data and is only evaluated on the simple face and object datasets Yale B, ORL, and COIL. [4] addresses generative modeling and unsupervised clustering for problems, not few-shot learning and classification, and its experiments are restricted to small-scale datasets with 10 or fewer clusters. [5] focuses on zero-shot learning with a linear auto-encoder on off-the-shelf features, and its \"supervised clustering\" section has only a 3-class synthetic dataset and a 17-class dataset of flower images where the clustering is optimized for the same 17 flower species it is evaluated on.\n\n> novelty of the proposed contribution is questionable\n\nHere is a brief summary of our key, novel contributions:\n\ntechnical novelty: our method is capable of adaptive, multi-modal clustering unlike the fixed, uni-modal clustering of Ren et al. and Snell et al. by our reconciliation of DP-means from Kulis et al. with end-to-end learning (section 3.2).\n\nempirical novelty: we propose and thoroughly investigate our \"variadic\" setting of any-shot/any-way generalization (section 4.2), find that several popular methods degrade in this setting (MAML, Reptile, few-shot graph nets), show that it is possible to learn a large-scale classifier (1692-way character recognition) from small-scale episodic optimization (5-way 1-shot tasks), show that episodic optimization of a prototypical method rivals the accuracy from large-scale SGD optimization of a strong fully-parametric baseline optimized by SGD on CIFAR-10/100, and evaluate few-shot learning of alphabets instead of characters to examine accuracy on more complex data distributions.\n\ntheoretical novelty: We shed further light on prototypical network methods with the lens of probabilistic interpretation. We derive an approximate interpretation of Ren et al. (Appendix A4), which lacked theoretical justification, and explain the direct interpretation of the hard variant of our own method (Section 3.4).\n\n> method is tested on several scenarios and datasets, showing promising results in prediction accuracy\n\nWe thank the reviewer for commenting on our breadth of evaluation and promising results. To reinforce this point, we note that our experiments cover several problem statements: few-shot fully-supervised/semi-supervised classification (Section 4.1, Tables 1 & 2), our proposed variadic setting of any-shot/any-way generalization (Section 4.2), purely unsupervised clustering (Section 4.3, table 3) and transfer learning from super-class training to sub-class recognition (Section 4.3, table 4). We approach each of these problems by meta-learning through episodic optimization of classification tasks, and these experiments focus on generalization to new tasks (of held-out classes, different settings of shot and way, or discovery of sub-classes from super-class training). \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "SyltxBsuTm", "original": null, "number": 3, "cdate": 1542137073508, "ddate": null, "tcdate": 1542137073508, "tmdate": 1542238836429, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "S1xc8-Uchm", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Contrast with Ren et al., Significance of Multi-modal (Many-to-One) Clustering, and Variadic Setting", "comment": "We thank the reviewer for raising three key points of our work: (1) clustering algorithm choices and our difference with Ren et al., (2) our technical contribution of extending prototypical methods to multi-modal representation for handling more complicated data distributions, and (3) our empirical contribution of proposing and thoroughly investigating the variadic setting of any-shot/any-way generalization.\n\n> the contrast to Ren et al, is not provided to the degree it should be\n> only differing in the choice of a different clustering algorithm\n\nThe difference in choice of clustering is crucial:\n- our method is capable of adaptive, multi-modal clustering unlike the fixed, uni-modal clustering of Ren et al. and Snell et al. This gives an improvement of +3 points accuracy on the standard few-shot benchmark of 5-way, 5-shot mini-ImageNet classification (Table 2), extends prototypical nets to problems without any labeled data (see next bullet point), and for more diverse classes like alphabets our accuracy is ~25 points higher.\n- our method handles labeled data by the same clustering rule unlike the heuristics of Ren et al. for unlabeled data, making inference in our method possible for zero labeled examples (of any kind, including meta-data as in zero-shot learning) whereas Ren et al. and Snell et al. are undefined in this setting. Section 4.3 shows high quality clustering without labels (Table 3), and 10-25 point improvements on prior work for learning more diverse classes like alphabets instead of single characters (Table 4), underlining the importance of multiple modes.\n- We shed further light on the choice of clustering with the lens of probabilistic interpretation: we derive an approximate interpretation of Ren et al. (Appendix A4), which lacked theoretical justification, while explaining the direct interpretation of the hard variant of our own method (Section 3.4).\n\n> significance of \"multi-model clustering\" \n\nMulti-modality is a key and distinguishing property of our method that is necessary for the quality of our results. Please refer to figure 1 for a schematic of the difference among Snell et. al, Ren et al., and BANDE (ours): note that having multiple modes lets BANDE more accurately cluster the labeled and unlabeled data alike. Among these methods, only BANDE can adjust its capacity to model simple, compact classes with a single mode while simultaneously modeling diverse, complicated classes with multiple modes. We achieve higher accuracy than Ren et al. for semi-supervised few-shot learning (Table 2). Furthermore, Table 4 in particular highlights the needs for multi-modal representation: a full alphabet is not uni-modal in the learned embedding, unlike a single character, and here we show major (10-25) point gains over the prototypical nets of Snell et al. and Ren et al. that assume each class has a uni-modal data distribution.\n\n> by their definition of \"variadic\", how is this more variadic than Ren et al. or Snell et al.?\n\nSnell et al., Ren et al., and our method do indeed generalize better across shot and way as we show (Figure 2). Our first contribution is in evaluating this generalization at all in our novel experiments: we cover extreme way at 1692 Omniglot classes (Figure 3), extreme shot at zero labeled examples for clustering (Table 3) and at scaling episodic optimization to the supervised learning regime of 50k labeled examples on CIFAR-10 and CIFAR-100. Existing work was restricted to the few-shot settings of Section 4.1 with training/testing on the same way and shot.\n\nBANDE (ours) is more variadic than Ren et al. and Snell et al. in 1. handling the case of purely unlabeled data and 2. handling more diverse data with complicated class distributions such as alphabet classes instead of character classes (section 4.3). We forecast that meta-learning, as it scales to more diverse data distributions, will encounter more tasks like our alphabet recognition experiments in the variety and even hierarchy of classes, where our adaptive, multi-modal clustering helps significantly (Table 4). While we expect further progress to improve on Ren et al., Snell et al., and our own method, the main point here is to encourage this kind of shot/way generalization to reconcile the distant poles of small-scale and large-scale learning.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "HJxdpNodTX", "original": null, "number": 2, "cdate": 1542137024039, "ddate": null, "tcdate": 1542137024039, "tmdate": 1542238744559, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "B1eAoVj_6m", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Incorporation of Presentation Feedback (Thanks!)", "comment": "We now turn to the reviewer's thorough feedback on presentation.\n\nP1: numbers of iterations. In principle, BANDE can be iterated multiple times, as in DP-means. However, in our experiments we found accuracy does not improve with more iterations. We will modify the text to make this more clear. We will also correct the algorithm description to appropriately update n and c with the required two lines (thank you for catching this).\n\nP2: Tables 1 and 2 captions and details. The metric is indeed accuracy percentage, as is standard for these benchmarks, which we are clarifying in our revision (to be posted during the rebuttal period). We appreciate that the semi-supervised setting of Ren et al. has a number of details, which is why we placed the paragraph on semi-supervised episode composition under table 2, and we will incorporate more of this text into the caption to make it easier to find.\n\nP3: episodic learning. We would like to thank the reviewer for commenting on the clarity of our work for readers who do not specialize in meta-learning and few-shot learning. We tried to follow the standard summary in this field (see Ren et al., Finn et al.). While fuller tutorial coverage of few-shot learning would be the most clear, we are constrained by the page limit when explaining the existing settings and our contributions of multi-modality and any-shot/any-way generalization in new settings. We are clarifying few-shot details in captions and the main text in the revision.\n\nP4: setting \u03bb. The technique for setting \u03bb is our own, which we summarize at the end of 3.2: \"We estimate \u03c1 as the variance in the labeled cluster means within an episode, while \u03b1 is treated as a hyperparameter.\" The algebraic expression of \u03bb in terms of \u03c1, \u03b1 is what we borrow from Kulis et al., and we are rewording this for clarity in the revision.\n\n\"computed in the same way as standard prototypical networks\" (section 3.2). This is explained in the last paragraph of 3.1, so we remove it here to avoid redundancy and potential confusion."}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "B1eAoVj_6m", "original": null, "number": 1, "cdate": 1542136998122, "ddate": null, "tcdate": 1542136998122, "tmdate": 1542238694742, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "S1xCeCI9nm", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "content": {"title": "Clarity, Reproducibility, and Details to Resolve Technical Concerns", "comment": "We thank the reviewer for their detailed feedback, in particular the attention to the technical aspects of the clustering steps and probabilistic interpretations in our work, and the comments on clarity and accessibility for audiences less familiar with meta-learning and few-shot learning. We agree with the reviewer on the importance of multi-modal clustering as \"better than rigid, one-to-one assumptions\" of prior work, which we show by experiment on alphabet recognition in section 4.3 and improved semi-supervised few-shot classification in section 4.1. We likewise agree that methods that \"really succeed across various variadic settings would be significant\" which is why we propose it in this work and investigate it by experiment in section 4.2.\n\nRegarding concerns of clarity and reproducibility, we are incorporating the feedback of the reviews into a revision to be posted during the rebuttal period and will release code after decision (omitted here only to preserve anonymity). Our comprehensive code release will cover our model, experimental evaluation and training settings, all few-shot baselines (including prototypical networks, semi-supervised prototypical networks, and our variadic extensions of MAML and few-shot graph networks), and datasets. This will help safeguard reproducibility for future work and serve as a reference implementation of the variadic setting.\n\nWe now clarify our method and experiments to address the reviewer's technical concerns.\n\nhard/soft assignments and probabilistic interpretation: We thank the reviewer for their theoretical precision. We are in full agreement, and wish to point out that we identify and experiment with fully hard (sec. 3.4) and fully soft variants of our method (appendix A4) for this reason of probabilistic justification. We choose the hard-soft hybrid for our main results, as mentioned in the paper, because it is marginally more accurate in experiments. We appreciate the feedback on this point, and are revising the text to make these variants more clear.\n\nnumber of passes/clustering steps: We will clarify our language to use the term \u201cclustering iteration\u201d instead of passes/clustering steps. In the fully hard model, an iteration corresponds to the assignment of all labeled and unlabeled points to clusters, and then an update of the means of all clusters. In the fully soft model, an iteration corresponds to computing soft assignments for all points, and then updating the means. In the hard-soft hybrid, we use the \u201chard\u201d step to compute a set of cluster means, and then perform a \"soft\" clustering step in order to update these cluster means.\n\ncluster-specific variances: \\sigma and \\sigma_u are learned and are shared across all labeled and all unlabeled clusters respectively. \\sigma_c was a typo for \\sigma as it is the variance of class clusters. The only exception to learning these variances, as noted, is Section 4.3 where they are fixed.\n\ninternal baselines/ablations: We agree with the reviewer on this list of ablations/internal baselines, so much so that we have already experimented with them in the development of the method: the selected multi-modal clustering with hard-soft assignment was best. For exposition we chose to focus on the hard-soft variant as our method and compare to competing works like Ren et al. and Finn et al., but for completeness we will include these ablation experiments in our revision to the text (to be posted during the rebuttal period).\n\n\u201cour method can only be used for classification, and not regression\u201d: While true, this weakness holds for prior prototypical methods too by Snell et al. and Ren et al. so our work is no more and no less limited in this regard."}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608626, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJf6BhAqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1587/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1587/Authors|ICLR.cc/2019/Conference/Paper1587/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers", "ICLR.cc/2019/Conference/Paper1587/Authors", "ICLR.cc/2019/Conference/Paper1587/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608626}}}, {"id": "S1xc8-Uchm", "original": null, "number": 2, "cdate": 1541198162247, "ddate": null, "tcdate": 1541198162247, "tmdate": 1541533010644, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "content": {"title": "Novelty is unclear", "review": "The paper proposes a meta-learning method that utilizes unlabeled examples along with labeled examples. The technique proposed is very similar to the one by (Ren et al. 2018), only differing in the choice of a different clustering algorithm (Kulis and Jordan, 2012) instead of soft k-means as used by Ren et al. \n\nI feel the contrast to Ren et al, is not provided to the degree it should be. The Appendix paragraph A4 is not sufficient in terms of explaining why this method is conceptually different or significantly better than the related approach. It is hard for me to certify the merits of their work, including explaining the experimental results.\n\nI also do not understand the significance of \"multi-model clustering\" in this context. Also, by their definition of \"variadic\", how is this more variadic than Ren et al. or Snell et al.?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "cdate": 1542234197611, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335978604, "tmdate": 1552335978604, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJeDOoul2m", "original": null, "number": 1, "cdate": 1540553582715, "ddate": null, "tcdate": 1540553582715, "tmdate": 1541533010440, "tddate": null, "forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "content": {"title": "A work lacking clarity", "review": "This work proposes a learning method based on deep subspace clustering. The method is formulated by identifying a deep data embedding, where clustering is performed in the latent space by a revised version of k-means, inspired by the work [1]. In this way, the proposed method can adapt to account for uni-modal distributions. The authors propose some variations of the framework based on soft cluster assignments, and on cumulative learning of the cluster means.\nThe method is tested on several scenarios and datasets, showing promising results in prediction accuracy.\n\nThe idea presented in this work is reasonable and rather intuitive. However, the paper presentation is often unnecessarily convoluted, and fails in clarifying the key points about the proposed methodology. The paper makes often use of abstract terms and jargon, which sensibly reduce the manuscript clarity and readability. For this reason, in my opinion, it is very difficult to appreciate the contribution of this work, from both methodological and applicative point of view. \n\nRelated to this latter point, the use of the term \u201cBayesian nonparametric\u201d is inappropriate. It is completely unclear in which sense the proposed framework is Bayesian, as it doesn\u2019t present any element related to parameters inference, uncertainty estimation, \u2026 Even the fact that the method uses an algorithm illustrated in [1] doesn\u2019t justifies this terminology, as the clustering procedure used here only corresponds to the limit case of a Dirichlet Process Gibbs Sampler when the covariance parameters goes to zero. Moreover, the original procedure requires the iteration until convergence, while it is here applied with a single pass only. The procedure is also known to be sensitive to the order by which the data is provided, and this point is not addressed in this work. \n\nFinally, the novelty of the proposed contribution is questionable. To my understanding, it may consist in the use of embedding methods based on the approach provided in [1]. However, for the reasons illustrated above, this is not clear. There is also a substantial amount of literature on deep subspace embeddings that proposes very similar methodologies to the one of this paper (e.g. [2-5]).  For this reason, the paper would largely benefit from further clarifications and comparison with respect to these methods.  \n\n\n\n\n\n[1] Kulis and Jordan,  Revisiting k-means: New Algorithms via Bayesian Nonparametrics, ICML 2012\n\n[2] Xie, Junyuan, Ross Girshick, and Ali Farhadi. \"Unsupervised deep embedding for clustering analysis.\" International conference on machine learning. 2016.\n[3] Ji, Pan, et al. \"Deep subspace clustering networks.\" Advances in Neural Information Processing Systems. 2017.\n[4] Jiang, Zhuxi, et al. \"Variational deep embedding: An unsupervised and generative approach to clustering.\" IJCAI 2017\n[5] Kodirov, Elyor, Tao Xiang, and Shaogang Gong. \"Semantic autoencoder for zero-shot learning. CVPR 2017.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1587/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variadic Learning by Bayesian Nonparametric Deep Embedding", "abstract": "Learning at small or large scales of data is addressed by two strong but divided frontiers: few-shot learning and standard supervised learning. Few-shot learning focuses on sample efficiency at small scale, while supervised learning focuses on accuracy at large scale. Ideally they could be reconciled for effective learning at any number of data points (shot) and number of classes (way). To span the full spectrum of shot and way, we frame the variadic learning regime of learning from any number of inputs. We approach variadic learning by meta-learning a novel multi-modal clustering model that connects bayesian nonparametrics and deep metric learning. Our bayesian nonparametric deep embedding (BANDE) method is optimized end-to-end with a single objective, and adaptively adjusts capacity to learn from variable amounts of supervision. We show that multi-modality is critical for learning complex classes such as Omniglot alphabets and carrying out unsupervised clustering. We explore variadic learning by measuring generalization across shot and way between meta-train and meta-test, show the first results for scaling from few-way, few-shot tasks to 1692-way Omniglot classification and 5k-shot CIFAR-10 classification, and find that nonparametric methods generalize better than parametric methods. On the standard few-shot learning benchmarks of Omniglot and mini-ImageNet, BANDE equals or improves on the state-of-the-art for semi-supervised classification.", "keywords": ["meta-learning", "metric learning", "bayesian nonparametrics", "few-shot learning", "deep learning"], "authorids": ["krallen@mit.edu", "skyshin@mit.edu", "shelhamer@cs.berkeley.edu", "jbt@mit.edu"], "authors": ["Kelsey R Allen", "Hanul Shin", "Evan Shelhamer", "Josh B. Tenenbaum"], "TL;DR": "We address any-shot, any-way learning with multi-modal prototypes by connecting bayesian nonparametrics and deep metric learning", "pdf": "/pdf/cd648eb69e56bf18d7996c4d845e029a71f5a1c8.pdf", "paperhash": "allen|variadic_learning_by_bayesian_nonparametric_deep_embedding", "_bibtex": "@misc{\nallen2019variadic,\ntitle={Variadic Learning by Bayesian Nonparametric Deep Embedding},\nauthor={Kelsey R Allen and Hanul Shin and Evan Shelhamer and Josh B. Tenenbaum},\nyear={2019},\nurl={https://openreview.net/forum?id=SJf6BhAqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1587/Official_Review", "cdate": 1542234197611, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJf6BhAqK7", "replyto": "SJf6BhAqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1587/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335978604, "tmdate": 1552335978604, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1587/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 18}