{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124450691, "tcdate": 1518470236230, "number": 277, "cdate": 1518470236230, "id": "SyVvEK1Df", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SyVvEK1Df", "signatures": ["~Lequn_Wang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Cost-Sensitive Learning via Deep Policy ERM", "abstract": "Deep networks for classification are typically trained by maximizing the log likelihood of the training data. However, the conditional probabilities learned in this way are often not well-calibrated and are thus not well-suited for cost-sensitive learning where making different errors incurs different rewards or penalties. In this paper, we propose to directly train neural networks to optimize a cost sensitive loss via Empirical Risk Minimization (ERM). Empirical results show that, with proper initialization, ERM training with cost-sensitive loss outperforms maximum-likelihood training with various form of post-processing on a range of cost-sensitive classification tasks. ", "paperhash": "wang|costsensitive_learning_via_deep_policy_erm", "keywords": ["Deep Learning", "Cost-Sensitive Learning", "Policy Learning", "Classification"], "_bibtex": "@misc{\n  wang2018cost-sensitive,\n  title={Cost-Sensitive Learning via Deep Policy ERM},\n  author={Lequn Wang and Qiantong Xu and Christopher De Sa and Thorsten Joachims},\n  year={2018},\n  url={https://openreview.net/forum?id=SyVvEK1Df}\n}", "authorids": ["lw633@cornell.edu", "qx57@cornell.edu", "cmd353@cornell.edu", "tj36@cornell.edu"], "authors": ["Lequn Wang", "Qiantong Xu", "Christopher De Sa", "Thorsten Joachims"], "TL;DR": "Approach cost sensitive classification with deep neural networks by directly learning a policy via empirical risk minimization", "pdf": "/pdf/08f9cd8a91294fef08bbeba3ba576371408b392b.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582871199, "tcdate": 1520550406769, "number": 1, "cdate": 1520550406769, "id": "HJyMzryKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "signatures": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer3"], "content": {"title": "Simple but effective idea", "rating": "6: Marginally above acceptance threshold", "review": "In the context that there is a cost of misclassifying an example, there is usually mis-calibration issues for the conditional probability. The manuscript proposes to directly optimize the cost-sensitive objective and shows that the proposed approach outperforms post-processing approach with proper tuning, and thus avoid the hassle of having an additional step of post-processing calibration.\n\nThe results seem promising. But it seems that the proposed approach heavily relied on initialization. If trained from scratch, the performance would be much worse. The result of proposed approach in Table 2 is way worse when intermediate loss is from 0.2 to 0.6. The CS Policy (ML init), from my perspective, is another post processing approach, where in the first half epoch the model is trained with normal objective and then fined-tuned in the second half. Having said that, the results are better than other baselines.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cost-Sensitive Learning via Deep Policy ERM", "abstract": "Deep networks for classification are typically trained by maximizing the log likelihood of the training data. However, the conditional probabilities learned in this way are often not well-calibrated and are thus not well-suited for cost-sensitive learning where making different errors incurs different rewards or penalties. In this paper, we propose to directly train neural networks to optimize a cost sensitive loss via Empirical Risk Minimization (ERM). Empirical results show that, with proper initialization, ERM training with cost-sensitive loss outperforms maximum-likelihood training with various form of post-processing on a range of cost-sensitive classification tasks. ", "paperhash": "wang|costsensitive_learning_via_deep_policy_erm", "keywords": ["Deep Learning", "Cost-Sensitive Learning", "Policy Learning", "Classification"], "_bibtex": "@misc{\n  wang2018cost-sensitive,\n  title={Cost-Sensitive Learning via Deep Policy ERM},\n  author={Lequn Wang and Qiantong Xu and Christopher De Sa and Thorsten Joachims},\n  year={2018},\n  url={https://openreview.net/forum?id=SyVvEK1Df}\n}", "authorids": ["lw633@cornell.edu", "qx57@cornell.edu", "cmd353@cornell.edu", "tj36@cornell.edu"], "authors": ["Lequn Wang", "Qiantong Xu", "Christopher De Sa", "Thorsten Joachims"], "TL;DR": "Approach cost sensitive classification with deep neural networks by directly learning a policy via empirical risk minimization", "pdf": "/pdf/08f9cd8a91294fef08bbeba3ba576371408b392b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582871021, "id": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper277/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer1"], "reply": {"forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582871021}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582683011, "tcdate": 1520723040713, "number": 2, "cdate": 1520723040713, "id": "SyKDN1GKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "signatures": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer2"], "content": {"title": "limited originality. Experiments only provide partial information.", "rating": "3: Clear rejection", "review": "The paper proposes a method for dealing with class sensitive classification. It consists in optimizing the Bayes risk for cost sensitive classification and then using the argmax decision rule on the classifier predictions. The classifier output is a softmax. Experiments are performed on image and text classification tasks. Comparisons are performed with ML trained baselines.\n\nThis seems a trivial idea, probably already used several times. This is similar for example to one of the strategies propose in ref. (Kukar et al 1998), but with a different training loss (they used a cost sensitive MSE). Concerning the performance, you mention the cost sensitive loss, but not the classical (0/1 loss) accuracy. Your decision rule being not the cost sensitive Bayes rule, but the 0/1 loss Bayes rule, you should also indicate the corresponding score. The training and decision criteria are different, why? You should also provide the performance with the cost sensitive Bayes decision rule. Also, the title is misleading since in this paper you do not use any policy but a simple argmax decision rule. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cost-Sensitive Learning via Deep Policy ERM", "abstract": "Deep networks for classification are typically trained by maximizing the log likelihood of the training data. However, the conditional probabilities learned in this way are often not well-calibrated and are thus not well-suited for cost-sensitive learning where making different errors incurs different rewards or penalties. In this paper, we propose to directly train neural networks to optimize a cost sensitive loss via Empirical Risk Minimization (ERM). Empirical results show that, with proper initialization, ERM training with cost-sensitive loss outperforms maximum-likelihood training with various form of post-processing on a range of cost-sensitive classification tasks. ", "paperhash": "wang|costsensitive_learning_via_deep_policy_erm", "keywords": ["Deep Learning", "Cost-Sensitive Learning", "Policy Learning", "Classification"], "_bibtex": "@misc{\n  wang2018cost-sensitive,\n  title={Cost-Sensitive Learning via Deep Policy ERM},\n  author={Lequn Wang and Qiantong Xu and Christopher De Sa and Thorsten Joachims},\n  year={2018},\n  url={https://openreview.net/forum?id=SyVvEK1Df}\n}", "authorids": ["lw633@cornell.edu", "qx57@cornell.edu", "cmd353@cornell.edu", "tj36@cornell.edu"], "authors": ["Lequn Wang", "Qiantong Xu", "Christopher De Sa", "Thorsten Joachims"], "TL;DR": "Approach cost sensitive classification with deep neural networks by directly learning a policy via empirical risk minimization", "pdf": "/pdf/08f9cd8a91294fef08bbeba3ba576371408b392b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582871021, "id": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper277/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer1"], "reply": {"forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582871021}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582622347, "tcdate": 1520850036907, "number": 3, "cdate": 1520850036907, "id": "Hy6uV0XYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "signatures": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer1"], "content": {"title": "good results but rather preliminary", "rating": "5: Marginally below acceptance threshold", "review": "The paper interprets a soft-max output deep network as a policy for cost-sensitive learning, and then use deep policy ERM to train a good network for a given cost matrix. Experimental results show that the deep policy ERM achieves better performance than probability calibration models.\n\nPros:\n  * simple idea that empirically works\n  * clear illustration\n\nCons:\n  * not comparing with state-of-the-art cost-sensitive deep learning models in Chung et al., 2016; in fact, Chung et al. highlighted the importance of initialization, which echoes the authors' findings in this paper, but the relationship is not carefully discussed\n  * not comparing with standard cost-sensitive benchmarks like those in Domingos, 1999\n  * the results are good but not surprising in the cost-sensitive literature, as many existing works shows that models trained with cost information can perform better than models trained without the cost information. So the results do not bring much more insights.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cost-Sensitive Learning via Deep Policy ERM", "abstract": "Deep networks for classification are typically trained by maximizing the log likelihood of the training data. However, the conditional probabilities learned in this way are often not well-calibrated and are thus not well-suited for cost-sensitive learning where making different errors incurs different rewards or penalties. In this paper, we propose to directly train neural networks to optimize a cost sensitive loss via Empirical Risk Minimization (ERM). Empirical results show that, with proper initialization, ERM training with cost-sensitive loss outperforms maximum-likelihood training with various form of post-processing on a range of cost-sensitive classification tasks. ", "paperhash": "wang|costsensitive_learning_via_deep_policy_erm", "keywords": ["Deep Learning", "Cost-Sensitive Learning", "Policy Learning", "Classification"], "_bibtex": "@misc{\n  wang2018cost-sensitive,\n  title={Cost-Sensitive Learning via Deep Policy ERM},\n  author={Lequn Wang and Qiantong Xu and Christopher De Sa and Thorsten Joachims},\n  year={2018},\n  url={https://openreview.net/forum?id=SyVvEK1Df}\n}", "authorids": ["lw633@cornell.edu", "qx57@cornell.edu", "cmd353@cornell.edu", "tj36@cornell.edu"], "authors": ["Lequn Wang", "Qiantong Xu", "Christopher De Sa", "Thorsten Joachims"], "TL;DR": "Approach cost sensitive classification with deep neural networks by directly learning a policy via empirical risk minimization", "pdf": "/pdf/08f9cd8a91294fef08bbeba3ba576371408b392b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582871021, "id": "ICLR.cc/2018/Workshop/-/Paper277/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper277/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper277/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper277/AnonReviewer1"], "reply": {"forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper277/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582871021}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573590584, "tcdate": 1521573590584, "number": 204, "cdate": 1521573590243, "id": "rk1yk119G", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SyVvEK1Df", "replyto": "SyVvEK1Df", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cost-Sensitive Learning via Deep Policy ERM", "abstract": "Deep networks for classification are typically trained by maximizing the log likelihood of the training data. However, the conditional probabilities learned in this way are often not well-calibrated and are thus not well-suited for cost-sensitive learning where making different errors incurs different rewards or penalties. In this paper, we propose to directly train neural networks to optimize a cost sensitive loss via Empirical Risk Minimization (ERM). Empirical results show that, with proper initialization, ERM training with cost-sensitive loss outperforms maximum-likelihood training with various form of post-processing on a range of cost-sensitive classification tasks. ", "paperhash": "wang|costsensitive_learning_via_deep_policy_erm", "keywords": ["Deep Learning", "Cost-Sensitive Learning", "Policy Learning", "Classification"], "_bibtex": "@misc{\n  wang2018cost-sensitive,\n  title={Cost-Sensitive Learning via Deep Policy ERM},\n  author={Lequn Wang and Qiantong Xu and Christopher De Sa and Thorsten Joachims},\n  year={2018},\n  url={https://openreview.net/forum?id=SyVvEK1Df}\n}", "authorids": ["lw633@cornell.edu", "qx57@cornell.edu", "cmd353@cornell.edu", "tj36@cornell.edu"], "authors": ["Lequn Wang", "Qiantong Xu", "Christopher De Sa", "Thorsten Joachims"], "TL;DR": "Approach cost sensitive classification with deep neural networks by directly learning a policy via empirical risk minimization", "pdf": "/pdf/08f9cd8a91294fef08bbeba3ba576371408b392b.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}