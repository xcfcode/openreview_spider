{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1391829960000, "tcdate": 1391829960000, "number": 3, "id": "czlkm7LZMQKwJ", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "uuFh8Ny0WPw0B", "replyto": "uuFh8Ny0WPw0B", "signatures": ["anonymous reviewer 98fd"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Some Improvements on Deep Convolutional Neural Network Based Image Classification", "review": "This paper presents a few simple tricks to improve over Krizhevsky's model:\r\n- use full image instead of cropped square by Krizhevsky.\r\n- jitter in image contrast, brightness and color.\r\n- add scales at testing time (+ greedy algorithm to keep it fast).\r\n- extra high-resolution model trained on scaled up patches (essentially adding scales at training time).\r\n- turning off dropout for the last learning rate decrease.\r\n\r\nNovelty: nothing new here, just the application of existing techniques.\r\n\r\nPros:\r\n- very good result on ILSVRC13 classification.\r\n\r\nCons:\r\n- the improvements proposed are not novel but the paper can be made interesting if details are given. For example, instead of just mentioning contrast, brightness and color jitter, explain precisely what operations are taking place here. And what do the .5 and 1.5 values correspond to?\r\n- the greedy algorithm is missing some details: 'starts with the best prediction', how is best defined here? highest confidence? out of which views? how many views are initially computed?\r\n- the training images for the high-res model differs from run-time, scaling up patches of 128x128 is in my opinion not as good as using the full-resolution image directly like at run-time. Although this approach possibly introduces noise that is beneficial for the case of images smaller than 224x224 which need to be scaled up at test time. And as mentioned, this augments the data considerably so it is a good thing."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification", "decision": "submitted, no decision", "abstract": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.", "pdf": "https://arxiv.org/abs/1312.5402", "paperhash": "howard|some_improvements_on_deep_convolutional_neural_network_based_image_classification", "authors": ["Andrew Howard"], "authorids": ["andrewgeraldhoward@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391468760000, "tcdate": 1391468760000, "number": 2, "id": "22dWxQ0r7e3vM", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "uuFh8Ny0WPw0B", "replyto": "uuFh8Ny0WPw0B", "signatures": ["anonymous reviewer a60d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Some Improvements on Deep Convolutional Neural Network Based Image Classification", "review": "This paper goes over data augmentation techniques that give 20% relative improvement over last year's winner of ILSVRC.\r\n\r\nFirst set of improvements is to augment training data with more kinds of distortions -- 2x zoom, different cropping approach. The second set of improvements is to combine predictions on multiple transformed versions of the image.\r\n\r\nBecause there are 90 transformed versions of the image, computing all 90 is too expensive, so they do a greedy approach where they combine predictions until there is 'no additional improvement.'\r\n\r\nThe combination approach is missing important details. How are predictions combined? What does 'no additional improvement' mean in regards to greedy method? This greedy method works on individual examples, but without knowing true labels, what's an 'improvement'?  Graph in Figure 3 shows that greedy method slightly outperforms the method which uses 'full 90 predictions', which seems counter-intuitive, but then I can't tell if it's an error because precise description of combining method is missing\r\n\r\nOverall this paper is slightly interesting because it measures the impact of additional transformations, but hardly novel since these approaches were tried before. Also, it is interesting because it shows that ImageNet is going the way of 'MNIST research', where authors focus on incremental improvements tailored for a specific dataset (in this case -- better cropping) and might not transfer to other datasets"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification", "decision": "submitted, no decision", "abstract": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.", "pdf": "https://arxiv.org/abs/1312.5402", "paperhash": "howard|some_improvements_on_deep_convolutional_neural_network_based_image_classification", "authors": ["Andrew Howard"], "authorids": ["andrewgeraldhoward@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390946400000, "tcdate": 1390946400000, "number": 1, "id": "GGUzJ4SdzZGgQ", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "uuFh8Ny0WPw0B", "replyto": "uuFh8Ny0WPw0B", "signatures": ["anonymous reviewer e5ff"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Some Improvements on Deep Convolutional Neural Network Based Image Classification", "review": "This paper details some training tricks such as transformations, combining multiple scales and different views for ILSVRC challenge which performed pretty well compared to last years winner.\r\n\r\nWhile there is nothing dramatically novel in terms of deep learning model or theory, empirical performance is the invisible hand that guides deep learning and generates buzz. So it is important to publish practical tricks-of-the trade and implementation details that can benefit all researchers."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification", "decision": "submitted, no decision", "abstract": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.", "pdf": "https://arxiv.org/abs/1312.5402", "paperhash": "howard|some_improvements_on_deep_convolutional_neural_network_based_image_classification", "authors": ["Andrew Howard"], "authorids": ["andrewgeraldhoward@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387526760000, "tcdate": 1387526760000, "number": 14, "id": "uuFh8Ny0WPw0B", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "uuFh8Ny0WPw0B", "signatures": ["andrewgeraldhoward@gmail.com"], "readers": ["everyone"], "content": {"title": "Some Improvements on Deep Convolutional Neural Network Based Image Classification", "decision": "submitted, no decision", "abstract": "We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.", "pdf": "https://arxiv.org/abs/1312.5402", "paperhash": "howard|some_improvements_on_deep_convolutional_neural_network_based_image_classification", "authors": ["Andrew Howard"], "authorids": ["andrewgeraldhoward@gmail.com"], "keywords": [], "conflicts": []}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 4}