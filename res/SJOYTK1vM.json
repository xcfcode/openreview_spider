{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1538986803869, "tcdate": 1518472576305, "number": 328, "cdate": 1518472576305, "id": "SJOYTK1vM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJOYTK1vM", "signatures": ["~Julius_Adebayo1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values", "abstract": "Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.", "paperhash": "adebayo|local_explanation_methods_for_deep_neural_networks_lack_sensitivity_to_parameter_values", "keywords": ["Interpretability", "Saliency", "DNNs", "Random", "Weights"], "_bibtex": "@misc{\n  adebayo2018local,\n  title={Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values},\n  author={Julius Adebayo and Justin Gilmer and Ian Goodfellow and Been Kim},\n  year={2018},\n  url={https://openreview.net/forum?id=SJOYTK1vM}\n}", "authorids": ["juliusad@google.com", "gilmer@google.com", "goodfellow@google.com", "beenkim@google.com"], "authors": ["Julius Adebayo", "Justin Gilmer", "Ian Goodfellow", "Been Kim"], "TL;DR": "Local explanations for DNNs remain visually and quantitatively similar to DNNs with learned weights and those with randomized weights.", "pdf": "/pdf/02685eaa1a087a482ea810c95654db28f45503f6.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582781611, "tcdate": 1520632609522, "number": 1, "cdate": 1520632609522, "id": "rJFmQKxtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "signatures": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer3"], "content": {"title": "very insightful paper", "rating": "9: Top 15% of accepted papers, strong accept", "review": "this paper is very well written and insightful.\n\nit made an attempt to address model interpretability in deep learning. the authors provide very curious and interesting results suggesting the interaction between the network architecture and interpretability of the weights via local explanation. I believe this paper would be an asset to the iclr workshop and could spawn many further explorations.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values", "abstract": "Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.", "paperhash": "adebayo|local_explanation_methods_for_deep_neural_networks_lack_sensitivity_to_parameter_values", "keywords": ["Interpretability", "Saliency", "DNNs", "Random", "Weights"], "_bibtex": "@misc{\n  adebayo2018local,\n  title={Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values},\n  author={Julius Adebayo and Justin Gilmer and Ian Goodfellow and Been Kim},\n  year={2018},\n  url={https://openreview.net/forum?id=SJOYTK1vM}\n}", "authorids": ["juliusad@google.com", "gilmer@google.com", "goodfellow@google.com", "beenkim@google.com"], "authors": ["Julius Adebayo", "Justin Gilmer", "Ian Goodfellow", "Been Kim"], "TL;DR": "Local explanations for DNNs remain visually and quantitatively similar to DNNs with learned weights and those with randomized weights.", "pdf": "/pdf/02685eaa1a087a482ea810c95654db28f45503f6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582781412, "id": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper328/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer1"], "reply": {"forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582781412}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582749490, "tcdate": 1520656319844, "number": 2, "cdate": 1520656319844, "id": "HkOpk1-Yz", "invitation": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "signatures": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer2"], "content": {"title": "Work provides only very limited insights", "rating": "4: Ok but not good enough - rejection", "review": "This paper empirically assesses the stability of few (mainly gradient-based) local explanation methods. Results show that explanations are not much affected by random reinitialization of higher layers of the DNN.\n\nAlthough the stability of explanation method is an important research topic, this work provides only very limited insights into the problem.\n1) The lack of sensitivity is empirically measured, but an in-depth analysis of the results is lacking. For instance, it remains unclear if the lack of sensitivity is due to the structure of the DNN model or the imperfection of the evaluated explanation methods. It also remains unclear why the Gradients show a slightly different behavior than the other methods.\n\n2) The authors ignore an important class of explanation methods which decompose the classification function, e.g., LRP (Bach et al. 2015), Excitation Backprop (Zhang et al. 2016), Deep Taylor Decomposition (Montavon et al. 2017). These three closely related methods have advantages in terms of explanation continuity and explanation selectivity over gradient-based approaches (see discussion in Montavon et al. 2018) and thus may show very different behaviour in randomization experiments. Actually, Zhang et al. demonstrated that Excitation Backprop (in contrast to other explanation methods) produces discriminative explanations. Thus, for Excitation Backprop (similare results are expected for alpha-beta LRP and Deep Taylor Decomposition) the signal at higher layers \"does matter\". Therefore, I believe that these three explanation methods will be sensitivity to parameters values and will show very different behaviour in randomization experiments.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values", "abstract": "Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.", "paperhash": "adebayo|local_explanation_methods_for_deep_neural_networks_lack_sensitivity_to_parameter_values", "keywords": ["Interpretability", "Saliency", "DNNs", "Random", "Weights"], "_bibtex": "@misc{\n  adebayo2018local,\n  title={Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values},\n  author={Julius Adebayo and Justin Gilmer and Ian Goodfellow and Been Kim},\n  year={2018},\n  url={https://openreview.net/forum?id=SJOYTK1vM}\n}", "authorids": ["juliusad@google.com", "gilmer@google.com", "goodfellow@google.com", "beenkim@google.com"], "authors": ["Julius Adebayo", "Justin Gilmer", "Ian Goodfellow", "Been Kim"], "TL;DR": "Local explanations for DNNs remain visually and quantitatively similar to DNNs with learned weights and those with randomized weights.", "pdf": "/pdf/02685eaa1a087a482ea810c95654db28f45503f6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582781412, "id": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper328/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer1"], "reply": {"forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582781412}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582695251, "tcdate": 1520712779709, "number": 3, "cdate": 1520712779709, "id": "BkNL3hWKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "signatures": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer1"], "content": {"title": "good paper", "rating": "7: Good paper, accept", "review": "This paper shows that local explanations for DNNs with random-initialized weights are qualitatively and quantitatively similar to explanations produced by DNNs with learned weights. \n\nPros:\nThe paper is clear, the problem is well stated and the method is sound. \n\nCons:\nThe impact of the findings in this paper is unclear. Perhaps the most important point made in the paper is the importance of the architecture over fine-tuning of the weights for explanation tasks (and more in general).", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values", "abstract": "Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.", "paperhash": "adebayo|local_explanation_methods_for_deep_neural_networks_lack_sensitivity_to_parameter_values", "keywords": ["Interpretability", "Saliency", "DNNs", "Random", "Weights"], "_bibtex": "@misc{\n  adebayo2018local,\n  title={Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values},\n  author={Julius Adebayo and Justin Gilmer and Ian Goodfellow and Been Kim},\n  year={2018},\n  url={https://openreview.net/forum?id=SJOYTK1vM}\n}", "authorids": ["juliusad@google.com", "gilmer@google.com", "goodfellow@google.com", "beenkim@google.com"], "authors": ["Julius Adebayo", "Justin Gilmer", "Ian Goodfellow", "Been Kim"], "TL;DR": "Local explanations for DNNs remain visually and quantitatively similar to DNNs with learned weights and those with randomized weights.", "pdf": "/pdf/02685eaa1a087a482ea810c95654db28f45503f6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582781412, "id": "ICLR.cc/2018/Workshop/-/Paper328/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper328/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper328/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper328/AnonReviewer1"], "reply": {"forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper328/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582781412}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573558085, "tcdate": 1521573558085, "number": 66, "cdate": 1521573557742, "id": "SkChCACtM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJOYTK1vM", "replyto": "SJOYTK1vM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values", "abstract": "Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.", "paperhash": "adebayo|local_explanation_methods_for_deep_neural_networks_lack_sensitivity_to_parameter_values", "keywords": ["Interpretability", "Saliency", "DNNs", "Random", "Weights"], "_bibtex": "@misc{\n  adebayo2018local,\n  title={Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values},\n  author={Julius Adebayo and Justin Gilmer and Ian Goodfellow and Been Kim},\n  year={2018},\n  url={https://openreview.net/forum?id=SJOYTK1vM}\n}", "authorids": ["juliusad@google.com", "gilmer@google.com", "goodfellow@google.com", "beenkim@google.com"], "authors": ["Julius Adebayo", "Justin Gilmer", "Ian Goodfellow", "Been Kim"], "TL;DR": "Local explanations for DNNs remain visually and quantitatively similar to DNNs with learned weights and those with randomized weights.", "pdf": "/pdf/02685eaa1a087a482ea810c95654db28f45503f6.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}