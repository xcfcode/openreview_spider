{"notes": [{"id": "rkgW0oA9FX", "original": "Hyx6kDqqYX", "number": 871, "cdate": 1538087881448, "ddate": null, "tcdate": 1538087881448, "tmdate": 1546447542767, "tddate": null, "forum": "rkgW0oA9FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1gXoGggxV", "original": null, "number": 1, "cdate": 1544712859062, "ddate": null, "tcdate": 1544712859062, "tmdate": 1545354507885, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Meta_Review", "content": {"metareview": "The paper proposes an architecture search method based on graph hypernetworks (GHN). The core idea is that given a candidate architecture, GHN predicts its weights (similar to SMASH), which allows for fast evaluation w/o training the architecture from scratch. Unlike SMASH, GHN can operate on an arbitrary directed acyclic graph. Architecture search using GHN is fast and achieves competitive performance. Overall, this is a relevant contribution backed up by solid experiments, and should be accepted.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "interesting contribution, competitive results"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper871/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353053666, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353053666}}}, {"id": "rkg3cupE14", "original": null, "number": 8, "cdate": 1543981204246, "ddate": null, "tcdate": 1543981204246, "tmdate": 1543981204246, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "S1g3LTC9C7", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Thanks for the response", "comment": "Thanks for the further explanation especially on the memory usage. I'm fine with this part.  However, the authors seem not adequatly addressed the other two concerns. \n\nFirst, for the LSTM encoding baseline, I'm not quite sure about the validness of \"the number of neighbours has been conventionally fixed for LSTM representations\" since we can always perform traversal on graph to form a sequence. Even though the authors are right, I'm not convinced about the importance to \"handle a varying number of neighbours\" in NAS, since there are no empirical evidences supporting that. \n\nSecond, the authors have not mentioned anything about code publish/reproducibility. I do agree with the public comment that *the reproduction of code is an essential step to make a solid NAS paper*,  otherwise the community has nothing except yet another paper/(unfair) baseline. I have to be quite conservative to recommend an acceptance if I'm not guaranteed that the experimental results could be reproduced without pain."}, "signatures": ["ICLR.cc/2019/Conference/Paper871/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "rylzxtxbkN", "original": null, "number": 4, "cdate": 1543731434136, "ddate": null, "tcdate": 1543731434136, "tmdate": 1543731434136, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "content": {"comment": "There was a previous question about code availability, and the response was:\n\n\"We cannot say for certain at this moment, but we will consider releasing code after acceptance.\"\n\nI'd just like to emphasize that this would be very important for reproducibility, since there are a lot of moving pieces in this paper and I'm unsure whether the results can be reproduced without code. Also, to give a positive spin, if code was available I would expect a lot more excitement about this paper than otherwise (e.g., the DARTS paper led to a lot of excitement, in large part due to people being able to play with the code right away).\n\nTherefore, I'd appreciate if the authors tried really hard to release their code. Thanks!", "title": "Code availability?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732873, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rkgW0oA9FX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732873}}}, {"id": "rklXC6R5RQ", "original": null, "number": 7, "cdate": 1543331274524, "ddate": null, "tcdate": 1543331274524, "tmdate": 1543423293139, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Overall response to reviewers", "comment": "We thank the reviewers for their comments. In addition to responding to the questions, we have updated the paper accordingly. \n\nRegarding concerns around novelty, we agree that the idea of extending hypernetworks with graph neural networks is a natural one. However, as Reviewer 3 has mentioned, we argue that the design of GHN itself is nontrivial. We investigate how various aspects of the design impact the performance through extensive ablation studies. For example, we show the benefits of a novel forward-backward graph propagation scheme, and stacking GNNs in the depth dimension for parameter sharing on an architectural-motif level. \n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "SkgA5aR5R7", "original": null, "number": 6, "cdate": 1543331221968, "ddate": null, "tcdate": 1543331221968, "tmdate": 1543331221968, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rJgN1Zfz3m", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for their evaluation! To answer the questions:\n\n>> \u201cSection 4.2: It's not entirely clear how this setup allows for variable sized kernels or variable #channels \u2026 is the #channels in each node held fixed with a predefined pattern, or also searched for? Are the channels for each node within a block allowed to vary relative to one another?\u201d\n\nYes, the output of H is as large as the largest parameter tensor and sliced as necessary. The number of channels is held fixed with a predefined pattern (doubling after each reduction). They are not searched for and do not vary relative to one another\n\n>> \u201cDo you sample a new, random architecture at every SGD step during training of the GHN?\u201d\n\nYes, a new, random architecture is sampled at every SGD step during training of the GHN\n\n>> \u201cGPU-days is an okay metric, but it's also problematic, since it will of course depend on the choice of GPU (e.g. you can achieve a 10x speedup just from switching from a 600-series to a V100! How does using 4 GPUS for 1 hour compare to 1 GPU for 4 hours? How does this change if you have more CPU power and can load data faster? What if you're using a DL framework which is faster than your competitor's?) Given that the difference here is an order of magnitude, I don't think it matters, but if authors begin to optimize for GPU-milliseconds then it will need to be better standardized.\u201d\n\nYes, we agree that a standardized metric may be necessary as GPU timings become lower and lower. To be clear, for our experiments, we use a single GTX 1080Ti with PyTorch. Additionally, we don\u2019t find data-loading to be a bottleneck for CIFAR-10.\n\n>>\u201dFor Section 5.3, I found the choice to use unseen architectures a little bit confusing. I think that even for this study, there's no reason to use a held-out set, as we seek to scrutinize the ability of the system to approximate performance even with architectures it *does* see during training. \u201d\n\nWe initially used a repeated held-out set to save computation during earlier experiments. Note that in practice due to the size of the search space, no architecture is seen twice anyways. However, an interesting avenue for future work would be investigating a hypernetwork\u2019s ability to \u2018overfit\u2019 to architectures.\n\n>> \u201cHow much does the accuracy drop when using GHN weights? I would like to see a plot showing true accuracy vs. accuracy with GHN weights for the random-100 networks, as using approximations like this typically results in the approximated weights being substantially worse. I am curious to see just how much of a drop there is.\u201d\n\nRegarding accuracy dropoff:  Please see the updated appendix with plots comparing  accuracy with generated weights vs. trained weights\n\n>>\u201dSection 5.4: it's interesting that performance is stronger when the GHN only sees a few (7) nodes during training, even though it sees 17 nodes during testing. I would expect that the best performance is attained with training-testing parity. Again, as I do not have any expertise in graph neural networks, I'm not sure if this is common (to train on smaller graphs and generalize to larger ones), so if the authors or another reviewer would like to comment and further illuminate this behavior, that would be helpful.\u201d\n\nWe suspect that the GHN has difficulty learning due to the vanishing gradients when passing messages across large graphs. We believe that the forward-backward passing scheme partially addresses this as it reduces the total number of messages passed. Exploring additional methods to help the GHN learn on larger graphs is an interesting avenue for future work.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "S1g3LTC9C7", "original": null, "number": 5, "cdate": 1543331155780, "ddate": null, "tcdate": 1543331155780, "tmdate": 1543331155780, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "HklyTNSthQ", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank the reviewer for their evaluation! \n\nTo answer the questions:\n\n>> \u201cThe authors mention that \u2018the first hypernetwork to generate all the weights of arbitrary CNN networks rather than a subset (Brock et al. 2018)\u2019. I\u2019m sorry that I do not understand the particular meaning of such a statement, especially given the only difference of this work with (Brock et al. 2018) lies in how to represent NN architectures. I am not clear that why encoding via 3D tensor cannot \u201cgenerate all weights\u201d, but can only generate only \u201ca subset\u201d. \n\nThe SMASH encoding method is formulated such that it generates weights only for the 1x1 convolution bottleneck layers. While it certainly may be possible for a to augment SMASH or propose a new 3D tensor encoding method to generate all weights, we are not aware of such a method yet. However, the graph representation lends itself to straightforwardly generate all weights. \n\n\n>> \u201cFurthermore, I\u2019m very curious about the effectiveness of representing the graph using LSTM encoding, and then feeding it to the hypernetworks, since simple LSTM encoding is shown to be very powerful [1]. This at least, should act as a baseline\u201d \n\nUnfortunately, we have not run an LSTM-Hypernet baseline, and are not aware of any existing methods, and we agree this would be interesting future work. However, we do compare with ENAS, which uses a weight sharing mechanism and an LSTM encoding with a controller.  As Reviewer 2 has pointed out, [1] has shown very strong results with an LSTM controller and a continuous optimization method. However, the graph method does carry some distinct advantages. For example, as Reviewer 1 pointed out, the graph representation is flexible enough to handle a varying number of neighbours (where the number of neighbours has been conventionally fixed for LSTM representations).\n\n>> \u201cCan the authors give more insights about why they can search on 9 operators within less than 1 GPU day? I mean that for example ENAS, can only support 5 operators due to GPU memory limitation (on single GPU card). Do the authors use more than one GPU to support the search process? \u201c\n\nFor ENAS, it must store all the parameters in memory because it finds paths in a larger model. Thus the memory requirements are O (KN) where K is the number of operations and N is the number of nodes in the candidate architecture. In contrast, the memory requirement for GHNs is O(N) + O(K) for the candidate architecture and GHN respectively. Thus, memory is not an issue, and we conduct GHN training on a single GTX 1080Ti.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "S1lkmT09CQ", "original": null, "number": 4, "cdate": 1543331094569, "ddate": null, "tcdate": 1543331094569, "tmdate": 1543331094569, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "SJlF5lI52X", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewer for their evaluation! To answer the questions:\n\n>> \u201cI\u2019m also curious about the stability of the algorithm and the confidence of the final results. What would be the standard deviation of the final performance if you repeat the entire experiments from scratch (training GHN+random search+architecture selection) using different random seeds?\u201d\n\nWe did not observe large variance when training the GHN on different seeds, and the variance for 10 architectures selected by the GHN is reported in Table 1.\n\n>> \u201cA related question is whether the final performance can be improved with more compute. The algorithm is terminated at 0.84 GPU day, but I wonder how the performance would change if we keep searching for longer time (with more architecture samples). It would be very informative to see the curve of performance vs search cost.\u201d\n\nTraining was halted after the HyperNetwork showed convergence. We saw conducting the random search for longer lead to marginal improvements. Extending the random search to 4 GPU days gave 97.24 $\\pm$ 0.05, compared to 97.16 $\\pm$ 0.07 using 0.84 GPU days as reported. However, we suspect a more advanced search method would be able to utilize the additional compute time more efficiently. \f\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "SJlF5lI52X", "original": null, "number": 3, "cdate": 1541197968680, "ddate": null, "tcdate": 1541197968680, "tmdate": 1541533621378, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "content": {"title": "Interesting method with solid results. ", "review": "The authors propose to use a graph hypernetwork (GHN) to speedup architecture search. Specifically, the architecture is formulated as a directed acyclic graph, which will be encoded by the (bidirectional) GHN as a dense vector for performance prediction. The prediction from GHN is then used as a proxy of the final performance during random search. The authors empirically show that GHN + random search is not only efficient but also performs competitively against the state-of-the-art. Additional results also suggest predictions from GHN is well correlated with the ground truth obtained by the standard training procedure. \n\nThe paper is well-written and technically sound. While the overall workflow of hypernets + random search resembles that of SMASH (Brock et al., 2018), the architecture of GHN itself is a nontrivial and useful contribution. I particularly like the facts that (1) GHN seems flexible enough to handle richer topologies than many prior works (where each node in the graph is typically restricted to have a fixed number of neighbors), thanks to graphnets (2) the authors have provided convincing empirical evidence to back up their design choices about GHN through ablation studies.\n\nIn terms of experiments, perhaps one missing piece is to investigate alternative hypernet architectures in a controlled setting. For example, the authors could have implemented the tensor encoding scheme as in SMASH in their codebase to compare the capabilities of graph vs. non-graph structured hypernetworks. \n\nI\u2019m also curious about the stability of the algorithm and the confidence of the final results. What would be the standard deviation of the final performance if you repeat the entire experiments from scratch (training GHN+random search+architecture selection) using different random seeds?\n\nA related question is whether the final performance can be improved with more compute. The algorithm is terminated at 0.84 GPU day, but I wonder how the performance would change if we keep searching for longer time (with more architecture samples). It would be very informative to see the curve of performance vs search cost.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "cdate": 1542234358052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822074, "tmdate": 1552335822074, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HklyTNSthQ", "original": null, "number": 2, "cdate": 1541129399400, "ddate": null, "tcdate": 1541129399400, "tmdate": 1541533621172, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "content": {"title": "Combing Graph Neural Networks and Hyper Networks for NAS", "review": "This paper proposes using graph neural network (GNN) as hypernetworks to generate free weight parameters for arbitrary CNN architectures. The achieved performance is satisfactory (e.g., error rate < 3 on CIFAR-10 with cutout). I\u2019m particularly interested in the results on ImageNet: it seems the discovered arch on CIFAR-10 (with less than 1 GPU day) successfully transferred to ImageNet. \n\nGenerally speaking, the paper is comprehensive in studying the effects of GNN acting as hypernetworks for NAS.  The idea is clear, and the experiments are satisfactory. There are no technical flaws per my reading. The writing is also easy to follow.\nOn the other hand, the extension of using GNN is indeed natural and straightforward compared with (Brock et al. 2018). Towards that end, the contribution and novelty of the paper is largely marginal and not impressive. \n\nQuestion: \n1.\tThe authors mention that \u2018the first hypernetwork to generate all the weights of arbitrary CNN networks rather than a subset (Brock et al. 2018)\u2019. I\u2019m sorry that I do not understand the particular meaning of such a statement, especially given the only difference of this work with (Brock et al. 2018) lies in how to represent NN architectures. I am not clear that why encoding via 3D tensor cannot \u201cgenerate all weights\u201d, but can only generate only \u201ca subset\u201d. Furthermore, I\u2019m very curious about the effectiveness of representing the graph using LSTM encoding, and then feeding it to the hypernetworks, since simple LSTM encoding is shown to be very powerful [1]. This at least, should act as a baseline. \n\n2.\tCan the authors give more insights about why they can search on 9 operators within less than 1 GPU day? I mean that for example ENAS, can only support 5 operators due to GPU memory limitation (on single GPU card). Do the authors use more than one GPU to support the search process? \nFinally, given the literature of NAS is suffering from the issue of reproduction, I do hope the authors could release their codes and detailed pipelines. \n\n[1] Luo, Renqian, et al. \"Neural architecture optimization.\" NIPS (2018).\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "cdate": 1542234358052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822074, "tmdate": 1552335822074, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJgN1Zfz3m", "original": null, "number": 1, "cdate": 1540657371520, "ddate": null, "tcdate": 1540657371520, "tmdate": 1541533620966, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "content": {"title": "Review 1 for \"Graph HyperNetworks for Neural Architecture Search\"", "review": "This paper proposes to accelerate architecture search by replacing the expensive inner loop (wherein candidate architectures are trained to completion) with a HyperNetwork which predicts the weights of candidate architectures, as in SMASH. Contrary to SMASH, this work employs a Graph neural network to allow for the use of any feedforward architecture, enabling fast architecture search through parameter prediction using highly performant search spaces. The authors test their system and show that performance using Graph HyperNet-generated weights correlates with performance when trained normally. The authors benchmark their method against competing approaches (\"traditional\" NAS techniques which incur the full expense of the inner loop, and one-shot techniques which learn a large model then select architectures by searching for paths in said model) and show competitive performance.\n\nThis is a solid technical contribution with a well-designed set of experiments. While the novelty is not especially high, the paper does a good job of synthesizing existing tools and achieves reasonably strong results with much less compute, making for a strong entry into the growing table of fast architecture search methods. I argue in favor of acceptance.\n\nNotes:\n\n-Whereas SMASH is limited to architectures which can be described with its proposed encoding scheme, GHNs only requires that the architecture be represented as a graph (which, to my knowledge, means it can handle any feedforward architecture). \n\n-Section 4.2: It's not entirely clear how this setup allows for variable sized kernels or variable #channels. Is the output of H simply as large as the largest allowable parameter tensor, and sliced as necessary? A snippet of code might be more illuminating here than a set of equations. Additionally (I may have missed this in the text) is the #channels in each node held fixed with a predfined pattern, or also searched for? Are the channels for each node within a block allowed to vary relative to one another?\n\n-Do you sample a new, random architecture at every SGD step during training of the GHN?\n\n-I have no expertise in graph neural networks, and I cannot judge the efficacy of this scheme wrt other GNN techniques, nor can I judge the forward-backward message passing scheme of section 4.4. If another reviewer has expertise in this area and can provide an evaluation that would be great.\n \n-GPU-days is an okay metric, but it's also problematic, since it will of course depend on the choice of GPU (e.g. you can achieve a 10x speedup just from switching from a 600-series to a V100! How does using 4 GPUS for 1 hour compare to 1 GPU for 4 hours? How does this change if you have more CPU power and can load data faster? What if you're using a DL framework which is faster than your competitor's?) Given that the difference here is an order of magnitude, I don't think it matters, but if authors begin to optimize for GPU-milliseconds then it will need to be better standardized.\n \n-Further empirical evidence showing the correlation between approximate performance and true performance is also strong. I very much like that this study has been run for a method based on finding paths in a larger model (ENAS) and shows that ENAS' performance does indeed correlate with true performance, *but* not perfectly, something which (if I recall correctly) is not addressed in the original paper.\n \n-It is worth noting that for ImageNet-Mobile and CIFAR-10 they perform on par with the top methods but tend to use more parameters.  \n\n-I like figures 3 and 4, the comparisons against MSDNet and random networks as a function of op budget is good to see.\n\n-Table 4 shows that the correlation is weaker (regardless of method) for the top architectures, which I don't find surprising as I would expect the variation in performance amongst top architectures to be lower. It would be interesting to also see what the range of error rates are; I would expect that the correlation is higher when the range of error rates across the population of architectures is large, as it is easier to distinguish very bad architectures from very good architectures. Distinguishing among a set of good-to-very-good architectures is likely to be more difficult.\n\n-For Section 5.3, I found the choice to use unseen architectures a little bit confusing. I think that even for this study, there's no reason to use a held-out set, as we seek to scrutinize the ability of the system to approximate performance even with architectures it *does* see during training. \n\n-How much does the accuracy drop when using GHN weights? I would like to see a plot showing true accuracy vs. accuracy with GHN weights for the random-100 networks, as using approximations like this typically results in the approximated weights being substantially worse. I am curious to see just how much of a drop there is.\n\n-Section 5.4: it's interesting that performance is stronger when the GHN only sees a few (7) nodes during training, even though it sees 17 nodes during testing. I would expect that the best performance is attained with training-testing parity. Again, as I do not have any expertise in graph neural networks, I'm not sure if this is common (to train on smaller graphs and generalize to larger ones), so if the authors or another reviewer would like to comment and further illuminate this behavior, that would be helpful.\n\nSome typos:\n\nAbstract: \"prematured\"  should be \"premature\"\n\nIntroducton, last paragraph: \"CNN networks.\" CNN already stands for Convolutional Neural Network.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Review", "cdate": 1542234358052, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335822074, "tmdate": 1552335822074, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJgpSxAQ27", "original": null, "number": 3, "cdate": 1540771908846, "ddate": null, "tcdate": 1540771908846, "tmdate": 1540821185631, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "SkxLWX-e2m", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Thanks", "comment": "The top-5 is 91.3\nWe will also update the paper. \nEDIT: Corrected top-5 value."}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "SkxLWX-e2m", "original": null, "number": 3, "cdate": 1540522749693, "ddate": null, "tcdate": 1540522749693, "tmdate": 1540522749693, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rJxZH6PLsX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "content": {"comment": "Thanks for your reply.\nMay I ask the top-5 accuracy of \"GHN Top-Best, 1K\" in Table 3?", "title": "Thanks for your reply."}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732873, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rkgW0oA9FX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732873}}}, {"id": "rJxZH6PLsX", "original": null, "number": 2, "cdate": 1539894584916, "ddate": null, "tcdate": 1539894584916, "tmdate": 1539894623528, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rJl4OSAVo7", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "We are happy to answer any more questions!", "comment": "Hi,\n\n1. We will update the paper with the specific number of FLOPS.\n2. 1x1 convolution means \"ReLU-1x1Conv-BN\"\n\nThanks again!"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "rJl4OSAVo7", "original": null, "number": 2, "cdate": 1539790188016, "ddate": null, "tcdate": 1539790188016, "tmdate": 1539790188016, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "HygnM4GEs7", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "content": {"comment": "Thanks for your reply. I still have two questions :)\n1. Table 3 misses the FLOPs for each method. Since we care about the computation cost on ImageNet, most previous methods show the FLOPs. I understand that the mobile set is < 600M FLOPs, but more precious FLOPs can always be helpful.\n2. Does \"1x1 convolution\" mean \"ReLU-1x1Conv-BN (3 layers)\"? Or a stack of two 1x1 Conv like the separable conv? \n\nBest Regards,", "title": "Most of my concerns are addressed."}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732873, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rkgW0oA9FX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732873}}}, {"id": "HygnM4GEs7", "original": null, "number": 1, "cdate": 1539740692074, "ddate": null, "tcdate": 1539740692074, "tmdate": 1539740692074, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "S1lpn7Pcc7", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "content": {"title": "Thank you for your interest!", "comment": "(1)\nFor Table 2, the process takes 6 hours (GHN training) + 4 hours (15 sec/model evaluating) + 10 hours (retraining top 10 to select top 1). Note that 4 hours is an overestimate, as the code is not heavily optimized.\nFor Table 1, there is no retraining phase.\n\n(2)\nFollowing (Liu et al., 2018c; Pham et al., 2018) , the first conv actually has 3x the number of channels F. So (F=32) means 96(first conv)-32(6 cells)-64(6 cells)-128(6 cells). \n\n(3)\nThe hyperparameters for CIFAR-10 and ImageNet are chosen to match Liu et al., (2018c). One difference is the drop-path probability (0.4 vs 0.3). This was chosen ad hoc in earlier experiments and we did not observe a difference in results. \nFor anytime, the hyperparameters are identical to Huang et al. (2018)\nOverall, we did not perform a grid search over hyperparameters. So it is possible that a grid search would improve our results. \n\nPerhaps the largest difference is that we accelerate training in a distributed fashion. However, our experiments showed negligible differences in accuracy compared to single GPU training.\n\n(4)\nWe cannot say for certain at this moment, but we will consider releasing code after acceptance. \n\nThanks again for your interest! Please let us know if any answers are unclear or if there are additional questions.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper871/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615372, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkgW0oA9FX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper871/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper871/Authors|ICLR.cc/2019/Conference/Paper871/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615372}}}, {"id": "S1lpn7Pcc7", "original": null, "number": 1, "cdate": 1539105717265, "ddate": null, "tcdate": 1539105717265, "tmdate": 1539144803532, "tddate": null, "forum": "rkgW0oA9FX", "replyto": "rkgW0oA9FX", "invitation": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "content": {"comment": "This is a nice work. I have a few questions about the experiments.\n(1) In Table 2, the search cost includes the training time and evaluation time on 1K models. Would you mind to also let us know the separate time of these two procedures?\n(2) In Table 1 and Table 2, does (F=32) mean that the channels in the CIFAR architecture are 32(first conv)-32(6 cells)-64(6 cells)-128(6 cells)?\n(3) In Sec.7.3, the hyper-parameters for optimization algorithms are different with some compared algorithms. These differences may lead a higher (or lower) accuracy. Would it be a little bit unfair?\n(4) Do you plan to release the codes? \nThanks again, this is an interesting paper!", "title": "Interesting Work!"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper871/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph HyperNetworks for Neural Architecture Search", "abstract": "Neural architecture search (NAS) automatically finds the best task-specific neural network topology, outperforming many manual architecture designs. However, it can be prohibitively expensive as the search requires training thousands of different networks, while each training run can last for hours. In this work, we propose the Graph HyperNetwork (GHN) to amortize the search cost: given an architecture, it directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, we randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast - they can search nearly 10\u00d7 faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs.", "keywords": ["neural", "architecture", "search", "graph", "network", "hypernetwork", "meta", "learning", "anytime", "prediction"], "authorids": ["cjzhang@edu.uwaterloo.ca", "mren@cs.toronto.edu", "urtasun@cs.toronto.edu"], "authors": ["Chris Zhang", "Mengye Ren", "Raquel Urtasun"], "pdf": "/pdf/b9c01adccfbaae7fad1c8e5c2db9ea6c19313a0c.pdf", "paperhash": "zhang|graph_hypernetworks_for_neural_architecture_search", "_bibtex": "@inproceedings{\nzhang2018graph,\ntitle={Graph HyperNetworks for Neural Architecture Search},\nauthor={Chris Zhang and Mengye Ren and Raquel Urtasun},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkgW0oA9FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper871/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311732873, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rkgW0oA9FX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper871/Authors", "ICLR.cc/2019/Conference/Paper871/Reviewers", "ICLR.cc/2019/Conference/Paper871/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311732873}}}], "count": 17}