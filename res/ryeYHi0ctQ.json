{"notes": [{"id": "ryeYHi0ctQ", "original": "BylpuqDvKX", "number": 108, "cdate": 1538087745357, "ddate": null, "tcdate": 1538087745357, "tmdate": 1551961072118, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJl-JRb3k4", "original": null, "number": 1, "cdate": 1544457689030, "ddate": null, "tcdate": 1544457689030, "tmdate": 1545354497847, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Meta_Review", "content": {"metareview": "A deep neural network pipeline for multiview stereo is presented. After rebuttal and discussion, all reviewers learn toward accepting the paper. Reviewer3 points to good results, but is concerned that the technical aspects are somewhat straightforward, and thus the contribution in this area is limited. The AC concurs with the reviewers.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper108/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353333746, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353333746}}}, {"id": "BklzKibF27", "original": null, "number": 2, "cdate": 1541114745928, "ddate": null, "tcdate": 1541114745928, "tmdate": 1543959319928, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "content": {"title": "Practically good but technically weak.", "review": "Summary\nThis paper proposes an end-to-end learnable  multiview stereo depth estimation network, which is basically very similar to the GCNet (Kendall et.al 2017) or PSMNet (Chang et.al 2018) for stereo estimation. The differences are using SPN to warp feature w.r.t RT, adding a multi view averaging cost and a cost aggregation component for final depth regression, which transform the original network to support multi-view stereo, yielding performance boost over other baselines.\n\nTechnically, I believe it is sound  because cost volume from stereo matching has already been demonstrate very effective in boosting performance because it use underlining geometry constraint.  My major concern lies in three aspects. \n\n1) Another most recent SOTA algorithm is  MVSNet (Yao et.al ECCV 2018), the paper should be considered for comparison. In addition, the structure is even more similar with the proposed network architecture.  \n\n2) The evaluation metrics are mostly use for single view depths, it is not consistent with paper of DeepMVS (Tab. 1) or that from MVSNet. Therefore, it might be hard to actual understand whether the numbers are  exactly comparable. \n\n3) Since the method largely improved over their baseline algorithms, and the number between different papers are hard to compare. In my opinion, to better show the results,  I suggest submitting results to an online benchmark with test data for verifying the results. such as ETH3D multi view benchmark, where everything is standardized. \n\nI hope the author can make strong feedback for validating the results. \n\n####### . After rebuttal\n\nThe author makes more clear indication of the performance contribution of the completeness of recovery.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "cdate": 1542234536063, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335651087, "tmdate": 1552335651087, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1gw0HrzRQ", "original": null, "number": 5, "cdate": 1542768079299, "ddate": null, "tcdate": 1542768079299, "tmdate": 1543802153090, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "BklzKibF27", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer2 (c)", "comment": "3) Since the method largely improved over their baseline algorithms, and the number between different papers are hard to compare. In my opinion, to better show the results, I suggest submitting results to an online benchmark with test data for verifying the results. such as ETH3D multi view benchmark, where everything is standardized.\n\nDifferent from MVSNet which estimates the full 3D of objects, our DPSNet is inspired by the plane sweeping algorithm which is originally devised for dense depth reconstruction. That is, DPSNet focuses on estimating the dense depth map. By your suggestion, we have submitted depth maps from DPSNet to the ETH3D benchmark, but did not receive satisfactory results, with lower ranks on the \u2018F1 score\u2019 metric. \nMethod\n(20cm)\tlow-res many-view\tindoor\toutdoor\tlakeside\tsand box\tstorage room\tstorage room 2\ttunnel\nDPSNet\t59.89\t54.16\t63.70\t71.39\t70.87\t52.09\t56.24\t48.85\nMVSNet\t63.58\t56.25\t68.47\t66\t71.12\t48.36\t64.13\t68.29\n\nIn order to obtain a high score on the accuracy metric, the depth corresponding to unobserved pixels should be removed. MVSNet performs a depth map filtering to remove outliers, and its multiple observed 3D points merged well to select a correct depth value from multiple observations for a pixel. However, the outlier rejection and the 3D point merging proces are out of the scope of this paper. Instead, we demonstrate that DPSNet produces dense depth maps well by achieving higher scores on the \u2018Completeness\u2019 metric than that of MVSNet on the ETH3D benchmark.\nMethod\n(20cm)\tlow-res many-view\tIndoor\toutdoor\tlakeside\tsand box\tstorage room\tstorage room 2\ttunnel\nDPSNet\t58.64\t47.21\t66.25\t72.10\t77.08\t48.12\t46.31\t49.58\nMVSNet\t47.72\t40.64\t52.43\t49.39\t55.25\t33.58\t47.7 \t52.66\n\nIn conclusion, DPSNet and MVSNet have different goals, and thus different strengths. In the revised paper, we clarify that our DPSNet aims to infer dense depth maps, to highlight its advantages.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "rJeH6BHMC7", "original": null, "number": 4, "cdate": 1542768060707, "ddate": null, "tcdate": 1542768060707, "tmdate": 1542768232397, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "BklzKibF27", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer2 (b) ", "comment": "2) The evaluation metrics are mostly use for single view depths, it is not consistent with paper of DeepMVS (Tab. 1) or that from MVSNet. Therefore, it might be hard to actual understand whether the numbers are exactly comparable. \nThe error metrics used in this paper are for dense depth measurements on the KITTI benchmark. Since the main goal of our work is to reconstruct a dense depth map from multiple images, we think the error metrics are suitable for performance evaluation of our DPSNet and the state-of-the-art methods. However, we agree with your view and report a quantitative evaluation using the three error metrics used in DeepMVS: (1) Completeness, which is the percentage of pixels whose errors are below a certain threshold. (2) Geometry error, taking the L1 distance between the estimated disparity and the ground truth. (3) Photometry error, which is the L1 distance between the reference image and warped image using the estimated disparity map. \n\nWe evaluated depth maps from our DPSNet and all comparison methods including MVSNet using those measures. For fair comparison, we use the ETH3D dataset on which all methods are not trained. As shown in Table 2 of the revised paper, our DPSNet shows promising results on these measures, compared to the state-of-the-art methods. In particular, DPSNet outperforms MVSNet in all metrics, except for the photometric error of filtered MVSNet. Since MVSNet is not designed for dense depth reconstruction, this evaluation protocol is highly disadvantageous to MVSNet. \nIn the next response, we will discuss error measures in the ETH3D benchmark, which are also used for MVSNet evaluation.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "S1lRoHBM0X", "original": null, "number": 3, "cdate": 1542768038367, "ddate": null, "tcdate": 1542768038367, "tmdate": 1542768224396, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "BklzKibF27", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer2 (a)", "comment": "1) Another most recent SOTA algorithm is MVSNet (Yao et.al ECCV 2018), the paper should be considered for comparison. In addition, the structure is even more similar with the proposed network architecture.  \nThanks for your suggestion to improve our experiments. Following your comment, we have added a description of MVSNet at the end of Sec. 2 and mentioned the differences from our DPSNet. Traditional stereo matching and multiview stereo consist of four steps: initial matching, cost aggregation, multi-label optimization and refinement. In our opinion, MVSNet mainly focuses on computing initial matching and refinement. Our contributions are mainly on initial matching and cost aggregation. Even though the main scheme for warping is similar, the cost volume generation and aggregation approaches are different. \n\nMVSNet was developed concurrently to our work, and there are differences in contributions. In particular, (1) our DPSNet concatenates the reference image features and warped pair image features, then builds a cost volume. If multiple views are available (more than 3 views), we iteratively compute the cost volume and average them. This cost volume generation strategy can produce a more confident cost volume as more views are matched. Moreover, we show that our DPSNet can be generalized to binocular stereo, while MVSNet builds a cost volume based on the variance of features, which fails to estimate accurate depth values when only using two views. (2) Our novel cost aggregation network shows significant performance improvements on textureless regions over MVSNet\u2019s refinement with a reference image feature. (3) Both the minimum and maximum depth range are user-defined parameters and scene-dependent. As an alternative, our DPSNet uniformly samples matching planes in inverse-depth scale, which is beneficial for alleviating depth quantization error and reconstructing scenes with large depth ranges. \nWe cannot say with certainty which method performs better. What we can say clearly is that both methods have shown great performance improvements by applying traditional techniques used in multiview stereo into deep learning architectures. In other words, both studies have independent academic contributions.\nFor a comparison to MVSNet, please refer to the next response.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "rJeqHUBf0X", "original": null, "number": 8, "cdate": 1542768193824, "ddate": null, "tcdate": 1542768193824, "tmdate": 1542768193824, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "rJeI9Oz5hQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer1 (c)", "comment": "3) I do believe the paper would significantly benefit from more discussion of DeepMVS since it's clearly the closest to this method (also solves MVS by deep networks + plane sweep). DeepMVS also learns the matching cost for cost volume generation, and the major difference seems to be that this method is learned end-to-end. It would be better to have a more detailed discussion of the differences (the current discussion at the end of Sec 2 is a little short on details)---architectures, super-vision at the end of the cost-volume vs end-to-end, etc.\n\nDeepMVS shows good performance on various datasets, but it is not an end-to-end system. DeepMVS computes input volumes for their network using the traditional warping process, different from our network which employs a differential warping process. In addition, even though they take feature aggregations (intra-, inter-feature aggregation), the final depth map is obtained from a conventional CRF which is sensitive to over-smoothing artifacts in textureless regions (see the artifacts in Fig. 3 and Fig. 4 of our paper). Following your comment, we have further explained the difference between DeepMVS and our work at end of Sec. 2. "}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "HkeF3NBMRQ", "original": null, "number": 2, "cdate": 1542767793231, "ddate": null, "tcdate": 1542767793231, "tmdate": 1542768177823, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "rJeI9Oz5hQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer1 (a)", "comment": "1) While the proposed network is complex, I do believe the description of the architecture could be a little better. It would be good to clarify that i indexes view (and N is the total number of views), and provide a few more definitions for the terms in equation (2): namely, are R and t the extrinsics of the reference camera or the i^th camera, etc. The overall approach is clear (for each plane, the method maps features from the paired camera to the reference camera assuming all points in the the world lie on that plane), but it would be good to clarify the specifics. It might also be useful to emphasize that the cost-volume generation is per-pair (perhaps change the title of Sec 3.2) and that these volumes are averaged for all pairs.\n\nThanks for your suggestions to improve our manuscript. Following your comments, we have clarified these parts by adding descriptions in Sec 3.2. In the first paragraph of Sec. 3.2, we explain that our cost volume generation is based on unstructured two-view images and can be extended to multiview matching by averaging other cost volumes to reduce a negative effect of image noise. In particular, we have changed the title of Sec 3.2 from \u201cCost Volume Generation\u201d to \u201cCost Volume Generation using Unstructured Two-View Images\u201d to highlight that the cost volume is computed from an image pair. We also added explanations for the notations i, R and t in the third paragraph of Sec. 3.2.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "SyxNEIBfCQ", "original": null, "number": 7, "cdate": 1542768171575, "ddate": null, "tcdate": 1542768171575, "tmdate": 1542768171575, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "rJeI9Oz5hQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer1 (b)", "comment": "2) It might also be useful to apply the algorithm to the rectified binocular stereo case (where the warping and definition of planes by disparity are much simpler), and show comparisons to the many stereo algorithms on datasets like KITTI. At some level, the proposed algorithm can be thought of taking approaches proved to be successful for rectified binocular stereo and generalizing them (by generic warping + plane sweep) to the multi-view case. Hence, such comparisons could be illuminating. (Note: the method doesn't need to outperform the state-of-the-art there, but the results would be informative).\n\nWe applied our algorithm to rectified stereo matching, particularly on the KITTI2015 test set, following the comment of reviewer1. We have obtained reasonable results using the model trained on SUN3D, RGBD, and Scenes11 as shown in Fig. 7(b) and Table 5. We also report the results with the KITTI finetuning in Fig. 7(c) and Table 5. \nOur DPSNet achieves performance compatible to DispNet, but not beyond the performance of recent CNN-based stereo matching algorithms (GC-Net and PSMNet). Based on the rectified stereo experiments, we also agree with reviewer 1\u2019s comments that our DPSNet can be considered a generalized version of stereo matching. We mention that our DPSNet can be directly applied to both rectified stereo and unrectified multiview stereo, and add the experiment results in Sec. 4.3.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "BJlme8SzAm", "original": null, "number": 6, "cdate": 1542768106828, "ddate": null, "tcdate": 1542768106828, "tmdate": 1542768106828, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "SkxJToirn7", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Response to Reviewer3", "comment": "More details would be welcome for Section 3.2\nThanks for your positive comments on our paper. Since your comment is the same as that of Reviewer 1, please refer to the response 1 to Reviewer 1\u2019s question and check our revised manuscript.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "rJeI9Oz5hQ", "original": null, "number": 3, "cdate": 1541183629932, "ddate": null, "tcdate": 1541183629932, "tmdate": 1541534276000, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "content": {"title": "Likely Accept: but requires some comments to be addressed", "review": "The paper describes a method for learning a deep neural network for multi-view stereo. The overall network includes feature-extraction layers applied to all images, followed by a spatial-transformer network (which is differentiable, but with no learnable parameters) that is applied to warp these features from every matching image to the reference image's co-ordinate frame for a series of candidate depth planes, followed by concatenation of the reference and match image features and 3D convolution layers to form a cost volume. The cost volumes of different pairs are averaged, and additional layers are used to refine this cost volume while relying on the reference image's RGB features, followed by soft-max and an expectation over depth values to output the final depth at each pixel. The entire network is trained end-to-end and experiments show that it outperforms state-of-the-art methods for MVS by a significant margin on a number of datasets.\n\nOverall, I have a positive view of the paper and believe it should be accepted to ICLR. However, I would like the authors to address the following issues:\n\n- While the proposed network is complex, I do believe the description of the architecture could be a little better. It would be good to clarify that i indexes view (and N is the total number of views), and provide a few more definitions for the terms in equation (2): namely, are R and t the extrinsics of the reference camera or the i^th camera, etc. The overall approach is clear (for each plane, the method maps features from the paired camera to the reference camera  assuming all points in the the world lie on that plane), but it would be good to clarify the specifics. It might also be useful to emphasize that the cost-volume generation is per-pair (perhaps change the title of Sec 3.2) and that these volumes are averaged for all pairs.\n\n- It might also be useful to apply the algorithm to the rectified binocular stereo case (where the warping and definition of planes by disparity are much simpler), and show comparisons to the many stereo algorithms on datasets like KITTI. At some level, the proposed algorithm can be thought of taking approaches proved to be successful for rectified binocular stereo and generalizing them (by generic warping + plane sweep) to the multi-view case. Hence, such comparisons could be illuminating. (Note: the method doesn't need to outperform the state-of-the-art there, but the results would be informative).\n\n- I do believe the paper would significantly benefit from more discussion of DeepMVS since it's clearly the closest to this method (also solves MVS by deep networks + plane sweep). DeepMVS also learns the matching cost for cost volume generation, and the major difference seems to be that this method is learned end-to-end. It would be better to have a more detailed discussion of the differences (the current discussion at the end of Sec 2 is a little short on details)---architectures, super-vision at the end of the cost-volume vs end-to-end, etc.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "cdate": 1542234536063, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335651087, "tmdate": 1552335651087, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkxJToirn7", "original": null, "number": 1, "cdate": 1540893622689, "ddate": null, "tcdate": 1540893622689, "tmdate": 1541534275504, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "content": {"title": "Works well, maybe too straightforward for ICLR", "review": "This paper proposes a method for stereo reconstruction using Deep Learning. Like some previous methods, a 'cost volume' is first computed by plane sweeping, in other words the cost volume is indexed by the 2D locations in the image plane, and the disparities for 3D planes parallel to the image plane. A network then predicts the disparities for each image location from this cost volume.\n\nThe contributions with respect to the state-of-the-art are:\n\n- the cost volume is computed using differential warps, thus the network can be trained end-to-end;\n\n- a better cost volume is computed from the original cost volume and the reference image.\n\nThe results look good, both quantitatively and qualitatively. The paper reads well, and related work is correctly referenced.\n\nThere is nothing wrong with the proposed method, it makes sense and I am convinced it works well. However, I found the contributions quite straightforward, and it is difficult to get excited about the paper.\n\nMore details would be welcome for Section 3.2", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper108/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Review", "cdate": 1542234536063, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335651087, "tmdate": 1552335651087, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJgWT3KSq7", "original": null, "number": 1, "cdate": 1538788537040, "ddate": null, "tcdate": 1538788537040, "tmdate": 1538788537040, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "HygmvWIH5Q", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "content": {"title": "Re: Access to Code", "comment": "Hello, thank you for your feedback and your interest in our work. Regarding your comments:\n\n\n1. We will release our PyTorch implementation for DPSNet upon the acceptance of this paper.\n\n2. The camera rotation R (3x3 matrix) and transform T (3x1 vector) described in our paper are defined in 3D space. Camera extrinsic [R | T] and the intrinsic parameter K are used to obtain the projected image coordinates (\\hat{u}_l) described in equation (2). Using the projected image coordinates (\\hat{u}_l), we calculate the pixel-wise 2x1 translation vector {T_stn} defined in the STN (similar to the flow field). Because we warp the image based on the projected coordinates, we set the 2x2 rotation matrix {R_stn} defined in the STN as the identity matrix. "}, "signatures": ["ICLR.cc/2019/Conference/Paper108/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621616741, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryeYHi0ctQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper108/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper108/Authors|ICLR.cc/2019/Conference/Paper108/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621616741}}}, {"id": "HygmvWIH5Q", "original": null, "number": 1, "cdate": 1538773339410, "ddate": null, "tcdate": 1538773339410, "tmdate": 1538773339410, "tddate": null, "forum": "ryeYHi0ctQ", "replyto": "ryeYHi0ctQ", "invitation": "ICLR.cc/2019/Conference/-/Paper108/Public_Comment", "content": {"comment": "Thanks to the author(s) for this contribution! Are you planning on releasing the PyTorch code for DPSNet?\n\nAlso, a implementation question regarding warping the target and reference images to a virtual plane.  At the end of page 3 you describe the formulation for the transformation with respect to the intrinsics, extrinsics, and the particular depth of the virtual plane. You continue to say you use the spatial transform network (STN) to implement this warping. STN defines it transformations with respect to a 2x2 rotation R and 2x1 translation T. What are the values of R and T w.r.t. the intrinsics, extrinsics, and depth?\n\nThank you again!", "title": "Access to Code"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper108/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DPSNet: End-to-end Deep Plane Sweep Stereo", "abstract": "Multiview stereo aims to reconstruct scene depth from images acquired by a camera under arbitrary motion. Recent methods address this problem through deep learning, which can utilize semantic cues to deal with challenges such as textureless and reflective regions. In this paper, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth and/or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume via a context-aware cost aggregation, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, DPSNet achieves state-of-the-art reconstruction results on a variety of challenging datasets.", "keywords": ["Deep Learning", "Stereo", "Depth", "Geometry"], "authorids": ["dlarl8927@kaist.ac.kr", "haegonj@andrew.cmu.edu", "stevelin@microsoft.com", "iskweon77@kaist.ac.kr"], "authors": ["Sunghoon Im", "Hae-Gon Jeon", "Stephen Lin", "In So Kweon"], "TL;DR": "A convolution neural network for multi-view stereo matching whose design is inspired by best practices of traditional geometry-based approaches", "pdf": "/pdf/6c524664342b2dad1ed394e5fbedd840485332f7.pdf", "paperhash": "im|dpsnet_endtoend_deep_plane_sweep_stereo", "_bibtex": "@inproceedings{\nim2018dpsnet,\ntitle={{DPSN}et: End-to-end Deep Plane Sweep Stereo},\nauthor={Sunghoon Im and Hae-Gon Jeon and Stephen Lin and In So Kweon},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ryeYHi0ctQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper108/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311916866, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "ryeYHi0ctQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper108/Authors", "ICLR.cc/2019/Conference/Paper108/Reviewers", "ICLR.cc/2019/Conference/Paper108/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311916866}}}], "count": 14}