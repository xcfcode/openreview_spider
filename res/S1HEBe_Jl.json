{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396305962, "tcdate": 1486396305962, "number": 1, "id": "B155ozUde", "invitation": "ICLR.cc/2017/conference/-/paper6/acceptance", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "Interesting paper but not over the accept bar."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396306534, "id": "ICLR.cc/2017/conference/-/paper6/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396306534}}}, {"tddate": null, "tmdate": 1482874339404, "tcdate": 1482874339404, "number": 6, "id": "rJs1RUlHe", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "Hk6V96lVe", "signatures": ["~David_G_Andersen1"], "readers": ["everyone"], "writers": ["~David_G_Andersen1"], "content": {"title": "Author response to review comments", "comment": "Decorrelating data is often attractive, as the review suggests, but it can be non-trivial. In our work, the role of the adversary is to expose the correlations, which may not otherwise be apparent. Moreover, decorrelating data may reduce utility, perhaps in completely unnecessary ways if the correlations are not relevant to the secrecy goals. Our work aims to show that there is an alternative, and that it can be learned: that neural networks can figure out which correlations matter given a set of secrecy goals, and can figure out how to hide them. We believe that this is an interesting capability, and that it may well be useful in building compositions of neural networks with confidentiality constraints (as suggested on page 2). On the other hand, we certainly do not expect to beat the state of the art in terms of cryptographic strength and assurance. It is conceivable that hybrid schemes would be viable, as discussed in our reply dated December 8.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1482874275444, "tcdate": 1482874275444, "number": 5, "id": "B1io6IxBl", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "HkltSFbNe", "signatures": ["~David_G_Andersen1"], "readers": ["everyone"], "writers": ["~David_G_Andersen1"], "content": {"title": "Author response to review comments", "comment": "Thank you for your encouraging comments. \n\nRegarding the experiments of section 3, the scenario is that Alice provides information so that anyone can observe an estimate of D without gaining information about C. The fact that C is hidden is formulated by introducing Eve, which attempts to reconstruct C. Alice also provides additional information so that Bob, with whom Alice shares a key, can do an even better job at estimating D, but may learn something about C. In sum, the main difference with section 2 is that here the \u201ccommunication goal\u201d and the \u201chiding goal\u201d concern two different parts of the plaintext (D and C respectively). We hope that this clarifies the matter; we would certainly be happy to expand the discussion in section 3 (perhaps adding diagrams which we have used in talks, but which seemed too long for the submission).\n\nRegarding minor concern (1), we will indeed be glad to include the results indicated in our response and some updated ones in the event that the paper is accepted. We agree that it is interesting to think about stronger Eve networks, as suggested by the reviewer. On the other hand, we believe that the appropriate strength of Eve may sometimes be dictated by intended applications; for example, if we are trying to hide information from one of our own neural-network components (as suggested in page 2), it makes sense that Eve be of a similar size and architecture as that component.\n\nRegarding minor concern (2), we have two thoughts.  First, it may often be appropriate to generate arbitrary-length key material using standard cryptographic key-generation techniques.  (These techniques generate an arbitrary-length stream of bits given a short initial seed, and parts of that stream of bits could be used as the keys passed into the neural cryptography).  Second, as a generalization of our work, we agree that the treatment of larger messages could be interesting. It is natural to evaluate neural cryptography with messages larger than keys;  this should be a straightforward extension of our current work.  As a more futuristic step, one could explore so-called \u201cmodes of operation\u201d using RNNs or similar architectures."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1482874236027, "tcdate": 1482874236027, "number": 4, "id": "BkEtpIxSx", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "Hym5uLBVx", "signatures": ["~David_G_Andersen1"], "readers": ["everyone"], "writers": ["~David_G_Andersen1"], "content": {"title": "Author response to review comments", "comment": "We are glad about your comment that this paper presents \u201can interesting thought experiment\u201d, as it is in line with how we regard this work. As for your points on the possible impact of this work:\n1) We also agree that the techniques that we present are not likely to yield high-assurance security. They may however yield suitable protection against low-grade attackers (much like spam filters) or against our own actions. In particular, as suggested in the submission (page 2), they may be adequate in order to prevent one of our own neural-network components from using information that we want to keep from it because of concerns about privacy or discrimination.\n2) An important contrast with readily available encryption systems is that, with our approach, one learns what needs to be \u201cscrambled\u201d for a given a protection goal (as indicated in our reply of December 8).\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1482152074922, "tcdate": 1482152074922, "number": 3, "id": "Hym5uLBVx", "invitation": "ICLR.cc/2017/conference/-/paper6/official/review", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/conference/paper6/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper6/AnonReviewer2"], "content": {"title": "Interesting thought experiment, but strong concerns about the practicality of the approach", "rating": "5: Marginally below acceptance threshold", "review": "The submission proposes to modify the typical GAN architecture slightly to include \"encrypt\" (Alice) and \"decrypt\" (Bob) modules as well as a module trying to decrypt the signal without a key (Eve).  Through repeated transmission of signals, the adversarial game is intended to converge to a system in which Alice and Bob can communicate securely (or at least a designated part of the signal should be secure), while a sophisticated Eve cannot break their code.  Examples are given on toy data:\n\"As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plain-text and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64.  Both plaintext and key values are uniformly distributed.\"\n\nThe idea considered here is cute.  If some, but not necessarily all of the signal is meant to be secure, the modules can learn to encrypt and decrypt a signal, while an adversary is simultaneously learned that tries to break the encryption.  In this way, some of the data can remain unencrypted, while the portion that is e.g. correlated with the encrypted signal will have to be encrypted in order for Eve to not be able to predict the encrypted part.\n\nWhile this is a nice thought experiment, there are significant barriers to this submission having a practical impact:\n1) GANs, and from the convergence figures also the objective considered here, are quite unstable to optimize.  The only guarantees of privacy are for an Eve that is converged to a very strong adversary (stronger than a dedicated attack over time).  I do not see how one can have any sort of reliable guarantee of the safety of the data transmission from the proposed approach, at least the paper does not outline such a guarantee.\n2) Public key encryption systems are readily available, computationally feasible, and successfully applied almost anywhere.  The toy examples given in the paper do not at all convince me that this is solving a real-world problem at this point.  Perhaps a good example will come up in the near future, and this work will be shown to be justified, but until such an example is shown, the approach is more of an interesting thought experiment.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512726127, "id": "ICLR.cc/2017/conference/-/paper6/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper6/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper6/AnonReviewer1", "ICLR.cc/2017/conference/paper6/AnonReviewer3", "ICLR.cc/2017/conference/paper6/AnonReviewer2"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512726127}}}, {"tddate": null, "tmdate": 1481901432093, "tcdate": 1481901432093, "number": 2, "id": "HkltSFbNe", "invitation": "ICLR.cc/2017/conference/-/paper6/official/review", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/conference/paper6/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper6/AnonReviewer3"], "content": {"title": "Very creative application of adversarial training to cryptography with some weaknesses in the toy examples", "rating": "6: Marginally above acceptance threshold", "review": "The paper deals with an interesting application of adversarial training to encryption. It considers the standard scenario of Alice, Eve and Bob, where A and B aim to exchange messages conditioned on a shared key, while Eve should be unable to encrypt the message. Experiments are performed in a simple symmetric 16 bit encryption task, and an application on privacy. The concepts, ideas and previous literature are quite nicely and carefully presented.\n\nThe only major concern I have - and I apologize to the authors for not raising this earlier - are the experiments in section 3. In particular, I don't quite get the scenario. The reasoning here seems to be as follows: given information < A, B, C, D >, I want to give the public the value of D (e.g. movies watched) without releasing information about C (e.g. gender). In this scenario, Eve would need to be able to reconstruct D as good as possible without gaining information about C. What is described in section 3, however, is that D and D-public are both reconstructed by Bob, but why would Bob reconstruct the latter (he is not public, in particular because he is allowed to reconstruct C, which is not tested here)? Also, Eve only tries to estimate C, thus rendering the scenario not different in any way to the scenario considered in section 2.\n\nI have two more minor concerns:\n\n1) As raised in the pre-review, Eve should actually be stronger then Alice and Bob in order to be able to compensate for the missing key. The authors noted they have been doing these experiments and are going to add the results.\n\n2) In any natural encryption case I would expect the length of the key to be much shorter then the length of the message. This, however, could potentially make the scenario much easier for Eve (although I doubt any of the results will change if the key is long enough).\n\nI like the creative application of adversarial training to a completely different domain, and I believe it could be the starting point of a very interesting direction in cryptographic systems or in privacy applications (although it is unclear whether the weak guarantees of neural network based approaches can ever be overcome). At the same time the application in the privacy setting leaves me quite confused, and the symmetric encryption example is not particularly strong either. I'd appreciate if the authors could address the major concern I raised above, and I will be quite happy to raise the score in case this confusion can be resolved.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512726127, "id": "ICLR.cc/2017/conference/-/paper6/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper6/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper6/AnonReviewer1", "ICLR.cc/2017/conference/paper6/AnonReviewer3", "ICLR.cc/2017/conference/paper6/AnonReviewer2"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512726127}}}, {"tddate": null, "tmdate": 1481853523566, "tcdate": 1481853493436, "number": 1, "id": "Hk6V96lVe", "invitation": "ICLR.cc/2017/conference/-/paper6/official/review", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/conference/paper6/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper6/AnonReviewer1"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposed to use GAN for encrypted communications.\n\nIn section 2, the authors proposed a 3 part neural network trained to encode and decode data. This model does not have any practical value except paving the way for describing the next model in section 3: it is strictly worse than any provable cryptography system.\n\nIn section 3, the authors designed a task where they want to hide part of the data, which has correlated fields, while publishing the rest. However, I'm having trouble thinking of an application where this system is better than simply decorrelating the data and encrypting the fields one wants to hide with a provable cryptography system while publishing the rest in plain text.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512726127, "id": "ICLR.cc/2017/conference/-/paper6/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper6/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper6/AnonReviewer1", "ICLR.cc/2017/conference/paper6/AnonReviewer3", "ICLR.cc/2017/conference/paper6/AnonReviewer2"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512726127}}}, {"tddate": null, "tmdate": 1481224198757, "tcdate": 1481224198752, "number": 3, "id": "rkyzxEDQe", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "SkWnoUkml", "signatures": ["~Martin_Abadi1"], "readers": ["everyone"], "writers": ["~Martin_Abadi1"], "content": {"title": "Re: Complexity of Eve (continued)", "comment": "This is an update to our reply on the interesting question on the complexity of Eve, after some new experiments.\n\nThere are several reasonable options for trying to make Eve stronger. To begin to answer this question, we defined two new types of Eve networks:\n\n  A) Eve++Layers has two additional convolutional layers.\n\n  B) Eve++RandomKey has exactly the same shape and size as Bob, but receives random inputs instead of key material.\n\nWe implemented these in a slightly improved version of the Alice, Bob, and Eve network structure, so the numbers are only approximately (not exactly) comparable to those in the paper.\n\nWith option (A), the median \u201cbest Eve performance\u201d after retraining (recalling that Eve would average about 8 bits wrong out of 16 in a perfect world) was:\n  1) 6.50  (Train and Eval using Eve)\n  2) 5.99 (Train and Eval using Eve++Layers)\n  3) 6.05 (Train using Eve, Eval using Eve++Layers)\n\nThese results show that the more-capable Eve++Layers is modestly more effective than Eve against Alice and Bob, but not catastrophically so. The results do not yet differentiate whether there is a training difference, and we plan to explore this through an additional set of more comprehensive measurements.\n\nNow turning to option (B) and Eve++RandomKey, we also explored the question of whether the extra inputs helped Alice and Bob disproportionately. Our preliminary results suggest that either the results are unchanged, or that Eve++RandomKey performs slightly worse (6.58 bits of error vs. 6.50 bits, without enough runs to indicate that this is a significant difference). Here too, we will run a larger set of experiments to answer this question more comprehensively.\n\n(In general, there are many other types of experiments we could try as follow-on work, of course, and one of the hopes we have for this paper is that it spurs that discussion.)\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1481222796421, "tcdate": 1481222796413, "number": 2, "id": "BkV55mwQe", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "SJmR0_17e", "signatures": ["~Martin_Abadi1"], "readers": ["everyone"], "writers": ["~Martin_Abadi1"], "content": {"title": "on applications and provable cryptography, presentation suggestions, and theory for alternation", "comment": "Thank you for the various helpful comments.\n\nOn applications and provable cryptography:\n\nAs indicated in the paper, we have in mind applications where we wish to hide data from some neural-network components because of concerns about privacy or discrimination (in line with the work on fair representations that we cite), but we have not developed such applications concretely. \n\nAs in the example of Section 3, there may be correlations in the data, so it may not be immediately apparent what to encrypt; therefore, provable cryptography alone does not provide a direct solution (E.g., if \u201cgender\u201d is not an explicit field in user data but may be inferred by combining other attributes, and we wish to hide it, what should we encrypt?).  Recall that, in Section 3, the program produces a \u201cpublic\u201d answer, which was required not to divulge a protected attribute, and a \u201cprivate\u201d (i.e., encrypted) value that could be combined with the public value to regain any accuracy lost in hiding the protected attribute.  Creating the public value is a learned operation that cannot be accomplished by encryption alone. However, we may perhaps imagine hybrid schemes, where we learn what to encrypt using our approach, then, at \u201ctest time\u201d (in deployment) replace neural-cryptography modules with classical encryption primitives.\n\nOur hope for this work is that its primary contribution will be spurring research on several fronts (i.e., that it will be thought-provoking, not that it will highlight particular applications). At a high level, our work concerns the training of multiple agents with competing objectives. There may well be a wide range of concrete domains where this matters. For example, a new paper https://arxiv.org/abs/1612.01294 \u201cbears close resemblance\u201d to our work (according to the authors), but focuses on multi-agent image generation. We have also heard (privately) of applications of neural cryptography in finance, for stock market efficiency. We have not yet looked closely at those applications, and are not in a position to assess them---but they seem indicative of the interest in training multiple competing agents. \n\nPresentation matters:\n\nThe current presentation is partly inspired by the presentation of the original paper on GANs, where there is both an abstract minimax game and implementation techniques. We found this attractive and enlightening. However, we will reconsider presentation matters. \n\nAnalysis of alternation:\n\nAgreed. We note that such analyses are mostly future work for most kinds of adversarial training (e.g., in research on GANs), and seen as an interesting open problem by at least some of the leading researchers in the area."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1480720136385, "tcdate": 1480720075086, "number": 2, "id": "SJmR0_17e", "invitation": "ICLR.cc/2017/conference/-/paper6/pre-review/question", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/conference/paper6/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper6/AnonReviewer2"], "content": {"title": "pre review questions", "question": "Are there any concrete applications of this method?  I am really having trouble thinking of a time when I would use this rather than employ a provable cryptography system.\n\nGiven that the actual design choices in 2.3 don't match the presentation of the system in 2.2, could you rewrite 2.2 to match 2.3?\n\non P.5 it is stated \"This kind of alternation is typical of games; the theory of continuous games includes results about convergence to equilibria (e.g., (Ratliff et al., 2013)) which it might be possible to apply in our setting.\" - it would be nice to actually perform such an analysis.\n\nA real world example with real-world data would be nice, specifically one in which for some reason it's not appropriate to apply a standard cryptography solution."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959510633, "id": "ICLR.cc/2017/conference/-/paper6/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper6/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper6/AnonReviewer3", "ICLR.cc/2017/conference/paper6/AnonReviewer2"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959510633}}}, {"tddate": null, "tmdate": 1480711080557, "tcdate": 1480711080553, "number": 1, "id": "SkWnoUkml", "invitation": "ICLR.cc/2017/conference/-/paper6/public/comment", "forum": "S1HEBe_Jl", "replyto": "Sku1ifszg", "signatures": ["~Martin_Abadi1"], "readers": ["everyone"], "writers": ["~Martin_Abadi1"], "content": {"title": "Re: Complexity of Eve", "comment": "Thank you for the interesting question!  We are running some experiments with a more powerful Eve that we call \u201cEve++\u201d; in the setting of Section 2 of our paper, these experiments aim to compare three scenarios:\n1) Unmodified Eve for both training and evaluation\n2) Eve++ for both training and evaluation\n3) Unmodified Eve for training, Eve++ for evaluation\n \nThe preliminary results of this are encouraging. Alice and Bob remain fairly successful against Eve++ in scenarios (2) and (3). Because making the Eve network more complicated potentially changes the rate at which it learns relative to Alice and Bob, we are now in the process of running a more comprehensive comparison of these three scenarios and will post an update with the results.\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287765308, "id": "ICLR.cc/2017/conference/-/paper6/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1HEBe_Jl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper6/reviewers", "ICLR.cc/2017/conference/paper6/areachairs"], "cdate": 1485287765308}}}, {"tddate": null, "tmdate": 1480432351769, "tcdate": 1480432351764, "number": 1, "id": "Sku1ifszg", "invitation": "ICLR.cc/2017/conference/-/paper6/pre-review/question", "forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "signatures": ["ICLR.cc/2017/conference/paper6/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper6/AnonReviewer3"], "content": {"title": "Complexity of Eve", "question": "In the current protocol, Eve has the same network architecture as Alice and Bob. In this case, however, Eve has a disadvantage as the complexity of transformations it can learn is less then those of Alice and Bob (whose hidden activations are additionally modulated by an external input). What happens if you substantially increase the complexity of Eve, e.g. by doubling the number of its layers?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959510633, "id": "ICLR.cc/2017/conference/-/paper6/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper6/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper6/AnonReviewer3", "ICLR.cc/2017/conference/paper6/AnonReviewer2"], "reply": {"forum": "S1HEBe_Jl", "replyto": "S1HEBe_Jl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959510633}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1477080364980, "tcdate": 1477080364972, "number": 6, "id": "S1HEBe_Jl", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "S1HEBe_Jl", "signatures": ["~David_G_Andersen1"], "readers": ["everyone"], "content": {"title": "Learning to Protect Communications with Adversarial Neural Cryptography", "abstract": "We ask whether neural networks can learn to use secret keys to protect\ninformation from other neural networks.  Specifically, we focus on\nensuring confidentiality properties in a multiagent system, and we\nspecify those properties in terms of an adversary.  Thus, a\nsystem may consist of neural networks named Alice and Bob, and we aim\nto limit what a third neural network named Eve learns from\neavesdropping on the communication between Alice and Bob.\nWe do not prescribe specific cryptographic algorithms to these neural networks;\ninstead, we train end-to-end, adversarially.\nWe demonstrate that the neural networks can learn \nhow to perform forms of encryption and decryption, and also\nhow to apply these operations selectively in order to meet\nconfidentiality goals.\n", "pdf": "/pdf/2caad8143d962dd837f7ea1a54b95aba2b12993a.pdf", "TL;DR": "Adversarial training of neural networks to learn rudimentary forms of encryption with no pre-specified algorithms", "paperhash": "abadi|learning_to_protect_communications_with_adversarial_neural_cryptography", "keywords": [], "conflicts": ["google.com", "cmu.edu"], "authors": ["Mart\u00edn Abadi", "David G. Andersen"], "authorids": ["abadi@google.com", "dga@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 13}