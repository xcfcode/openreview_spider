{"notes": [{"id": "rylgEULtdN", "original": "BJgW8gLYwN", "number": 11, "cdate": 1553716775600, "ddate": null, "tcdate": 1553716775600, "tmdate": 1562083044986, "tddate": null, "forum": "rylgEULtdN", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "FVD: A new Metric for Video Generation", "authors": ["Thomas Unterthiner", "Sjoerd van Steenkiste", "Karol Kurach", "Rapha\u00ebl Marinier", "Marcin Michalski", "Sylvain Gelly"], "authorids": ["unterthiner@bioinf.jku.at", "sjoerd@idsia.ch", "kkurach@gmail.com", "raphael.marinier@gmail.com", "cyfra0@gmail.com", "sylvain.gelly@gmail.com"], "keywords": ["Metric", "Evaluation", "Video Generation", "Generative Models"], "TL;DR": "We propose FVD: a new metric for generative models of video based on FID. A large-scale human study confirms that FVD correlates well with qualitative human judgment of generated videos.", "abstract": "Recent advances in deep generative models have lead to remarkable progress in synthesizing high quality images. Following their successful application in image processing and representation learning, an important next step is to consider videos. Learning generative models of video is a much harder task, requiring a model to capture the temporal dynamics of a scene, in addition to the visual presentation of objects. While recent generative models of video have had some success, current progress is hampered by the lack of qualitative metrics that consider visual quality, temporal coherence, and diversity of samples. To this extent we propose Fr\u00e9chet Video Distance (FVD), a new metric for generative models of video based on FID. We contribute a large-scale human study, which confirms that FVD correlates well with qualitative human judgment of generated videos.", "pdf": "/pdf/d9effdb2745776630f000d6c2c74d2eaf67da8a0.pdf", "paperhash": "unterthiner|fvd_a_new_metric_for_video_generation"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "HJlR4udf9E", "original": null, "number": 2, "cdate": 1555363893847, "ddate": null, "tcdate": 1555363893847, "tmdate": 1556906131697, "tddate": null, "forum": "rylgEULtdN", "replyto": "rylgEULtdN", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Official_Review", "content": {"title": "A new metric to evaluate generative models of video", "review": "The paper presents a new metric (FVD) for generative models of video. It basically builds on Frechet Inception Distance (FID) which has been proposed for Images and extends it to sequential data such as videos. It captures both the temporal coherence of the content of the video and the quality of each frame. Authors present a thorough evaluation of this proposed metric and show that it correlates with the qualitative human judgements of generated video.\n\nI am not an expert in this area. Still, I felt that the paper could have been presented in a better way. The new metric FVD is not well motivated. The paper is difficult to read, it is written as a summary, and most of experimental setup and evaluated systems are moved to appendices.  Given that the main paper is presented in only 3 pages (with appendices, it is only 8 pages), I  didn't understand the need of appendix sections. First three pages were not inclusive. If accepted, I would recommend to make the paper inclusive of all the details. \n\n", "rating": "3: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FVD: A new Metric for Video Generation", "authors": ["Thomas Unterthiner", "Sjoerd van Steenkiste", "Karol Kurach", "Rapha\u00ebl Marinier", "Marcin Michalski", "Sylvain Gelly"], "authorids": ["unterthiner@bioinf.jku.at", "sjoerd@idsia.ch", "kkurach@gmail.com", "raphael.marinier@gmail.com", "cyfra0@gmail.com", "sylvain.gelly@gmail.com"], "keywords": ["Metric", "Evaluation", "Video Generation", "Generative Models"], "TL;DR": "We propose FVD: a new metric for generative models of video based on FID. A large-scale human study confirms that FVD correlates well with qualitative human judgment of generated videos.", "abstract": "Recent advances in deep generative models have lead to remarkable progress in synthesizing high quality images. Following their successful application in image processing and representation learning, an important next step is to consider videos. Learning generative models of video is a much harder task, requiring a model to capture the temporal dynamics of a scene, in addition to the visual presentation of objects. While recent generative models of video have had some success, current progress is hampered by the lack of qualitative metrics that consider visual quality, temporal coherence, and diversity of samples. To this extent we propose Fr\u00e9chet Video Distance (FVD), a new metric for generative models of video based on FID. We contribute a large-scale human study, which confirms that FVD correlates well with qualitative human judgment of generated videos.", "pdf": "/pdf/d9effdb2745776630f000d6c2c74d2eaf67da8a0.pdf", "paperhash": "unterthiner|fvd_a_new_metric_for_video_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Official_Review", "cdate": 1554234179637, "reply": {"forum": "rylgEULtdN", "replyto": "rylgEULtdN", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234179637, "tmdate": 1556906085339, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "SJ9vIX-54", "original": null, "number": 1, "cdate": 1555277409515, "ddate": null, "tcdate": 1555277409515, "tmdate": 1556906131485, "tddate": null, "forum": "rylgEULtdN", "replyto": "rylgEULtdN", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Official_Review", "content": {"title": "metric for evaluating video generation", "review": "The paper extends the FID metric used for evaluating generative sample quality to video generation. They use I3D network that generalises the Inception architecture to sequential data. The paper provides extensive comparison with other baseline method and does a thorough human evaluation to show that their proposed metric has significant consensus with human evaluation.  ", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FVD: A new Metric for Video Generation", "authors": ["Thomas Unterthiner", "Sjoerd van Steenkiste", "Karol Kurach", "Rapha\u00ebl Marinier", "Marcin Michalski", "Sylvain Gelly"], "authorids": ["unterthiner@bioinf.jku.at", "sjoerd@idsia.ch", "kkurach@gmail.com", "raphael.marinier@gmail.com", "cyfra0@gmail.com", "sylvain.gelly@gmail.com"], "keywords": ["Metric", "Evaluation", "Video Generation", "Generative Models"], "TL;DR": "We propose FVD: a new metric for generative models of video based on FID. A large-scale human study confirms that FVD correlates well with qualitative human judgment of generated videos.", "abstract": "Recent advances in deep generative models have lead to remarkable progress in synthesizing high quality images. Following their successful application in image processing and representation learning, an important next step is to consider videos. Learning generative models of video is a much harder task, requiring a model to capture the temporal dynamics of a scene, in addition to the visual presentation of objects. While recent generative models of video have had some success, current progress is hampered by the lack of qualitative metrics that consider visual quality, temporal coherence, and diversity of samples. To this extent we propose Fr\u00e9chet Video Distance (FVD), a new metric for generative models of video based on FID. We contribute a large-scale human study, which confirms that FVD correlates well with qualitative human judgment of generated videos.", "pdf": "/pdf/d9effdb2745776630f000d6c2c74d2eaf67da8a0.pdf", "paperhash": "unterthiner|fvd_a_new_metric_for_video_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Official_Review", "cdate": 1554234179637, "reply": {"forum": "rylgEULtdN", "replyto": "rylgEULtdN", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234179637, "tmdate": 1556906085339, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper11/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "HklSNVuPqE", "original": null, "number": 1, "cdate": 1555690541341, "ddate": null, "tcdate": 1555690541341, "tmdate": 1556906131275, "tddate": null, "forum": "rylgEULtdN", "replyto": "rylgEULtdN", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "Accepted"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FVD: A new Metric for Video Generation", "authors": ["Thomas Unterthiner", "Sjoerd van Steenkiste", "Karol Kurach", "Rapha\u00ebl Marinier", "Marcin Michalski", "Sylvain Gelly"], "authorids": ["unterthiner@bioinf.jku.at", "sjoerd@idsia.ch", "kkurach@gmail.com", "raphael.marinier@gmail.com", "cyfra0@gmail.com", "sylvain.gelly@gmail.com"], "keywords": ["Metric", "Evaluation", "Video Generation", "Generative Models"], "TL;DR": "We propose FVD: a new metric for generative models of video based on FID. A large-scale human study confirms that FVD correlates well with qualitative human judgment of generated videos.", "abstract": "Recent advances in deep generative models have lead to remarkable progress in synthesizing high quality images. Following their successful application in image processing and representation learning, an important next step is to consider videos. Learning generative models of video is a much harder task, requiring a model to capture the temporal dynamics of a scene, in addition to the visual presentation of objects. While recent generative models of video have had some success, current progress is hampered by the lack of qualitative metrics that consider visual quality, temporal coherence, and diversity of samples. To this extent we propose Fr\u00e9chet Video Distance (FVD), a new metric for generative models of video based on FID. We contribute a large-scale human study, which confirms that FVD correlates well with qualitative human judgment of generated videos.", "pdf": "/pdf/d9effdb2745776630f000d6c2c74d2eaf67da8a0.pdf", "paperhash": "unterthiner|fvd_a_new_metric_for_video_generation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper11/Decision", "cdate": 1555612280479, "reply": {"forum": "rylgEULtdN", "replyto": "rylgEULtdN", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1555612280479, "tmdate": 1556906096124, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}