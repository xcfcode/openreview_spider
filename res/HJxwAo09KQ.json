{"notes": [{"id": "ryeUzvVKkN", "original": null, "number": 9, "cdate": 1544271630203, "ddate": null, "tcdate": 1544271630203, "tmdate": 1549840083389, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "SJlea51tTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Still the same issues in the version in the MetaLearning workshop", "comment": "I just looked into the version of this work accepted at the NeurIPS workshop on MetaLearning (http://metalearning.ml/2018/papers/metalearn2018_paper38.pdf -- warning to other reviewers: clicking this link will reveal the authors' identity), and I am disappointed to see that the issues with the experiments are not mentioned in it, even though the authors have known about them for a month. \n\nI am not asking for new experiments, just for explicitly stating that the authors only compare to optimizers with fixed learning rates and without any regularization. Otherwise, people will walk away from this with overblown expectations, thinking we all should use these learned optimizer (and that the only issue left is generalization to new problems, but this is simply not the case)!\n\nI hope that this was merely an issue of the authors forgetting to update that paper. I strongly encourage the authors to emphasize the limitations of the work and to update the camera ready copy. "}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "HkxFS_qaxN", "original": null, "number": 12, "cdate": 1545607233354, "ddate": null, "tcdate": 1545607233354, "tmdate": 1545607233354, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "B1gnWF_FkV", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Issue resolved", "comment": "The authors updated the metalearning workshop paper, resolving the issue I raised. \nI'm looking forward to seeing this interesting work progress!"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "HJxwAo09KQ", "original": "H1ey6H0KY7", "number": 900, "cdate": 1538087886521, "ddate": null, "tcdate": 1538087886521, "tmdate": 1545355409938, "tddate": null, "forum": "HJxwAo09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1gOOD7yx4", "original": null, "number": 1, "cdate": 1544660848420, "ddate": null, "tcdate": 1544660848420, "tmdate": 1545354504188, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Meta_Review", "content": {"metareview": "The paper conveys interesting idea but need more work in terms of fair empirical study and also improvement of the writing. The AC based her summary only on the technical argumentation presented by reviewers and authors. ", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper900/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353043260, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353043260}}}, {"id": "B1gnWF_FkV", "original": null, "number": 10, "cdate": 1544288516444, "ddate": null, "tcdate": 1544288516444, "tmdate": 1544288516444, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "ryeUzvVKkN", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Metalearning workshop ", "comment": "Thank you for your ongoing care as a reviewer.\n\nWe have not updated the 4 page metalearning workshop paper since its submission before the review discussion \u2014 we have simply been busy.\n\nWe completely agree that more extensive baselines would improve the paper. Especially, it would make our results stronger to compare against first order methods in conjunction with regularization, rather than first order methods on their own. We in fact have experiments currently running which extend the baselines in this and other fashions. We intend to include these additional baselines in any future submitted version of the paper.\n\nHowever, we also believe that the current baselines are accurately and clearly described, and we do not believe them to be in any sense dishonest."}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "B1ljRQC4yN", "original": null, "number": 8, "cdate": 1543984083330, "ddate": null, "tcdate": 1543984083330, "tmdate": 1543984083330, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "SJlea51tTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Good luck with a future submission", "comment": "Thank you for your response, and for accepting my points of criticism & promising to fix them for future submissions. I'm looking forward to seeing this interesting work progress!\n\nJust a quick point about your reply concerning reproducibility: while the weights of the learned optimizer would be somewhat interesting, it would be far more useful for the community to have access to the code for training these weights. E.g., only on toy problems, so that it can be run without massive compute resources (but even if it does take a lot of compute that would still be extremely useful).\n\nBy the way, since the paper's methodological contribution is about how the gradient signal is computed, and the definition of learned optimizers is \"just\" an application (and probably weaker when comparing to stronger baselines), you could consider changing the paper title to something along the lines of \"Computing high quality gradient signals for unrolled computation graphs\". \n\nGood luck with the continuation of this work!"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "rkl4p-n6sm", "original": null, "number": 2, "cdate": 1540370876055, "ddate": null, "tcdate": 1540370876055, "tmdate": 1542801955397, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "content": {"title": "An interesting paper too condensed and difficult to understand", "review": "Review:\n\n\tThis paper proposes a method to learn a neural network to perform optimization. The idea is that the neural network will receive as an input several parameters, including the weights of the network to be trained, the gradient, and so on, and will output new updated weights. The neural network that is used to compute new weights can be trained through a complicated process called un-rolled optimization. The authors of the paper show two problems with this approach. Namely, the gradients tend to explode as the number of iterations increases. Truncating the gradient computation introduces some bias. To solve these problems the authors propose a variational objective that smooths the objective surface. The proposed method is evaluated on the image net dataset showing better results than first order methods optimally optimized.\n\nQuality: \n\n\tThe quality of the paper is high. It addresses an important problem of the community and it seems to give better results than first other methods.\n\nClarity: \n\n\tThe clarity of the paper is low. It is difficult  to follow and includes many abstract concepts that the reader is not familiar with. I have had problems understanding what the truncation means. Furthermore, it is not clear at all how the validation data is used as a target in the outer-objective.  It is also unclear how the bias problem is addressed by the method proposed by the authors. They have said nothing about that, yet in the abstract they say that the proposed method alleviates the two problems detected.\n\nOriginality: \n\n\tAs far as I know the idea proposed is original and very useful to alleviate, at least, one of the problems mentioned of exploding gradients.\n\nSignificance:\n\n\tIt is not clear at all that the method is evaluated on unseen data when using the validation data for outer-training. This may question the significance of the results.\n\nPros:\n\n\t- Interesting idea.\n\n\t- Nice illustrative figures.\n\n\t- Good results.\n\nCons:\n\n\t- Unclear points in the paper with respect to what truncation means.\n\n\t- The validation data is used for training and there is no left-out data, which may bias the results.\n\n\t- Unclear how the authors address the bias problem in the gradients.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "cdate": 1542234351184, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335828693, "tmdate": 1552335828693, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1eAW5pfCm", "original": null, "number": 7, "cdate": 1542801925571, "ddate": null, "tcdate": 1542801925571, "tmdate": 1542801925571, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "r1ewyjyFpX", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Response to authors feedback", "comment": "Although I had initially increased a bit my score, I also think that the third reviewer may have a point. Doing what the first reviewer suggest could be the way to go to guarantee fair experiments. Therefore, I have left my score unchanged. "}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "BJgDdU6GAm", "original": null, "number": 6, "cdate": 1542801007130, "ddate": null, "tcdate": 1542801007130, "tmdate": 1542801007130, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "r1gjUikY6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Weight decay", "comment": "After reading the other reviews I want to further raise the issue that Reviewer3 raised for weight decay. I do think that it is unfair to pass to the learned optimizer as inputs the \"parameter values\" as indicated at the begining of the experimental section This allows them to effectively learn a weight decay update (and essentially simple prior functions over the weights) which could be the main (or even only) reason why the the proposed method perfrorms better than the baselines. Hence, I think for this experiment to be convincing you need to either exclude this term from the inputs to the MLP (and anything else that can resemble it) or alternatively include a weight decay parameter in the baseline algorithms and optimize that with respect to the final validation loss. "}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "S1x__R5z0m", "original": null, "number": 5, "cdate": 1542790767571, "ddate": null, "tcdate": 1542790767571, "tmdate": 1542790767571, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "r1ewyjyFpX", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Response to Author Feedback", "comment": "Thanks for the clarifications. Given them, I will slightly increase my score. "}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "r1gjUikY6Q", "original": null, "number": 4, "cdate": 1542155090960, "ddate": null, "tcdate": 1542155090960, "tmdate": 1542155090960, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "Byl8hoXzom", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Thank you", "comment": "Thank you for your thoughtful review! We will take these under consideration for a future submission. Comments addressed below.\n\nj=i+1: You are indeed correct. This was an unfortunate typo we realized just after submitting. Good catch and thank you for giving our work such a thorough review!\n\nYour points as to exploding or vanishing gradients are correct. If the optimal learning rate is known ahead of time (requiring knowledge of the hessian at each iteration) it is possible to not have exploding gradients. In practice, however, it is rarely possible to find useful bounds on the eigenvalues of the Hessian in neural network training. This, coupled with the fact that the optimal learning rate is often at the edge of unstable dynamics, can lead to learning rates in the unstable regime and thus exploding gradients.\n\nWe appreciate the comment about vanishing gradients. We will update this section discussing that gradients do not vanish -- only explode. (Note that the outer-parameters are used at every training iteration -- so even if the backpropagated outer-gradient shrinks exponentially with respect to unrolled optimization steps, it does not vanish with respect to the outer-parameters.)\n\n\" However, surprisingly here the authors rather than optimizing the learning rate, which they analyzed in the previous part of the section, they are now optimizing the momentum.\"\n\nHere, we use momentum as it more clearly maps to a physical phenomenon, in the hope that it provides better intuition. Similar behavior holds for learning rate -- it is possible to take a step that is either just under or just over a local maximum, resulting in diverging trajectories.\n\n\"in addition to the fact that usually large over-parameterized models behave differently than small models.\"\nWe use these toy problems as a tool to build intuition as understanding the non-convex setting is very complex. That being said, we have done additional work (not included) around exploring these effects on larger problems. In particular, we are able to find multiple saddle points / paths to descend a loss function resulting in discontinuous trajectories, and exploding gradients (as in the toy case). We do this by taking 2d slices through the inner problems, and sweeping meta-parameters. We observe discontinuous jumps in final location and trajectory. We will look into adding, likely in the appendix, some examples of this behavior in large networks. We emphasize that Figure 3e already shows a slice through the outer-loss landscape for a neural network task and a neural network optimizer, and that pathological behavior in the unrolled loss landscape is visible in this figure.\n\nScale: As of now, these methods are quite expensive. As a result, the field mostly explores meta-training on small scale tasks. Despite the expense, this work operates on considerably larger models than almost all prior work. We train conv-nets (as opposed to small MLPs) and train for 10k inner-iterations -- around 2 orders of magnitude longer than most existing work. We are extremely interested in pushing these methods further -- applying to even larger problems, but instability in meta-training has previously been a major obstacle to such scaling.\n\n\"Hence I think its slightly unfair to compare their \"final performance\" after this fixed period.\": When evaluating on training loss, we show optimization speed. With regard to validation loss, you are correct that we do not provide sufficient detail for the \"better final performance\" claim. In practice, we find overfitting occurs in under 20k inner-iterations (Shown in the dashed line on the figures). We will modify the text / figures to show the training step where existing optimizers begin to overfit.\n\n\" From the text it is also unclear whether the authors have optimized the parameters of the first-order methods with respect to their training or validation performance\"\nWe do the latter, and will update the text to better emphasize this.\n\n\"Figure 6 - the results here seem to indicate that the learned optimizer transfers reasonably well, achieving similar performance to first-order methods (slightly faster validation reduction). Given however that these are plots for only 10000 iterations it is still unclear if this is scalable to larger problems.\"\nTransfer to larger problems was not the focus of this work. We targeted stable training of task specific optimizers. In this context, 10k inner iterations is enough to achieve the best performance on these tasks (with learned optimizers). We agree that transfer to larger problems is critical for broad applicability, and are actively working on this.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "r1ewyjyFpX", "original": null, "number": 3, "cdate": 1542154974846, "ddate": null, "tcdate": 1542154974846, "tmdate": 1542154974846, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "rkl4p-n6sm", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Thank you", "comment": "Thank you for your thoughtful review. We will take these under consideration for a future submission. We have addressed your comments below.\n\nTruncation: Due to space limitations, we were unable to include a more comprehensive introduction to truncated backpropagation through time (TBTT). We would emphasize though that TBTT is a standard approach in training RNNs, and that it has an identical meaning in the case of backpropagation through many timesteps of unrolled optimization as it does in backpropagation through many timesteps of RNN dynamics. We will update the text to further emphasize this correspondence.\n\nUnseen / validation data: We agree that the distinction between validation data on train tasks and validation data on *test* tasks was unclear. We have updated the text to clarify this. To answer your question: we never see any test data before test time. This includes both the training and validation/test images. We split the Imagenet dataset by class (700 for train, 300 for test) and outer-train on the training set (using both train and validation data from those 700 classes). When evaluating our model, we use the alternate set (the remaining 300 test classes), and only use the training images for training those models.\n\nCombating biased gradients: Previous work was unable to train with longer truncations because of exploding gradients. In this work, we can simply make the truncation length longer which reduces the bias in the gradients. By unrolling longer, we drop fewer terms from the true gradient, thus lowering bias. We will make this connection clearer in the text.\f"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "SJlea51tTQ", "original": null, "number": 2, "cdate": 1542154936083, "ddate": null, "tcdate": 1542154936083, "tmdate": 1542154936083, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "Byetapx9nQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Thank you", "comment": "Thank you for your thoughtful review! We will take these under consideration for a future submission. Comments addressed below.\n\nLack of good baseline:\nYou raise a good point. We will update the paper to include a more extensive hyperparameter search for the baselines, including a denser learning rate search, and a search over regularization and learning rate decay parameters. We will also soften the claims surrounding speedups over hand designed optimizers.\n\nHowever, we would like to reemphasize that learned optimizers have not previously been shown to beat, or even match, standard first order optimizers on wall clock time. We would also like to reemphasize that previous approaches to meta-training learned optimizers required many tricks, and a lucky choice of random seed. A primary aim of our experiments was to provide proof that the proposed meta-training method works well and is reliable enough to train a simple mlp meta-optimizer without the complex tricks employed in other works. We believe that this work represents a significant step forward in training learned optimizers, and we are gratified to hear that you thought our analysis sections and proposed fixes were convincing.\n\n\"I don't see why the unnumbered equation necessarily leads to an exponential increase; H^{(j)} can be different for each j, such that there isn't a single term being exponentiated. Or am I mistaken?\"\n\nYou are correct that H^{(j)} can be different for each training iteration in the general case. In a quadratic setting, H is constant, and the outer-gradient will explode if the learning rate is too large. In the non-quadratic setting (any time the Hessian is changing) it is possible for this equation to be stable depending on the sequence of Hessians encountered. Empirically, we find that the optimal meta-parameters are right on the edge of instability, so it is common to enter the unstable regime, causing outer-gradients to then grow exponentially with the number of steps.\n\n\"The global minimum of the function is not 0.5 as stated in the caption\":\nThis is a typo and will be fixed. Should be ~3.5 (the actual global min). Thank you for spotting this.\n\n\"The problem in Figure 3a is not the problem discussed in the text.\"\nThis is discussed in the last paragraph of page 4.\n\nReproducibility: We provide more detailed information about experiments in the appendix (page 11-12). Additionally, we are looking into options as to how to release evaluation code containing demonstrative problems and the weights of the learned optimizer.\n\f"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}, {"id": "Byetapx9nQ", "original": null, "number": 3, "cdate": 1541176769281, "ddate": null, "tcdate": 1541176769281, "tmdate": 1541533595648, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "content": {"title": "Interesting method, but oversold results", "review": "This paper tackles the problem of learning an optimizer, like \"learning to learn by gradient descent by gradient descent\" and its follow-up papers. Specifically, the authors focus on obtaining cleaner gradients from the unrolled training procedure. To do this, they use a variational optimization formulation and two different gradient estimates: one based on the reparameterization trick and one based on evolutionary strategies. The paper then uses a method from the recent RL literature to combine these two gradient estimates to obtain a variance that is upper-bounded by the minimum of the two gradients' variances. \n\nWhile the method for obtaining lower-variance gradients is interesting and appears useful, the application to learn optimizers is very much oversold: the paper states that the comparison is to \"well tuned hand-designed optimizers\", but what that comes down to in the experiments is Adam, SGD+Momentum, and RMSProp with a very coarse grid of 11 learning rates and *no regularization* and *no learning rate schedule*. The authors' proposed optimizer is just a one-layer neural net with 32 hidden units that gets as input basically all the terms that the hand-designed optimizers compute, and it has everything it needs to simply use weight decay and learning rate schedules -- precisely what you need for the authors' contributions (speed and generalization). This is a fundamental flaw in the experimental setup (in particular the choice of baselines) and thus a clear reason for rejection.\n\nSome details:\n\n- While the authors' method is optimized by training 5 x 0.5 million, i.e. 2.5 million (!) full inner optimization runs of 10k steps each, the hand-designed optimizers get to try 11 values for the learning rate, which are logarithmically spaced between 10^{-4} and 10 (i.e., very coarsely, with sqrt{10} difference between successive values; even just for this fixed learning rate one would want to space factors by as little as 1.1 or so in the optimal region). \n\n- The lack of any learning rate schedule for the baselines is highly problematic; it is common knowledge that learning rate schedules are important. This is precisely why one would want to do research on learning optimizers to set the learning rate! Of course, without learning rate schedules one will not obtain a very efficient optimizer and it is easy to show large speedups over that poor baseline (the authors' first stated contribution in the title).\n\n- The authors' second stated contribution is that their learned optimizers generalize better than the baselines. But they pass their optimizers all information required to learn arbitrary weight decay, while the baselines are not allowed to use any weight decay. Thus, the second stated contribution in the title also does not hold up.\n\n- There are many details in the experiments that would be hard to reproduce truthfully. Given the reproducibility crisis in machine learning, I would trust the results far more if the authors made their code available in anonymized form during the review period. If the authors did this I could also evaluate it against properly tuned baseline optimizers myself. In that case I would lean towards increasing my score since the availability of code for this line of work would be very useful for the community.\n\n- Page 4 didn't print for me; both times I tried it came out as a blank page. \n\n- Several issues on page 4: \n - I don't see why the unnumbered equation necessarily leads to an exponential increase; H^{(j)} can be different for each j, such that there isn't a single term being exponentiated. Or am I mistaken?\n - The problem in Figure 3a is not the problem discussed in the text\n - The global minimum of the function is not 0.5 as stated in the caption\n - It is not stated what sort of MLP there is in Figure 3d (again, code availability would fix things like this)\n\n- Section 5 is extremely dense. This is the paper's key methodological contribution, and it is less than a page! I would suggest that the authors describe these methods in more detail (about another page) and save space elsewhere in the paper.\n\nThe paper is written well and the illustrations of the issues of TBPTT, as well as the authors' fix are convincing. It's a shame, but unfortunately, the stated contributions for the learned optimizers do not hold up.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "cdate": 1542234351184, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335828693, "tmdate": 1552335828693, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Byl8hoXzom", "original": null, "number": 1, "cdate": 1539615662144, "ddate": null, "tcdate": 1539615662144, "tmdate": 1541533595188, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "content": {"title": "Good idea, but needs more work", "review": "Summary:\nThe paper presents a method for \"learning an optimizer\"(also in the literature Learning to Learn and a form of Meta-Learning) by using a Variational Optimization for the \"outer\" optimizer loss. The mean idea of the paper is to combine both the reparametrized gradient and the score-function estimator for the Variational Objective and weight them using a product of Gaussians formula for the mean. The method is simple and clearly presented. The paper also presents issues with the standard \"learning to learn\" optimizers, one being the short-horizon bias and as credited by the authors has been observed before in the literature, and the second one is what is termed the \"exponential explosion of gradients\" which I think lacks enough justification as currently presented (see below for details). The ideas are clearly stated, although the work is not groundbreaking, but more on combining several ideas into a single one. \n\nExperiments: \nThe authors evaluate their method on a single task which consists of optimizing a 3-layer convolutional neural network on downsampled images from ImageNet. A key idea, not new to this work, is to optimize the meta-optimizer with respect to the validation dataset rather than the training, which seems to be crucial for any meaningful training to happen. Although the experiments do show so promising results, they seem to be somewhat limited (see below for details). There is also a small ablation study on how do different features presented to the optimizer affect its performance. Given the still small-scale experiments, I'm not sure this is a significant result for the community. \n\nConclusion:\nAs a whole, I think the idea in the paper is a good one and worth investigating further. However, the objections I have on section 2.3 and the experiments seem to indicate that there needs to be more work into this paper to make it ready for publication. \n\n\nOn section 2.3 and the explosion of gradients:\n\nThere is a mistake in the equation on page 4 regarding the \"gradient with respect to the learning rate\". Although the derivation in Appendix A is correct, the inner product in the equation starts wrongly from j=0, where it should in fact start at j = i + 1. To be more clear the actual enrolled equation for dw^T/dt for 3 steps back is:\n\ndw^T/dt = (I - tH^{T-1})(I - tH^{T-2})(I - tH^{T-3}) dw^{T-3} - (I - tH^{T-1})(I - tH^{T-2}) g^{T-3} - (I - tH^{T-1}) g^{T-2} - g^{T-1} \n\nHence the product must start at j = i + 1. \nIt is correct that in this setting the equation is a polynomial of degree T of the Hessian, however, there are several important factors that the authors have not discussed. Namely, if the learning rate is chosen accordingly such that the spectral radius of the Hessian is less than 1/t then rather than the gradient exploding the higher order term will vanish. However, even if they do vanish for large T since the Hessian plays with smaller and smaller power to more recent gradients (after correcting the mistake in the equation) than the actual T-step gradient will never vanish (in fact even if tH = I then dw^T/dt = g^{T-1}). Hence the claims of exploding gradients made in this section coupled with the very limited theoretical analysis seem to unconvincing that this is nessacarily an issue and under what circumstances they are. \n\nThe toy example with l(w) = (w - 4)(w - 3) w^2 is indeed interesting for visualizing a case where the gradient explosion does happen. However, surprisingly here the authors rather than optimizing the learning rate, which they analyzed in the previous part of the section, they are now optimizing the momentum. The observation that at high momentum the training is unstable are not really surprising as there are fundamental reasons why too high momentum leads to instabilities and these have been analyzed in the literature. Additionally, it is not mentioned what learning rate is used, which can also play a major role in the effects observed. \n\nAs a whole, although the example in this section is interesting, the claims made by the authors and some of the conclusions seem to lack any significant justifications, in addition to the fact that usually large over-parameterized models behave differently than small models. \n\n\nExperiments:\n\nI have a few key issues with the experimental setup, which I think need to be addressed:\n\n1. The CNN being optimized is quite small - only 3 layers. This allows the authors to train everything on a CPU. The key issue here, as well with previous work on Learning to Learn, is that it is not clear how scalable is this method to very Deep Networks. \n\n2. Figure 1 - The setup is to optimize the problem for 10000 iterations, however, I think it is pretty clear even to the naked eye that the standard first-order optimizers (Adam/RMS/Mom) have not fully converged on this problem. Hence I think its slightly unfair to compare their \"final performance\" after this fixed period. Additionally using the curriculum the \"meta\"-optimizer is trained explicitly for 10000 iterations. Hence, it is also unclear if it retains its stability after letting it run for longer. From the text it is also unclear whether the authors have optimized the parameters of the first-order methods with respect to their training or validation performance - I hope this is the latter as that is the only way to fairly compare the two approaches. \n\n3. Figure 6 - the results here seem to indicate that the learned optimizer transfers reasonably well, achieving similar performance to first-order methods (slightly faster validation reduction). Given however that these are plots for only 10000 iterations it is still unclear if this is scalable to larger problems. \n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper900/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Review", "cdate": 1542234351184, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxwAo09KQ", "replyto": "HJxwAo09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335828693, "tmdate": 1552335828693, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJxzDbc1n7", "original": null, "number": 1, "cdate": 1540493657848, "ddate": null, "tcdate": 1540493657848, "tmdate": 1540493657848, "tddate": null, "forum": "HJxwAo09KQ", "replyto": "SJg3QlISjX", "invitation": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "content": {"title": "Overfitting is impossible, since the dataset was not seen during optimizer training", "comment": "Thank you for your interest and comment! Sorry for the slow response -- we did not receive email notification of your comment, and are only seeing it now.\n\nFigure 1 was generated by applying the learned optimizer to a holdout dataset that was not seen during optimizer training. So, the good performance can not be a result of the optimizer overfitting to the training or validation loss of its training tasks, since the optimizer is being evaluated on a task which it was not trained on.\n\nThe optimizer is specifically targeted at optimizing three layer CNNs -- the goal in this paper is to design an optimizer that is very good at optimizing a specific architecture. (Though as we explore in Figure 6, and Appendix E, it does nonetheless demonstrate some generalization to new architectures.)\n\nWe will modify the Figure 1 caption to better emphasize that the optimizer was not trained on the dataset it is being applied to in the figure, but that it was trained specifically to be very good at optimizing three layer CNNs."}, "signatures": ["ICLR.cc/2019/Conference/Paper900/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learned optimizers that outperform on wall-clock and validation loss", "abstract": "Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned update functions may similarly outperform current hand-designed optimizers, especially for specific tasks. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process. The resulting gradients are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance. This allows us to train neural networks to perform optimization faster than well tuned first-order methods. Moreover, by training the optimizer against validation loss, as opposed to training loss, we are able to use it to train models which generalize better than those trained by first order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks in a fifth of the wall-clock time compared to tuned first-order methods, and with an improvement", "keywords": ["Learned Optimizers", "Meta-Learning"], "authorids": ["lmetz@google.com", "nirum@google.com", "jeremynixon@google.com", "cdfreeman@google.com", "jaschasd@google.com"], "authors": ["Luke Metz", "Niru Maheswaranathan", "Jeremy Nixon", "Daniel Freeman", "Jascha Sohl-dickstein"], "TL;DR": "We analyze problems when training learned optimizers, address those problems via variational optimization using two complementary gradient estimators, and train optimizers that are 5x faster in wall-clock time than baseline optimizers (e.g. Adam).", "pdf": "/pdf/2c94269a1648cac4ba5ccf7f1c3b5c505a09e1be.pdf", "paperhash": "metz|learned_optimizers_that_outperform_on_wallclock_and_validation_loss", "_bibtex": "@misc{\nmetz2019learned,\ntitle={Learned optimizers that outperform on wall-clock and validation loss},\nauthor={Luke Metz and Niru Maheswaranathan and Jeremy Nixon and Daniel Freeman and Jascha Sohl-dickstein},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxwAo09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper900/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621624903, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxwAo09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper900/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper900/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper900/Authors|ICLR.cc/2019/Conference/Paper900/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper900/Reviewers", "ICLR.cc/2019/Conference/Paper900/Authors", "ICLR.cc/2019/Conference/Paper900/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621624903}}}], "count": 16}