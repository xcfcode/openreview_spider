{"notes": [{"id": "SRzz6RtOdKR", "original": "vc3kbOLXHf1", "number": 2598, "cdate": 1601308287670, "ddate": null, "tcdate": 1601308287670, "tmdate": 1614985742611, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "qZ8ALB2Znwt", "original": null, "number": 1, "cdate": 1610040395204, "ddate": null, "tcdate": 1610040395204, "tmdate": 1610473990250, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The manuscript presents a deep network approach for heteroscedastic regression problem. It assumes the variance of heteroscedastic noise is known as privileged information and suggests to reweight the samples by their noise variance in the loss.\n\nThree reviewers agreed that the manuscript is not ready for publication. The major issue is the lack of novelty. Heteroscedastic regression is a classic problem in statistics. And reweighting using the inverse variance is a textbook method. \n\nR2 and R4 confirmed that they have read author response. The rebuttals are useful to clarify some points, especially related to experimental settings and results. However, they are not convinced by the authors' argument on novelty and whether the assumption is realistic. \n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040395188, "tmdate": 1610473990233, "id": "ICLR.cc/2021/Conference/Paper2598/-/Decision"}}}, {"id": "9MV-YVGu7Wl", "original": null, "number": 10, "cdate": 1606245781029, "ddate": null, "tcdate": 1606245781029, "tmdate": 1606245781029, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "crmGCKUiKcU", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Results about the robustness of BIV", "comment": "We would like to notify the reviewer that we have updated our manuscript with new results, as announced in our previous response. \n\nWe show that BIV is robust to moderate to high levels of noise in the variance. We also show that the number of samples in a mini-batch is not critical to the performance of BIV. These results are mentioned in part 6.4 and the details are in appendix B.4.\n\nWe hope that these results help making the experiments more convincing, as this was a concern raised by the reviewer."}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "y__JPxMgQmO", "original": null, "number": 9, "cdate": 1606245418129, "ddate": null, "tcdate": 1606245418129, "tmdate": 1606245418129, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "eZ_RUP2pekQ", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Results about the impact of batch size", "comment": "We would like to notify the reviewer that we have updated our manuscript with new results, as announced in our previous response. \n\nWe ran experiments with batch sizes of 16 to 256 and we show that the size of the mini-batch does not have a significant impact on the optimization process compared to L2 learning with the same batch size. These results are mentioned in section 6.4 and more details can be found in the appendix B.4.1. We hope that they address the concern raised by the reviewer."}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "Vjaj2eiIPLN", "original": null, "number": 8, "cdate": 1606244843381, "ddate": null, "tcdate": 1606244843381, "tmdate": 1606244843381, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "cpV5jZq1zzO", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Results about importance of variance accuracy ", "comment": "We would like to notify the reviewer that we have updated our manuscript with new results, as announced in our previous response.\nWe show that BIV is robust to moderate to high levels of noise in the variance. These results are mentioned in part 6.4 and the details are in the appendix B.4.2.\nWe hope this addresses the concern raised by the reviewer with respect to the assumption that the estimate of the variance is accurate enough."}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "eZ_RUP2pekQ", "original": null, "number": 7, "cdate": 1605632734696, "ddate": null, "tcdate": 1605632734696, "tmdate": 1605632734696, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "h4zrdPUIybz", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Response to AnonReviewer2 - part 2/2", "comment": "**Finally, in Fig.3, there are clear signs of overfitting: why did the authors suggest (end of Sec.3) that their work does not require regularisation?**\n\nIndeed, there is still overfitting with BIV, although it is less significant than with the competing methods. There is a confusion here. At the end of Sec. 3, we were comparing the loss function used in Kendall & Gal (2017) where log(sigma^2) is used to regulate the estimation of the data-related variance of the labels, which could be set to infinity otherwise as a trivial solution for their loss function. We have added a precision in the text to avoid confusing other readers.\n\n**The loss is scaled by a coefficient that collects statistics on the sample batch: if this batch is very small, or its elements not sufficiently diverse, I am afraid it could have a negative impact on the optimisation process (this is why, in the experiments, the authors chose a batch size of 256).**\n\nThis is a very interesting remark. First, to clarify, we have not chosen a batch size of 256 for this reason. Instead, when determining the amount of noise for our experiments, we noticed that, as reported by Rolnick and al. (2017), dataset noise can be partly compensated for by larger batch sizes, as noisy labels roughly cancel out. In L2 loss indeed, the effect of noise was significantly lower when the batch size was higher. It is to ensure the best performances for our L2 baseline that we chose to keep 256. We have clarified this in section A.1.2.\nWith respect to the representativity of each batch: indeed, the differences between the normalization constants applied to each batch would be statistically higher for smaller batches. While this should impact the optimisation process by mitigating the effects of BIV, we do not expect that it makes it worse than the L2 or \u201ccutoff\u201d baselines with the same batch size. We plan however to provide the reviewer with experimental results in the following days, that will test this hypothesis and will be added in the Appendix with a mention in the text.\n\n**A note on experiments using the UTKFace dataset. In this case, the MLP used with 4 layers may be a bit \u201ctoo simple\u201d, in light of the high test loss on GT labels. Did you try with convolutional architectures, even simple ones?**\n\nThere is a confusion here. For UTKFace, we did use the convolutional architecture of Resnet 18, as described in the appendix. We have tried several resnets and other simple convolutional architectures, and optimized the hyperparameters accordingly. Resnet18 was giving us the best results. We have made the precision in section 5. The GT labels have a test loss of 0.24, which represents a standard deviation of around 10 years old after de-normalizing, which is reasonable for this task. \n\n**Just to clarify, the test loss reported in the figures, as a function of training steps: what is the test batch size? Same as training batch size? The test loss is computer according to $\\sum_{k \\in \\text{test batch}} \\mathcal{L}(f(\\mathbf{x}_k, \\theta), \\tilde{y}_k)$ right?**\n\nThere is a confusion here. The test loss is computed with the ground-truth label values, in order to evaluate the performance of the model on its actual task (in most realistic situations, ground-truth test data would not be available, but this is not the point of the paper). \nThe loss is then $\\sum_{k \\in \\text{test batch}} \\mathcal{L}(f(\\mathbf{x}_k, \\theta), y_k)$, and the size of the test batch size is 256 too (even if it does not matter for the result, as it was computed on the whole test set after each training step). We have clarified this in the new section 5.2."}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "h4zrdPUIybz", "original": null, "number": 6, "cdate": 1605632507731, "ddate": null, "tcdate": 1605632507731, "tmdate": 1605632507731, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "A4bZxRsMaEP", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Response to AnonReviewer2 - part 1/2", "comment": "We thank the reviewer for their in-depth analysis of our work and their constructive remarks.\nAs some elements came several times in the review, we took the liberty to summarize them in the two first paragraphs.\n\n**There is a need for clarification and discussion on the noise likelihood model.**\n\nWe thank the reviewer for this remark. We indeed assume that the noise likelihood is Gaussian, and this asks for justification. We added some explanations in this respect at the beginning of section 2.1., before equation (1): Noise on measured or estimated values is often represented by Gaussian distribution, based on the central limit theorem as most noisy processes are the sum of several independent variables. Gaussian distributions are also practical, although it has some drawbacks as it can only represent uni-modal and symmetric noise models (Thrun et al., 2006). \n\n**There is a need for a thorough comparison to existing approaches to address heteroscedastic Gaussian noise (for simple linear models, weighted least squares with inverse variance weighting is the MLE solution)**\n\nIndeed, re-weighting using the inverse variance is a common strategy in regression, as it is the solution to MLE for Gaussian heteroscedastic noise. We hope to have answered this concern in the response to all reviewers posted above. We thank the reviewer for the references they provided, and have added some in the article.\n\n**For several noise distributions (including the additional ones considered in the supplement), the proposed method BIV does not seem to behave much better than the proposed baseline, that uses a simple threshold.**\n\nThe performance of BIV with respect to the baseline (\u201ccutoff\u201d) is strongly dependent on the variance distribution $P(\\sigma^2)$. When the \u201ccutoff\u201d can get a lot of low-noise data, such as the gamma distribution with alpha = .25 (fig 8 and 9), then the performances are very similar, and a lot better than L2. This is to be expected, as it resembles the binary uniform situation leading to Fig 2. When on the other side there is not a lot of support for low variances, BIV is doing similar to L2 (fig 10 with $\\alpha > 1$) and so would \u201ccutoff\u201d (or worse, as its dataset would be very few data). However, in other cases when the distribution is uniform (fig. 7) or somehow balanced, as for gamma with $\\alpha = 1$ (fig 3), BIV is clearly better than all cutoff and L2.\nWhat is important here is the consistency with which BIV is always at least better than the best of L2 and cutoffs, regardless of $P(\\sigma^2)$. We have underlined this in section 6.3.\n\n**Also, it is mentioned the baseline method requires to set a cutoff parameter, but the proposed method also depends on a hyper parameter to optimise (done in the appendix). As a consequence, it is difficult to appreciate the main advantage of BIV w.r.t. the baseline.**\n\nThe optimal value for $\\epsilon$ depends on the distribution of labels in the dataset. If the latter is normalized (unit variance), then the optimal epsilon is between 0.01 and 0.1, regardless of $P(\\sigma^2)$. As $\\epsilon$ is a \u201cminimal variance\u201d, it is straightforward to scale to any other label distribution. This is very different for the cutoff parameter, which would need to be optimized for every dataset as it is dependent on $P(\\sigma^2)$, as shown in our experiments. We agree that this advantage was not well explained, and we have clarified it in section 6.3.\n\n**Additionally, the figures are cropped and do not allow to get a sense of what happens for all competing methods (Fig1 and Fig2).**\n\nThe competing methods that are cropped in Fig 1 and Fig 2 are the ones using the L2 loss, and they are actually overfitting because of the noise. We have taken advantage of having a bit more space to crop these figures a bit less, so that the viewer can have a better sense of what is happening.\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "cpV5jZq1zzO", "original": null, "number": 5, "cdate": 1605632194116, "ddate": null, "tcdate": 1605632194116, "tmdate": 1605632194116, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "hBcSXDthu8R", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "We thank the reviewer for their constructive review.\n\n**It is a strong and usually impractical assumption to know a priori knowledge of label noise in the regression model training process.**\n\nWe hope to have answered this concern in the response to all reviewers posted above.\n\n**Especially, in the proposed method, the estimate of the noise variance needs to be accurate enough, so as to help suppress the noise impact accordingly.**\n\nIndeed, further studies on the robustness of BIV to noise in the noise variance estimation should be made to ensure that this method is applicable in real world cases. We are planning to add new experimental results in this respect in the following days. We thank the reviewer for this suggestion!\n\n**It is better to incorporate jointly the learning of noise distribution and the regression/classification model, so as to optimize the tolerance against the data-dependent noise.**\n\nThis strategy is indeed used in many frameworks, such as Kendall et al., 2017. The main problem, as correctly underlined by the reviewer, is that it assumes that the noise is data-dependent, which disregards the noise due to the label generator. A mixture of both methods could be interesting however when both kinds of noise are present. We thank the reviewer for their comment, as it will fuel our future reflection on how to improve this work.\n\n**Please refer to the following work for further reading: Learning with Noisy Labels, Nagarajan Natarajan, Inderjit S. Dhillon, Pradeep Ravikumar, and Ambuj Tewari, NIPS 2013.**\n\nWe have added the reference, thank you very much! It is actually very interesting, as this work assumes the knowledge of the probability \\rho of mislabeling, which is very close to our assumption of knowing the variance. As it is applied in binary classification with the same \\rho for each category, the authors are able to optimize these two hyperparameters using cross-validation, which is of course not possible in our case where each sample has its own noise distribution.\n\n**It only considers the noisy learning process for regression. However, in classification scenarios, noise (with respect to labels) is usually presented in the form of label flipping. The proposed reweighing technique is not directly applicable in that case.**\n\nThere is a lot of work in the case of classification, including the reference the reviewer provided, which takes into account the probability of label flipping, and which are not applicable to regression. In our case, we try to solve the problem in regression, where a lot less work has been made in the field of learning with noisy labels.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "crmGCKUiKcU", "original": null, "number": 4, "cdate": 1605631943741, "ddate": null, "tcdate": 1605631943741, "tmdate": 1605632043856, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "HSmOH7DumWn", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Response to AnonReviewer4", "comment": "We thank the reviewer for their constructive review.\n\n**Heteroscedastic regression is a classic problem in statistics. And reweighting using the inverse variance is a textbook method. See Chapter 10 of http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf**\n\nWe hope to have answered this concern in the response to all reviewers posted above. We thank the reviewer for the reference, which we have added in the article.\n\n\n**Instead, it assumes the variance is simply given during training. This is not very realistic in real world setting.**\n\nWe also hope to have answered this concern in the response to all reviewers posted above.\n\n\n**The experiments are all synthetic and are not particularly convincing.**\n\nGiven the fact that no regression dataset currently makes the uncertainty available, we were not able to make non-synthetic experiments. However, we do think that our results show convincingly that the method does perform significantly better than L2 and consistently better than a baseline. We are conscious that more detailed experiments, such as on the robustness to errors in the variance estimation, can be made, and we plan to add them to the paper in the following days.\n\n\n**Finally, the paper claims a lot of connection with privileged information (LUPI). But I found it hard to consider this variance a similar concept as privileged information, which is realistic and interesting.**\n\nOn further review based on this comment, we agree that the concepts of LUPI and variance heteroscedastic regressions are different, although interesting parallels can be made at the problem definition and objective levels. We have removed the direct references to LUPI both in the title and in several places in the text, and confined the comparison to section 2.2. We thank the reviewer for underlining that the connection claim was too strong.\n\n\n**To apply the method to a deep learning setting, some interesting problem can be how to estimate the variance with deep network in a reliable way (this was done previously using classic models). However, this paper did not tackle this harder (and more interesting) problem.**\n\nIndeed, the problem of reliably estimating the variance with deep networks is extremely interesting and has seen a lot of recent attention (Kendall & Gal, 2017; Gal & Ghahramani, 2016; Peretroukhin, 2019). The method we propose has a completely different objective however, which is to improve learning when confronted with noisy labels. We believe that the combination of both problems will be beneficial in complex neural architectures where the output of neural networks is a noisy label used for training another network.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "SWDLaeYWkYz", "original": null, "number": 3, "cdate": 1605631522063, "ddate": null, "tcdate": 1605631522063, "tmdate": 1605631522063, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment", "content": {"title": "Response to all reviewers", "comment": "We thank all the reviewers for their very valuable feedback. It is precious in the process of improving this article as well as the research project it stems from.\n\nAll the reviewers were concerned with the novelty of the method. Indeed, we had presented our algorithm through an Fisher information perspective, while the reviewers rightly pointed out that our method has a lot in common with the classic inverse-variance strategies for linear heteroscedastic regression, which achieves maximum likelihood estimation of the model parameters when the noise is Gaussian. We updated the article accordingly, replacing the paragraph about Fisher information by one on linear heteroscedastic regression and citing the references presented by the reviewers, in section 2.3.\nThere, we also underlined the aspects of this work which are novel compared to the text-book methods: it is the adaptation of such a strategy for the stochastic gradient descent methods applied to neural networks. Applying inverse-variance reweighting in the loss function directly is prone to problems: (1) when in presence of near-ground truth samples (2) when the learning rate needs to be controlled (3) when pre-processing the data cannot be done such as in continual learning. To the best of our knowledge, this is the first work proposing a solution to such issues, with both the role of epsilon and the batch-based normalization.\n\nAnother common concern is the realism of the assumption of knowing the label variance during training. While it is definitely not an assumption that holds for every dataset, we argue that having labels that are not estimated is, on the contrary, not an assumption that holds for all use cases. From robotics to studies on population to simulation, there are a lot of cases in which labels come with uncertainty, and for which this uncertainty is quantified. The question we address in this paper is: when such information is available, how can we use it in an optimal way? While this is not common in current datasets for regression, we hope that, if new methods such as the one we propose prove that such information is actually valuable, more datasets will take the extra step of including it. To answer these concerns, we have thus strengthened part 2.1 with more cases and the example of a dataset already including a confidence score.\n\nEach reviewer had particular questions and comments that we answered individually. Overall, we made several changes in the paper, which can be found in blue in the new version.\n\nPlease note that, for a better statistical significance of our results, we have repeated the experiments and now plot the average over 10 runs instead of 3. The overall results have not changed.\n\nWe are also planning to release additional experimental results in the following days. Based on the remarks from two reviewers, we will study the robustness of our method to noise in the variance estimation, as well as the impact of smaller batch sizes. \n\nWe would appreciate it if the reviewers can confirm that their concerns have been addressed and, if so, reconsider their assessment. Once again, we thank them for their precious time and comments."}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "SRzz6RtOdKR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2598/Authors|ICLR.cc/2021/Conference/Paper2598/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846503, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Comment"}}}, {"id": "A4bZxRsMaEP", "original": null, "number": 1, "cdate": 1603726644811, "ddate": null, "tcdate": 1603726644811, "tmdate": 1605024173169, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review", "content": {"title": "Very well written paper, but I didn't find the contribution strong enough", "review": "##########################################################################\n\nPaper Summary:\nThis work targets regression tasks with noisy labels, and proposes to incorporate knowledge about the variance of the gaussian noise corrupting the observed labels to weight the loss function, at training time. The proposed method is evaluated in a series of experiments involving deep networks trained according to the weighted loss function, and compared to a baseline method that omits training samples that have a label noise variance larger than a threshold.\nResults indicate the proposed method is more robust to noisy labels when compared to alternatives that do not exploit the information on the noise affecting labels.\n\n##########################################################################\n\nReasons for score:\u00a0\nOn the one hand, the paper is extremely well written and somehow pedagogic, in that it provides compelling motivations for considering heteroscedasticity, and its possible sources, and general, intuitive descriptions of the proposed method before specialising them to the instance they evaluate. On the other hand, I think the prose lacks sufficient technical depth, on the model they use, its relation to \u201ctext book\u201d material on heteroscedasticity, e.g. for Maximum Likelihood Estimation (MLE), and on the properties of the proposed method. The experimental evaluation, while representing a reasonable starting point, is not sufficient to fully understand the behaviour and the properties of the proposed method.\nFor these reasons, I think this work cannot be accepted as is.\n\n##########################################################################\n\nPositive points:\u00a0\n\n1) The editorial quality of this paper is high, and the overall motivations given to support the problem statement are compelling and well discussed. This also relates to the fundamental assumption underlying this work: access to privileged information, taking the form of knowledge of the stochastic noise variance affecting observed labels, at training time.\n\n2) The proposed method appears to be well positioned w.r.t. the recent literature on statistical modelling with noisy labels, especially concerning neural network based methods. It is unfortunate though that the literature scan doesn\u2019t cover well-known approaches to tackle heteroscedastic noise in simple linear models, or in general MLE frameworks, which may be considered text-book material.\n\n3) The experimental evaluation considers two regression tasks on their respective UCI/Bike sharing, and UTK Face datasets, considering several variants of noise generation processes, affecting labels in different and sufficiently realistic manner.\n\n\u00a0\n##########################################################################\n\nNegative points:\n1) My main concern is the \u201cthin\u201d contribution of this paper. The technical details of the proposed method are not sufficiently developed. Drawing inspiration from Fisher information calls for an appropriate discussion on the likelihood model, its noise model, to begin with. Then, I think the relation of the proposed idea to simple linear models, for which heteroscedastic regression has been studied in great detail (e.g. [1], for a general reference), and for MLE (e.g., [2]), would become more clear and would give the opportunity for the authors to develop what are the merits of their proposed method. For example, the weighted least square method is very similar to what is proposed in this paper. \n[1] Econometric analysis, Greene, William H, 2003, Pearson Education India\n[2] Maximum Likelihood Estimators with Heteroscedastic Errors, G. R. Fisher, Review of the International Statistical Institute\nVol. 25,  1957\nSee also \u201cPattern Recognition and Machine Learning\u201d, Bishop, 2006, (chapter 5 and 6)\n\n2) The experimental evaluation is not sufficient to appreciate the virtues of the proposed method. For several noise distributions (including the additional ones considered in the supplement), the proposed method BIV does not seem to behave much better than the proposed baseline, that uses a simple threshold. Additionally, the figures are  cropped and do not allow to get a sense of what happens for all competing methods (Fig1 and Fig2). In Fig3, the figures report test loss and as there seems to be overfitting kicking in.\nAlso, it is mentioned the baseline method requires to set a cutoff parameter, but the proposed method also depends on a hyper parameter to optimise (done in the appendix). As a consequence, it is difficult to appreciate the main advantage of BIV w.r.t. the baseline.\nFinally, in Fig.3, there are clear signs of overfitting: why did the authors suggest (end of Sec.3) that their work does not require regularisation?\n\n\n#########################################################################\n\nMain criticism:\nI think, overall, the main criticism I have for this work is that the contribution is not sufficient. The main idea proposed in the paper fits sec 4.2, and it is based on well known results from text books. In eq.(5), the summation term is MLE with heteroscedasticity. The loss is scaled by a coefficient that collects statistics on the sample batch: if this batch is very small, or its elements not sufficiently diverse, I am afraid it could have a negative impact on the optimisation process (this is why, in the experiments, the authors chose a batch size of 256).\nOne possible way to overcome this criticism is to clarify the likelihood model, and compare the proposed method to existing approaches to address heteroscedastic Gaussian noise.\nA possible advice would be to reduce (or move to the appendix) the discursive parts on heteroscedasticity, and the general formulations (e.g., sec. 2.2, sec. 4.1), and gain more space to explain how BIV is different from what is known.\n\nAdditional comments:\nA note on experiments using the UTKFace dataset. In this case, the MLP used with 4 layers may be a bit \u201ctoo simple\u201d, in light of the high test loss on GT labels. Did you try with convolutional architectures, even simple ones?\nJust to clarify, the test loss reported in the figures, as a function of training steps: what is the *test* batch size? Same as training batch size? The test loss is computer according to \\sum_{k \\in \\text{test batch}} \\mathcal{L}(f(\\mathbf{x}_k, \\theta), \\tilde{y}_k) right?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092742, "tmdate": 1606915771251, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2598/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review"}}}, {"id": "hBcSXDthu8R", "original": null, "number": 2, "cdate": 1603791791098, "ddate": null, "tcdate": 1603791791098, "tmdate": 1605024173105, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review", "content": {"title": "This paper proposes a reweighed loss function for robust regression model training against label noise. The weight value of each training instance is determined by prior knowledge about the noise generation process. Results confirm empirically the merit of the algorithmic design", "review": "In this paper, a reweighting technique is proposed to suppress the impact of heteroscedastic label noise in regression model training. The objective function of the regression model training process is composed of a weighted combination of instance-wise training loss. The instance-wise weight is determined by the estimated noise variance based on prior information of the label generation process. The weighting formulation is inspired by the best possible estimator of noisy measurements reaching the Cramer-Rao bound. \n\nThe paper is clearly written. It explains well the problem definition and the methodological formulation. However, we think the innovation in this work is limited. The downside of this paper is as follows: \n1. It is a strong and usually impractical assumption to know a priori knowledge of label noise in the regression model training process. Especially, in the proposed method, the estimate of the noise variance needs to be accurate enough, so as to help suppress the noise impact accordingly. It is better to incorporate jointly the learning of noise distribution and the regression/classification \nmodel, so as to optimize the tolerance against the data-dependent noise. \n2. It only considers the noisy learning process for regression. However, in classification scenarios, noise (with respect to labels) is usually presented in the form of label flipping. The proposed reweighing technique is not directly applicable in that case. Please refer to the following work for further reading: \nLearning with Noisy Labels, Nagarajan Natarajan, Inderjit S. Dhillon, Pradeep Ravikumar, and Ambuj Tewari, NIPS 2013. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092742, "tmdate": 1606915771251, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2598/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review"}}}, {"id": "HSmOH7DumWn", "original": null, "number": 3, "cdate": 1604012588192, "ddate": null, "tcdate": 1604012588192, "tmdate": 1605024173040, "tddate": null, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "invitation": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review", "content": {"title": "Important References are Missing; Novelty is Unclear.", "review": "The paper propose to address the heteroscedastic regression problem using deep neural networks. It assumes the variance of heteroscedastic noise is known as privileged information and suggests to reweight the samples by their noise variance in the loss.\n\nThe major issue to me is the lack of novelty. Heteroscedastic regression is a classic problem in statistics. And reweighting using the inverse variance is a textbook method. See Chapter 10 of \n\nhttp://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf\n\nThis paper failed to cite any relevant reference and clarify the novelty.\n\nTo apply the method to a deep learning setting, some interesting problem can be how to estimate the variance with deep network in a reliable way (this was done previously using classic models). However, this paper did not tackle this harder (and more interesting) problem. Instead, it assume the variance is simply given during training. This is not very realistic in real world setting. The experiments are all synthetic and are not particularly convincing. \n\nFinally, the paper claims a lot of connection with privileged information (LUPI). But I found it hard to consider this variance a similar concept as privileged information, which is realistic and interesting.\n\n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2598/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2598/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "authorids": ["~Vincent_Mai1", "~Waleed_Khamies1", "~Liam_Paull1"], "authors": ["Vincent Mai", "Waleed Khamies", "Liam Paull"], "keywords": ["Regression", "Noisy labels", "Supervised Learning", "Uncertainty", "Variance", "Heteroscedastic", "Privileged Information"], "abstract": "In model learning, when the training dataset on which the parameters are optimized and the testing dataset on which the model is evaluated are not sampled from identical distributions, we say that the datasets are misaligned. It is well-known that this misalignment can negatively impact model performance. A common source of misalignment is that the inputs are sampled from different distributions. Another source for this misalignment is that the label generating process used to create the training dataset is imperfect. In this work, we consider this setting and additionally assume that the label generating process is able to provide us with a quantity for the role of each label in the misalignment between the datasets, which we consider to be privileged information. Specifically, we consider the task of regression with labels corrupted by heteroscedastic noise and we assume that we have access to an estimate of the variance over each sample. We propose a general approach to include this privileged information in the loss function together with dataset statistics inferred from the mini-batch to mitigate the impact of the dataset misalignment. Subsequently, we propose a specific algorithm for the heteroscedastic regression case, called Batch Inverse-Variance weighting, which adapts inverse-variance weighting for linear regression to the case of neural network function approximation.  We demonstrate that this approach achieves a significant improvement in network training performances compared to baselines when confronted with high, input-independent noise.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "mai|batch_inversevariance_weighting_deep_heteroscedastic_regression", "one-sentence_summary": "A method to reduce the effect of heteroscedastic noisy labels in regression by weighting them based on their variance and the variance of the other samples in the minibatch.", "supplementary_material": "/attachment/c7d40a0e934d1a8b715f5bc21c37f10bfdc91189.zip", "pdf": "/pdf/3b8feb4acb73a876bf25c4c28aea3d5d339d376d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=YWSmhmSmXc", "_bibtex": "@misc{\nmai2021batch,\ntitle={Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression},\nauthor={Vincent Mai and Waleed Khamies and Liam Paull},\nyear={2021},\nurl={https://openreview.net/forum?id=SRzz6RtOdKR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SRzz6RtOdKR", "replyto": "SRzz6RtOdKR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2598/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092742, "tmdate": 1606915771251, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2598/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2598/-/Official_Review"}}}], "count": 13}