{"notes": [{"id": "BJeWOi09FQ", "original": "B1ezOXF9KX", "number": 328, "cdate": 1538087784928, "ddate": null, "tcdate": 1538087784928, "tmdate": 1545355395952, "tddate": null, "forum": "BJeWOi09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["cosmin.bercea@fau.de", "olivier.pauly@gmail.com", "andreas.maier@fau.de", "florin.ghesu@siemens-healthineers.com"], "authors": ["Cosmin I. Bercea", "Olivier Pauly", "Andreas K. Maier", "Florin C. Ghesu"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "bercea|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@misc{\nbercea2019shamann,\ntitle={{SHAMANN}: Shared Memory Augmented Neural Networks},\nauthor={Cosmin I. Bercea and Olivier Pauly and Andreas K. Maier and Florin C. Ghesu},\nyear={2019},\nurl={https://openreview.net/forum?id=BJeWOi09FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJltM8Ogg4", "original": null, "number": 1, "cdate": 1544746512969, "ddate": null, "tcdate": 1544746512969, "tmdate": 1545354515686, "tddate": null, "forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper328/Meta_Review", "content": {"metareview": "The paper addresses the problem semantic segmentation using a sequential patch-based model. I agree with the reviewers that the contributions of the paper are not enough for a machine learning venue: (1) there has been prior work on using sequence models for segmentation and (2) the complexity of the proposed approach is not fully justified. The authors did not submit a rebuttal. I encourage the authors to take the feedback into account and improve the paper.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "The paper can be improved"}, "signatures": ["ICLR.cc/2019/Conference/Paper328/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper328/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["cosmin.bercea@fau.de", "olivier.pauly@gmail.com", "andreas.maier@fau.de", "florin.ghesu@siemens-healthineers.com"], "authors": ["Cosmin I. Bercea", "Olivier Pauly", "Andreas K. Maier", "Florin C. Ghesu"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "bercea|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@misc{\nbercea2019shamann,\ntitle={{SHAMANN}: Shared Memory Augmented Neural Networks},\nauthor={Cosmin I. Bercea and Olivier Pauly and Andreas K. Maier and Florin C. Ghesu},\nyear={2019},\nurl={https://openreview.net/forum?id=BJeWOi09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper328/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353254036, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper328/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper328/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper328/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353254036}}}, {"id": "H1xV5LqjhX", "original": null, "number": 3, "cdate": 1541281420331, "ddate": null, "tcdate": 1541281420331, "tmdate": 1541534089361, "tddate": null, "forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "content": {"title": "lack of contributions and limited comparisons", "review": "The authors applied the external memory module proposed by Graves et al. (2016) to the image segmentation task. SHAMANN is an extension to allow memory sharing between directions. \n\nAuthors claimed that one of the contributions is a reformulation of the semantic segmentation problem as a sequence learning task.\nThere are many previous works done in this direction,\n- \"Multi-Dimensional Recurrent Neural Networks\", 2007\n- \"Scene Labeling with LSTM Recurrent Neural Networks\", 2015\n- \"ReSeg: A Recurrent Neural Network-Based Model for Semantic Segmentation\", 2016\n- \"Robust, Simple Page Segmentation Using Hybrid Convolutional MDLSTM Networks\", 2017 \nand many more.\nAuthors should compare with those LSTM-based image segmentation approaches as well.\n\nTheir second contribution is a network with a shared external memory module between directions. However, the experiments are not enough to show the benefits of it. See the details below.\n\nHandling long-range dependencies:\n- In Section 3.3.2, authors mentioned that \"One limitation of Bi-LSTM is that the number of network parameters grows proportionally to the memorization capacity, making it unsuitable for sequences with long-range dependencies.\". \nHowever, the experiments are not with long range sequences: 169 sequence length for X-ray dataset and 49 length for MNIST. A classic LSTM (not bi-directional) is known to handle up to 200 timesteps. Some comparison/analysis of handling long-range dependencies of Bi-LSTM, Bi-MANN, and SHAMANN are needed (ideally on high-resolution real images).\n\nDataset:\n-  Authors compared 3 models only on MNIST. The structure on MNIST is simple, and the resolution of images is small to show the benefit of using (shared) external memory module instead of individual memory cells. It is not surprising that the reported performance difference is small. Authors could have reported such a comparison on X-ray dataset too but they did not. I would recommend authors pick another high-resolution real-image dataset and compare the performance of these 3 models.  \n\nAdditional comparisons:\n- Various patch size\n- Longer sequence length\n- Especially a trade-off between the patch size and the sequence length on the high resolution images (larger patch size with a shorter sequence length or shorter patch size with a longer sequence length)\n\n- A comparison of Bi-LSTM with sharing weights will also be a good baseline. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper328/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["cosmin.bercea@fau.de", "olivier.pauly@gmail.com", "andreas.maier@fau.de", "florin.ghesu@siemens-healthineers.com"], "authors": ["Cosmin I. Bercea", "Olivier Pauly", "Andreas K. Maier", "Florin C. Ghesu"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "bercea|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@misc{\nbercea2019shamann,\ntitle={{SHAMANN}: Shared Memory Augmented Neural Networks},\nauthor={Cosmin I. Bercea and Olivier Pauly and Andreas K. Maier and Florin C. Ghesu},\nyear={2019},\nurl={https://openreview.net/forum?id=BJeWOi09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "cdate": 1542234486320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper328/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335699704, "tmdate": 1552335699704, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper328/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkgPhuM5h7", "original": null, "number": 2, "cdate": 1541183663447, "ddate": null, "tcdate": 1541183663447, "tmdate": 1541534089154, "tddate": null, "forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "content": {"title": "paper seems well written and novel.", "review": "The authors present a model for semantic segmentation. The proposed method casts the full image segmentation as a sequence of local segmentation predictions. The image is split in multiple patches and processed sequentially in some order. A shared memory allows the local patch predictions to propagate information to improve other patch predictions which is necessary for resolving ambiguities.  They show a set of results on an XRay segmentation dataset with a reasonable ablation and baseline study. As well as a somewhat unclear result on image completion. The paper is well written, mostly clear and novel to the best of my knowledge.\n\npros:\n- semantic segmentation is clearly very important problem with many applications\n- the method seems clean and promising\ncons:\n- the segmentation community is much more familiar with MS-COCO and VOC. I think results on those datasets will make the paper much more impactful and clear any doubts about the method.\n- it is not clear what processing order the patches are processed in. Does that matter ? This should be clearer in the paper.\n- there is a brief mention of multiple actors but it seems to me its just one Bi-MANN actor is that true ? \n- sec. 4.2 is very surprising to me. From what is written I understand that an MNIST classifier is trained on the original MNIST dataset and that it still works to 56% on the test set with the bottom blanked out. Is that correct ? What architecture is this ? Also I find it very surprising that you can recover accuracy to 96% without seeing the trained classifier at all. Anything that can help me understand how that is possible would be appreciated. Are you aware of anyone else matching these results in the literature ?", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper328/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["cosmin.bercea@fau.de", "olivier.pauly@gmail.com", "andreas.maier@fau.de", "florin.ghesu@siemens-healthineers.com"], "authors": ["Cosmin I. Bercea", "Olivier Pauly", "Andreas K. Maier", "Florin C. Ghesu"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "bercea|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@misc{\nbercea2019shamann,\ntitle={{SHAMANN}: Shared Memory Augmented Neural Networks},\nauthor={Cosmin I. Bercea and Olivier Pauly and Andreas K. Maier and Florin C. Ghesu},\nyear={2019},\nurl={https://openreview.net/forum?id=BJeWOi09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "cdate": 1542234486320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper328/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335699704, "tmdate": 1552335699704, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper328/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1xooNlq3m", "original": null, "number": 1, "cdate": 1541174434943, "ddate": null, "tcdate": 1541174434943, "tmdate": 1541534088946, "tddate": null, "forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "content": {"title": "Interesting, but complex method for semantic segmentation. Unfortunately without convincing experimental results yet.", "review": "Summary:\nThe paper proposes a system of semantic segmentation based on sequential processing of the image in a patch-wise manner with multiple \"actors\", sharing a common external memory. This approach stands in contrast to the more usual approach of single-shot prediction for the whole image, where encoder-decoder architectures or dilated convolutions are used to capture the global context. The authors then discuss three-variants of this method, out of which two use external memory (Bi-MANN, SHAMANN), and one uses memory shared between actors (SHAMANN). Results are presented on segmentation of lung X-ray data and on MNIST digit completion.\n\nComments:\nThe paper is easy to read. The authors cite the relevant literature on the baseline semantic segmentation methods, as well as neural networks with external memories. However, similar patch-wise and sequential methods have been presented in the literature (e.g. https://arxiv.org/abs/1506.07452), including ones with external storage (e.g. https://www.nature.com/articles/s41592-018-0049-4), but these are not discussed as prior work.\n\nOverall, the proposed approach is interesting, but significantly more complex than both the baselines and prior work. As is, the experimental results are not compelling enough to justify this (lack of clear quantitative improvement over state of the art). My recommendation would be to conduct additional experiments on semantic segmentation benchmark datasets. The proposed method seems promising for volumetric data as the authors note, but this also needs to be demonstrated experimentally.\n\nSome more specific & technical questions follow:\n- In Table 1, how is the confidence interval for the Dice score computed?\n- Have any experiments been done with more than 2 actors?\n- How exactly is the patch sequence formed, i.e. what is the spatial order of the patches? How much to the results depend on this order, if at all?\n- In the discussion on page 6, it seems to be implied that the reduced parameter count should allow more efficient application to volumetric data. This is a bit surprising, since with modern networks it is usually the input size that is limiting, not the number of network parameters.\n- Have experiments with Bi-MANN and Bi-LSTM been done on the X-ray segmentation data? How do the results compare to SHAMANN?\n- How does the inference and training time compare to the baseline methods?", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper328/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SHAMANN: Shared Memory Augmented Neural Networks", "abstract": "Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on chest X-Ray images, as well as on two synthetic tasks based on the MNIST dataset. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size compared to reference methods. In addition, we reduce the number of failure cases by at least half.", "keywords": ["memory networks", "deep learning", "medical image segmentation"], "authorids": ["cosmin.bercea@fau.de", "olivier.pauly@gmail.com", "andreas.maier@fau.de", "florin.ghesu@siemens-healthineers.com"], "authors": ["Cosmin I. Bercea", "Olivier Pauly", "Andreas K. Maier", "Florin C. Ghesu"], "TL;DR": "Multiple virtual actors cooperating through shared memory solve medical image segmentation.", "pdf": "/pdf/45eafa16ba64ffffd3a5f0aa884a777fb69fcde6.pdf", "paperhash": "bercea|shamann_shared_memory_augmented_neural_networks", "_bibtex": "@misc{\nbercea2019shamann,\ntitle={{SHAMANN}: Shared Memory Augmented Neural Networks},\nauthor={Cosmin I. Bercea and Olivier Pauly and Andreas K. Maier and Florin C. Ghesu},\nyear={2019},\nurl={https://openreview.net/forum?id=BJeWOi09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper328/Official_Review", "cdate": 1542234486320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJeWOi09FQ", "replyto": "BJeWOi09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper328/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335699704, "tmdate": 1552335699704, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper328/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}