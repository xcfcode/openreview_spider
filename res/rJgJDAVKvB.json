{"notes": [{"id": "rJgJDAVKvB", "original": "ryllkrvuDr", "number": 1161, "cdate": 1569439319448, "ddate": null, "tcdate": 1569439319448, "tmdate": 1583912045823, "tddate": null, "forum": "rJgJDAVKvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "aqGf8e_0ax", "original": null, "number": 1, "cdate": 1576798716115, "ddate": null, "tcdate": 1576798716115, "tmdate": 1576800920399, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "All reviewers unanimously accept the paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795711145, "tmdate": 1576800260286, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Decision"}}}, {"id": "SkewetU15S", "original": null, "number": 2, "cdate": 1571936495115, "ddate": null, "tcdate": 1571936495115, "tmdate": 1574361661275, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "Summary:\n\nMotion-planning in high dimensional spaces is challenging due to the curse of dimensionality. Sampling-based motion planners like PRM, PRM*, RRT, RRT*, BIT* etc have been the go-to solution family. But often these algorithms solve every planning problem tabula rasa. This work combines learning with sampling-based planning such that the parent-sampling and expansion steps instead of being done by common heuristics are learnt in an online manner. Also the resulting exploration-exploitation problem is naturally dealt via using a UCB-style contextual bandit algorithm. Since the number of parents are always varying the common trick of 'describe the action choices with respect to the environment' is adopted so that varying number of actions (states to be sampled from) can be naturally incorporated. \n\nThe other significant aspect of this paper is that there is a self-improving component (Algorithm 3) where a dataset is built up every time step, of environments where either an expansion with RRT or the learnt expansion policy is attempted with the policy being invoked more as time goes on and it trains more. If the process succeeds in finding a path to the goal then this example is added to a dataset and the dataset used to update the policy and associated value function to guide it towards the feasible paths found in the tree. \n\nComments:\n\n\n- Algorithm 3: \"Reconstruct optimal path\". These paths are not really optimal for the problem. They are optimal in the tree T that is built so far for example U. But for the problem they are feasible and if RRT* were to be run asymptotically then perhaps near-optimal. The accompanying text should be updated accordingly so that there isn't confusion.\n\n- Here is my main concern with Algorithm 3: For equation 6  where the policy and value functions are updated, the policy is inevitably going to suffer from covariate shift. This is because the algorithm is essentially doing behavior cloning (BC) with respect to the feasible paths found on the planning examples. Since we are inherently in a sequential setting (non-iid) where the states visited by the policy are a direct result of its own decisions the error bound will be quadratic in the horizon (path-length) for equation 6. This phenomenon has been well-understood in imitation learning literature and algorithms like DAgger, AggreVate or online versions like AggreVateD, LOLS already address these problems in a principled manner. Equation 6 should ideally be replaced with an inner DAgger/AggreVateD like loop (with an RRT* dynamic oracle) for stable learning of policy and value function. I am happy to be convinced that covariate shift and resulting quadratic mistake-bound problems are not present here.\n\n- Application of imitation learning to both self-improvement style path planning and leveraging experience in planning has been done before: See \"Learning to Search via Retrospective Imitation\nJialin Song, Ravi Lanka, Albert Zhao, Aadyot Bhatnagar, Yisong Yue, Masahiro Ono, 2018\" (this is unpublished it seems so it is unfair of me to mention this perhaps but I wanted to give an example of how to use dynamic oracles for stable imitation in planning.) and \"Data-driven Planning via Imitation Learning\nSanjiban Choudhury, Mohak Bhardwaj, Sankalp Arora, Ashish Kapoor\u2020, Gireeja Ranade, Sebastian Scherer and Debadeepta Dey\", IJRR 2018. At least the last paper should be cited and discussed in related work.\n\n- Also would be curious how the authors would situate methods which are non-learning based but leverage experience in planning (example E-Graphs: Bootstrapping Planning with Experience Graphs, Phillips et al, RSS 2012) via graphs discovered in other problems directly. Perhaps a discussion in related work is warranted?\n\nUpdate: After rebuttal updating to Accept.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633571963, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Reviewers"], "noninvitees": [], "tcdate": 1570237741454, "tmdate": 1575633571978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review"}}}, {"id": "ByxknBAjoB", "original": null, "number": 2, "cdate": 1573803430822, "ddate": null, "tcdate": 1573803430822, "tmdate": 1573842449046, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "Bkey_3u7qS", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thanks for your support and inspiring comments. We reply to the raised questions below:\n\n1. Neural induced prior in \"no-free lunch theorem\".\n\nWe are not seeking the omniscient planner dominating any other alternatives, which is impossible based on the no-free lunch theorems for optimization. Our underlying assumption, as discussed in Section 2, is that the learned planner will do better, in terms of collision check and quality, for planning problems from certain task distribution. \n\nAs an example, for the distribution that only generates planning problems in which $\\mathcal{S}_{goal}$ always lies in the 1 step right of $s_{init}$ in the mazes without any obstacles, the trivial planner that only produces 1 step right action will be the optimal planner. Although the learned planner pays for the degraded performances on this set of trivial problems, it will take the advantages in the neural network encoded repeated patterns in the practical tasks, which we are indeed interested in. \n\n\n2. Computing wall-clock comparison.\n\nWe used the number of collision checks and the number of samples as a surrogate for time because collision check for each sample is time-consuming and in many cases it dominates the total planning time. We have shown that asymptotically our method is more efficient than the existing ones. \n\nAs we show in the newly added experiments in Figure 8, to achieve the same success rate, our algorithm implemented in Python only requires 1/50 wall-clock time compared to the highly-optimized OMPL implementation in C of traditional planners such as BIT* and RRT*. The result shows a huge potential to improve the actual planning time in real-world tasks using our algorithm.\n\nIn each iteration, the algorithm calls the network to generate the next sample. We would like to emphasize that there is a computation trick to save the major compute time. As we discussed in the main text, the latent representation of the value/policy function $\\nu^{*(T)}$ defined before equation (5) is independent of the current state $s$. Therefore we can precompute $\\nu^{*(T)}$ and reuse that in each iteration, which avoids duplicating the efforts doing the neuralized value iteration. Using this trick the algorithm runs 10x - 100x faster than before.\n\n3. Parameter/network component sensitivity. \n\nWe did not find large variations in changing the hyper-parameters and network component:\n    - For neural network weights and biases, we used the default initialization (kaiming_uniform_) for nn layers (Linear/Conv) in Pytorch 1.0. Switching it to kaiming_normal_, xavier_uniform_, or xavier_normal_ does not improve/degrade the result by more than 1%.\n    - For optimization, we used Adam optimizer in Pytorch. We set betas to (0.9, 0.999) but did not tune it. The learning rates <= 1e-3 works fine.\n    - For latent dimensions in our neural network, if we vary each hyperparameter in the range of [0.5*r, 2*r], where r is the recommended value (in Appendix D), the variation is within 5%.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJgJDAVKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1161/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1161/Authors|ICLR.cc/2020/Conference/Paper1161/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160303, "tmdate": 1576860554015, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment"}}}, {"id": "SJgwUURsjr", "original": null, "number": 4, "cdate": 1573803598619, "ddate": null, "tcdate": 1573803598619, "tmdate": 1573803598619, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "Hylq3SQaYr", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thanks for the generally positive and constructive comments. We have refined paper accordingly to make the paper less intensive.\n\nWe address the raised concerns below:\n\n- Experimental environment.\n\nFor planning tasks, we did a thorough search and could not find one benchmark which (1) is used by many existing works, (2) is publicly available, and (3) has Python interface. \n\nWe are aware of the importance of making fair comparisons with existing methods. Therefore we created one benchmark, based on existing papers [Tamar et al. 2016, Lee et al. 2018, Ichter et al. 2018], without any inductive bias towards the proposed planner. Moreover, we carefully tuned the hyperparameters for all baselines. We would be grateful if you could point us to some benchmarks that meet the criteria.\n\nIn the updated version we include a new set of comparisons on a new environment, in which we show our algorithm also performs well when controlling a 7-DOF robot arm to fetch objects from a shelf. Similar (and much easier) experiments are done in BIT* [Gammell et al. 2015]. We show that our algorithm only requires 1/50 wall-clock time compared with the well-tuned BIT* and RRT*.\n\nWe will release the code and the environment platform to prosper future research in this direction. \n\n- Notation and terminology clarification.\n\n$\\mathtt{map}$ and $\\mathcal{S}_{free}$: The $\\mathtt{map}$ and $\\mathcal{S}_{free}$ are only redundant in 2D case. For a high-dimensional planning problem, the map only captures the workspace information, while the $S_{free}$ will contain the feasible configurations of the robot, e.g., the states of each joint and arm of the robot. While it is easy to operate on $\\mathtt{map}$, it would be difficult to work with $\\mathcal{S}_{free}$ directly.  In general, for sampling-based path planners, the only way to access $\\mathcal{S}_{free}$ is through calling the collision detection oracle.\n\n$s_0$ and $s_{init}$: They are different. The $s_{init}$ stands for the required starting point in the planning task, while $s_0$ stands for the starting point of one path. The planning algorithm is looking for a feasible path whose $s_0 = s_{init}$ and $s_T \\in \\mathcal{S}_{goal}$.\n\nMeta self-improving learning: As we discussed, each individual planning problem itself is an optimization problem (i.e., to minimize the path cost). We are learning an algorithmic planning solver, which can be generalized for solving other unseen planning problems in the same task distributions.  Therefore the process can be viewed as a meta-learning procedure. \n\n\n- Regarding the 'high-dimensional' planning tasks. \n\nThanks for the suggestion. It should be emphasized that the dimension in planning tasks usually refers to the controllable variables in configuration space. This is different from the problems with perceptual inputs, where the dimension refers to the observation. Actually, the research on perceptual inputs is a separate topic that is orthogonal to the problem the proposed NEXT targeting, and can be incorporated with NEXT to handle complicated agent planning with observed perceptual contexts.\n\nWith the clarification of the 'high-dimension', compared with the current learning to plan algorithms, e.g., VIN and GPPN which are restricted to handle a particle in 2D discrete domains, the proposed NEXT is naturally suitable for complicated agents with more controllable variables. \n\nThe proposed NEXT is compatible with arbitrary contexture bandit algorithms. We can definitely incorporate with learned neural networks as features to conduct the UCB estimation, which itself is of independent interest. In our paper, we exploited and tested the major dominated contexture UCB algorithms based on kernels, i.e., GP-UCB and KS-UCB. In practice, the kernel method performs comparably with neural networks when the number of dimensions is hundreds, as shown in [Dai et al. 2014], which is already considered high-dimensional planning tasks.\n\n[Tamar et al. 2016] Tamar, A., Wu, Y., Thomas, G., Levine, S., and Abbeel, P. Value iteration networks. In Advances in Neural Information Processing Systems, pp. 2154\u20132162, 2016.\n[Lee et al. 2018] Lee, L., Parisotto, E., Chaplot, D. S., Xing, E., and Salakhutdinov, R. Gated path planning networks, 2018.\n[Ichter et al. 2018] Ichter, B., Harrison, J., and Pavone, M. Learning sampling distributions for robot motion planning. In 2018 IEEE International Conference on Robotics and Automation (ICRA). 2018.\n[Gammell et al. 2015] Gammell, J. D., Srinivasa, S. S., and Barfoot, T. D. Batch informed trees (bit*): Sampling-based optimal planning via the heuristically guided search of implicit random geometric graphs. In Robotics and Automation (ICRA), 2015 IEEE International Conference on, pp. 3067\u20133074. IEEE, 2015.\n[Dai et al. 2014] Dai, B., Xie, B., He, N., Liang, Y., Raj, A., Balcan, M. F. F., & Song, L. (2014). Scalable kernel methods via doubly stochastic gradients. In Advances in Neural Information Processing Systems (pp. 3041-3049).  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJgJDAVKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1161/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1161/Authors|ICLR.cc/2020/Conference/Paper1161/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160303, "tmdate": 1576860554015, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment"}}}, {"id": "rygR18Roir", "original": null, "number": 3, "cdate": 1573803493935, "ddate": null, "tcdate": 1573803493935, "tmdate": 1573803493935, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "SkewetU15S", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "Thanks for the generally positive comments and constructive suggestions. We address the corresponding concerns below:\n\n1, Covariate shift and quadratic error\n\nThere might be several misunderstandings about our learning setting and the proposed meta self-improving learning (MSIL) algorithm. The major difference between our learning setting and traditional imitation learning, which is used in the existing VIN and GPPN, is that we do not have the optimal expert supervision. Therefore, neither vanilla Behavior Cloning (BC) and the advanced imitation learning algorithms, e.g., DAgger/AggreVateD, can be straightforwardly applied to achieve better performance. \n\nWe inherit the design philosophy in DAgger, i.e., \"correcting the decisions via guidance from the experts upon the trajectories obtained by the mixture of experts and current imitator\", which lead to the MSIL as illustrated in Algorithm 3. In fact, the proposed MSIL can be viewed as a variant of DAgger with the RRT* as the \u2018imperfect\u2019 expert. The data collection is executing a mixture of RRT* and current imitator in line 4 in Algorithm 3, which is different from BC where the samples purely come from the imperfect RRT*. Therefore, the covariate shift and quadratic error should not be presented. \n\n\n2, Related work\nThanks for the pointer to the references. We have added the discussions into the update version.\n\n- Comparison to [Song et al. 2018]\nThe [Song et al., 2018] indeed shares some similarities in the learning part of NEXT, in the sense that both are handling imperfect experts. However, there are significant differences as our major contributions:\n1, The planning tree expansion procedure is different. In [Song et al., 2018], the next search step must be conducted from the current node, while in our NEXT, the search tree expands from an arbitrary node, saving a huge cost for sampling.  \n2, To compensate for the sub-optimality of the current solution, we exploit the UCB algorithm to balance exploration and exploitation. \n3, We propose a novel neural network architecture to embed the planning tasks, on which the learned planner can be generalized for future tasks.\n\nAs shown in our ablation study, all these components are important to achieve the superb performances. \n\n- Comparison to [Choudhury et al., 2018]\nIn the previous version, we already cited and discussed the conference version of this paper [Bhardwaj et al., 2017]. We have changed it to the comprehensive journal version. The paper learns a policy to do search-based planning. However, their method is restricted to planning on graphs.\n\n- Discussion about [Phillips et al., 2012]\nIn NEXT, we are targeting a different problem setting compared with non-learning, memory-based planners such as PRM and E-Graphs. The latter planners are designed for largely fixed obstacles, so that one can leverage the search graphs created in previous planning problems to accelerate planning. Our method instead only assumes the planning problems follow some distribution, so that the learned planner can be generalized to unseen tasks from the same distribution. \n3, Other Questions\n\n- \u201cReconstruct optimal path\u201d in Algorithm 3\nWe have changed it to \u201cnearly-optimal/sub-optimal path\u201d in the updated version.\n\n\n[Bhardwaj et al., 2017] Bhardwaj, Mohak, Sanjiban Choudhury, and Sebastian Scherer. \"Learning heuristic search via imitation.\" arXiv preprint arXiv:1707.03034 (2017).\n[Choudhury et al., 2018] Choudhury, Sanjiban, et al. \"Data-driven planning via imitation learning.\" The International Journal of Robotics Research 37.13-14 (2018): 1632-1672.\n[Phillips et al., 2012] Phillips, Mike, et al. \"E-Graphs: Bootstrapping Planning with Experience Graphs.\" Robotics: Science and Systems. Vol. 5. No. 1. 2012.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJgJDAVKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1161/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1161/Authors|ICLR.cc/2020/Conference/Paper1161/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160303, "tmdate": 1576860554015, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Authors", "ICLR.cc/2020/Conference/Paper1161/Reviewers", "ICLR.cc/2020/Conference/Paper1161/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Comment"}}}, {"id": "Hylq3SQaYr", "original": null, "number": 1, "cdate": 1571792305646, "ddate": null, "tcdate": 1571792305646, "tmdate": 1572972504815, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper proposes an approach to learn how to plan in continuous spaces using neural\nnets to learn a value function and a policy for scoring and sampling next-step candidates\nin a stochastic tree search.  The networks are updated as more planning tasks\nare executed, producing more data for the policy and value function, leading to gradually\nbetter plans compared to a number of baselines on benchmarks introduced by the authors.\n\nThis is a very interesting paper, although I did not always found it easy to read,\nmaybe too densely packed for comfort. My main concerns are clarity of the exposition (especially\nof the neural net architecture (sec 4.2) and that the comparisons are exclusively done\non benchmarks introduced by the authors rather than on benchmarks on which the baseline\nmethods had been previously been optimized, which may introduce a bias in favour of the\nproposed approach.\n\nClarifications\n\nBefore eqn 2, I don't understand why U includes both S_free and map, although the map specifies the free space and thus S_free seems redundant.\n\nIn sec 3 (page 3), the authors introduce a new notation s_init which seems to be the same as s_0 in the previous sections (or is it?).\n\nSection 4.2 was really difficult for me to parse and is too compressed (so is the rest of the paper but this one was worse).\n\nFigures were too small (esp. fig 4 and fig 7) for me to read from the printed paper.\n\nThe term 'meta self-improving learning' seems inappropriate. I did not see  how this was a form of meta-learning. Unless I missed something I suggest to change the terminology.\n\nOther Concerns\n\nI have a concern regarding the way r_t(s) is estimated (page 4) by kernel interpolation of the rewards. I fear that it will not generalize properly when trying to extrapolate, especially in high dimensions (since the claim of the paper is that the proposed algorithms is meant for 'high dimensional' states).\n\nIn addition, the experiments are actually performed in  rather low-dimensional settings (compared to working on problems with perceptual inputs, for example).\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633571963, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Reviewers"], "noninvitees": [], "tcdate": 1570237741454, "tmdate": 1575633571978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review"}}}, {"id": "Bkey_3u7qS", "original": null, "number": 3, "cdate": 1572207719251, "ddate": null, "tcdate": 1572207719251, "tmdate": 1572972504706, "tddate": null, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "invitation": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper introduces a novel  meta path planning algorithm  that utilizes neural network module that improves the data-efficiency for iterated path planning problems.\n\nThe authors address a relevant issue and the experiments make sense given the research question.  I particular like the 3 ablation studies that the authors include, which makes the empirical analysis very thorough.\n\nWriting and Clarity:\nThe introduction is written quite well. Section II&III is written quite technical and dense. This can be very hard to understand for non-experts. However these section are  important to understand the  rest paper. Finally, these two sections should be integrated (preliminaries, quite literally, should be at the beginning). Section 5 \n\n\nAdditional Questions:\n1. Philosophically, how does the self-improvement for iterative planning problems not contradict the no-free lunch theorem? What kind of repeated structure do we assume here (because it seems as in Fig. 1 both the obstacles as well as the goal state change randomly)\n2. As you employ a neural network to do value iteration how does the wall-clock time compare to the baselines?  I do not mean the environment time-ticks (that you checked for using the number of collision checks), but actual compute time. \n3. How sensitive is the proposed solution to parameter initialization?  Did you find much variation in changing hyper-parameters, such as network topology, learning rate et cetera?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1161/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": ["Binghong Chen", "Bo Dai", "Qinjie Lin", "Guo Ye", "Han Liu", "Le Song"], "authorids": ["binghong@gatech.edu", "bodai@google.com", "qinjielin2018@u.northwestern.edu", "guoye2018@u.northwestern.edu", "hanliu@northwestern.edu", "lsong@cc.gatech.edu"], "keywords": ["learning to plan", "representation learning", "learning to design algorithm", "reinforcement learning", "meta learning"], "TL;DR": "We propose a meta path planning algorithm which exploits a novel attention-based neural module that can learn generalizable structures from prior experiences to drastically reduce the sample requirement for solving new path planning problems.", "abstract": "We propose a meta path planning algorithm named \\emph{Neural Exploration-Exploitation Trees~(NEXT)} for learning from prior experience for solving new path planning problems in high dimensional continuous state and action spaces. Compared to more classical sampling-based methods like RRT, our approach achieves much better sample efficiency in  high-dimensions and can benefit from prior experience of planning in similar environments. More specifically, NEXT exploits a novel neural architecture which can learn promising search directions from problem structures. The learned prior is then integrated into a UCB-type algorithm to achieve an online balance between \\emph{exploration} and \\emph{exploitation} when solving a new problem. We conduct thorough experiments to show that NEXT accomplishes new planning problems with more compact search trees and significantly outperforms state-of-the-art methods on several benchmarks.", "pdf": "/pdf/c45825c9605af935d5e51f065e4b4499bf2b5bde.pdf", "code": "https://github.com/NeurEXT/NEXT-learning-to-plan/blob/master/main.ipynb", "paperhash": "chen|learning_to_plan_in_high_dimensions_via_neural_explorationexploitation_trees", "_bibtex": "@inproceedings{\nChen2020Learning,\ntitle={Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees},\nauthor={Binghong Chen and Bo Dai and Qinjie Lin and Guo Ye and Han Liu and Le Song},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJgJDAVKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/aafda053b6b083ae2ec70f394ab308b7a4093ca4.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJgJDAVKvB", "replyto": "rJgJDAVKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1161/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633571963, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1161/Reviewers"], "noninvitees": [], "tcdate": 1570237741454, "tmdate": 1575633571978, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1161/-/Official_Review"}}}], "count": 8}