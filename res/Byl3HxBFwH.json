{"notes": [{"id": "Byl3HxBFwH", "original": "HylalFgYPB", "number": 2300, "cdate": 1569439811951, "ddate": null, "tcdate": 1569439811951, "tmdate": 1577168290032, "tddate": null, "forum": "Byl3HxBFwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "kWmxSk0YTw", "original": null, "number": 1, "cdate": 1576798745626, "ddate": null, "tcdate": 1576798745626, "tmdate": 1576800890506, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Decision", "content": {"decision": "Reject", "comment": "VAE-based sample selection for training NNs.  A well-written experimental paper that is demonstrated through a number of experiments, all of which are minimal and from which generalization is not per se expected.  The absence of an underlying theory, and the absence of rigorous experimentation makes me request to extend either or, better, both.  ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795720037, "tmdate": 1576800270793, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Decision"}}}, {"id": "SJeEOpVOiH", "original": null, "number": 4, "cdate": 1573567851803, "ddate": null, "tcdate": 1573567851803, "tmdate": 1573567851803, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "r1x78YE_or", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment", "content": {"title": "Thanks for the clarification", "comment": "Thanks for the detailed comments. It has resolved my concerns. I think the paper is very interesting and insightful. We should encourage such work that explores how a method works. Although it is not practical for large-scale experiments yet, it may do with some extensions in future work. Therefore, I have raised my rating to \"Accept\" for this paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl3HxBFwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2300/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2300/Authors|ICLR.cc/2020/Conference/Paper2300/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143395, "tmdate": 1576860531262, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment"}}}, {"id": "BygRX1NCtS", "original": null, "number": 2, "cdate": 1571860262370, "ddate": null, "tcdate": 1571860262370, "tmdate": 1573567603821, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This paper proposes a method to efficiently select hard samples during the training of a neural network. This is achieved via a variational auto-encoder (VAE) that encodes the samples into a latent space. The VAE is trained in a preparation stage using the images only and fixed at later stage. During training of a DNN framework, samples are selected in the latent space and then decoded via the Decoder in VAE to generate the input for DNN framework. The advantage of such a framework is that now it is able to calculate the gradient w.r.t. the input samples of DNN. This gradient is used to determine the sampling strategy in the next iteration to select harder samples. Two different sampling methods are explored, including nearest neighbor and interpolation (with annotation tool step). The experiments are conducted on small-scale datasets like MNIST CIFAR-10, and IVUS MSE with satisfactory gain over the baselines. Overall, the paper is very well-written and easy to follow. Although the experiment results are not super exciting mainly because of small-scale datasets and not enough gain in the numbers, some of the analysis in Figure 4 are quite insightful to validate the assumption and motivation of this work. So I propose to accept this work for its novelty. I think this work will benefit future research in this direction. \n\nHowever, I do have some concerns that I wish the authors could clarify if possible. First, the approach is very similar to online hard negative mining (OHNM) that is purely based on the loss to repeatedly select the samples that generate a larger loss. The major difference is that this work can model the sample distribution and thus select samples based on the gradient w.r.t. the samples in the latent space. This is very novel to me. However, I am wondering if the authors could compare with this sample baseline of OHNM. My concern is that the baselines in this work is too simple and it is not surprise that there is advantage over a simple baseline that is trained without any hard sample mining. \n\nSecond, the experiments are all conducted on small-scale and simple datasets like MNIST and CIFAR10. I am concerned how effective this approach could work for large-scale dataset. In the experiment, even for CIFAR10, a vanilla VAE will not work to reconstruct the input. So the authors have used alpha-GAN to help image reconstruction. If that is the case for CIFAR10 with only 10 classes, how could we extend this work to even larger dataset with more complicated background like ImageNet? I would think the preparation step itself is a very challenging task. This is my major concern that will question the effectiveness of the approach in real applications. \n\nThird, a related question to the above one. As the input to the DNN is the reconstructed image from the pre-trained decoder, there will be some information loss during the reconstruction process. This is the major challenge, I think, for large-scale applications. Is that possible to use the original image as the input to DNN while still being able to find hard samples using the latent space and the image space correlation? \n\nFourth, I really like the visualization of Figure 4 that shows the trajectory of the sampling process that follows the boundaries between classes. The authors also mentioned that some trajectories explore towards outside util there is no real samples, which should be avoided. Could the authors comment on how to avoid such cases? In my understand, as the input is randomly sampled at the beginning, it cannot avoid such cases unless some evaluation is done during training to stop the sampling for these trajectories. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575671635530, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Reviewers"], "noninvitees": [], "tcdate": 1570237724799, "tmdate": 1575671635542, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review"}}}, {"id": "r1xpqsNuoS", "original": null, "number": 3, "cdate": 1573567380934, "ddate": null, "tcdate": 1573567380934, "tmdate": 1573567380934, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "rJxqsKr6YH", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment", "content": {"title": "Response to reviewer 1", "comment": "We thank the reviewer for the constructive comments. We address the comments point-by-point below.\n\n1. \u201cWhy was the space chosen to be the VAE latent space? Would it be possible to demonstrate some benefits of doing so, theoretically or empirically?\u201d\n\nThere are several reasons that motivate us to sample in the VAE latent space.\n\nFirstly, the latent space of a VAE model (or a deep generative model) plays a fundamental and important role in the proposed framework with the basic assumption that many high-dimensional data structures (e.g. images or patches) can be represented as a manifold in a low-dimensional space. Deep generative models enable us to identify such a manifold in the format of the latent code. Sampling in this latent space will generate plausible samples that follow the original data distribution. In contrast, sampling in the original data space or intermediate feature space might generate out-of-distribution samples. This is very important if we would like to use the \u2018interpolation\u2019 sampling method as discussed in Section 3.5. \n\nSecondly, the latent space also provides us with better representation and interpretation of data, for example, similar samples tend to be distributed nearby. As a result, the exploration trajectory becomes more explainable and meaningful, as discussed in Figure 4. \n\nLastly, when we synthesize new samples, an interpolated point in the latent space can still produce a plausible training sample, compared to interpolating directly in the original data space. Therefore, when we navigate through the latent space according to the gradient direction, we can synthesize not only difficult but also plausible samples. The hardness information of synthesised training sample may be more accurate than the training sample selected by the nearest neighbours.\n\n2. \u201cThe datasets used are relatively small and in two out of the three datasets, the method does not improve.\u201d\n\nAlthough two of the datasets are relatively small, we still observed improvement according to the reported results (Figure 3 and Table 1). As Reviewer 3 pointed out, \u201cThe experiments are conducted on small-scale datasets like MNIST CIFAR-10, and IVUS MSE with satisfactory gain over the baselines.\u201d More importantly, in this paper, we focus on proposing a novel framework and demonstrating its feasibility. Applying our framework onto large scale datasets will be a meaningful follow-on work for future research. \n\n3. \u201cThe dimension of the latent space is also surprisingly small (2).\u201d\n\nThe latent spaces used for the three experiments (MNIST, CIFAR10, IVUS) have more than 2 dimensions. In the Appendix, the details of generative models and the corresponding latent space are given where you can find the actual numbers of dimensions (3 for all three datasets). We also discuss the choice of dimensions in Section 5.  In the revised version, we clarify the actual dimensions of latent spaces used for our experiments. \n\nIn Figure 4, an example of 2-dimensional latent space was shown mainly for visualisation purposes and for discussing the exploration trajectories.\n\n4. \u201cWhile the main body of the paper describes the method with VAEs, the experiments for the CIFAR10 dataset (where the results were in favour) were done \\alpha-GAN.\u201d\n\nIn this paper, we aim to demonstrate a general framework that adaptively selects more informative (harder) samples from the latent space to improve the training efficiency of a deep learning model. The deep generative model is a component of this framework. In the main body of the paper, we use the VAE as example to demonstrate the idea. But the framework can also use other kinds of generative models such as alpha-GAN etc as a component. We explicitly explained in Sec 4.3 Implementation that for the three tasks, two tasks (MNIST and IVUS) used VAE and other tasks (CIFAR-10) used alpha-GAN due to its better reconstruction performance on this dataset.\n\nMore specifically, for the scenario where a labelling tool is not available, an auto-encoder-like generative model is essential for our framework since we need the correspondence between the latent space and original image space to identify the label of the selected training sample. For the scenario where a labelling tool is available, deep generative models like GAN can be used to generate informative training samples at the interpolated point in the latent space and the generated samples can be annotated subsequently by the labelling tool or human analyst.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl3HxBFwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2300/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2300/Authors|ICLR.cc/2020/Conference/Paper2300/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143395, "tmdate": 1576860531262, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment"}}}, {"id": "r1x78YE_or", "original": null, "number": 2, "cdate": 1573566794891, "ddate": null, "tcdate": 1573566794891, "tmdate": 1573566794891, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "BygRX1NCtS", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank Reviewer 3 for appreciating the novelty of our work and the benefits for future research along the direction of data efficient learning. We address the comments point-by-point below.\n\n1.Clarification of the difference from online hard negative mining (OHNM).\n\nIn the field of hardness-aware learning, online hard negative mining (OHNM) or hard negative mining (HNM) selects the informative samples mainly by utilising the rank ordered by the training sample loss. This requires the whole dataset to be annotated before training. On the contrary, our framework is heuristic where the new informative training samples are identified within the neighbourhood of existing ones along the gradients derived from the loss function. We do not need to annotate the whole dataset and it is possible to perform human-in-the-loop learning. I.e., find the informative sample for annotation. This could dramatically benefit the tasks that have high cost on labelling each sample. We added this discussion to the Related Work Section.\n\n2. The effectiveness of the method on large-scale and challenging datasets as the current work use 3 relatively small datasets.\n\nWe agree with the reviewer that training a deep generative model for large-scale datasets and even \u201cthe preparation step itself is a very challenging task\u201d. As the aim of this paper is to demonstrate the basic idea of the proposed training framework, we use the most popular datasets (MNIST and CIFAR10) in machine learning community as examples and an additional datasets (IVUS) to demonstrate the case when an online labelling tool is available. We also demonstrate that the proposed framework is flexible by using either VAE (for MNIST and CIFAR10) or alpha-GAN (for IVUS) as the generative model. For the large-scale cases where high-fidelity reconstruction is required, many recent SOTA works are based on either VAE or GAN [1-3]. We believe that the proposed framework is flexible to allow more advanced deep generative model to be integrated in future research.\n\n[1] Razavi, Ali, Aaron van den Oord, and Oriol Vinyals. \"Generating Diverse High-Fidelity Images with VQ-VAE-2.\" arXiv preprint arXiv:1906.00446 (2019).\n[2] Gulrajani, Ishaan, et al. \"Pixelvae: A latent variable model for natural images.\" arXiv preprint arXiv:1611.05013 (2016). (Results reported on ImageNet) [UPDATE: ICLR 2017]\n[3] Brock, Andrew, Jeff Donahue, and Karen Simonyan. \"Large scale gan training for high fidelity natural image synthesis.\" arXiv preprint arXiv:1809.11096 (2018). [UPDATE: ICLR 2019]\n\nIn addition, for cases where there is an available labelling tool, a GAN-based decoder is also acceptable to the framework, where harder samples can be synthesised to be annotated by the labelling tool in an online manner.\n\n3. \u201cAs the input to the DNN is the reconstructed image from the pre-trained decoder, there will be some information loss during the reconstruction process. This is the major challenge, I think, for large-scale applications. Is that possible to use the original image as the input to DNN while still being able to find hard samples using the latent space and the image space correlation?\"\n\nWe understand your concern about the information loss during reconstruction. It is possible to replace the synthesised training samples with their corresponding original input. In fact, we noticed this issue when we were performing the experiments. On the other hand, because the datasets we used are relatively small-scale, currently we have not yet observed significant impact of the issue of information loss. Thus, to keep the description of methodology intuitive and simple, we did not include this alternative approach in the paper. But we believe that the alternative way would be a very promising extension for future work.\n\n4. \u201cI really like the visualization of Figure 4 that shows the trajectory of the sampling process that follows the boundaries between classes. The authors also mentioned that some trajectories explore towards outside util there is no real samples, which should be avoided. Could the authors comment on how to avoid such cases?\"\n\nWe really appreciate that you like Figure 4. To address the question, during the experiments, we periodically re-select a set of random points in the latent space as the new initial points for exploring harder samples, which would empirically reduce the chance of being trapped in the outer area. In the revised version, we further clarify this in Section 5.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl3HxBFwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2300/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2300/Authors|ICLR.cc/2020/Conference/Paper2300/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143395, "tmdate": 1576860531262, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment"}}}, {"id": "BygrWUEOoB", "original": null, "number": 1, "cdate": 1573565948843, "ddate": null, "tcdate": 1573565948843, "tmdate": 1573565948843, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "SJldn3zH9H", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment", "content": {"title": "Response to reviewer 2 ", "comment": "We thank Reviewer 2 for finding our work interesting and easy to follow. We answer the two questions below.\n\n1.\u201dThe information samples are fed to the training process, what about the rest \u2018Non-informative\u2019 ones?\u201d\n\nThe proposed framework aims to improve the data-efficiency of a deep learning model. Although those relatively non-informative samples may be left out, the other more informative samples are already able to make the deep learning model achieve a desirable performance. \n\nMoreover, those relatively non-informative (left-out) samples would not be annotated, which significantly reduce the annotating cost.\n\nHowever, it should be noted that all samples including the non-informative ones are still necessary and useful to construct a compact latent space capturing the data distribution in the preparation stage.\n\n2.\u201dWhat is the characteristics of the selected informative samples? I.e., for a class of images, which images should be informative?\u201d\n\nIn our paper, Figure 4 illustrates 6 trajectories (4 of them are positive examples) of how informative training samples are selected. It shows that these trajectories are more likely to explore the boundary area between classes in the latent space where massive ambiguous training sample are located. For example, in Figure 4, trajectory \u201cc\u201d keeps sampling point between class \u201c6\u201d and \u201c0\u201d (also shown in the right panel as sampling snapshots) where they look quite similar to each other.  From both our visualisation and experiments, the characteristic of more informative samples is that they are more likely to be distributed around the boundary area between classes.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl3HxBFwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2300/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2300/Authors|ICLR.cc/2020/Conference/Paper2300/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143395, "tmdate": 1576860531262, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Authors", "ICLR.cc/2020/Conference/Paper2300/Reviewers", "ICLR.cc/2020/Conference/Paper2300/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Comment"}}}, {"id": "rJxqsKr6YH", "original": null, "number": 1, "cdate": 1571801506205, "ddate": null, "tcdate": 1571801506205, "tmdate": 1572972356832, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper proposes a method for sequential and adaptive selection of training examples to be\npresented to the training algorithm. The selection happens in a latent space, based on choosing\nsamples which are in the direction of gradient of the loss in the latent space. Two selection\nstrategies are investigated: nearest neighbor and interpolation followed by generation. Results on\nshown on MNIST, CIFAR10 and IVUS (Intravascular Ultrasound) datasets.\n                                                                \n                                        \nDetailed comments:                      \nThe proposed method works in two stages. First a VAE is trained using unannotated samples. In the\nsecond stage, hard examples are found, in every iteration, in the latent space of the VAE and used\nfor sequential training. The sampling is done using the gradient of the objective function in the\nlatent space. The method makes sense, however the choice of space in which the sample selection is\nbeing done is not well motivated or validated. The space could have been the original image space\n(although given the high dimension, it would probably not work), or could have been any intermediate\nfeature space. Why was the space chosen to be the VAE latent space? Would it be possible to \ndemonstrate some benefits of doing so, theoretically and empirically? \n                                        \nThe experiment section is relatively weak. The datasets used are relatively small and in two out of\nthe three datasets, the method does not improve. The dimension of the latent space is also\nsurprisingly small (2). While the main body of the paper describes the method with VAEs, the\nexperiments for the CIFAR10 dataset (where the results were in favor) were done \\alpha-GAN. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575671635530, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Reviewers"], "noninvitees": [], "tcdate": 1570237724799, "tmdate": 1575671635542, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review"}}}, {"id": "SJldn3zH9H", "original": null, "number": 3, "cdate": 1572314288052, "ddate": null, "tcdate": 1572314288052, "tmdate": 1572972356739, "tddate": null, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "invitation": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes a novel training framework which adaptively selects informative samples that are fed to\nthe training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model.\nThe idea is intuitive and easy to follow. Experimental results demonstrate the efficacy of the proposed method.\nI have two questions about this work:\n1. The informative samples are fed to the training process, what about the rest \"non-informative\" ones?\n2. What is the characteristics of the selected informative samples? i.e., for a class of images, which images should be informative?"}, "signatures": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2300/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["y.mo16@imperial.ac.uk", "shuo.wang@imperial.ac.uk", "c.dai@imperial.ac.uk", "rui.zhou18@imperial.ac.uk", "zt215@cam.ac.uk", "w.bai@imperial.ac.uk", "y.guo@imperial.ac.uk"], "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "authors": ["Yuanhan Mo", "Shuo Wang", "Chengliang Dai", "Rui Zhou", "Zhongzhao Teng", "Wenjia Bai", "Yike Guo"], "pdf": "/pdf/4d5a71b5795167c32d8ef27e810bfa7c4c5c2f2f.pdf", "TL;DR": "This paper introduces a framework for data-efficient representation learning by adaptive sampling in latent space.", "abstract": "Supervised deep learning requires a large amount of training samples with annotations (e.g. label class for classification task, pixel- or voxel-wised label map for segmentation tasks), which are expensive and time-consuming to obtain. During the training of a deep neural network, the annotated samples are fed into the network in a mini-batch way, where they are often regarded of equal importance. However, some of the samples may become less informative during training, as the magnitude of the gradient start to vanish for these samples. In the meantime, other samples of higher utility or hardness may be more demanded for the training process to proceed and require more exploitation. To address the challenges of expensive annotations and loss of sample informativeness, here we propose a novel training framework which adaptively selects informative samples that are fed to the training process. The adaptive selection or sampling is performed based on a hardness-aware strategy in the latent space constructed by a generative model. To evaluate the proposed training framework, we perform experiments on three different datasets, including MNIST and CIFAR-10 for image classification task and a medical image dataset IVUS for biophysical simulation task. On all three datasets, the proposed framework outperforms a random sampling method, which demonstrates the effectiveness of our framework.", "keywords": ["Deep learning", "Data efficiency"], "paperhash": "mo|efficient_deep_representation_learning_by_adaptive_latent_space_sampling", "original_pdf": "/attachment/418053d6e16b6a5aa53dc746ba863739daa48910.pdf", "_bibtex": "@misc{\nmo2020efficient,\ntitle={Efficient Deep Representation Learning by Adaptive Latent Space Sampling},\nauthor={Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao Teng and Wenjia Bai and Yike Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl3HxBFwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl3HxBFwH", "replyto": "Byl3HxBFwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2300/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575671635530, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2300/Reviewers"], "noninvitees": [], "tcdate": 1570237724799, "tmdate": 1575671635542, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2300/-/Official_Review"}}}], "count": 9}