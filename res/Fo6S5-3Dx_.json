{"notes": [{"id": "Fo6S5-3Dx_", "original": "GiIIFbgGpK_", "number": 247, "cdate": 1601308035956, "ddate": null, "tcdate": 1601308035956, "tmdate": 1614985620883, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "S6Kp2IVPQBP", "original": null, "number": 1, "cdate": 1610040538416, "ddate": null, "tcdate": 1610040538416, "tmdate": 1610474148614, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This work combines deep generative models (variational autoencoders, FragVAE) and multi-objective evolutionary computation for molecular design. They use a multilayer perceptron as a predictor for properties. Evolutionary operations are used to explore the latent space of the generative model to produce novel competitive molecules. Experiments are executed to show the effectiveness of the proposed method with respect to Bayesian optimization-based methods.\n\nStrengths:\n\n1 - Combines multi-objective evolutionary computation and deep generative modeling, which is a promising approach to tackle multi-objective optimization in structured spaces.\n\nWeaknesses:\n\nAll the reviewers agree that the paper is not yet ready for publication. They point out the following areas to improve:\n\n1 - The lack of details and clarity in the method.\n\n2 - The experimental section needs to be improved. The evaluation metrics and baselines are weak.\n\n3 - Describe better and more clearly the novelty of the proposed approach with respect to previous work in the area."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040538404, "tmdate": 1610474148597, "id": "ICLR.cc/2021/Conference/Paper247/-/Decision"}}}, {"id": "CQPrV1nQ7SW", "original": null, "number": 2, "cdate": 1603911845850, "ddate": null, "tcdate": 1603911845850, "tmdate": 1606806329493, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Review", "content": {"title": "Needs major improvement", "review": "The authors propose to optimize the continuous representation of molecules in a latent space learned by a fragment-based variational autoencoder using an evolutionary algorithm. To improve the quality of the generated molecules over time, they use new generated samples as augmented data to fine-tune the generative model in each iteration. Experiments are conducted to demonstrate the effectiveness of the proposed algorithm compared with Bayesian optimization-based methods.\n\nThe paper paves a way for combining multi-objective evolutionary computation and deep generative modelling, which could be a potential benefit to other areas in machine learning. However, the paper is not ready for publication at ICLR, since it fails to discuss/empirically compare with highly related work, makes bold but incorrect statements about existing method, and lacks of clarity in presenting its own method.\n\n**Related work**\nRegarding multi-objective property optimization, \\cite{li2018multi, jin2020composing} investigate the same problem and the latter one is one of the state-of-the-arts. Regarding evolutionary algorithm/genetic algorithm in the drug design space, \\cite{Nigam2020Augmenting, leguy2020evomol} are highly relevant, and the authors should discuss how to position their work among these ones.\n\nThe second last sentence in the first page says, \"When SMILES strings are used in VAE, the model suffers from imbalance of tokens in embedding, generation of invalid structures,\" which is incorrect. There are many work in the space to address this problem, e.g. grammar/syntax guided variational autoencoders~\\cite{{kusner2017grammar, dai2018syntax, jin2018junction}.\n\n\n**Presentation**\nThe lack of details and clarity in the method section makes the paper hard to understand. For example, symbol \\bm{y} in equation (1) is never introduced in the context. Since the descriptions below mentioned \"mean square error\", I assume that \\bm{y} represents the ground true property produced by the simulator here. But the authors never explain the intuition behind this. Why is using the mean square error produced by the property predictor is helpful for training the generative model? This is very confusing and it would be better to jusify this in the text.\n\nThe role of the property predictor also confuses me, because we have this simulator which can produce ground truth properties. Is regularizing the generative model the sole purpose of the property predictor? It seems that in section 2.2 the predictor is involved in the evolution step. But this contradicts with section 3.4 where there is a variant in which the property predictor is disabled.\n\n**Evaluation**\nAlthough the paper compared with Bayesian optimization in the experiment section, it's still insufficient to convince the audience. Comparison with Bayesian optimization seems like an ablation study, and it would be hard to understand its effectiveness without comparing to other, especially state-of-the-art approaches. I suggest the author at least compare with the following baselines:\n\n1. a gradient-based baseline: continuous optimization in latent space using gradient of the learned property predictor.\n2. \\citep{jin2020composing}: one of the state-of-the-art in drug design, or other good-performing baselines using RL.\n\n@article{kusner2017grammar,\n  title={Grammar variational autoencoder},\n  author={Kusner, Matt J and Paige, Brooks and Hern{\\'a}ndez-Lobato, Jos{\\'e} Miguel},\n  journal={arXiv preprint arXiv:1703.01925},\n  year={2017}\n}\n\n@article{dai2018syntax,\n  title={Syntax-directed variational autoencoder for structured data},\n  author={Dai, Hanjun and Tian, Yingtao and Dai, Bo and Skiena, Steven and Song, Le},\n  journal={arXiv preprint arXiv:1802.08786},\n  year={2018}\n}\n\n@inproceedings{jin2018junction,\n  title={Junction Tree Variational Autoencoder for Molecular Graph Generation},\n  author={Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},\n  booktitle={International Conference on Machine Learning},\n  pages={2323--2332},\n  year={2018}\n}\n\n\n@article{li2018multi,\n  title={Multi-objective de novo drug design with conditional graph generative model},\n  author={Li, Yibo and Zhang, Liangren and Liu, Zhenming},\n  journal={Journal of cheminformatics},\n  volume={10},\n  number={1},\n  pages={33},\n  year={2018},\n  publisher={Springer}\n}\n\n@article{jin2020composing,\n  title={Composing Molecules with Multiple Property Constraints},\n  author={Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},\n  journal={arXiv preprint arXiv:2002.03244},\n  year={2020}\n}\n\n@inproceedings{\nNigam2020Augmenting,\ntitle={Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space},\nauthor={AkshatKumar Nigam and Pascal Friederich and Mario Krenn and Alan Aspuru-Guzik},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lmyRNFvr}\n}\n\n@article{leguy2020evomol,\n  title={EvoMol: a flexible and interpretable evolutionary algorithm for unbiased de novo molecular generation},\n  author={Leguy, Jules and Cauchy, Thomas and Glavatskikh, Marta and Duval, B{\\'e}atrice and Da Mota, Benoit},\n  journal={Journal of Cheminformatics},\n  volume={12},\n  number={1},\n  pages={1--19},\n  year={2020},\n  publisher={BioMed Central}\n}\n\nUpdate after rebuttal:\nThanks for the response! Combining deep generative modeling with evolutionary algorithms is a very interesting idea in general. I hope the authors can continue to improve the paper (especially on the evaluation part) and resubmit in the future. ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147275, "tmdate": 1606915810701, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper247/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Review"}}}, {"id": "1tT-49L0H4d", "original": null, "number": 4, "cdate": 1603921100080, "ddate": null, "tcdate": 1603921100080, "tmdate": 1606765253208, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Review", "content": {"title": "Official Blind Review #4", "review": "Summary: The paper proposes to tackle multi-objective optimization of molecular properties by combining a genetic algorithm with a fragment-based generative model of SMILES strings. Using a generative model allows to perform evolution in the latent space, as opposed to molecule space. Experiments show the model can produce a rich Pareto front of samples, outperforming bayesian optimization ran in the latent space of the same generative model.\n\nRecommendation: Overall, I am voting to reject. While combining evolutionary algorithms with deep molecular generative models is a very interesting research direction, the current draft uses a very limited set of metrics and baselines, making it unclear if the proposed method is comparable to the state-of-the-art. Technical novelty of the paper is rather limited (combining several previously published ideas), although the particular combination does seem novel. The approach looks promising, but with the provided set of experiments it's hard to compare it to existing methods.\n\nMain pros:\n1. The paper is easy to understand and explores a timely and important topic.\n2. Using concepts from multi-objective optimization (non-domination ranks and crowding distance) sounds like a good idea, given that some established molecular optimization works simply convert the multi-objective problem into a single-objective one by weighing the different terms, and using Pareto frontiers as done in this work could uncover a much richer structure in solution space.\n3. Evolution in the latent space is an interesting approach, which bears some similarities to using particle swarm optimization as in [1]. It would be interesting to see a comparison (quantitative and qualitative) of these two methods.\n\nMain cons:\n1. Most of my concerns are about weak metrics and baselines:\n- For benchmarking the generative model in isolation, the authors use validity, novelty, diversity, and simple molecular distribution statistics (atom, ring, and bond types, together with distributions of simple properties). This is a good sanity check, but a rather weak metric to compare to established models. Perfect validity, novelty and diversity can be obtained with an untrained graph-based model (e.g. [3]), while the other metrics do not capture more fine grained distribution statistics. It would be useful to also compute more complex metrics, such as those in [4] (KL divergence on a larger set of chemical properties, and Frechet ChemNet Distance), and additionally benchmark reconstruction success. Of course, a weak result on any distribution matching metric does not mean the model will not perform well for optimization; nevertheless, having the metrics for FragVAE would provide more insight into the model.\n- For benchmarking optimization, the authors jointly optimize three simple molecular properties. It is a bit unclear if that single task is representative of the broader class of problems encountered in generative chemistry. One could additionally optimize for the 20 tasks proposed in [4], and run quality filters on optimized samples to see if the optimizer exploited the scoring function (see [4] for the filters, and [5] for more discussion on the topic).\n2. The generative model itself is the one of [2], with the addition of a property predictor (to regularize the latent space), and a warm-up scheme for the KL-divergence part of the loss. Both modifications are rather standard, which raises expectations with respect to the experimental evaluation of the method.\n3. Some details of the comparison with BO are unclear:\n- Depending on the comparison, molecules from either 5 or 6 BO batches are selected; how was the number of batches chosen? Given that the evolutionary process by design is likely to retain all Pareto-optimal samples seen during optimization, wouldn't it be more fair to take all samples produced by BO, instead of a fixed number of batches? The paper mentions that the BO batch size is 8 - is it the case that evolution produces 20k samples, which are then compared to 40-48 samples from BO?\n- How many steps does BO do, and what is the dimension of the latent space? I am wondering what is contributing to BO being so slow (as seen in Table 3).\n\nOther comments:\n- In the loss for the property predictor, are the losses for the different kinds of properties normalized in some way?\n- The paper says \"One of the theoretical innovations of our approach is that it demonstrates that EC methods are extendable to corresponding deep versions.\" - this contribution is not theoretical; moreover, I wouldn't call the evolutionary algorithm deep (the generative model is)\n- \"Data evolution tends to be more efficient than direct evolution of model structures and parameters.\" - can the authors expand on what that means? Is that a result shown in the literature?\n- In Section 2.3, the sampling of r_i could be just from Uniform(-d, 1+d), instead of linearly transforming a sample from Uniform(0, 1). Moreover, I am curious about the fact that r_i can be outside of (0, 1), which means the child may land outside of the segment connecting the parents. Did the authors observe this to work better in practice that sampling r_i from (0, 1)? One danger there is that the samples may get drawn towards the origin, was this observed empirically?\n- \"To clarify, the perfect validity reported in Podda et al. (2020) is actually calculated as the ratio of valid generated SMILES strings after discarding invalid fragment sequences\" - can the authors expand on this? I assumed predicting the next fragment is a classification problem (with a very large number of classes), if so, how can invalid fragments be produced?\n- Since using a larger population size performs better (Table 7), is there any reason this is not the default setting for the method described in the paper? Would the Pareto front keep improving with even larger population sizes?\n- I cannot parse lines 2-9 of the pseudocode in Appendix A.1. Moreover, why does compute_crowding_distance take the Pareto fronts as one of the arguments?\n- The bug shown in Appendix A.2 looks very serious; it seems latent codes of different samples in a batch get arbitrarily mixed up. Is it fair to say that the original implementation of [2] was mostly ignoring the latent code?\n- I am confused by Table 4: as far as I understand, two groups of samples are being lumped together, and the Pareto front is recalculated. How is it possible that there are no samples from the \"Without PP\" setting in the combined Pareto front, yet the combined front doesn't include some samples that were Pareto-optimal in the \"With PP\" setting? If all samples from \"Without PP\" were dominated by Pareto-optimal samples from \"With PP\", then I would expect the combined front to be the same as for the \"With PP\" samples.\n- What is causing the sudden jumps in the loss plots in Figure 8?\n\nSmall remarks, typos, and grammar issues (did not influence my rating recommendation):\n- Page 1: \"adopt\" -> \"adopts\"\n- Page 1: the paper distinguishes two classes of approaches: one based on SMILES, and one based on Graph Convolutional Neural Networks. It would be better to drop the word \"Convolutional\", as it does not really apply to some methods based on graph message passing (e.g. [3, 6])\n- Page 1: \"that, molecules,\" -> \"that molecules,\"\n- Page 2: \"bounds\"\n- Page 2: \"optimizations\" -> \"optimization\" (twice)\n- Page 2: \"for neuroevolution that leads to evolution\" -> \"for evolution\"\n- The EDA acronym is introduced, and never used - I would just skip introducing the acronym then\n- The paper uses terms \"evolutionary computation (EC)\" and \"evolutionary strategy (ES)\", how do those differ? If they mean the same thing, I'd suggest sticking to one for clarity\n- Page 2: \"structural transformation\" -> \"structural transformations\"\n- Page 2: missing space in \"operations.This\"\n- Pages 2 & 4: \"for examples\" -> \"for example\"\n- Page 6: \"The novelty is defined as the ratio of number of generated novel valid molecules that do not exist in the training data (...)\" - I would drop the word \"novel\", since novelty is being defined by this very sentence\n- Page 6: \"proximity (...) with\" -> \"proximity (...) to\"\n- Page 13: \"phrase\"\n\nReferences:\n- [1] Efficient multi-objective molecular optimization in a continuous latent space\n- [2] A Deep Generative Model for Fragment-Based Molecule Generation\n- [3] Constrained Graph Variational Autoencoders for Molecule Design\n- [4] GuacaMol: Benchmarking Models for de Novo Molecular Design\n- [5] On Failure Modes of Molecule Generators and Optimizers\n- [6] Junction Tree Variational Autoencoder for Molecular Graph Generation\n\n----------------------------------------------------------------------------------------------------\n\nComments after rebuttal:\n\nI would like to thank the authors for their response. I am keeping my score, but I encourage the authors to resubmit after improving the things that were discussed (most importantly, using better metrics and comparing to more established baselines); I think this will make the paper much stronger.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147275, "tmdate": 1606915810701, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper247/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Review"}}}, {"id": "0LI49sskAM", "original": null, "number": 2, "cdate": 1606272370304, "ddate": null, "tcdate": 1606272370304, "tmdate": 1606275938276, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "1tT-49L0H4d", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment", "content": {"title": "Thanks for your valuable comments", "comment": "Your detailed comments are highly appreciated. In the past two weeks, I have to finish scheduled teaching and reviewing multiple papers for ICLR and AAAI. But I will focus on improving this work from now on. Below are some critical clarifications which be informative to the reviewers before the author response period is ended.  \n\n1. I will undertake more comparative studies particularly with benchmarks from GuacaMol and MOSES.\n\n2. Our DEL framework is not restricted to the currently used DGM. Most DGMs for molecular design can be instead embedded into this framework. We will test the performance of other DGMs in DEL.\n\n3. Our original paper is unclear. The concept \"batch\" used in MOBO is different from the concept \"minibatch\" in deep learning. \"Batch\" in MOBO refers to a group of data points / solutions in one iteration. As shown in Figure 26 in appendix, the two MOBO algorithms converge within 30 iterations. Putting the solutions in the last few iterations renders us 40-48 valid samples from MOBO. Compared with our method, scalability is one of the major issues. The efficiency of the two MOBO algorithms are highly restricted by the batch size (i.e. number of solutions in one iteration) and the number of MC samples in acquisition functions.\n\n4.  In the loss for the property predictor, the losses for the different kinds of properties were not normalized. We will test the impact of property normalization.\n\n5. \"Data evolution tends to be more efficient than direct evolution of model structures and parameters.\" Due to high time and space complexities, it is unlikely that we can evolve many different deep generative models with limited resources. However, data evolution is highly feasible.\n\n6. In Fragment-based molecular design, not all fragments can be assembled together due to constraints on bonds. Thus, not all generated sequences of fragments are valid.\n\n7. Pareto fronts is needed to compute crowding distances, because the crowding distances are computed front-wise. \n\n8. Yes, the bug in Podda et al. (2020)'s implementation is severe and crucial. We fixed it and make it really work.\n\n9.  The use of larger population size takes longer time. It is indeed a trade-off between efficiency and performance.\n\n10. Good question for Table 4. When we combine the Pareto fronts from two different cases and do non-dominated sorting, it is possible to have more than two new fronts.\n\n11. Evolutionary strategy (ES) is a special family of EC algorithms.\n\n12. The work in [Efficient multi-objective molecular optimization in a continuous latent space] is really interesting. The major difference between ours the their work is that we fine-tune the DGM using new populations of samples with better properties and show that this strategy does improve the performance in comparison with EC with static DGM.\n\nThank you again for your comments on our work."}, "signatures": ["ICLR.cc/2021/Conference/Paper247/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Fo6S5-3Dx_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper247/Authors|ICLR.cc/2021/Conference/Paper247/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873080, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment"}}}, {"id": "D4lSrJQFBs9", "original": null, "number": 5, "cdate": 1606275359850, "ddate": null, "tcdate": 1606275359850, "tmdate": 1606275359850, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "3y3gVpvDs1", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment", "content": {"title": "Some clarifications", "comment": "Thanks for your comments. Please see below our responses.\n\n1. The major novelty of our work is the apply evolutionary computing in the latent space of deep generative models, which is very unlike your mentioned methods that apply EC in the original space and did not combine with deep learning. \n\n2. Our DEL framework is simple and flexible, thus other DGMs and EC algorithms can be easily embedded in it. Here we show a prototype of our idea and show that it works well.\n\n 3. As mentioned in line 15 of Algorithm 1, the properties of new molecules are obtained using RDKit.\n\n4. We will continue to do comparative studies with baselines using statistical measures for evaluation.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Fo6S5-3Dx_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper247/Authors|ICLR.cc/2021/Conference/Paper247/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873080, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment"}}}, {"id": "Y6Vnx74SQU_", "original": null, "number": 4, "cdate": 1606274629275, "ddate": null, "tcdate": 1606274629275, "tmdate": 1606274629275, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "CQPrV1nQ7SW", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment", "content": {"title": "Thank you", "comment": "\nThank you for your review that can really help us improve our work. I was busy with lot of other commitments (teaching, reviewing, etc). But I will focus on improving this work from now on. Below are a few quick responses to your comments. \n\n1. RDKit is used as simulator to calculate properties of new molecules. The property predictor is merely designed to regularize the generative model.\n\n2. The work in [Nigam2020Augmenting] is seemingly similar to our work when reading the title. However their work neither take advantage of the latent representation space nor multi-objectivity, thus essentially very different from ours.\n\n3. EvoMol proposed in [leguy2020evomol] is a rather classic EC algorithm on molecular graph. It does not combine with deep generative models.  Thus our method is substantially different from EvoMol.\n\n4. We will have more comparisons with baselines including the above two methods.\n\nSincerely,\n --\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Fo6S5-3Dx_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper247/Authors|ICLR.cc/2021/Conference/Paper247/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873080, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment"}}}, {"id": "87zkkV9EUQC", "original": null, "number": 3, "cdate": 1606272859708, "ddate": null, "tcdate": 1606272859708, "tmdate": 1606272859708, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "XoQhLfl-nX", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment", "content": {"title": "Thanks for your comments", "comment": "In addition to our feedback to Reviewer 4, a few specific clarifications here:\n\n1. We do not tend to sell FragVAE. Basically most DGMs for molecular design can be instead embedded in our DEL system.\n\n2. Our major novelty is the creation of the DEL system.\n\n3. Within the next few days, we will continue to improve the presentation of this paper, conduct more comparisons with baselines and analysis.\n\nThanks!"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Fo6S5-3Dx_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper247/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper247/Authors|ICLR.cc/2021/Conference/Paper247/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873080, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Comment"}}}, {"id": "3y3gVpvDs1", "original": null, "number": 1, "cdate": 1603649897874, "ddate": null, "tcdate": 1603649897874, "tmdate": 1605024731956, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Review", "content": {"title": "Limited novelty and contribution", "review": "The authors combine deep generative models and multi-objective evolutionary computation for computer-aided molecular design. In particular, they employ a variational autoencoder (FragVAE, as molecule modeler) and a multilayer perceptron (as property predictor). Evolutionary operations explore the latent space of the generative model to produce novel competitive molecules. The paper is interesting and tackle a very relevant problem. However, I detect the following severe limitation: \n\n- My main concern is that I have the impression that this research is quite incremental and may not be suitable for publication in a top-tier machine learning conference. We should not forget that Evolutionary Computation techniques have been extensively applied to computer-aided molecular design and bioinformatics. In fact, there are works on the subject already published in the 90's (see, for instance, [1, 2, 3]). In the same way, there are already successful examples of automated drug-design applications using multi-objective evolutionary algorithms [4]. In this regard, I am not sure that the fact that the contributions presented in the paper (last paragraph of page 2) are sufficient. Furthermore, if I'm not mistaken, the authors did not design any specific evolutionary operator (selection, crossover and mutation) for this task and relied on conventional ones. In the same way, the authors adopted an already existing VAE model for molecular generation (Podda et al., 2020).\n\n[1] Clark, David E., and David R. Westhead. \"Evolutionary algorithms in computer-aided molecular design.\" Journal of Computer-Aided Molecular Design 10.4 (1996): 337-358.\n\n[2] Parrill, Abby L. \"Evolutionary and genetic methods in drug design.\" Drug Discovery Today 1.12 (1996): 514-521.\n\n[3] Willett, Peter. \"Genetic algorithms in molecular recognition and design.\" Trends in biotechnology 13.12 (1995): 516-521.\n\n[4] Besnard, J\u00e9r\u00e9my, et al. \"Automated design of ligands to polypharmacological profiles.\" Nature 492.7428 (2012): 215-220.\n\nThere are other aspects that, in my humble opinion, should be clarified or improved in the paper:\n\n- Not clear if the properties of the generated samples are obtained using the MLP (as indicated in page 3 and Figure 1) or by the RDKit simulator (Landrum, 2006) (as also mentioned in page 3). Could the authors clarify this point?\n\n- How all hyperparameters (FragVAE, MLP, evolutionary algorithm) were selected and how dependent are the results obtained to the values selected? \n\n- Why only multi-objetive Bayesian optimization methods are included in the final comparison? Also, in relation to the experimental section, I think that in this final comparison the authors should employ statistical hypothesis testing to check the existence of statistically significant differences between the methods under comparison. ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147275, "tmdate": 1606915810701, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper247/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Review"}}}, {"id": "XoQhLfl-nX", "original": null, "number": 3, "cdate": 1603919399988, "ddate": null, "tcdate": 1603919399988, "tmdate": 1605024731752, "tddate": null, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "invitation": "ICLR.cc/2021/Conference/Paper247/-/Official_Review", "content": {"title": "Careful tuning of existing methods, but limited technical novelty", "review": "\n= quality/ clarity = \nneeds work. see below.  too much focus on minor technical details (e.g. KL annealing for VAEs). not enough discussion of the more technically novel content, like the details of the multi-objective optimization method.\n\n= originality / significance = \nDraws on some interesting ideas from the evolutionary computation community on multi-objective optimization. However, these are not the focus of exposition. The VAE details overlap considerably with prior work.\n\nExperiments are for standard tasks from recent literature, but there is limited comparison to recently published methods.\n\n=Major Comments=\n\nThe Methods section is very dense. You should start with a definition of the problem. It was unclear, for example, that your optimization would be collecting multiple rounds of data and that you have a starting set of labeled and unlabeled data. You should definitely put an algorithm box in the main paper body and put many of the details that have been introduced in prior work (e.g. KL annealing) in an appendix. \n\nThe Methods section does not clearly delineate what is prior work and what is a novel contribution. Is there anything in Sec 2.1 novel, for example? Overall, is my assessment correct that your work combines an existing encoder-decoder model (FragVAE) with some methods from the evolution literature for multi-objective optimization? Is the primary novelty to adapt these evolution methods to work in latent space?\n\nThe difference between FragVAE and Podda et al., 2020 is minor, mostly consisting of the addition of a supervised regression network and some re-balancing of the terms in the loss, KL annealing, etc. Sec 3.1 of the results analyzes the impact of tuning these details. While this is important for a practitioner's model development, they will not be of sufficient general interest to readers. Sec 3.2 is also mostly focused again on understanding the impact of tuning parameter choice and does not compare to alternative methods from the literature.\n\nSec 3.3: The choice of baselines is very focused on comparing against other methods for multi-objective optimization. Why not also compare against other optimization methods for recent ML/chemistry papers that perform single-objective optimization? Many of these are referred to in the introduction. \n\nOverall, the methods in section 2.2 for multi-objective optimization are interesting and introducing them to the modern ML community is a valid contribution. However, the paper's exposition and experiments are too focused on details of the FragVAE model and do not analyze the details of the multi-objective optimization approach enough.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper247/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper247/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Evolutionary Learning for Molecular Design", "authorids": ["~Yifeng_Li1", "~Hsu_Kiang_Ooi1", "alain.tchagang@nrc-cnrc.gc.ca"], "authors": ["Yifeng Li", "Hsu Kiang Ooi", "Alain Tchagang"], "keywords": ["Deep Evolutionary Learning", "Fragment-Based Drug Design", "Deep Generative Model", "Drug Design", "Multi-objective Optimization"], "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that integrates  fragment-based deep generative model and multi-objective evolutionary computation for molecular design. Our approach enables (1) evolutionary operations in the latent space of the generative model, rather than the structural space, to generate novel promising molecular structures for the next evolutionary generation, and (2) generative model fine-tuning using newly generated high-quality samples. Thus, DEL implements a data-model co-evolution concept which improves both sample population and generative model learning. Experiments on two public datasets indicate that sample population obtained by DEL exhibits improved property distributions, and dominates samples generated by multi-objective Bayesian optimization algorithms.", "one-sentence_summary": "Population of new molecules designed by our novel deep evolutionary learning process exhibit improved values of properties in comparison with original training molecules.", "pdf": "/pdf/28537881effd198cea8cad58a739057e27823c1a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|deep_evolutionary_learning_for_molecular_design", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fHMPX_EmRd", "_bibtex": "@misc{\nli2021deep,\ntitle={Deep Evolutionary Learning for Molecular Design},\nauthor={Yifeng Li and Hsu Kiang Ooi and Alain Tchagang},\nyear={2021},\nurl={https://openreview.net/forum?id=Fo6S5-3Dx_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Fo6S5-3Dx_", "replyto": "Fo6S5-3Dx_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper247/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147275, "tmdate": 1606915810701, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper247/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper247/-/Official_Review"}}}], "count": 10}