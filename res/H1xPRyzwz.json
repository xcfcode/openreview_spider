{"notes": [{"tddate": null, "ddate": null, "tmdate": 1524765496873, "tcdate": 1518628439870, "number": 362, "cdate": 1518628439870, "id": "H1xPRyzwz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "H1xPRyzwz", "original": "BJy0fcgRZ", "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Capturing Human Category Representations by Sampling in Deep Feature Spaces", "abstract": "Understanding how people represent categories is a core problem in cognitive science, with the flexibility of human learning remaining a gold standard to which modern artificial intelligence and machine learning aspire. Decades of psychological research have yielded a variety of formal theories of categories, yet validating these theories with naturalistic stimuli remains a challenge. The problem is that human category representations cannot be directly observed and running informative experiments with naturalistic stimuli such as images requires having a workable representation of these stimuli. Deep neural networks have recently been successful in a range of computer vision tasks and provide a way to represent the features of images. In this paper, we introduce a method for estimating the structure of human categories that draws on ideas from both cognitive science and machine learning, blending human-based algorithms with state-of-the-art deep representation learners. We provide qualitative and quantitative results as a proof of concept for the feasibility of the method. Samples drawn from human distributions rival the quality of current state-of-the-art generative models and outperform alternative methods for estimating the structure of human categories.", "pdf": "/pdf/154b20dd29baba3c68444324e9852ace29204b37.pdf", "TL;DR": "using deep neural networks and clever algorithms to capture human mental visual concepts", "paperhash": "peterson|capturing_human_category_representations_by_sampling_in_deep_feature_spaces", "_bibtex": "@misc{\npeterson2018capturing,\ntitle={Capturing Human Category Representations by Sampling in Deep Feature Spaces},\nauthor={Joshua Peterson, Krishan Aghi, Jordan Suchow, Alexander Ku, Tom Griffiths},\nyear={2018},\nurl={https://openreview.net/forum?id=BJy0fcgRZ},\n}", "keywords": ["category representations", "psychology", "cognitive science", "deep neural networks"], "authors": ["Joshua Peterson", "Krishan Aghi", "Jordan Suchow", "Alexander Ku", "Tom Griffiths"], "authorids": ["peterson.c.joshua@gmail.com", "kaghi@berkeley.edu", "suchow@berkeley.edu", "alexku@berkeley.edu", "tom_griffiths@berkeley.edu"]}, "nonreaders": [], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730180904, "tcdate": 1509102279264, "number": 349, "cdate": 1518730180896, "id": "BJy0fcgRZ", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "BJy0fcgRZ", "original": "HykAGcxRZ", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Capturing Human Category Representations by Sampling in Deep Feature Spaces", "abstract": "Understanding how people represent categories is a core problem in cognitive science, with the flexibility of human learning remaining a gold standard to which modern artificial intelligence and machine learning aspire. Decades of psychological research have yielded a variety of formal theories of categories, yet validating these theories with naturalistic stimuli remains a challenge. The problem is that human category representations cannot be directly observed and running informative experiments with naturalistic stimuli such as images requires having a workable representation of these stimuli. Deep neural networks have recently been successful in a range of computer vision tasks and provide a way to represent the features of images. In this paper, we introduce a method for estimating the structure of human categories that draws on ideas from both cognitive science and machine learning, blending human-based algorithms with state-of-the-art deep representation learners. We provide qualitative and quantitative results as a proof of concept for the feasibility of the method. Samples drawn from human distributions rival the quality of current state-of-the-art generative models and outperform alternative methods for estimating the structure of human categories.", "pdf": "/pdf/25517f85b1d4ecfe69c658faadbbf877b2e69a0f.pdf", "TL;DR": "using deep neural networks and clever algorithms to capture human mental visual concepts", "paperhash": "peterson|capturing_human_category_representations_by_sampling_in_deep_feature_spaces", "_bibtex": "@misc{\npeterson2018capturing,\ntitle={Capturing Human Category Representations by Sampling in Deep Feature Spaces},\nauthor={Joshua Peterson and Krishan Aghi and Jordan Suchow and Alexander Ku and Tom Griffiths},\nyear={2018},\nurl={https://openreview.net/forum?id=BJy0fcgRZ},\n}", "keywords": ["category representations", "psychology", "cognitive science", "deep neural networks"], "authors": ["Joshua Peterson", "Krishan Aghi", "Jordan Suchow", "Alexander Ku", "Tom Griffiths"], "authorids": ["peterson.c.joshua@gmail.com", "kaghi@berkeley.edu", "suchow@berkeley.edu", "alexku@berkeley.edu", "tom_griffiths@berkeley.edu"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}, "tauthor": "ICLR.cc/2018/Workshop"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573625571, "tcdate": 1521573625571, "number": 345, "cdate": 1521573625233, "id": "SJzZ1kJ9M", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "H1xPRyzwz", "replyto": "H1xPRyzwz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "This paper was invited to the workshop track based on reviews at the main conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Capturing Human Category Representations by Sampling in Deep Feature Spaces", "abstract": "Understanding how people represent categories is a core problem in cognitive science, with the flexibility of human learning remaining a gold standard to which modern artificial intelligence and machine learning aspire. Decades of psychological research have yielded a variety of formal theories of categories, yet validating these theories with naturalistic stimuli remains a challenge. The problem is that human category representations cannot be directly observed and running informative experiments with naturalistic stimuli such as images requires having a workable representation of these stimuli. Deep neural networks have recently been successful in a range of computer vision tasks and provide a way to represent the features of images. In this paper, we introduce a method for estimating the structure of human categories that draws on ideas from both cognitive science and machine learning, blending human-based algorithms with state-of-the-art deep representation learners. We provide qualitative and quantitative results as a proof of concept for the feasibility of the method. Samples drawn from human distributions rival the quality of current state-of-the-art generative models and outperform alternative methods for estimating the structure of human categories.", "pdf": "/pdf/154b20dd29baba3c68444324e9852ace29204b37.pdf", "TL;DR": "using deep neural networks and clever algorithms to capture human mental visual concepts", "paperhash": "peterson|capturing_human_category_representations_by_sampling_in_deep_feature_spaces", "_bibtex": "@misc{\npeterson2018capturing,\ntitle={Capturing Human Category Representations by Sampling in Deep Feature Spaces},\nauthor={Joshua Peterson, Krishan Aghi, Jordan Suchow, Alexander Ku, Tom Griffiths},\nyear={2018},\nurl={https://openreview.net/forum?id=BJy0fcgRZ},\n}", "keywords": ["category representations", "psychology", "cognitive science", "deep neural networks"], "authors": ["Joshua Peterson", "Krishan Aghi", "Jordan Suchow", "Alexander Ku", "Tom Griffiths"], "authorids": ["peterson.c.joshua@gmail.com", "kaghi@berkeley.edu", "suchow@berkeley.edu", "alexku@berkeley.edu", "tom_griffiths@berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 2}