{"notes": [{"id": "HdX654Yn81", "original": "nSErnhs_mJ", "number": 1228, "cdate": 1601308137438, "ddate": null, "tcdate": 1601308137438, "tmdate": 1614985740774, "tddate": null, "forum": "HdX654Yn81", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "2z0R9WieGE", "original": null, "number": 1, "cdate": 1610040397436, "ddate": null, "tcdate": 1610040397436, "tmdate": 1610473992848, "tddate": null, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes to use an ensemble of VAEs to learn better disentangled representations by aligning their representations through additional losses. This training method is based on recent work by Rolinek et al (2019) and Duan et al (2020), which suggests that VAEs tend to approximate PCA-like behaviour when they are trained to disentangle. The method is well justified from the theoretical perspective, and the quantitative results are good. Saying this, the reviewers raised concerns about the qualitative nature of the learnt representations, which do not look as disentangled as the quantitative measures might suggest. There was a large range of scores given to this paper by the reviewers, which has generated a long discussion. I have also personally looked at the paper. Unfortunately I have to agree that the latent traversal plots do not look as disentangled as the metric scores would suggest, and as one might hope to see on such toy datasets as dSprites. The traversals are certainly subpar to even the most basic approaches to disentanglement, like beta-VAE. For this reason, and given the reviewer scores, I unfortunately have to recommend to reject the paper this time around, however I hope that the authors are able to address the reviewers' concerns and find the source of disagreement between their qualitative and quantitative results for the future revisions of this work."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"forum": "HdX654Yn81", "replyto": "HdX654Yn81", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040397422, "tmdate": 1610473992832, "id": "ICLR.cc/2021/Conference/Paper1228/-/Decision"}}}, {"id": "nRK0FwFceL9", "original": null, "number": 2, "cdate": 1603913294462, "ddate": null, "tcdate": 1603913294462, "tmdate": 1606768044586, "tddate": null, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review", "content": {"title": "Simple ensembling technique to improve disentanglement", "review": "This paper proposes a simple and effective technique to improve disentanglement by coupling the latent spaces of different VAE models. It builds on Duan et al. (2019)\u2019s proposed method to rank the representations of different models. By learning a VAE ensemble with linear transformations between the latent spaces and an additional \u201ccross-model\u201d reconstruction loss, the authors show that they can achieve significantly better disentangling.\n\nStrengths:\n- The theoretical justification seems reasonable and builds on previous work.\n- The experiments are organized to answer three meaningful questions. The results do suggest the VAE ensemble learns better latent representations which can be converted between models with simple, orthogonal linear transformations.\n\nQuestions:\n- Regarding the last term of the loss in equation (2): for a fixed i and j, the loss is E_{q(z_ij|x)} ||z_jj - z_ij|| = E_{q(z_ij|x)}||z_jj - M_ji z_ii||. This loss term can be optimized by tuning the parameters of VAE i, VAE j, and M_ji. Do you backprop through all these? Or is there a stopgradient on z_ii when used in computing this loss term (i.e. no gradients through VAE i from this loss term)?\n- What would be the effect of training the VAE models in two stages: independently first and then jointly in the ensemble? Would it help or hurt disentangling?\n- How would you express the total information cost of representing an image across the VAEs in the ensemble (say if you wanted to to compare the information rate to a single VAE)? It doesn't make sense to add up the KL costs linearly.\n\nSuggestions:\n- It would help enormously to strengthen the findings and assertions regarding the effect of ensemble size and the gamma hyperparameter.\n- Consider adding another disentanglement metric e.g. MIG.\n- Figure 5 in the Appendix shows a larger effect on DtO of the number of dims than the gamma hyperparameter. This result (and other results on CelebA) are perhaps worth describing in the main paper. \n\nMinor:\n- In Figure 2(a) I assume the curves are overlapping? Does it help to use a log scale for the y-axis?\n- How are the latent dimensions sorted in Figure 3?\n- Are the scores in Table 2 across different training runs?", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538123565, "tmdate": 1606915771862, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1228/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review"}}}, {"id": "IkYZyU1zin", "original": null, "number": 1, "cdate": 1603513177493, "ddate": null, "tcdate": 1603513177493, "tmdate": 1606406880713, "tddate": null, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review", "content": {"title": "Recommend to Reject", "review": "# Summary\n\nThe authors introduce a novel VAE-based approach for unsupervised learning of disentangled representations of image data.  The approach trains an ensemble of VAEs along with pair-wise linear transformations between their latent spaces.  The objective includes the ELBO objectives for each VAE as well as two additional pressures:  (i) An L2 similarity objective that pressures samples from each VAE latent space to match under linear transformations samples from the other VAE latent spaces, and (ii) A cross-model decoding objective that encourages decoding accuracy of the linearly transformed latent samples.  The authors provide a theoretical argument that the linear transformations should learn to be orthogonal, and show some experimental results indicating that their model performs well compared to baselines when evaluated with an established disentangling metric.\n\n# Pros\n\n* The theoretical analysis in section 4.1 is clear and provides good mathematical intuition for the authors\u2019 results.\n* The introduction and related work sections are clear and include a thorough set of references.\n\n\n# Cons:\n\n* The authors\u2019 baseline results give unexpectedly low metric scores.  The authors report FactorVAE metric values of 0.665 for beta-VAE and 0.764 for FactorVAE on the dSprites dataset.  However, the values reported in the FactorVAE paper (and corroborated by others) on the same dataset are significantly higher.  This makes me suspicious that something went wrong with the authors\u2019 training --- perhaps they didn\u2019t train those baseline models to completion or something else went wrong.  Having baseline results that are inconsistent with the existing literature makes me uneasy.\n* The traversals in Figure 8 from the authors\u2019 model are much less disentangled than other models in the literature.  For example, they are much less disentangled than the traversals shown in the beta-VAE paper and the FactorVAE paper on the same dataset.  Thus from these traversals, it seems that the authors\u2019 model is performing worse than existing models in the literature (the authors\u2019 metrics indicate the opposite, but as mentioned above I\u2019m uncertain about the validity of those metric results).  Figure 3-A also suggests that the authors\u2019 model is using too many informative latents, i.e. not disentangling well.\n* I am not convinced by the authors\u2019 intuitive justification in lines 216-225 (and appendix C) that the cross-model objective encourages entangled models to align to disentangled models.  Specifically, in that argument the authors seem to assume that orthogonal linear transformations are orthonormal.  However, there is nothing to enforce normality of the transformations in the model, hence the cross-model encoding variance from an entangled to a disentangled model could be quite small.\n* The purpose of the cross-model reconstructions is not clear, particularly given that I\u2019m not convinced by the authors\u2019 intuitive justification of them.  The L2 regularization between the transformed encodings should pressure the cross-model reconstructions to be good, so I do not see the reason to include them in the model objective.  It would be good if the authors could do an ablation study without the cross-model reconstructions.\n* The authors do not mention the computational complexity of their model, yet computational complexity seems to be a significant drawback of it.  Ensemble training is very computationally expensive, so the authors should include some discussion about it as well as runtimes and memory requirements for their model.  Furthermore, with the cross-model reconstructions the computational complexity of the authors\u2019 model scales with the square of the number of ensemble elements, which is quite a steep scaling.\n* The authors only compare to a couple (relatively old) baselines, betaVAE and FactorVAE, which are no longer state-of-the-art.  However, more recently a number of other VAE models have been published that perform better.  In order to support their claims about state-of-the-art performance, the authors should compare to newer baselines.  Here are a few examples:\nDIP-VAE  (Variational inference of disentangled latent concepts from unlabeled observations.  Kumar et al., 2017)\nTCVAE (Isolating sources of disentanglement in variational autoencoders. Chen et al., 2018)\nSpatial Broadcast VAE  (Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs.  Watters et al., 2019)\n* The authors also don\u2019t include many metrics or datasets.  dSprites and CelebA were used in the original betaVAE paper, but more recently it has become the norm to test on a larger set of datasets and with a number of different metrics to convincingly show disentangling.  By the way, a number of models, datasets, and metrics have been open-sourced in DistLib (https://github.com/google-research/disentanglement_lib), which may be useful for comparing to more models with more metrics on more datasets.\n\n# Summary\n\nI do not recommend accepting this paper.  Baseline results are inconsistent with prior work, the model seems to disentangle less well than existing methods, and the authors don\u2019t do ablation experiments to justify the high computational complexity of the model.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538123565, "tmdate": 1606915771862, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1228/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review"}}}, {"id": "bO9wmlOyAF", "original": null, "number": 3, "cdate": 1604069040598, "ddate": null, "tcdate": 1604069040598, "tmdate": 1606346848646, "tddate": null, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review", "content": {"title": "Interesting VAE ensemble approach for improving disentangled representations with theoretical as well as experimental validation ", "review": "### Summary:\nThis submission proposes an ensemble framework to improve learning disentangled representations with Variational Autoencoders (VAEs). The approach builds on the assumption that entangled latent representations learned by VAEs show some \u201cuniqueness\u201d in their latent space structure, while disentangled representations exhibit some \u201csimilarity\u201d; an assumption corroborated by recent studies. On that basis, a VAE ensemble approach is proposed where several VAEs are connected through linear mappings between the individual latent spaces to encourage alignment of latent representations and thus disentanglement. A formal derivation of the framework is provided and the formal validity of the underlying assumption demonstrated. Furthermore, empirical evaluation of the proposed approach in comparison to the standard VAE, beta-VAE and FactorVAE on the datasets dSprites (main results, main text) and CelebA (appendix) is performed, yielding improved results on the FactorVAE disentanglement metric (all baseline methods considered) as well as the Distance to Orthogonality (DtO) metric (only standard VAE considered).\n\n### Strengths:\n- Significance / Novelty: The proposed approach builds on recent work by Rolinek et al. and Duan et al., which show PCA-like behaviour in VAEs and leverage these results to develop disentanglement scores for model selection. This submission uses these insights for training an ensemble of VAEs in order to improve learning of disentangled representations. The claim is validated both formally as well as empirically on a benchmark dataset (dSprites) and state-of-the-art methods like FactorVAE, where the proposed framework performs favourably. To my knowledge the proposed idea is novel and simple yet potentially quite powerful. This approach could be relevant for other disentanglement methods and a wider audience employing VAE approaches.\n- Technical Quality: An important contribution of this paper is the thorough formal derivation and theoretical justification of the approach which to me appears sound. The experimental evaluation is well-designed and mostly succeeds in justifying the claims, with some exceptions outlined below. I believe that all the relevant details to reproduce the results are provided.\n- In particular, the results that the DtO comes close to 0 (fig. 2) for the ensemble approach illustrate that the latent representations of the different VAE in the ensemble converge (question 1), i.e. the linear transformations between latent space converge to (signed) permutations. This means that it should not matter which latent representations in the ensemble is studied (in the paper the first model in the ensemble is chosen; lines 274-275). However, I am curious whether the authors considered the results (\u201cpolarisation\u201d and FactorVAE scores) for other latent representations (i.e. not the first model) and how much the results agreed?\n- Clarity: I consider this paper well-written and well-structured. Relevant details and formal justifications are provided in an appropriate manner resulting in a self-contained paper.\n\n### Weaknesses:\n- The ensemble approach comes at a cost which is probably the reason why only up to 5 parallel models were used. Can the authors comment on the running time and memory requirements compared to the competing methods? I think the quality of the paper could be improved if these details and the restrictions of the ensemble approach were provided.\n- The results in table 1 (comparison of baseline methods and ensemble approach w.r.t. FactorVAE metric) show that an ensemble of size >=3 can outperform state-of-the-art methods like FactorVAE on the considered FactorVAE metric. However, they also show that it might not always be beneficial to put more weight onto enforcing aligned latent representations for the same ensemble size (gamma > 1). This is a bit at odds with the premise of the paper. As the discussion points out (question 3, lines 285-289), this could be due to balancing different contributions in the more extensive objective function. However, this could also hint at potential optimisation problems for more challenging tasks. \n- The examples for the latent traversal (in the appendix) are slightly less convincing and a comparison is only done w.r.t. a standard VAE. However, it would be much more insightful to compare the ensemble approach to beta-VAE and FactorVAE latent traversal results.\n- Similar to the last point, in figure 2, it would be quite insightful to see the DtO results for the beta-VAE and especially the FactorVAE. In my opinion, this is a crucial aspect which so far is missing and could justify the approach even more. Isn\u2019t the whole motivation that beta-VAE and FactorVAE should perform slightly worse w.r.t DtO?\n\n### Additional Feedback:\n- Figure 1: I like the illustration, however I do not understand the bar plot (\u201cVAE, BetaVAE, FactorVAE, VAE Ensemble\u201d). Maybe an additional annotation could help?\n- Line 8: *\u201csometime\u201d* -> *\u201dsometimes\u201d*\n- Line 24: *\u201dstate-of-the-arts\u201d* -> *\u201dstate-of-the-art\u201d*\n- Line 25: *\u201d[\u2026] deploy Variational Autoencoder [\u2026]\u201d* -> *\u201d[\u2026] deploy the Variational Autoencoder [\u2026]\u201d* or *\u201d[\u2026] deploy Variational Autoencoders [\u2026]\u201d*\n- Line 37, line 190, line 221 : *\u201dOn contrary, [\u2026]\u201d* -> *\u201dOn the contrary, [\u2026]\u201d*\n- Line 74: *\u201d[\u2026] closely approximate prior [\u2026]\u201d* -> *\u201d[\u2026] closely approximate the prior [\u2026]\u201d*\n- Line 127: *\u201d[\u2026] models [\u2026]\u201d* -> *\u201d[\u2026] model [\u2026]\u201d*\n- Line 164: *\u201d[\u2026] decomposition L2 term [\u2026]\u201d* -> *\u201d[\u2026] decomposition, the L2 term [\u2026]\u201d*\n- Line 224: *\u201dSuch gap [\u2026]\u201d* -> *\u201dSuch a gap [\u2026]\u201d*\n- Line 225: *\u201d[\u2026] such case [\u2026]\u201d* -> *\u201d[\u2026] such a case [\u2026]\u201d*\n- Line 233: *\u201dDoes VAE ensemble improves [\u2026]\u201d* -> *\u201dDoes the VAE ensemble improve [\u2026]\u201d*\n\n### Recommendation:\nThis submission was an enjoyable read, it provides some new insights and I believe this paper can pose an important contribution in areas which are concerned with learning disentangled representations and VAE models. In my opinion, the claims of the paper are justified both theoretically and empirically. However, there are certain aspects and concerns outlined above which need to be addressed adequately to warrant a publication. At the moment, I am inclined to accept the paper, but I would like the authors to clarify the concerns and questions above.\n\n### Post-Rebuttal:\nI would like to thank the authors for the insightful rebuttal! The authors were able to address my concerns adequately and I believe that the revision improved the quality of the paper quite a bit. Therefore, I stand with my initial recommendation and due to the reasons stated above, I endorse accepting this paper. \n\n\n### References: \n- Rolinek et al., \u201cVariational autoencoders pursue pca directions (by accident)\u201d, CVPR 2019.\n- Duan et al., \u201cUnsupervised model selection for variational disentangled representation learning\u201d, ICLR 2019.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538123565, "tmdate": 1606915771862, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1228/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Review"}}}, {"id": "UG1NyLjA8Vc", "original": null, "number": 9, "cdate": 1606239916064, "ddate": null, "tcdate": 1606239916064, "tmdate": 1606240787791, "tddate": null, "forum": "HdX654Yn81", "replyto": "kQGjVmFksY5", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Joint training versus separate training of VAE ensemble", "comment": "We would like to follow up with the reviewer\u2019s question regarding the separate training versus joint training of the VAE ensemble. We are conducting experiments of separate training of the VAE ensemble for all settings, where each VAE model is first trained and then added to the VAE ensemble. While this effort is still ongoing, based on the current results, we see little difference between separate training and joint training except for ensemble size 2. Specifically, we have the following results for gamma = 1:\n\nFactorVAE metric:\n\n                               Models  |  Joint training  | Separate training\n                               VAE_E_2 | 0.711+/-0.106   | 0.788+/-0.039\n                               VAE_E_3 | 0.794+/-0.030  | 0.795+/-0.043\n                               VAE_E_4 | 0.833+/-0.037  | 0.825+/-0.040\n                               VAE_E_5 | 0.828+/-0.016  | 0.772+/-0.036\n\nDCI-D metric:     \n\n                               Models  |  Joint training  | Separate training   \n                               VAE_E_2 | 0.176+/-0.043  | 0.288+/-0.053\n                               VAE_E_3 | 0.214+/-0.064  | 0.239+/-0.014\n                               VAE_E_4 | 0.240+/-0.059  | 0.238+/-0.013\n                               VAE_E_5 | 0.242+/-0.032  | 0.258+/-0.084\n\nVAE ensemble with size 2 seems to benefit from separate training, but we did notice that the pertained VAE models in VAE ensemble size 2 can achieve good metrics by themselves. We believe the quality of the pre-trained VAE models play an important role since they do vary a lot in terms of the evaluation metrics. Further investigation and experiments are necessary to support our conjectures mentioned in then earlier response and to conclude the effect of separate training. We are continuing with this effort, and will update the paper when all the results are available as a dedicated section in the Appendix. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "phj4efZoleR", "original": null, "number": 10, "cdate": 1606240305613, "ddate": null, "tcdate": 1606240305613, "tmdate": 1606240318123, "tddate": null, "forum": "HdX654Yn81", "replyto": "dtZA3z8vOvr", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Further clarification on baseline models and visualization, and discussion on additional ablation results", "comment": "Regarding the baseline results, since we did not receive any feedback from the reviewer, we want to further clarify that the results on the baseline models are from re-running the model training and evaluation provided by the disentanglement_lib library (with different random seeds and model initializations). In fact, we compared our results with the pre-trained models published with the disentanlgement_lib and observe similar results (for example, the randomly chosen 10 pre-trained FactorVAE models in disentanglement_lib achieves 0.779+/-0.094 on the FactorVAE metric, versus 0.764+/-0.075 from our re-run results). We believe these results are consistent with each other. More importantly, we follow the same evaluation parameter setting for the proposed VAE ensemble as other SOTA models, thus are confident with the reported results. \n\nRegarding the visualization, it is commonly used as a qualitative measurement where the results are interpreted based on subjective judgement. Using the visualization results to evaluate models can be useful but does not tell the complete story. For example, as we show in Fig. 11, the visualization by TC-VAE shows obvious artifacts despite the high evaluation metrics. Such traversal artifacts can also been seen in other models. \n\nWe would like to highlight the added ablation results in Fig. 8(b) since last response with the reviewer. To support our discussion on the effect of the cross-model reconstruction, we estimated the DtO of the ablation models and the result is shown in Fig 8(b). For the models without the cross-model reconstruction, we see that the linear transformations among models indeed are close to trivial transformations (signed permutation). More importantly, we show that adding the cross-model reconstruction can further reduce the DtO of the linear transformations among the models in the ensemble. This result can support our intuitive justification that the cross-model objective encourages entangled models to align to disentangled models. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "iCQCSwahp0", "original": null, "number": 8, "cdate": 1606239717503, "ddate": null, "tcdate": 1606239717503, "tmdate": 1606239717503, "tddate": null, "forum": "HdX654Yn81", "replyto": "hqz4snc_J6x", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "The consistency of the models in the same ensemble", "comment": "One thing we would like to add to the rebuttal for the reviewer is regarding the comment on the consistency of the models in the same ensemble. The reviewer asked whether the results are consistent (\u201cpolarisation\u201d and FactorVAE scores) among the latent representations (i.e. not the first model) and how much the results agreed? We can answer this question by referring to results shown in Fig. 3 and Table 2. In Fig. 3, we show the \u201cpolarized regime\u201d estimation for individual models in the VAE ensemble with size 2 (left) and 3 (right), where \u2018Ensemble i\u2019 stands for the i-th model in the ensemble. We see that individual models do work in similar \u201cpolarized regime\u201d and this is also reflected in the consistent FactorVAE metric performance in Table 2. Specifically in Table 2, we estimate the metrics with each individual model in the ensemble and calculate the  standard deviation among them. This calculation is done with 10 different runs and the average of the standard deviation is reported. The small standard deviation suggests that the individual model in the ensemble do achieve similar performance. For FactorVAE metric, we also observe that as ensemble size increases, this consistency decreases. We believe it is due to the difficulty of balancing the within and between model losses. In addition, higher gamma value also lead to reduced consistency. We believe this is due to the reduced effect of cross-model reconstruction that enhances the semantic consistency of the latent representations."}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "yHpFuN6KgdN", "original": null, "number": 5, "cdate": 1605662379575, "ddate": null, "tcdate": 1605662379575, "tmdate": 1605718254576, "tddate": null, "forum": "HdX654Yn81", "replyto": "HdX654Yn81", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Collective response to reviewers ", "comment": "We appreciate all three reviewers for taking the time to carefully assessing our work and providing feedbacks!\n\nFollowing the reviewers\u2019 suggestions, we extensively extended our experiment to demonstrate the effectiveness of the proposed VAE ensemble. These include:\n1. we conduct additional experiments by comparing our method with more SOTA models (\u03b2-VAE, FactorVAE, TC-VAE and two versions of DIP-VAE) using two metrics (FactorVAE metric and DCI Disentanglement score); \n2. we add ablation study to understand the effect of the linear transformation loss and cross-model reconstruction loss;\n3. we add the discussion on computation complexity of proposed VAE ensemble. \n4. along with these new results, we added discussion on the effect of ensemble size of hyper-parameter gamma.\n\nThe paper is updated accordingly to reflect these changes. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "dtZA3z8vOvr", "original": null, "number": 7, "cdate": 1605663018198, "ddate": null, "tcdate": 1605663018198, "tmdate": 1605663018198, "tddate": null, "forum": "HdX654Yn81", "replyto": "IkYZyU1zin", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "Thank the reviewer for raising the concerns! Below we answer each question from the reviewer.\n\n\u2022\tAs the reviewer suggested, we used the open-source distentanglement_lib to conduct our study, including the baseline results on beta-VAE and FactorVAE. We added this important implement detail in Appendix D of the paper. Our baseline results are consistent with the recent large-scale experiment results in (Locatello et al., 2018) and (Duan et al. 2019). Notice that the disentanglement_lib is published with (Locatello et al., 2018). The discrepancy between these results and the ones reported in the original FactorVAE paper is due to the parameter setting for estimating the FactorVAE metric. It involves training a classifier on a training data and reporting the classifier performance on an evaluation dataset. The parameters during this process include the size of training and evaluation, the batch size of training the classifier, the number of data points to estimate the variance of each latent dimension and the threshold for pruning the latent variables. We report the results of all the experiments following the same parameter settings as the two studies mentioned above.\n\n\u2022\tThe representation by VAE ensemble encourages more \u201cactive\u201d latent variables, thus can capture a decomposition of the ground truth generative factors. Especially from the \u201cpolarized regime\u201d estimation in Figure 3, we observe that some latent variables in the VAE ensemble are in-between \u201cactive\u201d and \u201cpassive\u201d modes. This suggests that the VAE ensemble model generates input-dependent factors based on the input complexity. The traversals in Figure 11 (original Figure 8) shows that an ellipse shape does not lead to an \u201cactive\u201d latent variable.  However, both heart and square shape lead to an \u201cactive\u201d mode of the second latent variable that changes the output.  In contrast, existing SOTA approaches do not have such behavior where the \u201cactive\u201d modes are consistent across different input data. We believe a latent representation that preserve the compositional property at the core is what makes disentangled representations useful. This is verified with the quantitative comparison in Table 1 of the updated paper. \n\n\u2022\tOur intuitive justification on the cross-model objective is built on the theoretical discussion in Section 4.1  where we show that the linear transformations among models in the VAE ensemble tend to converge to a trivial transformation (signed permutation). This implies the linear transformations to be close to orthonormal transformation. To verify the effect of the cross-model reconstruction, as the reviewer suggested, we conducted the ablation study where we remove the cross-model reconstruction as well as the linear transformation separately. The results are updated in Figure 4 and 8 in the paper. Without the linear transformation loss, the performance of VAE ensemble decreases significantly across different ensemble sizes. Without the cross-model reconstruction loss, the performance of VAE ensemble also decreases but the gap becomes smaller as the hyperparmeter gamma increases. When gamma value is high, the behavior of the VAE ensemble matches the reviewer\u2019s conjecture that the linear transformation loss would force closer mapping between the encoders and reduce the cross-model reconstruction error of the decoders. However, the cross-model reconstruction is important when gamma is low, where the optimal performance of VAE ensemble is achieved.   \n\n\u2022\tThe reviewer raised a valid point on the increased computation complexity of the proposed ensemble model. Since AnonReviewer4 raised the same question (the first question). Due to response space limitation, we kindly ask the reviewer to refer to the response above. \n\n\u2022\tWe disagree with the reviewer\u2019s comment that betaVAE and FactorVAE are no longer state-of-the-art. The large-scale experiments in (Locatello et al., 2018) and (Duan et al. 2019) still show comparable performance by these two models comparing with the models mentioned by the reviewer. In order to demonstrate the effectiveness of the proposed VAE ensemble, as the reviewer suggested, we extend our experiments to include more SOTA models including TC-VAE and two versions of DIP-VAE.  We also use two widely used supervised metrics including FactorVAE metric and DCI Disentanglement scores (Eastwood & Williams, 2018) as the quantitative measurements. These metrics are shown to correlate with other common supervised metrics (Locatello et al., 2018).  For example, FactorVAE metric and \u03b2-VAE metric (Higgins et al., 2017) capture similar notions, while DCI Disentanglement and Mutual Information Gap (MIG) capture similar notions.  In addition, DCI Disentanglement is closely related to the unsupervised model selection method UDR (Duan et al. 2019). Figure 2, Table 1 and 2 and their corresponding discussions are updated in the \u201cExperiment\u201d section of the paper to reflect these changes.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "hqz4snc_J6x", "original": null, "number": 4, "cdate": 1605662136117, "ddate": null, "tcdate": 1605662136117, "tmdate": 1605662545402, "tddate": null, "forum": "HdX654Yn81", "replyto": "bO9wmlOyAF", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Response to AnonReviewer4", "comment": "We thank the reviewer for comments! Below we answer each question from the reviewer.\n\n\u2022\tThe reviewer raised a valid point on the increased computation complexity of the proposed ensemble model. Comparing to training n original VAEs, the proposed VAE ensemble requires additional n*(n-1) linear layers. While this addition does not increase the size of the model much, the linear transformations and the cross-model reconstruction components grow with n*(n-1), which may be computationally expensive especially when n is large. That being said, the results in Section 5 show that the VAE ensemble achieves more stable results comparing to the current state-of-the-art models. Also, its computation is highly parallelizable. This important discussion is added to the paper (line 146-153).\n\n\u2022\tThe results in Table 1 shows that when gamma = 1, the performance of VAE ensemble increases as the ensemble size increases, indicated by the higher mean and smaller variance of the metrics. However, when gamma value is high, the linear transformation loss would force closer mapping between the encoders and reduce the effect of the cross-model reconstruction error of the decoders. As discussed in Section 4.2, the cross-model reconstruction can provide important semantic alignment of the latent representations. We verify its effect by conducting the ablation study as shown in Figure 4. As a result, balancing the within and between model loss is important for achieving good performance and this can indeed pose a challenge on the optimization. However, this is an issue of all existing state-of-the-art models where it is a common practice to train a number of seeds per hyperparameter setting. \n\n\u2022\tThe representation by VAE ensemble encourages more \u201cactive\u201d latent variables, thus can capture a decomposition of the ground truth generative factors. In Figure 3, we observe that some latent variables in the VAE ensemble are in-between \u201cactive\u201d and \u201cpassive\u201d modes. This suggests that the VAE ensemble model generates input-dependent factors based on the input complexity. The traversals in Figure 11 (original Figure 8) shows that an ellipse shape does not lead to an \u201cactive\u201d latent variable.  However, both heart and square shape lead to an \u201cactive\u201d mode of the second latent variable that changes the output. Following the reviewer\u2019s suggestion, we included the latent traversal results from beta-VAE and FactorVAE, as well as other state-of-the-art models that are added to our evaluation. As shown in Figure 11, all these models do not have the decomposition behavior of VAE ensemble where the \u201cactive\u201d modes are consistent across different input data. \n\n\u2022\tWe agree with reviewer that estimating the DtO for beta-VAE and FactorVAE should be insightful. In Figure 2 of the updated paper, we show the comparison of the DtO between the VAE ensemble and other state-of-the-art VAE models. As seen in the figure, the VAE ensemble models with different ensemble size all approach to trivial transformations between the individual models, while other VAE models do not have such property. \n\n\u2022\tFollowing the reviewer\u2019s suggestion, we have updated Figure 1 with annotations on the bar plot to improve its readability. \n\n\u2022\tWe thank the reviewer for pointing out the grammar errors in the paper! We have corrected them accordingly.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}, {"id": "kQGjVmFksY5", "original": null, "number": 6, "cdate": 1605662513293, "ddate": null, "tcdate": 1605662513293, "tmdate": 1605662513293, "tddate": null, "forum": "HdX654Yn81", "replyto": "nRK0FwFceL9", "invitation": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "Thank the reviewer for comments! Below we answer each question from the reviewer.\n\n\u2022\tThe proposed VAE ensemble is trained end-to-end where all parameters of VAE i, VAE j, and M_ji are updated simultaneously. For analysis purpose, the discussion in Section 4.1 assume fixed parameter in order to study the stochastic loss of the VAE ensemble loss.\n\n\u2022\tThe reviewer raised an interesting question. We believe pertaining individual VAE should help with the VAE ensemble., if not hurting the performance. This is because the individual VAE model do have learn well disentangled representation based on the results in Table 1. Also, the DtO estimation between well-trained individual VAE models in Figure 6 (original Figure 2) shows that the latent representations among these models do not align with each other. There might be a chance for all models in the ensemble to converge to one of the pertained models. That being said, confirming this would require large experiment and we leave it for future work. \n\n\u2022\tThe VAE ensemble generates multiple VAE models where each individual VAE learns similar disentangled representation. To compare the information rate, one would compare the individual VAE in an ensemble with a single VAE. \n\n\u2022\tWe agree with the reviewer that the discussion on the effect of ensemble size and the gamma hyperparameter is important. To better understand these effects, we have conducted ablation study as well as conducted further experiments. The results in Table 1 shows that when gamma = 1, the performance of VAE ensemble increases as the ensemble size increases, indicated by the higher mean and smaller variance of the metrics. However, when gamma value is high, the linear transformation loss would force closer mapping between the encoders and reduce the effect of the cross-model reconstruction error of the decoders. As discussed in Section 4.2, the cross-model reconstruction can provide important semantic alignment of the latent representations. We verify its effect by conducting the ablation study as shown in Figure 4.\n\n\u2022\tWe extend our experiments to include more SOTA models including TC-VAE (Isolating sources of disentanglement in variational autoencoders. Chen et al., 2018) and two versions of DIP-VAE (Variational inference of disentangled latent concepts from unlabeled observations. Kumar et al., 2017).  We also use two widely used supervised metrics including FactorVAE metric and DCI Disentanglement scores (A framework for the quantitative evaluation of disentangled representations. Eastwood & Williams, 2018) as the quantitative measurements.   They are shown to correlate with other common supervised metrics (Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations. Locatello et al., 2018).  For example, FactorVAE metric and \u03b2-VAE metric (Higgins et al., 2017) capture similar notions, while DCI Disentanglement and Mutual Information Gap (MIG) capture similar notions.  In addition, DCI Disentanglement is closely related to the unsupervised model selection method UDR (Unsupervised model selection for variational disentangled representation learning. Duan et al. 2019). \n\n\u2022\tWe agree with the reviewer that the effect of the latent dimension is important. We extended the discussion on this point. Due to the space limitation, we chose to leave the detail discussion in the appendix but added short sentence in the main paper.\n\n\u2022\tWe have updated Figure 6.b (Original Figure 2.b) with log scale and achieves better visualization results. \n\n\u2022\tFor easy visualization, the latent damson in Figure 3 is sorted based on the \u2018polarized regime\u2019 estimation metric. \n\n\u2022\tTable 2 aims to demonstrate the alignment of the individual models in an ensemble in term of the metric. Given a VAE ensemble, we estimate the metric for each individual model and calculate their standard deviation. Since we test each VAE ensemble multiple runs, an average of these standard deviation is reported.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1228/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving the Unsupervised Disentangled Representation Learning with VAE Ensemble", "authorids": ["~Nanxiang_Li1", "~Shabnam_Ghaffarzadegan1", "~Liu_Ren1"], "authors": ["Nanxiang Li", "Shabnam Ghaffarzadegan", "Liu Ren"], "keywords": ["Unsupervised disentangled representation learning", "network ensemble", "variational auto encoder"], "abstract": "Variational Autoencoder (VAE) based frameworks have achieved the state-of-the-art performance on the unsupervised disentangled representation learning. A recent theoretical analysis shows that such success is mainly due to the VAE implementation choices that encourage a PCA-like behavior locally on data samples. Despite this implied model identifiability, the VAE based disentanglement frameworks still face the trade-off between the local orthogonality and data reconstruction. As a result, models with the same architecture and hyperparameter setting can sometime learn entangled representations. To address this challenge, we propose a simple yet effective VAE ensemble framework consisting of multiple VAEs. It is based on the assumption that entangled representations are unique in their own ways, and the disentangled representations are \"alike\" (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent representations. We show both theoretically and experimentally, the VAE ensemble objective encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be \"alike\". We compare our approach with the state-of-the-art unsupervised disentangled representation learning approaches and show the improved performance.", "one-sentence_summary": "We show both theoretically and experimentally that an ensemble of VAEs with linear transformations connecting their latent representations can improve the unsupervised disentangled representation learning. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|improving_the_unsupervised_disentangled_representation_learning_with_vae_ensemble", "supplementary_material": "/attachment/90fe09c02f145fe5d4e33f225be450b37bac32b3.zip", "pdf": "/pdf/e2af57bcebcd38ce7dd5c92af4f98fe633960ba7.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NOtq8OQI56", "_bibtex": "@misc{\nli2021improving,\ntitle={Improving the Unsupervised Disentangled Representation Learning with {\\{}VAE{\\}} Ensemble},\nauthor={Nanxiang Li and Shabnam Ghaffarzadegan and Liu Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=HdX654Yn81}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HdX654Yn81", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1228/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1228/Authors|ICLR.cc/2021/Conference/Paper1228/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1228/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923862135, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1228/-/Official_Comment"}}}], "count": 12}