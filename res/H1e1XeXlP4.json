{"notes": [{"id": "H1e1XeXlP4", "original": "SyeRGe7gv4", "number": 4, "cdate": 1552064535104, "ddate": null, "tcdate": 1552064535104, "tmdate": 1562082110227, "tddate": null, "forum": "H1e1XeXlP4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Reference-based Variational Autoencoders", "authors": ["Adri\u00e0 Ruiz", "Oriol Martinez", "Xavier Binefa", "Jakob Verbeek"], "authorids": ["adria.ruiz-ovejero@inria.fr", "oriol.martinez@upf.edu", "xavier.binefa@upf.edu", "jakob.verbeek@inria.fr"], "keywords": ["Disentangled representations", "Weakly-Supervised Learning", "Variational Autoencoders"], "abstract": "Learning disentangled representations from visual data, where different high-level generative factors are independently encoded, is of importance for many computer vision tasks. Solving this problem, however, typically requires to explicitly label all the  factors of interest in training images. To alleviate the annotation cost, we introduce a learning setting which we refer to as \\textit{reference-based disentangling}. Given a pool of unlabelled images, the goal is to learn a representation where a set of target factors are disentangled from others. The only supervision comes from an auxiliary \\textit{reference set} containing  images where the factors of interest are constant. To address this problem, we propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak-supervision provided by the reference set. By addressing tasks such as feature learning, conditional image generation or attribute transfer, we validate the ability of the proposed model to learn disentangled representations from this minimal form of supervision.\n", "pdf": "/pdf/21786eb8106f5d683ed10e732540b002c24a7a71.pdf", "paperhash": "ruiz|referencebased_variational_autoencoders"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "BkgNNh1dFE", "original": null, "number": 1, "cdate": 1554672684261, "ddate": null, "tcdate": 1554672684261, "tmdate": 1555512016358, "tddate": null, "forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Official_Review", "content": {"title": "Interesting paper but not well explained", "review": "The authors provides a training paradigm to leverage \"weak supervision\" signal via a reference set, which they demonstrate empirically to be effective in regularizing the target factors to encode certain features of interests. This line of work seems quite similar in nature to [1,2,3], who propose to regularize the shared features instead of enforcing them to be a constant. \n\n\nPros: \n`1. to address the over-regularization problem in traditional VI, the author proposed to use the symmetrized KL loss to encourage the model to make use of the target factor, which is shown to be effective by their experiment. \n2. the authors have demonstrated the effectiveness of using a reference set to disentangle target factors from common factors. (see point 2 of Cons)\n\nCons: \n1. the author proposed to use adversarial training to minimize the two KL divergences, but a justification of the necessity of this method is not provided. \n2. it is not clear how forcing the target factor of a reference set to be a constant among all data points within the set can help with disentanglement in general. It seems to me to be a heuristic that providing some sort of \"weak supervision\" will impose some structure in the space of target factor, but I'm not sure to what extent this is effective; e.g. whether certain features will be discarded by \"e\" and be encoded by \"z\", or the other way around. Also, have you tried to (1) vary the size of the reference set, e.g. making it smaller, or (2) using multiple reference targets, e.g. with more shared features. \n\nIn general, this is an interesting direction. But I'd like to see some intuitive explanation of how this specific regularization help with \"disentanglement\", which is claimed by the authors. \n\n\n[1] Unsupervised Learning of Disentangled and Interpretable Representations from Sequential Data\n[2] Inferring Identity Factors for Grouped Examples\n[3] Disentangled Sequential Autoencoder", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reference-based Variational Autoencoders", "authors": ["Adri\u00e0 Ruiz", "Oriol Martinez", "Xavier Binefa", "Jakob Verbeek"], "authorids": ["adria.ruiz-ovejero@inria.fr", "oriol.martinez@upf.edu", "xavier.binefa@upf.edu", "jakob.verbeek@inria.fr"], "keywords": ["Disentangled representations", "Weakly-Supervised Learning", "Variational Autoencoders"], "abstract": "Learning disentangled representations from visual data, where different high-level generative factors are independently encoded, is of importance for many computer vision tasks. Solving this problem, however, typically requires to explicitly label all the  factors of interest in training images. To alleviate the annotation cost, we introduce a learning setting which we refer to as \\textit{reference-based disentangling}. Given a pool of unlabelled images, the goal is to learn a representation where a set of target factors are disentangled from others. The only supervision comes from an auxiliary \\textit{reference set} containing  images where the factors of interest are constant. To address this problem, we propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak-supervision provided by the reference set. By addressing tasks such as feature learning, conditional image generation or attribute transfer, we validate the ability of the proposed model to learn disentangled representations from this minimal form of supervision.\n", "pdf": "/pdf/21786eb8106f5d683ed10e732540b002c24a7a71.pdf", "paperhash": "ruiz|referencebased_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Official_Review", "cdate": 1553713421780, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713421780, "tmdate": 1555511819597, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper4/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SJlO7o_dYE", "original": null, "number": 2, "cdate": 1554709280277, "ddate": null, "tcdate": 1554709280277, "tmdate": 1555511883826, "tddate": null, "forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Official_Review", "content": {"title": "Solid paper, with clear discussion and contributions", "review": "This paper succinctly describes a VAE based method driven by a \"reference set\" for factor discovery. \n\nI particularly appreciate the detailed experimental section, and extremely thorough comparisons with other architectures. The appendix is also a nice addition, though even the four page version stands on its own merit.\n\nThe work itself is quite clear, and the results speak for themselves. They also raise a number of follow-on questions, maybe the authors have explored these in other experiments - none of these are required to be answered, but the author's insights may be useful for other readers of the work (as well as myself).\n\nThe selection of the reference set seems important - is it critical that the the factors of interest be constant across every example? How much \"noise\" in this selection is tolerable? Does choosing different subsets which both hold the variable constant, result in different factors discovered? How does the size of the reference set impact the result generally, is there some threshold below which the method performs far worse?\nAre there any suggestions for (perhaps) automated discovery of these constant subsets, or ways to bootstrap this labeling via weak learners and pruning? \n\nThe primary things that would improve this paper's rating for me are larger scale experiments, or perhaps non-image data. The model, its baselines, the datasets used, and the experiments completed are all thoroughly spelled out in this paper. Will the authors also release code at some point? \n\nOne other paper of interest may be GLSR-VAE (https://arxiv.org/abs/1707.04588) - though not directly comparable to this work, the use of a simple \"reward\" / label to drive factorization of the latent space seems similar in some ways to the requirement of the reference set to contain the factor of interest.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reference-based Variational Autoencoders", "authors": ["Adri\u00e0 Ruiz", "Oriol Martinez", "Xavier Binefa", "Jakob Verbeek"], "authorids": ["adria.ruiz-ovejero@inria.fr", "oriol.martinez@upf.edu", "xavier.binefa@upf.edu", "jakob.verbeek@inria.fr"], "keywords": ["Disentangled representations", "Weakly-Supervised Learning", "Variational Autoencoders"], "abstract": "Learning disentangled representations from visual data, where different high-level generative factors are independently encoded, is of importance for many computer vision tasks. Solving this problem, however, typically requires to explicitly label all the  factors of interest in training images. To alleviate the annotation cost, we introduce a learning setting which we refer to as \\textit{reference-based disentangling}. Given a pool of unlabelled images, the goal is to learn a representation where a set of target factors are disentangled from others. The only supervision comes from an auxiliary \\textit{reference set} containing  images where the factors of interest are constant. To address this problem, we propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak-supervision provided by the reference set. By addressing tasks such as feature learning, conditional image generation or attribute transfer, we validate the ability of the proposed model to learn disentangled representations from this minimal form of supervision.\n", "pdf": "/pdf/21786eb8106f5d683ed10e732540b002c24a7a71.pdf", "paperhash": "ruiz|referencebased_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Official_Review", "cdate": 1553713421780, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper4/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713421780, "tmdate": 1555511819597, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper4/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rklhyb4Ft4", "original": null, "number": 1, "cdate": 1554755812390, "ddate": null, "tcdate": 1554755812390, "tmdate": 1555510985118, "tddate": null, "forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reference-based Variational Autoencoders", "authors": ["Adri\u00e0 Ruiz", "Oriol Martinez", "Xavier Binefa", "Jakob Verbeek"], "authorids": ["adria.ruiz-ovejero@inria.fr", "oriol.martinez@upf.edu", "xavier.binefa@upf.edu", "jakob.verbeek@inria.fr"], "keywords": ["Disentangled representations", "Weakly-Supervised Learning", "Variational Autoencoders"], "abstract": "Learning disentangled representations from visual data, where different high-level generative factors are independently encoded, is of importance for many computer vision tasks. Solving this problem, however, typically requires to explicitly label all the  factors of interest in training images. To alleviate the annotation cost, we introduce a learning setting which we refer to as \\textit{reference-based disentangling}. Given a pool of unlabelled images, the goal is to learn a representation where a set of target factors are disentangled from others. The only supervision comes from an auxiliary \\textit{reference set} containing  images where the factors of interest are constant. To address this problem, we propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak-supervision provided by the reference set. By addressing tasks such as feature learning, conditional image generation or attribute transfer, we validate the ability of the proposed model to learn disentangled representations from this minimal form of supervision.\n", "pdf": "/pdf/21786eb8106f5d683ed10e732540b002c24a7a71.pdf", "paperhash": "ruiz|referencebased_variational_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper4/Decision", "cdate": 1554736070768, "reply": {"forum": "H1e1XeXlP4", "replyto": "H1e1XeXlP4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736070768, "tmdate": 1555510967987, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}