{"notes": [{"id": "HyeCnkHtwH", "original": "HkxXhM1tDH", "number": 1971, "cdate": 1569439669919, "ddate": null, "tcdate": 1569439669919, "tmdate": 1577168218773, "tddate": null, "forum": "HyeCnkHtwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "sB_v08TlTO", "original": null, "number": 1, "cdate": 1576798737204, "ddate": null, "tcdate": 1576798737204, "tmdate": 1576800899167, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Decision", "content": {"decision": "Reject", "comment": "This paper develops ideas for enabling the data generation with GANs in the presence of structured constraints on the data manifold. This problem is interesting and quite relevant to the ICLR community. The reviewers raised concerns about the similarity to prior work (Xu et al '17), and missing comparisons to previous approaches that study this problem (e.g. Hu et al '18) that make it difficult to judge the significance of the work. Overall, the paper is slightly below the bar for acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795720150, "tmdate": 1576800270926, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Decision"}}}, {"id": "BJgmAroiFB", "original": null, "number": 1, "cdate": 1571694027294, "ddate": null, "tcdate": 1571694027294, "tmdate": 1574291027009, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "In this paper the authors present a Generative Adversarial Neural Networks with Xu et al.\u2019s semantic loss applied to the generator. They call this GAN a Constrained Adversarial Network or (CAN) and identify it as a new class of GAN. The authors present three different problem domains for their experiments focused on the generation of constrained images, chunks of Super Mario Bros.-style levels, and molecules. For each domain they include particular constraints for the semantic loss, which biases the generator towards creating valid content according to these constraints. \n\nThe paper at present has a number of issues holding it back. First, I am not convinced by the author\u2019s claims that the application of an existing loss function to the generator is sufficient to identify a new class of GAN. Second, there is a lack of technical detail in the experiments necessary to replicate them. Third, there is a lack of discussion of the experimental results to place them in context for readers. Finally following from the earlier points, there seems to be a lack of technical contributions in the paper. \n\nI certainly agree with the authors about the inability of GANs to learn structural constraints with insufficient training data, as this has been demonstrated in many examples of prior work. I also agree that particular problem domains, as identified by the authors, have stronger structural requirements. However, it is unclear to me why in these instances one would use GANs and not some alternative approach such as constraint-based solvers. Or even if one wanted to employ GANs, what the benefit of adapting the constraints into a loss function is compared to say constraining generated output in a post-hoc process.\n\nThe descriptions of the two of the three experiments do not include any discussion of the GAN architectures or hyperparameters. While this is not strictly necessary in the paper text some discussion in an appendix or a citation to a prior application of the architecture(s) would be appropriate. Without this, it is impossible for future researchers to replicate these results. Further, it is difficult for readers to place the results in context. For individual experiments, such as the Super Mario Bros. experiment, it is unclear why certain choices were made. For example, why train a GAN on just level 1-3 or 3-3, and not train a single model on multiple levels as is common in the field of procedural content generation via machine learning. \n\nThere is a lack of discussion in the paper on the results of each experiment. For example, the output of the GANs for all the experiments seems quite low, and the differences in terms of the results between the GAN and the CAN across the experiments do not seem to be substantial. Some discussion to put this into context for readers would be helpful.\n\nAs far as I can understand the primary technical contributions of the paper are: (1) the application of Xu et al.\u2019s semantic loss to GANS, (2) the constraints developed for the three experiments, and (3) the results of the three experiments. I am unconvinced of the utility of these contributions to a general machine learning audience.\n\n---\n\nUpdated my review as the authors included extra detail regarding the experiments in a new draft, which helped with the reproducibility issue. However, I am still unconvinced in the contributions of the paper outside of what I previously listed. While I am also unfamiliar with any prior example demonstrating that GANs produce invalid structure, this is not a surprising result. Especially as validity can be defined in an arbitrary, domain-specific manner.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574963019512, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Reviewers"], "noninvitees": [], "tcdate": 1570237729637, "tmdate": 1574963019525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review"}}}, {"id": "r1xvGsaZsr", "original": null, "number": 3, "cdate": 1573145359469, "ddate": null, "tcdate": 1573145359469, "tmdate": 1573145359469, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "SygPGB_3YB", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment", "content": {"title": "Answer to Reviewer #1", "comment": "Thank you for your detailed review.\n\n\nClarity: We are happy to rewrite any parts of the paper that may be unclear.\n\nEq. 3: Theta is the distribution output by the stochastic generator, as explained at the end of the section on GANs.  We will make it more clear.\n\n\nNo details on knowledge compilation: All of the relevant details can be found in Xu et al.  We will update the short introduction to KC in the methods section to be more self-contained.\n\nIs KC used in the experiments? All constraints used in the experiments required us to apply KC.  We compiled the constraints into SDDs using the pysdd library.\n\nSome constraints result in extremely large circuits that cannot fit in memory. We show how to deal with these overly complex constraints  by using simpler constraints on a projected space. We remark that this is not exclusive of our approach but, to the best of the authors\u2019 knowledge, this is the first work that applies these ideas to effectively approximate the exact SL. We mentioned in  Sections 1,3 that this approach is used in the level generation task to approximate with a propositional formula the reachability (cf. pages 5-6). Although showcased in the level generation setting only, the approach is general. We will clarify these aspects in the revised version.\n\n\nReproducibility: Reproducibility is crucial for us. We will shortly share an archive with the anonymized version of the code with the reviewers.  We will also add a link to the code to the paper, as well as details on the architectures and hyperparameters in an Appendix.  An updated manuscript will be uploaded soon.\n\n\nSignificance: The focus of the molecules generation experiment is not on comparing the SL with other forms of supervision nor on comparing every existing approach in molecule generation, but rather on showing how the SL can be used in conjunction with reinforcement-based approaches (as used in MolGAN, ORGANs, etc.) to mitigate the mode collapse and foster diversity.  This is achieved by applying different constraints on different subregions of the latent space.\n\nOur experiments show that the SL improves the quality of the generated structures when combined with constrained baselines.\n\nNotice that in some cases the baseline already generates mostly valid structures, as in the molecule generation experiment.  In this case, there is little gain in trying to improve the validity further.  For this reason, we use the SL to improve the other quality measures.  The results show that indeed the SL improves uniqueness and diversity, see Table 2.\n\n\nBaselines: Thank you for the additional references.\n\n\nTechnical contributions: We stress that our contribution does not equate to combining GANs and the SL.  Our contributions are as follows:\n\nWe prove that GANs by design allocate non-zero mass to invalid structures whenever the dataset is noisy.\n\nWe fix this issue by pairing the generator with the SL and showing that the resulting architecture provably produces valid structures only (in the limit of $\\lambda \\to \\infty$). Compared to alternative architectures, the resulting model enjoys exact probabilistic semantics and can natively handle any arbitrary discrete constraint without special-purpose architectural modifications.\n\nWe show that the SL can be successfully supplemented with a neural component in practice when the constraints are beyond the reach of model counting technology.\n\nWe show that constraints can be turned on and off at test time despite being \"baked\" into the generator at training time.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyeCnkHtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1971/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1971/Authors|ICLR.cc/2020/Conference/Paper1971/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148204, "tmdate": 1576860559628, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment"}}}, {"id": "Hyx9h93-oH", "original": null, "number": 2, "cdate": 1573141170088, "ddate": null, "tcdate": 1573141170088, "tmdate": 1573141170088, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "BJgmAroiFB", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment", "content": {"title": "Reply to Reviewer #3", "comment": "Thank you for your careful review.\n\n\nNaming: We only coined the term CAN for recognizability.  We are open to changing the\nname of our approach, if necessary.\n\n\nMissing technical details and discussion: We will provide any missing material directly in an updated version of the manuscript very soon.\n\n\nTechnical contributions: Our paper does not equate to GAN + SL. Our technical contributions are:\n\nShowing that GANs by design allocate non-zero mass to invalid structures  whenever the dataset is noisy.\n\nFixing this issue by pairing the generator with the SL and showing that the resulting architecture provably produces valid structures only (in the limit of $\\lambda \\to \\infty$). Compared to alternative architectures, the resulting model enjoys exact probabilistic semantics and can natively handle any arbitrary discrete constraint without special-purpose architectural modifications.\n\nWe show that the SL can be successfully supplemented with a neural component in practice when the constraints are beyond the reach of model counting technology.\n\nWe show that constraints can be turned on and off at test time despite being \"baked\" into the generator at training time.\n\nUsing alternatives like constraint solvers: State-of-the-art approaches to discrete (weighted) sampling under constraints are either solver-based [a,b] or knowledge-compilation-based [c].  Approaches in the first group are approximate and rely on invoking a (usually NP-hard) oracle.  Also, these approaches tackle sampling, not learning.  Approaches in the second group, like PSDDs [c], make use of the same knowledge compilation techniques that underlie the Semantic Loss.  If the constraints are very complex, KC may output very large circuits (polynomials) that in turn seriously affect inference runtime and space requirements.  CANs on the other end only need the circuit during training (which can be handled on larger machines and is only performed once).  Further, the complexity of inference in CANs does not depend on the complexity of the constraints, while in PSDDs it does.  Finally, PSDDs can be learned from data, but just like GANs, they cannot acquire and apply constraints from a handful of potentially noisy examples.\n\n[a] Chakraborty et al. \u201cDistribution-Aware Sampling and Weighted Model Counting for SAT\u201d, 2014.\n[b] Ermon et al. \u201cEmbed and Project:Discrete Sampling with Universal Hashing\u201d, 2013.\n[c] Kisa et al. \u201cProbabilistic sentential decision diagrams\u201d, 2014.\n\nWe will make sure to discuss discrete sampling technology more in detail in the related work.\n\n\nCESAGAN: The main differences with CANs are as follows:\n\n(1) It is unclear if CESAGANs (and specifically count vectors plus an embedding layer) can be extended to deal with arbitrary logical constraints, like CANs do.\n\n(2) In CESAGANS, the count vector is given as input to the discriminator, not directly to the generator, which introduces one layer of indirection;  in CANs this is not necessary.\n\n(3) The relationship between the count vector and the decision of the discriminator must be learned, which is non-trival without extra supervision and, again, more indirect than imposing the SL loss term in CANs. \n\n(4) As in MarioGANs, the supervision on the playability is given by an A* agent, resulting in a much computationally expensive training.  In our experiments the agent is only used for performance evaluation.\n\n(5) CESAGANs focus on level generation and were not tested on other generative tasks, while we applied CANs to multiple applications.\n\nAn empirical comparison could be interesting, but [d] is not peer-reviewed and the code is not available.\n\nFinally, the pre-print [d] was uploaded to ArXiV after the ICLR \u201820 deadline.\n\n[d] https://arxiv.org/abs/1910.01603\n\n\nMissing details and missing discussion: Thank you for pointing out this deficiency of our paper.  We will upload an updated version soon.\n\n\nTraining on a single level: We can definitely use more than one level during the training. In order to compare with MarioGAN, we trained the generation on a single level. In the MarioGAN paper, the authors use 1-1.  We choose 1-3 and 3-3 as they are more challenging with respect to the playability. This was mentioned in the caption of Table 1; we will make sure to make this more prominent.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyeCnkHtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1971/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1971/Authors|ICLR.cc/2020/Conference/Paper1971/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148204, "tmdate": 1576860559628, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment"}}}, {"id": "SJgSmV5bsr", "original": null, "number": 1, "cdate": 1573131292792, "ddate": null, "tcdate": 1573131292792, "tmdate": 1573131292792, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "rkeHQhM3Kr", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment", "content": {"title": "Replies to Reviewer #2", "comment": "Thank you for your thoughtful review.\n\n\nIncrementality wrt [1]: Our contributions go beyond applying the SL to GANs:\n\nWe show that GANs by design generate invalid structures if the data is noisy.  To the best of our knowledge, previous papers on deep generative models for structured outputs do not look into this at all.\n\nCANs generalize beyond existing ad-hoc architectures, as thanks to the SL they can natively handle any arbitrary discrete constraint.\n\nWe discuss one case where the SL *cannot* be used as-is (i.e., for the level-wide reachability constraint in the mario experiment) and show that in practice it is possible to replace parts of the SL using a neural network.\n\nWe show that the constraints, although \"baked\" into the generator at training time, can be turned on and off using an InfoGAN-like approach (cf. the molecules generation experiment). This technique can also be used to sample valid objects from different modes, thus also mitigating mode collapse.\n\nWe agree that these contributions were not made clear enough, and we will definitely amend the paper to this effect.\n\n\nComparison with [2]: We had initially considered using posterior regularization for CANs, but a major issue it is that rewriting the constraint (e.g. applying De Morgan) is not guaranteed to preserve the semantics and thus may change the loss function.  This issue does not affect the SL.  Moreover, since the SL can be evaluated efficiently in the GAN case, we have no need to fit a variational distribution $q$.  We agree that an empirical comparison with [2] is in order, however their code is not publicly available.\n\n\nPlease expect an updated manuscript shortly."}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyeCnkHtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1971/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1971/Authors|ICLR.cc/2020/Conference/Paper1971/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148204, "tmdate": 1576860559628, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Authors", "ICLR.cc/2020/Conference/Paper1971/Reviewers", "ICLR.cc/2020/Conference/Paper1971/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Comment"}}}, {"id": "rkeHQhM3Kr", "original": null, "number": 2, "cdate": 1571724317113, "ddate": null, "tcdate": 1571724317113, "tmdate": 1572972399955, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposed Constrained Adversarial Networks (CAN), which incorporates structural constraints by augmenting a penalty term in the training object. The penalty term is formulated as the semantic loss proposed in [1] which can handle any logical constraints. Experiments are demonstrated to show the advantage of CAN over standard GAN in terms of whether the generated samples satisfy the hard constraints, and whether they are novel and unique.\n\nFirst, I'd like to thank the authors for making this paper easy to follow. I like the idea of encouraging constraints for generative models, which is useful and interesting. However, given the published paper [1], this work seems to be a bit incremental.\n\nThe semantic loss for incorporating constraints and the knowledge compilation techniques for efficient evaluation are both introduced and discussed in [1]. The novelty of this paper is to apply these techniques to generative models, which seem to be a bit straightforward. A similar idea is proposed in [2], where the authors also discussed logical constraints and generative models, but they call the augmented penalty as 'posterior regularization'. I will be interested in a comparison to their method in terms of both methodology level and experiment level.\n\nOverall the contribution of this paper does not seem to be strong enough. I would personally vote for weak rejection.\n\n[1] Xu, Jingyi, et al. \"A semantic loss function for deep learning with symbolic knowledge.\" arXiv preprint arXiv:1711.11157 (2017).\n[2] Hu, Zhiting, et al. \"Deep generative models with learnable knowledge constraints.\" Advances in Neural Information Processing Systems. 2018."}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574963019512, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Reviewers"], "noninvitees": [], "tcdate": 1570237729637, "tmdate": 1574963019525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review"}}}, {"id": "SygPGB_3YB", "original": null, "number": 3, "cdate": 1571747087438, "ddate": null, "tcdate": 1571747087438, "tmdate": 1572972399920, "tddate": null, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "invitation": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors describe a method to improve the performance of generative adversarial networks in the task of generating structured objectives that have to satisfy complicated constraints. The proposed solution involves using an additional term in the GAN objective that penalizes the generation of invalid samples. This term, called the semantic loss, is given by a multiple of the log probability of the model generating valid samples.\n\nClarity:\n\nThe paper is not very well written and several parts need to be clarified. In particular, in equation 3. What is theta in this equation?  how is it obtained? The authors mention briefly how their method could be used to deal with intractable constraints, but they're almost no specific details or examples of how this is done in practice. The proposed approach relays on the knowledge compilation method, but they're very few details of it in the document. Is it used at all in the experiments?\n\nI am concern about the lack of reproducibility of the paper. I believe, from the paper as it is, it will be impossible to reproduce the results. There are no details about public code release, hyper-parameters settings, etc. For example,\nin section 4.3 the authors mention that they condition the constraint on 5 latent dimensions without giving details about which dimensions exactly.\n\nSignificance:\n\nIt is hard to quantify the significance of the contribution. The constrained images problem is very toy and simple and the experiments with molecules do not include any baseline (only the GAN model without the constraint). There have been\nmany recent contributions improving the validity of generative models for molecules and the authors do not compare with any of them.\n\nThe authors also fail to cite relevant work such as\n\nJaques, Natasha, et al. \"Sequence tutor: Conservative fine-tuning of sequence\ngeneration models with kl-control.\" Proceedings of the 34th International\nConference on Machine Learning-Volume 70. JMLR. org, 2017.\n\nSeff, Ari, et al. \"Discrete Object Generation with Reversible Inductive\nConstruction.\" arXiv preprint arXiv:1907.08268 (2019).\n\nNovelty:\n\nThe proposed approach is rather incremental and lacks novelty. It consists in just applying the semantic loss approach of Xu et al. 2018 to GAN training, with very limited new methodological or algorithm contributions.\n\nQuality:\n\nThe experiments performed are not strong enough to validate the proposed method. The authors do not consider strong baselines in their evaluations.\n\nSummary:\n\nI find that the problem addressed by the authors is highly relevant and the proposed approach has the potential to be useful in practice. However, the paper needs to be improved regarding its clarity, reproducibility and strength of experiments before it can be accepted for publication."}, "signatures": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1971/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jacopo.gobbi@studenti.unitn.it", "luca.diliello@studenti.unitn.it", "pierfrancesco.ardino@unitn.it", "paolo.morettin@unitn.it", "stefano.teso@gmail.com", "andrea.passerini@unitn.it"], "title": "Efficient generation of structured objects with Constrained Adversarial Networks", "authors": ["Jacopo Gobbi", "Luca Di Liello", "Pierfrancesco Ardino", "Paolo Morettin", "Stefano Teso", "Andrea Passerini"], "pdf": "/pdf/6a978a04ae03e3514cc130e7166ccdab8126a182.pdf", "TL;DR": "We extend GANs towards the generation of structured objects like molecules and video game levels", "abstract": "Despite their success, generative adversarial networks (GANs) cannot easily generate structured objects like molecules or game maps. The issue is that such objects must satisfy structural requirements (e.g., molecules must be chemically valid, game maps must guarantee reachability of the end goal) that are difficult to capture with examples alone.  As a remedy, we     propose constrained adversarial networks (CANs), which embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures. As in unconstrained GANs, new objects can be sampled straightforwardly from the generator, but in addition they satisfy the constraints with high probability.  Our approach handles arbitrary logical constraints and leverages knowledge compilation techniques to efficiently evaluate the expected disagreement between the     model and the constraints.  This setup is further extended to hybrid logical-neural constraints for capturing complex requirements like graph reachability.  An extensive empirical analysis on constrained images, molecules, and video game levels shows that CANs efficiently generate valid structures that are both high-quality and novel.", "keywords": ["deep generative models", "generative adversarial networks", "constraints"], "paperhash": "gobbi|efficient_generation_of_structured_objects_with_constrained_adversarial_networks", "original_pdf": "/attachment/b77b2a11d6cd83c332ca3ef82924914963328256.pdf", "_bibtex": "@misc{\ngobbi2020efficient,\ntitle={Efficient generation of structured objects with Constrained Adversarial Networks},\nauthor={Jacopo Gobbi and Luca Di Liello and Pierfrancesco Ardino and Paolo Morettin and Stefano Teso and Andrea Passerini},\nyear={2020},\nurl={https://openreview.net/forum?id=HyeCnkHtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyeCnkHtwH", "replyto": "HyeCnkHtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1971/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574963019512, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1971/Reviewers"], "noninvitees": [], "tcdate": 1570237729637, "tmdate": 1574963019525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1971/-/Official_Review"}}}], "count": 8}