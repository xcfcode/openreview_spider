{"notes": [{"id": "XZzriKGEj0_", "original": "USLdMRVPDN", "number": 1064, "cdate": 1601308119774, "ddate": null, "tcdate": 1601308119774, "tmdate": 1614985700952, "tddate": null, "forum": "XZzriKGEj0_", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "2Vipgll91PO", "original": null, "number": 1, "cdate": 1610040444369, "ddate": null, "tcdate": 1610040444369, "tmdate": 1610474045785, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper is very pleasant to read. The reviewers also like the key idea discussed and find the targeted application interesting and practical. However, after reading the indeed interesting motivation, all four reviewers expected to see more from the evaluation section, including more challenging and realistic set-ups and clearer gains over standard methods. The reviewers also discuss how both the navigation problem as well as the GP constraint problem have been tackled in the past, often in combination (e.g. reference [1] by R1). Therefore, it would be needed to see additional experimental evaluation in line with those previous works."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040444354, "tmdate": 1610474045770, "id": "ICLR.cc/2021/Conference/Paper1064/-/Decision"}}}, {"id": "S1zuJcxOC_M", "original": null, "number": 2, "cdate": 1603832598324, "ddate": null, "tcdate": 1603832598324, "tmdate": 1606760131175, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review", "content": {"title": "Incorporating negative constraints into Gaussian process regression", "review": "Summary:\nThis paper incorporates information of obstacles to avoid (e.g robot navigation trajectory in the room where the robot has to avoid items such as furniture) into Gaussian process regression fit. They call the obstacles, negative datapairs and the rest of data, positive datapairs. The aim is to have a GP where the probability of passing through the negative datapairs is low. The proposed method is called the Gaussian process with negative constraints (GP-NC). \n\nTo be able to fit the GP regression to positive datapairs and avoid negative datapairs, they maximize the KL-divergence between the distributions of GP learned from positive datpairs $(p(y|\\theta. X))$ and negative datapiars $(q(\\hat{y}|\\hat{X}))$ which will have a bound between $[0, \\inf]$.\nFor being able to maximize the KL-divergence with the marginal log-likelihood they change the scale of KL-divergence to the log scale and a parameter $\\lambda$. $\\lambda$ is a tradeoff between curve fitting and avoidance of the negative datapoints. KL term has an analytical solution since both distributions are Gaussians.\nThey compare their method against SVGP (Hensman et al., 2013) and PPGPR (Jankowiak et al., 2019) and the exact GP.\n\nComments and questions: \nThe paper is well-written and easy to follow. This paper is also technically sound and to the best of my knowledge is novel and relevant to the community.\n\nIn figure two you have mentioned you sampled the inducing inputs randomly from the whole range of training inputs. Did you choose the same inducing inputs for the SVGP and SVGP-NC? \n\nIn the error calculation, standardized mean squared error (SMSE) could be a better choice than RMSR since the former incorporates variance information as well.\n\nIn the experiment section, all negative datapairs are synthetically made. I was wondering if you could apply your method to a dataset with real negative datapiars (like a robot in the room avoiding obstacles)? \n\nIn figure 3 (3DRoad) the approximate results are better than the exact GP. Is this because of the scale of the data and not being able to converge?\n\nMiscellaneous comments:\nIn Table 1 row 2 should be wine quality - white\n\n################### After the rebuttal ################\n\nI thank the authors for addressing the issues that were raised. The paper is indeed addressing a very practical issue in the ML community.\nAfter reading other reviewers' comments and concerns I decreased my score. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538127942, "tmdate": 1606915785005, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1064/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review"}}}, {"id": "zb8mYTUEKvr", "original": null, "number": 4, "cdate": 1603886347319, "ddate": null, "tcdate": 1603886347319, "tmdate": 1606739232268, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review", "content": {"title": "Novel approach, but not a new problem in GP regression.", "review": "Summary\n--------\nThe paper addresses Gaussian process regression (GPR) over 'positive' and 'negative' data points, such that the regression model fit the former and avoid the latter. The 'negative' data points in this work are each represented by individually distributed Gaussian random variables, with known parameters (mean vector and variance).\nThe authors propose a novel GPR loss (6) for optimizing GP model parameters $\\theta$, striking a compromise between the regular GP loss and the KL divergence between the predictive GP distribution and the set of 'negative' data points. The approach is novel and an interesting take on the problem, and it has several beneficial properties which are investigated empirically.\n\nStrong points\n-------------\n1. Compared to previous work on GPR with 'positive' and 'negative' data points, the proposed solution is elegant in its simplicity, and scalable for predictions (since the 'negative' data is only used during kernel parameter optimization). I especially like the scalability aspect, since it would allow the use of a otherwise prohibitively large amount of 'negative' examples. This is useful in navigation, for example in contextes where the boundaries of static obstacles are commonly represented by potential fields.\n2. The experiments are fairly extensive and demonstrate several beneficial properties of the proposed method, such as fast learning convergence and compatibility with sparse GP methods.\n\nWeak points\n-------------\n1. The problem of GPR with both 'positive' and 'negative' data points (and in the context of robot navigation) has been investigated before [1], where a non-stationary kernel function is proposed. The approach in [1] should be addressed, and compared with, at least qualitatively.\n2. The experiments are not representing any situation where the distinction of 'positive' and 'negative' data points naturally occur. This makes it hard to assess how well the proposed method works for real problems of the kind the paper intends to address.\n3. The technical clarity is varied:\n     1. Equation (5) is incorrect? The two multivariate Gaussian distributions have different dimension (n vs m), and they do not share the same support ($X$ and $\\bar X$ can differ). Maybe it should be \"$p(y|\\theta, \\bar X)$\". But is this then entirely compatible with the prior sentence: $\\theta$ is in essence the \"GP regression model learned from the positive data pairs\" and yet it is stated that you maximize KL divergence between the GP regression model and the positive data pairs with respect to $\\theta$? If $\\theta$ is changed, then the first distribution in the KL divergence is no longer the GP model learned from the positive data points. I suggest that this section is made clearer and more precise. Equation (6) on the other hand corresponds to the stated proposal.\n   2. It is not obvious to me how you make use of the re-parameterization trick proposed by (Kingma & Welling, 2013).\n   3. Why do you not minimize the loss (6) directly, instead of first minimizing NLL and then maximizing KL at each iteration (Algorithm 1)?\n   4. What value does $\\lambda$ and $\\sigma_{neg}$ have in the experiments?\n4. The 'Random shuffling technique' is not at all clear to me. \n   1. How can you get a set of *valid* data pairs (i.e. $x_i$ and $y_i$) by shuffling the labels (\"$y_i$\")? \n   2. If randomly create pseudo-negative data points, especially using existing data points (that are either designated 'negative' or shuffled in some way to produce new input-output pairs as 'negative'), then isn't it likely given real data sets that these data points will be in conflict (e.g. overlap) with other 'positive' data points? If so, what do you mean with that these are *valid* and what does this mean for the experiment (more details on the limitations of the experiment and interpretations of the results should be present in the paper)?\n\nReason for score\n----------------\nAlthough an interesting take on the problem, the paper in its current form is lacking technical clarity, comparisons to directly related works, and the evaluation is weak in that it does not consider actual instances of the addressed problem in the empirical evaluation.\n\nMinor comments\n--------------\n\"to model the uncertainty by providing the predictive variance\" -> \"to model [target] uncertainty by providing predictive variance\"\n\n\"in both the positive and negative data pair.\" -> \"in both the positive and negative data pair set.\"\n\nPage 4: \"$P(y|\\theta, X)$\" -> \"$p(y|\\theta, X)$\"\n\n\"loglikelihood\" -> \"log likelihood\"\n\n--------------\n\n[1] S. Choi, E. Kim, K. Lee and S. Oh, \"Leveraged non-stationary Gaussian process regression for autonomous robot navigation,\" 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, WA, 2015, pp. 473-478, doi: 10.1109/ICRA.2015.7139222.\n\nEdit: Markdown problem with nested lists\n\nEdit: Upgraded rating from 4 to 5\n\n-----\nThank you for addressing most of my concerns.\n\nI have increased my rating, but the paper still needs some work in my opinion. More specifically,\n* a more thorough comparison with [1], e.g. by including the quantitative comparison you were working on.\n* an improved representative experiment from the problem domain. The newly added one is a bit simplistic and not motivated enough. Although stated to be 2D, it is (as far as I can tell) indistinguishable from a 1D regression task? How do you handle the 2D output in GPR? How are the data points generated that are used as training data, and what could motivate such a generation of data in a plausibly real setting?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538127942, "tmdate": 1606915785005, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1064/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review"}}}, {"id": "FqQrALQKeJG", "original": null, "number": 1, "cdate": 1603561842864, "ddate": null, "tcdate": 1603561842864, "tmdate": 1606572204894, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review", "content": {"title": "Not sufficiently motivated", "review": "SUMMARY \n\nThis paper introduces GP-NC, a new methodology that allows Gaussian processes to stay far from certain data points (referred to as negative datapairs). These negative datapairs complement the standard training points to be fitted. The authors show enhanced performance when using this technique with standard GPs, SVGP and PPGPR.\n\n###################################################\n\nPROS\n\n1) I am not aware of previous works in the GP literature dealing with this scenario, i.e. data pairs to be avoided during training.\n\n####################################################\n\nCONS\n\n1) I think this work is not sufficiently motivated. The authors claim that the brand-new negative datapairs can be useful for modelling navigation problems with GPs. However, this type of problem is not addressed in the experimental section. I would expect to see how the proposed method compares to the previous approaches that have modelled the navigation problem with GPs. \n\n2) In fact, due to the lack of real problems that require the presented technique, in the experimental section they just simulate some negative datapairs (following the so-called random shuffling technique). Moreover, this simulation technique is pretty poor in my view, since different inputs could have very similar outputs, which may lead to a simulated datapair almost identical to a standard training datapair. \n\n3) Some arguments are too vague/ambiguous. For instance, the equivalence between the scale of magnitude of both terms in eq. (5). It is stated that, by using the so-called logarith trick, both terms have the same \"scale of magnitude\". How is that defined? and how can the equivalence be proved? Or the sentence that says \"A Gaussian process is a Bayesian non-parametric approach that fits Gaussian distributions to functions\". \n\n4) Low quality writing in general. I have come across many typos and sentences that are not well written. See e.g.:\n* caption of Fig. 1 \"is been given\".\n* after eq. (5) \"minimize\",\n* \"Hewing et al. (2020) are some of the works using sampling based techniques for trajectory prediction\"\n* \"We trained a sparse SVGP model to regress a curve on the using the classical GP framework and the one with negative constraints GP-NC\"\n* Caption of Figure 4: it says five datasets, but there are six\n* Many references are missing the journal/conference/arxiv reference. Format not homogeneous across references.\n\n\n############################################\n\nAFTER THE REBUTTAL\n\nI have decided to keep my score unchanged. The authors include a new \"road navigation experiment\" in Section 5.2. However, I have several concerns about it:\n* This is a synthetic experiment that the authors have created themselves. Therefore, it does not address my concern on seeing actual real-world problems that can be solved with this approach.\n* The results of GP-NC (the proposed approach) and GP are very similar. I don't really see that the predictive mean of GP-NC avoids the \"negative samples\" more than the standard GP.\n* In fact, the design of this experiment is not clear to me. They say at the beginning that they use the present location ($x,y$) to predict the next location ($\\hat x, \\hat y)$. How do they model these two outputs? How do they obtain the plotted error bars for this model? This is not sufficiently explained. My impression is that they are just fitting a standard 1-dimensional GP being the input the x-dimension and the output the y-dimension. ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538127942, "tmdate": 1606915785005, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1064/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review"}}}, {"id": "bhPEVrIswoS", "original": null, "number": 5, "cdate": 1606093671331, "ddate": null, "tcdate": 1606093671331, "tmdate": 1606093671331, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "FqQrALQKeJG", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment", "content": {"title": "Additional navigation experiments added to the revised paper", "comment": "We thank the reviewer for carefully reading our work and acknowledging the novelty of the work.  We address the cons listed by the reviewer below:\n1. We do believe that modeling negative datapairs is an important problem faced by researchers and engineers working on safety-critical problems.  We have added a road navigation experiment in our updated draft to partly address your concern. \n2. Regarding the random shuffling technique, we used extreme precautions that no negative targets of the simulated datapair are close to the positive targets of existing standard datapair. Hence, during the experiments, it can be observed that GPNC performs better than the standard GP.\n3. We have worked on your comments to raise the quality of writing in the updated draft. \n\n\n**Updates to the paper:**\n* Added a new set of experiments to address concerns over the GP navigation problems. (Sec. 5.2).\n* Improved presentation in the updated paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "XZzriKGEj0_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1064/Authors|ICLR.cc/2021/Conference/Paper1064/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864104, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment"}}}, {"id": "XV_hTFx12cU", "original": null, "number": 4, "cdate": 1606093515378, "ddate": null, "tcdate": 1606093515378, "tmdate": 1606093515378, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "S1zuJcxOC_M", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment", "content": {"title": "Paper updated; Experiments added to the updated paper", "comment": "We want to thank the reviewer for thoughtful comments; especially for acknowledging the novelty of the approach.  We have incorporated your suggestions in our updated draft. \n\n**Inducing points**\n\nIn Figure 2.c) and 2.d) we randomly selected 10 data points from the training data as inducing points and trained both the models. In doing so, we jointly learn the locations of the inducing points while fitting the curve. More details can be found in Appendix A1.\n\n**SMSE**\n\nWe used standard practices from the GP literature for our evaluations. That said, we used RMSE error to emphasize the rate of convergence for comparison between classical GPs vs. GP-NC versions.\n\n**Navigation Experiments**\n\nWe have updated our experiment section by adding a new set of navigation experiments. Please refer to Section 5.2 of our updated manuscript where we tried to address the concerns of R4 by applying our approach on simulated data where both the positive and negative datapairs occur naturally.\n\n**Misc**\n\nAs the scale of the data increases, we use more approximations like structured kernel interpolation for exact GP which results in a decrease in performance to a certain extent. Lastly, we fixed the typos in our revised manuscript, as suggested. We again want to thank the reviewer for providing us with valuable feedback.\n\n**Updates to the paper:**\n* Added new set of experiments (Section 5.2)\n* Fixed typos\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "XZzriKGEj0_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1064/Authors|ICLR.cc/2021/Conference/Paper1064/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864104, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment"}}}, {"id": "LNPXyhYVtc", "original": null, "number": 2, "cdate": 1606092823644, "ddate": null, "tcdate": 1606092823644, "tmdate": 1606093206765, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "zb8mYTUEKvr", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment", "content": {"title": "Paper revised; added new experiments ", "comment": "We thank the reviewer for their thorough evaluation of our work and identifying the potential of our approach. Below we address the concerns raised by the reviewer:\n1. Thank you for bringing [1] to our attention, we were not aware of it. It is an interesting method that directly modifies the kernel of the GP. We are in the process of running their method for quantitative comparison and will update our draft accordingly as soon as we have their results. Though, it seems like their method will have problems when scaling to larger problems as their covariance matrix size will increase with more negative training data as opposed to our method which handles negative training data differently. \n2. We have added an additional set of experiments in our draft, which shows a car navigating on a road with pits and cones acting as negative constraints that are to be avoided.\n\n\n3. * Thank you for catching this. Yes, you are correct, it should be $`p(y|\\theta, \\bar{X})\u2019$. Eq(6) corresponds to the stated proposal and we have updated the text accordingly. \n    * We used the re-parameterization trick to sample from the Gaussian distribution during the inference phase. For the KL Divergence calculations in Eq(6), we directly used the analytical solutions. We have updated this detail in our draft. \n    * We initially tried minimizing the loss Eq(6) directly, but we found that the optimization was not stable as it was not balancing between the two terms in the loss functions as desired. \n    * We have added the values of $\\lambda$ and $\\sigma_{neg}$ in the updated draft.\n4.  We understand the confusion regarding the random shuffling technique and have updated the text to make it clearer. In the real world navigation scenario, we will actually have positive and negative datapairs given to us (Please see Fig.1 and newly added road navigation experiment, Please refer to Section 5.2 in our updated manuscript) and it will be straightforward to define the datapairs. For the experiments shown in our paper, we assumed that we are given the set of positive datapairs consisting of the input data and the corresponding labels as positive targets. Now, since we know the positive labels corresponding to the input data, we assume that any other label assigned to the same input can be treated as a negative datapair. From this point of view, the randomly created negative datapairs are valid where we ensure no positive target is equal to negative targets for any input \u2018x\u2019.\n\n**Updates to the paper:**\n* Added new set of experiments (Section 5.2)\n* Updated [1] the related work section\n* Other bug fixes as described above.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "XZzriKGEj0_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1064/Authors|ICLR.cc/2021/Conference/Paper1064/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864104, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment"}}}, {"id": "EOwyXN_HUY7", "original": null, "number": 3, "cdate": 1606093067010, "ddate": null, "tcdate": 1606093067010, "tmdate": 1606093067010, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "jSWh4WAxmQZ", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment", "content": {"title": "Results of additional experiments added to the updated paper", "comment": "We thank the reviewer for their comments. Below we address the concerns. \n\n1. We believe that our work addresses a critical and important problem faced by the researchers while applying GP to problems in safety-critical applications, like navigation systems. We feel that the technique we proposed is scalable and our initial exploratory experiments support our claims. Nevertheless, we are constantly looking to improve our method, it will be helpful if you can suggest any possible additions to our work which we should include in our future versions.\n2. We have added extra experiments in which we vary $\\lambda$ to show their influence on trajectory prediction. Please refer to Section 5.2 of the updated manuscript.\n3. $\\lambda$ is a hyperparameter and it decides the balance between the 2 terms in Eq.(6). Please also refer to the newly added experiment on varying $\\lambda$\n4. We\u2019ve fixed other requested typos.\n\n**Updates to the paper:**\n* Added new set of experiments (Section 5.2)\n* Updated [1] the related work section\n* Fixed typos\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "XZzriKGEj0_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1064/Authors|ICLR.cc/2021/Conference/Paper1064/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864104, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Comment"}}}, {"id": "jSWh4WAxmQZ", "original": null, "number": 3, "cdate": 1603837275055, "ddate": null, "tcdate": 1603837275055, "tmdate": 1605024539442, "tddate": null, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "invitation": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review", "content": {"title": "Learning what not to model", "review": "Summary\n--\n\nThis paper in concerned with Gaussian process regression under constraints that aim to discourage the model from learning certain values (negative constraints). These are called negative data pairs, and the authors propose an extension to the standard GP methodology to incorporate these constraints in the model. This is done by iteratively training a standard GP and maximising the KL between the GP and blobs of the negative data pairs.\n\nThe problem tackled in the paper is of relevance in fields such as spatial statistics and robotics, with possible applications also in more general ML tasks. The paper could be of interest to a narrow audience at ICLR. The presentation is rather clear and the main idea is easy to follow.\n\n\nConcerns\n--\n\n1. My main concern is originality and novelty of the approach presented in the paper. The authors tackle an important practical problem (or limitation), but the presented contribution alone is small. The proposed approach for including negative data pairs is straightforward, and something that one might find in an application paper (where the main interest is in solving a task related to an application). \n\n2. Limitations. The limitations of the approach should have been discussed in detail. Questions related to uni- vs. multimodality (splitting), bias influenced by the parameter \\lambda, behaviour in multi-output (2d, like Fig. 1), would perhaps best have been illustrated with suitable simulated test cases and included as figures (including random samples from the GP posterior). Some of the issues are visible in Fig. 2, but these are not discussed in detail.\n\n3. Experiments. The experiments do not appear convincing. Rather than artificially changing standard test data sets to fit your task setting, it would have been more interesting to see actual problems, where the model class would have been beneficial.\n\n4. Presentation. Even if the method itself is easy to understand from how it is presented, the paper would deserve improvements in the presentation. As a practical suggestion: Background material could be presented more concisely, the methods section refined to be more concise, and the additional space used for improving experiments and discussion.\n\n5. From how Alg. 1 now reads, I would interpret \\lambda not to have any effect on the training. This should not be the case. Alg. 1 does not agree with the objective in Eq. (6).\n\n6. Minor: Typo in Eq. (4).", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1064/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1064/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning What Not to Model: Gaussian Process Regression with Negative Constraints", "authorids": ["~Gaurav_Shrivastava1", "~Harsh_Shrivastava1", "~Abhinav_Shrivastava2"], "authors": ["Gaurav Shrivastava", "Harsh Shrivastava", "Abhinav Shrivastava"], "keywords": ["Gaussian Process", "Gaussian Process Regression"], "abstract": "Gaussian Process (GP) regression fits a curve on a set of datapairs, with each pair consisting of an input point '$\\mathbf{x}$' and its corresponding target regression value '$y(\\mathbf{x})$' (a positive datapair). But, what if for an input point '$\\bar{\\mathbf{x}}$', we want to constrain the GP to avoid a target regression value '$\\bar{y}(\\bar{\\mathbf{x}})$' (a negative datapair)? This requirement can often appear in real-world navigation tasks, where an agent would want to avoid obstacles, like furniture items in a room when planning a trajectory to navigate. In this work, we propose to incorporate such negative constraints in a GP regression framework. Our approach, 'GP-NC' or Gaussian Process with Negative Constraints, fits over the positive datapairs while avoiding the negative datapairs. Specifically, our key idea is to model the negative datapairs using small blobs of Gaussian distribution and maximize its KL divergence from the GP. We jointly optimize the GP-NC for both the positive and negative datapairs. We empirically demonstrate that our GP-NC framework performs better than the traditional GP learning and that our framework does not affect the scalability of Gaussian Process regression and helps the model converge faster as the size of the data increases.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shrivastava|learning_what_not_to_model_gaussian_process_regression_with_negative_constraints", "supplementary_material": "/attachment/66d51d64a64a06c34d67c78228109372f493fe0c.zip", "pdf": "/pdf/231094d70f0ad58be0b246f7933d53b364f5ac2d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=NheVa3ee_q", "_bibtex": "@misc{\nshrivastava2021learning,\ntitle={Learning What Not to Model: Gaussian Process Regression with Negative Constraints},\nauthor={Gaurav Shrivastava and Harsh Shrivastava and Abhinav Shrivastava},\nyear={2021},\nurl={https://openreview.net/forum?id=XZzriKGEj0_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "XZzriKGEj0_", "replyto": "XZzriKGEj0_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1064/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538127942, "tmdate": 1606915785005, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1064/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1064/-/Official_Review"}}}], "count": 10}