{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028615593, "tcdate": 1490028615593, "number": 1, "id": "BkgU_Kpjl", "invitation": "ICLR.cc/2017/workshop/-/paper127/acceptance", "forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028616216, "id": "ICLR.cc/2017/workshop/-/paper127/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028616216}}}, {"tddate": null, "tmdate": 1489493851020, "tcdate": 1489493851020, "number": 2, "id": "SymPJvSjg", "invitation": "ICLR.cc/2017/workshop/-/paper127/official/review", "forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "signatures": ["ICLR.cc/2017/workshop/paper127/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper127/AnonReviewer1"], "content": {"title": "Point being made is neither terribly surprising nor well argued.", "rating": "4: Ok but not good enough - rejection", "review": "If I'm understanding correctly, the argument is essentially that labels convey at most log K bits given K classes -- a common refrain from proponents of unsupervised pretraining about 10 years ago, and therefore not a very novel contribution. The paper does a poor job of explaining how the experiments performed support this informal hypothesis.\n\nDue to both the lack of novelty and the ineffectiveness at communicating the points being made, I do not believe this is appropriate for the workshop track. I'd encourage the authors to try and flush out their arguments in slightly longer form and post it on arXiv, with a focus on clearly leading the reader from premise to experimental basis to conclusion.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489493851797, "id": "ICLR.cc/2017/workshop/-/paper127/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper127/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2", "ICLR.cc/2017/workshop/paper127/AnonReviewer1"], "reply": {"forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489493851797}}}, {"tddate": null, "tmdate": 1489461058845, "tcdate": 1489461058845, "number": 1, "id": "B1oBJJrog", "invitation": "ICLR.cc/2017/workshop/-/paper127/official/comment", "forum": "HkcpR04Yx", "replyto": "SkU5k5Jsx", "signatures": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2"], "content": {"title": "read the response & additional comments/questions", "comment": "Thanks for your response. Here are some additional stimulating questions whose answers might be useful for your future versions.\n\n1. What happens when none of the features contains any information for the prediction task?\n2. What is the relationship of your \"feature competition\" framework to the concept of sufficient statistics? Is it correct that when you say it is \"difficult\" to learn new features, you actually mean the current set of features is already almost sufficient? In your context, the sufficient statistics will be for the conditional distribution p(Y|X) where Y=label, X=input."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487363778157, "tcdate": 1487363778157, "id": "ICLR.cc/2017/workshop/-/paper127/official/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "reply": {"forum": "HkcpR04Yx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/workshop/paper127/reviewers", "ICLR.cc/2017/workshop/paper127/areachairs"], "cdate": 1487363778157}}}, {"tddate": null, "tmdate": 1489447280583, "tcdate": 1489447280583, "number": 3, "id": "r1YutsNil", "invitation": "ICLR.cc/2017/workshop/-/paper127/public/comment", "forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "signatures": ["~Jiaming_Song1"], "readers": ["everyone"], "writers": ["~Jiaming_Song1"], "content": {"title": "Updated paper", "comment": "We updated the paper according to comments of AnonReviewer2. Namely, we moved the argument for GANs to the appendix, and spent more space on the clarity of the supervised learning argument and the experiments.\n\nThe structure of the updated paper is as follows:\n1. We propose an assumption that relates \"the learnability\" of a feature to its \"signal\", which is the conditional mutual information.\n2. If the assumption holds, then \"the feature competition\" phenomenon and \"an upper bound for the total incentive to learn features\" would exist in supervised feature learning.\n3. We validate our assumption through an experiment, which suggests a high correlation between \"the learnability\" of a feature and its \"signal\"."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487363778157, "tcdate": 1487363778157, "id": "ICLR.cc/2017/workshop/-/paper127/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper127/reviewers"], "reply": {"forum": "HkcpR04Yx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487363778157}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1489367793073, "tcdate": 1487363777592, "number": 127, "id": "HkcpR04Yx", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HkcpR04Yx", "signatures": ["~Jiaming_Song1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "writers": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489113345808, "tcdate": 1489112929220, "number": 1, "id": "S1twkq1ig", "invitation": "ICLR.cc/2017/workshop/-/paper127/public/comment", "forum": "HkcpR04Yx", "replyto": "H1fpSOA9e", "signatures": ["~Jiaming_Song1"], "readers": ["everyone"], "writers": ["~Jiaming_Song1"], "content": {"title": "clarifications on problem, contributions, and experiments", "comment": "Thanks for your comments.\n\nYour summary is correct - we study when \"the presence of a set of features for a task may hinder the learning of additional features\", which we call\"feature competition\".\n\nThe claim for generative models to have greater potential for representation learning (compared to supervised learning) is an additional conclusion that we felt is worth noting. We will revise our writing to emphasize the main message on supervised feature learning in the main article, and move the discussion about generative models entirely to the appendix.\n\n\n=== Novelty ===\n\nIntuitively, let us consider a dataset with images of \"cats and dogs\". Our questions are: if we train using supervised methods to distinguish cats vs dogs, will we learn all the features that are related to cats and dogs? Will it learn additional features, such as a \u201ctable\u201d feature, even if it appears in the input data but is only slightly correlated with cats?\n\nWe informally use the term \"learnability\" to indicate the degree of incentive to learn features. The intuition is that features that add more predictive power to the current model (over a supervised task) have higher incentives to be learned.\n\n1.  We propose an assumption that relates \"the learnability\" of a feature to its \"signal\", which is the conditional mutual information.\n\n2.  If the assumption holds, then \"the feature competition\" phenomenon and \"an upper bound for the total incentive to learn features\" would exist in supervised feature learning.\n\nImagine learning features one by one. The existence of a set of features will decrease the conditional mutual information between a new feature and the label, and reduce the \"signal\", hence the \"learnability\". If the \"signal\" for a particular feature is small (or even worse, zero), then the model would receive little benefit in predicting the label correctly, hence it is unlikely for the model to learn this feature over others.\n\nEquation 2 states that the sum of \"signal\" is bounded by H(Y), which sets an upper bound to the total incentive to learn features in supervised learning, under our assumption. Once that upper bound is reached, there will be no incentive for learn additional features.\n\nIntuitively, if we have an \"eye\" feature that already allows us to discriminate cats vs dogs perfectly, there would be no incentive to learn an additional \"mouth\" feature, even though it is also highly related to the current task. Learning additional features that not directly related to the task, such as \"tables\", would be even more difficult.\n\n3.  We validate our assumption through an experiment, which suggests a high correlation between \"the learnability\" of a feature and its \"signal\".\n\nThe experiment process is as follows:\n\n1) We have two phases, \"feature extraction\" and \"feature evaluation\" using  a \u201cleft digit\u201d and a \u201cright digit\u201d as inputs in both phases.\n2) In \"feature extraction\", we train (left digit, right digit) --> (left label) to obtain features.\nWe manually control the conditional mutual information (\"signal\") between (right input, left label) with two mechanisms. \nArtificially Induce correlation between (left label, right label), and thus also between (right digit, left label), which will increase the \u201csignal.\u201d\nCorrupting the left input by some probability, which will increase the signal. (left input becomes less informative about left label)\n\n3) In \"feature evaluation\", we measure the quality of features corresponding to the right input learned in \u201cfeature extraction\u201d, by training a one-layer network (left feature, right feature) --> (right label). We use \"test accuracy\" as a means to measure the overall quality of the features learned. (\"learnability\")\n\nAn graphical explanation to the experiment can be seen in http://tsong.me/public/img/blog/competition.png\n\nIn Figure 1, we see a strong correlation between \"signal\" and \"test accuracy\", which suggests that features with higher \"signal\" will have higher incentive to be learned.\n\nSome corner cases in Figure 1:\nBottom row: The right label (hence also right input) has no correlation with the left label, hence there is no signal to learn features from the right part, and would perform no better than random initialization of the weights.\nTop left corner: The right input has high correlation with the \u201cleft label\u201d while the \u201cleft input\u201d doesn\u2019t (because of added noise), this has the highest signal, since this is essentially assigning the left label to the right input.\nTop right corner: Both inputs have high correlation to the left label. Due to feature competition, relatively few features corresponding to the right input are learned.\n\n4. The properties of conditional mutual information are indeed well known, and we do not claim any contributions there. The contribution is, identifying the relationship between this quantity and the difficulty of learning new features under the assumptions made.\n"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487363778157, "tcdate": 1487363778157, "id": "ICLR.cc/2017/workshop/-/paper127/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper127/reviewers"], "reply": {"forum": "HkcpR04Yx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487363778157}}}, {"tddate": null, "tmdate": 1489112973946, "tcdate": 1489112973946, "number": 2, "id": "SkU5k5Jsx", "invitation": "ICLR.cc/2017/workshop/-/paper127/public/comment", "forum": "HkcpR04Yx", "replyto": "S1twkq1ig", "signatures": ["~Jiaming_Song1"], "readers": ["everyone"], "writers": ["~Jiaming_Song1"], "content": {"title": "Responses to individual questions", "comment": "=== Responses to Major Comments ===\n\nQ: \"The fact that the mutual information I(Y, f_1,...,f_k) is bounded above by H(Y), to me, means that one cannot come up with features f_1,..,f_k to extract more information that the full amount contained in Y.\"\n\nA: This is the correct interpretation, but not the one we intend to emphasize throughout this paper.\n\nOur interpretation is that (under the assumption) once one has come up with features f_1,...,f_k that already maximize the mutual information, there is no incentive to come up with more features, even if the mutual information of some other feature I(Y; f_{k+1}) might still be high.\n\nFor the \"cats and dogs\" dataset example, if one has the \"eye\" feature that already maximizes the mutual information between features and labels, there is no \"signal\" to learn an additional useful \"mouth\" feature.\n\n\nQ: \"But, it does not mean that there is a limit in learning capacity of an algorithm..\"\n\nA: Indeed. However, this does not mean that there is no limit in the incentive to learn features. From an optimization perspective, if we can almost perfectly classify \"cats and dogs\" through the \"eye\" feature, we would have little gradient to optimize the objective, let alone learning the \"mouth\" feature.\n\n\nQ: Experiment to show feature competition is not clear.\n\nA: We will improve our writing using more space, which we would gain by removing parts of the generative model arguments.\n\n\nQ: Define \"feature competition\".\n\nA: In the summary, you stated that our paper \"investigates a phenomenon that the presence of a set of features for a task may hinder the learning of a new set of features for another task.\" As you may have suspected, this phenomenon is \"feature competition\". We will clarify this in the paper.\n\n\nQ: In Section 2.1, there are two phases, each phase using only one component of Y=(Y1, Y2). How do you justify this?\n\nA: Both components are present in both phases. We will clarify this in the paper, and add a figure to this (see http://tsong.me/public/img/blog/competition.png ).\n\n\nQ: Why corrupt the left digit?\n\nA: It allows us to increase \"the conditional mutual information between (left label) and the (right digit) conditioned on the (left digit)\", because the (left digit) will be less correlated to the (left label) due to noise. This allows us to explore two separate mechanisms to controlling the conditional mutual information. We will add how to compute the conditional mutual information in the appendix.\n\n\n=== Responses to Detailed Suggestions ===\n\n\nQ: \"But then at least some of those features must be very hard to learn..\" I could not follow the reasoning behind this at all.\n\nA: According to the Pigeonhole principle, if the sum of \"signal\" is bounded by H(Y), and there is k features, then at least some of the feature will have \"signal\" less than H(Y)/k. If k is large, then the \"signal\" is small and under our assumption these features will be hard to learn. We will clarify this, as well as the implications of Equation 2."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487363778157, "tcdate": 1487363778157, "id": "ICLR.cc/2017/workshop/-/paper127/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper127/reviewers"], "reply": {"forum": "HkcpR04Yx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487363778157}}}, {"tddate": null, "tmdate": 1489040826540, "tcdate": 1489040826540, "number": 1, "id": "H1fpSOA9e", "invitation": "ICLR.cc/2017/workshop/-/paper127/official/review", "forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "signatures": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2"], "content": {"title": "Unclear goal and conclusion", "rating": "5: Marginally below acceptance threshold", "review": "\n[Paper summary]\nThe paper investigates a phenomenon that the presence of a set of features for\na task may hinder the learning of a new set of features for another task. The\npaper uses the well-known conditional mutual information between the task label\n(Y) and the features to quantify the difficulty of learning a new set of\nfeatures. \n\n[Clarity, Novelty]\nThe paper is not clearly written. I spent a lot of time guessing the main\nmessage of the paper. If I understand correctly, the main message is \"The\npresence of some features may make the learning of a new set of features more\ndifficult.\" However, this is not at all emphasized. In fact, the introduction\nmentions a seemingly different claim: \"generative models have greater potential\nfor representation learning (compared to supervised learning).\" \n\nThe notation of the conditional mutual information is well known, as well as\nits decomposition into the difference of two conditional entropy terms. The\nlimits the novelty of the paper. The contribution from the paper is rather the\nuse of this quantity to quantify the difficulty of learning new features, as\nstated. However, experimental results do not seem to support this.\n\n[Major comments/questions]\n\n* The paper seems to be saying that the entropy of the task label H(Y) (in\n  Eq.2) is the limit of learning capacity (see the conclusion). I do not quite\nunderstand why this should be the right interpretation. I see H(Y) as the total\ninformation of the task label. The fact that the mutual information I(Y,\nf_1,...,f_k) is bounded above by H(Y), to me, means that one cannot come up\nwith features f_1,..,f_k to extract more information that the full amount\ncontained in Y. But, it does not mean that there is a limit in learning\ncapacity of an algorithm. It does mean that there is a limit to what a learner\nhas to know to learn to predict Y.\n\n* Section 2.1: Experiment to show feature competition:\nThe writing in this section is very difficult to follow. It might be better to\nfirst state what the goal of the experiment is. The paper does mention \"feature\ncompetition\" as the goal. But then, this term was not clearly defined.\n\n* Section 2.1: In Eq. 2, Y is Eq. 2 is a fixed task label random vector. In\n  Section 2.1, there are two phases, each phase using only one component of\nY=(Y1, Y2). How do you justify this in the context of Eq. 2 which uses a fixed\nY=(Y1, Y2)?\n\n* Section 2.1: It is unclear why you \"completely corrupt\" the left digit.\n  Please state the goal first.\n\n[Detailed suggestions]\n\n* Section 2: I (mutual information) is not defined. In fact, that it is the\n  conditional mutual information is not even mentioned. Eq 3 (difference of two\nentropies) should be moved to Section 2 to match the text description there.\n\n* Section 2: \"But then at least some of those features must be very hard to\n  learn..\" I could not follow the reasoning behind this at all.\n\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "On the Limits of Learning Representations with Label-Based Supervision", "abstract": "Advances in neural network based classifiers have accelerated the progress of automatic representation learning. Since the emergence of AlexNet, every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations, which are widely transferred to tasks such as evaluating the quality of generated samples. In this work, however, we demonstrate that supervised learning is limited in its capacity for representation learning. Based on an experimentally validated assumption, we show that the existence of a set of features will hinder the learning of additional features. We also show that the total incentive to learn features in supervised learning is bounded by the entropy of the labels. We hope that our analysis will provide a rigorous motivation for further exploration of other methods for learning robust and transferable representations. ", "pdf": "/pdf/15431e8e18d183e56b35e799f4adbb92dc163a01.pdf", "paperhash": "song|on_the_limits_of_learning_representations_with_labelbased_supervision", "keywords": ["Theory", "Deep learning", "Transfer Learning"], "conflicts": ["stanford.edu", "tsinghua.edu.cn", "duke.edu"], "authors": ["Jiaming Song", "Russell Stewart", "Shengjia Zhao", "Stefano Ermon"], "authorids": ["tsong@cs.stanford.edu", "stewartr@cs.stanford.edu", "zhaosj@cs.stanford.edu", "ermon@cs.stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489493851797, "id": "ICLR.cc/2017/workshop/-/paper127/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper127/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper127/AnonReviewer2", "ICLR.cc/2017/workshop/paper127/AnonReviewer1"], "reply": {"forum": "HkcpR04Yx", "replyto": "HkcpR04Yx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper127/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489493851797}}}], "count": 8}