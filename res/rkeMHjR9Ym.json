{"notes": [{"id": "rkeMHjR9Ym", "original": "rJxfoV9WKQ", "number": 69, "cdate": 1538087738211, "ddate": null, "tcdate": 1538087738211, "tmdate": 1545355413494, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BJlvuxYAJE", "original": null, "number": 1, "cdate": 1544618094826, "ddate": null, "tcdate": 1544618094826, "tmdate": 1545354501040, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Meta_Review", "content": {"metareview": "This paper shows convergence of stochastic gradient descent  for the problem of learning weight matrices for a linear dynamical system  with non-linear activation.  Reviewers agree that the problem considered is both interesting and challenging. However the paper makes many simplifying assumptions - 1) both input and hidden state are observed, a very non standard assumption, 2) analysis requires increasing activation functions, cannot handle ReLU functions. I agree with R2 and think these assumptions make the results significantly weaker. R1 and R3 are more optimistic, but authors response does not give an insight into how one might extend this analysis to the setting where hidden state is not observed. Relaxing these assumptions will make the paper more interesting. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "ICLR 2019 decision"}, "signatures": ["ICLR.cc/2019/Conference/Paper69/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper69/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353347916, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper69/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper69/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper69/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353347916}}}, {"id": "Sygf9aE927", "original": null, "number": 1, "cdate": 1541193097802, "ddate": null, "tcdate": 1541193097802, "tmdate": 1543859069056, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "content": {"title": "Good convergence result for non-convex dynamic problem under stable system condition", "review": "The paper studies discrete time dynamical systems with a non-linear state equation.  They assume the non-linear function is assumed to be \\beta-increasing like leaky ReLU. Under this setting, the authors prove that for the given state equation for stable systems with random gaussian input at each time step, running SGD on a fixed length trajectory gives logarithmic convergence.\n\nThe paper is well-written and proves strong convergence properties. The deterministic result does not seem very novel and uses the idea of one-point strong convexity which has been studied in various prior works. However the bounding of the condition number of the data matrix is interesting and guarantees are near-optimal. The faster convergence for odd activations is a good observation. Overall, I think the paper is good. I do list some concerns:\nQuestions/concerns:\n- The deterministic theorem (Theorem 4.1) seems similar to Theorem 3 in [1] with SGD instead of GD. Also under the distribution being symmetric, it can be derived from [2] with $k=1$. \n- Can the ideas be extended to other commonly used activations such as ReLUs/Sigmoids? Sigmoids have exponentially small slope near origin.\n- The proof seems to rely on the fact that due to the gaussian input added each time step and stable system assumption after a sufficient number of time steps, the input-output pairs will not be highly correlated. So the data is sufficiently uncorrelated taking enough data. What happens if this data at each step is not gaussian?\n- In the unstable setting, the solution proposed just samples from different trajectories which by default are independent hence correlation is not an issue, this seems a bit like cheating. \n- In RNNs, the motivation of the work, the hidden vectors are not observed, thus this setting seems a bit restrictive.\n- If SGD was performed on only one truncated series, do the results still hold?\n\nOther comments:\n- There has been previous work on generalized linear models which work in more general settings like GLMtron [3]. The authors should update prior work on generalized linear models as well as neural networks.\n- Typo on Page 2 y_t = h_{t+1} not y_t = h_t.\n\n[1] Dylan J. Foster, Ayush Sekhari, and Karthik Sridharan. Uniform Convergence of Gradients for Non-Convex Learning and Optimization. NIPS 2018.\n[2] Surbhi Goel, Adam Klivans, and Raghu Meka. Learning One Convolutional Layer with Overlapping Patches. ICML 2018.\n[3] Sham M. Kakade et al. Efficient learning of generalized linear and single index models with isotonic regression. NIPS 2011.\n\n\n--------------\nI would be maintaining the same score. I agree that the paper has nice convergence results that could possibly be building steps towards the harder problem of unobserved hidden states however, there is more work that could be done for unstable systems and possible extension to ReLU and other activations to take it a notch higher. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper69/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "cdate": 1542234544867, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335642194, "tmdate": 1552335642194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJx2X4Rpn7", "original": null, "number": 3, "cdate": 1541428260045, "ddate": null, "tcdate": 1541428260045, "tmdate": 1543848644815, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "content": {"title": "Interesting result on learning a non-linear dynamical system", "review": "This work considers the problem of learning a non-linear dynamical system in which the output equals the state.  Under several assumptions (input is Gaussian, non-linear activation is strictly increasing, stable system) it is shown that SGD converges linearly to the ground truth system with near-optimal sample complexity. The proof idea is to reduce this problem to the problem of learning a single non-linear neuron in the case that the covariance matrix of the data is well-conditioned. The main challenge is to show the covariance is well-conditioned under the reduction. In a nutshell, this is done by splitting the trajectory to sub-trajectories with independent states and using results from random matrix theory on matrices with independent rows.\n \nThis work tackles a very challenging problem and the results are interesting. The guarantees are strong \u2013 linear convergence to the ground truth parameters and near-optimal sample size. Given that not much is known on deep non-linear networks, I think that the result is significant. The main weakness of the paper is the assumption that the state equals the output. Another minor weakness is the clarity and presentation of results:\n1.       The proof outline of the main result is hard to follow. There is no proof outline of Theorem 4.2 in the main text. The proof is highly technical and there are many technical ideas that were moved to the appendix. For instance, the proofs in sections C and D are not mentioned in the main text. I suggest to write a summary of the steps required to prove the main result and how all of the technical ideas are combined together.\n2.       There is no reference and comparison to the paper of Mei et al. [1] that study single neuron models.\n3.       It is claimed that by increasing beta the convergence is faster. However, I am not sure why this is meaningful. By changing beta the ground truth changes as well. For beta = 0 the ground truth dynamical system is linear and for beta = 1 the ground truth is a non-linear dynamical system with ReLU. Since a ReLU network is more expressive, generally in the case of beta = 1 the ground truth is more difficult to learn than beta = 0. Therefore, we should expect convergence to be slower than beta=0 or not occur at all. Am I missing something?\n4.       The Gaussian assumption is not stated clearly in the text. It can be deduced only from the statements of the theorems and the conclusion section.\n5. In Theorem F.1, it is claimed that all rows of E are equal. However, in the statement of the theorem it is not mentioned that the rows of A are identically distributed. Should this assumption be included in the statement?\n\n[1] Mei, Song, Yu Bai, and Andrea Montanari. \"The landscape of empirical risk for non-convex losses.\" arXiv preprint arXiv:1607.06534 (2016).\u200f \n\n\n-----------Revision------------------------\n\nI am not changing the score. I disagree with AnonReviewer2 regarding the significance of the results.  The assumption that the states are observed is indeed a weakness of the paper. However, understanding non-linear dynamical systems is extremely challenging and this paper provides strong convergence guarantees. Furthermore, there are several insights in the analysis that may be useful in future work.\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper69/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "cdate": 1542234544867, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335642194, "tmdate": 1552335642194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJxDKvltR7", "original": null, "number": 3, "cdate": 1543206782928, "ddate": null, "tcdate": 1543206782928, "tmdate": 1543206782928, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "Sygf9aE927", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "content": {"title": "Response to Reviewer 3: Citations included and GLM discussed", "comment": "Thank you for the detailed review and helpful feedback. Our response is provided below.\n\n1 Re Similar results to Thm 4.1: We updated the manuscript and compared Thm 4.1 to [1,2]. Both results make distributional assumptions. As far as I understand, [1] is a statistical convergence result rather than algorithmic (e.g. establishing how fast SGD finds a solution). Corollary 1 of [2] is closer to Thm 4.1. The differences are [2] applies to leaky ReLU only, requires symmetric distribution and access to population landscape i.e. infinitely many samples (perhaps latter issue can be fixed using results of Mei et al. or [1]). Overall, we agree that the proof of Thm 4.1 is not that sophisticated. Actually, we asked a few colleagues to see if there is an identical result but we were unable to find it.\n\n2 Re Extension to sigmoid and ReLU: This is a very good question (also see response to Reviewer 2). The extension to other activations has two aspects (at least using our approach): (1) Establishing SGD convergence result (similar to Thm 4.1). (2) Showing that state vector has a good covariance. There is a good chance (1) is doable using related results from literature (e.g. Soltanolkotabi 2017). The bigger challenge seems to be addressing (2) i.e. ensuring input provides enough excitation for the output state covariance. As you mention, sigmoid's slope might help (perhaps at the expense of increasing the sample size). Overall, if one assumes that the state covariance is nice (e.g. Assumption 1), we believe extension is probably doable.\n\n3 Re Gaussian assumption: The Gaussianity assumption is again used to prove that state vector has a good covariance. The current proof needs it because it uses properties of multivariate Gaussians (e.g. rotational invariance). Again, if you assume state covariance is good (Assumption 1), one can use a wider class of distributions.\n\n4 Re Unstable systems: We agree that creating independent trajectories simplifies the problem. The challenge is that, the past state of the unstable system is not forgotten instead it is amplified. Hence, single trajectory analysis requires a different approach. We should remark that this problem is nontrivial even without any nonlinear activation. See the results of Simchowitz et al. and Faradonbeh et al. \n\n5 Re Truncated series: The result would still hold with truncated series or using a single subtrajectory. This is indeed the main proof strategy. We first show that truncation leads to small perturbation. Secondly, we show that if a single subtrajectory is sufficient, you can stitch them together to obtain a convergence on full dataset. As first reviewer suggested, we put a proof outline on Section 4 mentioning these.\n\n6 Re Other GLM works: Thanks for pointing out missing refs. We added [1,2,3] and Mei et al. and compared to our results. We are happy to add other references if relevant. Some neural net works appeared after our submission. We will add these (and possible future papers) during the final revision.\n\n7 Re Typo: Fixed. Thanks!\n\nReferences\n1) Mei, Song, Yu Bai, and Andrea Montanari. \"The landscape of empirical risk for nonconvex losses.\" The Annals of Statistics 46.6A (2018): 2747-2774.\n2) Soltanolkotabi, Mahdi. \"Learning relus via gradient descent.\" Advances in Neural Information Processing Systems. 2017.\n3) Simchowitz, Max, et al. \"Learning Without Mixing: Towards A Sharp Analysis of Linear System Identification.\" arXiv preprint arXiv:1802.08334 (2018).\n4) Faradonbeh, Mohamad Kazem Shirani, Ambuj Tewari, and George Michailidis. \"Finite time identification in unstable linear systems.\" Automatica 96 (2018): 342-353."}, "signatures": ["ICLR.cc/2019/Conference/Paper69/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612125, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkeMHjR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper69/Authors|ICLR.cc/2019/Conference/Paper69/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612125}}}, {"id": "HJlkw8gYA7", "original": null, "number": 2, "cdate": 1543206487079, "ddate": null, "tcdate": 1543206487079, "tmdate": 1543206487079, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "HJxxv9Bp37", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "content": {"title": "Response to Reviewer 2: Addressing assumptions", "comment": "Thank you for the thorough review and bringing up good points. Our response is provided below.\n\n1 Re State is observed directly: We agree that learning with output observations would be a more significant result. As the reviewer points out, even for linear systems, results on output observations are limited (e.g. Hardt, Ma, Recht). However, we believe that understanding nonlinear state equations is interesting in its own right. The fact that output observation is not addressed doesn't make the problem trivial. There is a very limited understanding of learning nonlinear dynamical systems and the setup considered here is a natural extension of the linear state equation. The intuitions and theory developed here can help address state equations with other nonlinearities. On the other hand, this paper also makes progress on multiple fronts which may help address output equations:\n\n(a) We show that output state has good covariance under nonlinear activations. Intuitively, this may play a critical role for learning the output observation matrix C where y_t=Cx_t.\n(b) Learning from single trajectory: We provide a technical framework for rigorously addressing temporal dependencies in the data obtained from dynamical systems.\n(c) Optimal sample complexity: We show that despite temporal dependencies and nonlinearities, one can learn dynamical systems in a statistically efficient way.\n\n2 Re Comparison to Bento et al: We believe the results of Bento et al and Jalali and Sanghavi are orthogonal to our work rather than being more difficult. These works use convex optimization and consider sparse linear equations whereas we use first order methods for nonlinear systems. On the other hand, we believe it is possible to extend our results to sparse systems by developing sparse variants of Theorems 4.1 and F.1 of our manuscript. Finally, the sparsity dependency of these works appear to be suboptimal (as acknowledged by Jalali and Sanghavi) whereas our results are sample optimal.\n\n3 Re Inability to use ReLU: This is a good point which is also brought up by Reviewer 3 (hence some of the response overlaps). Addressing ReLU has two challenges: (1) Establishing SGD convergence result (similar to Thm 4.1). (2) Showing that state vector has a good covariance. There is a good chance (1) is doable using related results from literature (e.g. Soltanolkotabi 2017, Mei et al. 2018 and others). The main challenge seems to be addressing (2) i.e. ensuring input provides enough excitation for the output state covariance. We believe that if one assumes that the state covariance is nice (e.g. Assumption 1), ReLU proof is likely doable. While writing the paper we had to decide between (i) obtaining a comprehensive result which provides an end-to-end learning guarantee or (ii) assuming that the state covariance is *somehow* well-conditioned and providing a more general result. We chose the first path which resulted in Gaussian input assumption as well as the necessity of beta-increasing activations.\n\nOn a related note, non-rigorously speaking, leaky ReLU results may perhaps help establish a ReLU result: ReLU can be approximated by a leaky ReLU with a very small slope beta. This means that the trajectory generated by a ReLU state equation can be written as the leaky ReLU trajectory plus a small noise. Hence, we can fit the ReLU data using the leaky ReLU state equation to find the A,B matrices. It is not clear if this argument would immediately work in theory because we believe provable noise robustness of SGD (via Thm 4.1) also decays in the slope beta so you might still suffer significant error on A,B estimates (e.g. while noise is small, it gets amplified by 1/beta).\n\nReferences\n1) Mei, Song, Yu Bai, and Andrea Montanari. \"The landscape of empirical risk for nonconvex losses.\" The Annals of Statistics 46.6A (2018): 2747-2774.\n2) Soltanolkotabi, Mahdi. \"Learning relus via gradient descent.\" Advances in Neural Information Processing Systems. 2017."}, "signatures": ["ICLR.cc/2019/Conference/Paper69/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612125, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkeMHjR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper69/Authors|ICLR.cc/2019/Conference/Paper69/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612125}}}, {"id": "HJeIAZlYCX", "original": null, "number": 1, "cdate": 1543205326358, "ddate": null, "tcdate": 1543205326358, "tmdate": 1543205326358, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "SJx2X4Rpn7", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "content": {"title": "Response to Reviewer 1: Proof outline included.", "comment": "Thanks for the careful review and helpful suggestions. Really appreciated. Our response is provided below.\n\n1 Re Proof outline: This is a really good suggestion. We updated the manuscript and added a proof outline at the start of Section 4. We believe this helps clarify the proof strategy. We also refer to Appendix A,B,C,D in this outline to navigate the reader.\n\n2 Re Comparison to Mei et al: Thanks for catching this. I am honestly surprised that we forgot to cite this paper. The reference is included and discussed. Additionally, proof outline states that \"Temporal dependencies prevent us from directly using statistical learning results that typically assume i.i.d. samples.\"\n\n3 Re beta=0 vs 1 convergence: We clarified that convergence becomes faster assuming a realizable model where the data is generated from a ground truth state equation. This is explained in the Footnote 3 in the numerical section 6. In particular, our experiments are trying to verify our main theoretical results which predict that if the data is realizable then convergence will be faster with increasing beta. Hence, numerics is indeed consistent with our theory. We agree with the reviewer that, if the dataset is fixed and we try to fit this fixed dataset with different beta, the results will be different. On a related note, leaky ReLU has similar expressivity as ReLU. If a small positive slope makes it converge faster compared to ReLU, it would be interesting to know.\n\n4 Re Gaussian not stated: We agree with the reviewer. We stated the Gaussian data assumption in the Introduction under Contributions. Technically speaking, the main use of Gaussian assumption is proving that covariance of the state matrix is well conditioned. In general, one can establish the same result for wider range of distributions (e.g. subgaussian) if Assumption 1 holds.\n\n5 Re Theorem F.1: Thanks for carefully reading the paper. This is a really good catch. We slightly modified the statement of Theorem F.1. Basically, the spectral norm bound doesn't need the rows of E to be equal. However, the minimum singular value bound needs them to be equal. This is a minor technicality and doesn't impact the remaining proof. You can see it by reading the proof of Theorem D.2 (e.g. bounding Q and bar{Q} matrices)."}, "signatures": ["ICLR.cc/2019/Conference/Paper69/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612125, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkeMHjR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper69/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper69/Authors|ICLR.cc/2019/Conference/Paper69/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers", "ICLR.cc/2019/Conference/Paper69/Authors", "ICLR.cc/2019/Conference/Paper69/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612125}}}, {"id": "HJxxv9Bp37", "original": null, "number": 2, "cdate": 1541392983716, "ddate": null, "tcdate": 1541392983716, "tmdate": 1541534312227, "tddate": null, "forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "content": {"title": "Interesting and challenging problem, but assumptions weaken the results", "review": "This paper studies the ability of SGD to learn dynamics of a linear system + non-linear activation. That is, in the standard LTI setting, the dynamics of a system evolve according to\n\nh_{t+1} = Ah_t + Bu_t,\n\non input u_t.\n\nIn addition, this paper considers the setting where the evolution is:\n\nh_{t+1} = \\phi(Ah_t + Bu_t)\n\nfor \\phi a non-linear activation function. \n\nThis is a difficult problem. Though system identification was for many decades a large and active area in the control community, the understanding of system identification from a modern statistical perspective (understanding sample complexity and computational complexity simultaneously) is surprisingly lacking. This is evidenced by the fact that the first results along these lines for the simplest possible (SISO, LTI) system, came only recently (Hardt, Ma, Recht \u201916). \n\nThis paper attacks a more general setting, due to the presence of the nonlinearity.\n\nHowever, the present setting is significantly limited in another sense: the authors assume that the state is observed directly. This is in contrast to the typical situation where we observe only a projection of the state, or possibly even a noisy such projection. Indeed, this is one of the critical complications in the work of Hardt, Ma and Recht. Without it, i.e., under the assumption that the entire state trajectory can be directly observed, much more is possible, and indeed much more has been done. For example, work by Bento, Ibrahimi and Montanari \u201910, solves a more difficult problem in that they estimate sparse dynamics (in appropriate sample complexity). Jalali and Sanghavi \u201911 generalized the work of Bento et al., to the setting where some of the components of the state are not all observed, but rather some are latent.\n\nThe motivating application for this work is estimating RNNs. In this case, the state variable represents the critical information that is carried from one time to the next in the RNN. Presumably the setting here is to show that if indeed data are generated by an RNN, then we can compute this using SGD and backprop. Towards this, the assumption of having access to the internal state is a difficult one. On the one hand, this is a hard and important problem. On the other, we really won\u2019t have access to such an internal state. There are of course other problematic aspects, such as robustness, the inability to use ReLU (Defn 3.1). But the observation model seems important. Again, I believe this is especially so, because the considerable complications present in Hardt, Ma, Rect \u201916 specifically seemed to be a consequence of the observation model being partial.\n\nThe inability to use ReLU at first look does not seem like a great limitation. But then one problematic aspect here seems that the proof concept and direction critically rely on this, as they basically reduce to the setting of linear activations \u2014 something which, presumably, is impossible for something like ReLU. So it is not only the results, but also the developed machinery, that seem to be inherently limited.\n\nThis is, overall, an interesting paper, attacking an important and also very challenging area. As with all papers in this vein, we are left with having to make a judgement call on whether this simplified scenario is indeed a good first step towards solving the problems we are hoping to solve. Is it developing the right insight, right tools, etc. While I find there is a lot of interesting and good work in this paper, I am not completely convinced about this last point.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper69/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Gradient Descent Learns State Equations with Nonlinear Activations", "abstract": "We study discrete time dynamical systems governed by the state equation $h_{t+1}=\u03d5(Ah_t+Bu_t)$. Here A,B are weight matrices, \u03d5 is an activation function, and $u_t$ is the input data. This relation is the backbone of recurrent neural networks (e.g. LSTMs) which have broad applications in sequential learning tasks. We utilize stochastic gradient descent to learn the weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We prove that SGD estimate linearly converges to the ground truth weights while using near-optimal sample size. Our results apply to increasing activations whose derivatives are bounded away from zero. The analysis is based on i) an SGD convergence result with nonlinear activations and ii) careful statistical characterization of the state vector. Numerical experiments verify the fast convergence of SGD on ReLU and leaky ReLU in consistence with our theory.", "paperhash": "oymak|stochastic_gradient_descent_learns_state_equations_with_nonlinear_activations", "TL;DR": "We study the state equation of a recurrent neural network. We show that SGD can efficiently learn the unknown dynamics from few input/output observations under proper assumptions.", "authorids": ["sametoymak@gmail.com"], "authors": ["Samet Oymak"], "keywords": ["recurrent neural network", "state equation", "gradient descent", "sample complexity"], "pdf": "/pdf/1f44fc9bef164d90075aaa2f444d914ea328a9ac.pdf", "_bibtex": "@misc{\noymak2019stochastic,\ntitle={Stochastic Gradient Descent Learns State Equations with Nonlinear Activations},\nauthor={Samet Oymak},\nyear={2019},\nurl={https://openreview.net/forum?id=rkeMHjR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper69/Official_Review", "cdate": 1542234544867, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkeMHjR9Ym", "replyto": "rkeMHjR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper69/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335642194, "tmdate": 1552335642194, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper69/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}