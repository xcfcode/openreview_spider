{"notes": [{"id": "H1lkYkrKDB", "original": "SJxGOmAOPH", "number": 1826, "cdate": 1569439607118, "ddate": null, "tcdate": 1569439607118, "tmdate": 1577168222447, "tddate": null, "forum": "H1lkYkrKDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["israr.haq@riken.jp", "kawahara@imi.kyushu-u.ac.jp"], "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": ["Israr Ul Haq", "Yoshinobu Kawahara"], "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "TL;DR": "Dynamic information extraction in multivariate time series data", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "keywords": ["Non-linear dynamics", "Convolutional Autoencoder", "Foreground modeling", "Video classification", "Dynamic mode decomposition"], "paperhash": "haq|universal_modal_embedding_of_dynamics_in_videos_and_its_applications", "original_pdf": "/attachment/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "_bibtex": "@misc{\nhaq2020universal,\ntitle={{\\{}UNIVERSAL{\\}} {\\{}MODAL{\\}} {\\{}EMBEDDING{\\}} {\\{}OF{\\}} {\\{}DYNAMICS{\\}} {\\{}IN{\\}} {\\{}VIDEOS{\\}} {\\{}AND{\\}} {\\{}ITS{\\}} {\\{}APPLICATIONS{\\}}},\nauthor={Israr Ul Haq and Yoshinobu Kawahara},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lkYkrKDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "J5FabpB6SM", "original": null, "number": 1, "cdate": 1576798733396, "ddate": null, "tcdate": 1576798733396, "tmdate": 1576800903046, "tddate": null, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "invitation": "ICLR.cc/2020/Conference/Paper1826/-/Decision", "content": {"decision": "Reject", "comment": "The paper focuses on extracting the underlying dynamics of objects in video frames, for background/foreground extraction and video classification. Generally speaking, the presentation of the paper should be improved. Novelty should be clarified, contrasting the proposed approach with existing literature. All reviewers also agree the experimental section is also too weak in its current form.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["israr.haq@riken.jp", "kawahara@imi.kyushu-u.ac.jp"], "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": ["Israr Ul Haq", "Yoshinobu Kawahara"], "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "TL;DR": "Dynamic information extraction in multivariate time series data", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "keywords": ["Non-linear dynamics", "Convolutional Autoencoder", "Foreground modeling", "Video classification", "Dynamic mode decomposition"], "paperhash": "haq|universal_modal_embedding_of_dynamics_in_videos_and_its_applications", "original_pdf": "/attachment/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "_bibtex": "@misc{\nhaq2020universal,\ntitle={{\\{}UNIVERSAL{\\}} {\\{}MODAL{\\}} {\\{}EMBEDDING{\\}} {\\{}OF{\\}} {\\{}DYNAMICS{\\}} {\\{}IN{\\}} {\\{}VIDEOS{\\}} {\\{}AND{\\}} {\\{}ITS{\\}} {\\{}APPLICATIONS{\\}}},\nauthor={Israr Ul Haq and Yoshinobu Kawahara},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lkYkrKDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726141, "tmdate": 1576800278206, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1826/-/Decision"}}}, {"id": "Syl2HTO2tB", "original": null, "number": 1, "cdate": 1571749188095, "ddate": null, "tcdate": 1571749188095, "tmdate": 1572972418740, "tddate": null, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "invitation": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper considers the problem of extracting the underlying dynamics of objects in video frames. The paper focuses on two major applications: background/foreground extraction and video classification. The paper proposes a method that first obtains latent vectors from a video sequence by training a neural network and then applies dynamic mode decomposition (by Schmidt, 2010). \n\nThe paper is not well written and even after reading it the second time I, unfortunately, have difficulties understanding the exact contributions and experiments.\nHere are concrete examples that lead to this critique:\n- Section 2: Letters are not defined (e.g., \\mathcal F is not defined when first used), and sentences are not finished and/or do not make sense.\n- Sec. 5.1: not clear whether the experiment is only done for one sequence or for many. If done on only one sequence, this is not sufficient to demonstrate that the method works well, if done on more than one then the results are not reported.\n- Conclusion: States that ``this method can be applied to any multivariate-time series data to extract complex and non-linear dynamics''. That statement sounds overlay general given the experimental evaluation."}, "signatures": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["israr.haq@riken.jp", "kawahara@imi.kyushu-u.ac.jp"], "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": ["Israr Ul Haq", "Yoshinobu Kawahara"], "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "TL;DR": "Dynamic information extraction in multivariate time series data", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "keywords": ["Non-linear dynamics", "Convolutional Autoencoder", "Foreground modeling", "Video classification", "Dynamic mode decomposition"], "paperhash": "haq|universal_modal_embedding_of_dynamics_in_videos_and_its_applications", "original_pdf": "/attachment/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "_bibtex": "@misc{\nhaq2020universal,\ntitle={{\\{}UNIVERSAL{\\}} {\\{}MODAL{\\}} {\\{}EMBEDDING{\\}} {\\{}OF{\\}} {\\{}DYNAMICS{\\}} {\\{}IN{\\}} {\\{}VIDEOS{\\}} {\\{}AND{\\}} {\\{}ITS{\\}} {\\{}APPLICATIONS{\\}}},\nauthor={Israr Ul Haq and Yoshinobu Kawahara},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lkYkrKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575677938979, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1826/Reviewers"], "noninvitees": [], "tcdate": 1570237731745, "tmdate": 1575677938995, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review"}}}, {"id": "rJxRE-91cS", "original": null, "number": 2, "cdate": 1571950901919, "ddate": null, "tcdate": 1571950901919, "tmdate": 1572972418704, "tddate": null, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "invitation": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "I found the topic of this paper interesting and I believe I understand what the authors are trying to achieve but I'm afraid this was after several readings and I do think the paper could be presented differently that would make it more accessible. My suggestion would be to explain how the model will be applied first (identify the required properties) to motivate the need for the learned basis and then present the DMD as a method for providing a basis that meets the properties required. I acknowledge that different communities have different styles of presentation so apologies if this is just me.\n\nFirst I would just like to check that I have understood correctly so please could the authors point out if I have missed something or misunderstood in the following?\n\nOur goal is to establish a basis invariant to the video dynamics that can then be used, for example, to partition the video into parts with differing dynamics - e.g. foreground/background. To do this we need to identify such a basis from a specific video - we will use the collection of pairs of neighboring frames.\n\nThe Koopman operator acts on a differential system to identify a function space invariant to the dynamics. If we instantiate this with a finite number of dimensions we can essentially establish the invariance as an eigenvalue problem. From this and our pairs of successive videos we can establish a vector basis for the space and then project the video into this basis. The spectral properties of the coefficients of the projection will determine whether something is static (omega = 0) or transitory in the scene and these can be used to identify foreground and background.\n\nNext there is the issue that this method operates in a linear domain with something like Gaussian noise which is not a good fit for image space videos so the authors propose to identify the dynamics in a linear latent space determined by an autoencoder to handle the non-linear mapping to image space.\n\nI hope I have understood the main points?\n\nIf this is the case, I think that much more needs to be said about the second part, which is the essential novelty of the paper, with a discussion of the merits of different approaches and full details - at the moment there is just one small paragraph at the end of 4.2 which contains the majority of the contribution.\n\nMy main concern about the paper is that I find it very difficult to appreciate the efficacy of the method given the current presentation of the results. There are no error bars to ascertain significance for any of the results and the summarization of multiple experiments to a single percentage gives very little insight into where this method works and where it doesn't. There are a number of ways that a dynamic prior could be added to a latent space and it is unclear why we would expect this approach to be preferred given the evidence presented in the paper.\n\nOther Notes:\n\nI found that the notation is not always consistent and sometimes could be simplified - it is unclear whether some operators are convolutions or multiplications (vector or scalar). To me the asterisk does not represent straight forward multiplication but it might be being used for this?\n\nCould Table 1 be placed in the experiments section rather than in the middle of page 5?\n\nDo the authors mean half the number of pixels or half the edge size (e.g. a quarter of the area) in terms of the latent space?\n\nPlease can all equations be numbered so that they can be referred to - there are no equation numbers in all of section 2."}, "signatures": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["israr.haq@riken.jp", "kawahara@imi.kyushu-u.ac.jp"], "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": ["Israr Ul Haq", "Yoshinobu Kawahara"], "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "TL;DR": "Dynamic information extraction in multivariate time series data", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "keywords": ["Non-linear dynamics", "Convolutional Autoencoder", "Foreground modeling", "Video classification", "Dynamic mode decomposition"], "paperhash": "haq|universal_modal_embedding_of_dynamics_in_videos_and_its_applications", "original_pdf": "/attachment/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "_bibtex": "@misc{\nhaq2020universal,\ntitle={{\\{}UNIVERSAL{\\}} {\\{}MODAL{\\}} {\\{}EMBEDDING{\\}} {\\{}OF{\\}} {\\{}DYNAMICS{\\}} {\\{}IN{\\}} {\\{}VIDEOS{\\}} {\\{}AND{\\}} {\\{}ITS{\\}} {\\{}APPLICATIONS{\\}}},\nauthor={Israr Ul Haq and Yoshinobu Kawahara},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lkYkrKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575677938979, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1826/Reviewers"], "noninvitees": [], "tcdate": 1570237731745, "tmdate": 1575677938995, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review"}}}, {"id": "SyeTbYISqH", "original": null, "number": 3, "cdate": 1572329732999, "ddate": null, "tcdate": 1572329732999, "tmdate": 1572972418658, "tddate": null, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "invitation": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an application of convolutional autoencoder networks and a nonlinear dynamic systems analysis method known as extended dynamic mode analysis (EDMD) to a data-driven analysis of multivariate time series.  \nThe DMD method appears to be well-known in the physics community but is outside my area of expertise and unfortunately I have limited time to make a quick study of it.  However, from what I gather, it involves empirical approximation of a nonlinear dynamical system as a high-dimensional linear dynamical system, which in turn enables analysis in terms of eigendecomposition of the resulting linear operator, revealing basic modes of the dynamics.   In the proposed method, DMD is used in the latent representations of a convolutional autoencoder for image sequences.   The DMD objective is incorporated into the autoencoder training loss to minimize its reconstruction error.    The DMD is also used, by conditioning on the eigenvalues, to split the reconstruction into high frequency (quickly varying) foreground modes and low-frequency (slowly varying) background modes.   Although end-to-end training is mentioned, it is not made clear how the derivatives of the DMD decomposition are implemented, especially considering that the DMD involves an SVD, which can have unstable/ singular derivatives when two or more singular values are close to the same / exactly the same.   The resulting methods are applied to a foreground extraction and a classification tasks, and compared with numerous baselines.  It is not clear to me what the state of the art is on these tasks, but the proposed methods compare favorably to reported baselines, and the images of results look convincing.   However the experimental results seem a little thin and I would expect a more thorough study.  Overall the method looks very interesting.  \n\nSome complaints:\n -  the tables are a bit sloppy and should be formatted to fit in the document with normal sized fonts, \n - the images are too small to see well.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1826/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["israr.haq@riken.jp", "kawahara@imi.kyushu-u.ac.jp"], "title": "UNIVERSAL MODAL EMBEDDING OF DYNAMICS IN VIDEOS AND ITS APPLICATIONS", "authors": ["Israr Ul Haq", "Yoshinobu Kawahara"], "pdf": "/pdf/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "TL;DR": "Dynamic information extraction in multivariate time series data", "abstract": "Extracting underlying dynamics of objects in image sequences is one of the challenging problems in computer vision. On the other hand, dynamic mode decomposition (DMD) has recently attracted attention as a way of obtaining modal representations of nonlinear dynamics from (general multivariate time-series) data without explicit prior knowledge about the dynamics. In this paper, we propose a convolutional autoencoder based DMD (CAE-DMD) that is an extended DMD (EDMD) approach, to extract underlying dynamics in videos. To this end, we develop a modified CAE model by incorporating DMD on the encoder, which gives a more meaningful compressed representation of input image sequences. On the reconstruction side, a decoder is used to minimize the reconstruction error after applying the DMD, which in result gives an accurate reconstruction of inputs. We empirically investigated the performance of CAE-DMD in two applications: background/foreground extraction and video classification, on publicly available datasets.", "keywords": ["Non-linear dynamics", "Convolutional Autoencoder", "Foreground modeling", "Video classification", "Dynamic mode decomposition"], "paperhash": "haq|universal_modal_embedding_of_dynamics_in_videos_and_its_applications", "original_pdf": "/attachment/f0e33eabea4e03123a86c53114cd47d675796e79.pdf", "_bibtex": "@misc{\nhaq2020universal,\ntitle={{\\{}UNIVERSAL{\\}} {\\{}MODAL{\\}} {\\{}EMBEDDING{\\}} {\\{}OF{\\}} {\\{}DYNAMICS{\\}} {\\{}IN{\\}} {\\{}VIDEOS{\\}} {\\{}AND{\\}} {\\{}ITS{\\}} {\\{}APPLICATIONS{\\}}},\nauthor={Israr Ul Haq and Yoshinobu Kawahara},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lkYkrKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lkYkrKDB", "replyto": "H1lkYkrKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1826/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575677938979, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1826/Reviewers"], "noninvitees": [], "tcdate": 1570237731745, "tmdate": 1575677938995, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1826/-/Official_Review"}}}], "count": 5}