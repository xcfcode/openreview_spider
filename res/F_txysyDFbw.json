{"notes": [{"id": "F_txysyDFbw", "original": "A0Lw6t2AOa", "number": 2314, "cdate": 1601308255175, "ddate": null, "tcdate": 1601308255175, "tmdate": 1614985740398, "tddate": null, "forum": "F_txysyDFbw", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "9r7HVjUqjwJ", "original": null, "number": 1, "cdate": 1610040397804, "ddate": null, "tcdate": 1610040397804, "tmdate": 1610473993253, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a promising solution to a very interesting and challenging problem, and the authors have improved the paper during the rebuttal by adding an important missing baseline. However, all reviewers still agree that the paper currently lacks sufficient analysis that would be required to understand properly the implications of past history on the regret. More specifically, the fact that assumption A2 does not apply to the given problem raises questions that should be addressed before publication. Theoretical analysis was provided for previous similar work (e.g. NeuralUCB). Providing this for the proposed method would significantly improve the impact of this work."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040397791, "tmdate": 1610473993237, "id": "ICLR.cc/2021/Conference/Paper2314/-/Decision"}}}, {"id": "RCLeEdHmO3w", "original": null, "number": 3, "cdate": 1604303750010, "ddate": null, "tcdate": 1604303750010, "tmdate": 1606677762339, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review", "content": {"title": "A challenging problem but a simple solution without theoretical guarantees", "review": "The paper proposed a neural-bandit approach using Thomson sampling for leveraging the DNN\u2019s non-linear representation. There is a growing interest in using Multi-armed Bandits with DNN in an end-to-end learning fashion but the difficulty of the understanding how the representation is learned in DNN, makes this problem a very challenging and interesting one. The paper proposes one solution to consider explore-exploit tradeoff in the non-linear DNN space. There is still several unanswered questions in this paper and leave the readers with more confusion than clarify. This is not because the paper is not written properly but the topic is fairly new and a very few works have considered this problem setting. The likelihood matching seems interesting idea but I couldn\u2019t find a reason whether it contributed to reward boost compared to using all the history. Some of the claims in the paper is demonstrated experimentally, not theoretically. Please clarify the following questions to understand the paper better. \n  \n### Major Questions:\n\n* The realizability assumption A2 doesn\u2019t seems to apply here as the history of the decisions (stored in the replay buffer) is used to update the representation. \n\n* The paper says $\\mu$ is assumed to be fixed in this problem, even before the representation is known. As we update the representation,$\\mu$ for the new representation varies and cannot be fixed.\n\n* Memory is poorly used without any significance to past decisions that are somehow key to changing the reward distribution or representation or both.\n\n* Unlike in the earlier work (Zhou et. Al), no theoretical guarantees have been provided. As in the earlier work, Network width/depth based guarantees can be used to show how the representation affects the realization assumption.\n\n* It is unclear why Alg 3 with limited memory outperforms Alg 2 with Full memory (stores all the past decisions) on both linear and non-linear datasets (Mushroom, Financial, Statlog, Epileptic). Please clarify.\n\n### Minor Questions:\n\n* $\\Phi_0$ was introduced before explaining about the likelihood matching. I suggest moving the updates at the end.\n\n* It would be beneficial for the paper if an additional experiment on how varying the size of the memory buffer affect the cumulative rewards\n\n* The paper claims that the linear models work only for \u201dmedium-sized\u201d inputs (with around 1000 features) due to numerical issues. Can you provide any further analysis on this? Perhaps varying the dim d vs cumulative rewards for linear vs Neural linear would demonstrate this claim. If there is an earlier work that did this, the citation would suffice.\n\nI have read the author's comments and I stand with my previous rating. I believe the paper addresses an interesting problem but lacks sufficient analysis due to the realizability assumption A2 which doesn't apply for the given problem and the other reviewers feel the same way. Unlike in online learning and MAB, the memory used by the proposed Neural-linear bandit significantly deviates from the A2 assumption. These should have been analyzed empirically or theoretically to understand the impact of the past history on the regret. ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2314/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2314/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099229, "tmdate": 1606915771961, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2314/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review"}}}, {"id": "hwOnkvClPw0", "original": null, "number": 8, "cdate": 1606238706401, "ddate": null, "tcdate": 1606238706401, "tmdate": 1606238706401, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Official_Comment", "content": {"title": "Updated paper", "comment": "We compared our algorithm against NeuralUCB, provided in Table 1 in the updated paper. We used the code provided by the authors in https://github.com/ZeroWeight/NeuralTS.\nAt the updated table we compare our online version algorithm against NeuralUCB while the old results are provided at the supplementary. Please note that columns of algorithms (3) and (4) in the new table correspond to the online version.\nWe also update the paper according to the helpful rejects of the reviewers that could be handled at the time frame of the rebuttal."}, "signatures": ["ICLR.cc/2021/Conference/Paper2314/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "F_txysyDFbw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2314/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2314/Authors|ICLR.cc/2021/Conference/Paper2314/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849865, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2314/-/Official_Comment"}}}, {"id": "fncmMjGKqi_", "original": null, "number": 4, "cdate": 1606026958743, "ddate": null, "tcdate": 1606026958743, "tmdate": 1606026958743, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Official_Comment", "content": {"title": "General comment for all of the reviewers ", "comment": "We would like to thank the reviewers for their constructive feedback. Below we address the main concerns that were raised by the reviewers:\n\n1. Comparison to NeuralUCB (Zhou et al.): Our work is not an alternative to the NeuralUCB algorithm but a complementary idea. Our focus is on the representation shift that the agent occurs during learning (under memory limitations). The theoretical analysis in Zhou et al. is a great contribution to the field, but it addresses the regret of the algorithm under the NTK assumptions and does not address this phenomena. We will add an empirical comparison of our approach to the  NeuralUCB method. \n\n2. The realizability assumption (A2): As mentioned in the paper, this assumption is indeed strong and we are not sure if it will hold in the real world. That said, analyzing the problem under this assumption is what motivated us to design an algorithm that performs well on real-world data sets. This is also true for the standard realizability assumption: it motivated many interesting and well analyzed algorithms that work well in practice, while it's unclear if the assumption itself holds with real data. \n\n3. Full memory neural-linear TS results - We are aware that in some of the experiments our memory-limited approach achieves better results against the full-memory version. This can be explained by the fact that sometimes you may benefit from forgetting as your past decisions may lead to the use of a sub-optimal policy. \n\n4. Ablation experiment of memory size -  great idea, will add them to the main paper. \n\nWe will rewrite the paper in order to add/fix these issues and other notes that the reviewers mentioned. \n\nWe want to thank you again for the informative review, the authors. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2314/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "F_txysyDFbw", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2314/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2314/Authors|ICLR.cc/2021/Conference/Paper2314/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849865, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2314/-/Official_Comment"}}}, {"id": "aCDcv23Ltp8", "original": null, "number": 1, "cdate": 1603702851922, "ddate": null, "tcdate": 1603702851922, "tmdate": 1605024240537, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review", "content": {"title": "The paper proposes the limited-memory neural-linear bandit algorithm. Neural-linear bandit extends the linear bandit algorithm by allowing a deep neural network for estimating the reward function from a given context. It uses the last layer in the DNN as the nonlinear representation and do Thompson sampling based exploration on the last linear layer. The paper proposes the technique to handle limited memory, avoiding saving a large amount of historical information in the memory.", "review": "The main contribution of the paper is the likelihood matching method for dealing with the catastrophic forgetting and save the memory usage. The empirical results demonstrate that the proposed method achieves good results comparing to other baselines.\n\nHowever, the paper has several issues, as discussed below.\n\n- The paper lacks the theoretical result on their algorithm. It is understandable that an algorithm based on DNN may be hard to analyze. But the NeuralUCB algorithm of Zhou et al. (2019) does provide a theoretical regret analysis, even though NeuralUCB is also based on a DNN. Therefore, at least some more discussions and comparisons are needed. What are the difficulties for the regret analysis comparing to NeuraUCB? In general, a more detailed comparison with NeuralUCB is needed, also see the empirical evaluation part below.\n\n- The realizability assumption (Assumption 2) on the DNN is quite strong. It requires that ANY representation \\phi produced by DNN is realizable, that is, have a corresponding unknown but fixed parameters \\mu_i that could generate the reward of i with representation \\phi(t) by a linear combination. The authors only mention that the assumption is too strong to hold in practice, but it does allow their algorithm to perform well in many problems. So what is the reason behind? is there any way to relax it and make it more reasonable? It is difficult to accept an approach that is based on an impossible assumption. I think this is linked to the underlying principle of the proposed approach. The DNN is part of the proposed algorithm that needs to be constructed and tuned from data, but when taking its last year for TS exploration, it seems that the authors are treating this entire DNN as given by the environment, as a transformation from the context b(t) to a representation \\phi(t), and thus making an assumption patterned from the Assumption 1 for linear bandit, which is entirely on the environment. This mixing of algorithm and environment creates the difficulty of both justifying the assumption and carrying out the analysis I believe. I hope that the authors could provide more discussions on this important point. Is there any way to alleviate this, such as considering a class of DNNs so that such a realizability assumption could be supported?\n\n- For the empirical comparison, the authors do not compare the NeuralUCB algorithm in Zhou et al. 2019. In fact, this paper already appears in ICML'2020. Since Thompson Sampling and UCB are two main approaches for stochastic MAB, it is important to compare the Neural-Linear algorithm of the current paper with NeuralUCB algorithm, both analytically and empirically. Moreover, I do not understand a result reported in Figure 2. In this figure, it shows that the Neural-linear TS with full memory performs much worse than Neural-Linear TS with finite memory. How could this be? To me the finite memory algorithm (proposed in the paper) is an approximation of the full memory version. It only gains in saving memory, but why could it also win in reward?\n\n- The writing of the paper is not entirely clear. Some technical parts of the paper is not easy to follow. For example, at the beginning of Page 4, it starts to use notations \\Phi_i and \\Phi^0_i, but they are not defined. Then \\Phi_i appears in Eq.(2), seemingly to be a definition, but \\Phi^0_i is still not defined. It turned out that at the end of this page, \\Phi^0_i is discussed as the correlation matrix connecting the new features with the old ones. But it still does not look like a solid technical definition to me. Without a clear definition up front on these key notations, it is very hard to understand the entire logical flow. Also, in line 3 of Page 4 mentions the noise parameter \\nu in Alg. 1, but there is no such parameter in the Alg. 1 pseudocode. I am guessing it is the v in the pseudocode. The authors need to provide rigorous technical definitions and the logical flow to help readers understand their approach. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2314/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2314/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099229, "tmdate": 1606915771961, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2314/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review"}}}, {"id": "8LqK2_hA3eI", "original": null, "number": 2, "cdate": 1603723951626, "ddate": null, "tcdate": 1603723951626, "tmdate": 1605024240465, "tddate": null, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "invitation": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review", "content": {"title": "Review Online Limited Memory Neural-Linear Bandits", "review": "Online Limited Memory Neural-Linear Bandits\nThe presented paper suggests a method for neural linear bandits that use limited memory. The memory limit is introduced by forgetting past observations and fitting the likelihood of the data under moments constraints using a semi definite program. The paper presents an interesting approach to a relevant problem but lacks novelty. Moreover, the presentation of the paper needs improvement (i.e. figures are not readable and results should be highlighted better in the tables). The paper needs another pass to correct writing mistakes and errors in the mathematical formulas. \n\nIntroduction:\nRepresentation change -> representation changes\nThe are -> there are\nWhat do you mean by computational problems? \nPlease change the citation style (no parentheses)\nWhat do you mean by \u201cpatch-based\u201d?\n\n\nBackground: \nFirst equation: what do you mean by \\sim? Is this rather \\propto?\nPlays the arm that maximises -> use \\tilde{\\mu} here\n\nLimited memory NL TS\nThe part on exploration is not clear, please improve readability\nInv-Gamma(a,b) you use a and b here (like action and context), please change notation\n\nExperiments: \nPlot is not readable\nTable would be better if best were highlighted in bold\n\nRate Control: \nPlot not readable\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2314/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2314/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Limited Memory Neural-Linear Bandits", "authorids": ["~Tom_Zahavy2", "~Ofir_Nabati1", "liorcohen5@gmail.com", "~Shie_Mannor2"], "authors": ["Tom Zahavy", "Ofir Nabati", "Leor Cohen", "Shie Mannor"], "keywords": [], "abstract": "We study neural-linear bandits for solving problems where both exploration and representation learning play an important role. Neural-linear bandits leverage the representation power of deep neural networks and combine it with efficient exploration mechanisms, designed for linear contextual bandits, on top of the last hidden layer. Since the representation is optimized during learning, information regarding exploration with \u201cold\u201d features is lost. We propose the first limited memory neural- linear bandit that is resilient to this catastrophic forgetting phenomenon by solving a semi-definite program. We then approximate the semi-definite program using stochastic gradient descent to make the algorithm practical and adjusted for online usage. We perform simulations on a variety of data sets, including regression, classification, and sentiment analysis. In addition, we evaluate our algorithm in a challenging uplink rate-control application. The bandit controls the transmission rates of data segments over cellular links to achieve optimal throughput. We observe that our algorithm achieves superior performance and shows resilience to catastrophic forgetting.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zahavy|online_limited_memory_neurallinear_bandits", "pdf": "/pdf/f89c0e486a0c19a6ef3826cd81cfbba903c84310.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=XGTzhXjYP7", "_bibtex": "@misc{\nzahavy2021online,\ntitle={Online Limited Memory Neural-Linear Bandits},\nauthor={Tom Zahavy and Ofir Nabati and Leor Cohen and Shie Mannor},\nyear={2021},\nurl={https://openreview.net/forum?id=F_txysyDFbw}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "F_txysyDFbw", "replyto": "F_txysyDFbw", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2314/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099229, "tmdate": 1606915771961, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2314/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2314/-/Official_Review"}}}], "count": 7}