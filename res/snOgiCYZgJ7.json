{"notes": [{"id": "snOgiCYZgJ7", "original": "8UbKwZZmmHu", "number": 2126, "cdate": 1601308234184, "ddate": null, "tcdate": 1601308234184, "tmdate": 1612420248419, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "59XzXb_Rd1f", "original": null, "number": 1, "cdate": 1610040418644, "ddate": null, "tcdate": 1610040418644, "tmdate": 1610474017111, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "Four knowledgeable referees support acceptance for the contributions, and I also recommend acceptance. There is agreement among all reviewers that this paper is about  a highly relevant topic, that the model presented is technically sound and has significantly novel aspects, and that the experimental results are convincing. There were several points of criticism raised by the reviewers, concerning, for instance, further comparison experiments,  the heuristic nature of masking rules, or the treatment of homologous sequences. In my opinion, however, most of these points have been addressed in a rather convincing way during the rebuttal phase.  "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040418630, "tmdate": 1610474017095, "id": "ICLR.cc/2021/Conference/Paper2126/-/Decision"}}}, {"id": "ezVW2nuJ7dj", "original": null, "number": 9, "cdate": 1606176806270, "ddate": null, "tcdate": 1606176806270, "tmdate": 1606176806270, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "Regarding the comparison to Infernal", "comment": "As two of our reviewers (R2, R4) suggested , it is worth considering a comparison to Infernal (Nawrocki and Eddy. 2013), to which our hierarchical approach shares certain similarity due to the modelling of RNA secondary structure using stochastic context free grammar (SCFG). \n\nIn Infernal, the use of SCFG leads to the so-called covariance model (CM), which can be understood as an adaption of profile HMM to the tree-like structure of nested RNA secondary structures. And much similar to the idea of searching new DNA/protein sequences with a profile HMM, which extends simple position specific scoring with insertions and deletions around a consensus sequence that captures conserved positions and residues in a multiple sequence alignment (MSA), **a CM is built around a consensus RNA secondary structure** that models conservation of base-pairs (covariation of paired nucleotides) with an essentially tree-structured HMM. \n\nTherefore, a CM is mostly used to search new membership in a sequence database, which belongs to a highly conserved RNA family, or to align sequences to make secondary structure predictions. On the other hand, as a generative model, we can also sample from a CM model to obtain an RNA sequences along a parse tree which should represent its secondary structure, which as we understand is where the suggestions of comparison have come from.\n\nConceptually, there are several issues with this evaluation approach:\n1. A CM reflects the consensus secondary structure of a conserved RNA family which itself is built on, therefore all sampled structures from this CM will have by and large similar secondary structures, hence of low structural diversity.\n2. A CM captures covariation of paired bases, and it alone is not good at predicting RNA folding, unless the RNA family is highly conserved. Therefore, sampled structures have no guarantee of folding stability.\n\nWe have also attempled to build a CM model using our datasets, using procedures:\nMAFFT (randomly selected 3000 sequences) --> RNAalifold --> cmbuild (infernal) --> cmemit (infernal samples)\nwhere MAFFT is used to obtain MSA of RNAs (sliced short snippets in the unlabeled dataset, or oligonucleotides in the labeled RNAcompete-S dataset), and RNAalifold is used to obtain consensus secondary structure.\n\nOur attempts always failed at steps 1 or 2. The consensus secondary structure predicted by RNAalifold does not contain any conserved columns, simply due to the fact that both datasets lack homologous sequences. The outcome is that all sampled RNAs from these CMs are single stranded.\n\nHowever, a comparison set-up with Infernal will become more meaningful, once we move our approach to RFAM and its many conserved RNA families. We consider it a very important direction, which we have indicated in the revised manuscript. We also thank the reviewers for pointing out Infernal."}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "_BEPdG5sPEZ", "original": null, "number": 4, "cdate": 1603966536929, "ddate": null, "tcdate": 1603966536929, "tmdate": 1606134295792, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review", "content": {"title": "Interesting work; needs more clarification", "review": "**Summary**\nThe work studies of the problem of jointly modelling RNA sequence and secondary structure using the framework of variational autoencoders. Several encoder and decoder architectures with increasing inductive bias for RNA structures are proposed. These are compared on two novel RNA sequence datasets and supervised and unsupervised RNA generation tasks.\n\n**Score justification**\nThe work presents a comparison of several interesting approaches to the problem of joint modelling of RNA structure and sequence using VAEs. Encoders and decoders that make use of (i) RNA sequence and structure in a string representation; (ii) in a graph representation; and (iii) in a junction tree representation are considered. This works particularly well on the encoder side, where the appropriate deep learning architectures are used; but becomes considerably less elegant on the decoder side, where the authors have to make use of sample masking with complex rules to prevent generation of invalid sequence-structure combinations. Furthermore it is not immediately clear from the empirical evaluation that the added complexity of the HierVAE, or that using VAEs are an optimal choice for the supervised generation task.\n\n\n**Major comments**\n* As noted by the authors, their decoders (linearized sequence and structure, as well as the hierarchical decoder) may generate invalide sequence-structure combinations. To eliminate this possibility the authors restrict the autoregressive decoder from sampling invalid sequence-structures by masking out some samples using a number of heuristic rules. First of all, it is unclear from the text whether this is also done during training and how the probabilities at masked stages are treated (are they re-normalized after the masking is applied?)\n* I appreciate that the authors include a comparison between decoding with and without the heuristic masking rules. Could the authors explain why the FE DEV in Table 1 is lower for samples produced without the masking rules (unconstrained generation)? This result seems counter-intuitive.\n* From the results in Table 1 it is still difficult to tease apart the relative contributions of (i) model training; (ii) inductive bias of decoder architecture; and (iii) decoding constraints. I would appreciate it if the authors also included decoding results for untrained decoders with and without constraints.\n* Comparing the AUC ROC in Table 2 to the results in Tables S2 and S3 it is not obvious what the benefit of using a VAE setup for the supervised problem is. The purely supervised approach is conceptually and technically easier.\n* I am a bit skeptical about the results presentable in Table 3 and section \"Targeted RNA design\" - judging improvement of a sequence using a different classifier trained on the same data is not very convincing. Ideally, empirical wet lab validation should be carried out for the improved designs; but absent that it would be great to see a more independent/less correlated evaluation. Perhaps the authors could demonstrate a reduction of edit distance of an improved negative test set sequence to a positive (test set / train set) sequence?\n* When generating the dataset for the unsupervised RNA modelling task the authors take human transcripts and draw random short (32 to 512 nucleotide) sequences from them for their dataset. Since the authors introduce a new dataset it would great to see more information about its composition - which kind of RNAs compose the dataset (e.g. mRNA, tRNA, lincRNA, shRNA, rRNA, etc); does this include alternatively spliced RNA (i.e. could there be leakage between the training and holdout sets)? What is the reasoning between random slicing of the RNAs into shorter sequences? Are the smaller RNA slices biologically plausible/relevant?\n* Could the authors provide additional justification / ablations of the choice of $\\beta \\ll 1$? How do the models behave if KL annealing is not used?\n\n\n**Minor comments**\n* The abstract states \"the design of large scale and complex biological structures *requires* dedicated graph-based deep generative modelling techniques\", which I believe is a too strong statement. These techniques work better right now, but does not mean that they are required (and the only appropriate way forward).\n* In \"Task Description\" section: \"functional properties *or* RNA\" -> \"functional properties of RNA\"\n* Is Figure 1 using some domain-specific terminology? It refers to cliques, but the nucleotides put into boxes are not all fully connected.\n* Why doesn't constrained generation (Table 2) achieve 100% validity? It seems to me that it should be possible at least for the linearized sequence-structure decoder.\n* Apologies if I missed it in the text, but what does \"RECON ACC \" in Table 2 refer to?\n* Incorrect opening quotes used for \"ground truth\" in section \"Targeted RNA design\"\n* In Appendix A there is \"$j > j$\"\n* In Appendix B: \"in-vitro\" -> \"*in vitro*\" and probably in italic\n* Why is FE DEV defined as the absolute value? Should not the MFE structure always have smaller Free Energy than any structure output by the model?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103476, "tmdate": 1606915777812, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2126/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review"}}}, {"id": "13399ES2qFf", "original": null, "number": 7, "cdate": 1605641512675, "ddate": null, "tcdate": 1605641512675, "tmdate": 1605641512675, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "u1mN0RVn0oV", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "We thank the reviewer for the constructive feedbacks!", "comment": "* Indeed we agree with the reviewer that it is hard to evaluate our models, and comparison to existing tools are lacking for a more comprehensive evaluation. The reasons why we have not considered Infernal or other RNA inverse design methods are as follow:\n   * For the comparison with Infernal, a covariance model needs to be built on top of the multiple sequence alignment in an RNA family. However, due to the lacking of homology information in either unsupervised or semi-supervised setting, the multiple sequence alignment is of poor quality and the generated sequence are not useful, nor do they form a reasonable comparison to our design RNA structures since Infernal does not actively fold RNA structures.\n   * Concerns with the other thermodynamic models are that they lack internal representation, nor are they learning based, which can result in unfair comparison with our approach since they can query the underlying thermodynamics system which we have used as an \"oracle\" to evaluate the quality of our generated RNA secondary structures. Besides, these are conditional models that search sequences that can fold into given secondary structures, as compared to our work which considers a joint distribution over sequences and structures.\n    \n    That being said, we are still searching for an adequate comparison set-up which will very likely make up our future works.\n\n* For the pairwise comparison between decoded RNA structures and their corresponding minimum free energy structures, we included figure S3 in the appendix. It turns out that as we walk in the latent space, both decoded structures and their corresponding MFE structures evolve smoothly. \n* We thank the reviewer for this important concern and we hope to clarify any misunderstanding here.\n\n   The main objective of our VAE model is to learn the grammar of RNA secondary structures and the dynamics of RNA folding so that generated RNA structures are valid and stable. We also seek to organize the latent space of RNA representation as in the semi-supervised generation setting, to reflect certain functional properties such as protein interaction.\n\n    The other concern that our model may become a functional approximator of RNAfold is a good one. We mainly use RNAfold as an \u201coracle\u201d which is to be frank very far from perfect since predicting RNA folding is still an open question. That being said, our unsupervised dataset has also relied on RNAfold to annotate the secondary structures, which is a limitation and the reason why we did not use experimentally observed data (e.g. on RFAM) is simply because our current evaluation measure cannot explain the observed data well.\n\n    However, one major advantage lies in that our deep generative approach is not restricted to any thermodynamics models and it can learn directly from observed data, which is an immediate step we will explore in the next step. And of course, we would also need to identify better evaluation measures.\n* We added Figure S4 which samples RNAs around a Cys-tRNA.\n* Compared to the RNAcompete dataset which mainly consists of weakly structured RNAs, RNAcompete-S features higher structural diversity and its primary focus is to investigate the roles played by RNA secondary structures in RNA protein interaction.In addition to the reviewer\u2019s comment that sequence model should have the capability of inferring secondary structures after seeing enough training examples, which may well explain why the inclusion of secondary structures does not tend to improve the accuracy, another plausible explanation may be the noise contained in the RNAcompete-S dataset due to the protocol only involves a single selection steps which cannot differentiate RNAs with high and low binding affinities.\n\n    We thank the reviewer for providing this explanation which we have added into the manuscript. As a future direction, we will investigate datasets curated from other experimental approaches such RNA Bind-n-seq and HTR-SELEX.\n* The latent space is meaningful in the sense that (1) similar latent encodings translate to similar RNA sequence and secondary structures, and (2) under the semi-supervised setting the latent space is organized to reflect properties of RBP bindings. Due to limitations posed by our datasets which do not contain non-coding RNA families, we believe our current VAE model cannot capture such information since it is never learnt. However, it may be salvaged by considering a dataset curated from RFAM coupled with new learning techniques, which is included in our next step.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "_ycnFLoEIR_", "original": null, "number": 6, "cdate": 1605639246979, "ddate": null, "tcdate": 1605639246979, "tmdate": 1605639246979, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "ntTCg-4BgyX", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "Thanks for the important suggestions and please refer to our answers below.", "comment": "Address to the comments in Cons\n* The unlabeled dataset used for unsupervised generation is obtained from the human transcripts by randomly slicing messenger RNAs into short and unique RNA snippets (32-512ns). Therefore, there do not tend to exist homologous sequences in this dataset. The labeled dataset acquired from RNAcompete-S consist of oligonucleotides (uniformly 40 nts) synthesized for in vitro experiments which are not derived from common ancestors, therefore there is also no such notion of homology in this dataset.\n* For the sampled RNAs from the dataset which comprise the null distribution, their FE DEV, Normed would be uniformly 0 since they already have the minimum free energy structures. We can add a footnote pointing this out, since having a null comparison can indeed be quite useful.\n* The valid structures considered in our study are ones that have canonical and nested basepairs. However, even if an RNA sequence has folded into a \u201cvalid\u201d secondary structure as defined above, it is not necessarily as stable as the minimum free energy structure, which will be the primary concern for potentially failing the biophysical simulation.\n* Building a covariance model with Infernal requires starting from a multiple alignment of several members of an RNA family. This is problematic in our setting, because for example in the supervised dataset, the positive sequences are not homologous to each other (i.e. they are not derived from a common ancestor, but are instead selected from a random pool of oligonucleotides). We attempted to build a multiple alignment from positive sequences using MAFFT, but the alignment was of extremely poor accuracy, making the covariance model learned from it useless.\n\nAddress to the comments in Neural\n* We have added up/down arrows next to the metrics in Table 1.\n* Indeed, we agree with the reviewer that it is an important future direction to consider the evolutionary information inherent in the RFAM database, which will by no doubt enable us to design RNA secondary structures that have meaningful functions pertaining to certain RNA families such as regulatory roles, since there exists crucial RNA structural motifs from certain RNA families that are evolutionarily conserved. We have updated our manuscript to include a discussion on this topic for future works.\n* We thank the reviewer for this suggestion. Indeed, it would be interesting to analyze our models in depth and see if it can learn RNA tertiary structural motifs from the CaRNAval RNAMotifs database, which will become feasible when we switch to the non-coding RNA families dataset from RFAM. Our current method would also require major upgrades to account for non-canonical interactions and pseudoknots which are common in tertiary contacts. This is an important future direction which we have indicated in our updated manuscript.\n* After double checking we can assure our reviewer that the scores reported in Table 1 are accurate. Some values are the same due to the rounding to the 2nd decimal in the percentages. For example, if rounding to the 5th decimal, the validity scores for LSTMVAE and GraphVAE under the Constrained & Posterior Decoding setting would be 99.47496% and 99.46935% respectively. The diversity scores for GraphVAE and HierVAE under the Constrained & Prior Decoding setting would be 6.79065 and 6.79079\n* Thanks for pointing out the typo"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "_AjkRYfJ_UV", "original": null, "number": 5, "cdate": 1605638692652, "ddate": null, "tcdate": 1605638692652, "tmdate": 1605638729815, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "fenvjcpgcmc", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "Thanks for the interest in our work! Please refer to our answers below.", "comment": "We thank the reviewer for the interest in our work! We hope to address the current limitations with new data combined with new generative modeling techniques.\n\n1. For RNA folding or RNA inverse design, the mode of generation is conditional in the sense that a secondary structure is predicted based on the input sequence (folding), or an RNA sequence is predicted based on the input secondary structure (inverse design).\n\n    For folding, one would certainly consider combining graph representation learning with reinforcement learning, where a graph neural network is used to acquire representation of an intermediately folded RNA secondary structure, and based on this intermediate representation, an RL agent samples actions such as pairing two bases in the graph. There already exists similar works such as You et al. 2018 where the authors proposed a graph convolutional policy network for targeted molecular design.\n\n    For the inverse design problem, one could also imagine that in the beginning an input secondary structure is given which misses node identities, and we need to specify a nucleotide for each node in the graph. Once again, GNN can be used to compute representation of this intermediately filled graph, and an RL agent samples a nucleotide for each unpaired region, or a pair of nucleotides in the paired region, in a similar fashion as in Runge et al. 2019.\n\n    In our work, the hierarchical modelling technique of RNA molecules can be certainly used as functional approximators in the RL algorithm under the conditional generation setting. Alternatively, under the joint sequence and structure modelling setting as employed by our work, RL can be potentially used to further fine tune our decoder to decode more stable and meaningful RNAs. \n2. We believe the answer is yes and a possible solution lies in generative pre-training using evolutionary data collected from a broad spectrum of organisms and RNA families, followed by finetuning using with reinforcement learning. The pre-training step is essential for the purpose of learning biologically-relevant and evolutionarily conserved knowledge into the model, such as meaningful and stable folding of RNAs that belong to certain RNA families, which will play a big role in the subsequent RNA generation step. Afterwards, reinforcement learning with rewards defined on structural validity, folding stability as well as customizable goals for example RBP binding can be used to further finetune the pre-trained model. And notably, the structural constraints mentioned in our current work can be applied to the reinforcement learning as a form of rejection sampling during training.\n3. Indeed our modelling choices for the graph perspective of RNA molecules also use graph neural networks as in Yan et al.2020. One major distinction, however, lies in that Yan et al. 2020 developed computational models for in-vivo RBP binding predictions, which were trained and evaluated with RNA snippets that come from much longer mRNAs in their actual cellular environment. On account of that, they used base-pairing probability annotated adjacency matrix to represent an ensemble of possible foldings, contrary to our work which uses a single minimum free energy structure for each RNA, because our work has focused on in-vitro RBP bindings, which means all the RNAs are experimentally synthesized short sequences with tractable secondary structures. Therefore, our work is not directly comparable with Yan et al. 2020 although both have studied RNA protein interaction.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "a_2OmCiWCMj", "original": null, "number": 2, "cdate": 1605637339039, "ddate": null, "tcdate": 1605637339039, "tmdate": 1605638056139, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "_BEPdG5sPEZ", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "We thank the reviewer for the constructive feedbacks! We hope to clarify all the questions with answers below.", "comment": "We thank the reviewer for the constructive feedbacks. We have updated our manuscript with clarification to points that were previously confusing, and new results that were suggested.\n\n> This works ... becomes considerably less elegant on the decoder side, where the authors have to make use of sample masking with complex rules to prevent generation of invalid sequence-structure combinations\n\nTo our knowledge, manually adding structural constraints to the decoding process is a common practice in computational drug discovery (similar construction can be seen in JTVAE, CGVAE, GCPN, GraphAF andMolecularRNN). Rather than merely adding to the complexity of our approach, these rules can help our models decode close to 100% valid RNAs, and they are a crucial source of domain knowledge can describes understanding of the RNA secondary structures, based on which we can influence the design process.\n\n#### Address to major comments:\n\n* The heuristic masking rules are only applied at test time (i.e., inference) and not needed during training; since the nucleotide sequences and secondary structures are known during training, we can use a teaching forcing strategy, meaning that the structures generated during training are always valid. Regarding the treatment of probabilities, when we apply the masks at test time, the constraints masks are added to the logits before the probabilities can be calculated using softmax (i.e., renormalization is performed). We have clarified both of these points in the manuscript. \n* The set of masking rules are designed in a way that decoded RNAs will adopt valid secondary structures by constraining the sample taken at each decoding step to valid basepairs and structural topology. However, these constraints do not have any knowledge of the stability of RNA secondary structures, nor do they understand how these actions will influence the free energy of RNA folding since they are hard coded. Therefore, by manually asserting the influence of domain knowledge, RNA stability is adversely influenced. However, we also showed that the inductive bias constructed into the decoder architecture can simultaneously improve the validity and stability of decoded RNAs, and coupled with hard coded structural constraints, the validity can approach 100% without greatly compromising the stability.\n*  Adding a comparison to untrained decoders is a great suggestion, and we have updated our manuscript accordingly. Using an untrained HierVAE model, we find out that the posterior and prior decoding under the constrained and stochastic setting will produces validity of 66.30% and 66.34% respectively, with very high free energy deviation \u2014 22.313 and 22.613, indicating that the generated secondary structures of RNA are of very low stability. Under the unconstrained setting, the validity drops to 9.51% and 9.37% for the posterior and prior, and the model can only decode single stranded RNAs that lack more complex secondary structures. The structures decoded under this setting are not useful at all, since the model does not have the knowledge of how to construct more complex RNA topology, as it is neither learned nor enforced via decoding constraints. In the end, this comparison shows that although decoding constraints help improve the validity, it alone is not capable of generating RNAs with more stable secondary structures. Modeling training is imperative for obtaining more stable RNA folding.\n* For targeted RNA generation, we need to organize the latent space to help the search for RNAs with desired properties, and adding auxiliary supervision on the latent encodings helps provide this structure. In the end, we demonstrated that a semi-supervised VAE has the discriminative power comparable to a fully supervised classification model. Indeed, a fully supervised classification model would be more straightforward and simpler to fit, however, our main objective is to show that our VAEs can adequately organize the latent space, rather than to compare with these predictive systems.\n\n\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "fJ-bDu11PRp", "original": null, "number": 4, "cdate": 1605637988698, "ddate": null, "tcdate": 1605637988698, "tmdate": 1605638031729, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "5B6SThmsxtR", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "Continued-2", "comment": "* >what does \"RECON ACC \" in Table 2 refer to?\n\n    It refers to reconstruction accuracy, which measures the fraction of RNA molecules decoded exactly as the input. We have clarified this abbreviation in the Table 2 caption.\n* Thanks for pointing out the typo.\n* > Why is FE DEV defined as the absolute value?\n\n    That is correct. The RNA secondary structure generated by our model would always have higher free energy than that of the MFE structure when it is evaluated by RNAfold, even if the predicted structure is indeed biologically more stable. We have removed \u201cabsolute\u201d from the manuscript."}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "5B6SThmsxtR", "original": null, "number": 3, "cdate": 1605637839046, "ddate": null, "tcdate": 1605637839046, "tmdate": 1605637873469, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "a_2OmCiWCMj", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment", "content": {"title": "Continued-1", "comment": "*  About the results in Table 3, we thank the reviewer for pointing out this possible correlation in the evaluation, which we will acknowledge in the revision, and for the interesting suggestion for an alternative evaluation approach. Unfortunately, however, there are some issues with a edit-distance-based evaluation approach, namely:\n\n    * Sequence/structure based similarity measures cannot accurately assess the capability of RNA interacting with proteins. First of all, RBP binding motifs are known to be short (5-10nt) which can be embedded into a relatively larger RNA. Therefore, two sequences with low edit distance may interact differently with the same protein if the sequence differences alters key binding motif; on the other hand, two sequences with high edit distance may bind to the same protein if they possess the same motif disregarding the rest in the RNA.\n    * Secondly, RNAcompete-S experiment protocol uses a single selection step which does not differentiate high and low binding affinities of RNAs, suggesting the existence of false positives in the curated dataset. Without explicitly extracting the knowledge of RBP binding, simply calculating the edit distance to the positive sequences as in a k-nearest-neighbor approach would thus provide a fairly inaccurate assessment of binding potential.\n    * In the RNAcompete-S dataset, all sequences are of uniform length (40nts), compared to our designed RNAs which are of variable length and not necessarily constrained to preserve the composition of its nucleic acids or the topology of its secondary structure. Therefore, we observe the edit distance computed by super-n-motifs (Glouzon et al. 2017) or ERA  (Zhong et al. 2013), which both take into account RNA sequence and structure into their similarity measures, contains a lot of noise and is not an trustworthy metrics for evaluating the protein binding capability of our designed sequences.\n\n    Based on these issues, we opted to use the evaluation approach proposed in the paper. Our hope is that the train/val/test split used in training our models is sufficient to provide a meaningful signal in this type of evaluation (e.g., the test set is never used for training either model). Of course, we acknowledge it is imperfect (e.g., due to an overlapping training set) and more sophisticated (e.g., wet lab) validation strategies is an active area for our future work.  \n\n*  Indeed, it would be interesting to consider a dataset that contains functional annotation and evolutionary information from RNA families. However, our project is solely concerned with the representation and generation of RNA secondary structures, therefore we do not have those information in the dataset, i.e. an RNA sequence is randomly sliced from the human messenger RNAs, having its secondary structure predicted by RNAfold and it does not belong to any of the non-coding RNA categories. The reason why we slice them to shorter snippets is for computational tractability, in addition to the fact that we cannot reliably obtain MFE for much longer RNA sequences. We admit it will be an important direction in the future to incorporate these information, and we have talked about this in the discussion section in the updated manuscript.\n\n* Using a KL annealing schedule is necessary for our models to avoid posterior collapse, where the decoder becomes independent of the latent encodings provided by the encoder, which is a common failure mode for VAEs with strong autoregressive components, as discussed in He et al. 2019. Our choice of the annealing schedule is entirely based on empirical observations, as to our knowledge, there has yet to exist any principled methods of selecting KL annealing schedule. We have used diagnostic metrics such as mutual information and active units along with a validation set to select a proper annealing schedule which is the one reported in our paper. We added these information to our manuscript.\n\n\nAddress to minor comments:\n*  We agree with the reviewer that this is a strong statement as the supporting evidence so far has been sparse and preliminary\u2014deep learning and graph representation methods have yet to dominate the field of design for biological structures and druggable molecules. We replaced the word \u201crequires\u201d to \u201cspurs\u201d in an attempt to tone down the sentence.\n* Thanks for pointing out the typo.\n* We thank the reviewer for pointing out this abuse of terminology, and we have replaced \u201cclique\u201d with \u201csubgraph\u201d in the manuscript.\n* We use a threshold to limit the number of decoding steps, which means the decoding of an RNA will terminate (hence fail) when the threshold has been reached when decoding the RNA topological structure or nucleotide segments. These thresholds are indicated in Algorithm 1 in the appendix, and we have made clarifications in the result section of the manuscript.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "snOgiCYZgJ7", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2126/Authors|ICLR.cc/2021/Conference/Paper2126/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851966, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Comment"}}}, {"id": "u1mN0RVn0oV", "original": null, "number": 1, "cdate": 1603849225307, "ddate": null, "tcdate": 1603849225307, "tmdate": 1605024282998, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review", "content": {"title": "Evaluating generative models for RNA secondary structure is a challenging problem", "review": "Summary: This paper proposes 3 deep generative models based on VAEs (with different encoding schemes for RNA secondary structure) for the generation of RNA secondary structures. They test each model on 3 benchmark tasks: unsupervised generation, semi-supervised learning and targeted generation.  This paper has many interesting contributions \u2014 a comparison of VAE models that use different RNA secondary structure encoding schemes, including traditional dot-bracket notation and a more complex hierarchical encoding, and they also introduce various decoding schemes to encourage valid secondary structures. \n\nThis is an important problem for drug discovery and basic biology, but the evaluation is very tricky because there are not that many solved RNA structures (unlike proteins). The tasks proposed in this paper are not comprehensive enough to entice a (comp) biologist to be convinced one way or another, but it does provide an introduction to the problem for the ML field. \n\nComments:\n* While the trends in their results are clear, it\u2019s difficult to know which values of Diversity, FE DEV, and Validity are good enough to say that they have made significant progress relative to the field. The main issue is that all model comparisons are only with their own VAEs. It would be nice to show how their VAEs stack up against other established methods. For unsupervised generation, perhaps Infernal (Nawrocki and Eddy. Bioinformatics, 2017), which uses a stochastic context-free grammar built up from sequences belonging to a single RNA family, but could still form the basis for a comparison. Other models include CONTRAfold (Do et al. Bioinformatics, 2006) and many other thermodynamic models (Lorenz et al. Algorithms for Mol Biol, 2011). These other approaches may lack the scalability of a VAE, but an effort should be made for at least a limited comparison.\n* It\u2019s difficult to assess the quality of the generated secondary structures shown in various plots throughout the paper and appendices. This paper should plot a side by side comparison with the ground state structure that they are comparing the FE DEV scores against to see how well the structure corresponds. For instance, the generated (but invalid) structure may visually look similar as they walk through latent space, but the key mismatches can fundamentally change the \u201cground truth\" structure of the RNA (which is not shown in their generated structure). The ground truth structure is given by RNAfold, which itself is not perfect.  \n* Evaluation is very tricky and it\u2019s unclear how to navigate this.  Careful wording can help differentiate true objectives (functional RNA) from difficult evaluations (FE DEV scores). If minimizing FE DEV is the objective, then I worry that models will simply become function approximators for RNAfold. \n* A good comparison (though limited) would be to compare the predicted structures with solved structures deposited in the PDB. Another comparison could be to sample about the posterior near well known non-coding RNAs, such as tRNA or 5S ribosomal RNA. Many more consensus RNA structures can be found in RFAM (Kalvari et al. NAR, 2018).  \n* On a side note, the comparison on RNAcompete-S in Table S3 shows that a sequence model is comparable to models that incorporate RNA secondary structures \u2014 there is only a small gain by including secondary structures. This is not that surprising as sequence-based models have demonstrated learning secondary structures when trained only on sequences (for the RNAcompete dataset \u2014 not RNAcompete-S yet).\n* One lingering question I had is, is the latent space of the VAE meaningful? For instance, does it capture well-established non-coding RNA families? \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103476, "tmdate": 1606915777812, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2126/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review"}}}, {"id": "ntTCg-4BgyX", "original": null, "number": 2, "cdate": 1603864835840, "ddate": null, "tcdate": 1603864835840, "tmdate": 1605024282932, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review", "content": {"title": "Interesting biologically-inspired generative models for RNA", "review": "Brief summary: The authors describe a generative model constrained to model the primary and secondary structure of RNA.\n\nPros:\n\n- I applaud the authors for working with RNA data. This is less characterization of modeling RNA data.\n\n- I think the constraints for the RNA generation structure are reasonable, and both the manual and ML constrained generative process are well thought out.\n\n- I think the comparison between constrained and unconstrained generation of molecules was well done.\n\nCons:\n\n- This paper falls into the common pitfall of not controlling for homologous sequences between the training and test set. For each sequence in the training set, what is the sequence with the largest sequence ID in the test set by alignment?\n\n- It would be great to have a null distribution to characterize your model to. What is FE DEV, Normed, and Diversity for randomized, but kmer controlled, RNA sequences?\n\n- The definition of \"valid structures\" is poorly defined. Could generated sequences still fold if optimized in a traditional biophysical simulation?\n\n- I think a comparison with an algorithm like INFERNAL (http://eddylab.org/infernal/Userguide.pdf) is necessary. This is the most simple context-free grammar generative model.\n\nNeutral:\n\n- It is difficult to assess the range of \"good\" values in Table 1. To aid in interpretability to the reader, I would advise more explicitly denoting whether diversity, FE DEV, and Normed should be metrics that go up or down with improved performance.\n\n- I think it would be wise to train this sort of model on more data, such as RFAM. This is an already curated database of RNAs by sequence family from a large number organisms, much more than just human sequences.\n\n- Is there any way to evaluate valid tertiary contacts? These would be sequence motifs that are preserved across organisms with constrained sequence and function that may not necessarily follow Watson-Crick basepairing rules.\n\n- It is slightly concerning to me that in Table 1, \"Validity\" is the same for LSTMVAE and GraphVAE in *Constrained & Posterior Decoding* and \"Diversity\" is the same for GraphVAE and HierVAE *Constrained & Prior Decoding*. Why is this the case?\n\n- Page 2, typo: \u201cbenchmhark datasets\u201d\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103476, "tmdate": 1606915777812, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2126/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review"}}}, {"id": "fenvjcpgcmc", "original": null, "number": 3, "cdate": 1603871750610, "ddate": null, "tcdate": 1603871750610, "tmdate": 1605024282803, "tddate": null, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "invitation": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review", "content": {"title": "New direction", "review": "##########################################################################\n\nSummary:\n\n \nThis paper sheds light into an impactful problem of neural representation and generation for RNA secondary structures. Authors presented benchmark tasks in unsupervised, semi-supervised and targeted generation setting and presented deep generative models to solve this tasks. They presented three different generative models using variational auto encoders based on sequence, graph and hierarchical representation. \n\n\n##########################################################################\n\nPros:\n \n1. The paper deals with a very important problem of neural representation and generation for RNA secondary structures. I think this area needs a lot more work to help solving real-world biological problems.\n\n \n2. As far as I can tell their method is novel in terms of idea. Generation of RNAs are not trivial. It requires extra attention to detail in terms of checking for validity and stability in folding. There are also diverse families of RNA which are very different from each other. In this work, the validity and stability constraints are implemented inside a depth first search traversal of building the RNA. Without these constraints its much harder to learn the structures of the RNA from embedding only as it is evident from the result on the unsupervised setting as well. In supervised setting, the authors showed their models efficacy in RBP datasets. Related works also contains recent works in RNA.\n \n3. Overall the paper is well written. I liked the illustrations for explaining the methods. Result section is also well structured. It clearly shows the effectiveness of the generative model used.\n \n##########################################################################\n\nCons: \n\n \n1. Is it possible to use this generation technique to use in solving problems like RNA folding or targeted RNA design? Specially the authors mentioned RL based method from (Runge et al., 2019). Is it possible to use this generative model and combine it with the existing RL techniques for RNA design or ML techniques for folding to show improvement in their result? That would definitely increase the impact of this work.\n\n2. Is it also feasible to learn the structural constraints from the data? Can we get rid of the dependency on constraints with more automated learning?\n\n3. I am also interested to know if we can compare it against any discriminative learning based baseline for any task. For example a recent work from (Yan et. al 2020) for RNA protein interaction.\n\n##########################################################################\n\nQuestions during rebuttal period: \n\n \nPlease address and clarify the cons above \n\n \n#########################################################################\n\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2126/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2126/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural representation and generation for RNA secondary structures", "authorids": ["~Zichao_Yan1", "~William_L._Hamilton1", "~Mathieu_Blanchette1"], "authors": ["Zichao Yan", "William L. Hamilton", "Mathieu Blanchette"], "keywords": ["Graph neural network", "Deep generative modeling", "Machine learning", "Drug discovery", "RNA structure", "RNA structure embedding", "RNA-protein interaction prediction"], "abstract": "Our work is concerned with the generation and targeted design of RNA, a type of genetic macromolecule that can adopt complex structures which influence their cellular activities and functions. The design of large scale and complex biological structures spurs dedicated graph-based deep generative modeling techniques, which represents a key but underappreciated aspect of computational drug discovery. In this work, we investigate the principles behind representing and generating different RNA structural modalities, and propose a flexible framework to jointly embed and generate these molecular structures along with their sequence in a meaningful latent space. Equipped with a deep understanding of RNA molecular structures, our most sophisticated encoding and decoding methods operate on the molecular graph as well as the junction tree hierarchy, integrating strong inductive bias about RNA structural regularity and folding mechanism such that high structural validity, stability and diversity of generated RNAs are achieved. Also, we seek to adequately organize the latent space of RNA molecular embeddings with regard to the interaction with proteins, and targeted optimization is used to navigate in this latent space to search for desired novel RNA molecules.", "one-sentence_summary": "We investigate a new direction in computational drug discovery for designing large scale and complex macromolecular structures known as the RNAs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|neural_representation_and_generation_for_rna_secondary_structures", "supplementary_material": "/attachment/6b9f89b83078750de08a7b1c966f5a32c0b42631.zip", "pdf": "/pdf/bc9ac721f355bf79861be2019a3d66689b2b8a33.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nyan2021neural,\ntitle={Neural representation and generation for {\\{}RNA{\\}} secondary structures},\nauthor={Zichao Yan and William L. Hamilton and Mathieu Blanchette},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=snOgiCYZgJ7}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "snOgiCYZgJ7", "replyto": "snOgiCYZgJ7", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2126/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103476, "tmdate": 1606915777812, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2126/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2126/-/Official_Review"}}}], "count": 13}