{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363779180000, "tcdate": 1363779180000, "number": 3, "id": "Xf5Pf5SWhtEYT", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzKhQhsTYlzAZ", "replyto": "zzKhQhsTYlzAZ", "signatures": ["Kye-Hyeon Kim, Rui Cai, Lei Zhang, Seungjin Choi"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We sincerely appreciate all the reviewers for their time and comments to this manuscript.\r\nWe fully agree that it is really hard to find maningful contributions from this short paper, while we tried our best to emphasize them. As we have noted, the full version of this manuscript is currently under review in an international journal. In order to avoid violating the dual-submission policy of the journal, we could not include most of the details and empirical results - only the main idea and some simple examples could be remained in this workshop track submission.\r\n\r\nWe promise that all the details omitted in this version will be presented clearly in the workshop, e.g., the choice of the weighting of each split, the training dataset used in our experiments, and conclusive empirical comparisons.\r\nFor example, we compared the image retrieval performance for landmark buildings in Oxford (http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/) and Paris (http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/). A nonlinear variant of LFDA implemented using deep belief networks (DBN) and a kernelized version of LDE (KDE) were compared to our method. In terms of the mean average precision (mAP) score, we observed significant improvements using our method (mAP: 0.678 on Oxford / 0.700 on Paris) over raw SIFT (0.611 / 0.649), KDE (0.656 / 0.673), DBN (0.662 / 0.678), under the same number of the learned features and the same size of visual vocabulary.\r\n\r\nThanks to all the reviewers again."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "pdf": "https://arxiv.org/abs/1301.3644", "paperhash": "kim|regularized_discriminant_embedding_for_visual_descriptor_learning", "keywords": [], "conflicts": [], "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choi"], "authorids": ["vapnik.chervonenkis@gmail.com", "ruicai@microsoft.com", "leizhang@microsoft.com", "seungjin.choi.mlg@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362287940000, "tcdate": 1362287940000, "number": 1, "id": "FBx7CpGZiEA32", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzKhQhsTYlzAZ", "replyto": "zzKhQhsTYlzAZ", "signatures": ["anonymous reviewer 1e7c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Regularized Discriminant Embedding for Visual Descriptor Learning", "review": "The paper aims to present a method for discriminant analysis for image\r\ndescriptors. The formulation splits a given dataset of labeled images\r\ninto 4 categories, Relevant/Irrelevant and Near/Far pairs\r\n(RN,RF,IN,IF). The final form of the objective aims to maximize the\r\nratio of sum of distances of irrelevant pairs divided by relevant pairs. The distance metric is calculated at the lower dimensional projected space. The\r\nmain contribution of this work as suggested in the paper is selecting\r\nthe weighting of 4 splits differently from previous work.\r\n\r\nThe main intuition or reasoning behind this choice is not given,\r\nneither any conclusive emprical evidence. In the only experiment that\r\ncontains real images in the paper, data is said to be taken from\r\nFlickr. However, it is not clear if this is a publicly available\r\ndataset or some random images that authors collected. Moreover, for\r\nthis experiment, one of the only two relevant methods are not included\r\nfor comparison. Neither, any details of the training procedure nor the actual hyper parameters (\beta) are explained in the paper."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "pdf": "https://arxiv.org/abs/1301.3644", "paperhash": "kim|regularized_discriminant_embedding_for_visual_descriptor_learning", "keywords": [], "conflicts": [], "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choi"], "authorids": ["vapnik.chervonenkis@gmail.com", "ruicai@microsoft.com", "leizhang@microsoft.com", "seungjin.choi.mlg@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362186780000, "tcdate": 1362186780000, "number": 2, "id": "-7pc74mqcO-Mr", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "zzKhQhsTYlzAZ", "replyto": "zzKhQhsTYlzAZ", "signatures": ["anonymous reviewer 39f1"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Regularized Discriminant Embedding for Visual Descriptor Learning", "review": "This paper describes a method for learning visual feature descriptors that are invariant to changes in illumination, viewpoint, and image quality. The method can be used for multi-view matching and alignment, or for robust image retrieval. The method computes a regularized linear projection of SIFT feature descriptors to optimize a weighted similarity measure. The method is applied to matching and non-matching patches from Flickr images. The primary contribution of this workshop submission is to demonstrate that a coarse weighting of the data samples according to the disparity between their semantic distance and their Euclidean distance in SIFT descriptor space.\r\n\r\nThe novelty of the paper is minimal, and most details of the method and the validation are not given. The authors focus on the weighting of the sample pairs to emphasize both the furthest similar pairs and the closest dissimilar pairs, but it is not clear that this is provides a substantial gain."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "pdf": "https://arxiv.org/abs/1301.3644", "paperhash": "kim|regularized_discriminant_embedding_for_visual_descriptor_learning", "keywords": [], "conflicts": [], "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choi"], "authorids": ["vapnik.chervonenkis@gmail.com", "ruicai@microsoft.com", "leizhang@microsoft.com", "seungjin.choi.mlg@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358487000000, "tcdate": 1358487000000, "number": 18, "id": "zzKhQhsTYlzAZ", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "zzKhQhsTYlzAZ", "signatures": ["vapnik.chervonenkis@gmail.com"], "readers": ["everyone"], "content": {"title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "decision": "conferencePoster-iclr2013-workshop", "abstract": "Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.", "pdf": "https://arxiv.org/abs/1301.3644", "paperhash": "kim|regularized_discriminant_embedding_for_visual_descriptor_learning", "keywords": [], "conflicts": [], "authors": ["Kye-Hyeon Kim", "Rui Cai", "Lei Zhang", "Seungjin Choi"], "authorids": ["vapnik.chervonenkis@gmail.com", "ruicai@microsoft.com", "leizhang@microsoft.com", "seungjin.choi.mlg@gmail.com"]}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 4}