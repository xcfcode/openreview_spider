{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396366254, "tcdate": 1486396366254, "number": 1, "id": "HJ80sMLOl", "invitation": "ICLR.cc/2017/conference/-/paper117/acceptance", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The program committee appreciates the authors' response to concerns raised in the reviews. Unfortunately, all reviewers are leaning against accepting the paper. Authors are encouraged to incorporate reviewer feedback in future iterations of this work."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396366803, "id": "ICLR.cc/2017/conference/-/paper117/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396366803}}}, {"tddate": null, "tmdate": 1482897285275, "tcdate": 1482895907556, "number": 6, "id": "SkjXGhgSl", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "ByFJkHY4x", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "thanks for your reviews.", "comment": "(1) yes, those claims about game rules and cross-modal supervision don't stand.\n\n(2) with all due respect, still we think the experiments presented here (RACs for experiment I/II/III are not 100% but vary a lot) cannot be perfectly explained by any existing theories. \n\n*AND* this (a phenomenon that cannot be explained) is the real reason why we claim that it is interesting (but *NOT* a 'subjective' judgement).\n\nAfter all, Mendel observed that \u20183:1\u2019 inheritance law in 19th century yet it got fully explained by DNA structure in 1950s.\n\n(3) Thanks for your improvement suggestions ! visualizing with wrong classes is a good idea."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "tmdate": 1482407649240, "tcdate": 1482407649240, "number": 3, "id": "ByFJkHY4x", "invitation": "ICLR.cc/2017/conference/-/paper117/official/review", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer3"], "content": {"title": "Unclear ", "rating": "3: Clear rejection", "review": "Game of tic-tac-toe is considered. 1029 tic-tac-toe board combinations are chosen so that a single move will result into victory of either the black or the white player. There are 18 possible moves - 2 players x 9 locations. A CNN is trained from a visual rendering of the game board to these 18 possible outputs. CAM technique is used to visualize the salient regions in the inputs responsible for the prediction that CNN makes. Authors find that predictions correspond to the winning board locations. \n\nAuthors claim that this:\n1. is a very interesting finding. \n2. CNN has figured out game rules. \n3. Cross modal supervision is applicable to higher-level semantics. \n\nI don't think (2) be can be claimed because the knowledge of game rules is not tested by any experiment. There is only \"one\" stage of a game - i.e. last move that is considered. Further, the results are on the training set itself - the bare minimum requirement of any implicit or explicit representation of game rules is the ability to act in previously unseen states (i.e. generalization). Even if the CNN did generalize, I would avoid making any claims about knowledge of game rules. \n\nFor (3), author's definition of cross-modal seems to be training from images to games moves. In image-classification we go from images --> labels (i.e. between two different domains). We already know CNNs can perform such mappings. CNNs have been used to map images to actions such as in DQN my Mnih et al., or DDPG by Lillicrap et al. and a lot of other classical work such as ALVIN. It's unclear what points authors are trying to make. \n\nFor (1): how interesting is an implicit attention mechanism is a subjective matter. The authors claim a difference between the concepts of \"what do do\" and \"what will happen\". They claim by supervising for \"what will happen\", the CNN can automatically learn about \"what to do\". This is extensively studied in the model predictive control literature. Where model is \"what will happen next\", and the model is used to infer a control law - \"what to do\". However, in the experimental setup presented in the paper what will happen and what to do seem to be the exact same things. \n\nFor further analysis of what the CNN has learnt I would recommend:\n(a) Visualizing CAM with respect to incorrect classes. For eg, visualize the CAM with respect to player would lose (instead of winning).\n\n(b) Split the data into train/val and use the predictions on the val-set for visualization. These would be much more informative about what kind of \"generalizable\" features the CNN pays attention to. \n\nIn summary, understanding why CNN's make what decisions they make is a very interesting area of research. While the emergence of an implicit attention mechanism may be considered to be an interesting finding by some, many claims made by the authors are not supported by experiments (see comments above). \n\n\n \n\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512692533, "id": "ICLR.cc/2017/conference/-/paper117/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer2", "ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512692533}}}, {"tddate": null, "tmdate": 1482129050636, "tcdate": 1481985401479, "number": 4, "id": "rJ-F66MVe", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "Hk5euvf4g", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "Thanks for your review.", "comment": "Dear reviewer_2,\n\nAs a pilot study on a very strange topic, I think you have already provided fair reviews on it. Thx for your time.\n\nBut I have two more questions that I am really interested in:\n\n(a) If activating at the right location is trivial/not surprising/natural, do you have any comments on RAC in Table 1 ?\n\nShouldn't RAC for expriment I/II/III all be 100% ? (or at least very close to each other ?)\n\n(b) Do you have any improvement/extension/resubmission suggestions ?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "tmdate": 1482128882418, "tcdate": 1482116821415, "number": 5, "id": "HyTCCa4Ne", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "BkXHxhEEe", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "Thank you for your valuable reviews.", "comment": "Dear reviewer_1,\n\n* I am not quite sure precisely how CAM is implemented here. In the original CAM\none must identify a class of interest to visualize (e.g., cat or dog). I don't\nthink this paper identifies such a choice. How is one of the 18 possible classes\nchosen for creating the CAM visualization and through that visualization\nchoosing an action?\n\nWe do identify such a choice. That choice is the network classification output (which is 100% correct in all experiments).\n\nOur CAM implementation can be found here: https://github.com/Fromandto/marvin_cam\n\nTo the best of our knowledge, it's technically same as Zhou's caffe version.\n\n* How was the test set for this dataset for the table 1 results created?\nHow many of the final 1029 states were used for test and was the\ndistribution of labels the same in train and test?\n\nWe did not split training and testing sets. And we think training and testing on the same set is fair here because finding out what the network has learnt from the training set is exactly what we are trying to do here.\n\nIn a future re-submission version, we will do a 5-fold cross validation (with label distribution regularization).\n\n* How is RCO computed? Is rank correlation or Pearson correlation used?\nIf Pearson correlation is used then it may be good to consider rank correlation,\nas argued in \"Human Attention in Visual Question Answering: Do Humans and\nDeep Networks Look at the Same Regions?\" by Das et. al. in EMNLP 2016.\nIn table 1, what does the 10^3 next to RCO mean?\n\n(10^3) means -8.096 * 10^3.\n\nI guess you are confused about the numerical scale of this correlation.\n\nTo clarify, the ideal representation kernel is generated by this matlab code:\n\n________________________________________________________________________________________\n\nkernel = zeros(180 , 180 , 9);\n\ncenter = [150 , 150 ; 150 , 90 ; 150 , 30 ; 90 , 150 ; 90 , 90 ; 90 , 30 ; 30 , 150 ; 30 , 90 ; 30 , 30];\nsigma = 30;\n\nfor i = 1 : 9\n    c = center(i , :);\n    for j = 1 : 180\n        for k = 1 : 180\n            kernel(j , k , i) = 2 * exp(-(norm(c - [j , k]) / sigma)) - 1;\n        end\n    end\nend\n_________________________________________________________________________________________________\n\nthe amplitude of the gaussian kernel is 2 and we add -1 bias (in order to penalize activations on wrong locations).\n\nthe CAM representations are normalized into [0,1]. So ... the numerical scale of RCO is around -10000.\n\n* PROS *\n\nThank you so much for your positive feedbacks. \n\nAs a pilot sduty, we are eager to know what other researchers find interesting in it so that we can work on these points in the future.\n\n* This work distinguishes between predictions about \"what will happen\"\n(will the white player win?) and \"what to do\" (where should the white\nplayer move to win?). The central idea is generalization from \"what will happen\"\nto \"what to do\" indicates concept learning (sec. 2.1). Why should an ability to\nact be any more indicative of a learned concept than an ability to predict\nfuture states. I see a further issue with the presentation of this approach and\na potential correctness problem:\n\nWe admit that our interpretations about 'what will happen' and 'what to do' are somewhat overstated.\n\nThank you for pointing out this and we will make these claims carefully in a future version.\n\n* Comparison to work that uses visualization to investigate deep RL networks\nis missing. In particular, other work in RL has used Simonyan et. al.\n(arXiv 2013) style saliency maps to investigate network behavior. For example, \n\"Dueling Network Architectures for Deep Reinforcement Learning\" by Wang et. al.\nin (ICML 2016) uses saliency maps to identify differences between their\nstate-value and advantage networks. In \"Graying the black box:\nUnderstanding DQNs\" by Zahavy et. al. (ICML 2016) these saliency maps are\nalso used to analyze network behavior.\n\nThank you very much for referring these two ICML 2016 papers.\n\nWe have went through CVPR/ECCV/ICCV/NIPS/ICLR (although not exhaustively) for such papers but just didn't find any highly-related ones.\n\n* In section 2.3, saliency maps of Simonyan et. al. are said to not be able to\nactivate on grid squares because they have constant intensity, yet no empirical\nor theoretical evidence is provided for this claim.\n\nYes, this claim does not stand.\n\nOn a related note, what precisely is the notion of information referenced in\nsection 2.3 and why is it relevant? Is it entropy of the distribution of pixel\nintensities in a patch? To me it seems that any measure which depends only\non one patch is irrelevant because the methods discussed (e.g., saliency maps)\ndepend on context as well as the intensities within a patch.\n\nYes, we will make these claims more carefully in a future version.\n\n* The presentation in the paper would be improved if the results in section 7\nwere presented along with relevant discussion in preceding sections.\n\nPaper structure will be improved in a future version.\n\nFinally,\n\nThank you again for your valuable reviews !"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "tmdate": 1482109014956, "tcdate": 1482108986847, "number": 2, "id": "BkXHxhEEe", "invitation": "ICLR.cc/2017/conference/-/paper117/official/review", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer1"], "content": {"title": "Novel experiments, but the results and significance are not clear", "rating": "3: Clear rejection", "review": "Summary\n===\nThis paper presents tic-tac-toe as toy problem for investigating CNNs.\nA dataset is created containing tic-tac-toe boards where one player is one\nmove away from winning and a CNN is trained to label boards according\nto (1) the player who can win (2 choices) and (2) the position they may move\nto win (9 choices), resulting in 18 labels. The CNN evaluated in this paper\nperforms perfectly at the task and the paper's goal is to inspect how the\nCNN works.\n\nThe fundamental mechanism for this inspection is Class Activation\nMapping (CAM) (Zhou et. al. 2016), which identifies regions of implicit attention\nin the CNN. These implicit attention maps (localization heat maps) are used to\nderive actions (which square each player should move). The attention maps  \n\n(1) attend to squares in the tic-tac-toe board rather than arbitrary\nblobs, despite the fact that one square in a board has uniform color, and\n\n(2) they can be used to pick correct (winning) actions.\n\nThis experiment are used to support assertions that the network understands\n(1) chess (tic-tac-toe) boards\n(2) a rule for winning tic-tac-toe\n(3) that there are two players.\n\nSome follow up experiments indicate similar results under various renderings\nof the tic-tac-toe boards and an incomplete training regime.\n\n\nMore Clarifying Questions\n===\n\n* I am not quite sure precisely how CAM is implemented here. In the original CAM\none must identify a class of interest to visualize (e.g., cat or dog). I don't\nthink this paper identifies such a choice. How is one of the 18 possible classes\nchosen for creating the CAM visualization and through that visualization\nchoosing an action?\n\n* How was the test set for this dataset for the table 1 results created?\nHow many of the final 1029 states were used for test and was the\ndistribution of labels the same in train and test?\n\n* How is RCO computed? Is rank correlation or Pearson correlation used?\nIf Pearson correlation is used then it may be good to consider rank correlation,\nas argued in \"Human Attention in Visual Question Answering: Do Humans and\nDeep Networks Look at the Same Regions?\" by Das et. al. in EMNLP 2016.\nIn table 1, what does the 10^3 next to RCO mean?\n\n\nPros\n===\n\n* The proposed method, deriving an action to take from the result of a\nvisualization technique, is very novel.\n\n* This paper provides an experiment that clearly shows a CNN relying on context\nto make accurate predictions.\n\n* The use of a toy tic-tac-toe domain to study attention in CNNs\n(implicit or otherwise) is a potentially fruitful setting that may\nlead to better understanding of implicit and maybe explicit attention mechanisms.\n\n\nCons\n===\n\n* This work distinguishes between predictions about \"what will happen\"\n(will the white player win?) and \"what to do\" (where should the white\nplayer move to win?). The central idea is generalization from \"what will happen\"\nto \"what to do\" indicates concept learning (sec. 2.1). Why should an ability to\nact be any more indicative of a learned concept than an ability to predict\nfuture states. I see a further issue with the presentation of this approach and\na potential correctness problem:\n\n1. (correctness)\nIn the specific setting proposed I see no difference between \"what to do\"\nand \"what will happen.\"\n\nSuppose one created labels dictating \"what to do\" for each example in the\nproposed dataset. How would these differ from the labels of \"what will happen\"\nin the proposed dataset? In this case \"what will happen\" labels include\nboth player identity (who wins) and board position (which position they move\nto win). Wouldn't the \"what to do\" labels need to indicate board position?\nThey could also chosen to indicate player identity, which would make them\nidentical to the \"what will happen\" labels (both 18-way softmaxes).\n\n2. (presentation)\nI think this distinction would usually be handled by the Reinforcement Learning\nframework, but the proposed method is not presented in that framework or\nrelated to an RL based approach. In RL \"what will happen\" is the reward an\nagent will receive for making a particular action and \"what to do\" is the\naction an agent should take. From this point of view, generalization from\n\"what will happen\" to \"what to do\" is not a novel thing to study.\n\nAlternate models include:\n    * A deep Q network (Mnih. et. al. 2015) could predict the value of\n      every possible action where an action is a (player, board position) tuple.\n    * The argmax of the current model's softmax could be used as an action\n      prediction.\nThe deep Q network approach need not be implemented, but differences between\nmethods should be explained because of the uniqueness of the proposed approach.\n\n\n* Comparison to work that uses visualization to investigate deep RL networks\nis missing. In particular, other work in RL has used Simonyan et. al.\n(arXiv 2013) style saliency maps to investigate network behavior. For example, \n\"Dueling Network Architectures for Deep Reinforcement Learning\" by Wang et. al.\nin (ICML 2016) uses saliency maps to identify differences between their\nstate-value and advantage networks. In \"Graying the black box:\nUnderstanding DQNs\" by Zahavy et. al. (ICML 2016) these saliency maps are\nalso used to analyze network behavior.\n\n\n* In section 2.3, saliency maps of Simonyan et. al. are said to not be able to\nactivate on grid squares because they have constant intensity, yet no empirical\nor theoretical evidence is provided for this claim.\n\nOn a related note, what precisely is the notion of information referenced in\nsection 2.3 and why is it relevant? Is it entropy of the distribution of pixel\nintensities in a patch? To me it seems that any measure which depends only\non one patch is irrelevant because the methods discussed (e.g., saliency maps)\ndepend on context as well as the intensities within a patch.\n\n\n* The presentation in the paper would be improved if the results in section 7\nwere presented along with relevant discussion in preceding sections.\n\n\nOverall Evaluation\n===\nThe experiments presented here are novel, but I am not sure they are very\nsignificant or offer clear conclusions. The methods and goals are not presented\nclearly and lack the broader relevant context mentioned above. Furthermore, I\nfind the lines of thought mentioned in the Cons section possibly incorrect\nor incomplete. As detailed with further clarifying questions, upon closer\ninspection I do not see how some aspects of the proposed approach were\nimplemented, so my opinion may change with further details.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512692533, "id": "ICLR.cc/2017/conference/-/paper117/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer2", "ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512692533}}}, {"tddate": null, "tmdate": 1481959410561, "tcdate": 1481959410561, "number": 1, "id": "Hk5euvf4g", "invitation": "ICLR.cc/2017/conference/-/paper117/official/review", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer2"], "content": {"title": "Still not sure what to take away from these experiments", "rating": "3: Clear rejection", "review": "1029 tic-tac-toe boards are rendered (in various ways). These 1029 boards are legal boards where the next legal play can end the game. There are 18 categories of such boards -- 9 for the different locations of the next play, and 2 for the color of the next play. The supervision is basically saying \"If you place a black square in the middle right, black will win\" or \"if you place a white square in the upper left, white will win\". A CNN is trained to predict these 18 categories and can do so with 100% accuracy.\n\nThe focus of the paper is using Zhou et al's Class Activation Mapping to show where the CNN focuses when making it's decision. As I understand it, an input to CAM is the class of interest. So let's say it is class 1 (black wins with a play to the bottom right square, if I've deciphered figure 2 correctly. Figure 2 should really be more clear about what each class is). So we ask CAM to determine the area of focus of the CNN for deciding whether class 1 is exhibited. The focus ends up being on the empty bottom right square (because certainly you can't exhibit class 1 if the bottom right square is occupied). The CNN also needs to condition its decision on other parts of the board -- it needs to know whether there will be 3 in a row from some direction. But maybe that conditioning is weaker?\n\nThat's kind of interesting but I'm not sure about the deeper statements about discovering game rules that the paper hints at. I'm also not sure about the connection of this work to weakly supervised learning or multi-modal learning.\n\nThe paper is pretty well written, overall, with some grammatical mistakes, but I simply don't see the surprising discovery of this work. \n\nI also have some concerns about how contrived this scenario is -- using a big, expressive CNN for such a simple game domain and using a particular CNN visualization method.\n\nI am not an expert in reinforcement learning (which isn't happening in this paper, but is in related works on CNN game playing), so maybe I'm not appreciating the paper appropriately.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512692533, "id": "ICLR.cc/2017/conference/-/paper117/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer2", "ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512692533}}}, {"tddate": null, "tmdate": 1481606848323, "tcdate": 1481606108293, "number": 3, "id": "r1VyNb67x", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "rJGZIxxXg", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "quantitative evaluation", "comment": "* Could more quantitative analysis be provided to support the claims about model behavior? How often does the CAM localization pick the correct winning square? Can the learned features be used to predict whose turn it is, where they should move, and if anyone can win?\n\nWe did quantitative evaluations with two protocols as described in the 7th section. Generally speaking, the accuracy is at least 70%.\n\n* The chessboard domain is much simpler than the domain of natural images, but a pre-trained AlexNet was used on this domain. Architecture choices are necessarily somewhat arbitrary, but is there a reason a network tuned to natural images was used? Why not a randomly initialized AlexNet or a simpler architecture?\n\nWe use alexnet just out of convenience ... experiments with arbitrary architectures coming soon.\n\n* This work shows a way in which the behavior of a model can be interpreted in a toy scenario. Aside from the original use of CAM for natural images, can this work provide insights about existing model classes deployed in real world problem or about how to design procedures that make non-toy models interpretable?\n\nAbout non-toy results, it is not quite feasible for us to experiment with complicated games like Go. But we may provide results on non-rendered tic-tac-toe chessboards.\n\n* The observation that CAM localizes regions of constant pixel intensity is interesting. Have the authors considered if there is a way to identify the relevant context?\n\nThanks for your positive feedback. We have not thought about it and maybe in the future we may figure out a solution to identify the relevant context."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "tmdate": 1481606177268, "tcdate": 1481522940205, "number": 2, "id": "H14Z1asml", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "H1KbXjF7x", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "on triviality", "comment": "* If I understand correctly, the CNN is trained to classify one of the 1029 states into 18 categories. These 18 categories and each of them correspond to the location of putting the piece that will make one of the 2 players win. Why is it surprising or interesting that a CNN activations fire at the correct location? *\n\nIn order to answer this question, we have added one more experiment IV in the paper.\n\nWe argue that 'firing at the correct location' is not the only choice to achieve this classification task (and thus not a trivial finding). Actually there are two potential ways:\n\n(1) classify by paying attention to the visual patterns formed by existing pieces. (without knowing the concepts of the game)\n\n(2) classify by paying attention at the 'correct location'\n\nexperiment IV shows that at an earlier stage the model behaves like (1) and finally gains the ability to 'fire at the correct location'.\n\n* More specifically consider the following case - the image consists of either letters A or B. Then I train a CNN to predict does the image have A or B and then I find activations of the CNN are on the character. This is expected. How is what you train for (functionally) different from this? *\n\nIt is highly related to the third point we claim in the paper: \"can CAM activate at non-salient regions\".\n\nIf there is only A/B in the visual inputs, activating at their locations is trivial because there are gradients at the boundaries of 'visual A/B'. However, in this experiment, totally information-free regions are activated. \n\nSo we argue that the 'A/B experiment' is not analogous to our experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481605575284, "tcdate": 1478237330949, "number": 117, "id": "rJo9n9Feg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJo9n9Feg", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "content": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481526563569, "tcdate": 1481520330411, "number": 1, "id": "SyMCE3oQe", "invitation": "ICLR.cc/2017/conference/-/paper117/public/comment", "forum": "rJo9n9Feg", "replyto": "B1685r97g", "signatures": ["~Hao_Zhao1"], "readers": ["everyone"], "writers": ["~Hao_Zhao1"], "content": {"title": "The problems studied in this paper and AlphaGo are different.", "comment": "The goal of AlphaGo's SL component is to predict the expert's move.\n\nThe goal of this paper is to investigate why the network can accurately predict the (expert's or right) move.\n\nAnd there are two potential answers to the question 'why the network can accurately predict the (expert's or right) move' :\n\n(1) The network does not understand the concepts of the game. It predicts the right move according to existing pieces' patterns.\n\n(2) The network somewhat understands the concepts of the game. It predicts the right move according to the 'empty space' on the chessboard.\n\nAnd we provide several experiments to support that: the second answer is right.\n\nThis is what we are trying to claim here ... and it's quite different from what AlphaGo claims so we did not cite AlphaGo in the draft. \n\nWe can cover AlphaGo in the background discussion."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287721006, "id": "ICLR.cc/2017/conference/-/paper117/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJo9n9Feg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper117/reviewers", "ICLR.cc/2017/conference/paper117/areachairs"], "cdate": 1485287721006}}}, {"tddate": null, "tmdate": 1481427541268, "tcdate": 1481427541261, "number": 3, "id": "B1685r97g", "invitation": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer2"], "content": {"title": "Relation to AlphaGo", "question": "This paper cites the 2015 DeepMind work on game playing but not the more related 2016 Nature paper on AlphaGo( Mastering the game of Go with deep neural networks and tree search. David Silver et al., Nature, 2016). AlphaGo's SL component seems similar to this work. Can you elaborate on the relationship?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481427541909, "id": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3", "ICLR.cc/2017/conference/paper117/AnonReviewer2"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481427541909}}}, {"tddate": null, "tmdate": 1481384705139, "tcdate": 1481384705129, "number": 2, "id": "H1KbXjF7x", "invitation": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer3"], "content": {"title": "Regarding interpretation of results", "question": "If I understand correctly, the CNN is trained to classify one of the 1029 states into 18 categories. These 18 categories and each of them correspond to the location of putting the piece that will make one of the 2 players win. Why is it surprising or interesting that a CNN activations fire at the correct location? \n\nMore specifically consider the following case - the image consists of either letters A or B. Then I train a CNN to predict does the image have A or B and then I find activations of the CNN are on the character. This is expected. How is what you train for (functionally) different from this? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481427541909, "id": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3", "ICLR.cc/2017/conference/paper117/AnonReviewer2"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481427541909}}}, {"tddate": null, "tmdate": 1480750586423, "tcdate": 1480750586419, "number": 1, "id": "rJGZIxxXg", "invitation": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "signatures": ["ICLR.cc/2017/conference/paper117/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper117/AnonReviewer1"], "content": {"title": "Initial Questions", "question": "* Could more quantitative analysis be provided to support the claims about model behavior? How often does the CAM localization pick the correct winning square? Can the learned features be used to predict whose turn it is, where they should move, and if anyone can win?\n\n* The chessboard domain is much simpler than the domain of natural images, but a pre-trained AlexNet was used on this domain. Architecture choices are necessarily somewhat arbitrary, but is there a reason a network tuned to natural images was used? Why not a randomly initialized AlexNet or a simpler architecture?\n\n* This work shows a way in which the behavior of a model can be interpreted in a toy scenario. Aside from the original use of CAM for natural images, can this work provide insights about existing model classes deployed in real world problem or about how to design procedures that make non-toy models interpretable?\n\n* The observation that CAM localizes regions of constant pixel intensity is interesting. Have the authors considered if there is a way to identify the relevant context?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Chess Game Concepts Emerge under Weak Supervision: A Case Study of Tic-tac-toe", "abstract": "This paper explores the possibility of learning chess game concepts under weak supervision with convolutional neural networks, which is a topic that has not been visited to the best of our knowledge. We put this task in three different backgrounds: (1) deep reinforcement learning has shown an amazing capability to learn a mapping from visual inputs to most rewarding actions, without knowing the concepts of a video game. But how could we confirm that the network understands these concepts or it just does not? (2) cross-modal supervision for visual representation learning draws much attention recently. Is this methodology still applicable when it comes to the domain of game concepts and actions? (3) class activation mapping is widely recognized as a visualization technique to help us understand what a network has learnt. Is it possible for it to activate at non-salient regions? With the simplest chess game tic-tac-toe, we report interesting results as answers to those three questions mentioned above. All codes, pre-processed datasets and pre-trained models will be released.", "pdf": "/pdf/479d3f447c4e6159ef11734a26a7bdfd1d82d7b5.pdf", "TL;DR": "investigating whether a CNN understands concepts from a new perspective", "paperhash": "zhao|chess_game_concepts_emerge_under_weak_supervision_a_case_study_of_tictactoe", "keywords": ["Semi-Supervised Learning"], "conflicts": ["tsinghua.edu.cn", "intel.com"], "authors": ["Hao Zhao", "Ming Lu", "Anbang Yao", "Yurong Chen", "Li Zhang"], "authorids": ["zhao-h13@mails.tsinghua.edu.cn", "lu-m13@mails.tsinghua.edu.cn", "anbang.yao@intel.com", "yurong.chen@intel.com", "chinazhangli@mail.tsinghua.edu.cn"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481427541909, "id": "ICLR.cc/2017/conference/-/paper117/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper117/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper117/AnonReviewer1", "ICLR.cc/2017/conference/paper117/AnonReviewer3", "ICLR.cc/2017/conference/paper117/AnonReviewer2"], "reply": {"forum": "rJo9n9Feg", "replyto": "rJo9n9Feg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper117/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481427541909}}}], "count": 14}