{"notes": [{"id": "r1GgDj0cKX", "original": "rklfed6FFX", "number": 233, "cdate": 1538087768077, "ddate": null, "tcdate": 1538087768077, "tmdate": 1545355429725, "tddate": null, "forum": "r1GgDj0cKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["yanweifu@fudan.edu.cn", "15300180012@fudan.edu.cn", "15307100013@fudan.edu.cn", "sxwxiaoxiaohehe@pku.edu.cn", "xyxue@fudan.edu.cn", "yuany@ust.hk"], "authors": ["Yanwei Fu", "Shun Zhang", "Donghao Li", "Xinwei Sun", "Xiangyang Xue", "Yuan Yao"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "fu|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@misc{\nfu2019pruning,\ntitle={{PRUNING} {IN} {TRAINING}: {LEARNING} {AND} {RANKING} {SPARSE} {CONNECTIONS} {IN} {DEEP} {CONVOLUTIONAL} {NETWORKS}},\nauthor={Yanwei Fu and Shun Zhang and Donghao Li and Xinwei Sun and Xiangyang Xue and Yuan Yao},\nyear={2019},\nurl={https://openreview.net/forum?id=r1GgDj0cKX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "S1giB6D4eN", "original": null, "number": 1, "cdate": 1545006402973, "ddate": null, "tcdate": 1545006402973, "tmdate": 1545354486570, "tddate": null, "forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "invitation": "ICLR.cc/2019/Conference/-/Paper233/Meta_Review", "content": {"metareview": "This paper propose to obtain high pruning ratio by adding constraints to obtain small weights. Reviewers have a consensus on rejection due to not convincing experiments and lack of novelty.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": " not convincing experiments and lack of novelty"}, "signatures": ["ICLR.cc/2019/Conference/Paper233/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper233/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["yanweifu@fudan.edu.cn", "15300180012@fudan.edu.cn", "15307100013@fudan.edu.cn", "sxwxiaoxiaohehe@pku.edu.cn", "xyxue@fudan.edu.cn", "yuany@ust.hk"], "authors": ["Yanwei Fu", "Shun Zhang", "Donghao Li", "Xinwei Sun", "Xiangyang Xue", "Yuan Yao"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "fu|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@misc{\nfu2019pruning,\ntitle={{PRUNING} {IN} {TRAINING}: {LEARNING} {AND} {RANKING} {SPARSE} {CONNECTIONS} {IN} {DEEP} {CONVOLUTIONAL} {NETWORKS}},\nauthor={Yanwei Fu and Shun Zhang and Donghao Li and Xinwei Sun and Xiangyang Xue and Yuan Yao},\nyear={2019},\nurl={https://openreview.net/forum?id=r1GgDj0cKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper233/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353290225, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper233/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper233/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper233/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353290225}}}, {"id": "Syx-wJFkpX", "original": null, "number": 3, "cdate": 1541537625332, "ddate": null, "tcdate": 1541537625332, "tmdate": 1541537625332, "tddate": null, "forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "invitation": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "content": {"title": "network pruning in training", "review": "This manuscript presents a method to prune deep neural networks while training. The main idea is to use some regularization to force some parameters to have small values, which will then be subject to pruning. \nOverall, the proposed method is not very interesting. More importantly, the manuscript only lists the percentage of pruned parameters, but did not compare the actual running time before and after pruning. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper233/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["yanweifu@fudan.edu.cn", "15300180012@fudan.edu.cn", "15307100013@fudan.edu.cn", "sxwxiaoxiaohehe@pku.edu.cn", "xyxue@fudan.edu.cn", "yuany@ust.hk"], "authors": ["Yanwei Fu", "Shun Zhang", "Donghao Li", "Xinwei Sun", "Xiangyang Xue", "Yuan Yao"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "fu|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@misc{\nfu2019pruning,\ntitle={{PRUNING} {IN} {TRAINING}: {LEARNING} {AND} {RANKING} {SPARSE} {CONNECTIONS} {IN} {DEEP} {CONVOLUTIONAL} {NETWORKS}},\nauthor={Yanwei Fu and Shun Zhang and Donghao Li and Xinwei Sun and Xiangyang Xue and Yuan Yao},\nyear={2019},\nurl={https://openreview.net/forum?id=r1GgDj0cKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "cdate": 1542234508738, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678306, "tmdate": 1552335678306, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkez5fyA3m", "original": null, "number": 2, "cdate": 1541431946099, "ddate": null, "tcdate": 1541431946099, "tmdate": 1541534172063, "tddate": null, "forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "invitation": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "content": {"title": "Needs more formalism regarding the regularization path", "review": "\n\n==Major comments==\n\nYou need to better explain how the regularization path is obtained for your method. It is not clear to me at all why the iterates from lines 5-8 in Alg 2 provide a valid regularization path. \n\nI am very confused by section 3.4. Is the pruning strategy introduced in this section specific to LBI? In other words, is there some property of LBI where the regularization path can be obtained by sorting the parameters by weight? It seems like it's not specific to LBI, since you use this pruning strategy for other models in your experiments. Is this the right baseline? Surely there are other sparsification strategies.\n\n\nHow/why did you select 5e-4 for lambda? You should have tuned for performance on a validation set. Also, you should have tuned separately for each of the baselines. There is no reason that they should all use the same lambda value.\n\nCan you say anything about the suboptimality of the support sets obtained by your regularization paths vs. if you had trained things independently with different regularization penalties?\n\nI am very concerned by this statement: \n\"However, in practice, we found that the network training algorithm, i.e., SGD in Alg. 3, is unstable, if we apply the sparse penalties more than four layers.\"\nThis is important. Do you have idea of why it is true? This instability seems like an obstacle for large-scale deployment.\n\nAre your baselines state of the art? Is there anything discussed in the related work section that you should also be comparing against?\n\n\n==Minor comments==\nThe difference between Alg 2 and 3 is mechanical and should be obvious to readers. I'd remove it, as the notation is complex and it doesn't add to the exposition quality. Instead, you should provide an algorithm box that explains how you postprocess W to obtain a sparse network.\n\nYour citation format is incorrect. You should either have something along the lines of \"foo, which does X, was introduced in author_name et al. (2010)\" or \"foo does X (author_name, 2010).\" Perhaps you're using \\citet instead of \\citep in natbib.\n\nAlgorithm box 1 is not necessary. It is a very standard concept in machine learning. \n\nOn the left hand of (5), shouldn't Prox be subscripted by L instead of P?\n\n\n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper233/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["yanweifu@fudan.edu.cn", "15300180012@fudan.edu.cn", "15307100013@fudan.edu.cn", "sxwxiaoxiaohehe@pku.edu.cn", "xyxue@fudan.edu.cn", "yuany@ust.hk"], "authors": ["Yanwei Fu", "Shun Zhang", "Donghao Li", "Xinwei Sun", "Xiangyang Xue", "Yuan Yao"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "fu|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@misc{\nfu2019pruning,\ntitle={{PRUNING} {IN} {TRAINING}: {LEARNING} {AND} {RANKING} {SPARSE} {CONNECTIONS} {IN} {DEEP} {CONVOLUTIONAL} {NETWORKS}},\nauthor={Yanwei Fu and Shun Zhang and Donghao Li and Xinwei Sun and Xiangyang Xue and Yuan Yao},\nyear={2019},\nurl={https://openreview.net/forum?id=r1GgDj0cKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "cdate": 1542234508738, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678306, "tmdate": 1552335678306, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkgQJOqsh7", "original": null, "number": 1, "cdate": 1541281755482, "ddate": null, "tcdate": 1541281755482, "tmdate": 1541534171861, "tddate": null, "forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "invitation": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "content": {"title": "pruning in training using lasso and split LBI penalties. Not convincing experiments", "review": "This paper introduces an approach to pruning while training a network. This is interesting and experiments show interesting results in several datasets including ResNet18\n\nHere are a few comments:\n\n - Pruning or regularization for compression is not new. Alvarez and Wen have used group lasso types as suggested in the paper and some others such as Alvarez and Salzmann (Compression aware training NIPS 2017) and Wen (Coordinating filters ICCV2017) have used low-rank type of while training. How is this different to those? They also do not need any sort of fine tuning and more importantly, they show this can scale to large networks and datasets. \n\n- These last two works I mentioned promote redundancy, similarly to what is suggested in the paper. Would be good to get them cited and compared. Important from those is the training methodology to avoid relevant overheads. How is that happening in the current approach\n\n\n- While I like the approach, would be nice to see how this scale.  All for methods above (and others related) do work on full imagenet to show performance.  For ResNet, cleaning the network is not really trivial (near the block), is that a limitation?\n- Why limiting experiments to small networks and datasets? Time wise, how does this impact the training time?\n- Why limiting the experiments to at most 4 layers? \n- I am certainly not impressed by results on fully connected layers in MNIST. While the experiment is interesting does not seem to be of value as most networks do not have those layers anymore.\n\n- Main properties of this approach are selecting right filters while training without compromising accuracy or needing fine tuning. While that is of interest, i do not see the difference with other related works (such as those I cited above)\n\n- As there is enough space, I would like to see top-1 results for comprehensive comparison. \n\n- I think tables need better captions for being self-contained. I do not really understand what i see in table 5 for instance. \n- Droping 13% of top5 accuracy does not seem negligible, what is the purpose there? Would also be interesting to compare then with any other network with that performance. \n- What about flops and forward time? Does this pruning strategy help there?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper233/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PRUNING IN TRAINING: LEARNING AND RANKING SPARSE CONNECTIONS IN DEEP CONVOLUTIONAL NETWORKS", "abstract": "This paper proposes a Pruning in Training (PiT) framework of learning to reduce the parameter size of networks. Different from existing works, our PiT framework employs the sparse penalties to train networks and thus help rank the importance of weights and filters. Our PiT algorithms can directly prune the network without any fine-tuning. The pruned networks can still achieve comparable performance to the original networks. In particular, we introduce the (Group) Lasso-type Penalty (L-P /GL-P), and (Group) Split LBI Penalty (S-P / GS-P) to regularize the networks, and a pruning strategy proposed  is used in help prune the network. We conduct the extensive experiments on MNIST, Cifar-10, and miniImageNet. The results validate the efficacy of our proposed methods. Remarkably, on MNIST dataset, our PiT framework can save 17.5% parameter size of LeNet-5, which achieves the 98.47% recognition accuracy.", "keywords": ["Split LBI", "sparse penalty", "network pruning", "feature selection"], "authorids": ["yanweifu@fudan.edu.cn", "15300180012@fudan.edu.cn", "15307100013@fudan.edu.cn", "sxwxiaoxiaohehe@pku.edu.cn", "xyxue@fudan.edu.cn", "yuany@ust.hk"], "authors": ["Yanwei Fu", "Shun Zhang", "Donghao Li", "Xinwei Sun", "Xiangyang Xue", "Yuan Yao"], "TL;DR": "we propose an algorithm of learning to prune network by enforcing structure sparsity penalties", "pdf": "/pdf/d2729e43481122474e30b5cb4ce4bc7bf837556d.pdf", "paperhash": "fu|pruning_in_training_learning_and_ranking_sparse_connections_in_deep_convolutional_networks", "_bibtex": "@misc{\nfu2019pruning,\ntitle={{PRUNING} {IN} {TRAINING}: {LEARNING} {AND} {RANKING} {SPARSE} {CONNECTIONS} {IN} {DEEP} {CONVOLUTIONAL} {NETWORKS}},\nauthor={Yanwei Fu and Shun Zhang and Donghao Li and Xinwei Sun and Xiangyang Xue and Yuan Yao},\nyear={2019},\nurl={https://openreview.net/forum?id=r1GgDj0cKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper233/Official_Review", "cdate": 1542234508738, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1GgDj0cKX", "replyto": "r1GgDj0cKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper233/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678306, "tmdate": 1552335678306, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper233/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}