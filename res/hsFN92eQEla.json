{"notes": [{"id": "hsFN92eQEla", "original": "bNIgGAm0nTr", "number": 1801, "cdate": 1601308198718, "ddate": null, "tcdate": 1601308198718, "tmdate": 1614975558644, "tddate": null, "forum": "hsFN92eQEla", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "-85RM5mGddT", "original": null, "number": 1, "cdate": 1610040348057, "ddate": null, "tcdate": 1610040348057, "tmdate": 1610473936836, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper questions the use of cross-entropy loss for classification tasks and shows that using squared error loss can work just as well for deep neural networks. The authors conduct extensive experiments across ASR, NLP, and CV tasks. Comparing cross-entropy to squared error loss is certainly not novel, but the conclusions of the paper, backed by a lot of experimental evidence, are certainly thought-provoking. \n\nI would have liked to see a bit more analysis into the results of the paper, and perhaps a bit more theoretical justification. That said, the paper will be of interest to the community, given the ubiquity of classification tasks.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040348034, "tmdate": 1610473936814, "id": "ICLR.cc/2021/Conference/Paper1801/-/Decision"}}}, {"id": "PFhXRHNCgRL", "original": null, "number": 3, "cdate": 1605747464465, "ddate": null, "tcdate": 1605747464465, "tmdate": 1605749651735, "tddate": null, "forum": "hsFN92eQEla", "replyto": "cmtj9T-j3d_", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment", "content": {"title": "They are not equivalent because the minimizer of the two losses are different", "comment": "Thanks for the comments!\n\nPerhaps the easiest way to see that the two losses are not equivalent is to consider the case with an infinite number of y\u2019s and a single fixed x.  Assuming you have two outcomes 1 with probability p and -1 with probability 1-p, the minimizer of the square loss is 2*p -1, while the minimizer of the cross-entropy loss is log(p/(1-p)). It is true that both are admissible loss functions (as is the hinge loss) -- the corresponding prediction rules (the sign of the minimizer) coincide with the Bayes optimal predictor, which is 1 if p>0.5 and -1 otherwise.  However, there is generally no reason (as is clear from the fact that the numerical values of the losses are different) that ERM algorithms that optimize different loss functions will produce same (or even similar) predictors.  "}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1801/Authors|ICLR.cc/2021/Conference/Paper1801/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923855596, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment"}}}, {"id": "zlCb8clTWBo", "original": null, "number": 7, "cdate": 1605749592506, "ddate": null, "tcdate": 1605749592506, "tmdate": 1605749592506, "tddate": null, "forum": "hsFN92eQEla", "replyto": "UtutCgLBgXe", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "Thanks for the encouraging comments!\n\nWe agree that understanding the choice of loss functions in different domains is very important. Indeed, our results already hint that there may be systematic differences between domains. However, we feel the evidence is not yet strong enough and  significantly more experimentation is needed before definite conclusions can be made.  This is an important direction of future work. We will adjust the conclusion to reflect this. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1801/Authors|ICLR.cc/2021/Conference/Paper1801/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923855596, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment"}}}, {"id": "jYWwmesH7mW", "original": null, "number": 6, "cdate": 1605749526131, "ddate": null, "tcdate": 1605749526131, "tmdate": 1605749541658, "tddate": null, "forum": "hsFN92eQEla", "replyto": "EM6koFBcsuU", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thanks for the comments!\n\n--> For the comment on additional learning settings about noisy label learning\n\n  We agree that the noisy label setting is important and interesting to explore. However we feel that it goes beyond the scope of this paper, as it requires significant additional experimental analysis in different settings (e.g., understanding the results depending on the noise level or types of noise). This is a direction of future work. \n\n--> For the comment about square loss with softmax outputs\n  \n  We have done experiments with the square loss with softmax output, however the results  generally appeared to be poor. For example, for ImageNet dataset generalization performance for square loss with softmax outputs was close to a random guess.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1801/Authors|ICLR.cc/2021/Conference/Paper1801/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923855596, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment"}}}, {"id": "E9hWk2YFRr5", "original": null, "number": 5, "cdate": 1605749446533, "ddate": null, "tcdate": 1605749446533, "tmdate": 1605749446533, "tddate": null, "forum": "hsFN92eQEla", "replyto": "iEfwhZDxnMi", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thanks for the comments!\n\n--> \u201cthe average accuracies are reported but not standard deviation to get a sense of the variation across performance for both loss functions. Statistical significance calculations would also be helpful to interpret results.\u201d\n\n  We give the standard deviations (among 5 runs with different initializations) in Table 8. Also we plot the error bars in Figure 1 and Figure 3. Figure 1 shows the difference between accuracy (or error rate) between square loss and CE for each initialization, while Figure 3 shows the error bars of 5 runs corresponding to 5 different initializations.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1801/Authors|ICLR.cc/2021/Conference/Paper1801/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923855596, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment"}}}, {"id": "GWa2aKDk-pQ", "original": null, "number": 4, "cdate": 1605748890382, "ddate": null, "tcdate": 1605748890382, "tmdate": 1605749138309, "tddate": null, "forum": "hsFN92eQEla", "replyto": "FM-XMSDc2rT", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thanks for the comments!\n\n--> \u201cThe paper does not make an effort to provide well-grounded explanations for the experimental observations.\u201d\n    \n  Currently there is  limited theoretical understanding of the choice of loss functions in modern neural architectures or even for simpler settings, such as kernel machines. Thus we concentrated on identifying and clearly demonstrating these practically important phenomena with the hope that future work will shed light on their theoretical aspects. \n\n--> \u201cIt is unclear how the CTC-based architectures for ASR were modified for square-loss. An explanation in the paper would be helpful.\u201d\n\n  Only the TIMIT experiments have CTC-based architectures and they use both CTC-loss and CE (a weighted sum of the two losses) in the original implementation. We only replaced the CE part with the square loss, and didn\u2019t change the CTC part. We updated the paper to make this clear, thanks for pointing it out.\n\n--> For Question 2: \u201cWhat is the opinion of authors about the trade-off between the hyperparameter associated with the loss-scaling Vs. the simplicity of the cross-entropy loss for a larger number of classes?\u201d\n \n   This is a very interesting question, and we have following points:\n      For tasks with small class numbers, rescaling for the square loss is not necessary, so there is no trade-off.\n      For tasks with a large number of classes, rescaling the loss function was needed to obtain competitive results. However, it is not clear whether it is a true trade-off or simply the result of our insufficient understanding of the underlying problem.  We conjecture that better theoretical understanding of the problem can give us a simple rescaling rule based on the number of classes and no additional hyper-parameter tuning will be needed. This is an important future direction for theoretical and empirical analysis. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1801/Authors|ICLR.cc/2021/Conference/Paper1801/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923855596, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Comment"}}}, {"id": "cmtj9T-j3d_", "original": null, "number": 1, "cdate": 1605203213101, "ddate": null, "tcdate": 1605203213101, "tmdate": 1605209656380, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Public_Comment", "content": {"title": "Why are the two losses not equivalent?", "comment": "I would like to thank the authors for proposing this interesting work that support their claims with very extensive experiments. I had a more theoretical question regarding their proposal.\n\nConsider for simplicity a binary classification problem with f_0(x), f_1(x) be the outputs of the neural network. Say we want to train with a squared error loss, and as mentioned on page 8 of the paper, let there be no final softmax layer. The loss then is\n$L = (f_0 - [1-y])^2/2 + (f_1-y)^2/2.$\n\nNow, say we would like to give a probabilistic interpretation to this. Minimizing the cross-entropy loss is the same as doing maximum likelihood on a Bernoulli response Y where the probabilities would be given by $\\text{softmax}([f_0, f_1])$. Thus I was wondering, if this loss was the result of doing maximum likelihood on a probabilistic model, what would that probabilistic model be?\n\nWorking out the math, it would mean that $P[Y=y|X=x] \\propto \\exp(-(f_0 - [1-y])^2/2 - (f_1-y)^2/2)$, which is  $\\exp(-f_0^2/2 + [1-y]f_0 - [1-y]/2 - f_1^2/2 + yf_1 - y/2)$ because $y^2=y$ and $(1-y)^2=1-y$. Thus $P[Y=y|X=x] \\propto \\exp([1-y]f_0 + yf_1) = \\exp(f_y(x))$, which is to say\n\n$P[Y=y|X=x] = \\frac{\\exp(f_y(x))}{\\exp(f_0(x))+\\exp(f_1(x))}.$\n\nAssuming I have not made a mistake, this would mean that Y|X=x would have exactly the same implied distribution as if you had used the cross-entropy loss. Thus any differences between using the cross-entropy loss or the squared error loss would not come from differences in modeling the relationship between the response and the covariates.\n\nLooking at experimental results, the differences between cross-entropy and squared-error loss seem very small (tables 2, 3, 5, 7). In fact, it is not clear to me whether the differences are even statistically significant. Thus I am wondering, could you expand as to why, despite the argument above, these two losses are not in fact equivalent?"}, "signatures": ["~Didier_Ch\u00e9telat1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Didier_Ch\u00e9telat1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "hsFN92eQEla", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/Authors", "ICLR.cc/2021/Conference/Paper1801/Reviewers", "ICLR.cc/2021/Conference/Paper1801/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024968640, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Public_Comment"}}}, {"id": "UtutCgLBgXe", "original": null, "number": 1, "cdate": 1603734538624, "ddate": null, "tcdate": 1603734538624, "tmdate": 1605024355085, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review", "content": {"title": "Interesting paper that challenges the conventional wisdom of CE loss being superior to MSE loss in clasffication tasks. ", "review": "\nI think this a very good contribution to ICLR given the topic and the quality of the submission (originality, contribution to the stare of the art, experimental evidence, etc) \n\n Some of the strong points of the submission are summarized as follows:\n\n1.\tThe paper tackles a very interesting subject, questioning the conventional wisdom the CE is superior to MSE loss in a wide range of machine learning problems. \n2.\tVery good introduction and motivations sections. The hypothesis, as well as the main motivations are discussed succinctly but in a very logical manner including historical aspects leading to the current state of affairs (in terms of the manner in which models are trained) that might be helpful for interested readers not sufficiently familiar with the aspects discussed in the article.\n3.\tThe state of the art (despite the previous comment) contextualizes the subject matter in a succinct but comprehensive manner. \n4.\tI have read people making similar claims in other forums and articles, but the authors here provide a very thorough and careful experimental design, which helps to validate their hypothesis. However, it would be interesting to see how these experiments generalize to problems (in particular in computer vision) where datasets are noisier or where the image quality/resolution are lower.\n5.\tThe experimental design is good, showing a careful analysis to validate the proposal and several ablation studies to confirm that the hypothesis holds for various machine learning domains, as well as several datasets.\n6.\tThe foundations for the method are presented in great detail in a formalized manner and provides sufficient to assess the validity of the proposed experimental design.\n\nHowever, there are certain things that in my opinion could be improved:\n\n1.\tFuture work could be further elaborated and discussion in specific domains (medical imaging, for instance) could be further discussed.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538110443, "tmdate": 1606915794799, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1801/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review"}}}, {"id": "EM6koFBcsuU", "original": null, "number": 2, "cdate": 1603880439969, "ddate": null, "tcdate": 1603880439969, "tmdate": 1605024355007, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review", "content": {"title": "Empirical Evaluation of Cross Entropy vs Square Loss ", "review": "The paper compares cross-entropy and squared losses on a wide range of tasks. The focus primarily is on thorough empirical evaluation of these two losses on NLP, Vision and Speech tasks. The paper shows that squared loss is better or competitive with cross-entropy loss in most cases. Most of the experiments and comparisons seem to be well done; parameters, setups etc. are well explained. \n\nI believe a few additional tasks and settings would have helped put a better picture of the comparison. \nFor speech, the application of the two losses in tasks beyond ASR might give more insights. Similar for vision, classification tasks other than image classification (on MNIST/CIFAR and Imagenet) might be useful. \n\nAdditional learning settings might also be useful. For example, there is considerable amount of work (e.g R1 and R2 below) on noisy label learning, where the loss function (often cross entropy losses) is modified for noisy label condition. What do we expect for these two losses  in this noisy label setting ? Essentially what can we expect in learning settings beyond the supervised training in vanilla form. \n\nFor square loss, scaling is done for a large number of classes. The motivation behind it is not very clear. Also, it is perhaps worth showing results for squared loss with softmax outputs. Especially for the large number of classes. Can softmax be advantageous in this case for performance, even though computationally it will be worse than the scaling mechanism applied. \n\nR1. Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels\nR2. Normalized Loss Functions for Deep Learning with Noisy Labels\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538110443, "tmdate": 1606915794799, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1801/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review"}}}, {"id": "iEfwhZDxnMi", "original": null, "number": 3, "cdate": 1603905706811, "ddate": null, "tcdate": 1603905706811, "tmdate": 1605024354937, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review", "content": {"title": "Important work towards understanding loss function choice", "review": "Summary: This paper compares the more popular cross entropy loss function to the squared loss function for classification tasks. The authors look at NLP, ASR and and CV tasks, keeping the architecture the same (as much as possible) and varying the loss functions. The authors demonstrate that although cross entropy is more commonly used in state-of-the-art architectures and is standard across tutorial code, square loss functions are often times advantageous. \n\nStrengths: \nThis paper highlights an ongoing issue in deep learning -- we often take for granted what 'best practices' are and do not sufficiently investigate the best loss function, etc. when starting a new problem. \n\nThe study covers a reasonable amount of types of problems and architectures and conducts 5 random initializations which is rare in many ML papers. \n\nWeaknesses:\nWhile this work is highly important and the study was well-done, the novelty is a little low. Many papers have done variations of this same type of work to answer this question. \n\nWhile I understand there are only so many experiments that a group can do, there are some limitations to this study -- including not performing hyper-parameterization for architectures comparing the two loss functions which may reveal some important distinctions and use-cases. \n\nA minor comment is that the average accuracies are reported but not standard deviation to get a sense of the variation across performance for both loss functions. Statistical significance calculations would also be helpful to interpret results. \n\nQuestion for authors:\nWhat other areas do you find people are using the wrong hyper-parameter choice? This could be an interesting discussion write-up for researchers to re-consider how they select their training paradigm. \n\nI recommend accepting this work. The study was well-done for answering this question and more thorough than related work. My reason for not giving a higher score is that the work is not highly novel. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538110443, "tmdate": 1606915794799, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1801/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review"}}}, {"id": "FM-XMSDc2rT", "original": null, "number": 4, "cdate": 1604266312106, "ddate": null, "tcdate": 1604266312106, "tmdate": 1605024354867, "tddate": null, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "invitation": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review", "content": {"title": "The paper shows that the square loss is usually as effective as the cross-entropy loss across classification tasks in a variety of domains and model architectures.", "review": "This paper questions the omnipresence of cross-entropy loss for classification tasks while showing that square loss also yields competitive results. The experimental section spans a wide variety of tasks and architectures covering NLP, ASR, and Vision. The authors find that the model performance is more stable w.r.t. the random initialization of parameters when trained using the square loss. For NLP and ASR datasets, the authors find that the square loss yields slightly better results. The authors also report that the square loss usually takes more time to converge and requires rescaling with a larger number of classes. \nThe authors do not dwell on the fundamental reasons behind the observations made in this paper. However, I believe that these observations are indeed useful to advance further research for better loss functions. \n\nStrong Points:\n1. Diverse experiments and insightful results\n\nWeak Points:\n1. The paper does not make an effort to provide well-grounded explanations for the experimental observations. \n2. It is unclear how the CTC-based architectures for ASR were modified for square-loss. An explanation in the paper would be helpful. \n\nQuestions:\n 1. How were the CTC-based architectures for ASR were modified for square-loss. ?\n 2. What is the opinion of authors about the trade-off between the hyperparameter associated with the loss-scaling Vs. the simplicity of the cross-entropy loss for a larger number of classes?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1801/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1801/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS", "authorids": ["~Like_Hui1", "mbelkin@ucsd.edu"], "authors": ["Like Hui", "Mikhail Belkin"], "keywords": ["large scale learning", "square loss vs cross-entropy", "classification", "experimental evaluation"], "abstract": "Modern neural architectures for classification tasks are trained using the cross-entropy loss, which is widely believed to be empirically superior to the square loss. In this work we provide evidence indicating that this belief may not be well-founded. \nWe explore several major neural architectures and a range of standard benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks to show that these architectures, with the same hyper-parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources.\nIndeed, we observe that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross-entropy appears to have a slight edge on computer vision tasks.\n\nWe argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage to the cross-entropy loss. Indeed, in our experiments, performance on nearly all non-vision tasks  can be improved, sometimes significantly, by switching to the square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. We posit that\ntraining using the square loss for classification needs to be a part of best practices of modern deep learning on equal footing with cross-entropy. ", "one-sentence_summary": "An experimental evaluation of neural architectures in classification tasks shows that training with square loss produces better results than the cross-entropy in the majority of NLP and ASR experiments.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hui|evaluation_of_neural_architectures_trained_with_square_loss_vs_crossentropy_in_classification_tasks", "supplementary_material": "/attachment/cc8b160a3aa09db934889d17e82fe2e81fc68cfd.zip", "pdf": "/pdf/374e8d19ecea989cd40fe8978d54d9435fb6a677.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nhui2021evaluation,\ntitle={{\\{}EVALUATION{\\}} {\\{}OF{\\}} {\\{}NEURAL{\\}} {\\{}ARCHITECTURES{\\}} {\\{}TRAINED{\\}} {\\{}WITH{\\}} {\\{}SQUARE{\\}} {\\{}LOSS{\\}} {\\{}VS{\\}} {\\{}CROSS{\\}}-{\\{}ENTROPY{\\}} {\\{}IN{\\}} {\\{}CLASSIFICATION{\\}} {\\{}TASKS{\\}}},\nauthor={Like Hui and Mikhail Belkin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=hsFN92eQEla}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "hsFN92eQEla", "replyto": "hsFN92eQEla", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1801/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538110443, "tmdate": 1606915794799, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1801/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1801/-/Official_Review"}}}], "count": 12}